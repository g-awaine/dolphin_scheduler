[WI-0][TI-0] - [INFO] 2024-04-24 05:03:19.126 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7264705882352941 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 05:03:28.164 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7311827956989247 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-1292] - [INFO] 2024-04-24 05:03:40.991 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1292, processInstanceId=546, status=9, startTime=1713904461692, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, logPath=/opt/dolphinscheduler/logs/20240424/13201021801792/90/546/1292.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/546/1292, endTime=1713905019537, processId=841, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], eventCreateTime=0, eventSendTime=1713905920162)
[WI-0][TI-1292] - [INFO] 2024-04-24 05:03:40.999 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1292, processInstanceId=546, status=9, startTime=1713904461692, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, logPath=/opt/dolphinscheduler/logs/20240424/13201021801792/90/546/1292.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/546/1292, endTime=1713905019537, processId=841, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], eventCreateTime=0, eventSendTime=1713906220991)
[WI-0][TI-0] - [INFO] 2024-04-24 05:03:42.227 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7374301675977655 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 05:03:43.236 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7371428571428572 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-1281] - [INFO] 2024-04-24 05:04:11.048 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1281, processInstanceId=543, status=9, startTime=1713903509183, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, logPath=/opt/dolphinscheduler/logs/20240424/13201021801792/90/543/1281.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/543/1281, endTime=1713904084494, processId=300, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], eventCreateTime=0, eventSendTime=1713905950831)
[WI-0][TI-1281] - [INFO] 2024-04-24 05:04:11.051 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1281, processInstanceId=543, status=9, startTime=1713903509183, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, logPath=/opt/dolphinscheduler/logs/20240424/13201021801792/90/543/1281.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/543/1281, endTime=1713904084494, processId=300, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], eventCreateTime=0, eventSendTime=1713906251048)
[WI-0][TI-1292] - [INFO] 2024-04-24 05:08:41.322 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1292, processInstanceId=546, status=9, startTime=1713904461692, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, logPath=/opt/dolphinscheduler/logs/20240424/13201021801792/90/546/1292.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/546/1292, endTime=1713905019537, processId=841, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], eventCreateTime=0, eventSendTime=1713906220991)
[WI-0][TI-1292] - [INFO] 2024-04-24 05:08:41.327 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1292, processInstanceId=546, status=9, startTime=1713904461692, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, logPath=/opt/dolphinscheduler/logs/20240424/13201021801792/90/546/1292.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/546/1292, endTime=1713905019537, processId=841, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], eventCreateTime=0, eventSendTime=1713906521321)
[WI-0][TI-1281] - [INFO] 2024-04-24 05:09:11.355 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1281, processInstanceId=543, status=9, startTime=1713903509183, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, logPath=/opt/dolphinscheduler/logs/20240424/13201021801792/90/543/1281.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/543/1281, endTime=1713904084494, processId=300, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], eventCreateTime=0, eventSendTime=1713906251048)
[WI-0][TI-1281] - [INFO] 2024-04-24 05:09:11.358 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1281, processInstanceId=543, status=9, startTime=1713903509183, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, logPath=/opt/dolphinscheduler/logs/20240424/13201021801792/90/543/1281.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/543/1281, endTime=1713904084494, processId=300, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], eventCreateTime=0, eventSendTime=1713906551354)
[WI-0][TI-0] - [INFO] 2024-04-24 05:10:00.385 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 05:09:59 ERROR StandaloneSchedulerBackend: Application has been killed. Reason: Master removed our application: KILLED
	24/04/24 05:09:59 INFO SparkContext: SparkContext is stopping with exitCode 0.
	24/04/24 05:09:59 INFO TaskSchedulerImpl: Cancelling stage 0
	24/04/24 05:09:59 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage cancelled: Job aborted due to stage failure: Master removed our application: KILLED
	24/04/24 05:09:59 INFO TaskSchedulerImpl: Stage 0 was cancelled
	24/04/24 05:09:59 INFO DAGScheduler: ResultStage 0 (json at NativeMethodAccessorImpl.java:0) failed in 1054.081 s due to Job aborted due to stage failure: Master removed our application: KILLED
	24/04/24 05:10:00 INFO DAGScheduler: Job 0 failed: json at NativeMethodAccessorImpl.java:0, took 1054.201136 s
	24/04/24 05:10:00 INFO SparkUI: Stopped Spark web UI at http://5afbfd5249fc:4040
	24/04/24 05:10:00 INFO StandaloneSchedulerBackend: Shutting down all executors
	24/04/24 05:10:00 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Asking each executor to shut down
	24/04/24 05:10:00 ERROR Inbox: Ignoring error
	java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@4c67dfb3 rejected from java.util.concurrent.ScheduledThreadPoolExecutor@12a08af1[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0]
		at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2063)
		at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:830)
		at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)
		at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
		at org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend$StandaloneDriverEndpoint.$anonfun$onDisconnected$1(StandaloneSchedulerBackend.scala:346)
		at scala.Option.foreach(Option.scala:407)
		at org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend$StandaloneDriverEndpoint.onDisconnected(StandaloneSchedulerBackend.scala:313)
		at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:141)
		at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
		at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
		at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
		at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
		at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
		at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
		at java.lang.Thread.run(Thread.java:750)
	24/04/24 05:10:00 ERROR Inbox: Ignoring error
	java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@55336b64 rejected from java.util.concurrent.ScheduledThreadPoolExecutor@12a08af1[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0]
		at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2063)
		at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:830)
		at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)
		at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
		at org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend$StandaloneDriverEndpoint.$anonfun$onDisconnected$1(StandaloneSchedulerBackend.scala:346)
		at scala.Option.foreach(Option.scala:407)
		at org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend$StandaloneDriverEndpoint.onDisconnected(StandaloneSchedulerBackend.scala:313)
		at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:141)
		at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
		at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
		at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
		at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
		at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
		at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
		at java.lang.Thread.run(Thread.java:750)
	24/04/24 05:10:00 ERROR Utils: Uncaught exception in thread stop-spark-context
	org.apache.spark.SparkException: Exception thrown in awaitResult: 
		at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
		at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
		at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
		at org.apache.spark.deploy.client.StandaloneAppClient.stop(StandaloneAppClient.scala:288)
		at org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend.org$apache$spark$scheduler$cluster$StandaloneSchedulerBackend$$stop(StandaloneSchedulerBackend.scala:275)
		at org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend.stop(StandaloneSchedulerBackend.scala:142)
		at org.apache.spark.scheduler.SchedulerBackend.stop(SchedulerBackend.scala:33)
		at org.apache.spark.scheduler.SchedulerBackend.stop$(SchedulerBackend.scala:33)
		at org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend.stop(CoarseGrainedSchedulerBackend.scala:54)
		at org.apache.spark.scheduler.TaskSchedulerImpl.$anonfun$stop$2(TaskSchedulerImpl.scala:992)
		at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1375)
		at org.apache.spark.scheduler.TaskSchedulerImpl.stop(TaskSchedulerImpl.scala:992)
		at org.apache.spark.scheduler.DAGScheduler.$anonfun$stop$4(DAGScheduler.scala:2976)
		at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1375)
		at org.apache.spark.scheduler.DAGScheduler.stop(DAGScheduler.scala:2976)
		at org.apache.spark.SparkContext.$anonfun$stop$12(SparkContext.scala:2263)
		at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1375)
		at org.apache.spark.SparkContext.stop(SparkContext.scala:2263)
		at org.apache.spark.SparkContext.stop(SparkContext.scala:2216)
		at org.apache.spark.SparkContext$$anon$3.run(SparkContext.scala:2203)
	Caused by: org.apache.spark.SparkException: Could not find AppClient.
		at org.apache.spark.rpc.netty.Dispatcher.postMessage(Dispatcher.scala:178)
		at org.apache.spark.rpc.netty.Dispatcher.postLocalMessage(Dispatcher.scala:144)
		at org.apache.spark.rpc.netty.NettyRpcEnv.askAbortable(NettyRpcEnv.scala:242)
		at org.apache.spark.rpc.netty.NettyRpcEndpointRef.askAbortable(NettyRpcEnv.scala:554)
		at org.apache.spark.rpc.netty.NettyRpcEndpointRef.ask(NettyRpcEnv.scala:558)
		at org.apache.spark.rpc.RpcEndpointRef.ask(RpcEndpointRef.scala:72)
		... 17 more
	24/04/24 05:10:00 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
	Traceback (most recent call last):
	  File "/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_91/548/1300/testing.py", line 38, in <module>
	    raw_df = spark.read.json(spark.sparkContext.parallelize([example_json]))
	             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
	  File "/opt/spark-3.5.1-bin-hadoop3/python/lib/pyspark.zip/pyspark/sql/readwriter.py", line 440, in json
	  File "/opt/spark-3.5.1-bin-hadoop3/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
	  File "/opt/spark-3.5.1-bin-hadoop3/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 179, in deco
	  File "/opt/spark-3.5.1-bin-hadoop3/python/lib/py4j-0.10.9.7-src.zip/py4j/protocol.py", line 326, in get_return_value
	py4j.protocol.Py4JJavaError: An error occurred while calling o30.json.
	: org.apache.spark.SparkException: Job aborted due to stage failure: Master removed our application: KILLED
		at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)
		at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)
		at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)
		at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
		at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
		at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
		at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)
		at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)
		at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)
		at scala.Option.foreach(Option.scala:407)
		at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)
		at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)
		at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)
		at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)
		at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
		at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:989)
		at org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)
		at org.apache.spark.SparkContext.runJob(SparkContext.scala:2493)
		at org.apache.spark.sql.catalyst.json.JsonInferSchema.infer(JsonInferSchema.scala:120)
		at org.apache.spark.sql.execution.datasources.json.TextInputJsonDataSource$.$anonfun$inferFromDataset$5(JsonDataSource.scala:109)
		at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)
		at org.apache.spark.sql.execution.datasources.json.TextInputJsonDataSource$.inferFromDataset(JsonDataSource.scala:109)
		at org.apache.spark.sql.DataFrameReader.$anonfun$json$4(DataFrameReader.scala:416)
		at scala.Option.getOrElse(Option.scala:189)
		at org.apache.spark.sql.DataFrameReader.json(DataFrameReader.scala:416)
		at org.apache.spark.sql.DataFrameReader.json(DataFrameReader.scala:391)
		at org.apache.spark.sql.DataFrameReader.json(DataFrameReader.scala:377)
		at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
		at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
		at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
		at java.lang.reflect.Method.invoke(Method.java:498)
		at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
		at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
		at py4j.Gateway.invoke(Gateway.java:282)
		at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
		at py4j.commands.CallCommand.execute(CallCommand.java:79)
		at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
		at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
		at java.lang.Thread.run(Thread.java:750)
	
[WI-0][TI-0] - [INFO] 2024-04-24 05:10:00.768 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9269662921348315 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 05:10:01.400 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 05:10:00 INFO BlockManagerMaster: BlockManagerMaster stopped
	24/04/24 05:10:00 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
	24/04/24 05:10:00 INFO SparkContext: Successfully stopped SparkContext
	24/04/24 05:10:00 INFO ShutdownHookManager: Shutdown hook called
	24/04/24 05:10:00 INFO ShutdownHookManager: Deleting directory /tmp/spark-b44cf0ed-2460-4f2f-88eb-d67fdca195b6/pyspark-81eec993-73a8-46d8-8196-3b63c9d74099
	24/04/24 05:10:00 INFO ShutdownHookManager: Deleting directory /tmp/spark-5411703b-421a-4fc2-a7ff-0a2369f1d3d4
	24/04/24 05:10:00 INFO ShutdownHookManager: Deleting directory /tmp/spark-b44cf0ed-2460-4f2f-88eb-d67fdca195b6
[WI-548][TI-1300] - [INFO] 2024-04-24 05:10:01.401 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_91/548/1300, processId:1367 ,exitStatusCode:1 ,processWaitForStatus:true ,processExitValue:1
[WI-548][TI-1300] - [INFO] 2024-04-24 05:10:01.402 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-548][TI-1300] - [INFO] 2024-04-24 05:10:01.403 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-548][TI-1300] - [INFO] 2024-04-24 05:10:01.404 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-548][TI-1300] - [INFO] 2024-04-24 05:10:01.404 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-548][TI-1300] - [INFO] 2024-04-24 05:10:01.408 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: FAILURE to master : 172.18.1.1:1234
[WI-548][TI-1300] - [INFO] 2024-04-24 05:10:01.408 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-548][TI-1300] - [INFO] 2024-04-24 05:10:01.409 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_91/548/1300
[WI-548][TI-1300] - [INFO] 2024-04-24 05:10:01.411 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_91/548/1300
[WI-548][TI-1300] - [INFO] 2024-04-24 05:10:01.413 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-1300] - [INFO] 2024-04-24 05:10:01.426 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1300, processInstanceId=548, status=6, startTime=1713905522319, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, logPath=/opt/dolphinscheduler/logs/20240424/13201021801792/91/548/1300.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_91/548/1300, endTime=1713906601404, processId=1367, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1300] - [INFO] 2024-04-24 05:10:01.429 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1300, processInstanceId=548, status=6, startTime=1713905522319, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, logPath=/opt/dolphinscheduler/logs/20240424/13201021801792/91/548/1300.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_91/548/1300, endTime=1713906601404, processId=1367, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], eventCreateTime=0, eventSendTime=1713906601425)
[WI-0][TI-0] - [INFO] 2024-04-24 05:10:01.782 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7660167130919221 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-1300] - [INFO] 2024-04-24 05:10:02.368 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1300, success=true)
[WI-0][TI-1300] - [INFO] 2024-04-24 05:10:02.371 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1300, success=true)
[WI-0][TI-0] - [INFO] 2024-04-24 05:10:19.864 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.75 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 05:10:28.871 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1301, taskName=search for intake JSON files, firstSubmitTime=1713906628853, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.10:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=92, appIds=null, processInstanceId=549, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"processing"}], executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":""}],"rawScript":"# find 1 raw file in the folder\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\n\n# check if raw_file_dir is empty, then set raw_file_dir to null\nif [ -z \"$raw_file_dir\" ]; then\n    raw_file_dir=null\nfi\n\necho \"#{setValue(raw_file_dir=${raw_file_dir})}\"","resourceList":[]}, environmentConfig=export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='search for intake JSON files'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240424'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1301'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13340113777664'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240424051028'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='processing'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='549'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240423'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=null, dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-549][TI-1301] - [INFO] 2024-04-24 05:10:28.873 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: search for intake JSON files to wait queue success
[WI-549][TI-1301] - [INFO] 2024-04-24 05:10:28.874 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-549][TI-1301] - [INFO] 2024-04-24 05:10:28.877 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-549][TI-1301] - [INFO] 2024-04-24 05:10:28.877 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-549][TI-1301] - [INFO] 2024-04-24 05:10:28.877 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-549][TI-1301] - [INFO] 2024-04-24 05:10:28.877 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713906628877
[WI-549][TI-1301] - [INFO] 2024-04-24 05:10:28.877 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 549_1301
[WI-549][TI-1301] - [INFO] 2024-04-24 05:10:28.878 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1301,
  "taskName" : "search for intake JSON files",
  "firstSubmitTime" : 1713906628853,
  "startTime" : 1713906628877,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.10:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240424/13201021801792/92/549/1301.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 92,
  "processInstanceId" : 549,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"processing\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[{\"prop\":\"raw_file_dir\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"\"}],\"rawScript\":\"# find 1 raw file in the folder\\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\\n\\n# check if raw_file_dir is empty, then set raw_file_dir to null\\nif [ -z \\\"$raw_file_dir\\\" ]; then\\n    raw_file_dir=null\\nfi\\n\\necho \\\"#{setValue(raw_file_dir=${raw_file_dir})}\\\"\",\"resourceList\":[]}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "search for intake JSON files"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240424"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1301"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13340113777664"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240424051028"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "processing"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "549"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "549_1301",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-549][TI-1301] - [INFO] 2024-04-24 05:10:28.879 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-549][TI-1301] - [INFO] 2024-04-24 05:10:28.879 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-549][TI-1301] - [INFO] 2024-04-24 05:10:28.879 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-549][TI-1301] - [INFO] 2024-04-24 05:10:28.884 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-549][TI-1301] - [INFO] 2024-04-24 05:10:28.885 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-549][TI-1301] - [INFO] 2024-04-24 05:10:28.886 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_92/549/1301 check successfully
[WI-549][TI-1301] - [INFO] 2024-04-24 05:10:28.887 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-549][TI-1301] - [INFO] 2024-04-24 05:10:28.887 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-549][TI-1301] - [INFO] 2024-04-24 05:10:28.888 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-549][TI-1301] - [INFO] 2024-04-24 05:10:28.888 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-549][TI-1301] - [INFO] 2024-04-24 05:10:28.888 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ {
    "prop" : "raw_file_dir",
    "direct" : "OUT",
    "type" : "VARCHAR",
    "value" : ""
  } ],
  "varPool" : null,
  "rawScript" : "# find 1 raw file in the folder\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\n\n# check if raw_file_dir is empty, then set raw_file_dir to null\nif [ -z \"$raw_file_dir\" ]; then\n    raw_file_dir=null\nfi\n\necho \"#{setValue(raw_file_dir=${raw_file_dir})}\"",
  "resourceList" : [ ]
}
[WI-549][TI-1301] - [INFO] 2024-04-24 05:10:28.889 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-549][TI-1301] - [INFO] 2024-04-24 05:10:28.889 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: null successfully
[WI-549][TI-1301] - [INFO] 2024-04-24 05:10:28.889 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-549][TI-1301] - [INFO] 2024-04-24 05:10:28.889 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-549][TI-1301] - [INFO] 2024-04-24 05:10:28.889 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-549][TI-1301] - [INFO] 2024-04-24 05:10:28.890 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-549][TI-1301] - [INFO] 2024-04-24 05:10:28.890 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-549][TI-1301] - [INFO] 2024-04-24 05:10:28.890 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export PYTHON_LAUNCHER=/bin/python3.11
# find 1 raw file in the folder
raw_file_dir=$(find /local_storage/reddit/processing -type f -name '*.json'| head -n 1)

# check if raw_file_dir is empty, then set raw_file_dir to null
if [ -z "$raw_file_dir" ]; then
    raw_file_dir=null
fi

echo "#{setValue(raw_file_dir=${raw_file_dir})}"
[WI-549][TI-1301] - [INFO] 2024-04-24 05:10:28.891 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-549][TI-1301] - [INFO] 2024-04-24 05:10:28.891 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_92/549/1301/549_1301.sh
[WI-549][TI-1301] - [INFO] 2024-04-24 05:10:28.898 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 1719
[WI-0][TI-1301] - [INFO] 2024-04-24 05:10:29.431 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1301, success=true)
[WI-0][TI-1301] - [INFO] 2024-04-24 05:10:29.447 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1301)
[WI-0][TI-0] - [INFO] 2024-04-24 05:10:29.900 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
	#{setValue(raw_file_dir=/local_storage/reddit/processing/500-20240423.json)}
[WI-549][TI-1301] - [INFO] 2024-04-24 05:10:29.904 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_92/549/1301, processId:1719 ,exitStatusCode:0 ,processWaitForStatus:true ,processExitValue:0
[WI-549][TI-1301] - [INFO] 2024-04-24 05:10:29.906 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-549][TI-1301] - [INFO] 2024-04-24 05:10:29.906 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-549][TI-1301] - [INFO] 2024-04-24 05:10:29.906 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-549][TI-1301] - [INFO] 2024-04-24 05:10:29.907 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-549][TI-1301] - [INFO] 2024-04-24 05:10:29.935 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: SUCCESS to master : 172.18.1.1:1234
[WI-549][TI-1301] - [INFO] 2024-04-24 05:10:29.937 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-549][TI-1301] - [INFO] 2024-04-24 05:10:29.937 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_92/549/1301
[WI-549][TI-1301] - [INFO] 2024-04-24 05:10:29.938 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_92/549/1301
[WI-549][TI-1301] - [INFO] 2024-04-24 05:10:29.938 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-1301] - [INFO] 2024-04-24 05:10:30.433 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1301, success=true)
[WI-0][TI-0] - [INFO] 2024-04-24 05:10:31.645 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1303, taskName=move to processing, firstSubmitTime=1713906631602, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.10:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=92, appIds=null, processInstanceId=549, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"processing"}], executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":""}],"rawScript":"# move file to the reddit processing folder\n# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error\nfilename=$(basename \"${raw_file_dir}\")\nif ! grep -q \"${REDDIT_HOME}/processing\" <<< \"${raw_file_dir}\"; then\n    mv ${raw_file_dir} ${REDDIT_HOME}/processing\nelse\n    echo JSON is already in processing\nfi\n\n# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing\necho \"#{setValue(raw_file_dir=${REDDIT_HOME}/processing/${filename})}\"","resourceList":[]}, environmentConfig=export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='move to processing'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240424'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1303'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13340390094208'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240424051031'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='processing'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='549'}, raw_file_dir=Property{prop='raw_file_dir', direct=IN, type=VARCHAR, value='/local_storage/reddit/processing/500-20240423.json'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240423'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-549][TI-1303] - [INFO] 2024-04-24 05:10:31.653 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: move to processing to wait queue success
[WI-549][TI-1303] - [INFO] 2024-04-24 05:10:31.655 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-549][TI-1303] - [INFO] 2024-04-24 05:10:31.683 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-549][TI-1303] - [INFO] 2024-04-24 05:10:31.684 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-549][TI-1303] - [INFO] 2024-04-24 05:10:31.684 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-549][TI-1303] - [INFO] 2024-04-24 05:10:31.684 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713906631684
[WI-549][TI-1303] - [INFO] 2024-04-24 05:10:31.684 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 549_1303
[WI-549][TI-1303] - [INFO] 2024-04-24 05:10:31.684 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1303,
  "taskName" : "move to processing",
  "firstSubmitTime" : 1713906631602,
  "startTime" : 1713906631684,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.10:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240424/13201021801792/92/549/1303.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 92,
  "processInstanceId" : 549,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"processing\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[{\"prop\":\"raw_file_dir\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"\"}],\"rawScript\":\"# move file to the reddit processing folder\\n# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error\\nfilename=$(basename \\\"${raw_file_dir}\\\")\\nif ! grep -q \\\"${REDDIT_HOME}/processing\\\" <<< \\\"${raw_file_dir}\\\"; then\\n    mv ${raw_file_dir} ${REDDIT_HOME}/processing\\nelse\\n    echo JSON is already in processing\\nfi\\n\\n# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing\\necho \\\"#{setValue(raw_file_dir=${REDDIT_HOME}/processing/${filename})}\\\"\",\"resourceList\":[]}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "move to processing"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240424"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1303"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13340390094208"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240424051031"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "processing"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "549"
    },
    "raw_file_dir" : {
      "prop" : "raw_file_dir",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit/processing/500-20240423.json"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "549_1303",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"raw_file_dir\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"/local_storage/reddit/processing/500-20240423.json\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-549][TI-1303] - [INFO] 2024-04-24 05:10:31.685 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-549][TI-1303] - [INFO] 2024-04-24 05:10:31.686 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-549][TI-1303] - [INFO] 2024-04-24 05:10:31.686 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-549][TI-1303] - [INFO] 2024-04-24 05:10:31.701 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-549][TI-1303] - [INFO] 2024-04-24 05:10:31.704 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-549][TI-1303] - [INFO] 2024-04-24 05:10:31.707 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_92/549/1303 check successfully
[WI-549][TI-1303] - [INFO] 2024-04-24 05:10:31.708 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-549][TI-1303] - [INFO] 2024-04-24 05:10:31.708 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-549][TI-1303] - [INFO] 2024-04-24 05:10:31.711 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-549][TI-1303] - [INFO] 2024-04-24 05:10:31.712 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-549][TI-1303] - [INFO] 2024-04-24 05:10:31.712 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ {
    "prop" : "raw_file_dir",
    "direct" : "OUT",
    "type" : "VARCHAR",
    "value" : ""
  } ],
  "varPool" : null,
  "rawScript" : "# move file to the reddit processing folder\n# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error\nfilename=$(basename \"${raw_file_dir}\")\nif ! grep -q \"${REDDIT_HOME}/processing\" <<< \"${raw_file_dir}\"; then\n    mv ${raw_file_dir} ${REDDIT_HOME}/processing\nelse\n    echo JSON is already in processing\nfi\n\n# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing\necho \"#{setValue(raw_file_dir=${REDDIT_HOME}/processing/${filename})}\"",
  "resourceList" : [ ]
}
[WI-549][TI-1303] - [INFO] 2024-04-24 05:10:31.712 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-549][TI-1303] - [INFO] 2024-04-24 05:10:31.712 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}] successfully
[WI-549][TI-1303] - [INFO] 2024-04-24 05:10:31.712 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-549][TI-1303] - [INFO] 2024-04-24 05:10:31.713 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-549][TI-1303] - [INFO] 2024-04-24 05:10:31.713 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-549][TI-1303] - [INFO] 2024-04-24 05:10:31.722 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-549][TI-1303] - [INFO] 2024-04-24 05:10:31.722 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-549][TI-1303] - [INFO] 2024-04-24 05:10:31.722 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export PYTHON_LAUNCHER=/bin/python3.11
# move file to the reddit processing folder
# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error
filename=$(basename "/local_storage/reddit/processing/500-20240423.json")
if ! grep -q "/local_storage/reddit/processing" <<< "/local_storage/reddit/processing/500-20240423.json"; then
    mv /local_storage/reddit/processing/500-20240423.json /local_storage/reddit/processing
else
    echo JSON is already in processing
fi

# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing
echo "#{setValue(raw_file_dir=/local_storage/reddit/processing/${filename})}"
[WI-549][TI-1303] - [INFO] 2024-04-24 05:10:31.722 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-549][TI-1303] - [INFO] 2024-04-24 05:10:31.722 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_92/549/1303/549_1303.sh
[WI-549][TI-1303] - [INFO] 2024-04-24 05:10:31.738 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 1732
[WI-0][TI-1303] - [INFO] 2024-04-24 05:10:32.451 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1303, success=true)
[WI-0][TI-1303] - [INFO] 2024-04-24 05:10:32.469 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1303)
[WI-0][TI-0] - [INFO] 2024-04-24 05:10:32.744 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
	JSON is already in processing
	#{setValue(raw_file_dir=/local_storage/reddit/processing/500-20240423.json)}
[WI-549][TI-1303] - [INFO] 2024-04-24 05:10:32.748 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_92/549/1303, processId:1732 ,exitStatusCode:0 ,processWaitForStatus:true ,processExitValue:0
[WI-549][TI-1303] - [INFO] 2024-04-24 05:10:32.749 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-549][TI-1303] - [INFO] 2024-04-24 05:10:32.749 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-549][TI-1303] - [INFO] 2024-04-24 05:10:32.749 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-549][TI-1303] - [INFO] 2024-04-24 05:10:32.751 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-549][TI-1303] - [INFO] 2024-04-24 05:10:32.757 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: SUCCESS to master : 172.18.1.1:1234
[WI-549][TI-1303] - [INFO] 2024-04-24 05:10:32.759 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-549][TI-1303] - [INFO] 2024-04-24 05:10:32.759 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_92/549/1303
[WI-549][TI-1303] - [INFO] 2024-04-24 05:10:32.761 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_92/549/1303
[WI-549][TI-1303] - [INFO] 2024-04-24 05:10:32.762 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-1303] - [INFO] 2024-04-24 05:10:33.434 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1303, success=true)
[WI-0][TI-0] - [INFO] 2024-04-24 05:10:33.495 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1304, taskName=spark preprocessing, firstSubmitTime=1713906633483, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.10:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=92, appIds=null, processInstanceId=549, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"processing"}], executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[],"rawScript":"$SPARK_HOME/bin/spark-submit \\\n    --master spark://spark-master:7077 \\\n    --deploy-mode client \\\n    --conf spark.driver.cores=1 \\\n    --conf spark.driver.memory=1G \\\n    --conf spark.executor.instances=1 \\\n    --conf spark.executor.cores=1 \\\n    --conf spark.executor.memory=1G \\\n    --name reddit_preprocessing testing.py\n\n# $SPARK_HOME/bin/spark-submit \\\n#     --master local \\\n#     --files ${raw_file_dir} \\\n#     --name reddit_preprocessing spark_reddit_preprocessing.py\n","resourceList":[{"id":null,"resourceName":"file:/dolphinscheduler/default/resources/testing.py","res":null}]}, environmentConfig=export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export PYSPARK_DRIVER_PYTHON=/bin/python3.11
export PYTHON_LAUNCHER=/bin/python3.11
export PYSPARK_PYTHON=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='spark preprocessing'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240424'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1304'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13210058002752'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240424051033'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='processing'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='549'}, raw_file_dir=Property{prop='raw_file_dir', direct=IN, type=VARCHAR, value='/local_storage/reddit/processing/500-20240423.json'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240423'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-549][TI-1304] - [INFO] 2024-04-24 05:10:33.496 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: spark preprocessing to wait queue success
[WI-549][TI-1304] - [INFO] 2024-04-24 05:10:33.496 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-549][TI-1304] - [INFO] 2024-04-24 05:10:33.497 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-549][TI-1304] - [INFO] 2024-04-24 05:10:33.497 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-549][TI-1304] - [INFO] 2024-04-24 05:10:33.497 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-549][TI-1304] - [INFO] 2024-04-24 05:10:33.497 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713906633497
[WI-549][TI-1304] - [INFO] 2024-04-24 05:10:33.498 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 549_1304
[WI-549][TI-1304] - [INFO] 2024-04-24 05:10:33.500 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1304,
  "taskName" : "spark preprocessing",
  "firstSubmitTime" : 1713906633483,
  "startTime" : 1713906633497,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.10:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240424/13201021801792/92/549/1304.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 92,
  "processInstanceId" : 549,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"processing\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[],\"rawScript\":\"$SPARK_HOME/bin/spark-submit \\\\\\n    --master spark://spark-master:7077 \\\\\\n    --deploy-mode client \\\\\\n    --conf spark.driver.cores=1 \\\\\\n    --conf spark.driver.memory=1G \\\\\\n    --conf spark.executor.instances=1 \\\\\\n    --conf spark.executor.cores=1 \\\\\\n    --conf spark.executor.memory=1G \\\\\\n    --name reddit_preprocessing testing.py\\n\\n# $SPARK_HOME/bin/spark-submit \\\\\\n#     --master local \\\\\\n#     --files ${raw_file_dir} \\\\\\n#     --name reddit_preprocessing spark_reddit_preprocessing.py\\n\",\"resourceList\":[{\"id\":null,\"resourceName\":\"file:/dolphinscheduler/default/resources/testing.py\",\"res\":null}]}",
  "environmentConfig" : "export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3\nexport JAVA_HOME=/opt/java/openjdk\nexport PYSPARK_DRIVER_PYTHON=/bin/python3.11\nexport PYTHON_LAUNCHER=/bin/python3.11\nexport PYSPARK_PYTHON=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "spark preprocessing"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240424"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1304"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13210058002752"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240424051033"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "processing"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "549"
    },
    "raw_file_dir" : {
      "prop" : "raw_file_dir",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit/processing/500-20240423.json"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "549_1304",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"raw_file_dir\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"/local_storage/reddit/processing/500-20240423.json\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-549][TI-1304] - [INFO] 2024-04-24 05:10:33.500 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-549][TI-1304] - [INFO] 2024-04-24 05:10:33.500 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-549][TI-1304] - [INFO] 2024-04-24 05:10:33.500 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-549][TI-1304] - [INFO] 2024-04-24 05:10:33.503 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-549][TI-1304] - [INFO] 2024-04-24 05:10:33.503 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-549][TI-1304] - [INFO] 2024-04-24 05:10:33.504 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_92/549/1304 check successfully
[WI-549][TI-1304] - [INFO] 2024-04-24 05:10:33.505 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-549][TI-1304] - [INFO] 2024-04-24 05:10:33.508 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={file:/dolphinscheduler/default/resources/testing.py=ResourceContext.ResourceItem(resourceAbsolutePathInStorage=file:/dolphinscheduler/default/resources/testing.py, resourceRelativePath=testing.py, resourceAbsolutePathInLocal=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_92/549/1304/testing.py)})
[WI-549][TI-1304] - [INFO] 2024-04-24 05:10:33.509 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-549][TI-1304] - [INFO] 2024-04-24 05:10:33.509 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-549][TI-1304] - [INFO] 2024-04-24 05:10:33.509 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ ],
  "varPool" : null,
  "rawScript" : "$SPARK_HOME/bin/spark-submit \\\n    --master spark://spark-master:7077 \\\n    --deploy-mode client \\\n    --conf spark.driver.cores=1 \\\n    --conf spark.driver.memory=1G \\\n    --conf spark.executor.instances=1 \\\n    --conf spark.executor.cores=1 \\\n    --conf spark.executor.memory=1G \\\n    --name reddit_preprocessing testing.py\n\n# $SPARK_HOME/bin/spark-submit \\\n#     --master local \\\n#     --files ${raw_file_dir} \\\n#     --name reddit_preprocessing spark_reddit_preprocessing.py\n",
  "resourceList" : [ {
    "id" : null,
    "resourceName" : "file:/dolphinscheduler/default/resources/testing.py",
    "res" : null
  } ]
}
[WI-549][TI-1304] - [INFO] 2024-04-24 05:10:33.509 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-549][TI-1304] - [INFO] 2024-04-24 05:10:33.509 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}] successfully
[WI-549][TI-1304] - [INFO] 2024-04-24 05:10:33.509 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-549][TI-1304] - [INFO] 2024-04-24 05:10:33.509 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-549][TI-1304] - [INFO] 2024-04-24 05:10:33.509 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-549][TI-1304] - [INFO] 2024-04-24 05:10:33.510 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-549][TI-1304] - [INFO] 2024-04-24 05:10:33.510 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-549][TI-1304] - [INFO] 2024-04-24 05:10:33.510 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export PYSPARK_DRIVER_PYTHON=/bin/python3.11
export PYTHON_LAUNCHER=/bin/python3.11
export PYSPARK_PYTHON=/bin/python3.11
$SPARK_HOME/bin/spark-submit \
    --master spark://spark-master:7077 \
    --deploy-mode client \
    --conf spark.driver.cores=1 \
    --conf spark.driver.memory=1G \
    --conf spark.executor.instances=1 \
    --conf spark.executor.cores=1 \
    --conf spark.executor.memory=1G \
    --name reddit_preprocessing testing.py

# $SPARK_HOME/bin/spark-submit \
#     --master local \
#     --files /local_storage/reddit/processing/500-20240423.json \
#     --name reddit_preprocessing spark_reddit_preprocessing.py

[WI-549][TI-1304] - [INFO] 2024-04-24 05:10:33.510 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-549][TI-1304] - [INFO] 2024-04-24 05:10:33.510 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_92/549/1304/549_1304.sh
[WI-549][TI-1304] - [INFO] 2024-04-24 05:10:33.515 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 1744
[WI-0][TI-1304] - [INFO] 2024-04-24 05:10:33.534 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionRunningEvent(taskInstanceId=1304, processInstanceId=549, startTime=1713906633497, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, status=TaskExecutionStatus{code=1, desc='running'}, logPath=/opt/dolphinscheduler/logs/20240424/13201021801792/92/549/1304.log, executePath=null, processId=0, appIds=null, eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1304] - [INFO] 2024-04-24 05:10:33.537 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionRunningEvent(taskInstanceId=1304, processInstanceId=549, startTime=1713906633497, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, status=TaskExecutionStatus{code=1, desc='running'}, logPath=/opt/dolphinscheduler/logs/20240424/13201021801792/92/549/1304.log, executePath=null, processId=0, appIds=null, eventCreateTime=0, eventSendTime=1713906633533)
[WI-0][TI-1304] - [INFO] 2024-04-24 05:10:33.537 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionInfoEvent(taskInstanceId=1304, processInstanceId=549, startTime=1713906633497, workflowInstanceHost=172.18.0.10:5678, taskInstanceHost=172.18.1.1:1234, logPath=null, processId=0, eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1304] - [INFO] 2024-04-24 05:10:33.538 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionInfoEvent(taskInstanceId=1304, processInstanceId=549, startTime=1713906633497, workflowInstanceHost=172.18.0.10:5678, taskInstanceHost=172.18.1.1:1234, logPath=null, processId=0, eventCreateTime=0, eventSendTime=1713906633533)
[WI-0][TI-1304] - [INFO] 2024-04-24 05:10:34.437 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1304, success=true)
[WI-0][TI-1304] - [INFO] 2024-04-24 05:10:34.443 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1304)
[WI-0][TI-1304] - [INFO] 2024-04-24 05:10:34.449 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1304, success=true)
[WI-0][TI-1304] - [INFO] 2024-04-24 05:10:34.462 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1304)
[WI-0][TI-0] - [INFO] 2024-04-24 05:10:34.515 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
[WI-0][TI-0] - [INFO] 2024-04-24 05:10:36.565 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 05:10:35 INFO SparkContext: Running Spark version 3.5.1
	24/04/24 05:10:35 INFO SparkContext: OS info Linux, 6.5.0-28-generic, amd64
	24/04/24 05:10:35 INFO SparkContext: Java version 1.8.0_402
	24/04/24 05:10:35 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
	24/04/24 05:10:36 INFO ResourceUtils: ==============================================================
	24/04/24 05:10:36 INFO ResourceUtils: No custom resources configured for spark.driver.
	24/04/24 05:10:36 INFO ResourceUtils: ==============================================================
	24/04/24 05:10:36 INFO SparkContext: Submitted application: reddit_preprocessing
	24/04/24 05:10:36 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
	24/04/24 05:10:36 INFO ResourceProfile: Limiting resource is cpus at 1 tasks per executor
	24/04/24 05:10:36 INFO ResourceProfileManager: Added ResourceProfile id: 0
	24/04/24 05:10:36 INFO SecurityManager: Changing view acls to: default
	24/04/24 05:10:36 INFO SecurityManager: Changing modify acls to: default
	24/04/24 05:10:36 INFO SecurityManager: Changing view acls groups to: 
	24/04/24 05:10:36 INFO SecurityManager: Changing modify acls groups to: 
	24/04/24 05:10:36 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: default; groups with view permissions: EMPTY; users with modify permissions: default; groups with modify permissions: EMPTY
[WI-0][TI-0] - [INFO] 2024-04-24 05:10:36.954 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9153605015673981 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 05:10:37.583 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 05:10:36 INFO Utils: Successfully started service 'sparkDriver' on port 38039.
	24/04/24 05:10:37 INFO SparkEnv: Registering MapOutputTracker
	24/04/24 05:10:37 INFO SparkEnv: Registering BlockManagerMaster
	24/04/24 05:10:37 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
	24/04/24 05:10:37 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
	24/04/24 05:10:37 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
	24/04/24 05:10:37 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-21eee485-e871-44dc-b63a-c464ade790cc
	24/04/24 05:10:37 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
	24/04/24 05:10:37 INFO SparkEnv: Registering OutputCommitCoordinator
[WI-0][TI-0] - [INFO] 2024-04-24 05:10:37.986 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9259259259259259 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 05:10:38.594 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 05:10:37 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
	24/04/24 05:10:37 INFO Utils: Successfully started service 'SparkUI' on port 4040.
	24/04/24 05:10:38 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
[WI-0][TI-0] - [INFO] 2024-04-24 05:10:38.990 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9452449567723343 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 05:10:39.613 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 05:10:38 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.4:7077 after 100 ms (0 ms spent in bootstraps)
	24/04/24 05:10:39 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20240423211038-0005
	24/04/24 05:10:39 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20240423211038-0005/0 on worker-20240423200818-172.18.0.6-42177 (172.18.0.6:42177) with 1 core(s)
	24/04/24 05:10:39 INFO StandaloneSchedulerBackend: Granted executor ID app-20240423211038-0005/0 on hostPort 172.18.0.6:42177 with 1 core(s), 1024.0 MiB RAM
	24/04/24 05:10:39 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20240423211038-0005/1 on worker-20240423200818-172.18.0.6-42177 (172.18.0.6:42177) with 1 core(s)
	24/04/24 05:10:39 INFO StandaloneSchedulerBackend: Granted executor ID app-20240423211038-0005/1 on hostPort 172.18.0.6:42177 with 1 core(s), 1024.0 MiB RAM
	24/04/24 05:10:39 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46799.
	24/04/24 05:10:39 INFO NettyBlockTransferService: Server created on 5afbfd5249fc:46799
	24/04/24 05:10:39 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
	24/04/24 05:10:39 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 5afbfd5249fc, 46799, None)
	24/04/24 05:10:39 INFO BlockManagerMasterEndpoint: Registering block manager 5afbfd5249fc:46799 with 366.3 MiB RAM, BlockManagerId(driver, 5afbfd5249fc, 46799, None)
	24/04/24 05:10:39 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20240423211038-0005/0 is now RUNNING
	24/04/24 05:10:39 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 5afbfd5249fc, 46799, None)
	24/04/24 05:10:39 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 5afbfd5249fc, 46799, None)
	24/04/24 05:10:39 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20240423211038-0005/1 is now RUNNING
[WI-0][TI-0] - [INFO] 2024-04-24 05:10:39.993 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9864864864864864 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 05:10:40.620 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 05:10:40 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
[WI-0][TI-0] - [INFO] 2024-04-24 05:10:41.015 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9911242603550295 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 05:10:41.626 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	
	[
	    {"name": "t3_abc123", "author": "user1", "body": "Sample comment 1", "permalink": "/r/subreddit1/post/abc123", "unix_time": 1619520000},
	    {"name": "t1_def456", "author": "user2", "body": "Sample comment 2", "permalink": "/r/subreddit2/post/def456", "unix_time": 1619521000}
	]
	
	24/04/24 05:10:41 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
	24/04/24 05:10:41 INFO SharedState: Warehouse path is 'file:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_92/549/1304/spark-warehouse'.
[WI-0][TI-0] - [INFO] 2024-04-24 05:10:42.036 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.988338192419825 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 05:10:43.045 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9622093023255814 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 05:10:44.050 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.003690036900369 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 05:10:45.052 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9175257731958764 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 05:10:46.059 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9202453987730062 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 05:10:47.069 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9475524475524476 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 05:10:48.081 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9387096774193548 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 05:10:49.084 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9501557632398754 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 05:10:50.092 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9333333333333333 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 05:10:50.746 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 05:10:50 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.6:34770) with ID 0,  ResourceProfileId 0
[WI-0][TI-0] - [INFO] 2024-04-24 05:10:51.112 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9546827794561934 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 05:10:51.748 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 05:10:50 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.6:42621 with 434.4 MiB RAM, BlockManagerId(0, 172.18.0.6, 42621, None)
	24/04/24 05:10:51 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.6:55054) with ID 1,  ResourceProfileId 0
	24/04/24 05:10:51 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.6:43451 with 434.4 MiB RAM, BlockManagerId(1, 172.18.0.6, 43451, None)
[WI-0][TI-0] - [INFO] 2024-04-24 05:10:52.115 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7074626865671642 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 05:10:52.750 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 05:10:52 INFO CodeGenerator: Code generated in 327.881874 ms
[WI-0][TI-0] - [INFO] 2024-04-24 05:10:53.751 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 05:10:52 INFO SparkContext: Starting job: json at NativeMethodAccessorImpl.java:0
	24/04/24 05:10:52 INFO DAGScheduler: Got job 0 (json at NativeMethodAccessorImpl.java:0) with 2 output partitions
	24/04/24 05:10:52 INFO DAGScheduler: Final stage: ResultStage 0 (json at NativeMethodAccessorImpl.java:0)
	24/04/24 05:10:52 INFO DAGScheduler: Parents of final stage: List()
	24/04/24 05:10:52 INFO DAGScheduler: Missing parents: List()
	24/04/24 05:10:52 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[6] at json at NativeMethodAccessorImpl.java:0), which has no missing parents
	24/04/24 05:10:53 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 20.8 KiB, free 366.3 MiB)
	24/04/24 05:10:53 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 10.1 KiB, free 366.3 MiB)
	24/04/24 05:10:53 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 5afbfd5249fc:46799 (size: 10.1 KiB, free: 366.3 MiB)
	24/04/24 05:10:53 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1585
	24/04/24 05:10:53 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (MapPartitionsRDD[6] at json at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
	24/04/24 05:10:53 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks resource profile 0
	24/04/24 05:10:53 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.6, executor 1, partition 0, PROCESS_LOCAL, 7599 bytes) 
	24/04/24 05:10:53 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1) (172.18.0.6, executor 0, partition 1, PROCESS_LOCAL, 7916 bytes) 
[WI-0][TI-0] - [INFO] 2024-04-24 05:11:00.134 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7011494252873564 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 05:11:18.193 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7747252747252747 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 05:11:32.266 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7556818181818181 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 05:11:36.319 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7245918003565063 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 05:11:38.355 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7243243243243244 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 05:11:40.406 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8494623655913979 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 05:12:19.790 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7582417582417582 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-1292] - [INFO] 2024-04-24 05:13:42.292 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1292, processInstanceId=546, status=9, startTime=1713904461692, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, logPath=/opt/dolphinscheduler/logs/20240424/13201021801792/90/546/1292.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/546/1292, endTime=1713905019537, processId=841, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], eventCreateTime=0, eventSendTime=1713906521321)
[WI-0][TI-1292] - [INFO] 2024-04-24 05:13:42.295 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1292, processInstanceId=546, status=9, startTime=1713904461692, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, logPath=/opt/dolphinscheduler/logs/20240424/13201021801792/90/546/1292.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/546/1292, endTime=1713905019537, processId=841, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], eventCreateTime=0, eventSendTime=1713906822292)
[WI-0][TI-1281] - [INFO] 2024-04-24 05:14:12.333 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1281, processInstanceId=543, status=9, startTime=1713903509183, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, logPath=/opt/dolphinscheduler/logs/20240424/13201021801792/90/543/1281.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/543/1281, endTime=1713904084494, processId=300, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], eventCreateTime=0, eventSendTime=1713906551354)
[WI-0][TI-1281] - [INFO] 2024-04-24 05:14:12.398 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1281, processInstanceId=543, status=9, startTime=1713903509183, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, logPath=/opt/dolphinscheduler/logs/20240424/13201021801792/90/543/1281.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/543/1281, endTime=1713904084494, processId=300, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], eventCreateTime=0, eventSendTime=1713906852333)
[WI-0][TI-1292] - [INFO] 2024-04-24 05:18:43.230 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1292, processInstanceId=546, status=9, startTime=1713904461692, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, logPath=/opt/dolphinscheduler/logs/20240424/13201021801792/90/546/1292.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/546/1292, endTime=1713905019537, processId=841, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], eventCreateTime=0, eventSendTime=1713906822292)
[WI-0][TI-1292] - [INFO] 2024-04-24 05:18:43.237 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1292, processInstanceId=546, status=9, startTime=1713904461692, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, logPath=/opt/dolphinscheduler/logs/20240424/13201021801792/90/546/1292.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/546/1292, endTime=1713905019537, processId=841, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], eventCreateTime=0, eventSendTime=1713907123230)
[WI-0][TI-1281] - [INFO] 2024-04-24 05:19:13.264 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1281, processInstanceId=543, status=9, startTime=1713903509183, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, logPath=/opt/dolphinscheduler/logs/20240424/13201021801792/90/543/1281.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/543/1281, endTime=1713904084494, processId=300, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], eventCreateTime=0, eventSendTime=1713906852333)
[WI-0][TI-1281] - [INFO] 2024-04-24 05:19:13.267 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1281, processInstanceId=543, status=9, startTime=1713903509183, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, logPath=/opt/dolphinscheduler/logs/20240424/13201021801792/90/543/1281.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/543/1281, endTime=1713904084494, processId=300, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], eventCreateTime=0, eventSendTime=1713907153264)
[WI-0][TI-1292] - [INFO] 2024-04-24 05:23:43.283 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1292, processInstanceId=546, status=9, startTime=1713904461692, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, logPath=/opt/dolphinscheduler/logs/20240424/13201021801792/90/546/1292.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/546/1292, endTime=1713905019537, processId=841, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], eventCreateTime=0, eventSendTime=1713907123230)
[WI-0][TI-1292] - [INFO] 2024-04-24 05:23:43.291 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1292, processInstanceId=546, status=9, startTime=1713904461692, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, logPath=/opt/dolphinscheduler/logs/20240424/13201021801792/90/546/1292.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/546/1292, endTime=1713905019537, processId=841, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], eventCreateTime=0, eventSendTime=1713907423283)
[WI-0][TI-1281] - [INFO] 2024-04-24 05:24:13.324 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1281, processInstanceId=543, status=9, startTime=1713903509183, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, logPath=/opt/dolphinscheduler/logs/20240424/13201021801792/90/543/1281.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/543/1281, endTime=1713904084494, processId=300, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], eventCreateTime=0, eventSendTime=1713907153264)
[WI-0][TI-1281] - [INFO] 2024-04-24 05:24:13.327 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1281, processInstanceId=543, status=9, startTime=1713903509183, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, logPath=/opt/dolphinscheduler/logs/20240424/13201021801792/90/543/1281.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/543/1281, endTime=1713904084494, processId=300, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], eventCreateTime=0, eventSendTime=1713907453324)
[WI-0][TI-0] - [INFO] 2024-04-24 05:26:20.720 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1305, taskName=search for intake JSON files, firstSubmitTime=1713907580709, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.10:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=92, appIds=null, processInstanceId=550, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"processing"}], executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":""}],"rawScript":"# find 1 raw file in the folder\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\n\n# check if raw_file_dir is empty, then set raw_file_dir to null\nif [ -z \"$raw_file_dir\" ]; then\n    raw_file_dir=null\nfi\n\necho \"#{setValue(raw_file_dir=${raw_file_dir})}\"","resourceList":[]}, environmentConfig=export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='search for intake JSON files'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240424'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1305'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13340113777664'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240424052620'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='processing'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='550'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240423'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=null, dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-550][TI-1305] - [INFO] 2024-04-24 05:26:20.721 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: search for intake JSON files to wait queue success
[WI-550][TI-1305] - [INFO] 2024-04-24 05:26:20.722 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-550][TI-1305] - [INFO] 2024-04-24 05:26:20.724 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-550][TI-1305] - [INFO] 2024-04-24 05:26:20.724 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-550][TI-1305] - [INFO] 2024-04-24 05:26:20.724 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-550][TI-1305] - [INFO] 2024-04-24 05:26:20.724 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713907580724
[WI-550][TI-1305] - [INFO] 2024-04-24 05:26:20.724 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 550_1305
[WI-550][TI-1305] - [INFO] 2024-04-24 05:26:20.724 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1305,
  "taskName" : "search for intake JSON files",
  "firstSubmitTime" : 1713907580709,
  "startTime" : 1713907580724,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.10:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240424/13201021801792/92/550/1305.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 92,
  "processInstanceId" : 550,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"processing\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[{\"prop\":\"raw_file_dir\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"\"}],\"rawScript\":\"# find 1 raw file in the folder\\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\\n\\n# check if raw_file_dir is empty, then set raw_file_dir to null\\nif [ -z \\\"$raw_file_dir\\\" ]; then\\n    raw_file_dir=null\\nfi\\n\\necho \\\"#{setValue(raw_file_dir=${raw_file_dir})}\\\"\",\"resourceList\":[]}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "search for intake JSON files"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240424"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1305"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13340113777664"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240424052620"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "processing"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "550"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "550_1305",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-550][TI-1305] - [INFO] 2024-04-24 05:26:20.725 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-550][TI-1305] - [INFO] 2024-04-24 05:26:20.725 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-550][TI-1305] - [INFO] 2024-04-24 05:26:20.725 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-550][TI-1305] - [INFO] 2024-04-24 05:26:20.752 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-550][TI-1305] - [INFO] 2024-04-24 05:26:20.754 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-550][TI-1305] - [INFO] 2024-04-24 05:26:20.755 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_92/550/1305 check successfully
[WI-550][TI-1305] - [INFO] 2024-04-24 05:26:20.756 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-550][TI-1305] - [INFO] 2024-04-24 05:26:20.756 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-550][TI-1305] - [INFO] 2024-04-24 05:26:20.756 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-550][TI-1305] - [INFO] 2024-04-24 05:26:20.756 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-550][TI-1305] - [INFO] 2024-04-24 05:26:20.756 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ {
    "prop" : "raw_file_dir",
    "direct" : "OUT",
    "type" : "VARCHAR",
    "value" : ""
  } ],
  "varPool" : null,
  "rawScript" : "# find 1 raw file in the folder\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\n\n# check if raw_file_dir is empty, then set raw_file_dir to null\nif [ -z \"$raw_file_dir\" ]; then\n    raw_file_dir=null\nfi\n\necho \"#{setValue(raw_file_dir=${raw_file_dir})}\"",
  "resourceList" : [ ]
}
[WI-550][TI-1305] - [INFO] 2024-04-24 05:26:20.756 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-550][TI-1305] - [INFO] 2024-04-24 05:26:20.756 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: null successfully
[WI-550][TI-1305] - [INFO] 2024-04-24 05:26:20.756 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-550][TI-1305] - [INFO] 2024-04-24 05:26:20.758 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-550][TI-1305] - [INFO] 2024-04-24 05:26:20.758 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-550][TI-1305] - [INFO] 2024-04-24 05:26:20.758 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-550][TI-1305] - [INFO] 2024-04-24 05:26:20.761 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-550][TI-1305] - [INFO] 2024-04-24 05:26:20.761 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export PYTHON_LAUNCHER=/bin/python3.11
# find 1 raw file in the folder
raw_file_dir=$(find /local_storage/reddit/processing -type f -name '*.json'| head -n 1)

# check if raw_file_dir is empty, then set raw_file_dir to null
if [ -z "$raw_file_dir" ]; then
    raw_file_dir=null
fi

echo "#{setValue(raw_file_dir=${raw_file_dir})}"
[WI-550][TI-1305] - [INFO] 2024-04-24 05:26:20.761 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-550][TI-1305] - [INFO] 2024-04-24 05:26:20.761 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_92/550/1305/550_1305.sh
[WI-550][TI-1305] - [INFO] 2024-04-24 05:26:20.773 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 2041
[WI-0][TI-1305] - [INFO] 2024-04-24 05:26:21.466 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionRunningEvent(taskInstanceId=1305, processInstanceId=550, startTime=1713907580724, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, status=TaskExecutionStatus{code=1, desc='running'}, logPath=/opt/dolphinscheduler/logs/20240424/13201021801792/92/550/1305.log, executePath=null, processId=0, appIds=null, eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1305] - [INFO] 2024-04-24 05:26:21.473 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionRunningEvent(taskInstanceId=1305, processInstanceId=550, startTime=1713907580724, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, status=TaskExecutionStatus{code=1, desc='running'}, logPath=/opt/dolphinscheduler/logs/20240424/13201021801792/92/550/1305.log, executePath=null, processId=0, appIds=null, eventCreateTime=0, eventSendTime=1713907581464)
[WI-0][TI-1305] - [INFO] 2024-04-24 05:26:21.473 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionInfoEvent(taskInstanceId=1305, processInstanceId=550, startTime=1713907580724, workflowInstanceHost=172.18.0.10:5678, taskInstanceHost=172.18.1.1:1234, logPath=null, processId=0, eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1305] - [INFO] 2024-04-24 05:26:21.476 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1305, success=true)
[WI-0][TI-1305] - [INFO] 2024-04-24 05:26:21.481 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionInfoEvent(taskInstanceId=1305, processInstanceId=550, startTime=1713907580724, workflowInstanceHost=172.18.0.10:5678, taskInstanceHost=172.18.1.1:1234, logPath=null, processId=0, eventCreateTime=0, eventSendTime=1713907581464)
[WI-0][TI-1305] - [WARN] 2024-04-24 05:26:21.481 +0800 o.a.d.s.w.m.MessageRetryRunner:[139] - Retry send message to master error
java.util.ConcurrentModificationException: null
	at java.util.ArrayList$Itr.checkForComodification(ArrayList.java:911)
	at java.util.ArrayList$Itr.next(ArrayList.java:861)
	at org.apache.dolphinscheduler.server.worker.message.MessageRetryRunner.run(MessageRetryRunner.java:127)
[WI-0][TI-1305] - [INFO] 2024-04-24 05:26:21.492 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1305)
[WI-0][TI-1305] - [INFO] 2024-04-24 05:26:21.500 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1305, success=true)
[WI-0][TI-1305] - [INFO] 2024-04-24 05:26:21.512 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1305)
[WI-0][TI-0] - [INFO] 2024-04-24 05:26:21.775 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
	#{setValue(raw_file_dir=/local_storage/reddit/processing/500-20240423.json)}
[WI-550][TI-1305] - [INFO] 2024-04-24 05:26:21.777 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_92/550/1305, processId:2041 ,exitStatusCode:0 ,processWaitForStatus:true ,processExitValue:0
[WI-550][TI-1305] - [INFO] 2024-04-24 05:26:21.777 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-550][TI-1305] - [INFO] 2024-04-24 05:26:21.777 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-550][TI-1305] - [INFO] 2024-04-24 05:26:21.778 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-550][TI-1305] - [INFO] 2024-04-24 05:26:21.778 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-550][TI-1305] - [INFO] 2024-04-24 05:26:21.781 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: SUCCESS to master : 172.18.1.1:1234
[WI-550][TI-1305] - [INFO] 2024-04-24 05:26:21.781 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-550][TI-1305] - [INFO] 2024-04-24 05:26:21.781 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_92/550/1305
[WI-550][TI-1305] - [INFO] 2024-04-24 05:26:21.782 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_92/550/1305
[WI-550][TI-1305] - [INFO] 2024-04-24 05:26:21.782 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-1305] - [INFO] 2024-04-24 05:26:22.476 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1305, success=true)
[WI-0][TI-0] - [INFO] 2024-04-24 05:26:23.576 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1307, taskName=move to processing, firstSubmitTime=1713907583569, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.10:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=92, appIds=null, processInstanceId=550, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"processing"}], executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":""}],"rawScript":"# move file to the reddit processing folder\n# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error\nfilename=$(basename \"${raw_file_dir}\")\nif ! grep -q \"${REDDIT_HOME}/processing\" <<< \"${raw_file_dir}\"; then\n    mv ${raw_file_dir} ${REDDIT_HOME}/processing\nelse\n    echo JSON is already in processing\nfi\n\n# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing\necho \"#{setValue(raw_file_dir=${REDDIT_HOME}/processing/${filename})}\"","resourceList":[]}, environmentConfig=export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='move to processing'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240424'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1307'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13340390094208'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240424052623'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='processing'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='550'}, raw_file_dir=Property{prop='raw_file_dir', direct=IN, type=VARCHAR, value='/local_storage/reddit/processing/500-20240423.json'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240423'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-550][TI-1307] - [INFO] 2024-04-24 05:26:23.577 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: move to processing to wait queue success
[WI-550][TI-1307] - [INFO] 2024-04-24 05:26:23.577 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-550][TI-1307] - [INFO] 2024-04-24 05:26:23.578 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-550][TI-1307] - [INFO] 2024-04-24 05:26:23.579 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-550][TI-1307] - [INFO] 2024-04-24 05:26:23.579 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-550][TI-1307] - [INFO] 2024-04-24 05:26:23.579 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713907583579
[WI-550][TI-1307] - [INFO] 2024-04-24 05:26:23.579 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 550_1307
[WI-550][TI-1307] - [INFO] 2024-04-24 05:26:23.580 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1307,
  "taskName" : "move to processing",
  "firstSubmitTime" : 1713907583569,
  "startTime" : 1713907583579,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.10:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240424/13201021801792/92/550/1307.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 92,
  "processInstanceId" : 550,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"processing\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[{\"prop\":\"raw_file_dir\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"\"}],\"rawScript\":\"# move file to the reddit processing folder\\n# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error\\nfilename=$(basename \\\"${raw_file_dir}\\\")\\nif ! grep -q \\\"${REDDIT_HOME}/processing\\\" <<< \\\"${raw_file_dir}\\\"; then\\n    mv ${raw_file_dir} ${REDDIT_HOME}/processing\\nelse\\n    echo JSON is already in processing\\nfi\\n\\n# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing\\necho \\\"#{setValue(raw_file_dir=${REDDIT_HOME}/processing/${filename})}\\\"\",\"resourceList\":[]}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "move to processing"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240424"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1307"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13340390094208"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240424052623"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "processing"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "550"
    },
    "raw_file_dir" : {
      "prop" : "raw_file_dir",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit/processing/500-20240423.json"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "550_1307",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"raw_file_dir\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"/local_storage/reddit/processing/500-20240423.json\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-550][TI-1307] - [INFO] 2024-04-24 05:26:23.580 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-550][TI-1307] - [INFO] 2024-04-24 05:26:23.580 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-550][TI-1307] - [INFO] 2024-04-24 05:26:23.581 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-550][TI-1307] - [INFO] 2024-04-24 05:26:23.584 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-550][TI-1307] - [INFO] 2024-04-24 05:26:23.584 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-550][TI-1307] - [INFO] 2024-04-24 05:26:23.585 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_92/550/1307 check successfully
[WI-550][TI-1307] - [INFO] 2024-04-24 05:26:23.585 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-550][TI-1307] - [INFO] 2024-04-24 05:26:23.585 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-550][TI-1307] - [INFO] 2024-04-24 05:26:23.585 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-550][TI-1307] - [INFO] 2024-04-24 05:26:23.585 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-550][TI-1307] - [INFO] 2024-04-24 05:26:23.586 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ {
    "prop" : "raw_file_dir",
    "direct" : "OUT",
    "type" : "VARCHAR",
    "value" : ""
  } ],
  "varPool" : null,
  "rawScript" : "# move file to the reddit processing folder\n# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error\nfilename=$(basename \"${raw_file_dir}\")\nif ! grep -q \"${REDDIT_HOME}/processing\" <<< \"${raw_file_dir}\"; then\n    mv ${raw_file_dir} ${REDDIT_HOME}/processing\nelse\n    echo JSON is already in processing\nfi\n\n# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing\necho \"#{setValue(raw_file_dir=${REDDIT_HOME}/processing/${filename})}\"",
  "resourceList" : [ ]
}
[WI-550][TI-1307] - [INFO] 2024-04-24 05:26:23.586 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-550][TI-1307] - [INFO] 2024-04-24 05:26:23.586 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}] successfully
[WI-550][TI-1307] - [INFO] 2024-04-24 05:26:23.586 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-550][TI-1307] - [INFO] 2024-04-24 05:26:23.586 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-550][TI-1307] - [INFO] 2024-04-24 05:26:23.586 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-550][TI-1307] - [INFO] 2024-04-24 05:26:23.587 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-550][TI-1307] - [INFO] 2024-04-24 05:26:23.587 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-550][TI-1307] - [INFO] 2024-04-24 05:26:23.587 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export PYTHON_LAUNCHER=/bin/python3.11
# move file to the reddit processing folder
# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error
filename=$(basename "/local_storage/reddit/processing/500-20240423.json")
if ! grep -q "/local_storage/reddit/processing" <<< "/local_storage/reddit/processing/500-20240423.json"; then
    mv /local_storage/reddit/processing/500-20240423.json /local_storage/reddit/processing
else
    echo JSON is already in processing
fi

# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing
echo "#{setValue(raw_file_dir=/local_storage/reddit/processing/${filename})}"
[WI-550][TI-1307] - [INFO] 2024-04-24 05:26:23.587 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-550][TI-1307] - [INFO] 2024-04-24 05:26:23.587 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_92/550/1307/550_1307.sh
[WI-550][TI-1307] - [INFO] 2024-04-24 05:26:23.590 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 2055
[WI-0][TI-1307] - [INFO] 2024-04-24 05:26:24.479 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1307, success=true)
[WI-0][TI-1307] - [INFO] 2024-04-24 05:26:24.483 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionInfoEvent(taskInstanceId=1307, processInstanceId=550, startTime=1713907583579, workflowInstanceHost=172.18.0.10:5678, taskInstanceHost=172.18.1.1:1234, logPath=null, processId=0, eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1307] - [INFO] 2024-04-24 05:26:24.485 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionInfoEvent(taskInstanceId=1307, processInstanceId=550, startTime=1713907583579, workflowInstanceHost=172.18.0.10:5678, taskInstanceHost=172.18.1.1:1234, logPath=null, processId=0, eventCreateTime=0, eventSendTime=1713907584483)
[WI-0][TI-1307] - [INFO] 2024-04-24 05:26:24.486 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1307)
[WI-0][TI-1307] - [INFO] 2024-04-24 05:26:24.493 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1307)
[WI-0][TI-0] - [INFO] 2024-04-24 05:26:24.591 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
	JSON is already in processing
	#{setValue(raw_file_dir=/local_storage/reddit/processing/500-20240423.json)}
[WI-550][TI-1307] - [INFO] 2024-04-24 05:26:24.593 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_92/550/1307, processId:2055 ,exitStatusCode:0 ,processWaitForStatus:true ,processExitValue:0
[WI-550][TI-1307] - [INFO] 2024-04-24 05:26:24.594 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-550][TI-1307] - [INFO] 2024-04-24 05:26:24.594 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-550][TI-1307] - [INFO] 2024-04-24 05:26:24.595 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-550][TI-1307] - [INFO] 2024-04-24 05:26:24.595 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-550][TI-1307] - [INFO] 2024-04-24 05:26:24.598 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: SUCCESS to master : 172.18.1.1:1234
[WI-550][TI-1307] - [INFO] 2024-04-24 05:26:24.598 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-550][TI-1307] - [INFO] 2024-04-24 05:26:24.598 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_92/550/1307
[WI-550][TI-1307] - [INFO] 2024-04-24 05:26:24.599 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_92/550/1307
[WI-550][TI-1307] - [INFO] 2024-04-24 05:26:24.599 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-1307] - [INFO] 2024-04-24 05:26:25.481 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1307, success=true)
[WI-0][TI-0] - [INFO] 2024-04-24 05:26:25.633 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1308, taskName=spark preprocessing, firstSubmitTime=1713907585612, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.10:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=92, appIds=null, processInstanceId=550, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"processing"}], executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[],"rawScript":"$SPARK_HOME/bin/spark-submit \\\n    --master spark://spark-master:7077 \\\n    --deploy-mode client \\\n    --conf spark.driver.cores=1 \\\n    --conf spark.driver.memory=1G \\\n    --conf spark.executor.instances=1 \\\n    --conf spark.executor.cores=1 \\\n    --conf spark.executor.memory=1G \\\n    --name reddit_preprocessing testing.py\n\n# $SPARK_HOME/bin/spark-submit \\\n#     --master local \\\n#     --files ${raw_file_dir} \\\n#     --name reddit_preprocessing spark_reddit_preprocessing.py\n","resourceList":[{"id":null,"resourceName":"file:/dolphinscheduler/default/resources/testing.py","res":null}]}, environmentConfig=export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export PYSPARK_DRIVER_PYTHON=/bin/python3.11
export PYTHON_LAUNCHER=/bin/python3.11
export PYSPARK_PYTHON=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='spark preprocessing'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240424'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1308'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13210058002752'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240424052625'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='processing'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='550'}, raw_file_dir=Property{prop='raw_file_dir', direct=IN, type=VARCHAR, value='/local_storage/reddit/processing/500-20240423.json'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240423'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-550][TI-1308] - [INFO] 2024-04-24 05:26:25.652 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: spark preprocessing to wait queue success
[WI-550][TI-1308] - [INFO] 2024-04-24 05:26:25.652 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-550][TI-1308] - [INFO] 2024-04-24 05:26:25.658 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-550][TI-1308] - [INFO] 2024-04-24 05:26:25.658 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-550][TI-1308] - [INFO] 2024-04-24 05:26:25.659 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-550][TI-1308] - [INFO] 2024-04-24 05:26:25.659 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713907585659
[WI-550][TI-1308] - [INFO] 2024-04-24 05:26:25.659 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 550_1308
[WI-550][TI-1308] - [INFO] 2024-04-24 05:26:25.660 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1308,
  "taskName" : "spark preprocessing",
  "firstSubmitTime" : 1713907585612,
  "startTime" : 1713907585659,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.10:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240424/13201021801792/92/550/1308.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 92,
  "processInstanceId" : 550,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"processing\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[],\"rawScript\":\"$SPARK_HOME/bin/spark-submit \\\\\\n    --master spark://spark-master:7077 \\\\\\n    --deploy-mode client \\\\\\n    --conf spark.driver.cores=1 \\\\\\n    --conf spark.driver.memory=1G \\\\\\n    --conf spark.executor.instances=1 \\\\\\n    --conf spark.executor.cores=1 \\\\\\n    --conf spark.executor.memory=1G \\\\\\n    --name reddit_preprocessing testing.py\\n\\n# $SPARK_HOME/bin/spark-submit \\\\\\n#     --master local \\\\\\n#     --files ${raw_file_dir} \\\\\\n#     --name reddit_preprocessing spark_reddit_preprocessing.py\\n\",\"resourceList\":[{\"id\":null,\"resourceName\":\"file:/dolphinscheduler/default/resources/testing.py\",\"res\":null}]}",
  "environmentConfig" : "export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3\nexport JAVA_HOME=/opt/java/openjdk\nexport PYSPARK_DRIVER_PYTHON=/bin/python3.11\nexport PYTHON_LAUNCHER=/bin/python3.11\nexport PYSPARK_PYTHON=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "spark preprocessing"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240424"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1308"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13210058002752"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240424052625"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "processing"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "550"
    },
    "raw_file_dir" : {
      "prop" : "raw_file_dir",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit/processing/500-20240423.json"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "550_1308",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"raw_file_dir\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"/local_storage/reddit/processing/500-20240423.json\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-550][TI-1308] - [INFO] 2024-04-24 05:26:25.661 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-550][TI-1308] - [INFO] 2024-04-24 05:26:25.661 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-550][TI-1308] - [INFO] 2024-04-24 05:26:25.661 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-550][TI-1308] - [INFO] 2024-04-24 05:26:25.702 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-550][TI-1308] - [INFO] 2024-04-24 05:26:25.703 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-550][TI-1308] - [INFO] 2024-04-24 05:26:25.705 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_92/550/1308 check successfully
[WI-550][TI-1308] - [INFO] 2024-04-24 05:26:25.705 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-550][TI-1308] - [INFO] 2024-04-24 05:26:25.718 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={file:/dolphinscheduler/default/resources/testing.py=ResourceContext.ResourceItem(resourceAbsolutePathInStorage=file:/dolphinscheduler/default/resources/testing.py, resourceRelativePath=testing.py, resourceAbsolutePathInLocal=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_92/550/1308/testing.py)})
[WI-550][TI-1308] - [INFO] 2024-04-24 05:26:25.722 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-550][TI-1308] - [INFO] 2024-04-24 05:26:25.722 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-550][TI-1308] - [INFO] 2024-04-24 05:26:25.724 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ ],
  "varPool" : null,
  "rawScript" : "$SPARK_HOME/bin/spark-submit \\\n    --master spark://spark-master:7077 \\\n    --deploy-mode client \\\n    --conf spark.driver.cores=1 \\\n    --conf spark.driver.memory=1G \\\n    --conf spark.executor.instances=1 \\\n    --conf spark.executor.cores=1 \\\n    --conf spark.executor.memory=1G \\\n    --name reddit_preprocessing testing.py\n\n# $SPARK_HOME/bin/spark-submit \\\n#     --master local \\\n#     --files ${raw_file_dir} \\\n#     --name reddit_preprocessing spark_reddit_preprocessing.py\n",
  "resourceList" : [ {
    "id" : null,
    "resourceName" : "file:/dolphinscheduler/default/resources/testing.py",
    "res" : null
  } ]
}
[WI-550][TI-1308] - [INFO] 2024-04-24 05:26:25.726 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-550][TI-1308] - [INFO] 2024-04-24 05:26:25.726 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}] successfully
[WI-550][TI-1308] - [INFO] 2024-04-24 05:26:25.726 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-550][TI-1308] - [INFO] 2024-04-24 05:26:25.726 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-550][TI-1308] - [INFO] 2024-04-24 05:26:25.726 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-550][TI-1308] - [INFO] 2024-04-24 05:26:25.749 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-550][TI-1308] - [INFO] 2024-04-24 05:26:25.756 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-550][TI-1308] - [INFO] 2024-04-24 05:26:25.756 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export PYSPARK_DRIVER_PYTHON=/bin/python3.11
export PYTHON_LAUNCHER=/bin/python3.11
export PYSPARK_PYTHON=/bin/python3.11
$SPARK_HOME/bin/spark-submit \
    --master spark://spark-master:7077 \
    --deploy-mode client \
    --conf spark.driver.cores=1 \
    --conf spark.driver.memory=1G \
    --conf spark.executor.instances=1 \
    --conf spark.executor.cores=1 \
    --conf spark.executor.memory=1G \
    --name reddit_preprocessing testing.py

# $SPARK_HOME/bin/spark-submit \
#     --master local \
#     --files /local_storage/reddit/processing/500-20240423.json \
#     --name reddit_preprocessing spark_reddit_preprocessing.py

[WI-550][TI-1308] - [INFO] 2024-04-24 05:26:25.757 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-550][TI-1308] - [INFO] 2024-04-24 05:26:25.757 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_92/550/1308/550_1308.sh
[WI-550][TI-1308] - [INFO] 2024-04-24 05:26:25.769 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 2067
[WI-0][TI-1308] - [INFO] 2024-04-24 05:26:26.484 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1308, success=true)
[WI-0][TI-1308] - [INFO] 2024-04-24 05:26:26.489 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionInfoEvent(taskInstanceId=1308, processInstanceId=550, startTime=1713907585659, workflowInstanceHost=172.18.0.10:5678, taskInstanceHost=172.18.1.1:1234, logPath=null, processId=0, eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1308] - [INFO] 2024-04-24 05:26:26.494 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionInfoEvent(taskInstanceId=1308, processInstanceId=550, startTime=1713907585659, workflowInstanceHost=172.18.0.10:5678, taskInstanceHost=172.18.1.1:1234, logPath=null, processId=0, eventCreateTime=0, eventSendTime=1713907586489)
[WI-0][TI-1308] - [INFO] 2024-04-24 05:26:26.500 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1308)
[WI-0][TI-1308] - [INFO] 2024-04-24 05:26:26.536 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1308)
[WI-0][TI-0] - [INFO] 2024-04-24 05:26:26.759 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9387504191349056 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 05:26:26.772 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
[WI-0][TI-0] - [INFO] 2024-04-24 05:26:29.789 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 05:26:29 INFO SparkContext: Running Spark version 3.5.1
	24/04/24 05:26:29 INFO SparkContext: OS info Linux, 6.5.0-28-generic, amd64
	24/04/24 05:26:29 INFO SparkContext: Java version 1.8.0_402
	24/04/24 05:26:29 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
	24/04/24 05:26:29 INFO ResourceUtils: ==============================================================
	24/04/24 05:26:29 INFO ResourceUtils: No custom resources configured for spark.driver.
	24/04/24 05:26:29 INFO ResourceUtils: ==============================================================
	24/04/24 05:26:29 INFO SparkContext: Submitted application: Create DataFrame Example
	24/04/24 05:26:29 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
	24/04/24 05:26:29 INFO ResourceProfile: Limiting resource is cpus at 1 tasks per executor
	24/04/24 05:26:29 INFO ResourceProfileManager: Added ResourceProfile id: 0
[WI-0][TI-0] - [INFO] 2024-04-24 05:26:30.803 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7639257294429709 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 05:26:30.794 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 05:26:29 INFO SecurityManager: Changing view acls to: default
	24/04/24 05:26:29 INFO SecurityManager: Changing modify acls to: default
	24/04/24 05:26:29 INFO SecurityManager: Changing view acls groups to: 
	24/04/24 05:26:29 INFO SecurityManager: Changing modify acls groups to: 
	24/04/24 05:26:29 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: default; groups with view permissions: EMPTY; users with modify permissions: default; groups with modify permissions: EMPTY
	24/04/24 05:26:30 INFO Utils: Successfully started service 'sparkDriver' on port 35849.
	24/04/24 05:26:30 INFO SparkEnv: Registering MapOutputTracker
[WI-0][TI-0] - [INFO] 2024-04-24 05:26:31.832 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 05:26:30 INFO SparkEnv: Registering BlockManagerMaster
	24/04/24 05:26:30 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
	24/04/24 05:26:30 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
	24/04/24 05:26:30 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
	24/04/24 05:26:31 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-4a0e7450-838b-49d5-8d1c-82cf134ffd41
	24/04/24 05:26:31 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
	24/04/24 05:26:31 INFO SparkEnv: Registering OutputCommitCoordinator
	24/04/24 05:26:31 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
	24/04/24 05:26:31 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
	24/04/24 05:26:31 INFO Utils: Successfully started service 'SparkUI' on port 4041.
[WI-0][TI-0] - [INFO] 2024-04-24 05:26:31.853 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9021739130434783 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 05:26:32.836 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 05:26:32 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
	24/04/24 05:26:32 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.4:7077 after 147 ms (0 ms spent in bootstraps)
	24/04/24 05:26:32 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20240423212632-0006
	24/04/24 05:26:32 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37657.
	24/04/24 05:26:32 INFO NettyBlockTransferService: Server created on 5afbfd5249fc:37657
	24/04/24 05:26:32 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
	24/04/24 05:26:32 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 5afbfd5249fc, 37657, None)
	24/04/24 05:26:32 INFO BlockManagerMasterEndpoint: Registering block manager 5afbfd5249fc:37657 with 366.3 MiB RAM, BlockManagerId(driver, 5afbfd5249fc, 37657, None)
	24/04/24 05:26:32 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 5afbfd5249fc, 37657, None)
	24/04/24 05:26:32 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 5afbfd5249fc, 37657, None)
[WI-0][TI-0] - [INFO] 2024-04-24 05:26:32.855 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.848 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 05:26:33.837 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 05:26:33 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
[WI-0][TI-0] - [INFO] 2024-04-24 05:26:34.839 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 05:26:33 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
	24/04/24 05:26:33 INFO SharedState: Warehouse path is 'file:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_92/550/1308/spark-warehouse'.
[WI-0][TI-0] - [INFO] 2024-04-24 05:26:36.871 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8169398907103825 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 05:26:37.848 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 05:26:37 INFO CodeGenerator: Code generated in 274.786489 ms
	24/04/24 05:26:37 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0
	24/04/24 05:26:37 INFO DAGScheduler: Got job 0 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
	24/04/24 05:26:37 INFO DAGScheduler: Final stage: ResultStage 0 (showString at NativeMethodAccessorImpl.java:0)
	24/04/24 05:26:37 INFO DAGScheduler: Parents of final stage: List()
	24/04/24 05:26:37 INFO DAGScheduler: Missing parents: List()
	24/04/24 05:26:37 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[6] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
	24/04/24 05:26:37 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 14.0 KiB, free 366.3 MiB)
	24/04/24 05:26:37 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 6.9 KiB, free 366.3 MiB)
	24/04/24 05:26:37 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 5afbfd5249fc:37657 (size: 6.9 KiB, free: 366.3 MiB)
	24/04/24 05:26:37 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1585
	24/04/24 05:26:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[6] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
	24/04/24 05:26:37 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
[WI-0][TI-0] - [INFO] 2024-04-24 05:26:40.898 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7740112994350282 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 05:26:41.956 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7845744680851063 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 05:26:49.614 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 05:26:48 ERROR StandaloneSchedulerBackend: Application has been killed. Reason: Master removed our application: KILLED
	24/04/24 05:26:49 INFO TaskSchedulerImpl: Cancelling stage 0
	24/04/24 05:26:49 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage cancelled: Job aborted due to stage failure: Master removed our application: KILLED
	24/04/24 05:26:49 INFO SparkContext: SparkContext is stopping with exitCode 0.
	24/04/24 05:26:49 INFO TaskSchedulerImpl: Stage 0 was cancelled
	24/04/24 05:26:49 INFO DAGScheduler: ResultStage 0 (json at NativeMethodAccessorImpl.java:0) failed in 956.103 s due to Job aborted due to stage failure: Master removed our application: KILLED
	24/04/24 05:26:49 INFO DAGScheduler: Job 0 failed: json at NativeMethodAccessorImpl.java:0, took 956.232843 s
	24/04/24 05:26:49 INFO SparkUI: Stopped Spark web UI at http://5afbfd5249fc:4040
	24/04/24 05:26:49 ERROR Inbox: Ignoring error
	java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@6a847920 rejected from java.util.concurrent.ScheduledThreadPoolExecutor@4f0b05fd[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0]
		at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2063)
		at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:830)
		at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)
		at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
		at org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend$StandaloneDriverEndpoint.$anonfun$onDisconnected$1(StandaloneSchedulerBackend.scala:346)
		at scala.Option.foreach(Option.scala:407)
		at org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend$StandaloneDriverEndpoint.onDisconnected(StandaloneSchedulerBackend.scala:313)
		at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:141)
		at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
		at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
		at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
		at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
		at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
		at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
		at java.lang.Thread.run(Thread.java:750)
	24/04/24 05:26:49 INFO StandaloneSchedulerBackend: Shutting down all executors
	24/04/24 05:26:49 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Asking each executor to shut down
	24/04/24 05:26:49 ERROR Utils: Uncaught exception in thread stop-spark-context
	org.apache.spark.SparkException: Exception thrown in awaitResult: 
		at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
		at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
		at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
		at org.apache.spark.deploy.client.StandaloneAppClient.stop(StandaloneAppClient.scala:288)
		at org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend.org$apache$spark$scheduler$cluster$StandaloneSchedulerBackend$$stop(StandaloneSchedulerBackend.scala:275)
		at org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend.stop(StandaloneSchedulerBackend.scala:142)
		at org.apache.spark.scheduler.SchedulerBackend.stop(SchedulerBackend.scala:33)
		at org.apache.spark.scheduler.SchedulerBackend.stop$(SchedulerBackend.scala:33)
		at org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend.stop(CoarseGrainedSchedulerBackend.scala:54)
		at org.apache.spark.scheduler.TaskSchedulerImpl.$anonfun$stop$2(TaskSchedulerImpl.scala:992)
		at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1375)
		at org.apache.spark.scheduler.TaskSchedulerImpl.stop(TaskSchedulerImpl.scala:992)
		at org.apache.spark.scheduler.DAGScheduler.$anonfun$stop$4(DAGScheduler.scala:2976)
		at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1375)
		at org.apache.spark.scheduler.DAGScheduler.stop(DAGScheduler.scala:2976)
		at org.apache.spark.SparkContext.$anonfun$stop$12(SparkContext.scala:2263)
		at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1375)
		at org.apache.spark.SparkContext.stop(SparkContext.scala:2263)
		at org.apache.spark.SparkContext.stop(SparkContext.scala:2216)
		at org.apache.spark.SparkContext$$anon$3.run(SparkContext.scala:2203)
	Caused by: org.apache.spark.SparkException: Could not find AppClient.
		at org.apache.spark.rpc.netty.Dispatcher.postMessage(Dispatcher.scala:178)
		at org.apache.spark.rpc.netty.Dispatcher.postLocalMessage(Dispatcher.scala:144)
		at org.apache.spark.rpc.netty.NettyRpcEnv.askAbortable(NettyRpcEnv.scala:242)
		at org.apache.spark.rpc.netty.NettyRpcEndpointRef.askAbortable(NettyRpcEnv.scala:554)
		at org.apache.spark.rpc.netty.NettyRpcEndpointRef.ask(NettyRpcEnv.scala:558)
		at org.apache.spark.rpc.RpcEndpointRef.ask(RpcEndpointRef.scala:72)
		... 17 more
	24/04/24 05:26:49 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
[WI-0][TI-0] - [INFO] 2024-04-24 05:26:49.856 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 05:26:49 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20240423212632-0006/0 on worker-20240423200818-172.18.0.6-42177 (172.18.0.6:42177) with 1 core(s)
	24/04/24 05:26:49 INFO StandaloneSchedulerBackend: Granted executor ID app-20240423212632-0006/0 on hostPort 172.18.0.6:42177 with 1 core(s), 1024.0 MiB RAM
	24/04/24 05:26:49 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20240423212632-0006/1 on worker-20240423200818-172.18.0.6-42177 (172.18.0.6:42177) with 1 core(s)
	24/04/24 05:26:49 INFO StandaloneSchedulerBackend: Granted executor ID app-20240423212632-0006/1 on hostPort 172.18.0.6:42177 with 1 core(s), 1024.0 MiB RAM
	24/04/24 05:26:49 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20240423212632-0006/1 is now RUNNING
	24/04/24 05:26:49 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20240423212632-0006/0 is now RUNNING
[WI-0][TI-0] - [INFO] 2024-04-24 05:26:49.976 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9908722483190567 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 05:26:50.619 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 05:26:49 INFO MemoryStore: MemoryStore cleared
	24/04/24 05:26:49 INFO BlockManager: BlockManager stopped
	24/04/24 05:26:49 INFO BlockManagerMaster: BlockManagerMaster stopped
	24/04/24 05:26:49 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
	24/04/24 05:26:49 INFO SparkContext: Successfully stopped SparkContext
	Traceback (most recent call last):
	  File "/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_92/549/1304/testing.py", line 38, in <module>
	    raw_df = spark.read.json(spark.sparkContext.parallelize([example_json]))
	             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
	  File "/opt/spark-3.5.1-bin-hadoop3/python/lib/pyspark.zip/pyspark/sql/readwriter.py", line 440, in json
	  File "/opt/spark-3.5.1-bin-hadoop3/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
	  File "/opt/spark-3.5.1-bin-hadoop3/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 179, in deco
	  File "/opt/spark-3.5.1-bin-hadoop3/python/lib/py4j-0.10.9.7-src.zip/py4j/protocol.py", line 326, in get_return_value
	py4j.protocol.Py4JJavaError: An error occurred while calling o29.json.
	: org.apache.spark.SparkException: Job aborted due to stage failure: Master removed our application: KILLED
		at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)
		at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)
		at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)
		at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
		at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
		at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
		at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)
		at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)
		at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)
		at scala.Option.foreach(Option.scala:407)
		at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)
		at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)
		at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)
		at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)
		at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
		at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:989)
		at org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)
		at org.apache.spark.SparkContext.runJob(SparkContext.scala:2493)
		at org.apache.spark.sql.catalyst.json.JsonInferSchema.infer(JsonInferSchema.scala:120)
		at org.apache.spark.sql.execution.datasources.json.TextInputJsonDataSource$.$anonfun$inferFromDataset$5(JsonDataSource.scala:109)
		at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)
		at org.apache.spark.sql.execution.datasources.json.TextInputJsonDataSource$.inferFromDataset(JsonDataSource.scala:109)
		at org.apache.spark.sql.DataFrameReader.$anonfun$json$4(DataFrameReader.scala:416)
		at scala.Option.getOrElse(Option.scala:189)
		at org.apache.spark.sql.DataFrameReader.json(DataFrameReader.scala:416)
		at org.apache.spark.sql.DataFrameReader.json(DataFrameReader.scala:391)
		at org.apache.spark.sql.DataFrameReader.json(DataFrameReader.scala:377)
		at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
		at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
		at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
		at java.lang.reflect.Method.invoke(Method.java:498)
		at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
		at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
		at py4j.Gateway.invoke(Gateway.java:282)
		at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
		at py4j.commands.CallCommand.execute(CallCommand.java:79)
		at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
		at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
		at java.lang.Thread.run(Thread.java:750)
	
	24/04/24 05:26:49 INFO ShutdownHookManager: Shutdown hook called
	24/04/24 05:26:49 INFO ShutdownHookManager: Deleting directory /tmp/spark-f88421f3-0956-4c07-bb13-8e9793dcc920/pyspark-49620398-319d-4c78-903c-89a22d0c3c9b
	24/04/24 05:26:49 INFO ShutdownHookManager: Deleting directory /tmp/spark-3170a32d-8640-48d6-9dd5-3146b1c37767
	24/04/24 05:26:49 INFO ShutdownHookManager: Deleting directory /tmp/spark-f88421f3-0956-4c07-bb13-8e9793dcc920
[WI-549][TI-1304] - [INFO] 2024-04-24 05:26:50.623 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_92/549/1304, processId:1744 ,exitStatusCode:1 ,processWaitForStatus:true ,processExitValue:1
[WI-549][TI-1304] - [INFO] 2024-04-24 05:26:50.624 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-549][TI-1304] - [INFO] 2024-04-24 05:26:50.624 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-549][TI-1304] - [INFO] 2024-04-24 05:26:50.624 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-549][TI-1304] - [INFO] 2024-04-24 05:26:50.625 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-549][TI-1304] - [INFO] 2024-04-24 05:26:50.637 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: FAILURE to master : 172.18.1.1:1234
[WI-549][TI-1304] - [INFO] 2024-04-24 05:26:50.639 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-549][TI-1304] - [INFO] 2024-04-24 05:26:50.639 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_92/549/1304
[WI-549][TI-1304] - [INFO] 2024-04-24 05:26:50.641 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_92/549/1304
[WI-549][TI-1304] - [INFO] 2024-04-24 05:26:50.641 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-0] - [INFO] 2024-04-24 05:26:51.011 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.945877085877086 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-1304] - [INFO] 2024-04-24 05:26:51.624 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1304, processInstanceId=549, status=6, startTime=1713906633497, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, logPath=/opt/dolphinscheduler/logs/20240424/13201021801792/92/549/1304.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_92/549/1304, endTime=1713907610625, processId=1744, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1304] - [INFO] 2024-04-24 05:26:51.635 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1304, processInstanceId=549, status=6, startTime=1713906633497, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, logPath=/opt/dolphinscheduler/logs/20240424/13201021801792/92/549/1304.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_92/549/1304, endTime=1713907610625, processId=1744, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], eventCreateTime=0, eventSendTime=1713907611624)
[WI-0][TI-1304] - [INFO] 2024-04-24 05:26:51.640 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1304, success=true)
[WI-0][TI-1304] - [INFO] 2024-04-24 05:26:51.645 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1304, success=true)
[WI-0][TI-0] - [INFO] 2024-04-24 05:26:52.014 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9375 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 05:26:52.862 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 05:26:52 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
[WI-0][TI-0] - [INFO] 2024-04-24 05:26:53.028 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8441558441558441 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 05:26:54.037 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8882175226586102 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 05:26:55.038 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9196787148594378 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 05:26:56.042 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8900709219858156 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 05:26:56.902 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 05:26:56 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.6:35788) with ID 0,  ResourceProfileId 0
	24/04/24 05:26:56 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.6:38555 with 434.4 MiB RAM, BlockManagerId(0, 172.18.0.6, 38555, None)
[WI-0][TI-0] - [INFO] 2024-04-24 05:26:57.106 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8188153310104529 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 05:26:57.903 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 05:26:56 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.6, executor 0, partition 0, PROCESS_LOCAL, 7742 bytes) 
	24/04/24 05:26:56 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.6:35796) with ID 1,  ResourceProfileId 0
	24/04/24 05:26:57 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.6:42231 with 434.4 MiB RAM, BlockManagerId(1, 172.18.0.6, 42231, None)
[WI-0][TI-0] - [INFO] 2024-04-24 05:27:48.254 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7598870056497176 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 05:27:49.287 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7929155313351498 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 05:28:30.425 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7796610169491526 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-1292] - [INFO] 2024-04-24 05:28:43.440 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1292, processInstanceId=546, status=9, startTime=1713904461692, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, logPath=/opt/dolphinscheduler/logs/20240424/13201021801792/90/546/1292.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/546/1292, endTime=1713905019537, processId=841, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], eventCreateTime=0, eventSendTime=1713907423283)
[WI-0][TI-1292] - [INFO] 2024-04-24 05:28:43.450 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1292, processInstanceId=546, status=9, startTime=1713904461692, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, logPath=/opt/dolphinscheduler/logs/20240424/13201021801792/90/546/1292.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/546/1292, endTime=1713905019537, processId=841, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], eventCreateTime=0, eventSendTime=1713907723440)
[WI-0][TI-1281] - [INFO] 2024-04-24 05:29:13.492 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1281, processInstanceId=543, status=9, startTime=1713903509183, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, logPath=/opt/dolphinscheduler/logs/20240424/13201021801792/90/543/1281.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/543/1281, endTime=1713904084494, processId=300, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], eventCreateTime=0, eventSendTime=1713907453324)
[WI-0][TI-1281] - [INFO] 2024-04-24 05:29:13.495 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1281, processInstanceId=543, status=9, startTime=1713903509183, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, logPath=/opt/dolphinscheduler/logs/20240424/13201021801792/90/543/1281.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/543/1281, endTime=1713904084494, processId=300, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], eventCreateTime=0, eventSendTime=1713907753492)
[WI-0][TI-0] - [INFO] 2024-04-24 05:29:56.758 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8528610354223434 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 05:30:17.819 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7576601671309191 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-1292] - [INFO] 2024-04-24 05:33:43.775 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1292, processInstanceId=546, status=9, startTime=1713904461692, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, logPath=/opt/dolphinscheduler/logs/20240424/13201021801792/90/546/1292.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/546/1292, endTime=1713905019537, processId=841, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], eventCreateTime=0, eventSendTime=1713907723440)
[WI-0][TI-1292] - [INFO] 2024-04-24 05:33:43.779 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1292, processInstanceId=546, status=9, startTime=1713904461692, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, logPath=/opt/dolphinscheduler/logs/20240424/13201021801792/90/546/1292.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/546/1292, endTime=1713905019537, processId=841, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], eventCreateTime=0, eventSendTime=1713908023775)
[WI-0][TI-1281] - [INFO] 2024-04-24 05:34:13.809 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1281, processInstanceId=543, status=9, startTime=1713903509183, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, logPath=/opt/dolphinscheduler/logs/20240424/13201021801792/90/543/1281.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/543/1281, endTime=1713904084494, processId=300, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], eventCreateTime=0, eventSendTime=1713907753492)
[WI-0][TI-1281] - [INFO] 2024-04-24 05:34:13.816 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1281, processInstanceId=543, status=9, startTime=1713903509183, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, logPath=/opt/dolphinscheduler/logs/20240424/13201021801792/90/543/1281.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/543/1281, endTime=1713904084494, processId=300, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], eventCreateTime=0, eventSendTime=1713908053809)
[WI-0][TI-0] - [INFO] 2024-04-24 05:34:42.725 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7138888888888888 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 05:34:43.751 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7058823529411764 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 05:34:46.860 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1309, taskName=search for intake JSON files, firstSubmitTime=1713908086821, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.10:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=93, appIds=null, processInstanceId=551, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"in"}], executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":""}],"rawScript":"# find 1 raw file in the folder\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\n\n# check if raw_file_dir is empty, then set raw_file_dir to null\nif [ -z \"$raw_file_dir\" ]; then\n    raw_file_dir=null\nfi\n\necho \"#{setValue(raw_file_dir=${raw_file_dir})}\"","resourceList":[]}, environmentConfig=export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='search for intake JSON files'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240424'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1309'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13340113777664'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240424053446'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='in'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='551'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240423'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=null, dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-551][TI-1309] - [INFO] 2024-04-24 05:34:46.861 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: search for intake JSON files to wait queue success
[WI-551][TI-1309] - [INFO] 2024-04-24 05:34:46.863 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-551][TI-1309] - [INFO] 2024-04-24 05:34:46.882 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-551][TI-1309] - [INFO] 2024-04-24 05:34:46.886 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-551][TI-1309] - [INFO] 2024-04-24 05:34:46.897 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-551][TI-1309] - [INFO] 2024-04-24 05:34:46.897 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713908086897
[WI-551][TI-1309] - [INFO] 2024-04-24 05:34:46.898 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 551_1309
[WI-551][TI-1309] - [INFO] 2024-04-24 05:34:46.902 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1309,
  "taskName" : "search for intake JSON files",
  "firstSubmitTime" : 1713908086821,
  "startTime" : 1713908086897,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.10:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240424/13201021801792/93/551/1309.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 93,
  "processInstanceId" : 551,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"in\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[{\"prop\":\"raw_file_dir\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"\"}],\"rawScript\":\"# find 1 raw file in the folder\\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\\n\\n# check if raw_file_dir is empty, then set raw_file_dir to null\\nif [ -z \\\"$raw_file_dir\\\" ]; then\\n    raw_file_dir=null\\nfi\\n\\necho \\\"#{setValue(raw_file_dir=${raw_file_dir})}\\\"\",\"resourceList\":[]}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "search for intake JSON files"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240424"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1309"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13340113777664"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240424053446"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "in"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "551"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "551_1309",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-551][TI-1309] - [INFO] 2024-04-24 05:34:46.913 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-551][TI-1309] - [INFO] 2024-04-24 05:34:46.916 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-551][TI-1309] - [INFO] 2024-04-24 05:34:46.916 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-551][TI-1309] - [INFO] 2024-04-24 05:34:46.922 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-551][TI-1309] - [INFO] 2024-04-24 05:34:46.923 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-551][TI-1309] - [INFO] 2024-04-24 05:34:46.924 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_93/551/1309 check successfully
[WI-551][TI-1309] - [INFO] 2024-04-24 05:34:46.924 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-551][TI-1309] - [INFO] 2024-04-24 05:34:46.925 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-551][TI-1309] - [INFO] 2024-04-24 05:34:46.925 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-551][TI-1309] - [INFO] 2024-04-24 05:34:46.925 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-551][TI-1309] - [INFO] 2024-04-24 05:34:46.925 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ {
    "prop" : "raw_file_dir",
    "direct" : "OUT",
    "type" : "VARCHAR",
    "value" : ""
  } ],
  "varPool" : null,
  "rawScript" : "# find 1 raw file in the folder\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\n\n# check if raw_file_dir is empty, then set raw_file_dir to null\nif [ -z \"$raw_file_dir\" ]; then\n    raw_file_dir=null\nfi\n\necho \"#{setValue(raw_file_dir=${raw_file_dir})}\"",
  "resourceList" : [ ]
}
[WI-551][TI-1309] - [INFO] 2024-04-24 05:34:46.925 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-551][TI-1309] - [INFO] 2024-04-24 05:34:46.925 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: null successfully
[WI-551][TI-1309] - [INFO] 2024-04-24 05:34:46.925 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-551][TI-1309] - [INFO] 2024-04-24 05:34:46.926 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-551][TI-1309] - [INFO] 2024-04-24 05:34:46.926 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-551][TI-1309] - [INFO] 2024-04-24 05:34:46.926 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-551][TI-1309] - [INFO] 2024-04-24 05:34:46.927 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-551][TI-1309] - [INFO] 2024-04-24 05:34:46.927 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export PYTHON_LAUNCHER=/bin/python3.11
# find 1 raw file in the folder
raw_file_dir=$(find /local_storage/reddit/in -type f -name '*.json'| head -n 1)

# check if raw_file_dir is empty, then set raw_file_dir to null
if [ -z "$raw_file_dir" ]; then
    raw_file_dir=null
fi

echo "#{setValue(raw_file_dir=${raw_file_dir})}"
[WI-551][TI-1309] - [INFO] 2024-04-24 05:34:46.927 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-551][TI-1309] - [INFO] 2024-04-24 05:34:46.927 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_93/551/1309/551_1309.sh
[WI-551][TI-1309] - [INFO] 2024-04-24 05:34:46.934 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 2294
[WI-0][TI-1309] - [INFO] 2024-04-24 05:34:47.855 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1309, success=true)
[WI-0][TI-1309] - [INFO] 2024-04-24 05:34:47.866 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1309)
[WI-0][TI-0] - [INFO] 2024-04-24 05:34:47.934 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
	#{setValue(raw_file_dir=null)}
[WI-551][TI-1309] - [INFO] 2024-04-24 05:34:47.936 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_93/551/1309, processId:2294 ,exitStatusCode:0 ,processWaitForStatus:true ,processExitValue:0
[WI-551][TI-1309] - [INFO] 2024-04-24 05:34:47.937 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-551][TI-1309] - [INFO] 2024-04-24 05:34:47.937 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-551][TI-1309] - [INFO] 2024-04-24 05:34:47.937 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-551][TI-1309] - [INFO] 2024-04-24 05:34:47.937 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-551][TI-1309] - [INFO] 2024-04-24 05:34:47.959 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: SUCCESS to master : 172.18.1.1:1234
[WI-551][TI-1309] - [INFO] 2024-04-24 05:34:47.960 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-551][TI-1309] - [INFO] 2024-04-24 05:34:47.960 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_93/551/1309
[WI-551][TI-1309] - [INFO] 2024-04-24 05:34:47.960 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_93/551/1309
[WI-551][TI-1309] - [INFO] 2024-04-24 05:34:47.960 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-1309] - [INFO] 2024-04-24 05:34:48.875 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1309, success=true)
[WI-0][TI-0] - [INFO] 2024-04-24 05:34:50.108 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1311, taskName=end workflow, firstSubmitTime=1713908090034, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.10:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=93, appIds=null, processInstanceId=551, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"in"}], executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[],"rawScript":"echo No Files Detected - End Workflow","resourceList":[]}, environmentConfig=export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='end workflow'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240424'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1311'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13348985859488'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240424053450'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='in'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='551'}, raw_file_dir=Property{prop='raw_file_dir', direct=IN, type=VARCHAR, value='null'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240423'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"null"}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-551][TI-1311] - [INFO] 2024-04-24 05:34:50.119 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: end workflow to wait queue success
[WI-551][TI-1311] - [INFO] 2024-04-24 05:34:50.125 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-551][TI-1311] - [INFO] 2024-04-24 05:34:50.143 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-551][TI-1311] - [INFO] 2024-04-24 05:34:50.146 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-551][TI-1311] - [INFO] 2024-04-24 05:34:50.150 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-551][TI-1311] - [INFO] 2024-04-24 05:34:50.158 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713908090158
[WI-551][TI-1311] - [INFO] 2024-04-24 05:34:50.159 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 551_1311
[WI-551][TI-1311] - [INFO] 2024-04-24 05:34:50.160 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1311,
  "taskName" : "end workflow",
  "firstSubmitTime" : 1713908090034,
  "startTime" : 1713908090158,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.10:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240424/13201021801792/93/551/1311.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 93,
  "processInstanceId" : 551,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"in\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[],\"rawScript\":\"echo No Files Detected - End Workflow\",\"resourceList\":[]}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "end workflow"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240424"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1311"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13348985859488"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240424053450"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "in"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "551"
    },
    "raw_file_dir" : {
      "prop" : "raw_file_dir",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "null"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "551_1311",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"raw_file_dir\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"null\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-551][TI-1311] - [INFO] 2024-04-24 05:34:50.161 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-551][TI-1311] - [INFO] 2024-04-24 05:34:50.161 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-551][TI-1311] - [INFO] 2024-04-24 05:34:50.161 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-551][TI-1311] - [INFO] 2024-04-24 05:34:50.196 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-551][TI-1311] - [INFO] 2024-04-24 05:34:50.197 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-551][TI-1311] - [INFO] 2024-04-24 05:34:50.198 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_93/551/1311 check successfully
[WI-551][TI-1311] - [INFO] 2024-04-24 05:34:50.198 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-551][TI-1311] - [INFO] 2024-04-24 05:34:50.199 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-551][TI-1311] - [INFO] 2024-04-24 05:34:50.200 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-551][TI-1311] - [INFO] 2024-04-24 05:34:50.200 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-551][TI-1311] - [INFO] 2024-04-24 05:34:50.200 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ ],
  "varPool" : null,
  "rawScript" : "echo No Files Detected - End Workflow",
  "resourceList" : [ ]
}
[WI-551][TI-1311] - [INFO] 2024-04-24 05:34:50.200 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-551][TI-1311] - [INFO] 2024-04-24 05:34:50.201 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"null"}] successfully
[WI-551][TI-1311] - [INFO] 2024-04-24 05:34:50.201 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-551][TI-1311] - [INFO] 2024-04-24 05:34:50.201 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-551][TI-1311] - [INFO] 2024-04-24 05:34:50.201 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-551][TI-1311] - [INFO] 2024-04-24 05:34:50.202 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-551][TI-1311] - [INFO] 2024-04-24 05:34:50.202 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-551][TI-1311] - [INFO] 2024-04-24 05:34:50.202 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export PYTHON_LAUNCHER=/bin/python3.11
echo No Files Detected - End Workflow
[WI-551][TI-1311] - [INFO] 2024-04-24 05:34:50.202 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-551][TI-1311] - [INFO] 2024-04-24 05:34:50.203 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_93/551/1311/551_1311.sh
[WI-551][TI-1311] - [INFO] 2024-04-24 05:34:50.211 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 2314
[WI-0][TI-0] - [INFO] 2024-04-24 05:34:50.783 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8517441860465116 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-1311] - [INFO] 2024-04-24 05:34:50.884 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1311, success=true)
[WI-0][TI-1311] - [INFO] 2024-04-24 05:34:50.890 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionRunningEvent(taskInstanceId=1311, processInstanceId=551, startTime=1713908090158, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, status=TaskExecutionStatus{code=1, desc='running'}, logPath=/opt/dolphinscheduler/logs/20240424/13201021801792/93/551/1311.log, executePath=null, processId=0, appIds=null, eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1311] - [INFO] 2024-04-24 05:34:50.922 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionRunningEvent(taskInstanceId=1311, processInstanceId=551, startTime=1713908090158, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, status=TaskExecutionStatus{code=1, desc='running'}, logPath=/opt/dolphinscheduler/logs/20240424/13201021801792/93/551/1311.log, executePath=null, processId=0, appIds=null, eventCreateTime=0, eventSendTime=1713908090884)
[WI-0][TI-1311] - [INFO] 2024-04-24 05:34:50.924 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1311)
[WI-0][TI-1311] - [INFO] 2024-04-24 05:34:50.984 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1311, success=true)
[WI-0][TI-0] - [INFO] 2024-04-24 05:34:51.213 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
	No Files Detected - End Workflow
[WI-551][TI-1311] - [INFO] 2024-04-24 05:34:51.217 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_93/551/1311, processId:2314 ,exitStatusCode:0 ,processWaitForStatus:true ,processExitValue:0
[WI-551][TI-1311] - [INFO] 2024-04-24 05:34:51.220 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-551][TI-1311] - [INFO] 2024-04-24 05:34:51.220 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-551][TI-1311] - [INFO] 2024-04-24 05:34:51.220 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-551][TI-1311] - [INFO] 2024-04-24 05:34:51.221 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-551][TI-1311] - [INFO] 2024-04-24 05:34:51.231 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: SUCCESS to master : 172.18.1.1:1234
[WI-551][TI-1311] - [INFO] 2024-04-24 05:34:51.231 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-551][TI-1311] - [INFO] 2024-04-24 05:34:51.232 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_93/551/1311
[WI-551][TI-1311] - [INFO] 2024-04-24 05:34:51.233 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_93/551/1311
[WI-551][TI-1311] - [INFO] 2024-04-24 05:34:51.233 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-0] - [INFO] 2024-04-24 05:34:51.820 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7085714285714286 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-1311] - [INFO] 2024-04-24 05:34:51.883 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1311, success=true)
[WI-0][TI-0] - [INFO] 2024-04-24 05:34:57.845 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7464788732394366 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 05:34:59.942 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7486033519553073 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 05:35:06.078 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.813953488372093 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 05:35:09.122 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8075801749271136 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 05:35:14.200 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7554347826086957 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 05:35:15.217 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7130434782608696 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 05:35:16.222 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7392550143266475 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 05:35:18.239 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7469135802469136 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 05:35:19.296 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.819484240687679 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 05:35:20.298 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8563049853372434 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 05:35:21.301 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7754491017964071 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 05:35:30.346 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8606060606060606 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 05:35:31.362 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7267267267267267 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 05:35:34.457 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8176470588235294 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 05:35:39.490 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7151162790697675 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 05:35:40.566 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7211267605633802 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 05:35:42.047 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1312, taskName=search for intake JSON files, firstSubmitTime=1713908142034, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.10:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=93, appIds=null, processInstanceId=552, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"processing"}], executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":""}],"rawScript":"# find 1 raw file in the folder\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\n\n# check if raw_file_dir is empty, then set raw_file_dir to null\nif [ -z \"$raw_file_dir\" ]; then\n    raw_file_dir=null\nfi\n\necho \"#{setValue(raw_file_dir=${raw_file_dir})}\"","resourceList":[]}, environmentConfig=export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='search for intake JSON files'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240424'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1312'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13340113777664'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240424053542'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='processing'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='552'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240423'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=null, dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-552][TI-1312] - [INFO] 2024-04-24 05:35:42.050 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: search for intake JSON files to wait queue success
[WI-552][TI-1312] - [INFO] 2024-04-24 05:35:42.051 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-552][TI-1312] - [INFO] 2024-04-24 05:35:42.057 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-552][TI-1312] - [INFO] 2024-04-24 05:35:42.057 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-552][TI-1312] - [INFO] 2024-04-24 05:35:42.058 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-552][TI-1312] - [INFO] 2024-04-24 05:35:42.058 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713908142058
[WI-552][TI-1312] - [INFO] 2024-04-24 05:35:42.059 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 552_1312
[WI-552][TI-1312] - [INFO] 2024-04-24 05:35:42.060 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1312,
  "taskName" : "search for intake JSON files",
  "firstSubmitTime" : 1713908142034,
  "startTime" : 1713908142058,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.10:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240424/13201021801792/93/552/1312.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 93,
  "processInstanceId" : 552,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"processing\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[{\"prop\":\"raw_file_dir\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"\"}],\"rawScript\":\"# find 1 raw file in the folder\\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\\n\\n# check if raw_file_dir is empty, then set raw_file_dir to null\\nif [ -z \\\"$raw_file_dir\\\" ]; then\\n    raw_file_dir=null\\nfi\\n\\necho \\\"#{setValue(raw_file_dir=${raw_file_dir})}\\\"\",\"resourceList\":[]}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "search for intake JSON files"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240424"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1312"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13340113777664"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240424053542"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "processing"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "552"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "552_1312",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-552][TI-1312] - [INFO] 2024-04-24 05:35:42.061 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-552][TI-1312] - [INFO] 2024-04-24 05:35:42.061 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-552][TI-1312] - [INFO] 2024-04-24 05:35:42.061 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-552][TI-1312] - [INFO] 2024-04-24 05:35:42.066 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-552][TI-1312] - [INFO] 2024-04-24 05:35:42.082 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-552][TI-1312] - [INFO] 2024-04-24 05:35:42.085 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_93/552/1312 check successfully
[WI-552][TI-1312] - [INFO] 2024-04-24 05:35:42.086 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-552][TI-1312] - [INFO] 2024-04-24 05:35:42.086 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-552][TI-1312] - [INFO] 2024-04-24 05:35:42.087 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-552][TI-1312] - [INFO] 2024-04-24 05:35:42.087 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-552][TI-1312] - [INFO] 2024-04-24 05:35:42.088 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ {
    "prop" : "raw_file_dir",
    "direct" : "OUT",
    "type" : "VARCHAR",
    "value" : ""
  } ],
  "varPool" : null,
  "rawScript" : "# find 1 raw file in the folder\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\n\n# check if raw_file_dir is empty, then set raw_file_dir to null\nif [ -z \"$raw_file_dir\" ]; then\n    raw_file_dir=null\nfi\n\necho \"#{setValue(raw_file_dir=${raw_file_dir})}\"",
  "resourceList" : [ ]
}
[WI-552][TI-1312] - [INFO] 2024-04-24 05:35:42.088 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-552][TI-1312] - [INFO] 2024-04-24 05:35:42.088 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: null successfully
[WI-552][TI-1312] - [INFO] 2024-04-24 05:35:42.088 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-552][TI-1312] - [INFO] 2024-04-24 05:35:42.088 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-552][TI-1312] - [INFO] 2024-04-24 05:35:42.088 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-552][TI-1312] - [INFO] 2024-04-24 05:35:42.089 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-552][TI-1312] - [INFO] 2024-04-24 05:35:42.089 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-552][TI-1312] - [INFO] 2024-04-24 05:35:42.089 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export PYTHON_LAUNCHER=/bin/python3.11
# find 1 raw file in the folder
raw_file_dir=$(find /local_storage/reddit/processing -type f -name '*.json'| head -n 1)

# check if raw_file_dir is empty, then set raw_file_dir to null
if [ -z "$raw_file_dir" ]; then
    raw_file_dir=null
fi

echo "#{setValue(raw_file_dir=${raw_file_dir})}"
[WI-552][TI-1312] - [INFO] 2024-04-24 05:35:42.090 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-552][TI-1312] - [INFO] 2024-04-24 05:35:42.090 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_93/552/1312/552_1312.sh
[WI-552][TI-1312] - [INFO] 2024-04-24 05:35:42.100 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 2330
[WI-0][TI-1312] - [INFO] 2024-04-24 05:35:42.990 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1312, success=true)
[WI-0][TI-1312] - [INFO] 2024-04-24 05:35:43.003 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1312)
[WI-0][TI-0] - [INFO] 2024-04-24 05:35:43.100 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
	#{setValue(raw_file_dir=/local_storage/reddit/processing/500-20240423.json)}
[WI-552][TI-1312] - [INFO] 2024-04-24 05:35:43.102 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_93/552/1312, processId:2330 ,exitStatusCode:0 ,processWaitForStatus:true ,processExitValue:0
[WI-552][TI-1312] - [INFO] 2024-04-24 05:35:43.105 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-552][TI-1312] - [INFO] 2024-04-24 05:35:43.106 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-552][TI-1312] - [INFO] 2024-04-24 05:35:43.106 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-552][TI-1312] - [INFO] 2024-04-24 05:35:43.106 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-552][TI-1312] - [INFO] 2024-04-24 05:35:43.148 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: SUCCESS to master : 172.18.1.1:1234
[WI-552][TI-1312] - [INFO] 2024-04-24 05:35:43.148 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-552][TI-1312] - [INFO] 2024-04-24 05:35:43.148 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_93/552/1312
[WI-552][TI-1312] - [INFO] 2024-04-24 05:35:43.149 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_93/552/1312
[WI-552][TI-1312] - [INFO] 2024-04-24 05:35:43.149 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-0] - [INFO] 2024-04-24 05:35:43.599 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8155619596541788 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-1312] - [INFO] 2024-04-24 05:35:43.976 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1312, success=true)
[WI-0][TI-0] - [INFO] 2024-04-24 05:35:45.058 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1314, taskName=move to processing, firstSubmitTime=1713908145051, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.10:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=93, appIds=null, processInstanceId=552, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"processing"}], executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":""}],"rawScript":"# move file to the reddit processing folder\n# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error\nfilename=$(basename \"${raw_file_dir}\")\nif ! grep -q \"${REDDIT_HOME}/processing\" <<< \"${raw_file_dir}\"; then\n    mv ${raw_file_dir} ${REDDIT_HOME}/processing\nelse\n    echo JSON is already in processing\nfi\n\n# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing\necho \"#{setValue(raw_file_dir=${REDDIT_HOME}/processing/${filename})}\"","resourceList":[]}, environmentConfig=export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='move to processing'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240424'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1314'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13340390094208'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240424053545'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='processing'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='552'}, raw_file_dir=Property{prop='raw_file_dir', direct=IN, type=VARCHAR, value='/local_storage/reddit/processing/500-20240423.json'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240423'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-552][TI-1314] - [INFO] 2024-04-24 05:35:45.060 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: move to processing to wait queue success
[WI-552][TI-1314] - [INFO] 2024-04-24 05:35:45.060 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-552][TI-1314] - [INFO] 2024-04-24 05:35:45.062 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-552][TI-1314] - [INFO] 2024-04-24 05:35:45.062 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-552][TI-1314] - [INFO] 2024-04-24 05:35:45.062 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-552][TI-1314] - [INFO] 2024-04-24 05:35:45.062 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713908145062
[WI-552][TI-1314] - [INFO] 2024-04-24 05:35:45.071 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 552_1314
[WI-552][TI-1314] - [INFO] 2024-04-24 05:35:45.072 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1314,
  "taskName" : "move to processing",
  "firstSubmitTime" : 1713908145051,
  "startTime" : 1713908145062,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.10:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240424/13201021801792/93/552/1314.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 93,
  "processInstanceId" : 552,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"processing\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[{\"prop\":\"raw_file_dir\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"\"}],\"rawScript\":\"# move file to the reddit processing folder\\n# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error\\nfilename=$(basename \\\"${raw_file_dir}\\\")\\nif ! grep -q \\\"${REDDIT_HOME}/processing\\\" <<< \\\"${raw_file_dir}\\\"; then\\n    mv ${raw_file_dir} ${REDDIT_HOME}/processing\\nelse\\n    echo JSON is already in processing\\nfi\\n\\n# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing\\necho \\\"#{setValue(raw_file_dir=${REDDIT_HOME}/processing/${filename})}\\\"\",\"resourceList\":[]}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "move to processing"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240424"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1314"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13340390094208"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240424053545"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "processing"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "552"
    },
    "raw_file_dir" : {
      "prop" : "raw_file_dir",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit/processing/500-20240423.json"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "552_1314",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"raw_file_dir\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"/local_storage/reddit/processing/500-20240423.json\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-552][TI-1314] - [INFO] 2024-04-24 05:35:45.073 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-552][TI-1314] - [INFO] 2024-04-24 05:35:45.077 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-552][TI-1314] - [INFO] 2024-04-24 05:35:45.077 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-552][TI-1314] - [INFO] 2024-04-24 05:35:45.082 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-552][TI-1314] - [INFO] 2024-04-24 05:35:45.083 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-552][TI-1314] - [INFO] 2024-04-24 05:35:45.084 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_93/552/1314 check successfully
[WI-552][TI-1314] - [INFO] 2024-04-24 05:35:45.085 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-552][TI-1314] - [INFO] 2024-04-24 05:35:45.085 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-552][TI-1314] - [INFO] 2024-04-24 05:35:45.086 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-552][TI-1314] - [INFO] 2024-04-24 05:35:45.086 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-552][TI-1314] - [INFO] 2024-04-24 05:35:45.087 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ {
    "prop" : "raw_file_dir",
    "direct" : "OUT",
    "type" : "VARCHAR",
    "value" : ""
  } ],
  "varPool" : null,
  "rawScript" : "# move file to the reddit processing folder\n# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error\nfilename=$(basename \"${raw_file_dir}\")\nif ! grep -q \"${REDDIT_HOME}/processing\" <<< \"${raw_file_dir}\"; then\n    mv ${raw_file_dir} ${REDDIT_HOME}/processing\nelse\n    echo JSON is already in processing\nfi\n\n# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing\necho \"#{setValue(raw_file_dir=${REDDIT_HOME}/processing/${filename})}\"",
  "resourceList" : [ ]
}
[WI-552][TI-1314] - [INFO] 2024-04-24 05:35:45.087 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-552][TI-1314] - [INFO] 2024-04-24 05:35:45.088 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}] successfully
[WI-552][TI-1314] - [INFO] 2024-04-24 05:35:45.088 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-552][TI-1314] - [INFO] 2024-04-24 05:35:45.088 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-552][TI-1314] - [INFO] 2024-04-24 05:35:45.088 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-552][TI-1314] - [INFO] 2024-04-24 05:35:45.089 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-552][TI-1314] - [INFO] 2024-04-24 05:35:45.089 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-552][TI-1314] - [INFO] 2024-04-24 05:35:45.089 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export PYTHON_LAUNCHER=/bin/python3.11
# move file to the reddit processing folder
# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error
filename=$(basename "/local_storage/reddit/processing/500-20240423.json")
if ! grep -q "/local_storage/reddit/processing" <<< "/local_storage/reddit/processing/500-20240423.json"; then
    mv /local_storage/reddit/processing/500-20240423.json /local_storage/reddit/processing
else
    echo JSON is already in processing
fi

# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing
echo "#{setValue(raw_file_dir=/local_storage/reddit/processing/${filename})}"
[WI-552][TI-1314] - [INFO] 2024-04-24 05:35:45.090 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-552][TI-1314] - [INFO] 2024-04-24 05:35:45.090 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_93/552/1314/552_1314.sh
[WI-552][TI-1314] - [INFO] 2024-04-24 05:35:45.093 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 2343
[WI-0][TI-1314] - [INFO] 2024-04-24 05:35:45.989 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1314, success=true)
[WI-0][TI-1314] - [INFO] 2024-04-24 05:35:46.007 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1314)
[WI-0][TI-0] - [INFO] 2024-04-24 05:35:46.098 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
	JSON is already in processing
	#{setValue(raw_file_dir=/local_storage/reddit/processing/500-20240423.json)}
[WI-552][TI-1314] - [INFO] 2024-04-24 05:35:46.126 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_93/552/1314, processId:2343 ,exitStatusCode:0 ,processWaitForStatus:true ,processExitValue:0
[WI-552][TI-1314] - [INFO] 2024-04-24 05:35:46.127 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-552][TI-1314] - [INFO] 2024-04-24 05:35:46.127 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-552][TI-1314] - [INFO] 2024-04-24 05:35:46.127 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-552][TI-1314] - [INFO] 2024-04-24 05:35:46.128 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-552][TI-1314] - [INFO] 2024-04-24 05:35:46.133 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: SUCCESS to master : 172.18.1.1:1234
[WI-552][TI-1314] - [INFO] 2024-04-24 05:35:46.134 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-552][TI-1314] - [INFO] 2024-04-24 05:35:46.134 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_93/552/1314
[WI-552][TI-1314] - [INFO] 2024-04-24 05:35:46.135 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_93/552/1314
[WI-552][TI-1314] - [INFO] 2024-04-24 05:35:46.136 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-1314] - [INFO] 2024-04-24 05:35:46.992 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1314, success=true)
[WI-0][TI-0] - [INFO] 2024-04-24 05:35:47.094 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1315, taskName=spark preprocessing, firstSubmitTime=1713908147088, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.10:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=93, appIds=null, processInstanceId=552, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"processing"}], executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[],"rawScript":"$SPARK_HOME/bin/spark-submit \\\n    --master spark://spark-master:7077 \\\n    --deploy-mode client \\\n    --conf spark.driver.cores=1 \\\n    --conf spark.driver.memory=1G \\\n    --conf spark.executor.instances=1 \\\n    --conf spark.executor.cores=1 \\\n    --conf spark.executor.memory=1G \\\n    --name reddit_preprocessing \\\n    --py-files testing.py\n\n# $SPARK_HOME/bin/spark-submit \\\n#     --master local \\\n#     --files ${raw_file_dir} \\\n#     --name reddit_preprocessing spark_reddit_preprocessing.py\n","resourceList":[{"id":null,"resourceName":"file:/dolphinscheduler/default/resources/testing.py","res":null}]}, environmentConfig=export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export PYSPARK_DRIVER_PYTHON=/bin/python3.11
export PYTHON_LAUNCHER=/bin/python3.11
export PYSPARK_PYTHON=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='spark preprocessing'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240424'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1315'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13210058002752'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240424053547'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='processing'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='552'}, raw_file_dir=Property{prop='raw_file_dir', direct=IN, type=VARCHAR, value='/local_storage/reddit/processing/500-20240423.json'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240423'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-552][TI-1315] - [INFO] 2024-04-24 05:35:47.096 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: spark preprocessing to wait queue success
[WI-552][TI-1315] - [INFO] 2024-04-24 05:35:47.096 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-552][TI-1315] - [INFO] 2024-04-24 05:35:47.098 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-552][TI-1315] - [INFO] 2024-04-24 05:35:47.098 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-552][TI-1315] - [INFO] 2024-04-24 05:35:47.098 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-552][TI-1315] - [INFO] 2024-04-24 05:35:47.098 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713908147098
[WI-552][TI-1315] - [INFO] 2024-04-24 05:35:47.098 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 552_1315
[WI-552][TI-1315] - [INFO] 2024-04-24 05:35:47.098 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1315,
  "taskName" : "spark preprocessing",
  "firstSubmitTime" : 1713908147088,
  "startTime" : 1713908147098,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.10:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240424/13201021801792/93/552/1315.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 93,
  "processInstanceId" : 552,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"processing\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[],\"rawScript\":\"$SPARK_HOME/bin/spark-submit \\\\\\n    --master spark://spark-master:7077 \\\\\\n    --deploy-mode client \\\\\\n    --conf spark.driver.cores=1 \\\\\\n    --conf spark.driver.memory=1G \\\\\\n    --conf spark.executor.instances=1 \\\\\\n    --conf spark.executor.cores=1 \\\\\\n    --conf spark.executor.memory=1G \\\\\\n    --name reddit_preprocessing \\\\\\n    --py-files testing.py\\n\\n# $SPARK_HOME/bin/spark-submit \\\\\\n#     --master local \\\\\\n#     --files ${raw_file_dir} \\\\\\n#     --name reddit_preprocessing spark_reddit_preprocessing.py\\n\",\"resourceList\":[{\"id\":null,\"resourceName\":\"file:/dolphinscheduler/default/resources/testing.py\",\"res\":null}]}",
  "environmentConfig" : "export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3\nexport JAVA_HOME=/opt/java/openjdk\nexport PYSPARK_DRIVER_PYTHON=/bin/python3.11\nexport PYTHON_LAUNCHER=/bin/python3.11\nexport PYSPARK_PYTHON=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "spark preprocessing"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240424"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1315"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13210058002752"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240424053547"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "processing"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "552"
    },
    "raw_file_dir" : {
      "prop" : "raw_file_dir",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit/processing/500-20240423.json"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "552_1315",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"raw_file_dir\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"/local_storage/reddit/processing/500-20240423.json\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-552][TI-1315] - [INFO] 2024-04-24 05:35:47.099 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-552][TI-1315] - [INFO] 2024-04-24 05:35:47.099 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-552][TI-1315] - [INFO] 2024-04-24 05:35:47.099 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-552][TI-1315] - [INFO] 2024-04-24 05:35:47.102 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-552][TI-1315] - [INFO] 2024-04-24 05:35:47.102 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-552][TI-1315] - [INFO] 2024-04-24 05:35:47.103 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_93/552/1315 check successfully
[WI-552][TI-1315] - [INFO] 2024-04-24 05:35:47.103 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-552][TI-1315] - [INFO] 2024-04-24 05:35:47.106 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={file:/dolphinscheduler/default/resources/testing.py=ResourceContext.ResourceItem(resourceAbsolutePathInStorage=file:/dolphinscheduler/default/resources/testing.py, resourceRelativePath=testing.py, resourceAbsolutePathInLocal=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_93/552/1315/testing.py)})
[WI-552][TI-1315] - [INFO] 2024-04-24 05:35:47.107 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-552][TI-1315] - [INFO] 2024-04-24 05:35:47.107 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-552][TI-1315] - [INFO] 2024-04-24 05:35:47.107 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ ],
  "varPool" : null,
  "rawScript" : "$SPARK_HOME/bin/spark-submit \\\n    --master spark://spark-master:7077 \\\n    --deploy-mode client \\\n    --conf spark.driver.cores=1 \\\n    --conf spark.driver.memory=1G \\\n    --conf spark.executor.instances=1 \\\n    --conf spark.executor.cores=1 \\\n    --conf spark.executor.memory=1G \\\n    --name reddit_preprocessing \\\n    --py-files testing.py\n\n# $SPARK_HOME/bin/spark-submit \\\n#     --master local \\\n#     --files ${raw_file_dir} \\\n#     --name reddit_preprocessing spark_reddit_preprocessing.py\n",
  "resourceList" : [ {
    "id" : null,
    "resourceName" : "file:/dolphinscheduler/default/resources/testing.py",
    "res" : null
  } ]
}
[WI-552][TI-1315] - [INFO] 2024-04-24 05:35:47.107 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-552][TI-1315] - [INFO] 2024-04-24 05:35:47.107 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}] successfully
[WI-552][TI-1315] - [INFO] 2024-04-24 05:35:47.107 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-552][TI-1315] - [INFO] 2024-04-24 05:35:47.107 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-552][TI-1315] - [INFO] 2024-04-24 05:35:47.107 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-552][TI-1315] - [INFO] 2024-04-24 05:35:47.108 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-552][TI-1315] - [INFO] 2024-04-24 05:35:47.108 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-552][TI-1315] - [INFO] 2024-04-24 05:35:47.108 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export PYSPARK_DRIVER_PYTHON=/bin/python3.11
export PYTHON_LAUNCHER=/bin/python3.11
export PYSPARK_PYTHON=/bin/python3.11
$SPARK_HOME/bin/spark-submit \
    --master spark://spark-master:7077 \
    --deploy-mode client \
    --conf spark.driver.cores=1 \
    --conf spark.driver.memory=1G \
    --conf spark.executor.instances=1 \
    --conf spark.executor.cores=1 \
    --conf spark.executor.memory=1G \
    --name reddit_preprocessing \
    --py-files testing.py

# $SPARK_HOME/bin/spark-submit \
#     --master local \
#     --files /local_storage/reddit/processing/500-20240423.json \
#     --name reddit_preprocessing spark_reddit_preprocessing.py

[WI-552][TI-1315] - [INFO] 2024-04-24 05:35:47.108 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-552][TI-1315] - [INFO] 2024-04-24 05:35:47.108 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_93/552/1315/552_1315.sh
[WI-552][TI-1315] - [INFO] 2024-04-24 05:35:47.111 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 2355
[WI-0][TI-1315] - [INFO] 2024-04-24 05:35:47.990 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1315, success=true)
[WI-0][TI-1315] - [INFO] 2024-04-24 05:35:47.997 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1315)
[WI-0][TI-0] - [INFO] 2024-04-24 05:35:48.123 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
	Error: Missing application resource.
	
[WI-0][TI-0] - [INFO] 2024-04-24 05:35:49.131 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	Usage: spark-submit [options] <app jar | python file | R file> [app arguments]
	Usage: spark-submit --kill [submission ID] --master [spark://...]
	Usage: spark-submit --status [submission ID] --master [spark://...]
	Usage: spark-submit run-example [options] example-class [example args]
	
	Options:
	  --master MASTER_URL         spark://host:port, mesos://host:port, yarn,
	                              k8s://https://host:port, or local (Default: local[*]).
	  --deploy-mode DEPLOY_MODE   Whether to launch the driver program locally ("client") or
	                              on one of the worker machines inside the cluster ("cluster")
	                              (Default: client).
	  --class CLASS_NAME          Your application's main class (for Java / Scala apps).
	  --name NAME                 A name of your application.
	  --jars JARS                 Comma-separated list of jars to include on the driver
	                              and executor classpaths.
	  --packages                  Comma-separated list of maven coordinates of jars to include
	                              on the driver and executor classpaths. Will search the local
	                              maven repo, then maven central and any additional remote
	                              repositories given by --repositories. The format for the
	                              coordinates should be groupId:artifactId:version.
	  --exclude-packages          Comma-separated list of groupId:artifactId, to exclude while
	                              resolving the dependencies provided in --packages to avoid
	                              dependency conflicts.
	  --repositories              Comma-separated list of additional remote repositories to
	                              search for the maven coordinates given with --packages.
	  --py-files PY_FILES         Comma-separated list of .zip, .egg, or .py files to place
	                              on the PYTHONPATH for Python apps.
	  --files FILES               Comma-separated list of files to be placed in the working
	                              directory of each executor. File paths of these files
	                              in executors can be accessed via SparkFiles.get(fileName).
	  --archives ARCHIVES         Comma-separated list of archives to be extracted into the
	                              working directory of each executor.
	
	  --conf, -c PROP=VALUE       Arbitrary Spark configuration property.
	  --properties-file FILE      Path to a file from which to load extra properties. If not
	                              specified, this will look for conf/spark-defaults.conf.
	
	  --driver-memory MEM         Memory for driver (e.g. 1000M, 2G) (Default: 1024M).
	  --driver-java-options       Extra Java options to pass to the driver.
	  --driver-library-path       Extra library path entries to pass to the driver.
	  --driver-class-path         Extra class path entries to pass to the driver. Note that
	                              jars added with --jars are automatically included in the
	                              classpath.
	
	  --executor-memory MEM       Memory per executor (e.g. 1000M, 2G) (Default: 1G).
	
	  --proxy-user NAME           User to impersonate when submitting the application.
	                              This argument does not work with --principal / --keytab.
	
	  --help, -h                  Show this help message and exit.
	  --verbose, -v               Print additional debug output.
	  --version,                  Print the version of current Spark.
	
	 Spark Connect only:
	   --remote CONNECT_URL       URL to connect to the server for Spark Connect, e.g.,
	                              sc://host:port. --master and --deploy-mode cannot be set
	                              together with this option. This option is experimental, and
	                              might change between minor releases.
	
	 Cluster deploy mode only:
	  --driver-cores NUM          Number of cores used by the driver, only in cluster mode
	                              (Default: 1).
	
	 Spark standalone or Mesos with cluster deploy mode only:
	  --supervise                 If given, restarts the driver on failure.
	
	 Spark standalone, Mesos or K8s with cluster deploy mode only:
	  --kill SUBMISSION_ID        If given, kills the driver specified.
	  --status SUBMISSION_ID      If given, requests the status of the driver specified.
	
	 Spark standalone and Mesos only:
	  --total-executor-cores NUM  Total cores for all executors.
	
	 Spark standalone, YARN and Kubernetes only:
	  --executor-cores NUM        Number of cores used by each executor. (Default: 1 in
	                              YARN and K8S modes, or all available cores on the worker
	                              in standalone mode).
	
	 Spark on YARN and Kubernetes only:
	  --num-executors NUM         Number of executors to launch (Default: 2).
	                              If dynamic allocation is enabled, the initial number of
	                              executors will be at least NUM.
	  --principal PRINCIPAL       Principal to be used to login to KDC.
	  --keytab KEYTAB             The full path to the file that contains the keytab for the
	                              principal specified above.
	
	 Spark on YARN only:
	  --queue QUEUE_NAME          The YARN queue to submit to (Default: "default").
	      
[WI-552][TI-1315] - [INFO] 2024-04-24 05:35:49.134 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_93/552/1315, processId:2355 ,exitStatusCode:1 ,processWaitForStatus:true ,processExitValue:1
[WI-552][TI-1315] - [INFO] 2024-04-24 05:35:49.135 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-552][TI-1315] - [INFO] 2024-04-24 05:35:49.137 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-552][TI-1315] - [INFO] 2024-04-24 05:35:49.138 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-552][TI-1315] - [INFO] 2024-04-24 05:35:49.140 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-552][TI-1315] - [INFO] 2024-04-24 05:35:49.145 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: FAILURE to master : 172.18.1.1:1234
[WI-552][TI-1315] - [INFO] 2024-04-24 05:35:49.154 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-552][TI-1315] - [INFO] 2024-04-24 05:35:49.165 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_93/552/1315
[WI-552][TI-1315] - [INFO] 2024-04-24 05:35:49.174 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_93/552/1315
[WI-552][TI-1315] - [INFO] 2024-04-24 05:35:49.182 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-1315] - [INFO] 2024-04-24 05:35:49.985 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1315, success=true)
[WI-0][TI-0] - [INFO] 2024-04-24 05:35:54.993 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 05:35:54 ERROR StandaloneSchedulerBackend: Application has been killed. Reason: Master removed our application: KILLED
	24/04/24 05:35:54 INFO SparkContext: SparkContext is stopping with exitCode 0.
	24/04/24 05:35:54 INFO TaskSchedulerImpl: Cancelling stage 0
	24/04/24 05:35:54 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage cancelled: Job aborted due to stage failure: Master removed our application: KILLED
	24/04/24 05:35:54 INFO TaskSchedulerImpl: Stage 0 was cancelled
	24/04/24 05:35:54 INFO DAGScheduler: ResultStage 0 (showString at NativeMethodAccessorImpl.java:0) failed in 557.068 s due to Job aborted due to stage failure: Master removed our application: KILLED
	24/04/24 05:35:54 INFO SparkUI: Stopped Spark web UI at http://5afbfd5249fc:4041
	24/04/24 05:35:54 INFO DAGScheduler: Job 0 failed: showString at NativeMethodAccessorImpl.java:0, took 557.198384 s
	24/04/24 05:35:54 INFO StandaloneSchedulerBackend: Shutting down all executors
	24/04/24 05:35:54 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Asking each executor to shut down
	24/04/24 05:35:54 ERROR Inbox: Ignoring error
	java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@49588ce7 rejected from java.util.concurrent.ScheduledThreadPoolExecutor@35682e10[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0]
		at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2063)
		at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:830)
		at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)
		at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
		at org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend$StandaloneDriverEndpoint.$anonfun$onDisconnected$1(StandaloneSchedulerBackend.scala:346)
		at scala.Option.foreach(Option.scala:407)
		at org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend$StandaloneDriverEndpoint.onDisconnected(StandaloneSchedulerBackend.scala:313)
		at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:141)
		at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
		at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
		at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
		at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
		at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
		at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
		at java.lang.Thread.run(Thread.java:750)
	24/04/24 05:35:54 ERROR Utils: Uncaught exception in thread stop-spark-context
	org.apache.spark.SparkException: Exception thrown in awaitResult: 
		at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
		at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
		at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
		at org.apache.spark.deploy.client.StandaloneAppClient.stop(StandaloneAppClient.scala:288)
		at org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend.org$apache$spark$scheduler$cluster$StandaloneSchedulerBackend$$stop(StandaloneSchedulerBackend.scala:275)
		at org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend.stop(StandaloneSchedulerBackend.scala:142)
		at org.apache.spark.scheduler.SchedulerBackend.stop(SchedulerBackend.scala:33)
		at org.apache.spark.scheduler.SchedulerBackend.stop$(SchedulerBackend.scala:33)
		at org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend.stop(CoarseGrainedSchedulerBackend.scala:54)
		at org.apache.spark.scheduler.TaskSchedulerImpl.$anonfun$stop$2(TaskSchedulerImpl.scala:992)
		at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1375)
		at org.apache.spark.scheduler.TaskSchedulerImpl.stop(TaskSchedulerImpl.scala:992)
		at org.apache.spark.scheduler.DAGScheduler.$anonfun$stop$4(DAGScheduler.scala:2976)
		at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1375)
		at org.apache.spark.scheduler.DAGScheduler.stop(DAGScheduler.scala:2976)
		at org.apache.spark.SparkContext.$anonfun$stop$12(SparkContext.scala:2263)
		at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1375)
		at org.apache.spark.SparkContext.stop(SparkContext.scala:2263)
		at org.apache.spark.SparkContext.stop(SparkContext.scala:2216)
		at org.apache.spark.SparkContext$$anon$3.run(SparkContext.scala:2203)
	Caused by: org.apache.spark.SparkException: Could not find AppClient.
		at org.apache.spark.rpc.netty.Dispatcher.postMessage(Dispatcher.scala:178)
		at org.apache.spark.rpc.netty.Dispatcher.postLocalMessage(Dispatcher.scala:144)
		at org.apache.spark.rpc.netty.NettyRpcEnv.askAbortable(NettyRpcEnv.scala:242)
		at org.apache.spark.rpc.netty.NettyRpcEndpointRef.askAbortable(NettyRpcEnv.scala:554)
		at org.apache.spark.rpc.netty.NettyRpcEndpointRef.ask(NettyRpcEnv.scala:558)
		at org.apache.spark.rpc.RpcEndpointRef.ask(RpcEndpointRef.scala:72)
		... 17 more
	24/04/24 05:35:54 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
	24/04/24 05:35:54 INFO MemoryStore: MemoryStore cleared
	24/04/24 05:35:54 INFO BlockManager: BlockManager stopped
	24/04/24 05:35:54 INFO BlockManagerMaster: BlockManagerMaster stopped
	24/04/24 05:35:54 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
	24/04/24 05:35:54 INFO SparkContext: Successfully stopped SparkContext
[WI-0][TI-0] - [INFO] 2024-04-24 05:35:55.677 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8802395209580838 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 05:35:55.997 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	Traceback (most recent call last):
	  File "/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_92/550/1308/testing.py", line 29, in <module>
	    df.show()
	  File "/opt/spark-3.5.1-bin-hadoop3/python/lib/pyspark.zip/pyspark/sql/dataframe.py", line 945, in show
	  File "/opt/spark-3.5.1-bin-hadoop3/python/lib/pyspark.zip/pyspark/sql/dataframe.py", line 963, in _show_string
	  File "/opt/spark-3.5.1-bin-hadoop3/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
	  File "/opt/spark-3.5.1-bin-hadoop3/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 179, in deco
	  File "/opt/spark-3.5.1-bin-hadoop3/python/lib/py4j-0.10.9.7-src.zip/py4j/protocol.py", line 326, in get_return_value
	py4j.protocol.Py4JJavaError: An error occurred while calling o42.showString.
	: org.apache.spark.SparkException: Job aborted due to stage failure: Master removed our application: KILLED
		at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)
		at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)
		at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)
		at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
		at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
		at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
		at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)
		at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)
		at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)
		at scala.Option.foreach(Option.scala:407)
		at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)
		at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)
		at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)
		at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)
		at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
		at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:989)
		at org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)
		at org.apache.spark.SparkContext.runJob(SparkContext.scala:2419)
		at org.apache.spark.SparkContext.runJob(SparkContext.scala:2438)
		at org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:530)
		at org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:483)
		at org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:61)
		at org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:4332)
		at org.apache.spark.sql.Dataset.$anonfun$head$1(Dataset.scala:3314)
		at org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:4322)
		at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
		at org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:4320)
		at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)
		at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)
		at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)
		at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
		at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)
		at org.apache.spark.sql.Dataset.withAction(Dataset.scala:4320)
		at org.apache.spark.sql.Dataset.head(Dataset.scala:3314)
		at org.apache.spark.sql.Dataset.take(Dataset.scala:3537)
		at org.apache.spark.sql.Dataset.getRows(Dataset.scala:280)
		at org.apache.spark.sql.Dataset.showString(Dataset.scala:315)
		at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
		at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
		at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
		at java.lang.reflect.Method.invoke(Method.java:498)
		at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
		at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
		at py4j.Gateway.invoke(Gateway.java:282)
		at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
		at py4j.commands.CallCommand.execute(CallCommand.java:79)
		at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
		at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
		at java.lang.Thread.run(Thread.java:750)
	
	24/04/24 05:35:55 INFO ShutdownHookManager: Shutdown hook called
	24/04/24 05:35:55 INFO ShutdownHookManager: Deleting directory /tmp/spark-4b55944a-3ba9-4b72-baaa-f58ae47c0f03
	24/04/24 05:35:55 INFO ShutdownHookManager: Deleting directory /tmp/spark-c525cd9b-df30-4b84-aad0-cf0a6c0ded07
	24/04/24 05:35:55 INFO ShutdownHookManager: Deleting directory /tmp/spark-c525cd9b-df30-4b84-aad0-cf0a6c0ded07/pyspark-868b98af-5570-4c6d-a4eb-3fd3a48995b5
[WI-550][TI-1308] - [INFO] 2024-04-24 05:35:56.001 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_92/550/1308, processId:2067 ,exitStatusCode:1 ,processWaitForStatus:true ,processExitValue:1
[WI-550][TI-1308] - [INFO] 2024-04-24 05:35:56.002 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-550][TI-1308] - [INFO] 2024-04-24 05:35:56.002 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-550][TI-1308] - [INFO] 2024-04-24 05:35:56.002 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-550][TI-1308] - [INFO] 2024-04-24 05:35:56.003 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-550][TI-1308] - [INFO] 2024-04-24 05:35:56.006 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: FAILURE to master : 172.18.1.1:1234
[WI-550][TI-1308] - [INFO] 2024-04-24 05:35:56.006 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-550][TI-1308] - [INFO] 2024-04-24 05:35:56.007 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_92/550/1308
[WI-550][TI-1308] - [INFO] 2024-04-24 05:35:56.007 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_92/550/1308
[WI-550][TI-1308] - [INFO] 2024-04-24 05:35:56.010 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-1308] - [INFO] 2024-04-24 05:35:56.073 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1308, processInstanceId=550, status=6, startTime=1713907585659, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, logPath=/opt/dolphinscheduler/logs/20240424/13201021801792/92/550/1308.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_92/550/1308, endTime=1713908156002, processId=2067, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1308] - [INFO] 2024-04-24 05:35:56.078 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1308, processInstanceId=550, status=6, startTime=1713907585659, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, logPath=/opt/dolphinscheduler/logs/20240424/13201021801792/92/550/1308.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_92/550/1308, endTime=1713908156002, processId=2067, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], eventCreateTime=0, eventSendTime=1713908156073)
[WI-0][TI-1308] - [INFO] 2024-04-24 05:35:56.994 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1308, success=true)
[WI-0][TI-1308] - [INFO] 2024-04-24 05:35:57.049 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1308, success=true)
[WI-0][TI-0] - [INFO] 2024-04-24 05:35:57.702 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7976878612716762 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 05:36:01.738 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8073654390934845 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 05:36:02.772 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7677053824362606 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 05:36:03.778 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7219101123595505 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 05:36:04.783 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7331460674157303 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 05:36:05.786 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7285714285714285 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 05:36:06.791 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7815126050420168 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 05:36:10.813 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8776119402985075 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 05:37:43.943 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8611898016997168 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 05:37:44.976 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7206703910614525 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-1292] - [INFO] 2024-04-24 05:38:44.021 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1292, processInstanceId=546, status=9, startTime=1713904461692, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, logPath=/opt/dolphinscheduler/logs/20240424/13201021801792/90/546/1292.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/546/1292, endTime=1713905019537, processId=841, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], eventCreateTime=0, eventSendTime=1713908023775)
[WI-0][TI-1292] - [INFO] 2024-04-24 05:38:44.024 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1292, processInstanceId=546, status=9, startTime=1713904461692, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, logPath=/opt/dolphinscheduler/logs/20240424/13201021801792/90/546/1292.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/546/1292, endTime=1713905019537, processId=841, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], eventCreateTime=0, eventSendTime=1713908324021)
[WI-0][TI-1281] - [INFO] 2024-04-24 05:39:14.054 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1281, processInstanceId=543, status=9, startTime=1713903509183, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, logPath=/opt/dolphinscheduler/logs/20240424/13201021801792/90/543/1281.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/543/1281, endTime=1713904084494, processId=300, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], eventCreateTime=0, eventSendTime=1713908053809)
[WI-0][TI-1281] - [INFO] 2024-04-24 05:39:14.058 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1281, processInstanceId=543, status=9, startTime=1713903509183, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, logPath=/opt/dolphinscheduler/logs/20240424/13201021801792/90/543/1281.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/543/1281, endTime=1713904084494, processId=300, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], eventCreateTime=0, eventSendTime=1713908354054)
[WI-0][TI-1292] - [INFO] 2024-04-24 05:43:44.591 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1292, processInstanceId=546, status=9, startTime=1713904461692, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, logPath=/opt/dolphinscheduler/logs/20240424/13201021801792/90/546/1292.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/546/1292, endTime=1713905019537, processId=841, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], eventCreateTime=0, eventSendTime=1713908324021)
[WI-0][TI-1292] - [INFO] 2024-04-24 05:43:44.594 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1292, processInstanceId=546, status=9, startTime=1713904461692, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, logPath=/opt/dolphinscheduler/logs/20240424/13201021801792/90/546/1292.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/546/1292, endTime=1713905019537, processId=841, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], eventCreateTime=0, eventSendTime=1713908624591)
[WI-0][TI-1281] - [INFO] 2024-04-24 05:44:14.626 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1281, processInstanceId=543, status=9, startTime=1713903509183, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, logPath=/opt/dolphinscheduler/logs/20240424/13201021801792/90/543/1281.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/543/1281, endTime=1713904084494, processId=300, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], eventCreateTime=0, eventSendTime=1713908354054)
[WI-0][TI-1281] - [INFO] 2024-04-24 05:44:14.630 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1281, processInstanceId=543, status=9, startTime=1713903509183, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, logPath=/opt/dolphinscheduler/logs/20240424/13201021801792/90/543/1281.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/543/1281, endTime=1713904084494, processId=300, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], eventCreateTime=0, eventSendTime=1713908654626)
[WI-0][TI-1292] - [INFO] 2024-04-24 05:48:45.163 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1292, processInstanceId=546, status=9, startTime=1713904461692, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, logPath=/opt/dolphinscheduler/logs/20240424/13201021801792/90/546/1292.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/546/1292, endTime=1713905019537, processId=841, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], eventCreateTime=0, eventSendTime=1713908624591)
[WI-0][TI-1292] - [INFO] 2024-04-24 05:48:45.172 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1292, processInstanceId=546, status=9, startTime=1713904461692, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, logPath=/opt/dolphinscheduler/logs/20240424/13201021801792/90/546/1292.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/546/1292, endTime=1713905019537, processId=841, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], eventCreateTime=0, eventSendTime=1713908925163)
[WI-0][TI-1281] - [INFO] 2024-04-24 05:49:15.199 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1281, processInstanceId=543, status=9, startTime=1713903509183, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, logPath=/opt/dolphinscheduler/logs/20240424/13201021801792/90/543/1281.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/543/1281, endTime=1713904084494, processId=300, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], eventCreateTime=0, eventSendTime=1713908654626)
[WI-0][TI-1281] - [INFO] 2024-04-24 05:49:15.202 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1281, processInstanceId=543, status=9, startTime=1713903509183, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, logPath=/opt/dolphinscheduler/logs/20240424/13201021801792/90/543/1281.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/543/1281, endTime=1713904084494, processId=300, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], eventCreateTime=0, eventSendTime=1713908955199)
[WI-0][TI-0] - [WARN] 2024-04-24 05:53:48.534 +0800 o.s.c.k.c.p.AbstractKubernetesProfileEnvironmentPostProcessor:[258] - Not running inside kubernetes. Skipping 'kubernetes' profile activation.
[WI-0][TI-0] - [WARN] 2024-04-24 05:53:51.755 +0800 o.s.c.k.c.p.AbstractKubernetesProfileEnvironmentPostProcessor:[258] - Not running inside kubernetes. Skipping 'kubernetes' profile activation.
[WI-0][TI-0] - [INFO] 2024-04-24 05:53:51.994 +0800 o.a.d.s.w.WorkerServer:[634] - No active profile set, falling back to 1 default profile: "default"
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:02.246 +0800 o.s.c.c.s.GenericScope:[283] - BeanFactory id=7e7bf7c6-2cb3-34d2-a0d5-a56161c67d0e
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:04.101 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'org.springframework.cloud.commons.config.CommonsConfigAutoConfiguration' of type [org.springframework.cloud.commons.config.CommonsConfigAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:04.111 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'org.springframework.cloud.client.loadbalancer.LoadBalancerDefaultMappingsProviderAutoConfiguration' of type [org.springframework.cloud.client.loadbalancer.LoadBalancerDefaultMappingsProviderAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:04.119 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'loadBalancerClientsDefaultsMappingsProvider' of type [org.springframework.cloud.client.loadbalancer.LoadBalancerDefaultMappingsProviderAutoConfiguration$$Lambda$392/732611751] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:04.215 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'defaultsBindHandlerAdvisor' of type [org.springframework.cloud.commons.config.DefaultsBindHandlerAdvisor] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:04.337 +0800 o.a.d.c.u.NetUtils:[312] - Get all NetworkInterfaces: [name:eth0 (eth0), name:lo (lo)]
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:04.493 +0800 o.a.d.s.w.c.WorkerConfig:[98] - 
****************************Worker Configuration**************************************
  listen-port -> 1234
  exec-threads -> 100
  max-heartbeat-interval -> PT10S
  host-weight -> 100
  tenantConfig -> TenantConfig(autoCreateTenantEnabled=true, distributedTenantEnabled=false, defaultTenantEnabled=false)
  server-load-protection -> WorkerServerLoadProtection(enabled=true, maxCpuUsagePercentageThresholds=0.7, maxJVMMemoryUsagePercentageThresholds=0.7, maxSystemMemoryUsagePercentageThresholds=0.7, maxDiskUsagePercentageThresholds=0.7)
  registry-disconnect-strategy -> ConnectStrategyProperties(strategy=WAITING, maxWaitingTime=PT1M40S)
  task-execute-threads-full-policy: REJECT
  address -> 172.18.1.1:1234
  registry-path: /nodes/worker/172.18.1.1:1234
****************************Worker Configuration**************************************
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:04.500 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'workerConfig' of type [org.apache.dolphinscheduler.server.worker.config.WorkerConfig$$EnhancerBySpringCGLIB$$f317e50e] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:05.168 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'io.kubernetes.client.spring.extended.manifests.config.KubernetesManifestsAutoConfiguration' of type [io.kubernetes.client.spring.extended.manifests.config.KubernetesManifestsAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:05.246 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'kubernetes.manifests-io.kubernetes.client.spring.extended.manifests.config.KubernetesManifestsProperties' of type [io.kubernetes.client.spring.extended.manifests.config.KubernetesManifestsProperties] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:05.277 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'io.kubernetes.client.spring.extended.controller.config.KubernetesInformerAutoConfiguration' of type [io.kubernetes.client.spring.extended.controller.config.KubernetesInformerAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:05.342 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'defaultApiClient' of type [io.kubernetes.client.openapi.ApiClient] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:06.379 +0800 o.e.j.u.log:[170] - Logging initialized @26285ms to org.eclipse.jetty.util.log.Slf4jLog
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:07.503 +0800 o.s.b.w.e.j.JettyServletWebServerFactory:[166] - Server initialized with port: 1235
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:07.511 +0800 o.e.j.s.Server:[375] - jetty-9.4.48.v20220622; built: 2022-06-21T20:42:25.880Z; git: 6b67c5719d1f4371b33655ff2d047d24e171e49a; jvm 1.8.0_402-b06
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:08.058 +0800 o.e.j.s.h.C.application:[2368] - Initializing Spring embedded WebApplicationContext
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:08.078 +0800 o.s.b.w.s.c.ServletWebServerApplicationContext:[292] - Root WebApplicationContext: initialization completed in 15995 ms
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:10.538 +0800 o.e.j.s.session:[334] - DefaultSessionIdManager workerName=node0
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:10.539 +0800 o.e.j.s.session:[339] - No SessionScavenger set, using defaults
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:10.541 +0800 o.e.j.s.session:[132] - node0 Scavenging every 660000ms
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:10.639 +0800 o.e.j.s.h.ContextHandler:[921] - Started o.s.b.w.e.j.JettyEmbeddedWebAppContext@6df2af02{application,/,[file:///tmp/jetty-docbase.1235.1220077423152983462/],AVAILABLE}
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:10.643 +0800 o.e.j.s.Server:[415] - Started @30547ms
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:11.462 +0800 o.a.c.f.i.CuratorFrameworkImpl:[338] - Starting
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:11.669 +0800 o.a.z.ZooKeeper:[98] - Client environment:zookeeper.version=3.8.0-5a02a05eddb59aee6ac762f7ea82e92a68eb9c0f, built on 2022-02-25 08:49 UTC
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:11.670 +0800 o.a.z.ZooKeeper:[98] - Client environment:host.name=39d46fe27506
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:11.670 +0800 o.a.z.ZooKeeper:[98] - Client environment:java.version=1.8.0_402
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:11.671 +0800 o.a.z.ZooKeeper:[98] - Client environment:java.vendor=Temurin
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:11.671 +0800 o.a.z.ZooKeeper:[98] - Client environment:java.home=/opt/java/openjdk
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:11.671 +0800 o.a.z.ZooKeeper:[98] - Client environment:java.class.path=/opt/dolphinscheduler/conf:/opt/dolphinscheduler/libs/kerb-client-1.0.1.jar:/opt/dolphinscheduler/libs/spring-cloud-starter-kubernetes-client-config-2.1.3.jar:/opt/dolphinscheduler/libs/oauth2-oidc-sdk-9.35.jar:/opt/dolphinscheduler/libs/jsqlparser-4.4.jar:/opt/dolphinscheduler/libs/reactive-streams-1.0.4.jar:/opt/dolphinscheduler/libs/kubernetes-model-extensions-5.10.2.jar:/opt/dolphinscheduler/libs/zookeeper-3.8.0.jar:/opt/dolphinscheduler/libs/kubernetes-model-apps-5.10.2.jar:/opt/dolphinscheduler/libs/grpc-api-1.41.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-pigeon-3.2.1.jar:/opt/dolphinscheduler/libs/client-java-api-13.0.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-obs-3.2.1.jar:/opt/dolphinscheduler/libs/spring-web-5.3.22.jar:/opt/dolphinscheduler/libs/aws-java-sdk-emr-1.12.300.jar:/opt/dolphinscheduler/libs/spring-context-5.3.22.jar:/opt/dolphinscheduler/libs/gapic-google-cloud-storage-v2-2.18.0-alpha.jar:/opt/dolphinscheduler/libs/spring-cloud-kubernetes-client-config-2.1.3.jar:/opt/dolphinscheduler/libs/jetty-io-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/annotations-13.0.jar:/opt/dolphinscheduler/libs/jpam-1.1.jar:/opt/dolphinscheduler/libs/joda-time-2.10.13.jar:/opt/dolphinscheduler/libs/spring-cloud-kubernetes-client-autoconfig-2.1.3.jar:/opt/dolphinscheduler/libs/kerb-identity-1.0.1.jar:/opt/dolphinscheduler/libs/vertica-jdbc-12.0.4-0.jar:/opt/dolphinscheduler/libs/grpc-googleapis-1.52.1.jar:/opt/dolphinscheduler/libs/aliyun-java-sdk-kms-2.11.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-dvc-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-hana-3.2.1.jar:/opt/dolphinscheduler/libs/kubernetes-httpclient-okhttp-6.0.0.jar:/opt/dolphinscheduler/libs/jline-2.12.jar:/opt/dolphinscheduler/libs/sshd-core-2.8.0.jar:/opt/dolphinscheduler/libs/jna-platform-5.10.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-sqlserver-3.2.1.jar:/opt/dolphinscheduler/libs/commons-beanutils-1.9.4.jar:/opt/dolphinscheduler/libs/grpc-services-1.41.0.jar:/opt/dolphinscheduler/libs/jmespath-java-1.12.300.jar:/opt/dolphinscheduler/libs/curator-client-5.3.0.jar:/opt/dolphinscheduler/libs/proto-google-common-protos-2.0.1.jar:/opt/dolphinscheduler/libs/mybatis-3.5.10.jar:/opt/dolphinscheduler/libs/jackson-annotations-2.13.4.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-all-3.2.1.jar:/opt/dolphinscheduler/libs/jakarta.xml.bind-api-2.3.3.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-jupyter-3.2.1.jar:/opt/dolphinscheduler/libs/mybatis-plus-extension-3.5.2.jar:/opt/dolphinscheduler/libs/j2objc-annotations-1.3.jar:/opt/dolphinscheduler/libs/Java-WebSocket-1.5.1.jar:/opt/dolphinscheduler/libs/azure-storage-common-12.20.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-sagemaker-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-databend-3.2.1.jar:/opt/dolphinscheduler/libs/google-auth-library-oauth2-http-1.15.0.jar:/opt/dolphinscheduler/libs/jetty-security-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-python-3.2.1.jar:/opt/dolphinscheduler/libs/snappy-java-1.1.10.1.jar:/opt/dolphinscheduler/libs/kubernetes-model-batch-5.10.2.jar:/opt/dolphinscheduler/libs/netty-transport-native-epoll-4.1.53.Final-linux-x86_64.jar:/opt/dolphinscheduler/libs/jackson-core-asl-1.9.13.jar:/opt/dolphinscheduler/libs/gson-fire-1.8.5.jar:/opt/dolphinscheduler/libs/clickhouse-jdbc-0.4.6.jar:/opt/dolphinscheduler/libs/grpc-netty-shaded-1.41.0.jar:/opt/dolphinscheduler/libs/caffeine-2.9.3.jar:/opt/dolphinscheduler/libs/aliyun-java-sdk-core-4.5.10.jar:/opt/dolphinscheduler/libs/jackson-module-jaxb-annotations-2.13.3.jar:/opt/dolphinscheduler/libs/jetty-http-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/jersey-servlet-1.19.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-dinky-3.2.1.jar:/opt/dolphinscheduler/libs/simpleclient_tracer_common-0.15.0.jar:/opt/dolphinscheduler/libs/netty-handler-4.1.53.Final.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-datafactory-3.2.1.jar:/opt/dolphinscheduler/libs/json-path-2.7.0.jar:/opt/dolphinscheduler/libs/mybatis-plus-annotation-3.5.2.jar:/opt/dolphinscheduler/libs/azure-resourcemanager-datafactory-1.0.0-beta.19.jar:/opt/dolphinscheduler/libs/commons-codec-1.11.jar:/opt/dolphinscheduler/libs/dolphinscheduler-extract-master-3.2.1.jar:/opt/dolphinscheduler/libs/spring-aop-5.3.22.jar:/opt/dolphinscheduler/libs/kubernetes-model-core-5.10.2.jar:/opt/dolphinscheduler/libs/kubernetes-model-networking-5.10.2.jar:/opt/dolphinscheduler/libs/kotlin-stdlib-jdk7-1.6.21.jar:/opt/dolphinscheduler/libs/kerby-xdr-1.0.1.jar:/opt/dolphinscheduler/libs/aliyun-java-sdk-ram-3.1.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-k8s-3.2.1.jar:/opt/dolphinscheduler/libs/guava-31.1-jre.jar:/opt/dolphinscheduler/libs/netty-codec-dns-4.1.53.Final.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-kubeflow-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-azure-sql-3.2.1.jar:/opt/dolphinscheduler/libs/HikariCP-4.0.3.jar:/opt/dolphinscheduler/libs/hive-metastore-2.3.9.jar:/opt/dolphinscheduler/libs/msal4j-1.13.3.jar:/opt/dolphinscheduler/libs/jackson-core-2.13.4.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-hive-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-mr-3.2.1.jar:/opt/dolphinscheduler/libs/kubernetes-model-node-5.10.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-common-3.2.1.jar:/opt/dolphinscheduler/libs/jose4j-0.7.8.jar:/opt/dolphinscheduler/libs/jul-to-slf4j-1.7.36.jar:/opt/dolphinscheduler/libs/azure-identity-1.7.1.jar:/opt/dolphinscheduler/libs/spring-boot-autoconfigure-2.7.3.jar:/opt/dolphinscheduler/libs/commons-math3-3.1.1.jar:/opt/dolphinscheduler/libs/jackson-jaxrs-json-provider-2.13.3.jar:/opt/dolphinscheduler/libs/perfmark-api-0.23.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-doris-3.2.1.jar:/opt/dolphinscheduler/libs/httpclient-4.5.13.jar:/opt/dolphinscheduler/libs/hive-service-2.3.9.jar:/opt/dolphinscheduler/libs/kerby-util-1.0.1.jar:/opt/dolphinscheduler/libs/commons-collections-3.2.2.jar:/opt/dolphinscheduler/libs/hadoop-yarn-client-3.2.4.jar:/opt/dolphinscheduler/libs/commons-text-1.8.jar:/opt/dolphinscheduler/libs/dolphinscheduler-worker-3.2.1.jar:/opt/dolphinscheduler/libs/hadoop-yarn-common-3.2.4.jar:/opt/dolphinscheduler/libs/zeppelin-client-0.10.1.jar:/opt/dolphinscheduler/libs/azure-core-management-1.10.1.jar:/opt/dolphinscheduler/libs/hadoop-mapreduce-client-jobclient-3.2.4.jar:/opt/dolphinscheduler/libs/jta-1.1.jar:/opt/dolphinscheduler/libs/annotations-4.1.1.4.jar:/opt/dolphinscheduler/libs/dolphinscheduler-extract-alert-3.2.1.jar:/opt/dolphinscheduler/libs/curator-framework-5.3.0.jar:/opt/dolphinscheduler/libs/hive-jdbc-2.3.9.jar:/opt/dolphinscheduler/libs/kyuubi-hive-jdbc-shaded-1.7.0.jar:/opt/dolphinscheduler/libs/client-java-proto-13.0.2.jar:/opt/dolphinscheduler/libs/checker-qual-3.19.0.jar:/opt/dolphinscheduler/libs/jetty-servlet-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/google-cloud-core-grpc-2.10.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-shell-3.2.1.jar:/opt/dolphinscheduler/libs/spring-security-rsa-1.0.10.RELEASE.jar:/opt/dolphinscheduler/libs/avro-1.7.7.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-postgresql-3.2.1.jar:/opt/dolphinscheduler/libs/netty-nio-client-2.17.282.jar:/opt/dolphinscheduler/libs/spring-webmvc-5.3.22.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-mysql-3.2.1.jar:/opt/dolphinscheduler/libs/opentracing-util-0.33.0.jar:/opt/dolphinscheduler/libs/auto-value-1.10.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-all-3.2.1.jar:/opt/dolphinscheduler/libs/jetcd-core-0.5.11.jar:/opt/dolphinscheduler/libs/grpc-context-1.41.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-datasync-3.2.1.jar:/opt/dolphinscheduler/libs/jackson-dataformat-cbor-2.13.3.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-gcs-3.2.1.jar:/opt/dolphinscheduler/libs/client-java-extended-13.0.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-redshift-3.2.1.jar:/opt/dolphinscheduler/libs/opencsv-2.3.jar:/opt/dolphinscheduler/libs/jcip-annotations-1.0-1.jar:/opt/dolphinscheduler/libs/accessors-smart-2.4.8.jar:/opt/dolphinscheduler/libs/hadoop-client-3.2.4.jar:/opt/dolphinscheduler/libs/commons-collections4-4.3.jar:/opt/dolphinscheduler/libs/metrics-core-4.2.11.jar:/opt/dolphinscheduler/libs/netty-resolver-4.1.53.Final.jar:/opt/dolphinscheduler/libs/parquet-hadoop-bundle-1.8.1.jar:/opt/dolphinscheduler/libs/bucket4j-core-6.2.0.jar:/opt/dolphinscheduler/libs/spring-cloud-starter-3.1.3.jar:/opt/dolphinscheduler/libs/mssql-jdbc-11.2.1.jre8.jar:/opt/dolphinscheduler/libs/netty-tcnative-boringssl-static-2.0.53.Final.jar:/opt/dolphinscheduler/libs/kubernetes-model-coordination-5.10.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-linkis-3.2.1.jar:/opt/dolphinscheduler/libs/commons-net-3.6.jar:/opt/dolphinscheduler/libs/netty-transport-native-kqueue-4.1.53.Final-osx-x86_64.jar:/opt/dolphinscheduler/libs/dolphinscheduler-meter-3.2.1.jar:/opt/dolphinscheduler/libs/kubernetes-client-api-6.0.0.jar:/opt/dolphinscheduler/libs/kubernetes-model-certificates-5.10.2.jar:/opt/dolphinscheduler/libs/opencensus-api-0.31.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-mlflow-3.2.1.jar:/opt/dolphinscheduler/libs/kotlin-stdlib-jdk8-1.6.21.jar:/opt/dolphinscheduler/libs/dolphinscheduler-registry-jdbc-3.2.1.jar:/opt/dolphinscheduler/libs/audience-annotations-0.12.0.jar:/opt/dolphinscheduler/libs/simpleclient_httpserver-0.15.0.jar:/opt/dolphinscheduler/libs/jetty-xml-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/kerby-asn1-1.0.1.jar:/opt/dolphinscheduler/libs/lang-tag-1.6.jar:/opt/dolphinscheduler/libs/api-common-2.6.0.jar:/opt/dolphinscheduler/libs/HdrHistogram-2.1.12.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-abs-3.2.1.jar:/opt/dolphinscheduler/libs/failsafe-2.4.4.jar:/opt/dolphinscheduler/libs/hbase-noop-htrace-4.1.1.jar:/opt/dolphinscheduler/libs/jamon-runtime-2.3.1.jar:/opt/dolphinscheduler/libs/jetty-util-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/threetenbp-1.6.5.jar:/opt/dolphinscheduler/libs/jakarta.activation-api-1.2.2.jar:/opt/dolphinscheduler/libs/kubernetes-model-common-5.10.2.jar:/opt/dolphinscheduler/libs/okhttp-4.9.3.jar:/opt/dolphinscheduler/libs/profiles-2.17.282.jar:/opt/dolphinscheduler/libs/hadoop-auth-3.2.4.jar:/opt/dolphinscheduler/libs/grpc-netty-1.41.0.jar:/opt/dolphinscheduler/libs/httpcore-nio-4.4.15.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-seatunnel-3.2.1.jar:/opt/dolphinscheduler/libs/aws-java-sdk-sagemaker-1.12.300.jar:/opt/dolphinscheduler/libs/oshi-core-6.1.1.jar:/opt/dolphinscheduler/libs/bonecp-0.8.0.RELEASE.jar:/opt/dolphinscheduler/libs/jackson-module-parameter-names-2.13.3.jar:/opt/dolphinscheduler/libs/bcutil-jdk15on-1.69.jar:/opt/dolphinscheduler/libs/aws-json-protocol-2.17.282.jar:/opt/dolphinscheduler/libs/dolphinscheduler-extract-base-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-all-3.2.1.jar:/opt/dolphinscheduler/libs/derby-10.14.2.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-snowflake-3.2.1.jar:/opt/dolphinscheduler/libs/netty-codec-http2-4.1.53.Final.jar:/opt/dolphinscheduler/libs/jetty-continuation-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/jackson-mapper-asl-1.9.13.jar:/opt/dolphinscheduler/libs/datanucleus-core-4.1.17.jar:/opt/dolphinscheduler/libs/netty-tcnative-boringssl-static-2.0.53.Final-osx-aarch_64.jar:/opt/dolphinscheduler/libs/failureaccess-1.0.1.jar:/opt/dolphinscheduler/libs/error_prone_annotations-2.5.1.jar:/opt/dolphinscheduler/libs/kerb-admin-1.0.1.jar:/opt/dolphinscheduler/libs/token-provider-1.0.1.jar:/opt/dolphinscheduler/libs/reactor-netty-core-1.0.22.jar:/opt/dolphinscheduler/libs/dolphinscheduler-registry-all-3.2.1.jar:/opt/dolphinscheduler/libs/jakarta.servlet-api-4.0.4.jar:/opt/dolphinscheduler/libs/http-client-spi-2.17.282.jar:/opt/dolphinscheduler/libs/regions-2.17.282.jar:/opt/dolphinscheduler/libs/logback-core-1.2.11.jar:/opt/dolphinscheduler/libs/json-1.8.jar:/opt/dolphinscheduler/libs/gax-grpc-2.23.0.jar:/opt/dolphinscheduler/libs/google-http-client-1.42.3.jar:/opt/dolphinscheduler/libs/hive-serde-2.3.9.jar:/opt/dolphinscheduler/libs/jettison-1.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-http-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-registry-zookeeper-3.2.1.jar:/opt/dolphinscheduler/libs/spring-security-crypto-5.7.3.jar:/opt/dolphinscheduler/libs/auth-2.17.282.jar:/opt/dolphinscheduler/libs/proto-google-cloud-storage-v2-2.18.0-alpha.jar:/opt/dolphinscheduler/libs/jetty-server-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/javax.annotation-api-1.3.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-starrocks-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-dataquality-3.2.1.jar:/opt/dolphinscheduler/libs/jcl-over-slf4j-1.7.36.jar:/opt/dolphinscheduler/libs/commons-lang3-3.12.0.jar:/opt/dolphinscheduler/libs/tomcat-embed-el-9.0.65.jar:/opt/dolphinscheduler/libs/opentracing-noop-0.33.0.jar:/opt/dolphinscheduler/libs/client-java-13.0.2.jar:/opt/dolphinscheduler/libs/spring-beans-5.3.22.jar:/opt/dolphinscheduler/libs/snakeyaml-1.33.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-ssh-3.2.1.jar:/opt/dolphinscheduler/libs/commons-pool-1.6.jar:/opt/dolphinscheduler/libs/javax.servlet-api-3.1.0.jar:/opt/dolphinscheduler/libs/hadoop-common-3.2.4.jar:/opt/dolphinscheduler/libs/kubernetes-model-apiextensions-5.10.2.jar:/opt/dolphinscheduler/libs/spring-boot-2.7.3.jar:/opt/dolphinscheduler/libs/bcprov-ext-jdk15on-1.69.jar:/opt/dolphinscheduler/libs/spring-boot-starter-2.7.3.jar:/opt/dolphinscheduler/libs/paranamer-2.3.jar:/opt/dolphinscheduler/libs/httpmime-4.5.13.jar:/opt/dolphinscheduler/libs/reactor-core-3.4.22.jar:/opt/dolphinscheduler/libs/azure-core-1.36.0.jar:/opt/dolphinscheduler/libs/bcpkix-jdk15on-1.69.jar:/opt/dolphinscheduler/libs/kubernetes-model-scheduling-5.10.2.jar:/opt/dolphinscheduler/libs/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/dolphinscheduler/libs/websocket-client-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/unirest-java-3.7.04-standalone.jar:/opt/dolphinscheduler/libs/hadoop-mapreduce-client-core-3.2.4.jar:/opt/dolphinscheduler/libs/google-auth-library-credentials-1.15.0.jar:/opt/dolphinscheduler/libs/azure-storage-internal-avro-12.6.0.jar:/opt/dolphinscheduler/libs/jackson-datatype-jdk8-2.13.3.jar:/opt/dolphinscheduler/libs/spring-expression-5.3.22.jar:/opt/dolphinscheduler/libs/aspectjweaver-1.9.7.jar:/opt/dolphinscheduler/libs/websocket-common-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/client-java-api-fluent-13.0.2.jar:/opt/dolphinscheduler/libs/mybatis-plus-3.5.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-athena-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-oss-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-openmldb-3.2.1.jar:/opt/dolphinscheduler/libs/curator-recipes-5.3.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-api-3.2.1.jar:/opt/dolphinscheduler/libs/netty-all-4.1.53.Final.jar:/opt/dolphinscheduler/libs/netty-resolver-dns-4.1.53.Final.jar:/opt/dolphinscheduler/libs/kubernetes-model-autoscaling-5.10.2.jar:/opt/dolphinscheduler/libs/kerb-util-1.0.1.jar:/opt/dolphinscheduler/libs/grpc-alts-1.41.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-presto-3.2.1.jar:/opt/dolphinscheduler/libs/kerb-simplekdc-1.0.1.jar:/opt/dolphinscheduler/libs/protobuf-java-util-3.17.2.jar:/opt/dolphinscheduler/libs/azure-core-http-netty-1.13.0.jar:/opt/dolphinscheduler/libs/transaction-api-1.1.jar:/opt/dolphinscheduler/libs/datanucleus-api-jdo-4.2.4.jar:/opt/dolphinscheduler/libs/zeppelin-common-0.10.1.jar:/opt/dolphinscheduler/libs/zt-zip-1.15.jar:/opt/dolphinscheduler/libs/animal-sniffer-annotations-1.19.jar:/opt/dolphinscheduler/libs/google-http-client-jackson2-1.42.3.jar:/opt/dolphinscheduler/libs/netty-buffer-4.1.53.Final.jar:/opt/dolphinscheduler/libs/jsr305-3.0.0.jar:/opt/dolphinscheduler/libs/netty-transport-classes-epoll-4.1.79.Final.jar:/opt/dolphinscheduler/libs/spring-boot-actuator-autoconfigure-2.7.3.jar:/opt/dolphinscheduler/libs/simpleclient-0.15.0.jar:/opt/dolphinscheduler/libs/aliyun-sdk-oss-3.15.1.jar:/opt/dolphinscheduler/libs/json-utils-2.17.282.jar:/opt/dolphinscheduler/libs/tephra-api-0.6.0.jar:/opt/dolphinscheduler/libs/spring-jdbc-5.3.22.jar:/opt/dolphinscheduler/libs/grpc-xds-1.41.0.jar:/opt/dolphinscheduler/libs/logback-classic-1.2.11.jar:/opt/dolphinscheduler/libs/google-cloud-storage-2.18.0.jar:/opt/dolphinscheduler/libs/micrometer-registry-prometheus-1.9.3.jar:/opt/dolphinscheduler/libs/grpc-core-1.41.0.jar:/opt/dolphinscheduler/libs/aws-java-sdk-kms-1.12.300.jar:/opt/dolphinscheduler/libs/kubernetes-model-rbac-5.10.2.jar:/opt/dolphinscheduler/libs/ini4j-0.5.4.jar:/opt/dolphinscheduler/libs/spring-boot-starter-web-2.7.3.jar:/opt/dolphinscheduler/libs/spring-cloud-commons-3.1.3.jar:/opt/dolphinscheduler/libs/netty-codec-http-4.1.53.Final.jar:/opt/dolphinscheduler/libs/jetty-client-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/jetcd-common-0.5.11.jar:/opt/dolphinscheduler/libs/metrics-spi-2.17.282.jar:/opt/dolphinscheduler/libs/utils-2.17.282.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-emr-3.2.1.jar:/opt/dolphinscheduler/libs/protocol-core-2.17.282.jar:/opt/dolphinscheduler/libs/micrometer-core-1.9.3.jar:/opt/dolphinscheduler/libs/netty-transport-native-unix-common-4.1.53.Final.jar:/opt/dolphinscheduler/libs/zjsonpatch-0.4.11.jar:/opt/dolphinscheduler/libs/annotations-2.17.282.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-sql-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-extract-common-3.2.1.jar:/opt/dolphinscheduler/libs/apache-client-2.17.282.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-oceanbase-3.2.1.jar:/opt/dolphinscheduler/libs/jdo-api-3.0.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-datax-3.2.1.jar:/opt/dolphinscheduler/libs/postgresql-42.4.1.jar:/opt/dolphinscheduler/libs/jetty-util-ajax-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/gax-2.23.0.jar:/opt/dolphinscheduler/libs/grpc-stub-1.41.0.jar:/opt/dolphinscheduler/libs/libfb303-0.9.3.jar:/opt/dolphinscheduler/libs/spring-core-5.3.22.jar:/opt/dolphinscheduler/libs/jaxb-api-2.3.1.jar:/opt/dolphinscheduler/libs/hive-service-rpc-2.3.9.jar:/opt/dolphinscheduler/libs/kubernetes-model-flowcontrol-5.10.2.jar:/opt/dolphinscheduler/libs/commons-logging-1.1.1.jar:/opt/dolphinscheduler/libs/mybatis-spring-2.0.7.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-oracle-3.2.1.jar:/opt/dolphinscheduler/libs/opencensus-proto-0.2.0.jar:/opt/dolphinscheduler/libs/grpc-protobuf-1.41.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-clickhouse-3.2.1.jar:/opt/dolphinscheduler/libs/spring-cloud-starter-bootstrap-3.1.3.jar:/opt/dolphinscheduler/libs/kubernetes-model-admissionregistration-5.10.2.jar:/opt/dolphinscheduler/libs/grpc-google-cloud-storage-v2-2.18.0-alpha.jar:/opt/dolphinscheduler/libs/esdk-obs-java-bundle-3.23.3.jar:/opt/dolphinscheduler/libs/dnsjava-2.1.7.jar:/opt/dolphinscheduler/libs/asm-9.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-spark-3.2.1.jar:/opt/dolphinscheduler/libs/netty-tcnative-boringssl-static-2.0.53.Final-linux-aarch_64.jar:/opt/dolphinscheduler/libs/re2j-1.6.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-vertica-3.2.1.jar:/opt/dolphinscheduler/libs/json-smart-2.4.8.jar:/opt/dolphinscheduler/libs/reactor-netty-http-1.0.22.jar:/opt/dolphinscheduler/libs/google-api-services-storage-v1-rev20220705-2.0.0.jar:/opt/dolphinscheduler/libs/kubernetes-client-6.0.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-kyuubi-3.2.1.jar:/opt/dolphinscheduler/libs/auto-value-annotations-1.10.1.jar:/opt/dolphinscheduler/libs/commons-cli-1.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-data-quality-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-chunjun-3.2.1.jar:/opt/dolphinscheduler/libs/kerb-server-1.0.1.jar:/opt/dolphinscheduler/libs/content-type-2.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-remoteshell-3.2.1.jar:/opt/dolphinscheduler/libs/opencensus-contrib-http-util-0.31.1.jar:/opt/dolphinscheduler/libs/druid-1.2.20.jar:/opt/dolphinscheduler/libs/javolution-5.5.1.jar:/opt/dolphinscheduler/libs/protobuf-java-3.17.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-db2-3.2.1.jar:/opt/dolphinscheduler/libs/aws-java-sdk-core-1.12.300.jar:/opt/dolphinscheduler/libs/spring-boot-starter-logging-2.7.3.jar:/opt/dolphinscheduler/libs/kerby-pkix-1.0.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-procedure-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-registry-etcd-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-sqoop-3.2.1.jar:/opt/dolphinscheduler/libs/zookeeper-jute-3.8.0.jar:/opt/dolphinscheduler/libs/netty-resolver-dns-native-macos-4.1.53.Final-osx-x86_64.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-sagemaker-3.2.1.jar:/opt/dolphinscheduler/libs/spring-boot-configuration-processor-2.6.1.jar:/opt/dolphinscheduler/libs/hive-common-2.3.9.jar:/opt/dolphinscheduler/libs/kerb-common-1.0.1.jar:/opt/dolphinscheduler/libs/stax-api-1.0.1.jar:/opt/dolphinscheduler/libs/kubernetes-model-storageclass-5.10.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-s3-3.2.1.jar:/opt/dolphinscheduler/libs/spring-boot-starter-jetty-2.7.3.jar:/opt/dolphinscheduler/libs/okio-2.8.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-dms-3.2.1.jar:/opt/dolphinscheduler/libs/simpleclient_common-0.15.0.jar:/opt/dolphinscheduler/libs/sdk-core-2.17.282.jar:/opt/dolphinscheduler/libs/javax.activation-api-1.2.0.jar:/opt/dolphinscheduler/libs/netty-handler-proxy-4.1.53.Final.jar:/opt/dolphinscheduler/libs/kerby-config-1.0.1.jar:/opt/dolphinscheduler/libs/netty-tcnative-classes-2.0.53.Final.jar:/opt/dolphinscheduler/libs/jackson-jaxrs-base-2.13.3.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-trino-3.2.1.jar:/opt/dolphinscheduler/libs/presto-jdbc-0.238.1.jar:/opt/dolphinscheduler/libs/websocket-api-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-flink-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-api-3.2.1.jar:/opt/dolphinscheduler/libs/kubernetes-model-metrics-5.10.2.jar:/opt/dolphinscheduler/libs/datasync-2.17.282.jar:/opt/dolphinscheduler/libs/hadoop-yarn-api-3.2.4.jar:/opt/dolphinscheduler/libs/google-http-client-apache-v2-1.42.3.jar:/opt/dolphinscheduler/libs/hadoop-annotations-3.2.4.jar:/opt/dolphinscheduler/libs/google-oauth-client-1.34.1.jar:/opt/dolphinscheduler/libs/sshd-common-2.8.0.jar:/opt/dolphinscheduler/libs/LatencyUtils-2.0.3.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-spark-3.2.1.jar:/opt/dolphinscheduler/libs/slf4j-api-1.7.36.jar:/opt/dolphinscheduler/libs/snowflake-jdbc-3.13.29.jar:/opt/dolphinscheduler/libs/jackson-datatype-jsr310-2.13.3.jar:/opt/dolphinscheduler/libs/trino-jdbc-402.jar:/opt/dolphinscheduler/libs/logging-interceptor-4.9.3.jar:/opt/dolphinscheduler/libs/simpleclient_tracer_otel_agent-0.15.0.jar:/opt/dolphinscheduler/libs/janino-3.0.16.jar:/opt/dolphinscheduler/libs/jackson-dataformat-yaml-2.13.3.jar:/opt/dolphinscheduler/libs/ion-java-1.0.2.jar:/opt/dolphinscheduler/libs/commons-dbcp-1.4.jar:/opt/dolphinscheduler/libs/jsp-api-2.1.jar:/opt/dolphinscheduler/libs/google-http-client-gson-1.42.3.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-hivecli-3.2.1.jar:/opt/dolphinscheduler/libs/spring-boot-actuator-2.7.3.jar:/opt/dolphinscheduler/libs/google-cloud-core-http-2.10.0.jar:/opt/dolphinscheduler/libs/DmJdbcDriver18-8.1.2.79.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-java-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-dameng-3.2.1.jar:/opt/dolphinscheduler/libs/sshd-sftp-2.8.0.jar:/opt/dolphinscheduler/libs/kerb-crypto-1.0.1.jar:/opt/dolphinscheduler/libs/conscrypt-openjdk-uber-2.5.2.jar:/opt/dolphinscheduler/libs/httpcore-4.4.15.jar:/opt/dolphinscheduler/libs/lz4-java-1.4.0.jar:/opt/dolphinscheduler/libs/guava-retrying-2.0.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-flink-stream-3.2.1.jar:/opt/dolphinscheduler/libs/spring-tx-5.3.22.jar:/opt/dolphinscheduler/libs/grpc-auth-1.41.0.jar:/opt/dolphinscheduler/libs/netty-tcnative-boringssl-static-2.0.53.Final-osx-x86_64.jar:/opt/dolphinscheduler/libs/databend-jdbc-0.0.7.jar:/opt/dolphinscheduler/libs/bcprov-jdk15on-1.69.jar:/opt/dolphinscheduler/libs/commons-lang-2.6.jar:/opt/dolphinscheduler/libs/kubernetes-model-policy-5.10.2.jar:/opt/dolphinscheduler/libs/commons-io-2.11.0.jar:/opt/dolphinscheduler/libs/grpc-grpclb-1.41.0.jar:/opt/dolphinscheduler/libs/netty-tcnative-boringssl-static-2.0.53.Final-linux-x86_64.jar:/opt/dolphinscheduler/libs/opentracing-api-0.33.0.jar:/opt/dolphinscheduler/libs/sshd-scp-2.8.0.jar:/opt/dolphinscheduler/libs/reload4j-1.2.18.3.jar:/opt/dolphinscheduler/libs/netty-tcnative-2.0.48.Final.jar:/opt/dolphinscheduler/libs/jdom2-2.0.6.1.jar:/opt/dolphinscheduler/libs/spring-boot-starter-json-2.7.3.jar:/opt/dolphinscheduler/libs/netty-transport-native-epoll-4.1.53.Final.jar:/opt/dolphinscheduler/libs/google-cloud-core-2.10.0.jar:/opt/dolphinscheduler/libs/javax.jdo-3.2.0-m3.jar:/opt/dolphinscheduler/libs/gax-httpjson-0.108.0.jar:/opt/dolphinscheduler/libs/mybatis-plus-core-3.5.2.jar:/opt/dolphinscheduler/libs/auto-service-annotations-1.0.1.jar:/opt/dolphinscheduler/libs/nimbus-jose-jwt-9.22.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-zeppelin-3.2.1.jar:/opt/dolphinscheduler/libs/commons-compress-1.21.jar:/opt/dolphinscheduler/libs/hadoop-hdfs-client-3.2.4.jar:/opt/dolphinscheduler/libs/msal4j-persistence-extension-1.1.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-pytorch-3.2.1.jar:/opt/dolphinscheduler/libs/netty-tcnative-boringssl-static-2.0.53.Final-windows-x86_64.jar:/opt/dolphinscheduler/libs/jetty-servlets-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/woodstox-core-6.4.0.jar:/opt/dolphinscheduler/libs/spring-cloud-kubernetes-commons-2.1.3.jar:/opt/dolphinscheduler/libs/grpc-protobuf-lite-1.41.0.jar:/opt/dolphinscheduler/libs/jetty-webapp-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/eventstream-1.0.1.jar:/opt/dolphinscheduler/libs/commons-compiler-3.1.7.jar:/opt/dolphinscheduler/libs/netty-transport-4.1.53.Final.jar:/opt/dolphinscheduler/libs/spring-cloud-context-3.1.3.jar:/opt/dolphinscheduler/libs/aws-java-sdk-dms-1.12.300.jar:/opt/dolphinscheduler/libs/hive-storage-api-2.4.0.jar:/opt/dolphinscheduler/libs/client-java-spring-integration-13.0.2.jar:/opt/dolphinscheduler/libs/spring-boot-starter-actuator-2.7.3.jar:/opt/dolphinscheduler/libs/third-party-jackson-core-2.17.282.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-hdfs-3.2.1.jar:/opt/dolphinscheduler/libs/netty-codec-4.1.53.Final.jar:/opt/dolphinscheduler/libs/google-http-client-appengine-1.42.3.jar:/opt/dolphinscheduler/libs/commons-configuration2-2.1.1.jar:/opt/dolphinscheduler/libs/datanucleus-rdbms-4.1.19.jar:/opt/dolphinscheduler/libs/swagger-annotations-1.6.2.jar:/opt/dolphinscheduler/libs/simpleclient_tracer_otel-0.15.0.jar:/opt/dolphinscheduler/libs/kotlin-stdlib-common-1.6.21.jar:/opt/dolphinscheduler/libs/aws-core-2.17.282.jar:/opt/dolphinscheduler/libs/kerb-core-1.0.1.jar:/opt/dolphinscheduler/libs/httpasyncclient-4.1.5.jar:/opt/dolphinscheduler/libs/dolphinscheduler-extract-worker-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-spi-3.2.1.jar:/opt/dolphinscheduler/libs/okhttp-2.7.5.jar:/opt/dolphinscheduler/libs/google-api-client-2.2.0.jar:/opt/dolphinscheduler/libs/kotlin-stdlib-1.6.21.jar:/opt/dolphinscheduler/libs/jakarta.websocket-api-1.1.2.jar:/opt/dolphinscheduler/libs/libthrift-0.9.3.jar:/opt/dolphinscheduler/libs/spring-boot-starter-aop-2.7.3.jar:/opt/dolphinscheduler/libs/netty-common-4.1.53.Final.jar:/opt/dolphinscheduler/libs/log4j-1.2-api-2.17.2.jar:/opt/dolphinscheduler/libs/jackson-databind-2.13.4.jar:/opt/dolphinscheduler/libs/jackson-dataformat-xml-2.13.3.jar:/opt/dolphinscheduler/libs/kubernetes-model-events-5.10.2.jar:/opt/dolphinscheduler/libs/gson-2.9.1.jar:/opt/dolphinscheduler/libs/proto-google-iam-v1-1.9.0.jar:/opt/dolphinscheduler/libs/netty-codec-socks-4.1.53.Final.jar:/opt/dolphinscheduler/libs/zjsonpatch-0.3.0.jar:/opt/dolphinscheduler/libs/hadoop-mapreduce-client-common-3.2.4.jar:/opt/dolphinscheduler/libs/dolphinscheduler-registry-api-3.2.1.jar:/opt/dolphinscheduler/libs/azure-storage-blob-12.21.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-zeppelin-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-api-3.2.1.jar:/opt/dolphinscheduler/libs/aws-java-sdk-s3-1.12.300.jar:/opt/dolphinscheduler/libs/stax2-api-4.2.1.jar:/opt/dolphinscheduler/libs/jakarta.annotation-api-1.3.5.jar:/opt/dolphinscheduler/libs/kubernetes-model-discovery-5.10.2.jar:/opt/dolphinscheduler/libs/jna-5.10.0.jar:/opt/dolphinscheduler/libs/spring-jcl-5.3.22.jar
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:11.672 +0800 o.a.z.ZooKeeper:[98] - Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:11.672 +0800 o.a.z.ZooKeeper:[98] - Client environment:java.io.tmpdir=/tmp
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:11.689 +0800 o.a.z.ZooKeeper:[98] - Client environment:java.compiler=<NA>
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:11.690 +0800 o.a.z.ZooKeeper:[98] - Client environment:os.name=Linux
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:11.691 +0800 o.a.z.ZooKeeper:[98] - Client environment:os.arch=amd64
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:11.692 +0800 o.a.z.ZooKeeper:[98] - Client environment:os.version=6.5.0-28-generic
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:11.692 +0800 o.a.z.ZooKeeper:[98] - Client environment:user.name=root
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:11.693 +0800 o.a.z.ZooKeeper:[98] - Client environment:user.home=/root
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:11.697 +0800 o.a.z.ZooKeeper:[98] - Client environment:user.dir=/opt/dolphinscheduler
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:11.698 +0800 o.a.z.ZooKeeper:[98] - Client environment:os.memory.free=3215MB
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:11.700 +0800 o.a.z.ZooKeeper:[98] - Client environment:os.memory.max=3840MB
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:11.700 +0800 o.a.z.ZooKeeper:[98] - Client environment:os.memory.total=3840MB
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:11.727 +0800 o.a.z.ZooKeeper:[637] - Initiating client connection, connectString=dolphinscheduler-zookeeper:2181 sessionTimeout=30000 watcher=org.apache.curator.ConnectionState@28bd5015
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:11.744 +0800 o.a.z.c.X509Util:[77] - Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:11.751 +0800 o.a.z.ClientCnxnSocket:[239] - jute.maxbuffer value is 1048575 Bytes
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:11.775 +0800 o.a.z.ClientCnxn:[1732] - zookeeper.request.timeout value is 0. feature enabled=false
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:11.875 +0800 o.a.c.f.i.CuratorFrameworkImpl:[386] - Default schema
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:11.903 +0800 o.a.z.ClientCnxn:[1171] - Opening socket connection to server dolphinscheduler-zookeeper/172.18.0.5:2181.
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:12.115 +0800 o.a.z.ClientCnxn:[1173] - SASL config status: Will not attempt to authenticate using SASL (unknown error)
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:12.163 +0800 o.a.z.ClientCnxn:[1005] - Socket connection established, initiating session, client: /172.18.1.1:48618, server: dolphinscheduler-zookeeper/172.18.0.5:2181
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:12.212 +0800 o.a.z.ClientCnxn:[1444] - Session establishment complete on server dolphinscheduler-zookeeper/172.18.0.5:2181, session id = 0x100007a5de90000, negotiated timeout = 30000
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:12.225 +0800 o.a.c.f.s.ConnectionStateManager:[252] - State change: CONNECTED
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:12.550 +0800 o.a.c.f.i.EnsembleTracker:[201] - New config event received: {}
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:12.559 +0800 o.a.c.f.i.EnsembleTracker:[201] - New config event received: {}
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:13.521 +0800 o.a.d.s.w.r.WorkerRpcServer:[41] - WorkerRpcServer starting...
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:13.875 +0800 o.a.d.e.b.NettyRemotingServer:[112] - WorkerRpcServer bind success at port: 1234
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:13.886 +0800 o.a.d.s.w.r.WorkerRpcServer:[43] - WorkerRpcServer started...
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:13.978 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: JAVA - JavaTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:13.983 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: JAVA - JavaTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:13.993 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: JUPYTER - JupyterTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:13.997 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: JUPYTER - JupyterTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:13.998 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: SPARK - SparkTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:14.019 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: SPARK - SparkTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:14.020 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: FLINK_STREAM - FlinkStreamTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:14.036 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: FLINK_STREAM - FlinkStreamTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:14.037 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: PYTHON - PythonTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:14.040 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: PYTHON - PythonTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:14.041 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: DATASYNC - DatasyncTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:14.044 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: DATASYNC - DatasyncTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:14.052 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: DATA_FACTORY - DatafactoryTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:14.054 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: DATA_FACTORY - DatafactoryTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:14.054 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: CHUNJUN - ChunJunTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:14.064 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: CHUNJUN - ChunJunTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:14.065 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: REMOTESHELL - RemoteShellTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:14.070 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: REMOTESHELL - RemoteShellTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:14.070 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: PIGEON - PigeonTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:14.073 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: PIGEON - PigeonTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:14.074 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: SHELL - ShellTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:14.085 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: SHELL - ShellTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:14.086 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: PROCEDURE - ProcedureTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:14.091 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: PROCEDURE - ProcedureTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:14.092 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: MR - MapReduceTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:14.104 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: MR - MapReduceTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:14.105 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: SQOOP - SqoopTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:14.109 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: SQOOP - SqoopTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:14.111 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: PYTORCH - PytorchTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:14.114 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: PYTORCH - PytorchTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:14.137 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: K8S - K8sTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:14.140 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: K8S - K8sTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:14.141 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: SEATUNNEL - SeatunnelTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:14.145 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: SEATUNNEL - SeatunnelTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:14.146 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: SAGEMAKER - SagemakerTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:14.149 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: SAGEMAKER - SagemakerTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:14.150 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: HTTP - HttpTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:14.153 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: HTTP - HttpTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:14.154 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: EMR - EmrTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:14.159 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: EMR - EmrTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:14.168 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: DMS - DmsTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:14.171 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: DMS - DmsTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:14.171 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: DATA_QUALITY - DataQualityTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:14.174 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: DATA_QUALITY - DataQualityTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:14.175 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: KUBEFLOW - KubeflowTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:14.184 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: KUBEFLOW - KubeflowTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:14.186 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: SQL - SqlTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:14.189 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: SQL - SqlTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:14.199 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: DVC - DvcTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:14.201 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: DVC - DvcTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:14.203 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: DATAX - DataxTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:14.206 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: DATAX - DataxTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:14.209 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: ZEPPELIN - ZeppelinTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:14.212 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: ZEPPELIN - ZeppelinTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:14.231 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: DINKY - DinkyTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:14.234 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: DINKY - DinkyTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:14.236 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: MLFLOW - MlflowTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:14.238 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: MLFLOW - MlflowTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:14.239 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: OPENMLDB - OpenmldbTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:14.241 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: OPENMLDB - OpenmldbTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:14.243 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: LINKIS - LinkisTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:14.245 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: LINKIS - LinkisTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:14.248 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: FLINK - FlinkTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:14.250 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: FLINK - FlinkTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:14.285 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: HIVECLI - HiveCliTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:14.292 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: HIVECLI - HiveCliTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:14.682 +0800 o.a.d.c.u.JSONUtils:[72] - init timezone: sun.util.calendar.ZoneInfo[id="Asia/Shanghai",offset=28800000,dstSavings=0,useDaylight=false,transitions=31,lastRule=null]
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:15.184 +0800 o.a.d.s.w.r.WorkerRegistryClient:[104] - Worker node: 172.18.1.1:1234 registry to ZK /nodes/worker/172.18.1.1:1234 successfully
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:16.291 +0800 o.a.d.c.m.BaseHeartBeatTask:[48] - Starting WorkerHeartBeatTask...
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:16.294 +0800 o.a.d.c.m.BaseHeartBeatTask:[50] - Started WorkerHeartBeatTask, heartBeatInterval: 10000...
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:16.305 +0800 o.a.d.s.w.r.WorkerRegistryClient:[114] - Worker node: 172.18.1.1:1234 registry finished
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:16.306 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.3372549019607844 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:16.322 +0800 o.a.d.s.w.m.MessageRetryRunner:[69] - Message retry runner staring
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:16.387 +0800 o.a.d.s.w.m.MessageRetryRunner:[72] - Injected message sender: TaskInstanceExecutionFinishEventSender
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:16.387 +0800 o.a.d.s.w.m.MessageRetryRunner:[72] - Injected message sender: TaskInstanceExecutionInfoUpdateEventSender
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:16.388 +0800 o.a.d.s.w.m.MessageRetryRunner:[72] - Injected message sender: TaskInstanceExecutionRunningEventSender
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:16.467 +0800 o.a.d.s.w.m.MessageRetryRunner:[75] - Message retry runner started
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:17.700 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.61875 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:18.772 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.5093167701863355 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:20.097 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.7396449704142012 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:21.205 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.5209580838323356 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:22.207 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.4487179487179487 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:23.215 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.81 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:24.328 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.8952380952380952 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:25.701 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.5694444444444444 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:26.713 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.5847457627118644 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:27.842 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.5774647887323945 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:29.009 +0800 o.s.b.a.e.w.EndpointLinksResolver:[58] - Exposing 3 endpoint(s) beneath base path '/actuator'
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:29.027 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 2.0 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:29.497 +0800 o.e.j.s.h.C.application:[2368] - Initializing Spring DispatcherServlet 'dispatcherServlet'
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:29.499 +0800 o.s.w.s.DispatcherServlet:[525] - Initializing Servlet 'dispatcherServlet'
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:29.509 +0800 o.s.w.s.DispatcherServlet:[547] - Completed initialization in 2 ms
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:29.731 +0800 o.e.j.s.AbstractConnector:[333] - Started ServerConnector@720a1fd0{HTTP/1.1, (http/1.1)}{0.0.0.0:1235}
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:29.733 +0800 o.s.b.w.e.j.JettyWebServer:[172] - Jetty started on port(s) 1235 (http/1.1) with context path '/'
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:29.780 +0800 o.a.d.s.w.WorkerServer:[61] - Started WorkerServer in 46.489 seconds (JVM running for 49.687)
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:30.058 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.3210807584841167 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:31.096 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9787323425930787 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:32.103 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9912663755458516 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:33.109 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.949438202247191 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:34.135 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7522123893805309 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:35.150 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8325123152709359 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:36.159 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7482993197278912 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:37.229 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8275862068965517 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:38.341 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9178007023705004 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:40.354 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.819371727748691 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:41.374 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.0594405594405594 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:42.376 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8837209302325582 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 05:54:43.385 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7924528301886793 is over then the MaxCpuUsagePercentageThresholds 0.7
