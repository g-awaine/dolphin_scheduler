[INFO] 2024-05-03 08:39:49.874 +0800 - ***********************************************************************************************
[INFO] 2024-05-03 08:39:49.876 +0800 - *********************************  Initialize task context  ***********************************
[INFO] 2024-05-03 08:39:49.876 +0800 - ***********************************************************************************************
[INFO] 2024-05-03 08:39:49.876 +0800 - Begin to initialize task
[INFO] 2024-05-03 08:39:49.876 +0800 - Set task startTime: 1714696789876
[INFO] 2024-05-03 08:39:49.877 +0800 - Set task appId: 815_2431
[INFO] 2024-05-03 08:39:49.882 +0800 - End initialize task {
  "taskInstanceId" : 2431,
  "taskName" : "check if it exists in the database",
  "firstSubmitTime" : 1714696789849,
  "startTime" : 1714696789876,
  "taskType" : "SQL",
  "workflowInstanceHost" : "172.18.0.12:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240503/13471825071552/14/815/2431.log",
  "processId" : 0,
  "processDefineCode" : 13471825071552,
  "processDefineVersion" : 14,
  "processInstanceId" : 815,
  "scheduleTime" : 0,
  "executorId" : 1,
  "cmdTypeIfComplement" : 7,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[{\"prop\":\"artricle_hash\",\"direct\":\"OUT\",\"type\":\"LIST\",\"value\":\"\"}],\"resourceList\":[],\"type\":\"POSTGRESQL\",\"datasource\":5,\"sql\":\"SELECT hash\\nFROM article_hashes\\nWHERE hash = llll\\n\",\"sqlType\":\"0\",\"preStatements\":[\"CREATE TABLE IF NOT EXISTS article_hashes (\\n\\t    hash TEXT NOT NULL\\n\\t);\"],\"postStatements\":[],\"displayRows\":10}",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "check if it exists in the database"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "artricle_hash" : {
      "prop" : "artricle_hash",
      "direct" : "IN",
      "type" : "LIST",
      "value" : "null"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240503"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "2431"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13472192399424"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240503083949"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "815"
    },
    "article_data_hash" : {
      "prop" : "article_data_hash",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "c1890cda263e4d010c5292e71f03fbcca8e13aa3a5e703e6efcc2966dad482df"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240502"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "extract_gnews_articles_hashing_subprocess"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13471825071552"
    }
  },
  "taskAppId" : "815_2431",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "resourceParametersHelper" : {
    "resourceMap" : {
      "DATASOURCE" : {
        "5" : {
          "resourceType" : "DATASOURCE",
          "type" : "POSTGRESQL",
          "connectionParams" : "{\"user\":\"root\",\"password\":\"******\",\"address\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432\",\"database\":\"gnews_article_hash_db\",\"jdbcUrl\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432/gnews_article_hash_db\",\"driverClassName\":\"org.postgresql.Driver\",\"validationQuery\":\"select version()\",\"other\":{\"password\":\"****\"}}",
          "DATASOURCE" : null
        }
      }
    }
  },
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"artricle_hash\",\"direct\":\"IN\",\"type\":\"LIST\",\"value\":\"null\"},{\"prop\":\"article_data_hash\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"c1890cda263e4d010c5292e71f03fbcca8e13aa3a5e703e6efcc2966dad482df\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[INFO] 2024-05-03 08:39:49.883 +0800 - ***********************************************************************************************
[INFO] 2024-05-03 08:39:49.883 +0800 - *********************************  Load task instance plugin  *********************************
[INFO] 2024-05-03 08:39:49.884 +0800 - ***********************************************************************************************
[INFO] 2024-05-03 08:39:49.887 +0800 - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[INFO] 2024-05-03 08:39:49.888 +0800 - TenantCode: default check successfully
[INFO] 2024-05-03 08:39:49.889 +0800 - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13471825071552_14/815/2431 check successfully
[INFO] 2024-05-03 08:39:49.889 +0800 - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.sql.SqlTaskChannel successfully
[INFO] 2024-05-03 08:39:49.889 +0800 - Download resources successfully: 
ResourceContext(resourceItemMap={})
[INFO] 2024-05-03 08:39:49.892 +0800 - Download upstream files: [] successfully
[INFO] 2024-05-03 08:39:49.893 +0800 - Initialize sql task parameter {
  "localParams" : [ {
    "prop" : "artricle_hash",
    "direct" : "OUT",
    "type" : "LIST",
    "value" : ""
  } ],
  "varPool" : null,
  "type" : "POSTGRESQL",
  "datasource" : 5,
  "sql" : "SELECT hash\nFROM article_hashes\nWHERE hash = llll\n",
  "sqlType" : 0,
  "sendEmail" : null,
  "displayRows" : 10,
  "udfs" : null,
  "showType" : null,
  "connParams" : null,
  "preStatements" : [ "CREATE TABLE IF NOT EXISTS article_hashes (\n\t    hash TEXT NOT NULL\n\t);" ],
  "postStatements" : [ ],
  "groupId" : 0,
  "title" : null,
  "limit" : 0
}
[INFO] 2024-05-03 08:39:49.894 +0800 - Task plugin instance: SQL create successfully
[INFO] 2024-05-03 08:39:49.899 +0800 - Success initialized task plugin instance successfully
[INFO] 2024-05-03 08:39:49.899 +0800 - Set taskVarPool: [{"prop":"artricle_hash","direct":"IN","type":"LIST","value":"null"},{"prop":"article_data_hash","direct":"IN","type":"VARCHAR","value":"c1890cda263e4d010c5292e71f03fbcca8e13aa3a5e703e6efcc2966dad482df"}] successfully
[INFO] 2024-05-03 08:39:49.899 +0800 - ***********************************************************************************************
[INFO] 2024-05-03 08:39:49.899 +0800 - *********************************  Execute task instance  *************************************
[INFO] 2024-05-03 08:39:49.899 +0800 - ***********************************************************************************************
[INFO] 2024-05-03 08:39:49.900 +0800 - Full sql parameters: SqlParameters{type='POSTGRESQL', datasource=5, sql='SELECT hash
FROM article_hashes
WHERE hash = llll
', sqlType=0, sendEmail=null, displayRows=10, limit=0, udfs='null', showType='null', connParams='null', groupId='0', title='null', preStatements=[CREATE TABLE IF NOT EXISTS article_hashes (
	    hash TEXT NOT NULL
	);], postStatements=[]}
[INFO] 2024-05-03 08:39:49.900 +0800 - sql type : POSTGRESQL, datasource : 5, sql : SELECT hash
FROM article_hashes
WHERE hash = llll
 , localParams : [Property{prop='artricle_hash', direct=OUT, type=LIST, value=''}],udfs : null,showType : null,connParams : null,varPool : [Property{prop='artricle_hash', direct=IN, type=LIST, value='null'}, Property{prop='article_data_hash', direct=IN, type=VARCHAR, value='c1890cda263e4d010c5292e71f03fbcca8e13aa3a5e703e6efcc2966dad482df'}] ,query max result limit  0
[INFO] 2024-05-03 08:39:49.901 +0800 - after replace sql , preparing : SELECT hash
FROM article_hashes
WHERE hash = llll

[INFO] 2024-05-03 08:39:49.902 +0800 - Sql Params are replaced sql , parameters:
[INFO] 2024-05-03 08:39:49.905 +0800 - after replace sql , preparing : CREATE TABLE IF NOT EXISTS article_hashes (
	    hash TEXT NOT NULL
	);
[INFO] 2024-05-03 08:39:49.906 +0800 - Sql Params are replaced sql , parameters:
[INFO] 2024-05-03 08:39:49.906 +0800 - can't find udf function resource
[WARN] 2024-05-03 08:39:49.907 +0800 - Connect strings must start with jdbc:snowflake://
[INFO] 2024-05-03 08:39:49.934 +0800 - prepare statement replace sql : CREATE TABLE IF NOT EXISTS article_hashes (
	    hash TEXT NOT NULL
	);, sql parameters : {}
[INFO] 2024-05-03 08:39:49.935 +0800 - pre statement execute update result: 0, for sql: CREATE TABLE IF NOT EXISTS article_hashes (
	    hash TEXT NOT NULL
	);
[INFO] 2024-05-03 08:39:49.936 +0800 - prepare statement replace sql : SELECT hash
FROM article_hashes
WHERE hash = llll
, sql parameters : {}
[INFO] 2024-05-03 08:39:49.936 +0800 - main statement execute query, for sql: SELECT hash
FROM article_hashes
WHERE hash = llll

[ERROR] 2024-05-03 08:39:49.939 +0800 - execute sql error: ERROR: column "llll" does not exist
  Position: 46
[ERROR] 2024-05-03 08:39:49.940 +0800 - sql task error
org.postgresql.util.PSQLException: ERROR: column "llll" does not exist
  Position: 46
	at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2676)
	at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2366)
	at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:356)
	at org.postgresql.jdbc.PgStatement.executeInternal(PgStatement.java:490)
	at org.postgresql.jdbc.PgStatement.execute(PgStatement.java:408)
	at org.postgresql.jdbc.PgPreparedStatement.executeWithFlags(PgPreparedStatement.java:181)
	at org.postgresql.jdbc.PgPreparedStatement.executeQuery(PgPreparedStatement.java:133)
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.executeQuery(SqlTask.java:317)
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.executeFuncAndSql(SqlTask.java:205)
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.handle(SqlTask.java:159)
	at org.apache.dolphinscheduler.server.worker.runner.DefaultWorkerTaskExecutor.executeTask(DefaultWorkerTaskExecutor.java:54)
	at org.apache.dolphinscheduler.server.worker.runner.WorkerTaskExecutor.run(WorkerTaskExecutor.java:175)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
[ERROR] 2024-05-03 08:39:49.940 +0800 - Task execute failed, due to meet an exception
org.apache.dolphinscheduler.plugin.task.api.TaskException: Execute sql task failed
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.handle(SqlTask.java:166)
	at org.apache.dolphinscheduler.server.worker.runner.DefaultWorkerTaskExecutor.executeTask(DefaultWorkerTaskExecutor.java:54)
	at org.apache.dolphinscheduler.server.worker.runner.WorkerTaskExecutor.run(WorkerTaskExecutor.java:175)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.postgresql.util.PSQLException: ERROR: column "llll" does not exist
  Position: 46
	at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2676)
	at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2366)
	at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:356)
	at org.postgresql.jdbc.PgStatement.executeInternal(PgStatement.java:490)
	at org.postgresql.jdbc.PgStatement.execute(PgStatement.java:408)
	at org.postgresql.jdbc.PgPreparedStatement.executeWithFlags(PgPreparedStatement.java:181)
	at org.postgresql.jdbc.PgPreparedStatement.executeQuery(PgPreparedStatement.java:133)
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.executeQuery(SqlTask.java:317)
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.executeFuncAndSql(SqlTask.java:205)
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.handle(SqlTask.java:159)
	... 5 common frames omitted
[INFO] 2024-05-03 08:39:49.940 +0800 - Get appIds from worker 172.18.1.1:1234, taskLogPath: /opt/dolphinscheduler/logs/20240503/13471825071552/14/815/2431.log
[INFO] 2024-05-03 08:39:49.940 +0800 - Start finding appId in /opt/dolphinscheduler/logs/20240503/13471825071552/14/815/2431.log, fetch way: log 
[INFO] 2024-05-03 08:39:49.940 +0800 - The appId is empty
[INFO] 2024-05-03 08:39:49.941 +0800 - Cancel the task successfully
[INFO] 2024-05-03 08:39:49.944 +0800 - Get a exception when execute the task, will send the task status: FAILURE to master: 172.18.1.1:1234
[INFO] 2024-05-03 08:39:49.945 +0800 - FINALIZE_SESSION
