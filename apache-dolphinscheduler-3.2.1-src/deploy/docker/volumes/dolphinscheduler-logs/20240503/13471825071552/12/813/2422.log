[INFO] 2024-05-03 08:31:55.892 +0800 - ***********************************************************************************************
[INFO] 2024-05-03 08:31:55.894 +0800 - *********************************  Initialize task context  ***********************************
[INFO] 2024-05-03 08:31:55.894 +0800 - ***********************************************************************************************
[INFO] 2024-05-03 08:31:55.894 +0800 - Begin to initialize task
[INFO] 2024-05-03 08:31:55.894 +0800 - Set task startTime: 1714696315894
[INFO] 2024-05-03 08:31:55.894 +0800 - Set task appId: 813_2422
[INFO] 2024-05-03 08:31:55.894 +0800 - End initialize task {
  "taskInstanceId" : 2422,
  "taskName" : "check if it exists in the database",
  "firstSubmitTime" : 1714696315871,
  "startTime" : 1714696315894,
  "taskType" : "SQL",
  "workflowInstanceHost" : "172.18.0.12:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240503/13471825071552/12/813/2422.log",
  "processId" : 0,
  "processDefineCode" : 13471825071552,
  "processDefineVersion" : 12,
  "processInstanceId" : 813,
  "scheduleTime" : 0,
  "executorId" : 1,
  "cmdTypeIfComplement" : 7,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[{\"prop\":\"hash\",\"direct\":\"OUT\",\"type\":\"LIST\",\"value\":\"\"}],\"resourceList\":[],\"type\":\"POSTGRESQL\",\"datasource\":5,\"sql\":\"SELECT hash as HASH\\nFROM article_hashes\\nWHERE HASH = ${article_data_hash}\\n\",\"sqlType\":\"0\",\"preStatements\":[\"CREATE TABLE IF NOT EXISTS article_hashes (\\n\\t    hash TEXT NOT NULL\\n\\t);\"],\"postStatements\":[],\"displayRows\":10}",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "check if it exists in the database"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240503"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "2422"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13472192399424"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240503083155"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "813"
    },
    "article_data_hash" : {
      "prop" : "article_data_hash",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "c1890cda263e4d010c5292e71f03fbcca8e13aa3a5e703e6efcc2966dad482df"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240502"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "extract_gnews_articles_hashing_subprocess"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13471825071552"
    },
    "hash" : {
      "prop" : "hash",
      "direct" : "IN",
      "type" : "LIST",
      "value" : "c1890cda263e4d010c5292e71f03fbcca8e13aa3a5e703e6efcc2966dad482df"
    }
  },
  "taskAppId" : "813_2422",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "resourceParametersHelper" : {
    "resourceMap" : {
      "DATASOURCE" : {
        "5" : {
          "resourceType" : "DATASOURCE",
          "type" : "POSTGRESQL",
          "connectionParams" : "{\"user\":\"root\",\"password\":\"******\",\"address\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432\",\"database\":\"gnews_article_hash_db\",\"jdbcUrl\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432/gnews_article_hash_db\",\"driverClassName\":\"org.postgresql.Driver\",\"validationQuery\":\"select version()\",\"other\":{\"password\":\"****\"}}",
          "DATASOURCE" : null
        }
      }
    }
  },
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"article_data_hash\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"c1890cda263e4d010c5292e71f03fbcca8e13aa3a5e703e6efcc2966dad482df\"},{\"prop\":\"hash\",\"direct\":\"IN\",\"type\":\"LIST\",\"value\":\"c1890cda263e4d010c5292e71f03fbcca8e13aa3a5e703e6efcc2966dad482df\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[INFO] 2024-05-03 08:31:55.895 +0800 - ***********************************************************************************************
[INFO] 2024-05-03 08:31:55.895 +0800 - *********************************  Load task instance plugin  *********************************
[INFO] 2024-05-03 08:31:55.895 +0800 - ***********************************************************************************************
[INFO] 2024-05-03 08:31:55.903 +0800 - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[INFO] 2024-05-03 08:31:55.904 +0800 - TenantCode: default check successfully
[INFO] 2024-05-03 08:31:55.904 +0800 - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13471825071552_12/813/2422 check successfully
[INFO] 2024-05-03 08:31:55.905 +0800 - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.sql.SqlTaskChannel successfully
[INFO] 2024-05-03 08:31:55.905 +0800 - Download resources successfully: 
ResourceContext(resourceItemMap={})
[INFO] 2024-05-03 08:31:55.905 +0800 - Download upstream files: [] successfully
[INFO] 2024-05-03 08:31:55.906 +0800 - Initialize sql task parameter {
  "localParams" : [ {
    "prop" : "hash",
    "direct" : "OUT",
    "type" : "LIST",
    "value" : ""
  } ],
  "varPool" : null,
  "type" : "POSTGRESQL",
  "datasource" : 5,
  "sql" : "SELECT hash as HASH\nFROM article_hashes\nWHERE HASH = ${article_data_hash}\n",
  "sqlType" : 0,
  "sendEmail" : null,
  "displayRows" : 10,
  "udfs" : null,
  "showType" : null,
  "connParams" : null,
  "preStatements" : [ "CREATE TABLE IF NOT EXISTS article_hashes (\n\t    hash TEXT NOT NULL\n\t);" ],
  "postStatements" : [ ],
  "groupId" : 0,
  "title" : null,
  "limit" : 0
}
[INFO] 2024-05-03 08:31:55.906 +0800 - Task plugin instance: SQL create successfully
[INFO] 2024-05-03 08:31:55.907 +0800 - Success initialized task plugin instance successfully
[INFO] 2024-05-03 08:31:55.907 +0800 - Set taskVarPool: [{"prop":"article_data_hash","direct":"IN","type":"VARCHAR","value":"c1890cda263e4d010c5292e71f03fbcca8e13aa3a5e703e6efcc2966dad482df"},{"prop":"hash","direct":"IN","type":"LIST","value":"c1890cda263e4d010c5292e71f03fbcca8e13aa3a5e703e6efcc2966dad482df"}] successfully
[INFO] 2024-05-03 08:31:55.907 +0800 - ***********************************************************************************************
[INFO] 2024-05-03 08:31:55.907 +0800 - *********************************  Execute task instance  *************************************
[INFO] 2024-05-03 08:31:55.907 +0800 - ***********************************************************************************************
[INFO] 2024-05-03 08:31:55.907 +0800 - Full sql parameters: SqlParameters{type='POSTGRESQL', datasource=5, sql='SELECT hash as HASH
FROM article_hashes
WHERE HASH = ${article_data_hash}
', sqlType=0, sendEmail=null, displayRows=10, limit=0, udfs='null', showType='null', connParams='null', groupId='0', title='null', preStatements=[CREATE TABLE IF NOT EXISTS article_hashes (
	    hash TEXT NOT NULL
	);], postStatements=[]}
[INFO] 2024-05-03 08:31:55.908 +0800 - sql type : POSTGRESQL, datasource : 5, sql : SELECT hash as HASH
FROM article_hashes
WHERE HASH = ${article_data_hash}
 , localParams : [Property{prop='hash', direct=OUT, type=LIST, value=''}],udfs : null,showType : null,connParams : null,varPool : [Property{prop='article_data_hash', direct=IN, type=VARCHAR, value='c1890cda263e4d010c5292e71f03fbcca8e13aa3a5e703e6efcc2966dad482df'}, Property{prop='hash', direct=IN, type=LIST, value='c1890cda263e4d010c5292e71f03fbcca8e13aa3a5e703e6efcc2966dad482df'}] ,query max result limit  0
[INFO] 2024-05-03 08:31:55.909 +0800 - setSqlParamsMap: Property with paramName: article_data_hash put in sqlParamsMap of content SELECT hash as HASH
FROM article_hashes
WHERE HASH = ${article_data_hash}
 successfully.
[INFO] 2024-05-03 08:31:55.909 +0800 - after replace sql , preparing : SELECT hash as HASH
FROM article_hashes
WHERE HASH = ?

[INFO] 2024-05-03 08:31:55.909 +0800 - Sql Params are replaced sql , parameters:c1890cda263e4d010c5292e71f03fbcca8e13aa3a5e703e6efcc2966dad482df(VARCHAR)
[INFO] 2024-05-03 08:31:55.909 +0800 - after replace sql , preparing : CREATE TABLE IF NOT EXISTS article_hashes (
	    hash TEXT NOT NULL
	);
[INFO] 2024-05-03 08:31:55.910 +0800 - Sql Params are replaced sql , parameters:
[INFO] 2024-05-03 08:31:55.910 +0800 - can't find udf function resource
[WARN] 2024-05-03 08:31:55.910 +0800 - Connect strings must start with jdbc:snowflake://
[INFO] 2024-05-03 08:31:55.952 +0800 - prepare statement replace sql : CREATE TABLE IF NOT EXISTS article_hashes (
	    hash TEXT NOT NULL
	);, sql parameters : {}
[INFO] 2024-05-03 08:31:55.955 +0800 - pre statement execute update result: 0, for sql: CREATE TABLE IF NOT EXISTS article_hashes (
	    hash TEXT NOT NULL
	);
[INFO] 2024-05-03 08:31:55.955 +0800 - prepare statement replace sql : SELECT hash as HASH
FROM article_hashes
WHERE HASH = ?
, sql parameters : {1=Property{prop='article_data_hash', direct=IN, type=VARCHAR, value='c1890cda263e4d010c5292e71f03fbcca8e13aa3a5e703e6efcc2966dad482df'}}
[INFO] 2024-05-03 08:31:55.955 +0800 - main statement execute query, for sql: SELECT hash as HASH
FROM article_hashes
WHERE HASH = ?

[INFO] 2024-05-03 08:31:55.960 +0800 - display sql result 1 rows as follows:
[INFO] 2024-05-03 08:31:55.960 +0800 - row 1 : {"hash":"c1890cda263e4d010c5292e71f03fbcca8e13aa3a5e703e6efcc2966dad482df"}
[INFO] 2024-05-03 08:31:55.960 +0800 - ***********************************************************************************************
[INFO] 2024-05-03 08:31:55.960 +0800 - *********************************  Finalize task instance  ************************************
[INFO] 2024-05-03 08:31:55.960 +0800 - ***********************************************************************************************
[ERROR] 2024-05-03 08:31:55.961 +0800 - Task execute failed, due to meet an exception
java.lang.IllegalStateException: Duplicate key Property{prop='hash', direct=IN, type=LIST, value='c1890cda263e4d010c5292e71f03fbcca8e13aa3a5e703e6efcc2966dad482df'}
	at java.util.stream.Collectors.lambda$throwingMerger$0(Collectors.java:133)
	at java.util.HashMap.merge(HashMap.java:1255)
	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1320)
	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169)
	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1384)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)
	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:566)
	at org.apache.dolphinscheduler.server.worker.utils.TaskFilesTransferUtils.uploadOutputFiles(TaskFilesTransferUtils.java:75)
	at org.apache.dolphinscheduler.server.worker.runner.WorkerTaskExecutor.sendTaskResult(WorkerTaskExecutor.java:288)
	at org.apache.dolphinscheduler.server.worker.runner.WorkerTaskExecutor.afterExecute(WorkerTaskExecutor.java:108)
	at org.apache.dolphinscheduler.server.worker.runner.DefaultWorkerTaskExecutor.afterExecute(DefaultWorkerTaskExecutor.java:59)
	at org.apache.dolphinscheduler.server.worker.runner.WorkerTaskExecutor.run(WorkerTaskExecutor.java:178)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
[INFO] 2024-05-03 08:31:55.961 +0800 - Get appIds from worker 172.18.1.1:1234, taskLogPath: /opt/dolphinscheduler/logs/20240503/13471825071552/12/813/2422.log
[INFO] 2024-05-03 08:31:55.961 +0800 - Start finding appId in /opt/dolphinscheduler/logs/20240503/13471825071552/12/813/2422.log, fetch way: log 
[INFO] 2024-05-03 08:31:55.961 +0800 - The appId is empty
[INFO] 2024-05-03 08:31:55.961 +0800 - Cancel the task successfully
[INFO] 2024-05-03 08:31:55.971 +0800 - Get a exception when execute the task, will send the task status: FAILURE to master: 172.18.1.1:1234
[INFO] 2024-05-03 08:31:55.972 +0800 - FINALIZE_SESSION
