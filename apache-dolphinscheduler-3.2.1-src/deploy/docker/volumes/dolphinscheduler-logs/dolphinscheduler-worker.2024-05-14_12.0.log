[WI-0][TI-0] - [INFO] 2024-05-14 12:18:47.066 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7023121387283238 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 12:19:00.170 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7882352941176471 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 12:19:06.224 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7787356321839081 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 12:19:09.255 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7732919254658385 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 12:19:14.286 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7774566473988439 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 12:19:23.355 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.731638418079096 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 12:19:50.617 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7655786350148368 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 12:19:54.685 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7310924369747899 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 12:20:10.773 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7859327217125383 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 12:20:11.868 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7692307692307692 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 12:20:16.968 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7904761904761906 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 12:20:18.019 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.738872403560831 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 12:20:22.052 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7031700288184438 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 12:20:23.064 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7201166180758017 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 12:20:54.207 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7189349112426036 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 12:20:58.274 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8092485549132948 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 12:20:59.286 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7774566473988439 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 12:21:04.321 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8416149068322981 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 12:21:06.429 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7253731343283583 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 12:21:09.511 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8342857142857143 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 12:21:13.583 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.717201166180758 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 12:21:14.616 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8055555555555556 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 12:21:30.689 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7826086956521738 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 12:21:35.731 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7728613569321534 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 12:21:37.834 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.717948717948718 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 12:21:42.868 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7454545454545455 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 12:21:45.982 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7667638483965015 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 12:21:52.100 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7740963855421686 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 12:21:54.149 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7074626865671642 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 12:21:57.202 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7478005865102639 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 12:22:02.255 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7118155619596542 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 12:38:23.191 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7514450867052024 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 12:38:24.234 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7295081967213114 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 12:38:29.253 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7565217391304347 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 12:40:16.164 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=4035, taskName=Extract Reddit Data, firstSubmitTime=1715661616126, startTime=0, taskType=PYTHON, workflowInstanceHost=172.18.0.16:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13045665829504, processDefineVersion=20, appIds=null, processInstanceId=1118, scheduleTime=0, globalParams=[{"prop":"subreddit","direct":"IN","type":"VARCHAR","value":"singapore"},{"prop":"limit","direct":"IN","type":"VARCHAR","value":"3"}], executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[],"rawScript":"import praw\nimport json\n\nclass RedditPostDataExtractor:\n    def __init__(self):\n        self.data = []\n\n    def extract_data(self, hot_posts):\n        if hot_posts:\n            for post in hot_posts:\n                post.comments.replace_more(limit=None)\n                # initialise a dictionary to contain the data of the post\n                post_data = {}\n\n                # get the relevant post's data and store it inside post_data\n\n                # get the poster's name\n                if post.author is not None:\n                    post_data['author'] = post.author.name\n                else:\n                    post_data['author'] = '[deleted]' # if the user was deleted, post.author will return None. This line will catch that scenario and instead provide the value 'deleted'\n\n                # get the unix time in which the post was created\n                post_data['unix_time'] = post.created_utc\n                post_data['permalink'] = post.permalink\n                post_data['score'] = post.score\n                post_data['post_title'] = post.title\n                post_data['body'] = post.selftext\n\n                # get the unique name of the post (name refers to the id of the post prefixed with t3_)\n                # t3 represents that it is a post\n                post_data['name'] = post.name\n\n                # store the posts data in the dictionary where the name is used as the key\n                self.data.append(post_data)\n\n                # extract the comments from the post\n                comments = post.comments.list()\n\n                # extract the data in the comments and store them inside the dictionary\n                self.extract_comments_data(comments)\n        \n        return self.data\n\n    def extract_comments_data(self, comments):\n        if comments:\n            for comment in comments:\n                # initialise a dictionary to contain the data of the comment\n                comment_data = {}\n\n\n                # get the relevant post's data and store it inside post_data\n\n                # get the commenter name\n                if comment.author is not None:\n                    comment_data['author'] = comment.author.name\n                else:\n                    comment_data['author'] = '[deleted]' # if the user was deleted, comment.author will return None, this line will catch that scenario and instead provide the value 'deleted'\n\n                # get the unix time in which the comment was created\n                comment_data['unix_time'] = comment.created_utc\n                comment_data['permalink'] = comment.permalink\n                comment_data['score'] = comment.score\n                comment_data['post_title'] = comment.submission.title\n                comment_data['body'] = comment.body\n\n                # get the unique name of the comment (name refers to the id of the post prefixed with t1_)\n                # t1 represents that it is a post\n                comment_data['name'] = comment.name\n\n                # store the comment's data in the dictionary where the name is used as the key\n                self.data.append(comment_data)\n\n                # extract the comment's replies from the post\n                # replies = comment.replies\n\n                # extract the data in the comments and store them inside the dictionary\n                # self.extract_comments_data(replies)\n        \n        return\n    \ndef get_hot_posts(reddit_instance, subreddit_name, limit):\n    # Define the subreddit\n    subreddit = reddit_instance.subreddit(subreddit_name)\n\n    # Get hot posts from the subreddit\n    hot_posts = subreddit.hot(limit=limit)\n\n    # Filter out posts that are not pinned\n    filtered_posts = [post for post in hot_posts if not post.stickied]\n    return filtered_posts\n\n\n# initialize Reddit instance\nreddit = praw.Reddit(client_id='hM2BAD8XKakgkVdR2V2S-Q',\n                     client_secret='dWBfOf7Ed2WxqVavqQIcZ6V72QyBLg',\n                     user_agent='Prawlingv1')\n\n\n# choose the subreddit to extract data from\nsubreddit = \"${subreddit}\"\nlimit = ${limit}\n\n# get hot posts from the subreddit\nhot_posts = get_hot_posts(reddit, subreddit, limit)\n\n# initialise a reddit data extractor object\ndata_extractor = RedditPostDataExtractor()\n\n# extract data from the hot posts from r/singapore\ndata = data_extractor.extract_data(hot_posts)\n\nwith open(\"/local_storage/reddit/in/${system.workflow.instance.id}-${system.datetime}.json\", \"w\") as fp:\n    json.dump(data, fp, indent=4)","resourceList":[]}, environmentConfig=export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={GNEWS_HOME=Property{prop='GNEWS_HOME', direct=IN, type=VARCHAR, value='/local_storage/google_news'}, system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='Extract Reddit Data'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240514'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='4035'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13045662268160'}, subreddit=Property{prop='subreddit', direct=IN, type=VARCHAR, value='singapore'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240514124016'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='1118'}, limit=Property{prop='limit', direct=IN, type=VARCHAR, value='3'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240513'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='extract_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13045665829504'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=null, dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-1118][TI-4035] - [INFO] 2024-05-14 12:40:16.167 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: Extract Reddit Data to wait queue success
[WI-1118][TI-4035] - [INFO] 2024-05-14 12:40:16.167 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-1118][TI-4035] - [INFO] 2024-05-14 12:40:16.171 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-1118][TI-4035] - [INFO] 2024-05-14 12:40:16.172 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-1118][TI-4035] - [INFO] 2024-05-14 12:40:16.172 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-1118][TI-4035] - [INFO] 2024-05-14 12:40:16.172 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1715661616172
[WI-1118][TI-4035] - [INFO] 2024-05-14 12:40:16.173 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 1118_4035
[WI-1118][TI-4035] - [INFO] 2024-05-14 12:40:16.179 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 4035,
  "taskName" : "Extract Reddit Data",
  "firstSubmitTime" : 1715661616126,
  "startTime" : 1715661616172,
  "taskType" : "PYTHON",
  "workflowInstanceHost" : "172.18.0.16:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240514/13045665829504/20/1118/4035.log",
  "processId" : 0,
  "processDefineCode" : 13045665829504,
  "processDefineVersion" : 20,
  "processInstanceId" : 1118,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"subreddit\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"singapore\"},{\"prop\":\"limit\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"3\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[],\"rawScript\":\"import praw\\nimport json\\n\\nclass RedditPostDataExtractor:\\n    def __init__(self):\\n        self.data = []\\n\\n    def extract_data(self, hot_posts):\\n        if hot_posts:\\n            for post in hot_posts:\\n                post.comments.replace_more(limit=None)\\n                # initialise a dictionary to contain the data of the post\\n                post_data = {}\\n\\n                # get the relevant post's data and store it inside post_data\\n\\n                # get the poster's name\\n                if post.author is not None:\\n                    post_data['author'] = post.author.name\\n                else:\\n                    post_data['author'] = '[deleted]' # if the user was deleted, post.author will return None. This line will catch that scenario and instead provide the value 'deleted'\\n\\n                # get the unix time in which the post was created\\n                post_data['unix_time'] = post.created_utc\\n                post_data['permalink'] = post.permalink\\n                post_data['score'] = post.score\\n                post_data['post_title'] = post.title\\n                post_data['body'] = post.selftext\\n\\n                # get the unique name of the post (name refers to the id of the post prefixed with t3_)\\n                # t3 represents that it is a post\\n                post_data['name'] = post.name\\n\\n                # store the posts data in the dictionary where the name is used as the key\\n                self.data.append(post_data)\\n\\n                # extract the comments from the post\\n                comments = post.comments.list()\\n\\n                # extract the data in the comments and store them inside the dictionary\\n                self.extract_comments_data(comments)\\n        \\n        return self.data\\n\\n    def extract_comments_data(self, comments):\\n        if comments:\\n            for comment in comments:\\n                # initialise a dictionary to contain the data of the comment\\n                comment_data = {}\\n\\n\\n                # get the relevant post's data and store it inside post_data\\n\\n                # get the commenter name\\n                if comment.author is not None:\\n                    comment_data['author'] = comment.author.name\\n                else:\\n                    comment_data['author'] = '[deleted]' # if the user was deleted, comment.author will return None, this line will catch that scenario and instead provide the value 'deleted'\\n\\n                # get the unix time in which the comment was created\\n                comment_data['unix_time'] = comment.created_utc\\n                comment_data['permalink'] = comment.permalink\\n                comment_data['score'] = comment.score\\n                comment_data['post_title'] = comment.submission.title\\n                comment_data['body'] = comment.body\\n\\n                # get the unique name of the comment (name refers to the id of the post prefixed with t1_)\\n                # t1 represents that it is a post\\n                comment_data['name'] = comment.name\\n\\n                # store the comment's data in the dictionary where the name is used as the key\\n                self.data.append(comment_data)\\n\\n                # extract the comment's replies from the post\\n                # replies = comment.replies\\n\\n                # extract the data in the comments and store them inside the dictionary\\n                # self.extract_comments_data(replies)\\n        \\n        return\\n    \\ndef get_hot_posts(reddit_instance, subreddit_name, limit):\\n    # Define the subreddit\\n    subreddit = reddit_instance.subreddit(subreddit_name)\\n\\n    # Get hot posts from the subreddit\\n    hot_posts = subreddit.hot(limit=limit)\\n\\n    # Filter out posts that are not pinned\\n    filtered_posts = [post for post in hot_posts if not post.stickied]\\n    return filtered_posts\\n\\n\\n# initialize Reddit instance\\nreddit = praw.Reddit(client_id='hM2BAD8XKakgkVdR2V2S-Q',\\n                     client_secret='dWBfOf7Ed2WxqVavqQIcZ6V72QyBLg',\\n                     user_agent='Prawlingv1')\\n\\n\\n# choose the subreddit to extract data from\\nsubreddit = \\\"${subreddit}\\\"\\nlimit = ${limit}\\n\\n# get hot posts from the subreddit\\nhot_posts = get_hot_posts(reddit, subreddit, limit)\\n\\n# initialise a reddit data extractor object\\ndata_extractor = RedditPostDataExtractor()\\n\\n# extract data from the hot posts from r/singapore\\ndata = data_extractor.extract_data(hot_posts)\\n\\nwith open(\\\"/local_storage/reddit/in/${system.workflow.instance.id}-${system.datetime}.json\\\", \\\"w\\\") as fp:\\n    json.dump(data, fp, indent=4)\",\"resourceList\":[]}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "GNEWS_HOME" : {
      "prop" : "GNEWS_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/google_news"
    },
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "Extract Reddit Data"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240514"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "4035"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13045662268160"
    },
    "subreddit" : {
      "prop" : "subreddit",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "singapore"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240514124016"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1118"
    },
    "limit" : {
      "prop" : "limit",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "3"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240513"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "extract_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13045665829504"
    }
  },
  "taskAppId" : "1118_4035",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-1118][TI-4035] - [INFO] 2024-05-14 12:40:16.181 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-1118][TI-4035] - [INFO] 2024-05-14 12:40:16.181 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-1118][TI-4035] - [INFO] 2024-05-14 12:40:16.181 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-1118][TI-4035] - [INFO] 2024-05-14 12:40:16.201 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-1118][TI-4035] - [INFO] 2024-05-14 12:40:16.204 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-1118][TI-4035] - [INFO] 2024-05-14 12:40:16.205 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13045665829504_20/1118/4035 check successfully
[WI-1118][TI-4035] - [INFO] 2024-05-14 12:40:16.206 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.python.PythonTaskChannel successfully
[WI-1118][TI-4035] - [INFO] 2024-05-14 12:40:16.207 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-1118][TI-4035] - [INFO] 2024-05-14 12:40:16.207 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-1118][TI-4035] - [INFO] 2024-05-14 12:40:16.214 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: PYTHON create successfully
[WI-1118][TI-4035] - [INFO] 2024-05-14 12:40:16.215 +0800 o.a.d.p.t.p.PythonTask:[75] - Initialize python task params {
  "localParams" : [ ],
  "varPool" : null,
  "rawScript" : "import praw\nimport json\n\nclass RedditPostDataExtractor:\n    def __init__(self):\n        self.data = []\n\n    def extract_data(self, hot_posts):\n        if hot_posts:\n            for post in hot_posts:\n                post.comments.replace_more(limit=None)\n                # initialise a dictionary to contain the data of the post\n                post_data = {}\n\n                # get the relevant post's data and store it inside post_data\n\n                # get the poster's name\n                if post.author is not None:\n                    post_data['author'] = post.author.name\n                else:\n                    post_data['author'] = '[deleted]' # if the user was deleted, post.author will return None. This line will catch that scenario and instead provide the value 'deleted'\n\n                # get the unix time in which the post was created\n                post_data['unix_time'] = post.created_utc\n                post_data['permalink'] = post.permalink\n                post_data['score'] = post.score\n                post_data['post_title'] = post.title\n                post_data['body'] = post.selftext\n\n                # get the unique name of the post (name refers to the id of the post prefixed with t3_)\n                # t3 represents that it is a post\n                post_data['name'] = post.name\n\n                # store the posts data in the dictionary where the name is used as the key\n                self.data.append(post_data)\n\n                # extract the comments from the post\n                comments = post.comments.list()\n\n                # extract the data in the comments and store them inside the dictionary\n                self.extract_comments_data(comments)\n        \n        return self.data\n\n    def extract_comments_data(self, comments):\n        if comments:\n            for comment in comments:\n                # initialise a dictionary to contain the data of the comment\n                comment_data = {}\n\n\n                # get the relevant post's data and store it inside post_data\n\n                # get the commenter name\n                if comment.author is not None:\n                    comment_data['author'] = comment.author.name\n                else:\n                    comment_data['author'] = '[deleted]' # if the user was deleted, comment.author will return None, this line will catch that scenario and instead provide the value 'deleted'\n\n                # get the unix time in which the comment was created\n                comment_data['unix_time'] = comment.created_utc\n                comment_data['permalink'] = comment.permalink\n                comment_data['score'] = comment.score\n                comment_data['post_title'] = comment.submission.title\n                comment_data['body'] = comment.body\n\n                # get the unique name of the comment (name refers to the id of the post prefixed with t1_)\n                # t1 represents that it is a post\n                comment_data['name'] = comment.name\n\n                # store the comment's data in the dictionary where the name is used as the key\n                self.data.append(comment_data)\n\n                # extract the comment's replies from the post\n                # replies = comment.replies\n\n                # extract the data in the comments and store them inside the dictionary\n                # self.extract_comments_data(replies)\n        \n        return\n    \ndef get_hot_posts(reddit_instance, subreddit_name, limit):\n    # Define the subreddit\n    subreddit = reddit_instance.subreddit(subreddit_name)\n\n    # Get hot posts from the subreddit\n    hot_posts = subreddit.hot(limit=limit)\n\n    # Filter out posts that are not pinned\n    filtered_posts = [post for post in hot_posts if not post.stickied]\n    return filtered_posts\n\n\n# initialize Reddit instance\nreddit = praw.Reddit(client_id='hM2BAD8XKakgkVdR2V2S-Q',\n                     client_secret='dWBfOf7Ed2WxqVavqQIcZ6V72QyBLg',\n                     user_agent='Prawlingv1')\n\n\n# choose the subreddit to extract data from\nsubreddit = \"${subreddit}\"\nlimit = ${limit}\n\n# get hot posts from the subreddit\nhot_posts = get_hot_posts(reddit, subreddit, limit)\n\n# initialise a reddit data extractor object\ndata_extractor = RedditPostDataExtractor()\n\n# extract data from the hot posts from r/singapore\ndata = data_extractor.extract_data(hot_posts)\n\nwith open(\"/local_storage/reddit/in/${system.workflow.instance.id}-${system.datetime}.json\", \"w\") as fp:\n    json.dump(data, fp, indent=4)",
  "resourceList" : [ ]
}
[WI-1118][TI-4035] - [INFO] 2024-05-14 12:40:16.216 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-1118][TI-4035] - [INFO] 2024-05-14 12:40:16.217 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: null successfully
[WI-1118][TI-4035] - [INFO] 2024-05-14 12:40:16.217 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-1118][TI-4035] - [INFO] 2024-05-14 12:40:16.217 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-1118][TI-4035] - [INFO] 2024-05-14 12:40:16.217 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-1118][TI-4035] - [INFO] 2024-05-14 12:40:16.217 +0800 o.a.d.p.t.p.PythonTask:[165] - raw python script : import praw
import json

class RedditPostDataExtractor:
    def __init__(self):
        self.data = []

    def extract_data(self, hot_posts):
        if hot_posts:
            for post in hot_posts:
                post.comments.replace_more(limit=None)
                # initialise a dictionary to contain the data of the post
                post_data = {}

                # get the relevant post's data and store it inside post_data

                # get the poster's name
                if post.author is not None:
                    post_data['author'] = post.author.name
                else:
                    post_data['author'] = '[deleted]' # if the user was deleted, post.author will return None. This line will catch that scenario and instead provide the value 'deleted'

                # get the unix time in which the post was created
                post_data['unix_time'] = post.created_utc
                post_data['permalink'] = post.permalink
                post_data['score'] = post.score
                post_data['post_title'] = post.title
                post_data['body'] = post.selftext

                # get the unique name of the post (name refers to the id of the post prefixed with t3_)
                # t3 represents that it is a post
                post_data['name'] = post.name

                # store the posts data in the dictionary where the name is used as the key
                self.data.append(post_data)

                # extract the comments from the post
                comments = post.comments.list()

                # extract the data in the comments and store them inside the dictionary
                self.extract_comments_data(comments)
        
        return self.data

    def extract_comments_data(self, comments):
        if comments:
            for comment in comments:
                # initialise a dictionary to contain the data of the comment
                comment_data = {}


                # get the relevant post's data and store it inside post_data

                # get the commenter name
                if comment.author is not None:
                    comment_data['author'] = comment.author.name
                else:
                    comment_data['author'] = '[deleted]' # if the user was deleted, comment.author will return None, this line will catch that scenario and instead provide the value 'deleted'

                # get the unix time in which the comment was created
                comment_data['unix_time'] = comment.created_utc
                comment_data['permalink'] = comment.permalink
                comment_data['score'] = comment.score
                comment_data['post_title'] = comment.submission.title
                comment_data['body'] = comment.body

                # get the unique name of the comment (name refers to the id of the post prefixed with t1_)
                # t1 represents that it is a post
                comment_data['name'] = comment.name

                # store the comment's data in the dictionary where the name is used as the key
                self.data.append(comment_data)

                # extract the comment's replies from the post
                # replies = comment.replies

                # extract the data in the comments and store them inside the dictionary
                # self.extract_comments_data(replies)
        
        return
    
def get_hot_posts(reddit_instance, subreddit_name, limit):
    # Define the subreddit
    subreddit = reddit_instance.subreddit(subreddit_name)

    # Get hot posts from the subreddit
    hot_posts = subreddit.hot(limit=limit)

    # Filter out posts that are not pinned
    filtered_posts = [post for post in hot_posts if not post.stickied]
    return filtered_posts


# initialize Reddit instance
reddit = praw.Reddit(client_id='hM2BAD8XKakgkVdR2V2S-Q',
                     client_secret='dWBfOf7Ed2WxqVavqQIcZ6V72QyBLg',
                     user_agent='Prawlingv1')


# choose the subreddit to extract data from
subreddit = "${subreddit}"
limit = ${limit}

# get hot posts from the subreddit
hot_posts = get_hot_posts(reddit, subreddit, limit)

# initialise a reddit data extractor object
data_extractor = RedditPostDataExtractor()

# extract data from the hot posts from r/singapore
data = data_extractor.extract_data(hot_posts)

with open("/local_storage/reddit/in/${system.workflow.instance.id}-${system.datetime}.json", "w") as fp:
    json.dump(data, fp, indent=4)
[WI-1118][TI-4035] - [INFO] 2024-05-14 12:40:16.218 +0800 o.a.d.p.t.p.PythonTask:[131] - tenantCode :default, task dir:/tmp/dolphinscheduler/exec/process/default/13010050770016/13045665829504_20/1118/4035
[WI-1118][TI-4035] - [INFO] 2024-05-14 12:40:16.218 +0800 o.a.d.p.t.p.PythonTask:[134] - generate python script file:/tmp/dolphinscheduler/exec/process/default/13010050770016/13045665829504_20/1118/4035/py_1118_4035.py
[WI-1118][TI-4035] - [INFO] 2024-05-14 12:40:16.218 +0800 o.a.d.p.t.p.PythonTask:[141] - #-*- encoding=utf8 -*-

import praw
import json

class RedditPostDataExtractor:
    def __init__(self):
        self.data = []

    def extract_data(self, hot_posts):
        if hot_posts:
            for post in hot_posts:
                post.comments.replace_more(limit=None)
                # initialise a dictionary to contain the data of the post
                post_data = {}

                # get the relevant post's data and store it inside post_data

                # get the poster's name
                if post.author is not None:
                    post_data['author'] = post.author.name
                else:
                    post_data['author'] = '[deleted]' # if the user was deleted, post.author will return None. This line will catch that scenario and instead provide the value 'deleted'

                # get the unix time in which the post was created
                post_data['unix_time'] = post.created_utc
                post_data['permalink'] = post.permalink
                post_data['score'] = post.score
                post_data['post_title'] = post.title
                post_data['body'] = post.selftext

                # get the unique name of the post (name refers to the id of the post prefixed with t3_)
                # t3 represents that it is a post
                post_data['name'] = post.name

                # store the posts data in the dictionary where the name is used as the key
                self.data.append(post_data)

                # extract the comments from the post
                comments = post.comments.list()

                # extract the data in the comments and store them inside the dictionary
                self.extract_comments_data(comments)
        
        return self.data

    def extract_comments_data(self, comments):
        if comments:
            for comment in comments:
                # initialise a dictionary to contain the data of the comment
                comment_data = {}


                # get the relevant post's data and store it inside post_data

                # get the commenter name
                if comment.author is not None:
                    comment_data['author'] = comment.author.name
                else:
                    comment_data['author'] = '[deleted]' # if the user was deleted, comment.author will return None, this line will catch that scenario and instead provide the value 'deleted'

                # get the unix time in which the comment was created
                comment_data['unix_time'] = comment.created_utc
                comment_data['permalink'] = comment.permalink
                comment_data['score'] = comment.score
                comment_data['post_title'] = comment.submission.title
                comment_data['body'] = comment.body

                # get the unique name of the comment (name refers to the id of the post prefixed with t1_)
                # t1 represents that it is a post
                comment_data['name'] = comment.name

                # store the comment's data in the dictionary where the name is used as the key
                self.data.append(comment_data)

                # extract the comment's replies from the post
                # replies = comment.replies

                # extract the data in the comments and store them inside the dictionary
                # self.extract_comments_data(replies)
        
        return
    
def get_hot_posts(reddit_instance, subreddit_name, limit):
    # Define the subreddit
    subreddit = reddit_instance.subreddit(subreddit_name)

    # Get hot posts from the subreddit
    hot_posts = subreddit.hot(limit=limit)

    # Filter out posts that are not pinned
    filtered_posts = [post for post in hot_posts if not post.stickied]
    return filtered_posts


# initialize Reddit instance
reddit = praw.Reddit(client_id='hM2BAD8XKakgkVdR2V2S-Q',
                     client_secret='dWBfOf7Ed2WxqVavqQIcZ6V72QyBLg',
                     user_agent='Prawlingv1')


# choose the subreddit to extract data from
subreddit = "singapore"
limit = 3

# get hot posts from the subreddit
hot_posts = get_hot_posts(reddit, subreddit, limit)

# initialise a reddit data extractor object
data_extractor = RedditPostDataExtractor()

# extract data from the hot posts from r/singapore
data = data_extractor.extract_data(hot_posts)

with open("/local_storage/reddit/in/1118-20240514124016.json", "w") as fp:
    json.dump(data, fp, indent=4)
[WI-1118][TI-4035] - [INFO] 2024-05-14 12:40:16.219 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-1118][TI-4035] - [INFO] 2024-05-14 12:40:16.220 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-1118][TI-4035] - [INFO] 2024-05-14 12:40:16.220 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export PYTHON_LAUNCHER=/bin/python3.11
${PYTHON_LAUNCHER} /tmp/dolphinscheduler/exec/process/default/13010050770016/13045665829504_20/1118/4035/py_1118_4035.py
[WI-1118][TI-4035] - [INFO] 2024-05-14 12:40:16.220 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-1118][TI-4035] - [INFO] 2024-05-14 12:40:16.220 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13045665829504_20/1118/4035/1118_4035.sh
[WI-1118][TI-4035] - [INFO] 2024-05-14 12:40:16.252 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 1870
[WI-0][TI-4035] - [INFO] 2024-05-14 12:40:17.048 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=4035, success=true)
[WI-0][TI-0] - [INFO] 2024-05-14 12:40:17.073 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7971428571428572 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-4035] - [INFO] 2024-05-14 12:40:17.081 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=4035)
[WI-0][TI-0] - [INFO] 2024-05-14 12:40:17.254 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
[WI-1118][TI-4035] - [INFO] 2024-05-14 12:40:19.259 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13045665829504_20/1118/4035, processId:1870 ,exitStatusCode:0 ,processWaitForStatus:true ,processExitValue:0
[WI-1118][TI-4035] - [INFO] 2024-05-14 12:40:19.259 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-1118][TI-4035] - [INFO] 2024-05-14 12:40:19.262 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-1118][TI-4035] - [INFO] 2024-05-14 12:40:19.263 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-1118][TI-4035] - [INFO] 2024-05-14 12:40:19.263 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-1118][TI-4035] - [INFO] 2024-05-14 12:40:19.287 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: SUCCESS to master : 172.18.1.1:1234
[WI-1118][TI-4035] - [INFO] 2024-05-14 12:40:19.288 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-1118][TI-4035] - [INFO] 2024-05-14 12:40:19.288 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13045665829504_20/1118/4035
[WI-1118][TI-4035] - [INFO] 2024-05-14 12:40:19.289 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13045665829504_20/1118/4035
[WI-1118][TI-4035] - [INFO] 2024-05-14 12:40:19.290 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-4035] - [INFO] 2024-05-14 12:40:20.061 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=4035, success=true)
[WI-0][TI-0] - [INFO] 2024-05-14 12:40:22.112 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8149171270718232 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 12:41:00.313 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7197726930603643 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 12:49:20.918 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7261146496815286 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 12:49:22.949 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7197802197802198 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 12:49:57.171 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7743732590529248 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 12:49:59.262 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7631578947368421 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 12:50:02.341 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7581120943952802 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 12:50:32.441 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7955648904920627 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 12:51:02.886 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7082152974504249 is over then the MaxCpuUsagePercentageThresholds 0.7
