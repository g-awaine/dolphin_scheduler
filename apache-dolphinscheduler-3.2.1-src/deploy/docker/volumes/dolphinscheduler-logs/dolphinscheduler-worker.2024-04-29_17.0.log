[WI-0][TI-0] - [INFO] 2024-04-29 17:12:37.229 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7463556851311954 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-29 17:12:51.406 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7514705630155545 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-29 17:13:35.729 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8390722260646182 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [WARN] 2024-04-29 17:22:05.994 +0800 o.s.c.k.c.p.AbstractKubernetesProfileEnvironmentPostProcessor:[258] - Not running inside kubernetes. Skipping 'kubernetes' profile activation.
[WI-0][TI-0] - [WARN] 2024-04-29 17:22:09.275 +0800 o.s.c.k.c.p.AbstractKubernetesProfileEnvironmentPostProcessor:[258] - Not running inside kubernetes. Skipping 'kubernetes' profile activation.
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:09.283 +0800 o.a.d.s.w.WorkerServer:[634] - No active profile set, falling back to 1 default profile: "default"
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:15.951 +0800 o.s.c.c.s.GenericScope:[283] - BeanFactory id=7e7bf7c6-2cb3-34d2-a0d5-a56161c67d0e
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:17.400 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'org.springframework.cloud.commons.config.CommonsConfigAutoConfiguration' of type [org.springframework.cloud.commons.config.CommonsConfigAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:17.415 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'org.springframework.cloud.client.loadbalancer.LoadBalancerDefaultMappingsProviderAutoConfiguration' of type [org.springframework.cloud.client.loadbalancer.LoadBalancerDefaultMappingsProviderAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:17.421 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'loadBalancerClientsDefaultsMappingsProvider' of type [org.springframework.cloud.client.loadbalancer.LoadBalancerDefaultMappingsProviderAutoConfiguration$$Lambda$392/302905744] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:17.435 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'defaultsBindHandlerAdvisor' of type [org.springframework.cloud.commons.config.DefaultsBindHandlerAdvisor] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:17.483 +0800 o.a.d.c.u.NetUtils:[312] - Get all NetworkInterfaces: [name:eth0 (eth0), name:lo (lo)]
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:17.589 +0800 o.a.d.s.w.c.WorkerConfig:[98] - 
****************************Worker Configuration**************************************
  listen-port -> 1234
  exec-threads -> 100
  max-heartbeat-interval -> PT10S
  host-weight -> 100
  tenantConfig -> TenantConfig(autoCreateTenantEnabled=true, distributedTenantEnabled=false, defaultTenantEnabled=false)
  server-load-protection -> WorkerServerLoadProtection(enabled=true, maxCpuUsagePercentageThresholds=0.7, maxJVMMemoryUsagePercentageThresholds=0.7, maxSystemMemoryUsagePercentageThresholds=0.7, maxDiskUsagePercentageThresholds=0.7)
  registry-disconnect-strategy -> ConnectStrategyProperties(strategy=WAITING, maxWaitingTime=PT1M40S)
  task-execute-threads-full-policy: REJECT
  address -> 172.18.1.1:1234
  registry-path: /nodes/worker/172.18.1.1:1234
****************************Worker Configuration**************************************
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:17.589 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'workerConfig' of type [org.apache.dolphinscheduler.server.worker.config.WorkerConfig$$EnhancerBySpringCGLIB$$da954724] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:18.135 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'io.kubernetes.client.spring.extended.manifests.config.KubernetesManifestsAutoConfiguration' of type [io.kubernetes.client.spring.extended.manifests.config.KubernetesManifestsAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:18.163 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'kubernetes.manifests-io.kubernetes.client.spring.extended.manifests.config.KubernetesManifestsProperties' of type [io.kubernetes.client.spring.extended.manifests.config.KubernetesManifestsProperties] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:18.233 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'io.kubernetes.client.spring.extended.controller.config.KubernetesInformerAutoConfiguration' of type [io.kubernetes.client.spring.extended.controller.config.KubernetesInformerAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:18.271 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'defaultApiClient' of type [io.kubernetes.client.openapi.ApiClient] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:18.881 +0800 o.e.j.u.log:[170] - Logging initialized @22266ms to org.eclipse.jetty.util.log.Slf4jLog
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:20.338 +0800 o.s.b.w.e.j.JettyServletWebServerFactory:[166] - Server initialized with port: 1235
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:20.388 +0800 o.e.j.s.Server:[375] - jetty-9.4.48.v20220622; built: 2022-06-21T20:42:25.880Z; git: 6b67c5719d1f4371b33655ff2d047d24e171e49a; jvm 1.8.0_402-b06
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:20.589 +0800 o.e.j.s.h.C.application:[2368] - Initializing Spring embedded WebApplicationContext
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:20.590 +0800 o.s.b.w.s.c.ServletWebServerApplicationContext:[292] - Root WebApplicationContext: initialization completed in 11248 ms
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:23.546 +0800 o.e.j.s.session:[334] - DefaultSessionIdManager workerName=node0
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:23.548 +0800 o.e.j.s.session:[339] - No SessionScavenger set, using defaults
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:23.587 +0800 o.e.j.s.session:[132] - node0 Scavenging every 660000ms
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:23.683 +0800 o.e.j.s.h.ContextHandler:[921] - Started o.s.b.w.e.j.JettyEmbeddedWebAppContext@52433946{application,/,[file:///tmp/jetty-docbase.1235.7770473742965107410/],AVAILABLE}
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:23.730 +0800 o.e.j.s.Server:[415] - Started @27069ms
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:23.953 +0800 o.a.c.f.i.CuratorFrameworkImpl:[338] - Starting
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:24.307 +0800 o.a.z.ZooKeeper:[98] - Client environment:zookeeper.version=3.8.0-5a02a05eddb59aee6ac762f7ea82e92a68eb9c0f, built on 2022-02-25 08:49 UTC
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:24.308 +0800 o.a.z.ZooKeeper:[98] - Client environment:host.name=0447f0f66119
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:24.308 +0800 o.a.z.ZooKeeper:[98] - Client environment:java.version=1.8.0_402
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:24.308 +0800 o.a.z.ZooKeeper:[98] - Client environment:java.vendor=Temurin
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:24.308 +0800 o.a.z.ZooKeeper:[98] - Client environment:java.home=/opt/java/openjdk
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:24.311 +0800 o.a.z.ZooKeeper:[98] - Client environment:java.class.path=/opt/dolphinscheduler/conf:/opt/dolphinscheduler/libs/kerb-client-1.0.1.jar:/opt/dolphinscheduler/libs/spring-cloud-starter-kubernetes-client-config-2.1.3.jar:/opt/dolphinscheduler/libs/oauth2-oidc-sdk-9.35.jar:/opt/dolphinscheduler/libs/jsqlparser-4.4.jar:/opt/dolphinscheduler/libs/reactive-streams-1.0.4.jar:/opt/dolphinscheduler/libs/kubernetes-model-extensions-5.10.2.jar:/opt/dolphinscheduler/libs/zookeeper-3.8.0.jar:/opt/dolphinscheduler/libs/kubernetes-model-apps-5.10.2.jar:/opt/dolphinscheduler/libs/grpc-api-1.41.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-pigeon-3.2.1.jar:/opt/dolphinscheduler/libs/client-java-api-13.0.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-obs-3.2.1.jar:/opt/dolphinscheduler/libs/spring-web-5.3.22.jar:/opt/dolphinscheduler/libs/aws-java-sdk-emr-1.12.300.jar:/opt/dolphinscheduler/libs/spring-context-5.3.22.jar:/opt/dolphinscheduler/libs/gapic-google-cloud-storage-v2-2.18.0-alpha.jar:/opt/dolphinscheduler/libs/spring-cloud-kubernetes-client-config-2.1.3.jar:/opt/dolphinscheduler/libs/jetty-io-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/annotations-13.0.jar:/opt/dolphinscheduler/libs/jpam-1.1.jar:/opt/dolphinscheduler/libs/joda-time-2.10.13.jar:/opt/dolphinscheduler/libs/spring-cloud-kubernetes-client-autoconfig-2.1.3.jar:/opt/dolphinscheduler/libs/kerb-identity-1.0.1.jar:/opt/dolphinscheduler/libs/vertica-jdbc-12.0.4-0.jar:/opt/dolphinscheduler/libs/grpc-googleapis-1.52.1.jar:/opt/dolphinscheduler/libs/aliyun-java-sdk-kms-2.11.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-dvc-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-hana-3.2.1.jar:/opt/dolphinscheduler/libs/kubernetes-httpclient-okhttp-6.0.0.jar:/opt/dolphinscheduler/libs/jline-2.12.jar:/opt/dolphinscheduler/libs/sshd-core-2.8.0.jar:/opt/dolphinscheduler/libs/jna-platform-5.10.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-sqlserver-3.2.1.jar:/opt/dolphinscheduler/libs/commons-beanutils-1.9.4.jar:/opt/dolphinscheduler/libs/grpc-services-1.41.0.jar:/opt/dolphinscheduler/libs/jmespath-java-1.12.300.jar:/opt/dolphinscheduler/libs/curator-client-5.3.0.jar:/opt/dolphinscheduler/libs/proto-google-common-protos-2.0.1.jar:/opt/dolphinscheduler/libs/mybatis-3.5.10.jar:/opt/dolphinscheduler/libs/jackson-annotations-2.13.4.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-all-3.2.1.jar:/opt/dolphinscheduler/libs/jakarta.xml.bind-api-2.3.3.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-jupyter-3.2.1.jar:/opt/dolphinscheduler/libs/mybatis-plus-extension-3.5.2.jar:/opt/dolphinscheduler/libs/j2objc-annotations-1.3.jar:/opt/dolphinscheduler/libs/Java-WebSocket-1.5.1.jar:/opt/dolphinscheduler/libs/azure-storage-common-12.20.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-sagemaker-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-databend-3.2.1.jar:/opt/dolphinscheduler/libs/google-auth-library-oauth2-http-1.15.0.jar:/opt/dolphinscheduler/libs/jetty-security-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-python-3.2.1.jar:/opt/dolphinscheduler/libs/snappy-java-1.1.10.1.jar:/opt/dolphinscheduler/libs/kubernetes-model-batch-5.10.2.jar:/opt/dolphinscheduler/libs/netty-transport-native-epoll-4.1.53.Final-linux-x86_64.jar:/opt/dolphinscheduler/libs/jackson-core-asl-1.9.13.jar:/opt/dolphinscheduler/libs/gson-fire-1.8.5.jar:/opt/dolphinscheduler/libs/clickhouse-jdbc-0.4.6.jar:/opt/dolphinscheduler/libs/grpc-netty-shaded-1.41.0.jar:/opt/dolphinscheduler/libs/caffeine-2.9.3.jar:/opt/dolphinscheduler/libs/aliyun-java-sdk-core-4.5.10.jar:/opt/dolphinscheduler/libs/jackson-module-jaxb-annotations-2.13.3.jar:/opt/dolphinscheduler/libs/jetty-http-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/jersey-servlet-1.19.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-dinky-3.2.1.jar:/opt/dolphinscheduler/libs/simpleclient_tracer_common-0.15.0.jar:/opt/dolphinscheduler/libs/netty-handler-4.1.53.Final.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-datafactory-3.2.1.jar:/opt/dolphinscheduler/libs/json-path-2.7.0.jar:/opt/dolphinscheduler/libs/mybatis-plus-annotation-3.5.2.jar:/opt/dolphinscheduler/libs/azure-resourcemanager-datafactory-1.0.0-beta.19.jar:/opt/dolphinscheduler/libs/commons-codec-1.11.jar:/opt/dolphinscheduler/libs/dolphinscheduler-extract-master-3.2.1.jar:/opt/dolphinscheduler/libs/spring-aop-5.3.22.jar:/opt/dolphinscheduler/libs/kubernetes-model-core-5.10.2.jar:/opt/dolphinscheduler/libs/kubernetes-model-networking-5.10.2.jar:/opt/dolphinscheduler/libs/kotlin-stdlib-jdk7-1.6.21.jar:/opt/dolphinscheduler/libs/kerby-xdr-1.0.1.jar:/opt/dolphinscheduler/libs/aliyun-java-sdk-ram-3.1.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-k8s-3.2.1.jar:/opt/dolphinscheduler/libs/guava-31.1-jre.jar:/opt/dolphinscheduler/libs/netty-codec-dns-4.1.53.Final.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-kubeflow-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-azure-sql-3.2.1.jar:/opt/dolphinscheduler/libs/HikariCP-4.0.3.jar:/opt/dolphinscheduler/libs/hive-metastore-2.3.9.jar:/opt/dolphinscheduler/libs/msal4j-1.13.3.jar:/opt/dolphinscheduler/libs/jackson-core-2.13.4.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-hive-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-mr-3.2.1.jar:/opt/dolphinscheduler/libs/kubernetes-model-node-5.10.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-common-3.2.1.jar:/opt/dolphinscheduler/libs/jose4j-0.7.8.jar:/opt/dolphinscheduler/libs/jul-to-slf4j-1.7.36.jar:/opt/dolphinscheduler/libs/azure-identity-1.7.1.jar:/opt/dolphinscheduler/libs/spring-boot-autoconfigure-2.7.3.jar:/opt/dolphinscheduler/libs/commons-math3-3.1.1.jar:/opt/dolphinscheduler/libs/jackson-jaxrs-json-provider-2.13.3.jar:/opt/dolphinscheduler/libs/perfmark-api-0.23.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-doris-3.2.1.jar:/opt/dolphinscheduler/libs/httpclient-4.5.13.jar:/opt/dolphinscheduler/libs/hive-service-2.3.9.jar:/opt/dolphinscheduler/libs/kerby-util-1.0.1.jar:/opt/dolphinscheduler/libs/commons-collections-3.2.2.jar:/opt/dolphinscheduler/libs/hadoop-yarn-client-3.2.4.jar:/opt/dolphinscheduler/libs/commons-text-1.8.jar:/opt/dolphinscheduler/libs/dolphinscheduler-worker-3.2.1.jar:/opt/dolphinscheduler/libs/hadoop-yarn-common-3.2.4.jar:/opt/dolphinscheduler/libs/zeppelin-client-0.10.1.jar:/opt/dolphinscheduler/libs/azure-core-management-1.10.1.jar:/opt/dolphinscheduler/libs/hadoop-mapreduce-client-jobclient-3.2.4.jar:/opt/dolphinscheduler/libs/jta-1.1.jar:/opt/dolphinscheduler/libs/annotations-4.1.1.4.jar:/opt/dolphinscheduler/libs/dolphinscheduler-extract-alert-3.2.1.jar:/opt/dolphinscheduler/libs/curator-framework-5.3.0.jar:/opt/dolphinscheduler/libs/hive-jdbc-2.3.9.jar:/opt/dolphinscheduler/libs/kyuubi-hive-jdbc-shaded-1.7.0.jar:/opt/dolphinscheduler/libs/client-java-proto-13.0.2.jar:/opt/dolphinscheduler/libs/checker-qual-3.19.0.jar:/opt/dolphinscheduler/libs/jetty-servlet-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/google-cloud-core-grpc-2.10.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-shell-3.2.1.jar:/opt/dolphinscheduler/libs/spring-security-rsa-1.0.10.RELEASE.jar:/opt/dolphinscheduler/libs/avro-1.7.7.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-postgresql-3.2.1.jar:/opt/dolphinscheduler/libs/netty-nio-client-2.17.282.jar:/opt/dolphinscheduler/libs/spring-webmvc-5.3.22.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-mysql-3.2.1.jar:/opt/dolphinscheduler/libs/opentracing-util-0.33.0.jar:/opt/dolphinscheduler/libs/auto-value-1.10.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-all-3.2.1.jar:/opt/dolphinscheduler/libs/jetcd-core-0.5.11.jar:/opt/dolphinscheduler/libs/grpc-context-1.41.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-datasync-3.2.1.jar:/opt/dolphinscheduler/libs/jackson-dataformat-cbor-2.13.3.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-gcs-3.2.1.jar:/opt/dolphinscheduler/libs/client-java-extended-13.0.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-redshift-3.2.1.jar:/opt/dolphinscheduler/libs/opencsv-2.3.jar:/opt/dolphinscheduler/libs/jcip-annotations-1.0-1.jar:/opt/dolphinscheduler/libs/accessors-smart-2.4.8.jar:/opt/dolphinscheduler/libs/hadoop-client-3.2.4.jar:/opt/dolphinscheduler/libs/commons-collections4-4.3.jar:/opt/dolphinscheduler/libs/metrics-core-4.2.11.jar:/opt/dolphinscheduler/libs/netty-resolver-4.1.53.Final.jar:/opt/dolphinscheduler/libs/parquet-hadoop-bundle-1.8.1.jar:/opt/dolphinscheduler/libs/bucket4j-core-6.2.0.jar:/opt/dolphinscheduler/libs/spring-cloud-starter-3.1.3.jar:/opt/dolphinscheduler/libs/mssql-jdbc-11.2.1.jre8.jar:/opt/dolphinscheduler/libs/netty-tcnative-boringssl-static-2.0.53.Final.jar:/opt/dolphinscheduler/libs/kubernetes-model-coordination-5.10.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-linkis-3.2.1.jar:/opt/dolphinscheduler/libs/commons-net-3.6.jar:/opt/dolphinscheduler/libs/netty-transport-native-kqueue-4.1.53.Final-osx-x86_64.jar:/opt/dolphinscheduler/libs/dolphinscheduler-meter-3.2.1.jar:/opt/dolphinscheduler/libs/kubernetes-client-api-6.0.0.jar:/opt/dolphinscheduler/libs/kubernetes-model-certificates-5.10.2.jar:/opt/dolphinscheduler/libs/opencensus-api-0.31.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-mlflow-3.2.1.jar:/opt/dolphinscheduler/libs/kotlin-stdlib-jdk8-1.6.21.jar:/opt/dolphinscheduler/libs/dolphinscheduler-registry-jdbc-3.2.1.jar:/opt/dolphinscheduler/libs/audience-annotations-0.12.0.jar:/opt/dolphinscheduler/libs/simpleclient_httpserver-0.15.0.jar:/opt/dolphinscheduler/libs/jetty-xml-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/kerby-asn1-1.0.1.jar:/opt/dolphinscheduler/libs/lang-tag-1.6.jar:/opt/dolphinscheduler/libs/api-common-2.6.0.jar:/opt/dolphinscheduler/libs/HdrHistogram-2.1.12.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-abs-3.2.1.jar:/opt/dolphinscheduler/libs/failsafe-2.4.4.jar:/opt/dolphinscheduler/libs/hbase-noop-htrace-4.1.1.jar:/opt/dolphinscheduler/libs/jamon-runtime-2.3.1.jar:/opt/dolphinscheduler/libs/jetty-util-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/threetenbp-1.6.5.jar:/opt/dolphinscheduler/libs/jakarta.activation-api-1.2.2.jar:/opt/dolphinscheduler/libs/kubernetes-model-common-5.10.2.jar:/opt/dolphinscheduler/libs/okhttp-4.9.3.jar:/opt/dolphinscheduler/libs/profiles-2.17.282.jar:/opt/dolphinscheduler/libs/hadoop-auth-3.2.4.jar:/opt/dolphinscheduler/libs/grpc-netty-1.41.0.jar:/opt/dolphinscheduler/libs/httpcore-nio-4.4.15.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-seatunnel-3.2.1.jar:/opt/dolphinscheduler/libs/aws-java-sdk-sagemaker-1.12.300.jar:/opt/dolphinscheduler/libs/oshi-core-6.1.1.jar:/opt/dolphinscheduler/libs/bonecp-0.8.0.RELEASE.jar:/opt/dolphinscheduler/libs/jackson-module-parameter-names-2.13.3.jar:/opt/dolphinscheduler/libs/bcutil-jdk15on-1.69.jar:/opt/dolphinscheduler/libs/aws-json-protocol-2.17.282.jar:/opt/dolphinscheduler/libs/dolphinscheduler-extract-base-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-all-3.2.1.jar:/opt/dolphinscheduler/libs/derby-10.14.2.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-snowflake-3.2.1.jar:/opt/dolphinscheduler/libs/netty-codec-http2-4.1.53.Final.jar:/opt/dolphinscheduler/libs/jetty-continuation-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/jackson-mapper-asl-1.9.13.jar:/opt/dolphinscheduler/libs/datanucleus-core-4.1.17.jar:/opt/dolphinscheduler/libs/netty-tcnative-boringssl-static-2.0.53.Final-osx-aarch_64.jar:/opt/dolphinscheduler/libs/failureaccess-1.0.1.jar:/opt/dolphinscheduler/libs/error_prone_annotations-2.5.1.jar:/opt/dolphinscheduler/libs/kerb-admin-1.0.1.jar:/opt/dolphinscheduler/libs/token-provider-1.0.1.jar:/opt/dolphinscheduler/libs/reactor-netty-core-1.0.22.jar:/opt/dolphinscheduler/libs/dolphinscheduler-registry-all-3.2.1.jar:/opt/dolphinscheduler/libs/jakarta.servlet-api-4.0.4.jar:/opt/dolphinscheduler/libs/http-client-spi-2.17.282.jar:/opt/dolphinscheduler/libs/regions-2.17.282.jar:/opt/dolphinscheduler/libs/logback-core-1.2.11.jar:/opt/dolphinscheduler/libs/json-1.8.jar:/opt/dolphinscheduler/libs/gax-grpc-2.23.0.jar:/opt/dolphinscheduler/libs/google-http-client-1.42.3.jar:/opt/dolphinscheduler/libs/hive-serde-2.3.9.jar:/opt/dolphinscheduler/libs/jettison-1.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-http-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-registry-zookeeper-3.2.1.jar:/opt/dolphinscheduler/libs/spring-security-crypto-5.7.3.jar:/opt/dolphinscheduler/libs/auth-2.17.282.jar:/opt/dolphinscheduler/libs/proto-google-cloud-storage-v2-2.18.0-alpha.jar:/opt/dolphinscheduler/libs/jetty-server-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/javax.annotation-api-1.3.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-starrocks-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-dataquality-3.2.1.jar:/opt/dolphinscheduler/libs/jcl-over-slf4j-1.7.36.jar:/opt/dolphinscheduler/libs/commons-lang3-3.12.0.jar:/opt/dolphinscheduler/libs/tomcat-embed-el-9.0.65.jar:/opt/dolphinscheduler/libs/opentracing-noop-0.33.0.jar:/opt/dolphinscheduler/libs/client-java-13.0.2.jar:/opt/dolphinscheduler/libs/spring-beans-5.3.22.jar:/opt/dolphinscheduler/libs/snakeyaml-1.33.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-ssh-3.2.1.jar:/opt/dolphinscheduler/libs/commons-pool-1.6.jar:/opt/dolphinscheduler/libs/javax.servlet-api-3.1.0.jar:/opt/dolphinscheduler/libs/hadoop-common-3.2.4.jar:/opt/dolphinscheduler/libs/kubernetes-model-apiextensions-5.10.2.jar:/opt/dolphinscheduler/libs/spring-boot-2.7.3.jar:/opt/dolphinscheduler/libs/bcprov-ext-jdk15on-1.69.jar:/opt/dolphinscheduler/libs/spring-boot-starter-2.7.3.jar:/opt/dolphinscheduler/libs/paranamer-2.3.jar:/opt/dolphinscheduler/libs/httpmime-4.5.13.jar:/opt/dolphinscheduler/libs/reactor-core-3.4.22.jar:/opt/dolphinscheduler/libs/azure-core-1.36.0.jar:/opt/dolphinscheduler/libs/bcpkix-jdk15on-1.69.jar:/opt/dolphinscheduler/libs/kubernetes-model-scheduling-5.10.2.jar:/opt/dolphinscheduler/libs/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/dolphinscheduler/libs/websocket-client-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/unirest-java-3.7.04-standalone.jar:/opt/dolphinscheduler/libs/hadoop-mapreduce-client-core-3.2.4.jar:/opt/dolphinscheduler/libs/google-auth-library-credentials-1.15.0.jar:/opt/dolphinscheduler/libs/azure-storage-internal-avro-12.6.0.jar:/opt/dolphinscheduler/libs/jackson-datatype-jdk8-2.13.3.jar:/opt/dolphinscheduler/libs/spring-expression-5.3.22.jar:/opt/dolphinscheduler/libs/aspectjweaver-1.9.7.jar:/opt/dolphinscheduler/libs/websocket-common-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/client-java-api-fluent-13.0.2.jar:/opt/dolphinscheduler/libs/mybatis-plus-3.5.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-athena-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-oss-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-openmldb-3.2.1.jar:/opt/dolphinscheduler/libs/curator-recipes-5.3.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-api-3.2.1.jar:/opt/dolphinscheduler/libs/netty-all-4.1.53.Final.jar:/opt/dolphinscheduler/libs/netty-resolver-dns-4.1.53.Final.jar:/opt/dolphinscheduler/libs/kubernetes-model-autoscaling-5.10.2.jar:/opt/dolphinscheduler/libs/kerb-util-1.0.1.jar:/opt/dolphinscheduler/libs/grpc-alts-1.41.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-presto-3.2.1.jar:/opt/dolphinscheduler/libs/kerb-simplekdc-1.0.1.jar:/opt/dolphinscheduler/libs/protobuf-java-util-3.17.2.jar:/opt/dolphinscheduler/libs/azure-core-http-netty-1.13.0.jar:/opt/dolphinscheduler/libs/transaction-api-1.1.jar:/opt/dolphinscheduler/libs/datanucleus-api-jdo-4.2.4.jar:/opt/dolphinscheduler/libs/zeppelin-common-0.10.1.jar:/opt/dolphinscheduler/libs/zt-zip-1.15.jar:/opt/dolphinscheduler/libs/animal-sniffer-annotations-1.19.jar:/opt/dolphinscheduler/libs/google-http-client-jackson2-1.42.3.jar:/opt/dolphinscheduler/libs/netty-buffer-4.1.53.Final.jar:/opt/dolphinscheduler/libs/jsr305-3.0.0.jar:/opt/dolphinscheduler/libs/netty-transport-classes-epoll-4.1.79.Final.jar:/opt/dolphinscheduler/libs/spring-boot-actuator-autoconfigure-2.7.3.jar:/opt/dolphinscheduler/libs/simpleclient-0.15.0.jar:/opt/dolphinscheduler/libs/aliyun-sdk-oss-3.15.1.jar:/opt/dolphinscheduler/libs/json-utils-2.17.282.jar:/opt/dolphinscheduler/libs/tephra-api-0.6.0.jar:/opt/dolphinscheduler/libs/spring-jdbc-5.3.22.jar:/opt/dolphinscheduler/libs/grpc-xds-1.41.0.jar:/opt/dolphinscheduler/libs/logback-classic-1.2.11.jar:/opt/dolphinscheduler/libs/google-cloud-storage-2.18.0.jar:/opt/dolphinscheduler/libs/micrometer-registry-prometheus-1.9.3.jar:/opt/dolphinscheduler/libs/grpc-core-1.41.0.jar:/opt/dolphinscheduler/libs/aws-java-sdk-kms-1.12.300.jar:/opt/dolphinscheduler/libs/kubernetes-model-rbac-5.10.2.jar:/opt/dolphinscheduler/libs/ini4j-0.5.4.jar:/opt/dolphinscheduler/libs/spring-boot-starter-web-2.7.3.jar:/opt/dolphinscheduler/libs/spring-cloud-commons-3.1.3.jar:/opt/dolphinscheduler/libs/netty-codec-http-4.1.53.Final.jar:/opt/dolphinscheduler/libs/jetty-client-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/jetcd-common-0.5.11.jar:/opt/dolphinscheduler/libs/metrics-spi-2.17.282.jar:/opt/dolphinscheduler/libs/utils-2.17.282.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-emr-3.2.1.jar:/opt/dolphinscheduler/libs/protocol-core-2.17.282.jar:/opt/dolphinscheduler/libs/micrometer-core-1.9.3.jar:/opt/dolphinscheduler/libs/netty-transport-native-unix-common-4.1.53.Final.jar:/opt/dolphinscheduler/libs/zjsonpatch-0.4.11.jar:/opt/dolphinscheduler/libs/annotations-2.17.282.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-sql-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-extract-common-3.2.1.jar:/opt/dolphinscheduler/libs/apache-client-2.17.282.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-oceanbase-3.2.1.jar:/opt/dolphinscheduler/libs/jdo-api-3.0.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-datax-3.2.1.jar:/opt/dolphinscheduler/libs/postgresql-42.4.1.jar:/opt/dolphinscheduler/libs/jetty-util-ajax-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/gax-2.23.0.jar:/opt/dolphinscheduler/libs/grpc-stub-1.41.0.jar:/opt/dolphinscheduler/libs/libfb303-0.9.3.jar:/opt/dolphinscheduler/libs/spring-core-5.3.22.jar:/opt/dolphinscheduler/libs/jaxb-api-2.3.1.jar:/opt/dolphinscheduler/libs/hive-service-rpc-2.3.9.jar:/opt/dolphinscheduler/libs/kubernetes-model-flowcontrol-5.10.2.jar:/opt/dolphinscheduler/libs/commons-logging-1.1.1.jar:/opt/dolphinscheduler/libs/mybatis-spring-2.0.7.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-oracle-3.2.1.jar:/opt/dolphinscheduler/libs/opencensus-proto-0.2.0.jar:/opt/dolphinscheduler/libs/grpc-protobuf-1.41.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-clickhouse-3.2.1.jar:/opt/dolphinscheduler/libs/spring-cloud-starter-bootstrap-3.1.3.jar:/opt/dolphinscheduler/libs/kubernetes-model-admissionregistration-5.10.2.jar:/opt/dolphinscheduler/libs/grpc-google-cloud-storage-v2-2.18.0-alpha.jar:/opt/dolphinscheduler/libs/esdk-obs-java-bundle-3.23.3.jar:/opt/dolphinscheduler/libs/dnsjava-2.1.7.jar:/opt/dolphinscheduler/libs/asm-9.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-spark-3.2.1.jar:/opt/dolphinscheduler/libs/netty-tcnative-boringssl-static-2.0.53.Final-linux-aarch_64.jar:/opt/dolphinscheduler/libs/re2j-1.6.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-vertica-3.2.1.jar:/opt/dolphinscheduler/libs/json-smart-2.4.8.jar:/opt/dolphinscheduler/libs/reactor-netty-http-1.0.22.jar:/opt/dolphinscheduler/libs/google-api-services-storage-v1-rev20220705-2.0.0.jar:/opt/dolphinscheduler/libs/kubernetes-client-6.0.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-kyuubi-3.2.1.jar:/opt/dolphinscheduler/libs/auto-value-annotations-1.10.1.jar:/opt/dolphinscheduler/libs/commons-cli-1.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-data-quality-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-chunjun-3.2.1.jar:/opt/dolphinscheduler/libs/kerb-server-1.0.1.jar:/opt/dolphinscheduler/libs/content-type-2.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-remoteshell-3.2.1.jar:/opt/dolphinscheduler/libs/opencensus-contrib-http-util-0.31.1.jar:/opt/dolphinscheduler/libs/druid-1.2.20.jar:/opt/dolphinscheduler/libs/javolution-5.5.1.jar:/opt/dolphinscheduler/libs/protobuf-java-3.17.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-db2-3.2.1.jar:/opt/dolphinscheduler/libs/aws-java-sdk-core-1.12.300.jar:/opt/dolphinscheduler/libs/spring-boot-starter-logging-2.7.3.jar:/opt/dolphinscheduler/libs/kerby-pkix-1.0.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-procedure-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-registry-etcd-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-sqoop-3.2.1.jar:/opt/dolphinscheduler/libs/zookeeper-jute-3.8.0.jar:/opt/dolphinscheduler/libs/netty-resolver-dns-native-macos-4.1.53.Final-osx-x86_64.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-sagemaker-3.2.1.jar:/opt/dolphinscheduler/libs/spring-boot-configuration-processor-2.6.1.jar:/opt/dolphinscheduler/libs/hive-common-2.3.9.jar:/opt/dolphinscheduler/libs/kerb-common-1.0.1.jar:/opt/dolphinscheduler/libs/stax-api-1.0.1.jar:/opt/dolphinscheduler/libs/kubernetes-model-storageclass-5.10.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-s3-3.2.1.jar:/opt/dolphinscheduler/libs/spring-boot-starter-jetty-2.7.3.jar:/opt/dolphinscheduler/libs/okio-2.8.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-dms-3.2.1.jar:/opt/dolphinscheduler/libs/simpleclient_common-0.15.0.jar:/opt/dolphinscheduler/libs/sdk-core-2.17.282.jar:/opt/dolphinscheduler/libs/javax.activation-api-1.2.0.jar:/opt/dolphinscheduler/libs/netty-handler-proxy-4.1.53.Final.jar:/opt/dolphinscheduler/libs/kerby-config-1.0.1.jar:/opt/dolphinscheduler/libs/netty-tcnative-classes-2.0.53.Final.jar:/opt/dolphinscheduler/libs/jackson-jaxrs-base-2.13.3.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-trino-3.2.1.jar:/opt/dolphinscheduler/libs/presto-jdbc-0.238.1.jar:/opt/dolphinscheduler/libs/websocket-api-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-flink-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-api-3.2.1.jar:/opt/dolphinscheduler/libs/kubernetes-model-metrics-5.10.2.jar:/opt/dolphinscheduler/libs/datasync-2.17.282.jar:/opt/dolphinscheduler/libs/hadoop-yarn-api-3.2.4.jar:/opt/dolphinscheduler/libs/google-http-client-apache-v2-1.42.3.jar:/opt/dolphinscheduler/libs/hadoop-annotations-3.2.4.jar:/opt/dolphinscheduler/libs/google-oauth-client-1.34.1.jar:/opt/dolphinscheduler/libs/sshd-common-2.8.0.jar:/opt/dolphinscheduler/libs/LatencyUtils-2.0.3.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-spark-3.2.1.jar:/opt/dolphinscheduler/libs/slf4j-api-1.7.36.jar:/opt/dolphinscheduler/libs/snowflake-jdbc-3.13.29.jar:/opt/dolphinscheduler/libs/jackson-datatype-jsr310-2.13.3.jar:/opt/dolphinscheduler/libs/trino-jdbc-402.jar:/opt/dolphinscheduler/libs/logging-interceptor-4.9.3.jar:/opt/dolphinscheduler/libs/simpleclient_tracer_otel_agent-0.15.0.jar:/opt/dolphinscheduler/libs/janino-3.0.16.jar:/opt/dolphinscheduler/libs/jackson-dataformat-yaml-2.13.3.jar:/opt/dolphinscheduler/libs/ion-java-1.0.2.jar:/opt/dolphinscheduler/libs/commons-dbcp-1.4.jar:/opt/dolphinscheduler/libs/jsp-api-2.1.jar:/opt/dolphinscheduler/libs/google-http-client-gson-1.42.3.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-hivecli-3.2.1.jar:/opt/dolphinscheduler/libs/spring-boot-actuator-2.7.3.jar:/opt/dolphinscheduler/libs/google-cloud-core-http-2.10.0.jar:/opt/dolphinscheduler/libs/DmJdbcDriver18-8.1.2.79.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-java-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-dameng-3.2.1.jar:/opt/dolphinscheduler/libs/sshd-sftp-2.8.0.jar:/opt/dolphinscheduler/libs/kerb-crypto-1.0.1.jar:/opt/dolphinscheduler/libs/conscrypt-openjdk-uber-2.5.2.jar:/opt/dolphinscheduler/libs/httpcore-4.4.15.jar:/opt/dolphinscheduler/libs/lz4-java-1.4.0.jar:/opt/dolphinscheduler/libs/guava-retrying-2.0.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-flink-stream-3.2.1.jar:/opt/dolphinscheduler/libs/spring-tx-5.3.22.jar:/opt/dolphinscheduler/libs/grpc-auth-1.41.0.jar:/opt/dolphinscheduler/libs/netty-tcnative-boringssl-static-2.0.53.Final-osx-x86_64.jar:/opt/dolphinscheduler/libs/databend-jdbc-0.0.7.jar:/opt/dolphinscheduler/libs/bcprov-jdk15on-1.69.jar:/opt/dolphinscheduler/libs/commons-lang-2.6.jar:/opt/dolphinscheduler/libs/kubernetes-model-policy-5.10.2.jar:/opt/dolphinscheduler/libs/commons-io-2.11.0.jar:/opt/dolphinscheduler/libs/grpc-grpclb-1.41.0.jar:/opt/dolphinscheduler/libs/netty-tcnative-boringssl-static-2.0.53.Final-linux-x86_64.jar:/opt/dolphinscheduler/libs/opentracing-api-0.33.0.jar:/opt/dolphinscheduler/libs/sshd-scp-2.8.0.jar:/opt/dolphinscheduler/libs/reload4j-1.2.18.3.jar:/opt/dolphinscheduler/libs/netty-tcnative-2.0.48.Final.jar:/opt/dolphinscheduler/libs/jdom2-2.0.6.1.jar:/opt/dolphinscheduler/libs/spring-boot-starter-json-2.7.3.jar:/opt/dolphinscheduler/libs/netty-transport-native-epoll-4.1.53.Final.jar:/opt/dolphinscheduler/libs/google-cloud-core-2.10.0.jar:/opt/dolphinscheduler/libs/javax.jdo-3.2.0-m3.jar:/opt/dolphinscheduler/libs/gax-httpjson-0.108.0.jar:/opt/dolphinscheduler/libs/mybatis-plus-core-3.5.2.jar:/opt/dolphinscheduler/libs/auto-service-annotations-1.0.1.jar:/opt/dolphinscheduler/libs/nimbus-jose-jwt-9.22.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-zeppelin-3.2.1.jar:/opt/dolphinscheduler/libs/commons-compress-1.21.jar:/opt/dolphinscheduler/libs/hadoop-hdfs-client-3.2.4.jar:/opt/dolphinscheduler/libs/msal4j-persistence-extension-1.1.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-pytorch-3.2.1.jar:/opt/dolphinscheduler/libs/netty-tcnative-boringssl-static-2.0.53.Final-windows-x86_64.jar:/opt/dolphinscheduler/libs/jetty-servlets-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/woodstox-core-6.4.0.jar:/opt/dolphinscheduler/libs/spring-cloud-kubernetes-commons-2.1.3.jar:/opt/dolphinscheduler/libs/grpc-protobuf-lite-1.41.0.jar:/opt/dolphinscheduler/libs/jetty-webapp-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/eventstream-1.0.1.jar:/opt/dolphinscheduler/libs/commons-compiler-3.1.7.jar:/opt/dolphinscheduler/libs/netty-transport-4.1.53.Final.jar:/opt/dolphinscheduler/libs/spring-cloud-context-3.1.3.jar:/opt/dolphinscheduler/libs/aws-java-sdk-dms-1.12.300.jar:/opt/dolphinscheduler/libs/hive-storage-api-2.4.0.jar:/opt/dolphinscheduler/libs/client-java-spring-integration-13.0.2.jar:/opt/dolphinscheduler/libs/spring-boot-starter-actuator-2.7.3.jar:/opt/dolphinscheduler/libs/third-party-jackson-core-2.17.282.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-hdfs-3.2.1.jar:/opt/dolphinscheduler/libs/netty-codec-4.1.53.Final.jar:/opt/dolphinscheduler/libs/google-http-client-appengine-1.42.3.jar:/opt/dolphinscheduler/libs/commons-configuration2-2.1.1.jar:/opt/dolphinscheduler/libs/datanucleus-rdbms-4.1.19.jar:/opt/dolphinscheduler/libs/swagger-annotations-1.6.2.jar:/opt/dolphinscheduler/libs/simpleclient_tracer_otel-0.15.0.jar:/opt/dolphinscheduler/libs/kotlin-stdlib-common-1.6.21.jar:/opt/dolphinscheduler/libs/aws-core-2.17.282.jar:/opt/dolphinscheduler/libs/kerb-core-1.0.1.jar:/opt/dolphinscheduler/libs/httpasyncclient-4.1.5.jar:/opt/dolphinscheduler/libs/dolphinscheduler-extract-worker-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-spi-3.2.1.jar:/opt/dolphinscheduler/libs/okhttp-2.7.5.jar:/opt/dolphinscheduler/libs/google-api-client-2.2.0.jar:/opt/dolphinscheduler/libs/kotlin-stdlib-1.6.21.jar:/opt/dolphinscheduler/libs/jakarta.websocket-api-1.1.2.jar:/opt/dolphinscheduler/libs/libthrift-0.9.3.jar:/opt/dolphinscheduler/libs/spring-boot-starter-aop-2.7.3.jar:/opt/dolphinscheduler/libs/netty-common-4.1.53.Final.jar:/opt/dolphinscheduler/libs/log4j-1.2-api-2.17.2.jar:/opt/dolphinscheduler/libs/jackson-databind-2.13.4.jar:/opt/dolphinscheduler/libs/jackson-dataformat-xml-2.13.3.jar:/opt/dolphinscheduler/libs/kubernetes-model-events-5.10.2.jar:/opt/dolphinscheduler/libs/gson-2.9.1.jar:/opt/dolphinscheduler/libs/proto-google-iam-v1-1.9.0.jar:/opt/dolphinscheduler/libs/netty-codec-socks-4.1.53.Final.jar:/opt/dolphinscheduler/libs/zjsonpatch-0.3.0.jar:/opt/dolphinscheduler/libs/hadoop-mapreduce-client-common-3.2.4.jar:/opt/dolphinscheduler/libs/dolphinscheduler-registry-api-3.2.1.jar:/opt/dolphinscheduler/libs/azure-storage-blob-12.21.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-zeppelin-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-api-3.2.1.jar:/opt/dolphinscheduler/libs/aws-java-sdk-s3-1.12.300.jar:/opt/dolphinscheduler/libs/stax2-api-4.2.1.jar:/opt/dolphinscheduler/libs/jakarta.annotation-api-1.3.5.jar:/opt/dolphinscheduler/libs/kubernetes-model-discovery-5.10.2.jar:/opt/dolphinscheduler/libs/jna-5.10.0.jar:/opt/dolphinscheduler/libs/spring-jcl-5.3.22.jar
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:24.312 +0800 o.a.z.ZooKeeper:[98] - Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:24.312 +0800 o.a.z.ZooKeeper:[98] - Client environment:java.io.tmpdir=/tmp
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:24.312 +0800 o.a.z.ZooKeeper:[98] - Client environment:java.compiler=<NA>
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:24.312 +0800 o.a.z.ZooKeeper:[98] - Client environment:os.name=Linux
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:24.312 +0800 o.a.z.ZooKeeper:[98] - Client environment:os.arch=amd64
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:24.313 +0800 o.a.z.ZooKeeper:[98] - Client environment:os.version=6.5.0-28-generic
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:24.313 +0800 o.a.z.ZooKeeper:[98] - Client environment:user.name=root
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:24.313 +0800 o.a.z.ZooKeeper:[98] - Client environment:user.home=/root
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:24.313 +0800 o.a.z.ZooKeeper:[98] - Client environment:user.dir=/opt/dolphinscheduler
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:24.313 +0800 o.a.z.ZooKeeper:[98] - Client environment:os.memory.free=3199MB
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:24.313 +0800 o.a.z.ZooKeeper:[98] - Client environment:os.memory.max=3840MB
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:24.313 +0800 o.a.z.ZooKeeper:[98] - Client environment:os.memory.total=3840MB
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:24.317 +0800 o.a.z.ZooKeeper:[637] - Initiating client connection, connectString=dolphinscheduler-zookeeper:2181 sessionTimeout=30000 watcher=org.apache.curator.ConnectionState@6996bbc4
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:24.329 +0800 o.a.z.c.X509Util:[77] - Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:24.337 +0800 o.a.z.ClientCnxnSocket:[239] - jute.maxbuffer value is 1048575 Bytes
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:24.346 +0800 o.a.z.ClientCnxn:[1732] - zookeeper.request.timeout value is 0. feature enabled=false
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:24.413 +0800 o.a.c.f.i.CuratorFrameworkImpl:[386] - Default schema
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:24.411 +0800 o.a.z.ClientCnxn:[1171] - Opening socket connection to server dolphinscheduler-zookeeper/172.18.0.3:2181.
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:24.452 +0800 o.a.z.ClientCnxn:[1173] - SASL config status: Will not attempt to authenticate using SASL (unknown error)
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:24.459 +0800 o.a.z.ClientCnxn:[1005] - Socket connection established, initiating session, client: /172.18.1.1:38818, server: dolphinscheduler-zookeeper/172.18.0.3:2181
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:24.507 +0800 o.a.z.ClientCnxn:[1444] - Session establishment complete on server dolphinscheduler-zookeeper/172.18.0.3:2181, session id = 0x10001e06c760001, negotiated timeout = 30000
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:24.522 +0800 o.a.c.f.s.ConnectionStateManager:[252] - State change: CONNECTED
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:24.724 +0800 o.a.c.f.i.EnsembleTracker:[201] - New config event received: {}
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:24.725 +0800 o.a.c.f.i.EnsembleTracker:[201] - New config event received: {}
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:25.285 +0800 o.a.d.s.w.r.WorkerRpcServer:[41] - WorkerRpcServer starting...
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:25.794 +0800 o.a.d.e.b.NettyRemotingServer:[112] - WorkerRpcServer bind success at port: 1234
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:25.794 +0800 o.a.d.s.w.r.WorkerRpcServer:[43] - WorkerRpcServer started...
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:25.875 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: JAVA - JavaTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:25.896 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: JAVA - JavaTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:25.910 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: JUPYTER - JupyterTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:25.912 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: JUPYTER - JupyterTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:25.912 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: SPARK - SparkTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:25.914 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: SPARK - SparkTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:25.915 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: FLINK_STREAM - FlinkStreamTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:25.918 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: FLINK_STREAM - FlinkStreamTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:25.919 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: PYTHON - PythonTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:25.920 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: PYTHON - PythonTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:25.920 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: DATASYNC - DatasyncTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:25.922 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: DATASYNC - DatasyncTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:25.922 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: DATA_FACTORY - DatafactoryTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:25.950 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: DATA_FACTORY - DatafactoryTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:25.951 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: CHUNJUN - ChunJunTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:25.953 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: CHUNJUN - ChunJunTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:25.954 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: REMOTESHELL - RemoteShellTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:25.956 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: REMOTESHELL - RemoteShellTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:25.956 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: PIGEON - PigeonTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:25.958 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: PIGEON - PigeonTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:25.958 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: SHELL - ShellTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:25.960 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: SHELL - ShellTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:25.960 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: PROCEDURE - ProcedureTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:25.962 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: PROCEDURE - ProcedureTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:25.963 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: MR - MapReduceTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:25.964 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: MR - MapReduceTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:25.964 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: SQOOP - SqoopTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:25.966 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: SQOOP - SqoopTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:25.966 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: PYTORCH - PytorchTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:25.968 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: PYTORCH - PytorchTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:25.968 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: K8S - K8sTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:25.970 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: K8S - K8sTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:25.971 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: SEATUNNEL - SeatunnelTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:25.973 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: SEATUNNEL - SeatunnelTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:25.974 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: SAGEMAKER - SagemakerTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:25.975 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: SAGEMAKER - SagemakerTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:25.976 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: HTTP - HttpTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:25.978 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: HTTP - HttpTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:26.033 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: EMR - EmrTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:26.036 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: EMR - EmrTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:26.037 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: DMS - DmsTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:26.039 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: DMS - DmsTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:26.040 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: DATA_QUALITY - DataQualityTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:26.041 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: DATA_QUALITY - DataQualityTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:26.042 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: KUBEFLOW - KubeflowTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:26.043 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: KUBEFLOW - KubeflowTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:26.044 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: SQL - SqlTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:26.046 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: SQL - SqlTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:26.047 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: DVC - DvcTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:26.048 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: DVC - DvcTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:26.049 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: DATAX - DataxTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:26.052 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: DATAX - DataxTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:26.052 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: ZEPPELIN - ZeppelinTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:26.055 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: ZEPPELIN - ZeppelinTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:26.057 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: DINKY - DinkyTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:26.058 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: DINKY - DinkyTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:26.059 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: MLFLOW - MlflowTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:26.062 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: MLFLOW - MlflowTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:26.062 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: OPENMLDB - OpenmldbTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:26.064 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: OPENMLDB - OpenmldbTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:26.064 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: LINKIS - LinkisTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:26.066 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: LINKIS - LinkisTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:26.067 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: FLINK - FlinkTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:26.068 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: FLINK - FlinkTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:26.068 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: HIVECLI - HiveCliTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:26.070 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: HIVECLI - HiveCliTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:26.160 +0800 o.a.d.c.u.JSONUtils:[72] - init timezone: sun.util.calendar.ZoneInfo[id="Asia/Shanghai",offset=28800000,dstSavings=0,useDaylight=false,transitions=31,lastRule=null]
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:26.422 +0800 o.a.d.s.w.r.WorkerRegistryClient:[104] - Worker node: 172.18.1.1:1234 registry to ZK /nodes/worker/172.18.1.1:1234 successfully
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:27.471 +0800 o.a.d.c.m.BaseHeartBeatTask:[48] - Starting WorkerHeartBeatTask...
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:27.474 +0800 o.a.d.c.m.BaseHeartBeatTask:[50] - Started WorkerHeartBeatTask, heartBeatInterval: 10000...
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:27.475 +0800 o.a.d.s.w.r.WorkerRegistryClient:[114] - Worker node: 172.18.1.1:1234 registry finished
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:27.477 +0800 o.a.d.s.w.m.MessageRetryRunner:[69] - Message retry runner staring
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:27.500 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.0346666666666666 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:27.556 +0800 o.a.d.s.w.m.MessageRetryRunner:[72] - Injected message sender: TaskInstanceExecutionFinishEventSender
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:27.556 +0800 o.a.d.s.w.m.MessageRetryRunner:[72] - Injected message sender: TaskInstanceExecutionInfoUpdateEventSender
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:27.564 +0800 o.a.d.s.w.m.MessageRetryRunner:[72] - Injected message sender: TaskInstanceExecutionRunningEventSender
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:27.565 +0800 o.a.d.s.w.m.MessageRetryRunner:[75] - Message retry runner started
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:28.743 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.2470588235294118 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:29.770 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.1917098445595855 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:31.045 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.2608695652173914 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:32.114 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.7857142857142858 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:33.377 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.1682242990654206 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:34.521 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.7622950819672132 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:35.634 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.6 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:36.755 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.2819383259911894 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:37.776 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.3674698795180722 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:38.814 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.222972972972973 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:39.818 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.595890410958904 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:40.387 +0800 o.s.b.a.e.w.EndpointLinksResolver:[58] - Exposing 3 endpoint(s) beneath base path '/actuator'
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:40.697 +0800 o.e.j.s.h.C.application:[2368] - Initializing Spring DispatcherServlet 'dispatcherServlet'
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:40.700 +0800 o.s.w.s.DispatcherServlet:[525] - Initializing Servlet 'dispatcherServlet'
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:40.706 +0800 o.s.w.s.DispatcherServlet:[547] - Completed initialization in 2 ms
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:40.833 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.702290076335878 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:41.096 +0800 o.e.j.s.AbstractConnector:[333] - Started ServerConnector@acb5508{HTTP/1.1, (http/1.1)}{0.0.0.0:1235}
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:41.097 +0800 o.s.b.w.e.j.JettyWebServer:[172] - Jetty started on port(s) 1235 (http/1.1) with context path '/'
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:41.130 +0800 o.a.d.s.w.WorkerServer:[61] - Started WorkerServer in 41.474 seconds (JVM running for 44.515)
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:41.851 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.5075757575757576 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:42.853 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.0601503759398496 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:43.871 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.0 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:44.874 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9456066945606694 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:45.876 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9230769230769231 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:46.934 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8324873096446701 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:47.935 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7636363636363636 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:49.223 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8157894736842106 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:55.354 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8151658767772512 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:56.391 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7374999999999999 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:57.403 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.0 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-29 17:22:58.444 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.0049261083743843 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-29 17:26:26.072 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.889589905362776 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-29 17:26:27.099 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7763578274760383 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-29 17:27:23.079 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=2013, taskName=consume_filtered_data, firstSubmitTime=1714382842651, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.10:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13426477386080, processDefineVersion=6, appIds=null, processInstanceId=746, scheduleTime=0, globalParams=null, executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[],"rawScript":"# /bin/kafka-console-consumer.sh \\\n#     --bootstrap-server kafka:9092 \\\n#     --topic reddit_post_filtered \\\n#     --max-messages 10 \\\n#     --from-beginning \\\n#     --group filtered_data_consumer \n#     --timeout-ms 15000","resourceList":[]}, environmentConfig=export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='consume_filtered_data'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='746'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240429'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240428'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='2013'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='es_filtered_data_persistence_subprocess'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13433255983872'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13426477386080'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240429172722'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=null, dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-746][TI-2013] - [INFO] 2024-04-29 17:27:23.233 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: consume_filtered_data to wait queue success
[WI-746][TI-2013] - [INFO] 2024-04-29 17:27:23.297 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-746][TI-2013] - [INFO] 2024-04-29 17:27:23.313 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-746][TI-2013] - [INFO] 2024-04-29 17:27:23.314 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-746][TI-2013] - [INFO] 2024-04-29 17:27:23.315 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-746][TI-2013] - [INFO] 2024-04-29 17:27:23.315 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1714382843315
[WI-746][TI-2013] - [INFO] 2024-04-29 17:27:23.315 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 746_2013
[WI-746][TI-2013] - [INFO] 2024-04-29 17:27:23.320 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 2013,
  "taskName" : "consume_filtered_data",
  "firstSubmitTime" : 1714382842651,
  "startTime" : 1714382843315,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.10:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240429/13426477386080/6/746/2013.log",
  "processId" : 0,
  "processDefineCode" : 13426477386080,
  "processDefineVersion" : 6,
  "processInstanceId" : 746,
  "scheduleTime" : 0,
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[],\"rawScript\":\"# /bin/kafka-console-consumer.sh \\\\\\n#     --bootstrap-server kafka:9092 \\\\\\n#     --topic reddit_post_filtered \\\\\\n#     --max-messages 10 \\\\\\n#     --from-beginning \\\\\\n#     --group filtered_data_consumer \\n#     --timeout-ms 15000\",\"resourceList\":[]}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "consume_filtered_data"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "746"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240429"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240428"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "2013"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "es_filtered_data_persistence_subprocess"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13433255983872"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13426477386080"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240429172722"
    }
  },
  "taskAppId" : "746_2013",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-746][TI-2013] - [INFO] 2024-04-29 17:27:23.323 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-746][TI-2013] - [INFO] 2024-04-29 17:27:23.323 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-746][TI-2013] - [INFO] 2024-04-29 17:27:23.323 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-0][TI-0] - [INFO] 2024-04-29 17:27:23.452 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8309037900874636 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-746][TI-2013] - [INFO] 2024-04-29 17:27:23.671 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-746][TI-2013] - [INFO] 2024-04-29 17:27:23.744 +0800 o.a.d.c.u.OSUtils:[231] - create linux os user: default
[WI-746][TI-2013] - [INFO] 2024-04-29 17:27:23.745 +0800 o.a.d.c.u.OSUtils:[233] - execute cmd: sudo useradd -g root
 default
[WI-746][TI-2013] - [INFO] 2024-04-29 17:27:23.942 +0800 o.a.d.c.u.OSUtils:[190] - create user default success
[WI-746][TI-2013] - [INFO] 2024-04-29 17:27:23.943 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-746][TI-2013] - [INFO] 2024-04-29 17:27:23.951 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_6/746/2013 check successfully
[WI-746][TI-2013] - [INFO] 2024-04-29 17:27:23.953 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-746][TI-2013] - [INFO] 2024-04-29 17:27:23.970 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-746][TI-2013] - [INFO] 2024-04-29 17:27:23.987 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-746][TI-2013] - [INFO] 2024-04-29 17:27:23.991 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-746][TI-2013] - [INFO] 2024-04-29 17:27:24.004 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ ],
  "varPool" : null,
  "rawScript" : "# /bin/kafka-console-consumer.sh \\\n#     --bootstrap-server kafka:9092 \\\n#     --topic reddit_post_filtered \\\n#     --max-messages 10 \\\n#     --from-beginning \\\n#     --group filtered_data_consumer \n#     --timeout-ms 15000",
  "resourceList" : [ ]
}
[WI-746][TI-2013] - [INFO] 2024-04-29 17:27:24.005 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-746][TI-2013] - [INFO] 2024-04-29 17:27:24.005 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: null successfully
[WI-746][TI-2013] - [INFO] 2024-04-29 17:27:24.010 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-746][TI-2013] - [INFO] 2024-04-29 17:27:24.010 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-746][TI-2013] - [INFO] 2024-04-29 17:27:24.010 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-746][TI-2013] - [INFO] 2024-04-29 17:27:24.038 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-746][TI-2013] - [INFO] 2024-04-29 17:27:24.041 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-746][TI-2013] - [INFO] 2024-04-29 17:27:24.046 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export PYTHON_LAUNCHER=/bin/python3.11
# /bin/kafka-console-consumer.sh \
#     --bootstrap-server kafka:9092 \
#     --topic reddit_post_filtered \
#     --max-messages 10 \
#     --from-beginning \
#     --group filtered_data_consumer 
#     --timeout-ms 15000
[WI-746][TI-2013] - [INFO] 2024-04-29 17:27:24.047 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-746][TI-2013] - [INFO] 2024-04-29 17:27:24.048 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_6/746/2013/746_2013.sh
[WI-746][TI-2013] - [INFO] 2024-04-29 17:27:24.065 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 134
[WI-0][TI-2013] - [INFO] 2024-04-29 17:27:24.169 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=2013, success=true)
[WI-0][TI-2013] - [INFO] 2024-04-29 17:27:24.190 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=2013)
[WI-0][TI-0] - [INFO] 2024-04-29 17:27:24.489 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7219251336898396 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-29 17:27:25.070 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
[WI-746][TI-2013] - [INFO] 2024-04-29 17:27:25.083 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_6/746/2013, processId:134 ,exitStatusCode:0 ,processWaitForStatus:true ,processExitValue:0
[WI-746][TI-2013] - [INFO] 2024-04-29 17:27:25.085 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-746][TI-2013] - [INFO] 2024-04-29 17:27:25.085 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-746][TI-2013] - [INFO] 2024-04-29 17:27:25.085 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-746][TI-2013] - [INFO] 2024-04-29 17:27:25.086 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-746][TI-2013] - [INFO] 2024-04-29 17:27:25.098 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: SUCCESS to master : 172.18.1.1:1234
[WI-746][TI-2013] - [INFO] 2024-04-29 17:27:25.099 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-746][TI-2013] - [INFO] 2024-04-29 17:27:25.099 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_6/746/2013
[WI-746][TI-2013] - [INFO] 2024-04-29 17:27:25.154 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_6/746/2013
[WI-746][TI-2013] - [INFO] 2024-04-29 17:27:25.160 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-2013] - [INFO] 2024-04-29 17:27:26.102 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=2013, success=true)
[WI-0][TI-0] - [INFO] 2024-04-29 17:27:26.227 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=2014, taskName=persist_to_postgre, firstSubmitTime=1714382846193, startTime=0, taskType=PYTHON, workflowInstanceHost=172.18.0.10:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13426477386080, processDefineVersion=6, appIds=null, processInstanceId=746, scheduleTime=0, globalParams=null, executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[{"prop":"query","direct":"OUT","type":"VARCHAR","value":""}],"rawScript":"import re\n\n# define the table to send the data to\ntable_name = \"filtered_data_persistence\"\n\n# Provided JSON data as strings\njson_data = ''' \n{\n  \"user\": \"premiumplatinum\",\n  \"content\": \"singapore is stupid\",\n  \"url\": \"https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/\",\n  \"context\": \"21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist\",\n  \"score\": 131,\n  \"type\": \"post\",\n  \"id\": \"1c9itat\",\n  \"datetime\": \"2024-04-21 22:10:42\"\n}\n{\n        \"user\": \"premiumplatinum\",\n        \"content\": \"s is stupid\",\n        \"url\": \"https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/\",\n        \"context\": \"21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist\",\n        \"score\": 131,\n        \"type\": \"post\",\n        \"id\": \"1c9itat\",\n        \"datetime\": \"2024-04-21 22:10:42\"\n}\n'''\n\n# process the kafka messages to individual JSON objects\njson_objects = json_data.replace('}\\n{', '},\\n{').strip()\njson_objects = re.sub(\" +\", \" \",json_objects)   \njson_objects = '[' + json_objects + ']'\n\n# convert JSON string to a list of dicts\njson_list = json.loads(json_objects)\n\n# convert list of dictionaries into list of tuples containing only the values\nvalues = [tuple(message.values()) for message in json_list]\n\n# create the SQL Query\nquery = f'''\nINSERT INTO {table_name} (user, content, url, context, score, type, id, datetime)\nVALUES \n'''\n\nfor value in values:\n    query += str(value) + ',\\n'\n\n# remove the last 2 character ,\\n and change it to ; for the query\nquery = query[:-2] + ';'\n\n# pass the query as a parameter downstream\nprint(\"#setValue(query=%s)\" % query)","resourceList":[]}, environmentConfig=null, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='persist_to_postgre'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='746'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240429'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240428'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='2014'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='es_filtered_data_persistence_subprocess'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13426451158240'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13426477386080'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240429172726'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=null, dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-746][TI-2014] - [INFO] 2024-04-29 17:27:26.235 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-746][TI-2014] - [INFO] 2024-04-29 17:27:26.244 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-746][TI-2014] - [INFO] 2024-04-29 17:27:26.245 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-746][TI-2014] - [INFO] 2024-04-29 17:27:26.246 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-746][TI-2014] - [INFO] 2024-04-29 17:27:26.246 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1714382846246
[WI-746][TI-2014] - [INFO] 2024-04-29 17:27:26.247 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 746_2014
[WI-746][TI-2014] - [INFO] 2024-04-29 17:27:26.235 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: persist_to_postgre to wait queue success
[WI-746][TI-2014] - [INFO] 2024-04-29 17:27:26.251 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 2014,
  "taskName" : "persist_to_postgre",
  "firstSubmitTime" : 1714382846193,
  "startTime" : 1714382846246,
  "taskType" : "PYTHON",
  "workflowInstanceHost" : "172.18.0.10:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240429/13426477386080/6/746/2014.log",
  "processId" : 0,
  "processDefineCode" : 13426477386080,
  "processDefineVersion" : 6,
  "processInstanceId" : 746,
  "scheduleTime" : 0,
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[{\"prop\":\"query\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"\"}],\"rawScript\":\"import re\\n\\n# define the table to send the data to\\ntable_name = \\\"filtered_data_persistence\\\"\\n\\n# Provided JSON data as strings\\njson_data = ''' \\n{\\n  \\\"user\\\": \\\"premiumplatinum\\\",\\n  \\\"content\\\": \\\"singapore is stupid\\\",\\n  \\\"url\\\": \\\"https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/\\\",\\n  \\\"context\\\": \\\"21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist\\\",\\n  \\\"score\\\": 131,\\n  \\\"type\\\": \\\"post\\\",\\n  \\\"id\\\": \\\"1c9itat\\\",\\n  \\\"datetime\\\": \\\"2024-04-21 22:10:42\\\"\\n}\\n{\\n        \\\"user\\\": \\\"premiumplatinum\\\",\\n        \\\"content\\\": \\\"s is stupid\\\",\\n        \\\"url\\\": \\\"https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/\\\",\\n        \\\"context\\\": \\\"21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist\\\",\\n        \\\"score\\\": 131,\\n        \\\"type\\\": \\\"post\\\",\\n        \\\"id\\\": \\\"1c9itat\\\",\\n        \\\"datetime\\\": \\\"2024-04-21 22:10:42\\\"\\n}\\n'''\\n\\n# process the kafka messages to individual JSON objects\\njson_objects = json_data.replace('}\\\\n{', '},\\\\n{').strip()\\njson_objects = re.sub(\\\" +\\\", \\\" \\\",json_objects)   \\njson_objects = '[' + json_objects + ']'\\n\\n# convert JSON string to a list of dicts\\njson_list = json.loads(json_objects)\\n\\n# convert list of dictionaries into list of tuples containing only the values\\nvalues = [tuple(message.values()) for message in json_list]\\n\\n# create the SQL Query\\nquery = f'''\\nINSERT INTO {table_name} (user, content, url, context, score, type, id, datetime)\\nVALUES \\n'''\\n\\nfor value in values:\\n    query += str(value) + ',\\\\n'\\n\\n# remove the last 2 character ,\\\\n and change it to ; for the query\\nquery = query[:-2] + ';'\\n\\n# pass the query as a parameter downstream\\nprint(\\\"#setValue(query=%s)\\\" % query)\",\"resourceList\":[]}",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "persist_to_postgre"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "746"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240429"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240428"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "2014"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "es_filtered_data_persistence_subprocess"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13426451158240"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13426477386080"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240429172726"
    }
  },
  "taskAppId" : "746_2014",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-746][TI-2014] - [INFO] 2024-04-29 17:27:26.253 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-746][TI-2014] - [INFO] 2024-04-29 17:27:26.254 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-746][TI-2014] - [INFO] 2024-04-29 17:27:26.254 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-746][TI-2014] - [INFO] 2024-04-29 17:27:26.262 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-746][TI-2014] - [INFO] 2024-04-29 17:27:26.263 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-746][TI-2014] - [INFO] 2024-04-29 17:27:26.265 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_6/746/2014 check successfully
[WI-746][TI-2014] - [INFO] 2024-04-29 17:27:26.266 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.python.PythonTaskChannel successfully
[WI-746][TI-2014] - [INFO] 2024-04-29 17:27:26.271 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-746][TI-2014] - [INFO] 2024-04-29 17:27:26.277 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-746][TI-2014] - [INFO] 2024-04-29 17:27:26.288 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: PYTHON create successfully
[WI-746][TI-2014] - [INFO] 2024-04-29 17:27:26.291 +0800 o.a.d.p.t.p.PythonTask:[75] - Initialize python task params {
  "localParams" : [ {
    "prop" : "query",
    "direct" : "OUT",
    "type" : "VARCHAR",
    "value" : ""
  } ],
  "varPool" : null,
  "rawScript" : "import re\n\n# define the table to send the data to\ntable_name = \"filtered_data_persistence\"\n\n# Provided JSON data as strings\njson_data = ''' \n{\n  \"user\": \"premiumplatinum\",\n  \"content\": \"singapore is stupid\",\n  \"url\": \"https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/\",\n  \"context\": \"21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist\",\n  \"score\": 131,\n  \"type\": \"post\",\n  \"id\": \"1c9itat\",\n  \"datetime\": \"2024-04-21 22:10:42\"\n}\n{\n        \"user\": \"premiumplatinum\",\n        \"content\": \"s is stupid\",\n        \"url\": \"https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/\",\n        \"context\": \"21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist\",\n        \"score\": 131,\n        \"type\": \"post\",\n        \"id\": \"1c9itat\",\n        \"datetime\": \"2024-04-21 22:10:42\"\n}\n'''\n\n# process the kafka messages to individual JSON objects\njson_objects = json_data.replace('}\\n{', '},\\n{').strip()\njson_objects = re.sub(\" +\", \" \",json_objects)   \njson_objects = '[' + json_objects + ']'\n\n# convert JSON string to a list of dicts\njson_list = json.loads(json_objects)\n\n# convert list of dictionaries into list of tuples containing only the values\nvalues = [tuple(message.values()) for message in json_list]\n\n# create the SQL Query\nquery = f'''\nINSERT INTO {table_name} (user, content, url, context, score, type, id, datetime)\nVALUES \n'''\n\nfor value in values:\n    query += str(value) + ',\\n'\n\n# remove the last 2 character ,\\n and change it to ; for the query\nquery = query[:-2] + ';'\n\n# pass the query as a parameter downstream\nprint(\"#setValue(query=%s)\" % query)",
  "resourceList" : [ ]
}
[WI-746][TI-2014] - [INFO] 2024-04-29 17:27:26.291 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-746][TI-2014] - [INFO] 2024-04-29 17:27:26.292 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: null successfully
[WI-746][TI-2014] - [INFO] 2024-04-29 17:27:26.293 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-746][TI-2014] - [INFO] 2024-04-29 17:27:26.293 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-746][TI-2014] - [INFO] 2024-04-29 17:27:26.293 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-746][TI-2014] - [INFO] 2024-04-29 17:27:26.294 +0800 o.a.d.p.t.p.PythonTask:[165] - raw python script : import re

# define the table to send the data to
table_name = "filtered_data_persistence"

# Provided JSON data as strings
json_data = ''' 
{
  "user": "premiumplatinum",
  "content": "singapore is stupid",
  "url": "https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/",
  "context": "21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist",
  "score": 131,
  "type": "post",
  "id": "1c9itat",
  "datetime": "2024-04-21 22:10:42"
}
{
        "user": "premiumplatinum",
        "content": "s is stupid",
        "url": "https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/",
        "context": "21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist",
        "score": 131,
        "type": "post",
        "id": "1c9itat",
        "datetime": "2024-04-21 22:10:42"
}
'''

# process the kafka messages to individual JSON objects
json_objects = json_data.replace('}\n{', '},\n{').strip()
json_objects = re.sub(" +", " ",json_objects)   
json_objects = '[' + json_objects + ']'

# convert JSON string to a list of dicts
json_list = json.loads(json_objects)

# convert list of dictionaries into list of tuples containing only the values
values = [tuple(message.values()) for message in json_list]

# create the SQL Query
query = f'''
INSERT INTO {table_name} (user, content, url, context, score, type, id, datetime)
VALUES 
'''

for value in values:
    query += str(value) + ',\n'

# remove the last 2 character ,\n and change it to ; for the query
query = query[:-2] + ';'

# pass the query as a parameter downstream
print("#setValue(query=%s)" % query)
[WI-746][TI-2014] - [INFO] 2024-04-29 17:27:26.294 +0800 o.a.d.p.t.p.PythonTask:[131] - tenantCode :default, task dir:/tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_6/746/2014
[WI-746][TI-2014] - [INFO] 2024-04-29 17:27:26.295 +0800 o.a.d.p.t.p.PythonTask:[134] - generate python script file:/tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_6/746/2014/py_746_2014.py
[WI-746][TI-2014] - [INFO] 2024-04-29 17:27:26.295 +0800 o.a.d.p.t.p.PythonTask:[141] - #-*- encoding=utf8 -*-

import re

# define the table to send the data to
table_name = "filtered_data_persistence"

# Provided JSON data as strings
json_data = ''' 
{
  "user": "premiumplatinum",
  "content": "singapore is stupid",
  "url": "https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/",
  "context": "21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist",
  "score": 131,
  "type": "post",
  "id": "1c9itat",
  "datetime": "2024-04-21 22:10:42"
}
{
        "user": "premiumplatinum",
        "content": "s is stupid",
        "url": "https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/",
        "context": "21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist",
        "score": 131,
        "type": "post",
        "id": "1c9itat",
        "datetime": "2024-04-21 22:10:42"
}
'''

# process the kafka messages to individual JSON objects
json_objects = json_data.replace('}\n{', '},\n{').strip()
json_objects = re.sub(" +", " ",json_objects)   
json_objects = '[' + json_objects + ']'

# convert JSON string to a list of dicts
json_list = json.loads(json_objects)

# convert list of dictionaries into list of tuples containing only the values
values = [tuple(message.values()) for message in json_list]

# create the SQL Query
query = f'''
INSERT INTO {table_name} (user, content, url, context, score, type, id, datetime)
VALUES 
'''

for value in values:
    query += str(value) + ',\n'

# remove the last 2 character ,\n and change it to ; for the query
query = query[:-2] + ';'

# pass the query as a parameter downstream
print("#setValue(query=%s)" % query)
[WI-746][TI-2014] - [INFO] 2024-04-29 17:27:26.307 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-746][TI-2014] - [INFO] 2024-04-29 17:27:26.307 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-746][TI-2014] - [INFO] 2024-04-29 17:27:26.307 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
${PYTHON_LAUNCHER} /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_6/746/2014/py_746_2014.py
[WI-746][TI-2014] - [INFO] 2024-04-29 17:27:26.308 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-746][TI-2014] - [INFO] 2024-04-29 17:27:26.308 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_6/746/2014/746_2014.sh
[WI-746][TI-2014] - [INFO] 2024-04-29 17:27:26.312 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 148
[WI-0][TI-2014] - [INFO] 2024-04-29 17:27:27.122 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=2014, success=true)
[WI-0][TI-2014] - [INFO] 2024-04-29 17:27:27.140 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=2014)
[WI-0][TI-0] - [INFO] 2024-04-29 17:27:27.315 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
	/tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_6/746/2014/746_2014.sh: line 4: /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_6/746/2014/py_746_2014.py: Permission denied
[WI-746][TI-2014] - [INFO] 2024-04-29 17:27:27.320 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_6/746/2014, processId:148 ,exitStatusCode:126 ,processWaitForStatus:true ,processExitValue:126
[WI-746][TI-2014] - [INFO] 2024-04-29 17:27:27.321 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-746][TI-2014] - [INFO] 2024-04-29 17:27:27.321 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-746][TI-2014] - [INFO] 2024-04-29 17:27:27.321 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-746][TI-2014] - [INFO] 2024-04-29 17:27:27.327 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-746][TI-2014] - [INFO] 2024-04-29 17:27:27.365 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: FAILURE to master : 172.18.1.1:1234
[WI-746][TI-2014] - [INFO] 2024-04-29 17:27:27.366 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-746][TI-2014] - [INFO] 2024-04-29 17:27:27.366 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_6/746/2014
[WI-746][TI-2014] - [INFO] 2024-04-29 17:27:27.366 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_6/746/2014
[WI-746][TI-2014] - [INFO] 2024-04-29 17:27:27.367 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-2014] - [INFO] 2024-04-29 17:27:27.940 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=2014, processInstanceId=746, status=6, startTime=1714382846246, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, logPath=/opt/dolphinscheduler/logs/20240429/13426477386080/6/746/2014.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_6/746/2014, endTime=1714382847322, processId=148, appIds=null, varPool=[{"prop":"query","direct":"OUT","type":"VARCHAR","value":""}], eventCreateTime=0, eventSendTime=0)
[WI-0][TI-2014] - [INFO] 2024-04-29 17:27:27.973 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=2014, processInstanceId=746, status=6, startTime=1714382846246, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, logPath=/opt/dolphinscheduler/logs/20240429/13426477386080/6/746/2014.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_6/746/2014, endTime=1714382847322, processId=148, appIds=null, varPool=[{"prop":"query","direct":"OUT","type":"VARCHAR","value":""}], eventCreateTime=0, eventSendTime=1714382847940)
[WI-0][TI-2014] - [INFO] 2024-04-29 17:27:28.159 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=2014, success=true)
[WI-0][TI-2014] - [INFO] 2024-04-29 17:27:28.166 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=2014, success=true)
[WI-0][TI-0] - [INFO] 2024-04-29 17:27:28.248 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=2015, taskName=persist_to_postgre, firstSubmitTime=1714382848223, startTime=0, taskType=PYTHON, workflowInstanceHost=172.18.0.10:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13426477386080, processDefineVersion=6, appIds=null, processInstanceId=746, scheduleTime=0, globalParams=null, executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[{"prop":"query","direct":"OUT","type":"VARCHAR","value":""}],"rawScript":"import re\n\n# define the table to send the data to\ntable_name = \"filtered_data_persistence\"\n\n# Provided JSON data as strings\njson_data = ''' \n{\n  \"user\": \"premiumplatinum\",\n  \"content\": \"singapore is stupid\",\n  \"url\": \"https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/\",\n  \"context\": \"21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist\",\n  \"score\": 131,\n  \"type\": \"post\",\n  \"id\": \"1c9itat\",\n  \"datetime\": \"2024-04-21 22:10:42\"\n}\n{\n        \"user\": \"premiumplatinum\",\n        \"content\": \"s is stupid\",\n        \"url\": \"https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/\",\n        \"context\": \"21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist\",\n        \"score\": 131,\n        \"type\": \"post\",\n        \"id\": \"1c9itat\",\n        \"datetime\": \"2024-04-21 22:10:42\"\n}\n'''\n\n# process the kafka messages to individual JSON objects\njson_objects = json_data.replace('}\\n{', '},\\n{').strip()\njson_objects = re.sub(\" +\", \" \",json_objects)   \njson_objects = '[' + json_objects + ']'\n\n# convert JSON string to a list of dicts\njson_list = json.loads(json_objects)\n\n# convert list of dictionaries into list of tuples containing only the values\nvalues = [tuple(message.values()) for message in json_list]\n\n# create the SQL Query\nquery = f'''\nINSERT INTO {table_name} (user, content, url, context, score, type, id, datetime)\nVALUES \n'''\n\nfor value in values:\n    query += str(value) + ',\\n'\n\n# remove the last 2 character ,\\n and change it to ; for the query\nquery = query[:-2] + ';'\n\n# pass the query as a parameter downstream\nprint(\"#setValue(query=%s)\" % query)","resourceList":[]}, environmentConfig=null, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='persist_to_postgre'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, query=Property{prop='query', direct=OUT, type=VARCHAR, value=''}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240429'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='2015'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13426451158240'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240429172728'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='746'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240428'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='es_filtered_data_persistence_subprocess'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13426477386080'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"query","direct":"OUT","type":"VARCHAR","value":""}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-746][TI-2015] - [INFO] 2024-04-29 17:27:28.250 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: persist_to_postgre to wait queue success
[WI-746][TI-2015] - [INFO] 2024-04-29 17:27:28.250 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-746][TI-2015] - [INFO] 2024-04-29 17:27:28.252 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-746][TI-2015] - [INFO] 2024-04-29 17:27:28.252 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-746][TI-2015] - [INFO] 2024-04-29 17:27:28.252 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-746][TI-2015] - [INFO] 2024-04-29 17:27:28.253 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1714382848253
[WI-746][TI-2015] - [INFO] 2024-04-29 17:27:28.254 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 746_2015
[WI-746][TI-2015] - [INFO] 2024-04-29 17:27:28.254 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 2015,
  "taskName" : "persist_to_postgre",
  "firstSubmitTime" : 1714382848223,
  "startTime" : 1714382848253,
  "taskType" : "PYTHON",
  "workflowInstanceHost" : "172.18.0.10:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240429/13426477386080/6/746/2015.log",
  "processId" : 0,
  "processDefineCode" : 13426477386080,
  "processDefineVersion" : 6,
  "processInstanceId" : 746,
  "scheduleTime" : 0,
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[{\"prop\":\"query\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"\"}],\"rawScript\":\"import re\\n\\n# define the table to send the data to\\ntable_name = \\\"filtered_data_persistence\\\"\\n\\n# Provided JSON data as strings\\njson_data = ''' \\n{\\n  \\\"user\\\": \\\"premiumplatinum\\\",\\n  \\\"content\\\": \\\"singapore is stupid\\\",\\n  \\\"url\\\": \\\"https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/\\\",\\n  \\\"context\\\": \\\"21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist\\\",\\n  \\\"score\\\": 131,\\n  \\\"type\\\": \\\"post\\\",\\n  \\\"id\\\": \\\"1c9itat\\\",\\n  \\\"datetime\\\": \\\"2024-04-21 22:10:42\\\"\\n}\\n{\\n        \\\"user\\\": \\\"premiumplatinum\\\",\\n        \\\"content\\\": \\\"s is stupid\\\",\\n        \\\"url\\\": \\\"https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/\\\",\\n        \\\"context\\\": \\\"21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist\\\",\\n        \\\"score\\\": 131,\\n        \\\"type\\\": \\\"post\\\",\\n        \\\"id\\\": \\\"1c9itat\\\",\\n        \\\"datetime\\\": \\\"2024-04-21 22:10:42\\\"\\n}\\n'''\\n\\n# process the kafka messages to individual JSON objects\\njson_objects = json_data.replace('}\\\\n{', '},\\\\n{').strip()\\njson_objects = re.sub(\\\" +\\\", \\\" \\\",json_objects)   \\njson_objects = '[' + json_objects + ']'\\n\\n# convert JSON string to a list of dicts\\njson_list = json.loads(json_objects)\\n\\n# convert list of dictionaries into list of tuples containing only the values\\nvalues = [tuple(message.values()) for message in json_list]\\n\\n# create the SQL Query\\nquery = f'''\\nINSERT INTO {table_name} (user, content, url, context, score, type, id, datetime)\\nVALUES \\n'''\\n\\nfor value in values:\\n    query += str(value) + ',\\\\n'\\n\\n# remove the last 2 character ,\\\\n and change it to ; for the query\\nquery = query[:-2] + ';'\\n\\n# pass the query as a parameter downstream\\nprint(\\\"#setValue(query=%s)\\\" % query)\",\"resourceList\":[]}",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "persist_to_postgre"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "query" : {
      "prop" : "query",
      "direct" : "OUT",
      "type" : "VARCHAR",
      "value" : ""
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240429"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "2015"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13426451158240"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240429172728"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "746"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240428"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "es_filtered_data_persistence_subprocess"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13426477386080"
    }
  },
  "taskAppId" : "746_2015",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"query\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-746][TI-2015] - [INFO] 2024-04-29 17:27:28.255 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-746][TI-2015] - [INFO] 2024-04-29 17:27:28.255 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-746][TI-2015] - [INFO] 2024-04-29 17:27:28.255 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-746][TI-2015] - [INFO] 2024-04-29 17:27:28.302 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-746][TI-2015] - [INFO] 2024-04-29 17:27:28.303 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-746][TI-2015] - [INFO] 2024-04-29 17:27:28.304 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_6/746/2015 check successfully
[WI-746][TI-2015] - [INFO] 2024-04-29 17:27:28.305 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.python.PythonTaskChannel successfully
[WI-746][TI-2015] - [INFO] 2024-04-29 17:27:28.305 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-746][TI-2015] - [INFO] 2024-04-29 17:27:28.306 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-746][TI-2015] - [INFO] 2024-04-29 17:27:28.306 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: PYTHON create successfully
[WI-746][TI-2015] - [INFO] 2024-04-29 17:27:28.307 +0800 o.a.d.p.t.p.PythonTask:[75] - Initialize python task params {
  "localParams" : [ {
    "prop" : "query",
    "direct" : "OUT",
    "type" : "VARCHAR",
    "value" : ""
  } ],
  "varPool" : null,
  "rawScript" : "import re\n\n# define the table to send the data to\ntable_name = \"filtered_data_persistence\"\n\n# Provided JSON data as strings\njson_data = ''' \n{\n  \"user\": \"premiumplatinum\",\n  \"content\": \"singapore is stupid\",\n  \"url\": \"https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/\",\n  \"context\": \"21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist\",\n  \"score\": 131,\n  \"type\": \"post\",\n  \"id\": \"1c9itat\",\n  \"datetime\": \"2024-04-21 22:10:42\"\n}\n{\n        \"user\": \"premiumplatinum\",\n        \"content\": \"s is stupid\",\n        \"url\": \"https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/\",\n        \"context\": \"21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist\",\n        \"score\": 131,\n        \"type\": \"post\",\n        \"id\": \"1c9itat\",\n        \"datetime\": \"2024-04-21 22:10:42\"\n}\n'''\n\n# process the kafka messages to individual JSON objects\njson_objects = json_data.replace('}\\n{', '},\\n{').strip()\njson_objects = re.sub(\" +\", \" \",json_objects)   \njson_objects = '[' + json_objects + ']'\n\n# convert JSON string to a list of dicts\njson_list = json.loads(json_objects)\n\n# convert list of dictionaries into list of tuples containing only the values\nvalues = [tuple(message.values()) for message in json_list]\n\n# create the SQL Query\nquery = f'''\nINSERT INTO {table_name} (user, content, url, context, score, type, id, datetime)\nVALUES \n'''\n\nfor value in values:\n    query += str(value) + ',\\n'\n\n# remove the last 2 character ,\\n and change it to ; for the query\nquery = query[:-2] + ';'\n\n# pass the query as a parameter downstream\nprint(\"#setValue(query=%s)\" % query)",
  "resourceList" : [ ]
}
[WI-746][TI-2015] - [INFO] 2024-04-29 17:27:28.307 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-746][TI-2015] - [INFO] 2024-04-29 17:27:28.307 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"query","direct":"OUT","type":"VARCHAR","value":""}] successfully
[WI-746][TI-2015] - [INFO] 2024-04-29 17:27:28.307 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-746][TI-2015] - [INFO] 2024-04-29 17:27:28.307 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-746][TI-2015] - [INFO] 2024-04-29 17:27:28.308 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-746][TI-2015] - [INFO] 2024-04-29 17:27:28.308 +0800 o.a.d.p.t.p.PythonTask:[165] - raw python script : import re

# define the table to send the data to
table_name = "filtered_data_persistence"

# Provided JSON data as strings
json_data = ''' 
{
  "user": "premiumplatinum",
  "content": "singapore is stupid",
  "url": "https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/",
  "context": "21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist",
  "score": 131,
  "type": "post",
  "id": "1c9itat",
  "datetime": "2024-04-21 22:10:42"
}
{
        "user": "premiumplatinum",
        "content": "s is stupid",
        "url": "https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/",
        "context": "21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist",
        "score": 131,
        "type": "post",
        "id": "1c9itat",
        "datetime": "2024-04-21 22:10:42"
}
'''

# process the kafka messages to individual JSON objects
json_objects = json_data.replace('}\n{', '},\n{').strip()
json_objects = re.sub(" +", " ",json_objects)   
json_objects = '[' + json_objects + ']'

# convert JSON string to a list of dicts
json_list = json.loads(json_objects)

# convert list of dictionaries into list of tuples containing only the values
values = [tuple(message.values()) for message in json_list]

# create the SQL Query
query = f'''
INSERT INTO {table_name} (user, content, url, context, score, type, id, datetime)
VALUES 
'''

for value in values:
    query += str(value) + ',\n'

# remove the last 2 character ,\n and change it to ; for the query
query = query[:-2] + ';'

# pass the query as a parameter downstream
print("#setValue(query=%s)" % query)
[WI-746][TI-2015] - [INFO] 2024-04-29 17:27:28.308 +0800 o.a.d.p.t.p.PythonTask:[131] - tenantCode :default, task dir:/tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_6/746/2015
[WI-746][TI-2015] - [INFO] 2024-04-29 17:27:28.308 +0800 o.a.d.p.t.p.PythonTask:[134] - generate python script file:/tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_6/746/2015/py_746_2015.py
[WI-746][TI-2015] - [INFO] 2024-04-29 17:27:28.308 +0800 o.a.d.p.t.p.PythonTask:[141] - #-*- encoding=utf8 -*-

import re

# define the table to send the data to
table_name = "filtered_data_persistence"

# Provided JSON data as strings
json_data = ''' 
{
  "user": "premiumplatinum",
  "content": "singapore is stupid",
  "url": "https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/",
  "context": "21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist",
  "score": 131,
  "type": "post",
  "id": "1c9itat",
  "datetime": "2024-04-21 22:10:42"
}
{
        "user": "premiumplatinum",
        "content": "s is stupid",
        "url": "https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/",
        "context": "21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist",
        "score": 131,
        "type": "post",
        "id": "1c9itat",
        "datetime": "2024-04-21 22:10:42"
}
'''

# process the kafka messages to individual JSON objects
json_objects = json_data.replace('}\n{', '},\n{').strip()
json_objects = re.sub(" +", " ",json_objects)   
json_objects = '[' + json_objects + ']'

# convert JSON string to a list of dicts
json_list = json.loads(json_objects)

# convert list of dictionaries into list of tuples containing only the values
values = [tuple(message.values()) for message in json_list]

# create the SQL Query
query = f'''
INSERT INTO {table_name} (user, content, url, context, score, type, id, datetime)
VALUES 
'''

for value in values:
    query += str(value) + ',\n'

# remove the last 2 character ,\n and change it to ; for the query
query = query[:-2] + ';'

# pass the query as a parameter downstream
print("#setValue(query=%s)" % query)
[WI-746][TI-2015] - [INFO] 2024-04-29 17:27:28.316 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-746][TI-2015] - [INFO] 2024-04-29 17:27:28.316 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-746][TI-2015] - [INFO] 2024-04-29 17:27:28.316 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
${PYTHON_LAUNCHER} /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_6/746/2015/py_746_2015.py
[WI-746][TI-2015] - [INFO] 2024-04-29 17:27:28.316 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-746][TI-2015] - [INFO] 2024-04-29 17:27:28.316 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_6/746/2015/746_2015.sh
[WI-746][TI-2015] - [INFO] 2024-04-29 17:27:28.343 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 162
[WI-0][TI-0] - [INFO] 2024-04-29 17:27:28.343 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
[WI-0][TI-0] - [INFO] 2024-04-29 17:27:28.519 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9753424657534246 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-2015] - [INFO] 2024-04-29 17:27:28.978 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionRunningEvent(taskInstanceId=2015, processInstanceId=746, startTime=1714382848253, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, status=TaskExecutionStatus{code=1, desc='running'}, logPath=/opt/dolphinscheduler/logs/20240429/13426477386080/6/746/2015.log, executePath=null, processId=0, appIds=null, eventCreateTime=0, eventSendTime=0)
[WI-0][TI-2015] - [INFO] 2024-04-29 17:27:28.985 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionRunningEvent(taskInstanceId=2015, processInstanceId=746, startTime=1714382848253, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, status=TaskExecutionStatus{code=1, desc='running'}, logPath=/opt/dolphinscheduler/logs/20240429/13426477386080/6/746/2015.log, executePath=null, processId=0, appIds=null, eventCreateTime=0, eventSendTime=1714382848975)
[WI-0][TI-2015] - [INFO] 2024-04-29 17:27:28.985 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionInfoEvent(taskInstanceId=2015, processInstanceId=746, startTime=1714382848253, workflowInstanceHost=172.18.0.10:5678, taskInstanceHost=172.18.1.1:1234, logPath=null, processId=0, eventCreateTime=0, eventSendTime=0)
[WI-0][TI-2015] - [INFO] 2024-04-29 17:27:28.991 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionInfoEvent(taskInstanceId=2015, processInstanceId=746, startTime=1714382848253, workflowInstanceHost=172.18.0.10:5678, taskInstanceHost=172.18.1.1:1234, logPath=null, processId=0, eventCreateTime=0, eventSendTime=1714382848975)
[WI-0][TI-2015] - [INFO] 2024-04-29 17:27:29.144 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=2015, success=true)
[WI-0][TI-2015] - [INFO] 2024-04-29 17:27:29.154 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=2015)
[WI-0][TI-2015] - [INFO] 2024-04-29 17:27:29.163 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=2015, success=true)
[WI-0][TI-2015] - [INFO] 2024-04-29 17:27:29.191 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=2015)
[WI-0][TI-0] - [INFO] 2024-04-29 17:27:29.347 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	/tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_6/746/2015/746_2015.sh: line 4: /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_6/746/2015/py_746_2015.py: Permission denied
[WI-746][TI-2015] - [INFO] 2024-04-29 17:27:29.361 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_6/746/2015, processId:162 ,exitStatusCode:126 ,processWaitForStatus:true ,processExitValue:126
[WI-746][TI-2015] - [INFO] 2024-04-29 17:27:29.362 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-746][TI-2015] - [INFO] 2024-04-29 17:27:29.362 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-746][TI-2015] - [INFO] 2024-04-29 17:27:29.362 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-746][TI-2015] - [INFO] 2024-04-29 17:27:29.364 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-746][TI-2015] - [INFO] 2024-04-29 17:27:29.388 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: FAILURE to master : 172.18.1.1:1234
[WI-746][TI-2015] - [INFO] 2024-04-29 17:27:29.389 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-746][TI-2015] - [INFO] 2024-04-29 17:27:29.389 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_6/746/2015
[WI-746][TI-2015] - [INFO] 2024-04-29 17:27:29.390 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_6/746/2015
[WI-746][TI-2015] - [INFO] 2024-04-29 17:27:29.391 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-0] - [INFO] 2024-04-29 17:27:29.550 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9730538922155688 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-2015] - [INFO] 2024-04-29 17:27:30.127 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=2015, processInstanceId=746, status=6, startTime=1714382848253, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, logPath=/opt/dolphinscheduler/logs/20240429/13426477386080/6/746/2015.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_6/746/2015, endTime=1714382849364, processId=162, appIds=null, varPool=[{"prop":"query","direct":"OUT","type":"VARCHAR","value":""}], eventCreateTime=0, eventSendTime=0)
[WI-0][TI-2015] - [INFO] 2024-04-29 17:27:30.152 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=2015, processInstanceId=746, status=6, startTime=1714382848253, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, logPath=/opt/dolphinscheduler/logs/20240429/13426477386080/6/746/2015.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_6/746/2015, endTime=1714382849364, processId=162, appIds=null, varPool=[{"prop":"query","direct":"OUT","type":"VARCHAR","value":""}], eventCreateTime=0, eventSendTime=1714382850127)
[WI-0][TI-2015] - [INFO] 2024-04-29 17:27:30.160 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=2015, success=true)
[WI-0][TI-2015] - [INFO] 2024-04-29 17:27:30.171 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=2015, success=true)
[WI-0][TI-0] - [INFO] 2024-04-29 17:27:32.574 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7624309392265194 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-29 17:27:33.609 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8202247191011236 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-29 17:27:34.614 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8756906077348067 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-29 17:27:42.839 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=2018, taskName=consume_filtered_data, firstSubmitTime=1714382862830, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.10:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13426477386080, processDefineVersion=6, appIds=null, processInstanceId=746, scheduleTime=0, globalParams=null, executorId=1, cmdTypeIfComplement=7, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[],"rawScript":"# /bin/kafka-console-consumer.sh \\\n#     --bootstrap-server kafka:9092 \\\n#     --topic reddit_post_filtered \\\n#     --max-messages 10 \\\n#     --from-beginning \\\n#     --group filtered_data_consumer \n#     --timeout-ms 15000","resourceList":[]}, environmentConfig=export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='consume_filtered_data'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='746'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240429'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240428'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='2018'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='es_filtered_data_persistence_subprocess'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13433255983872'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13426477386080'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240429172742'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-746][TI-2018] - [INFO] 2024-04-29 17:27:42.840 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: consume_filtered_data to wait queue success
[WI-746][TI-2018] - [INFO] 2024-04-29 17:27:42.840 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-746][TI-2018] - [INFO] 2024-04-29 17:27:42.845 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-746][TI-2018] - [INFO] 2024-04-29 17:27:42.846 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-746][TI-2018] - [INFO] 2024-04-29 17:27:42.846 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-746][TI-2018] - [INFO] 2024-04-29 17:27:42.846 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1714382862846
[WI-746][TI-2018] - [INFO] 2024-04-29 17:27:42.846 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 746_2018
[WI-746][TI-2018] - [INFO] 2024-04-29 17:27:42.846 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 2018,
  "taskName" : "consume_filtered_data",
  "firstSubmitTime" : 1714382862830,
  "startTime" : 1714382862846,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.10:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240429/13426477386080/6/746/2018.log",
  "processId" : 0,
  "processDefineCode" : 13426477386080,
  "processDefineVersion" : 6,
  "processInstanceId" : 746,
  "scheduleTime" : 0,
  "executorId" : 1,
  "cmdTypeIfComplement" : 7,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[],\"rawScript\":\"# /bin/kafka-console-consumer.sh \\\\\\n#     --bootstrap-server kafka:9092 \\\\\\n#     --topic reddit_post_filtered \\\\\\n#     --max-messages 10 \\\\\\n#     --from-beginning \\\\\\n#     --group filtered_data_consumer \\n#     --timeout-ms 15000\",\"resourceList\":[]}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "consume_filtered_data"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "746"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240429"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240428"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "2018"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "es_filtered_data_persistence_subprocess"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13433255983872"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13426477386080"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240429172742"
    }
  },
  "taskAppId" : "746_2018",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "varPool" : "[]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-746][TI-2018] - [INFO] 2024-04-29 17:27:42.847 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-746][TI-2018] - [INFO] 2024-04-29 17:27:42.847 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-746][TI-2018] - [INFO] 2024-04-29 17:27:42.847 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-746][TI-2018] - [INFO] 2024-04-29 17:27:42.852 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-746][TI-2018] - [INFO] 2024-04-29 17:27:42.853 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-746][TI-2018] - [INFO] 2024-04-29 17:27:42.853 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_6/746/2018 check successfully
[WI-746][TI-2018] - [INFO] 2024-04-29 17:27:42.853 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-746][TI-2018] - [INFO] 2024-04-29 17:27:42.853 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-746][TI-2018] - [INFO] 2024-04-29 17:27:42.854 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-746][TI-2018] - [INFO] 2024-04-29 17:27:42.854 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-746][TI-2018] - [INFO] 2024-04-29 17:27:42.854 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ ],
  "varPool" : null,
  "rawScript" : "# /bin/kafka-console-consumer.sh \\\n#     --bootstrap-server kafka:9092 \\\n#     --topic reddit_post_filtered \\\n#     --max-messages 10 \\\n#     --from-beginning \\\n#     --group filtered_data_consumer \n#     --timeout-ms 15000",
  "resourceList" : [ ]
}
[WI-746][TI-2018] - [INFO] 2024-04-29 17:27:42.854 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-746][TI-2018] - [INFO] 2024-04-29 17:27:42.854 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [] successfully
[WI-746][TI-2018] - [INFO] 2024-04-29 17:27:42.854 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-746][TI-2018] - [INFO] 2024-04-29 17:27:42.854 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-746][TI-2018] - [INFO] 2024-04-29 17:27:42.854 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-746][TI-2018] - [INFO] 2024-04-29 17:27:42.855 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-746][TI-2018] - [INFO] 2024-04-29 17:27:42.855 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-746][TI-2018] - [INFO] 2024-04-29 17:27:42.855 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export PYTHON_LAUNCHER=/bin/python3.11
# /bin/kafka-console-consumer.sh \
#     --bootstrap-server kafka:9092 \
#     --topic reddit_post_filtered \
#     --max-messages 10 \
#     --from-beginning \
#     --group filtered_data_consumer 
#     --timeout-ms 15000
[WI-746][TI-2018] - [INFO] 2024-04-29 17:27:42.855 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-746][TI-2018] - [INFO] 2024-04-29 17:27:42.855 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_6/746/2018/746_2018.sh
[WI-746][TI-2018] - [INFO] 2024-04-29 17:27:42.859 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 179
[WI-0][TI-2018] - [INFO] 2024-04-29 17:27:43.767 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=2018, success=true)
[WI-0][TI-2018] - [INFO] 2024-04-29 17:27:43.776 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=2018)
[WI-0][TI-0] - [INFO] 2024-04-29 17:27:43.860 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
[WI-746][TI-2018] - [INFO] 2024-04-29 17:27:43.862 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_6/746/2018, processId:179 ,exitStatusCode:0 ,processWaitForStatus:true ,processExitValue:0
[WI-746][TI-2018] - [INFO] 2024-04-29 17:27:43.863 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-746][TI-2018] - [INFO] 2024-04-29 17:27:43.863 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-746][TI-2018] - [INFO] 2024-04-29 17:27:43.863 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-746][TI-2018] - [INFO] 2024-04-29 17:27:43.864 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-746][TI-2018] - [INFO] 2024-04-29 17:27:43.870 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: SUCCESS to master : 172.18.1.1:1234
[WI-746][TI-2018] - [INFO] 2024-04-29 17:27:43.870 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-746][TI-2018] - [INFO] 2024-04-29 17:27:43.871 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_6/746/2018
[WI-746][TI-2018] - [INFO] 2024-04-29 17:27:43.871 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_6/746/2018
[WI-746][TI-2018] - [INFO] 2024-04-29 17:27:43.872 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-2018] - [INFO] 2024-04-29 17:27:44.742 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=2018, success=true)
[WI-0][TI-0] - [INFO] 2024-04-29 17:27:44.849 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=2019, taskName=persist_to_postgre, firstSubmitTime=1714382864838, startTime=0, taskType=PYTHON, workflowInstanceHost=172.18.0.10:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13426477386080, processDefineVersion=6, appIds=null, processInstanceId=746, scheduleTime=0, globalParams=null, executorId=1, cmdTypeIfComplement=7, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[{"prop":"query","direct":"OUT","type":"VARCHAR","value":""}],"rawScript":"import re\n\n# define the table to send the data to\ntable_name = \"filtered_data_persistence\"\n\n# Provided JSON data as strings\njson_data = ''' \n{\n  \"user\": \"premiumplatinum\",\n  \"content\": \"singapore is stupid\",\n  \"url\": \"https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/\",\n  \"context\": \"21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist\",\n  \"score\": 131,\n  \"type\": \"post\",\n  \"id\": \"1c9itat\",\n  \"datetime\": \"2024-04-21 22:10:42\"\n}\n{\n        \"user\": \"premiumplatinum\",\n        \"content\": \"s is stupid\",\n        \"url\": \"https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/\",\n        \"context\": \"21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist\",\n        \"score\": 131,\n        \"type\": \"post\",\n        \"id\": \"1c9itat\",\n        \"datetime\": \"2024-04-21 22:10:42\"\n}\n'''\n\n# process the kafka messages to individual JSON objects\njson_objects = json_data.replace('}\\n{', '},\\n{').strip()\njson_objects = re.sub(\" +\", \" \",json_objects)   \njson_objects = '[' + json_objects + ']'\n\n# convert JSON string to a list of dicts\njson_list = json.loads(json_objects)\n\n# convert list of dictionaries into list of tuples containing only the values\nvalues = [tuple(message.values()) for message in json_list]\n\n# create the SQL Query\nquery = f'''\nINSERT INTO {table_name} (user, content, url, context, score, type, id, datetime)\nVALUES \n'''\n\nfor value in values:\n    query += str(value) + ',\\n'\n\n# remove the last 2 character ,\\n and change it to ; for the query\nquery = query[:-2] + ';'\n\n# pass the query as a parameter downstream\nprint(\"#setValue(query=%s)\" % query)","resourceList":[]}, environmentConfig=null, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='persist_to_postgre'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='746'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240429'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240428'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='2019'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='es_filtered_data_persistence_subprocess'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13426451158240'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13426477386080'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240429172744'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=null, dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-746][TI-2019] - [INFO] 2024-04-29 17:27:44.849 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: persist_to_postgre to wait queue success
[WI-746][TI-2019] - [INFO] 2024-04-29 17:27:44.850 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-746][TI-2019] - [INFO] 2024-04-29 17:27:44.851 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-746][TI-2019] - [INFO] 2024-04-29 17:27:44.851 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-746][TI-2019] - [INFO] 2024-04-29 17:27:44.852 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-746][TI-2019] - [INFO] 2024-04-29 17:27:44.852 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1714382864852
[WI-746][TI-2019] - [INFO] 2024-04-29 17:27:44.852 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 746_2019
[WI-746][TI-2019] - [INFO] 2024-04-29 17:27:44.852 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 2019,
  "taskName" : "persist_to_postgre",
  "firstSubmitTime" : 1714382864838,
  "startTime" : 1714382864852,
  "taskType" : "PYTHON",
  "workflowInstanceHost" : "172.18.0.10:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240429/13426477386080/6/746/2019.log",
  "processId" : 0,
  "processDefineCode" : 13426477386080,
  "processDefineVersion" : 6,
  "processInstanceId" : 746,
  "scheduleTime" : 0,
  "executorId" : 1,
  "cmdTypeIfComplement" : 7,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[{\"prop\":\"query\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"\"}],\"rawScript\":\"import re\\n\\n# define the table to send the data to\\ntable_name = \\\"filtered_data_persistence\\\"\\n\\n# Provided JSON data as strings\\njson_data = ''' \\n{\\n  \\\"user\\\": \\\"premiumplatinum\\\",\\n  \\\"content\\\": \\\"singapore is stupid\\\",\\n  \\\"url\\\": \\\"https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/\\\",\\n  \\\"context\\\": \\\"21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist\\\",\\n  \\\"score\\\": 131,\\n  \\\"type\\\": \\\"post\\\",\\n  \\\"id\\\": \\\"1c9itat\\\",\\n  \\\"datetime\\\": \\\"2024-04-21 22:10:42\\\"\\n}\\n{\\n        \\\"user\\\": \\\"premiumplatinum\\\",\\n        \\\"content\\\": \\\"s is stupid\\\",\\n        \\\"url\\\": \\\"https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/\\\",\\n        \\\"context\\\": \\\"21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist\\\",\\n        \\\"score\\\": 131,\\n        \\\"type\\\": \\\"post\\\",\\n        \\\"id\\\": \\\"1c9itat\\\",\\n        \\\"datetime\\\": \\\"2024-04-21 22:10:42\\\"\\n}\\n'''\\n\\n# process the kafka messages to individual JSON objects\\njson_objects = json_data.replace('}\\\\n{', '},\\\\n{').strip()\\njson_objects = re.sub(\\\" +\\\", \\\" \\\",json_objects)   \\njson_objects = '[' + json_objects + ']'\\n\\n# convert JSON string to a list of dicts\\njson_list = json.loads(json_objects)\\n\\n# convert list of dictionaries into list of tuples containing only the values\\nvalues = [tuple(message.values()) for message in json_list]\\n\\n# create the SQL Query\\nquery = f'''\\nINSERT INTO {table_name} (user, content, url, context, score, type, id, datetime)\\nVALUES \\n'''\\n\\nfor value in values:\\n    query += str(value) + ',\\\\n'\\n\\n# remove the last 2 character ,\\\\n and change it to ; for the query\\nquery = query[:-2] + ';'\\n\\n# pass the query as a parameter downstream\\nprint(\\\"#setValue(query=%s)\\\" % query)\",\"resourceList\":[]}",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "persist_to_postgre"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "746"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240429"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240428"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "2019"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "es_filtered_data_persistence_subprocess"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13426451158240"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13426477386080"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240429172744"
    }
  },
  "taskAppId" : "746_2019",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-746][TI-2019] - [INFO] 2024-04-29 17:27:44.853 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-746][TI-2019] - [INFO] 2024-04-29 17:27:44.853 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-746][TI-2019] - [INFO] 2024-04-29 17:27:44.853 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-746][TI-2019] - [INFO] 2024-04-29 17:27:44.858 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-746][TI-2019] - [INFO] 2024-04-29 17:27:44.858 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-746][TI-2019] - [INFO] 2024-04-29 17:27:44.859 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_6/746/2019 check successfully
[WI-746][TI-2019] - [INFO] 2024-04-29 17:27:44.859 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.python.PythonTaskChannel successfully
[WI-746][TI-2019] - [INFO] 2024-04-29 17:27:44.859 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-746][TI-2019] - [INFO] 2024-04-29 17:27:44.860 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-746][TI-2019] - [INFO] 2024-04-29 17:27:44.860 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: PYTHON create successfully
[WI-746][TI-2019] - [INFO] 2024-04-29 17:27:44.861 +0800 o.a.d.p.t.p.PythonTask:[75] - Initialize python task params {
  "localParams" : [ {
    "prop" : "query",
    "direct" : "OUT",
    "type" : "VARCHAR",
    "value" : ""
  } ],
  "varPool" : null,
  "rawScript" : "import re\n\n# define the table to send the data to\ntable_name = \"filtered_data_persistence\"\n\n# Provided JSON data as strings\njson_data = ''' \n{\n  \"user\": \"premiumplatinum\",\n  \"content\": \"singapore is stupid\",\n  \"url\": \"https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/\",\n  \"context\": \"21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist\",\n  \"score\": 131,\n  \"type\": \"post\",\n  \"id\": \"1c9itat\",\n  \"datetime\": \"2024-04-21 22:10:42\"\n}\n{\n        \"user\": \"premiumplatinum\",\n        \"content\": \"s is stupid\",\n        \"url\": \"https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/\",\n        \"context\": \"21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist\",\n        \"score\": 131,\n        \"type\": \"post\",\n        \"id\": \"1c9itat\",\n        \"datetime\": \"2024-04-21 22:10:42\"\n}\n'''\n\n# process the kafka messages to individual JSON objects\njson_objects = json_data.replace('}\\n{', '},\\n{').strip()\njson_objects = re.sub(\" +\", \" \",json_objects)   \njson_objects = '[' + json_objects + ']'\n\n# convert JSON string to a list of dicts\njson_list = json.loads(json_objects)\n\n# convert list of dictionaries into list of tuples containing only the values\nvalues = [tuple(message.values()) for message in json_list]\n\n# create the SQL Query\nquery = f'''\nINSERT INTO {table_name} (user, content, url, context, score, type, id, datetime)\nVALUES \n'''\n\nfor value in values:\n    query += str(value) + ',\\n'\n\n# remove the last 2 character ,\\n and change it to ; for the query\nquery = query[:-2] + ';'\n\n# pass the query as a parameter downstream\nprint(\"#setValue(query=%s)\" % query)",
  "resourceList" : [ ]
}
[WI-746][TI-2019] - [INFO] 2024-04-29 17:27:44.861 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-746][TI-2019] - [INFO] 2024-04-29 17:27:44.861 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: null successfully
[WI-746][TI-2019] - [INFO] 2024-04-29 17:27:44.862 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-746][TI-2019] - [INFO] 2024-04-29 17:27:44.862 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-746][TI-2019] - [INFO] 2024-04-29 17:27:44.862 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-746][TI-2019] - [INFO] 2024-04-29 17:27:44.862 +0800 o.a.d.p.t.p.PythonTask:[165] - raw python script : import re

# define the table to send the data to
table_name = "filtered_data_persistence"

# Provided JSON data as strings
json_data = ''' 
{
  "user": "premiumplatinum",
  "content": "singapore is stupid",
  "url": "https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/",
  "context": "21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist",
  "score": 131,
  "type": "post",
  "id": "1c9itat",
  "datetime": "2024-04-21 22:10:42"
}
{
        "user": "premiumplatinum",
        "content": "s is stupid",
        "url": "https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/",
        "context": "21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist",
        "score": 131,
        "type": "post",
        "id": "1c9itat",
        "datetime": "2024-04-21 22:10:42"
}
'''

# process the kafka messages to individual JSON objects
json_objects = json_data.replace('}\n{', '},\n{').strip()
json_objects = re.sub(" +", " ",json_objects)   
json_objects = '[' + json_objects + ']'

# convert JSON string to a list of dicts
json_list = json.loads(json_objects)

# convert list of dictionaries into list of tuples containing only the values
values = [tuple(message.values()) for message in json_list]

# create the SQL Query
query = f'''
INSERT INTO {table_name} (user, content, url, context, score, type, id, datetime)
VALUES 
'''

for value in values:
    query += str(value) + ',\n'

# remove the last 2 character ,\n and change it to ; for the query
query = query[:-2] + ';'

# pass the query as a parameter downstream
print("#setValue(query=%s)" % query)
[WI-746][TI-2019] - [INFO] 2024-04-29 17:27:44.862 +0800 o.a.d.p.t.p.PythonTask:[131] - tenantCode :default, task dir:/tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_6/746/2019
[WI-746][TI-2019] - [INFO] 2024-04-29 17:27:44.863 +0800 o.a.d.p.t.p.PythonTask:[134] - generate python script file:/tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_6/746/2019/py_746_2019.py
[WI-746][TI-2019] - [INFO] 2024-04-29 17:27:44.863 +0800 o.a.d.p.t.p.PythonTask:[141] - #-*- encoding=utf8 -*-

import re

# define the table to send the data to
table_name = "filtered_data_persistence"

# Provided JSON data as strings
json_data = ''' 
{
  "user": "premiumplatinum",
  "content": "singapore is stupid",
  "url": "https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/",
  "context": "21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist",
  "score": 131,
  "type": "post",
  "id": "1c9itat",
  "datetime": "2024-04-21 22:10:42"
}
{
        "user": "premiumplatinum",
        "content": "s is stupid",
        "url": "https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/",
        "context": "21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist",
        "score": 131,
        "type": "post",
        "id": "1c9itat",
        "datetime": "2024-04-21 22:10:42"
}
'''

# process the kafka messages to individual JSON objects
json_objects = json_data.replace('}\n{', '},\n{').strip()
json_objects = re.sub(" +", " ",json_objects)   
json_objects = '[' + json_objects + ']'

# convert JSON string to a list of dicts
json_list = json.loads(json_objects)

# convert list of dictionaries into list of tuples containing only the values
values = [tuple(message.values()) for message in json_list]

# create the SQL Query
query = f'''
INSERT INTO {table_name} (user, content, url, context, score, type, id, datetime)
VALUES 
'''

for value in values:
    query += str(value) + ',\n'

# remove the last 2 character ,\n and change it to ; for the query
query = query[:-2] + ';'

# pass the query as a parameter downstream
print("#setValue(query=%s)" % query)
[WI-746][TI-2019] - [INFO] 2024-04-29 17:27:44.863 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-746][TI-2019] - [INFO] 2024-04-29 17:27:44.863 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-746][TI-2019] - [INFO] 2024-04-29 17:27:44.863 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
${PYTHON_LAUNCHER} /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_6/746/2019/py_746_2019.py
[WI-746][TI-2019] - [INFO] 2024-04-29 17:27:44.863 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-746][TI-2019] - [INFO] 2024-04-29 17:27:44.863 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_6/746/2019/746_2019.sh
[WI-746][TI-2019] - [INFO] 2024-04-29 17:27:44.867 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 189
[WI-0][TI-2019] - [INFO] 2024-04-29 17:27:45.749 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=2019, success=true)
[WI-0][TI-2019] - [INFO] 2024-04-29 17:27:45.764 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=2019)
[WI-0][TI-0] - [INFO] 2024-04-29 17:27:45.869 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
	/tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_6/746/2019/746_2019.sh: line 4: /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_6/746/2019/py_746_2019.py: Permission denied
[WI-746][TI-2019] - [INFO] 2024-04-29 17:27:45.871 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_6/746/2019, processId:189 ,exitStatusCode:126 ,processWaitForStatus:true ,processExitValue:126
[WI-746][TI-2019] - [INFO] 2024-04-29 17:27:45.871 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-746][TI-2019] - [INFO] 2024-04-29 17:27:45.872 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-746][TI-2019] - [INFO] 2024-04-29 17:27:45.872 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-746][TI-2019] - [INFO] 2024-04-29 17:27:45.874 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-746][TI-2019] - [INFO] 2024-04-29 17:27:45.879 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: FAILURE to master : 172.18.1.1:1234
[WI-746][TI-2019] - [INFO] 2024-04-29 17:27:45.880 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-746][TI-2019] - [INFO] 2024-04-29 17:27:45.880 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_6/746/2019
[WI-746][TI-2019] - [INFO] 2024-04-29 17:27:45.881 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_6/746/2019
[WI-746][TI-2019] - [INFO] 2024-04-29 17:27:45.881 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-2019] - [INFO] 2024-04-29 17:27:46.771 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=2019, success=true)
[WI-0][TI-0] - [INFO] 2024-04-29 17:27:46.861 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=2020, taskName=persist_to_postgre, firstSubmitTime=1714382866828, startTime=0, taskType=PYTHON, workflowInstanceHost=172.18.0.10:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13426477386080, processDefineVersion=6, appIds=null, processInstanceId=746, scheduleTime=0, globalParams=null, executorId=1, cmdTypeIfComplement=7, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[{"prop":"query","direct":"OUT","type":"VARCHAR","value":""}],"rawScript":"import re\n\n# define the table to send the data to\ntable_name = \"filtered_data_persistence\"\n\n# Provided JSON data as strings\njson_data = ''' \n{\n  \"user\": \"premiumplatinum\",\n  \"content\": \"singapore is stupid\",\n  \"url\": \"https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/\",\n  \"context\": \"21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist\",\n  \"score\": 131,\n  \"type\": \"post\",\n  \"id\": \"1c9itat\",\n  \"datetime\": \"2024-04-21 22:10:42\"\n}\n{\n        \"user\": \"premiumplatinum\",\n        \"content\": \"s is stupid\",\n        \"url\": \"https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/\",\n        \"context\": \"21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist\",\n        \"score\": 131,\n        \"type\": \"post\",\n        \"id\": \"1c9itat\",\n        \"datetime\": \"2024-04-21 22:10:42\"\n}\n'''\n\n# process the kafka messages to individual JSON objects\njson_objects = json_data.replace('}\\n{', '},\\n{').strip()\njson_objects = re.sub(\" +\", \" \",json_objects)   \njson_objects = '[' + json_objects + ']'\n\n# convert JSON string to a list of dicts\njson_list = json.loads(json_objects)\n\n# convert list of dictionaries into list of tuples containing only the values\nvalues = [tuple(message.values()) for message in json_list]\n\n# create the SQL Query\nquery = f'''\nINSERT INTO {table_name} (user, content, url, context, score, type, id, datetime)\nVALUES \n'''\n\nfor value in values:\n    query += str(value) + ',\\n'\n\n# remove the last 2 character ,\\n and change it to ; for the query\nquery = query[:-2] + ';'\n\n# pass the query as a parameter downstream\nprint(\"#setValue(query=%s)\" % query)","resourceList":[]}, environmentConfig=null, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='persist_to_postgre'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, query=Property{prop='query', direct=OUT, type=VARCHAR, value=''}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240429'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='2020'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13426451158240'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240429172746'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='746'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240428'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='es_filtered_data_persistence_subprocess'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13426477386080'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"query","direct":"OUT","type":"VARCHAR","value":""}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-746][TI-2020] - [INFO] 2024-04-29 17:27:46.862 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: persist_to_postgre to wait queue success
[WI-746][TI-2020] - [INFO] 2024-04-29 17:27:46.862 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-746][TI-2020] - [INFO] 2024-04-29 17:27:46.864 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-746][TI-2020] - [INFO] 2024-04-29 17:27:46.864 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-746][TI-2020] - [INFO] 2024-04-29 17:27:46.865 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-746][TI-2020] - [INFO] 2024-04-29 17:27:46.865 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1714382866865
[WI-746][TI-2020] - [INFO] 2024-04-29 17:27:46.865 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 746_2020
[WI-746][TI-2020] - [INFO] 2024-04-29 17:27:46.866 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 2020,
  "taskName" : "persist_to_postgre",
  "firstSubmitTime" : 1714382866828,
  "startTime" : 1714382866865,
  "taskType" : "PYTHON",
  "workflowInstanceHost" : "172.18.0.10:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240429/13426477386080/6/746/2020.log",
  "processId" : 0,
  "processDefineCode" : 13426477386080,
  "processDefineVersion" : 6,
  "processInstanceId" : 746,
  "scheduleTime" : 0,
  "executorId" : 1,
  "cmdTypeIfComplement" : 7,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[{\"prop\":\"query\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"\"}],\"rawScript\":\"import re\\n\\n# define the table to send the data to\\ntable_name = \\\"filtered_data_persistence\\\"\\n\\n# Provided JSON data as strings\\njson_data = ''' \\n{\\n  \\\"user\\\": \\\"premiumplatinum\\\",\\n  \\\"content\\\": \\\"singapore is stupid\\\",\\n  \\\"url\\\": \\\"https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/\\\",\\n  \\\"context\\\": \\\"21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist\\\",\\n  \\\"score\\\": 131,\\n  \\\"type\\\": \\\"post\\\",\\n  \\\"id\\\": \\\"1c9itat\\\",\\n  \\\"datetime\\\": \\\"2024-04-21 22:10:42\\\"\\n}\\n{\\n        \\\"user\\\": \\\"premiumplatinum\\\",\\n        \\\"content\\\": \\\"s is stupid\\\",\\n        \\\"url\\\": \\\"https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/\\\",\\n        \\\"context\\\": \\\"21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist\\\",\\n        \\\"score\\\": 131,\\n        \\\"type\\\": \\\"post\\\",\\n        \\\"id\\\": \\\"1c9itat\\\",\\n        \\\"datetime\\\": \\\"2024-04-21 22:10:42\\\"\\n}\\n'''\\n\\n# process the kafka messages to individual JSON objects\\njson_objects = json_data.replace('}\\\\n{', '},\\\\n{').strip()\\njson_objects = re.sub(\\\" +\\\", \\\" \\\",json_objects)   \\njson_objects = '[' + json_objects + ']'\\n\\n# convert JSON string to a list of dicts\\njson_list = json.loads(json_objects)\\n\\n# convert list of dictionaries into list of tuples containing only the values\\nvalues = [tuple(message.values()) for message in json_list]\\n\\n# create the SQL Query\\nquery = f'''\\nINSERT INTO {table_name} (user, content, url, context, score, type, id, datetime)\\nVALUES \\n'''\\n\\nfor value in values:\\n    query += str(value) + ',\\\\n'\\n\\n# remove the last 2 character ,\\\\n and change it to ; for the query\\nquery = query[:-2] + ';'\\n\\n# pass the query as a parameter downstream\\nprint(\\\"#setValue(query=%s)\\\" % query)\",\"resourceList\":[]}",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "persist_to_postgre"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "query" : {
      "prop" : "query",
      "direct" : "OUT",
      "type" : "VARCHAR",
      "value" : ""
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240429"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "2020"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13426451158240"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240429172746"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "746"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240428"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "es_filtered_data_persistence_subprocess"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13426477386080"
    }
  },
  "taskAppId" : "746_2020",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"query\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-746][TI-2020] - [INFO] 2024-04-29 17:27:46.866 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-746][TI-2020] - [INFO] 2024-04-29 17:27:46.866 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-746][TI-2020] - [INFO] 2024-04-29 17:27:46.867 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-746][TI-2020] - [INFO] 2024-04-29 17:27:46.872 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-746][TI-2020] - [INFO] 2024-04-29 17:27:46.872 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-746][TI-2020] - [INFO] 2024-04-29 17:27:46.873 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_6/746/2020 check successfully
[WI-746][TI-2020] - [INFO] 2024-04-29 17:27:46.873 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.python.PythonTaskChannel successfully
[WI-746][TI-2020] - [INFO] 2024-04-29 17:27:46.874 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-746][TI-2020] - [INFO] 2024-04-29 17:27:46.879 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-746][TI-2020] - [INFO] 2024-04-29 17:27:46.879 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: PYTHON create successfully
[WI-746][TI-2020] - [INFO] 2024-04-29 17:27:46.883 +0800 o.a.d.p.t.p.PythonTask:[75] - Initialize python task params {
  "localParams" : [ {
    "prop" : "query",
    "direct" : "OUT",
    "type" : "VARCHAR",
    "value" : ""
  } ],
  "varPool" : null,
  "rawScript" : "import re\n\n# define the table to send the data to\ntable_name = \"filtered_data_persistence\"\n\n# Provided JSON data as strings\njson_data = ''' \n{\n  \"user\": \"premiumplatinum\",\n  \"content\": \"singapore is stupid\",\n  \"url\": \"https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/\",\n  \"context\": \"21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist\",\n  \"score\": 131,\n  \"type\": \"post\",\n  \"id\": \"1c9itat\",\n  \"datetime\": \"2024-04-21 22:10:42\"\n}\n{\n        \"user\": \"premiumplatinum\",\n        \"content\": \"s is stupid\",\n        \"url\": \"https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/\",\n        \"context\": \"21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist\",\n        \"score\": 131,\n        \"type\": \"post\",\n        \"id\": \"1c9itat\",\n        \"datetime\": \"2024-04-21 22:10:42\"\n}\n'''\n\n# process the kafka messages to individual JSON objects\njson_objects = json_data.replace('}\\n{', '},\\n{').strip()\njson_objects = re.sub(\" +\", \" \",json_objects)   \njson_objects = '[' + json_objects + ']'\n\n# convert JSON string to a list of dicts\njson_list = json.loads(json_objects)\n\n# convert list of dictionaries into list of tuples containing only the values\nvalues = [tuple(message.values()) for message in json_list]\n\n# create the SQL Query\nquery = f'''\nINSERT INTO {table_name} (user, content, url, context, score, type, id, datetime)\nVALUES \n'''\n\nfor value in values:\n    query += str(value) + ',\\n'\n\n# remove the last 2 character ,\\n and change it to ; for the query\nquery = query[:-2] + ';'\n\n# pass the query as a parameter downstream\nprint(\"#setValue(query=%s)\" % query)",
  "resourceList" : [ ]
}
[WI-746][TI-2020] - [INFO] 2024-04-29 17:27:46.884 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-746][TI-2020] - [INFO] 2024-04-29 17:27:46.884 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"query","direct":"OUT","type":"VARCHAR","value":""}] successfully
[WI-746][TI-2020] - [INFO] 2024-04-29 17:27:46.884 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-746][TI-2020] - [INFO] 2024-04-29 17:27:46.884 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-746][TI-2020] - [INFO] 2024-04-29 17:27:46.884 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-746][TI-2020] - [INFO] 2024-04-29 17:27:46.884 +0800 o.a.d.p.t.p.PythonTask:[165] - raw python script : import re

# define the table to send the data to
table_name = "filtered_data_persistence"

# Provided JSON data as strings
json_data = ''' 
{
  "user": "premiumplatinum",
  "content": "singapore is stupid",
  "url": "https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/",
  "context": "21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist",
  "score": 131,
  "type": "post",
  "id": "1c9itat",
  "datetime": "2024-04-21 22:10:42"
}
{
        "user": "premiumplatinum",
        "content": "s is stupid",
        "url": "https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/",
        "context": "21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist",
        "score": 131,
        "type": "post",
        "id": "1c9itat",
        "datetime": "2024-04-21 22:10:42"
}
'''

# process the kafka messages to individual JSON objects
json_objects = json_data.replace('}\n{', '},\n{').strip()
json_objects = re.sub(" +", " ",json_objects)   
json_objects = '[' + json_objects + ']'

# convert JSON string to a list of dicts
json_list = json.loads(json_objects)

# convert list of dictionaries into list of tuples containing only the values
values = [tuple(message.values()) for message in json_list]

# create the SQL Query
query = f'''
INSERT INTO {table_name} (user, content, url, context, score, type, id, datetime)
VALUES 
'''

for value in values:
    query += str(value) + ',\n'

# remove the last 2 character ,\n and change it to ; for the query
query = query[:-2] + ';'

# pass the query as a parameter downstream
print("#setValue(query=%s)" % query)
[WI-746][TI-2020] - [INFO] 2024-04-29 17:27:46.885 +0800 o.a.d.p.t.p.PythonTask:[131] - tenantCode :default, task dir:/tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_6/746/2020
[WI-746][TI-2020] - [INFO] 2024-04-29 17:27:46.885 +0800 o.a.d.p.t.p.PythonTask:[134] - generate python script file:/tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_6/746/2020/py_746_2020.py
[WI-746][TI-2020] - [INFO] 2024-04-29 17:27:46.885 +0800 o.a.d.p.t.p.PythonTask:[141] - #-*- encoding=utf8 -*-

import re

# define the table to send the data to
table_name = "filtered_data_persistence"

# Provided JSON data as strings
json_data = ''' 
{
  "user": "premiumplatinum",
  "content": "singapore is stupid",
  "url": "https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/",
  "context": "21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist",
  "score": 131,
  "type": "post",
  "id": "1c9itat",
  "datetime": "2024-04-21 22:10:42"
}
{
        "user": "premiumplatinum",
        "content": "s is stupid",
        "url": "https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/",
        "context": "21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist",
        "score": 131,
        "type": "post",
        "id": "1c9itat",
        "datetime": "2024-04-21 22:10:42"
}
'''

# process the kafka messages to individual JSON objects
json_objects = json_data.replace('}\n{', '},\n{').strip()
json_objects = re.sub(" +", " ",json_objects)   
json_objects = '[' + json_objects + ']'

# convert JSON string to a list of dicts
json_list = json.loads(json_objects)

# convert list of dictionaries into list of tuples containing only the values
values = [tuple(message.values()) for message in json_list]

# create the SQL Query
query = f'''
INSERT INTO {table_name} (user, content, url, context, score, type, id, datetime)
VALUES 
'''

for value in values:
    query += str(value) + ',\n'

# remove the last 2 character ,\n and change it to ; for the query
query = query[:-2] + ';'

# pass the query as a parameter downstream
print("#setValue(query=%s)" % query)
[WI-746][TI-2020] - [INFO] 2024-04-29 17:27:46.886 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-746][TI-2020] - [INFO] 2024-04-29 17:27:46.886 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-746][TI-2020] - [INFO] 2024-04-29 17:27:46.886 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
${PYTHON_LAUNCHER} /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_6/746/2020/py_746_2020.py
[WI-746][TI-2020] - [INFO] 2024-04-29 17:27:46.886 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-746][TI-2020] - [INFO] 2024-04-29 17:27:46.886 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_6/746/2020/746_2020.sh
[WI-746][TI-2020] - [INFO] 2024-04-29 17:27:46.896 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 200
[WI-0][TI-2020] - [INFO] 2024-04-29 17:27:47.765 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=2020, success=true)
[WI-0][TI-2020] - [INFO] 2024-04-29 17:27:47.781 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=2020)
[WI-0][TI-0] - [INFO] 2024-04-29 17:27:47.899 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
	/tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_6/746/2020/746_2020.sh: line 4: /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_6/746/2020/py_746_2020.py: Permission denied
[WI-746][TI-2020] - [INFO] 2024-04-29 17:27:47.901 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_6/746/2020, processId:200 ,exitStatusCode:126 ,processWaitForStatus:true ,processExitValue:126
[WI-746][TI-2020] - [INFO] 2024-04-29 17:27:47.904 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-746][TI-2020] - [INFO] 2024-04-29 17:27:47.905 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-746][TI-2020] - [INFO] 2024-04-29 17:27:47.905 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-746][TI-2020] - [INFO] 2024-04-29 17:27:47.905 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-746][TI-2020] - [INFO] 2024-04-29 17:27:47.911 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: FAILURE to master : 172.18.1.1:1234
[WI-746][TI-2020] - [INFO] 2024-04-29 17:27:47.914 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-746][TI-2020] - [INFO] 2024-04-29 17:27:47.915 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_6/746/2020
[WI-746][TI-2020] - [INFO] 2024-04-29 17:27:47.916 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_6/746/2020
[WI-746][TI-2020] - [INFO] 2024-04-29 17:27:47.916 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-2020] - [INFO] 2024-04-29 17:27:48.749 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=2020, success=true)
[WI-0][TI-0] - [INFO] 2024-04-29 17:27:48.881 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=2021, taskName=persist_to_postgre, firstSubmitTime=1714382868855, startTime=0, taskType=PYTHON, workflowInstanceHost=172.18.0.10:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13426477386080, processDefineVersion=6, appIds=null, processInstanceId=746, scheduleTime=0, globalParams=null, executorId=1, cmdTypeIfComplement=7, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[{"prop":"query","direct":"OUT","type":"VARCHAR","value":""}],"rawScript":"import re\n\n# define the table to send the data to\ntable_name = \"filtered_data_persistence\"\n\n# Provided JSON data as strings\njson_data = ''' \n{\n  \"user\": \"premiumplatinum\",\n  \"content\": \"singapore is stupid\",\n  \"url\": \"https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/\",\n  \"context\": \"21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist\",\n  \"score\": 131,\n  \"type\": \"post\",\n  \"id\": \"1c9itat\",\n  \"datetime\": \"2024-04-21 22:10:42\"\n}\n{\n        \"user\": \"premiumplatinum\",\n        \"content\": \"s is stupid\",\n        \"url\": \"https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/\",\n        \"context\": \"21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist\",\n        \"score\": 131,\n        \"type\": \"post\",\n        \"id\": \"1c9itat\",\n        \"datetime\": \"2024-04-21 22:10:42\"\n}\n'''\n\n# process the kafka messages to individual JSON objects\njson_objects = json_data.replace('}\\n{', '},\\n{').strip()\njson_objects = re.sub(\" +\", \" \",json_objects)   \njson_objects = '[' + json_objects + ']'\n\n# convert JSON string to a list of dicts\njson_list = json.loads(json_objects)\n\n# convert list of dictionaries into list of tuples containing only the values\nvalues = [tuple(message.values()) for message in json_list]\n\n# create the SQL Query\nquery = f'''\nINSERT INTO {table_name} (user, content, url, context, score, type, id, datetime)\nVALUES \n'''\n\nfor value in values:\n    query += str(value) + ',\\n'\n\n# remove the last 2 character ,\\n and change it to ; for the query\nquery = query[:-2] + ';'\n\n# pass the query as a parameter downstream\nprint(\"#setValue(query=%s)\" % query)","resourceList":[]}, environmentConfig=null, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='persist_to_postgre'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, query=Property{prop='query', direct=OUT, type=VARCHAR, value=''}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240429'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='2021'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13426451158240'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240429172748'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='746'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240428'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='es_filtered_data_persistence_subprocess'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13426477386080'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"query","direct":"OUT","type":"VARCHAR","value":""}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-746][TI-2021] - [INFO] 2024-04-29 17:27:48.882 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: persist_to_postgre to wait queue success
[WI-746][TI-2021] - [INFO] 2024-04-29 17:27:48.882 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-746][TI-2021] - [INFO] 2024-04-29 17:27:48.884 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-746][TI-2021] - [INFO] 2024-04-29 17:27:48.884 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-746][TI-2021] - [INFO] 2024-04-29 17:27:48.884 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-746][TI-2021] - [INFO] 2024-04-29 17:27:48.884 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1714382868884
[WI-746][TI-2021] - [INFO] 2024-04-29 17:27:48.884 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 746_2021
[WI-746][TI-2021] - [INFO] 2024-04-29 17:27:48.884 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 2021,
  "taskName" : "persist_to_postgre",
  "firstSubmitTime" : 1714382868855,
  "startTime" : 1714382868884,
  "taskType" : "PYTHON",
  "workflowInstanceHost" : "172.18.0.10:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240429/13426477386080/6/746/2021.log",
  "processId" : 0,
  "processDefineCode" : 13426477386080,
  "processDefineVersion" : 6,
  "processInstanceId" : 746,
  "scheduleTime" : 0,
  "executorId" : 1,
  "cmdTypeIfComplement" : 7,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[{\"prop\":\"query\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"\"}],\"rawScript\":\"import re\\n\\n# define the table to send the data to\\ntable_name = \\\"filtered_data_persistence\\\"\\n\\n# Provided JSON data as strings\\njson_data = ''' \\n{\\n  \\\"user\\\": \\\"premiumplatinum\\\",\\n  \\\"content\\\": \\\"singapore is stupid\\\",\\n  \\\"url\\\": \\\"https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/\\\",\\n  \\\"context\\\": \\\"21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist\\\",\\n  \\\"score\\\": 131,\\n  \\\"type\\\": \\\"post\\\",\\n  \\\"id\\\": \\\"1c9itat\\\",\\n  \\\"datetime\\\": \\\"2024-04-21 22:10:42\\\"\\n}\\n{\\n        \\\"user\\\": \\\"premiumplatinum\\\",\\n        \\\"content\\\": \\\"s is stupid\\\",\\n        \\\"url\\\": \\\"https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/\\\",\\n        \\\"context\\\": \\\"21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist\\\",\\n        \\\"score\\\": 131,\\n        \\\"type\\\": \\\"post\\\",\\n        \\\"id\\\": \\\"1c9itat\\\",\\n        \\\"datetime\\\": \\\"2024-04-21 22:10:42\\\"\\n}\\n'''\\n\\n# process the kafka messages to individual JSON objects\\njson_objects = json_data.replace('}\\\\n{', '},\\\\n{').strip()\\njson_objects = re.sub(\\\" +\\\", \\\" \\\",json_objects)   \\njson_objects = '[' + json_objects + ']'\\n\\n# convert JSON string to a list of dicts\\njson_list = json.loads(json_objects)\\n\\n# convert list of dictionaries into list of tuples containing only the values\\nvalues = [tuple(message.values()) for message in json_list]\\n\\n# create the SQL Query\\nquery = f'''\\nINSERT INTO {table_name} (user, content, url, context, score, type, id, datetime)\\nVALUES \\n'''\\n\\nfor value in values:\\n    query += str(value) + ',\\\\n'\\n\\n# remove the last 2 character ,\\\\n and change it to ; for the query\\nquery = query[:-2] + ';'\\n\\n# pass the query as a parameter downstream\\nprint(\\\"#setValue(query=%s)\\\" % query)\",\"resourceList\":[]}",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "persist_to_postgre"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "query" : {
      "prop" : "query",
      "direct" : "OUT",
      "type" : "VARCHAR",
      "value" : ""
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240429"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "2021"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13426451158240"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240429172748"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "746"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240428"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "es_filtered_data_persistence_subprocess"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13426477386080"
    }
  },
  "taskAppId" : "746_2021",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"query\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-746][TI-2021] - [INFO] 2024-04-29 17:27:48.885 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-746][TI-2021] - [INFO] 2024-04-29 17:27:48.885 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-746][TI-2021] - [INFO] 2024-04-29 17:27:48.885 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-746][TI-2021] - [INFO] 2024-04-29 17:27:48.890 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-746][TI-2021] - [INFO] 2024-04-29 17:27:48.891 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-746][TI-2021] - [INFO] 2024-04-29 17:27:48.894 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_6/746/2021 check successfully
[WI-746][TI-2021] - [INFO] 2024-04-29 17:27:48.896 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.python.PythonTaskChannel successfully
[WI-746][TI-2021] - [INFO] 2024-04-29 17:27:48.898 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-746][TI-2021] - [INFO] 2024-04-29 17:27:48.900 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-746][TI-2021] - [INFO] 2024-04-29 17:27:48.900 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: PYTHON create successfully
[WI-746][TI-2021] - [INFO] 2024-04-29 17:27:48.901 +0800 o.a.d.p.t.p.PythonTask:[75] - Initialize python task params {
  "localParams" : [ {
    "prop" : "query",
    "direct" : "OUT",
    "type" : "VARCHAR",
    "value" : ""
  } ],
  "varPool" : null,
  "rawScript" : "import re\n\n# define the table to send the data to\ntable_name = \"filtered_data_persistence\"\n\n# Provided JSON data as strings\njson_data = ''' \n{\n  \"user\": \"premiumplatinum\",\n  \"content\": \"singapore is stupid\",\n  \"url\": \"https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/\",\n  \"context\": \"21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist\",\n  \"score\": 131,\n  \"type\": \"post\",\n  \"id\": \"1c9itat\",\n  \"datetime\": \"2024-04-21 22:10:42\"\n}\n{\n        \"user\": \"premiumplatinum\",\n        \"content\": \"s is stupid\",\n        \"url\": \"https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/\",\n        \"context\": \"21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist\",\n        \"score\": 131,\n        \"type\": \"post\",\n        \"id\": \"1c9itat\",\n        \"datetime\": \"2024-04-21 22:10:42\"\n}\n'''\n\n# process the kafka messages to individual JSON objects\njson_objects = json_data.replace('}\\n{', '},\\n{').strip()\njson_objects = re.sub(\" +\", \" \",json_objects)   \njson_objects = '[' + json_objects + ']'\n\n# convert JSON string to a list of dicts\njson_list = json.loads(json_objects)\n\n# convert list of dictionaries into list of tuples containing only the values\nvalues = [tuple(message.values()) for message in json_list]\n\n# create the SQL Query\nquery = f'''\nINSERT INTO {table_name} (user, content, url, context, score, type, id, datetime)\nVALUES \n'''\n\nfor value in values:\n    query += str(value) + ',\\n'\n\n# remove the last 2 character ,\\n and change it to ; for the query\nquery = query[:-2] + ';'\n\n# pass the query as a parameter downstream\nprint(\"#setValue(query=%s)\" % query)",
  "resourceList" : [ ]
}
[WI-746][TI-2021] - [INFO] 2024-04-29 17:27:48.901 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-746][TI-2021] - [INFO] 2024-04-29 17:27:48.901 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"query","direct":"OUT","type":"VARCHAR","value":""}] successfully
[WI-746][TI-2021] - [INFO] 2024-04-29 17:27:48.902 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-746][TI-2021] - [INFO] 2024-04-29 17:27:48.902 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-746][TI-2021] - [INFO] 2024-04-29 17:27:48.902 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-746][TI-2021] - [INFO] 2024-04-29 17:27:48.902 +0800 o.a.d.p.t.p.PythonTask:[165] - raw python script : import re

# define the table to send the data to
table_name = "filtered_data_persistence"

# Provided JSON data as strings
json_data = ''' 
{
  "user": "premiumplatinum",
  "content": "singapore is stupid",
  "url": "https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/",
  "context": "21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist",
  "score": 131,
  "type": "post",
  "id": "1c9itat",
  "datetime": "2024-04-21 22:10:42"
}
{
        "user": "premiumplatinum",
        "content": "s is stupid",
        "url": "https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/",
        "context": "21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist",
        "score": 131,
        "type": "post",
        "id": "1c9itat",
        "datetime": "2024-04-21 22:10:42"
}
'''

# process the kafka messages to individual JSON objects
json_objects = json_data.replace('}\n{', '},\n{').strip()
json_objects = re.sub(" +", " ",json_objects)   
json_objects = '[' + json_objects + ']'

# convert JSON string to a list of dicts
json_list = json.loads(json_objects)

# convert list of dictionaries into list of tuples containing only the values
values = [tuple(message.values()) for message in json_list]

# create the SQL Query
query = f'''
INSERT INTO {table_name} (user, content, url, context, score, type, id, datetime)
VALUES 
'''

for value in values:
    query += str(value) + ',\n'

# remove the last 2 character ,\n and change it to ; for the query
query = query[:-2] + ';'

# pass the query as a parameter downstream
print("#setValue(query=%s)" % query)
[WI-746][TI-2021] - [INFO] 2024-04-29 17:27:48.903 +0800 o.a.d.p.t.p.PythonTask:[131] - tenantCode :default, task dir:/tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_6/746/2021
[WI-746][TI-2021] - [INFO] 2024-04-29 17:27:48.903 +0800 o.a.d.p.t.p.PythonTask:[134] - generate python script file:/tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_6/746/2021/py_746_2021.py
[WI-746][TI-2021] - [INFO] 2024-04-29 17:27:48.903 +0800 o.a.d.p.t.p.PythonTask:[141] - #-*- encoding=utf8 -*-

import re

# define the table to send the data to
table_name = "filtered_data_persistence"

# Provided JSON data as strings
json_data = ''' 
{
  "user": "premiumplatinum",
  "content": "singapore is stupid",
  "url": "https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/",
  "context": "21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist",
  "score": 131,
  "type": "post",
  "id": "1c9itat",
  "datetime": "2024-04-21 22:10:42"
}
{
        "user": "premiumplatinum",
        "content": "s is stupid",
        "url": "https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/",
        "context": "21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist",
        "score": 131,
        "type": "post",
        "id": "1c9itat",
        "datetime": "2024-04-21 22:10:42"
}
'''

# process the kafka messages to individual JSON objects
json_objects = json_data.replace('}\n{', '},\n{').strip()
json_objects = re.sub(" +", " ",json_objects)   
json_objects = '[' + json_objects + ']'

# convert JSON string to a list of dicts
json_list = json.loads(json_objects)

# convert list of dictionaries into list of tuples containing only the values
values = [tuple(message.values()) for message in json_list]

# create the SQL Query
query = f'''
INSERT INTO {table_name} (user, content, url, context, score, type, id, datetime)
VALUES 
'''

for value in values:
    query += str(value) + ',\n'

# remove the last 2 character ,\n and change it to ; for the query
query = query[:-2] + ';'

# pass the query as a parameter downstream
print("#setValue(query=%s)" % query)
[WI-746][TI-2021] - [INFO] 2024-04-29 17:27:48.904 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-746][TI-2021] - [INFO] 2024-04-29 17:27:48.904 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-746][TI-2021] - [INFO] 2024-04-29 17:27:48.904 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
${PYTHON_LAUNCHER} /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_6/746/2021/py_746_2021.py
[WI-746][TI-2021] - [INFO] 2024-04-29 17:27:48.905 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-746][TI-2021] - [INFO] 2024-04-29 17:27:48.905 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_6/746/2021/746_2021.sh
[WI-746][TI-2021] - [INFO] 2024-04-29 17:27:48.929 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 211
[WI-0][TI-0] - [INFO] 2024-04-29 17:27:48.931 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
[WI-0][TI-2021] - [INFO] 2024-04-29 17:27:49.758 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=2021, success=true)
[WI-0][TI-2021] - [INFO] 2024-04-29 17:27:49.772 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=2021)
[WI-0][TI-0] - [INFO] 2024-04-29 17:27:49.938 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	/tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_6/746/2021/746_2021.sh: line 4: /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_6/746/2021/py_746_2021.py: Permission denied
[WI-746][TI-2021] - [INFO] 2024-04-29 17:27:49.945 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_6/746/2021, processId:211 ,exitStatusCode:126 ,processWaitForStatus:true ,processExitValue:126
[WI-746][TI-2021] - [INFO] 2024-04-29 17:27:49.947 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-746][TI-2021] - [INFO] 2024-04-29 17:27:49.947 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-746][TI-2021] - [INFO] 2024-04-29 17:27:49.947 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-746][TI-2021] - [INFO] 2024-04-29 17:27:49.947 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-746][TI-2021] - [INFO] 2024-04-29 17:27:49.953 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: FAILURE to master : 172.18.1.1:1234
[WI-746][TI-2021] - [INFO] 2024-04-29 17:27:49.953 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-746][TI-2021] - [INFO] 2024-04-29 17:27:49.954 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_6/746/2021
[WI-746][TI-2021] - [INFO] 2024-04-29 17:27:49.955 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_6/746/2021
[WI-746][TI-2021] - [INFO] 2024-04-29 17:27:49.955 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-2021] - [INFO] 2024-04-29 17:27:50.751 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=2021, success=true)
[WI-0][TI-0] - [INFO] 2024-04-29 17:27:50.815 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=2022, taskName=persist_to_postgre, firstSubmitTime=1714382870796, startTime=0, taskType=PYTHON, workflowInstanceHost=172.18.0.10:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13426477386080, processDefineVersion=6, appIds=null, processInstanceId=746, scheduleTime=0, globalParams=null, executorId=1, cmdTypeIfComplement=7, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[{"prop":"query","direct":"OUT","type":"VARCHAR","value":""}],"rawScript":"import re\n\n# define the table to send the data to\ntable_name = \"filtered_data_persistence\"\n\n# Provided JSON data as strings\njson_data = ''' \n{\n  \"user\": \"premiumplatinum\",\n  \"content\": \"singapore is stupid\",\n  \"url\": \"https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/\",\n  \"context\": \"21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist\",\n  \"score\": 131,\n  \"type\": \"post\",\n  \"id\": \"1c9itat\",\n  \"datetime\": \"2024-04-21 22:10:42\"\n}\n{\n        \"user\": \"premiumplatinum\",\n        \"content\": \"s is stupid\",\n        \"url\": \"https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/\",\n        \"context\": \"21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist\",\n        \"score\": 131,\n        \"type\": \"post\",\n        \"id\": \"1c9itat\",\n        \"datetime\": \"2024-04-21 22:10:42\"\n}\n'''\n\n# process the kafka messages to individual JSON objects\njson_objects = json_data.replace('}\\n{', '},\\n{').strip()\njson_objects = re.sub(\" +\", \" \",json_objects)   \njson_objects = '[' + json_objects + ']'\n\n# convert JSON string to a list of dicts\njson_list = json.loads(json_objects)\n\n# convert list of dictionaries into list of tuples containing only the values\nvalues = [tuple(message.values()) for message in json_list]\n\n# create the SQL Query\nquery = f'''\nINSERT INTO {table_name} (user, content, url, context, score, type, id, datetime)\nVALUES \n'''\n\nfor value in values:\n    query += str(value) + ',\\n'\n\n# remove the last 2 character ,\\n and change it to ; for the query\nquery = query[:-2] + ';'\n\n# pass the query as a parameter downstream\nprint(\"#setValue(query=%s)\" % query)","resourceList":[]}, environmentConfig=null, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='persist_to_postgre'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, query=Property{prop='query', direct=OUT, type=VARCHAR, value=''}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240429'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='2022'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13426451158240'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240429172750'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='746'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240428'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='es_filtered_data_persistence_subprocess'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13426477386080'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"query","direct":"OUT","type":"VARCHAR","value":""}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-746][TI-2022] - [INFO] 2024-04-29 17:27:50.818 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: persist_to_postgre to wait queue success
[WI-746][TI-2022] - [INFO] 2024-04-29 17:27:50.818 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-746][TI-2022] - [INFO] 2024-04-29 17:27:50.820 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-746][TI-2022] - [INFO] 2024-04-29 17:27:50.820 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-746][TI-2022] - [INFO] 2024-04-29 17:27:50.820 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-746][TI-2022] - [INFO] 2024-04-29 17:27:50.820 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1714382870820
[WI-746][TI-2022] - [INFO] 2024-04-29 17:27:50.820 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 746_2022
[WI-746][TI-2022] - [INFO] 2024-04-29 17:27:50.821 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 2022,
  "taskName" : "persist_to_postgre",
  "firstSubmitTime" : 1714382870796,
  "startTime" : 1714382870820,
  "taskType" : "PYTHON",
  "workflowInstanceHost" : "172.18.0.10:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240429/13426477386080/6/746/2022.log",
  "processId" : 0,
  "processDefineCode" : 13426477386080,
  "processDefineVersion" : 6,
  "processInstanceId" : 746,
  "scheduleTime" : 0,
  "executorId" : 1,
  "cmdTypeIfComplement" : 7,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[{\"prop\":\"query\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"\"}],\"rawScript\":\"import re\\n\\n# define the table to send the data to\\ntable_name = \\\"filtered_data_persistence\\\"\\n\\n# Provided JSON data as strings\\njson_data = ''' \\n{\\n  \\\"user\\\": \\\"premiumplatinum\\\",\\n  \\\"content\\\": \\\"singapore is stupid\\\",\\n  \\\"url\\\": \\\"https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/\\\",\\n  \\\"context\\\": \\\"21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist\\\",\\n  \\\"score\\\": 131,\\n  \\\"type\\\": \\\"post\\\",\\n  \\\"id\\\": \\\"1c9itat\\\",\\n  \\\"datetime\\\": \\\"2024-04-21 22:10:42\\\"\\n}\\n{\\n        \\\"user\\\": \\\"premiumplatinum\\\",\\n        \\\"content\\\": \\\"s is stupid\\\",\\n        \\\"url\\\": \\\"https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/\\\",\\n        \\\"context\\\": \\\"21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist\\\",\\n        \\\"score\\\": 131,\\n        \\\"type\\\": \\\"post\\\",\\n        \\\"id\\\": \\\"1c9itat\\\",\\n        \\\"datetime\\\": \\\"2024-04-21 22:10:42\\\"\\n}\\n'''\\n\\n# process the kafka messages to individual JSON objects\\njson_objects = json_data.replace('}\\\\n{', '},\\\\n{').strip()\\njson_objects = re.sub(\\\" +\\\", \\\" \\\",json_objects)   \\njson_objects = '[' + json_objects + ']'\\n\\n# convert JSON string to a list of dicts\\njson_list = json.loads(json_objects)\\n\\n# convert list of dictionaries into list of tuples containing only the values\\nvalues = [tuple(message.values()) for message in json_list]\\n\\n# create the SQL Query\\nquery = f'''\\nINSERT INTO {table_name} (user, content, url, context, score, type, id, datetime)\\nVALUES \\n'''\\n\\nfor value in values:\\n    query += str(value) + ',\\\\n'\\n\\n# remove the last 2 character ,\\\\n and change it to ; for the query\\nquery = query[:-2] + ';'\\n\\n# pass the query as a parameter downstream\\nprint(\\\"#setValue(query=%s)\\\" % query)\",\"resourceList\":[]}",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "persist_to_postgre"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "query" : {
      "prop" : "query",
      "direct" : "OUT",
      "type" : "VARCHAR",
      "value" : ""
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240429"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "2022"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13426451158240"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240429172750"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "746"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240428"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "es_filtered_data_persistence_subprocess"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13426477386080"
    }
  },
  "taskAppId" : "746_2022",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"query\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-746][TI-2022] - [INFO] 2024-04-29 17:27:50.821 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-746][TI-2022] - [INFO] 2024-04-29 17:27:50.822 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-746][TI-2022] - [INFO] 2024-04-29 17:27:50.822 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-746][TI-2022] - [INFO] 2024-04-29 17:27:50.841 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-746][TI-2022] - [INFO] 2024-04-29 17:27:50.842 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-746][TI-2022] - [INFO] 2024-04-29 17:27:50.845 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_6/746/2022 check successfully
[WI-746][TI-2022] - [INFO] 2024-04-29 17:27:50.845 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.python.PythonTaskChannel successfully
[WI-746][TI-2022] - [INFO] 2024-04-29 17:27:50.846 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-746][TI-2022] - [INFO] 2024-04-29 17:27:50.848 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-746][TI-2022] - [INFO] 2024-04-29 17:27:50.850 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: PYTHON create successfully
[WI-746][TI-2022] - [INFO] 2024-04-29 17:27:50.859 +0800 o.a.d.p.t.p.PythonTask:[75] - Initialize python task params {
  "localParams" : [ {
    "prop" : "query",
    "direct" : "OUT",
    "type" : "VARCHAR",
    "value" : ""
  } ],
  "varPool" : null,
  "rawScript" : "import re\n\n# define the table to send the data to\ntable_name = \"filtered_data_persistence\"\n\n# Provided JSON data as strings\njson_data = ''' \n{\n  \"user\": \"premiumplatinum\",\n  \"content\": \"singapore is stupid\",\n  \"url\": \"https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/\",\n  \"context\": \"21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist\",\n  \"score\": 131,\n  \"type\": \"post\",\n  \"id\": \"1c9itat\",\n  \"datetime\": \"2024-04-21 22:10:42\"\n}\n{\n        \"user\": \"premiumplatinum\",\n        \"content\": \"s is stupid\",\n        \"url\": \"https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/\",\n        \"context\": \"21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist\",\n        \"score\": 131,\n        \"type\": \"post\",\n        \"id\": \"1c9itat\",\n        \"datetime\": \"2024-04-21 22:10:42\"\n}\n'''\n\n# process the kafka messages to individual JSON objects\njson_objects = json_data.replace('}\\n{', '},\\n{').strip()\njson_objects = re.sub(\" +\", \" \",json_objects)   \njson_objects = '[' + json_objects + ']'\n\n# convert JSON string to a list of dicts\njson_list = json.loads(json_objects)\n\n# convert list of dictionaries into list of tuples containing only the values\nvalues = [tuple(message.values()) for message in json_list]\n\n# create the SQL Query\nquery = f'''\nINSERT INTO {table_name} (user, content, url, context, score, type, id, datetime)\nVALUES \n'''\n\nfor value in values:\n    query += str(value) + ',\\n'\n\n# remove the last 2 character ,\\n and change it to ; for the query\nquery = query[:-2] + ';'\n\n# pass the query as a parameter downstream\nprint(\"#setValue(query=%s)\" % query)",
  "resourceList" : [ ]
}
[WI-746][TI-2022] - [INFO] 2024-04-29 17:27:50.860 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-746][TI-2022] - [INFO] 2024-04-29 17:27:50.861 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"query","direct":"OUT","type":"VARCHAR","value":""}] successfully
[WI-746][TI-2022] - [INFO] 2024-04-29 17:27:50.862 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-746][TI-2022] - [INFO] 2024-04-29 17:27:50.862 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-746][TI-2022] - [INFO] 2024-04-29 17:27:50.863 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-746][TI-2022] - [INFO] 2024-04-29 17:27:50.863 +0800 o.a.d.p.t.p.PythonTask:[165] - raw python script : import re

# define the table to send the data to
table_name = "filtered_data_persistence"

# Provided JSON data as strings
json_data = ''' 
{
  "user": "premiumplatinum",
  "content": "singapore is stupid",
  "url": "https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/",
  "context": "21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist",
  "score": 131,
  "type": "post",
  "id": "1c9itat",
  "datetime": "2024-04-21 22:10:42"
}
{
        "user": "premiumplatinum",
        "content": "s is stupid",
        "url": "https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/",
        "context": "21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist",
        "score": 131,
        "type": "post",
        "id": "1c9itat",
        "datetime": "2024-04-21 22:10:42"
}
'''

# process the kafka messages to individual JSON objects
json_objects = json_data.replace('}\n{', '},\n{').strip()
json_objects = re.sub(" +", " ",json_objects)   
json_objects = '[' + json_objects + ']'

# convert JSON string to a list of dicts
json_list = json.loads(json_objects)

# convert list of dictionaries into list of tuples containing only the values
values = [tuple(message.values()) for message in json_list]

# create the SQL Query
query = f'''
INSERT INTO {table_name} (user, content, url, context, score, type, id, datetime)
VALUES 
'''

for value in values:
    query += str(value) + ',\n'

# remove the last 2 character ,\n and change it to ; for the query
query = query[:-2] + ';'

# pass the query as a parameter downstream
print("#setValue(query=%s)" % query)
[WI-746][TI-2022] - [INFO] 2024-04-29 17:27:50.864 +0800 o.a.d.p.t.p.PythonTask:[131] - tenantCode :default, task dir:/tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_6/746/2022
[WI-746][TI-2022] - [INFO] 2024-04-29 17:27:50.865 +0800 o.a.d.p.t.p.PythonTask:[134] - generate python script file:/tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_6/746/2022/py_746_2022.py
[WI-746][TI-2022] - [INFO] 2024-04-29 17:27:50.865 +0800 o.a.d.p.t.p.PythonTask:[141] - #-*- encoding=utf8 -*-

import re

# define the table to send the data to
table_name = "filtered_data_persistence"

# Provided JSON data as strings
json_data = ''' 
{
  "user": "premiumplatinum",
  "content": "singapore is stupid",
  "url": "https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/",
  "context": "21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist",
  "score": 131,
  "type": "post",
  "id": "1c9itat",
  "datetime": "2024-04-21 22:10:42"
}
{
        "user": "premiumplatinum",
        "content": "s is stupid",
        "url": "https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/",
        "context": "21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist",
        "score": 131,
        "type": "post",
        "id": "1c9itat",
        "datetime": "2024-04-21 22:10:42"
}
'''

# process the kafka messages to individual JSON objects
json_objects = json_data.replace('}\n{', '},\n{').strip()
json_objects = re.sub(" +", " ",json_objects)   
json_objects = '[' + json_objects + ']'

# convert JSON string to a list of dicts
json_list = json.loads(json_objects)

# convert list of dictionaries into list of tuples containing only the values
values = [tuple(message.values()) for message in json_list]

# create the SQL Query
query = f'''
INSERT INTO {table_name} (user, content, url, context, score, type, id, datetime)
VALUES 
'''

for value in values:
    query += str(value) + ',\n'

# remove the last 2 character ,\n and change it to ; for the query
query = query[:-2] + ';'

# pass the query as a parameter downstream
print("#setValue(query=%s)" % query)
[WI-746][TI-2022] - [INFO] 2024-04-29 17:27:50.867 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-746][TI-2022] - [INFO] 2024-04-29 17:27:50.868 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-746][TI-2022] - [INFO] 2024-04-29 17:27:50.868 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
${PYTHON_LAUNCHER} /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_6/746/2022/py_746_2022.py
[WI-746][TI-2022] - [INFO] 2024-04-29 17:27:50.869 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-746][TI-2022] - [INFO] 2024-04-29 17:27:50.869 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_6/746/2022/746_2022.sh
[WI-746][TI-2022] - [INFO] 2024-04-29 17:27:50.880 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 222
[WI-0][TI-2022] - [INFO] 2024-04-29 17:27:51.761 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=2022, success=true)
[WI-0][TI-2022] - [INFO] 2024-04-29 17:27:51.781 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=2022)
[WI-0][TI-0] - [INFO] 2024-04-29 17:27:51.882 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
	/tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_6/746/2022/746_2022.sh: line 4: /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_6/746/2022/py_746_2022.py: Permission denied
[WI-746][TI-2022] - [INFO] 2024-04-29 17:27:51.887 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_6/746/2022, processId:222 ,exitStatusCode:126 ,processWaitForStatus:true ,processExitValue:126
[WI-746][TI-2022] - [INFO] 2024-04-29 17:27:51.888 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-746][TI-2022] - [INFO] 2024-04-29 17:27:51.888 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-746][TI-2022] - [INFO] 2024-04-29 17:27:51.888 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-746][TI-2022] - [INFO] 2024-04-29 17:27:51.890 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-746][TI-2022] - [INFO] 2024-04-29 17:27:51.895 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: FAILURE to master : 172.18.1.1:1234
[WI-746][TI-2022] - [INFO] 2024-04-29 17:27:51.895 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-746][TI-2022] - [INFO] 2024-04-29 17:27:51.896 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_6/746/2022
[WI-746][TI-2022] - [INFO] 2024-04-29 17:27:51.898 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_6/746/2022
[WI-746][TI-2022] - [INFO] 2024-04-29 17:27:51.899 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-2022] - [INFO] 2024-04-29 17:27:52.753 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=2022, success=true)
[WI-0][TI-0] - [INFO] 2024-04-29 17:27:59.994 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.904225352112676 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-29 17:28:01.039 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8717277486910995 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-29 17:28:05.062 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8045730000329347 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-29 17:28:31.188 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7206349206349206 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-29 17:28:43.283 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7593123209169055 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-29 17:28:47.344 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=2023, taskName=consume_filtered_data, firstSubmitTime=1714382927337, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.10:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13426477386080, processDefineVersion=7, appIds=null, processInstanceId=747, scheduleTime=0, globalParams=null, executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[],"rawScript":"# /bin/kafka-console-consumer.sh \\\n#     --bootstrap-server kafka:9092 \\\n#     --topic reddit_post_filtered \\\n#     --max-messages 10 \\\n#     --from-beginning \\\n#     --group filtered_data_consumer \n#     --timeout-ms 15000","resourceList":[]}, environmentConfig=export JAVA_HOME=/opt/java/openjdk, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='consume_filtered_data'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='747'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240429'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240428'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='2023'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='es_filtered_data_persistence_subprocess'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13433255983872'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13426477386080'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240429172847'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=null, dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-747][TI-2023] - [INFO] 2024-04-29 17:28:47.346 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: consume_filtered_data to wait queue success
[WI-747][TI-2023] - [INFO] 2024-04-29 17:28:47.350 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-747][TI-2023] - [INFO] 2024-04-29 17:28:47.355 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-747][TI-2023] - [INFO] 2024-04-29 17:28:47.356 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-747][TI-2023] - [INFO] 2024-04-29 17:28:47.356 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-747][TI-2023] - [INFO] 2024-04-29 17:28:47.356 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1714382927356
[WI-747][TI-2023] - [INFO] 2024-04-29 17:28:47.356 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 747_2023
[WI-747][TI-2023] - [INFO] 2024-04-29 17:28:47.357 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 2023,
  "taskName" : "consume_filtered_data",
  "firstSubmitTime" : 1714382927337,
  "startTime" : 1714382927356,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.10:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240429/13426477386080/7/747/2023.log",
  "processId" : 0,
  "processDefineCode" : 13426477386080,
  "processDefineVersion" : 7,
  "processInstanceId" : 747,
  "scheduleTime" : 0,
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[],\"rawScript\":\"# /bin/kafka-console-consumer.sh \\\\\\n#     --bootstrap-server kafka:9092 \\\\\\n#     --topic reddit_post_filtered \\\\\\n#     --max-messages 10 \\\\\\n#     --from-beginning \\\\\\n#     --group filtered_data_consumer \\n#     --timeout-ms 15000\",\"resourceList\":[]}",
  "environmentConfig" : "export JAVA_HOME=/opt/java/openjdk",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "consume_filtered_data"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "747"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240429"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240428"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "2023"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "es_filtered_data_persistence_subprocess"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13433255983872"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13426477386080"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240429172847"
    }
  },
  "taskAppId" : "747_2023",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-747][TI-2023] - [INFO] 2024-04-29 17:28:47.357 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-747][TI-2023] - [INFO] 2024-04-29 17:28:47.357 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-747][TI-2023] - [INFO] 2024-04-29 17:28:47.357 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-747][TI-2023] - [INFO] 2024-04-29 17:28:47.380 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-747][TI-2023] - [INFO] 2024-04-29 17:28:47.383 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-747][TI-2023] - [INFO] 2024-04-29 17:28:47.383 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_7/747/2023 check successfully
[WI-747][TI-2023] - [INFO] 2024-04-29 17:28:47.384 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-747][TI-2023] - [INFO] 2024-04-29 17:28:47.385 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-747][TI-2023] - [INFO] 2024-04-29 17:28:47.386 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-747][TI-2023] - [INFO] 2024-04-29 17:28:47.386 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-747][TI-2023] - [INFO] 2024-04-29 17:28:47.386 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ ],
  "varPool" : null,
  "rawScript" : "# /bin/kafka-console-consumer.sh \\\n#     --bootstrap-server kafka:9092 \\\n#     --topic reddit_post_filtered \\\n#     --max-messages 10 \\\n#     --from-beginning \\\n#     --group filtered_data_consumer \n#     --timeout-ms 15000",
  "resourceList" : [ ]
}
[WI-747][TI-2023] - [INFO] 2024-04-29 17:28:47.387 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-747][TI-2023] - [INFO] 2024-04-29 17:28:47.387 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: null successfully
[WI-747][TI-2023] - [INFO] 2024-04-29 17:28:47.387 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-747][TI-2023] - [INFO] 2024-04-29 17:28:47.394 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-747][TI-2023] - [INFO] 2024-04-29 17:28:47.395 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-747][TI-2023] - [INFO] 2024-04-29 17:28:47.396 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-747][TI-2023] - [INFO] 2024-04-29 17:28:47.396 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-747][TI-2023] - [INFO] 2024-04-29 17:28:47.396 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export JAVA_HOME=/opt/java/openjdk
# /bin/kafka-console-consumer.sh \
#     --bootstrap-server kafka:9092 \
#     --topic reddit_post_filtered \
#     --max-messages 10 \
#     --from-beginning \
#     --group filtered_data_consumer 
#     --timeout-ms 15000
[WI-747][TI-2023] - [INFO] 2024-04-29 17:28:47.397 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-747][TI-2023] - [INFO] 2024-04-29 17:28:47.397 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_7/747/2023/747_2023.sh
[WI-747][TI-2023] - [INFO] 2024-04-29 17:28:47.428 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 246
[WI-0][TI-2023] - [INFO] 2024-04-29 17:28:47.907 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=2023, success=true)
[WI-0][TI-2023] - [INFO] 2024-04-29 17:28:47.942 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=2023)
[WI-0][TI-0] - [INFO] 2024-04-29 17:28:48.431 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
[WI-747][TI-2023] - [INFO] 2024-04-29 17:28:48.434 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_7/747/2023, processId:246 ,exitStatusCode:0 ,processWaitForStatus:true ,processExitValue:0
[WI-747][TI-2023] - [INFO] 2024-04-29 17:28:48.435 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-747][TI-2023] - [INFO] 2024-04-29 17:28:48.436 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-747][TI-2023] - [INFO] 2024-04-29 17:28:48.436 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-747][TI-2023] - [INFO] 2024-04-29 17:28:48.436 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-747][TI-2023] - [INFO] 2024-04-29 17:28:48.441 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: SUCCESS to master : 172.18.1.1:1234
[WI-747][TI-2023] - [INFO] 2024-04-29 17:28:48.442 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-747][TI-2023] - [INFO] 2024-04-29 17:28:48.442 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_7/747/2023
[WI-747][TI-2023] - [INFO] 2024-04-29 17:28:48.442 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_7/747/2023
[WI-747][TI-2023] - [INFO] 2024-04-29 17:28:48.443 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-2023] - [INFO] 2024-04-29 17:28:48.887 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=2023, success=true)
[WI-0][TI-0] - [INFO] 2024-04-29 17:28:49.016 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=2024, taskName=persist_to_postgre, firstSubmitTime=1714382929006, startTime=0, taskType=PYTHON, workflowInstanceHost=172.18.0.10:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13426477386080, processDefineVersion=7, appIds=null, processInstanceId=747, scheduleTime=0, globalParams=null, executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[{"prop":"query","direct":"OUT","type":"VARCHAR","value":""}],"rawScript":"import re\n\n# define the table to send the data to\ntable_name = \"filtered_data_persistence\"\n\n# Provided JSON data as strings\njson_data = ''' \n{\n  \"user\": \"premiumplatinum\",\n  \"content\": \"singapore is stupid\",\n  \"url\": \"https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/\",\n  \"context\": \"21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist\",\n  \"score\": 131,\n  \"type\": \"post\",\n  \"id\": \"1c9itat\",\n  \"datetime\": \"2024-04-21 22:10:42\"\n}\n{\n        \"user\": \"premiumplatinum\",\n        \"content\": \"s is stupid\",\n        \"url\": \"https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/\",\n        \"context\": \"21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist\",\n        \"score\": 131,\n        \"type\": \"post\",\n        \"id\": \"1c9itat\",\n        \"datetime\": \"2024-04-21 22:10:42\"\n}\n'''\n\n# process the kafka messages to individual JSON objects\njson_objects = json_data.replace('}\\n{', '},\\n{').strip()\njson_objects = re.sub(\" +\", \" \",json_objects)   \njson_objects = '[' + json_objects + ']'\n\n# convert JSON string to a list of dicts\njson_list = json.loads(json_objects)\n\n# convert list of dictionaries into list of tuples containing only the values\nvalues = [tuple(message.values()) for message in json_list]\n\n# create the SQL Query\nquery = f'''\nINSERT INTO {table_name} (user, content, url, context, score, type, id, datetime)\nVALUES \n'''\n\nfor value in values:\n    query += str(value) + ',\\n'\n\n# remove the last 2 character ,\\n and change it to ; for the query\nquery = query[:-2] + ';'\n\n# pass the query as a parameter downstream\nprint(\"#setValue(query=%s)\" % query)","resourceList":[]}, environmentConfig=export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='persist_to_postgre'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='747'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240429'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240428'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='2024'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='es_filtered_data_persistence_subprocess'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13426451158240'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13426477386080'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240429172849'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=null, dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-747][TI-2024] - [INFO] 2024-04-29 17:28:49.017 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: persist_to_postgre to wait queue success
[WI-747][TI-2024] - [INFO] 2024-04-29 17:28:49.017 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-747][TI-2024] - [INFO] 2024-04-29 17:28:49.018 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-747][TI-2024] - [INFO] 2024-04-29 17:28:49.018 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-747][TI-2024] - [INFO] 2024-04-29 17:28:49.019 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-747][TI-2024] - [INFO] 2024-04-29 17:28:49.019 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1714382929019
[WI-747][TI-2024] - [INFO] 2024-04-29 17:28:49.019 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 747_2024
[WI-747][TI-2024] - [INFO] 2024-04-29 17:28:49.019 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 2024,
  "taskName" : "persist_to_postgre",
  "firstSubmitTime" : 1714382929006,
  "startTime" : 1714382929019,
  "taskType" : "PYTHON",
  "workflowInstanceHost" : "172.18.0.10:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240429/13426477386080/7/747/2024.log",
  "processId" : 0,
  "processDefineCode" : 13426477386080,
  "processDefineVersion" : 7,
  "processInstanceId" : 747,
  "scheduleTime" : 0,
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[{\"prop\":\"query\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"\"}],\"rawScript\":\"import re\\n\\n# define the table to send the data to\\ntable_name = \\\"filtered_data_persistence\\\"\\n\\n# Provided JSON data as strings\\njson_data = ''' \\n{\\n  \\\"user\\\": \\\"premiumplatinum\\\",\\n  \\\"content\\\": \\\"singapore is stupid\\\",\\n  \\\"url\\\": \\\"https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/\\\",\\n  \\\"context\\\": \\\"21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist\\\",\\n  \\\"score\\\": 131,\\n  \\\"type\\\": \\\"post\\\",\\n  \\\"id\\\": \\\"1c9itat\\\",\\n  \\\"datetime\\\": \\\"2024-04-21 22:10:42\\\"\\n}\\n{\\n        \\\"user\\\": \\\"premiumplatinum\\\",\\n        \\\"content\\\": \\\"s is stupid\\\",\\n        \\\"url\\\": \\\"https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/\\\",\\n        \\\"context\\\": \\\"21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist\\\",\\n        \\\"score\\\": 131,\\n        \\\"type\\\": \\\"post\\\",\\n        \\\"id\\\": \\\"1c9itat\\\",\\n        \\\"datetime\\\": \\\"2024-04-21 22:10:42\\\"\\n}\\n'''\\n\\n# process the kafka messages to individual JSON objects\\njson_objects = json_data.replace('}\\\\n{', '},\\\\n{').strip()\\njson_objects = re.sub(\\\" +\\\", \\\" \\\",json_objects)   \\njson_objects = '[' + json_objects + ']'\\n\\n# convert JSON string to a list of dicts\\njson_list = json.loads(json_objects)\\n\\n# convert list of dictionaries into list of tuples containing only the values\\nvalues = [tuple(message.values()) for message in json_list]\\n\\n# create the SQL Query\\nquery = f'''\\nINSERT INTO {table_name} (user, content, url, context, score, type, id, datetime)\\nVALUES \\n'''\\n\\nfor value in values:\\n    query += str(value) + ',\\\\n'\\n\\n# remove the last 2 character ,\\\\n and change it to ; for the query\\nquery = query[:-2] + ';'\\n\\n# pass the query as a parameter downstream\\nprint(\\\"#setValue(query=%s)\\\" % query)\",\"resourceList\":[]}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "persist_to_postgre"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "747"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240429"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240428"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "2024"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "es_filtered_data_persistence_subprocess"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13426451158240"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13426477386080"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240429172849"
    }
  },
  "taskAppId" : "747_2024",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-747][TI-2024] - [INFO] 2024-04-29 17:28:49.020 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-747][TI-2024] - [INFO] 2024-04-29 17:28:49.020 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-747][TI-2024] - [INFO] 2024-04-29 17:28:49.020 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-747][TI-2024] - [INFO] 2024-04-29 17:28:49.024 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-747][TI-2024] - [INFO] 2024-04-29 17:28:49.025 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-747][TI-2024] - [INFO] 2024-04-29 17:28:49.026 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_7/747/2024 check successfully
[WI-747][TI-2024] - [INFO] 2024-04-29 17:28:49.027 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.python.PythonTaskChannel successfully
[WI-747][TI-2024] - [INFO] 2024-04-29 17:28:49.027 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-747][TI-2024] - [INFO] 2024-04-29 17:28:49.027 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-747][TI-2024] - [INFO] 2024-04-29 17:28:49.028 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: PYTHON create successfully
[WI-747][TI-2024] - [INFO] 2024-04-29 17:28:49.028 +0800 o.a.d.p.t.p.PythonTask:[75] - Initialize python task params {
  "localParams" : [ {
    "prop" : "query",
    "direct" : "OUT",
    "type" : "VARCHAR",
    "value" : ""
  } ],
  "varPool" : null,
  "rawScript" : "import re\n\n# define the table to send the data to\ntable_name = \"filtered_data_persistence\"\n\n# Provided JSON data as strings\njson_data = ''' \n{\n  \"user\": \"premiumplatinum\",\n  \"content\": \"singapore is stupid\",\n  \"url\": \"https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/\",\n  \"context\": \"21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist\",\n  \"score\": 131,\n  \"type\": \"post\",\n  \"id\": \"1c9itat\",\n  \"datetime\": \"2024-04-21 22:10:42\"\n}\n{\n        \"user\": \"premiumplatinum\",\n        \"content\": \"s is stupid\",\n        \"url\": \"https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/\",\n        \"context\": \"21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist\",\n        \"score\": 131,\n        \"type\": \"post\",\n        \"id\": \"1c9itat\",\n        \"datetime\": \"2024-04-21 22:10:42\"\n}\n'''\n\n# process the kafka messages to individual JSON objects\njson_objects = json_data.replace('}\\n{', '},\\n{').strip()\njson_objects = re.sub(\" +\", \" \",json_objects)   \njson_objects = '[' + json_objects + ']'\n\n# convert JSON string to a list of dicts\njson_list = json.loads(json_objects)\n\n# convert list of dictionaries into list of tuples containing only the values\nvalues = [tuple(message.values()) for message in json_list]\n\n# create the SQL Query\nquery = f'''\nINSERT INTO {table_name} (user, content, url, context, score, type, id, datetime)\nVALUES \n'''\n\nfor value in values:\n    query += str(value) + ',\\n'\n\n# remove the last 2 character ,\\n and change it to ; for the query\nquery = query[:-2] + ';'\n\n# pass the query as a parameter downstream\nprint(\"#setValue(query=%s)\" % query)",
  "resourceList" : [ ]
}
[WI-747][TI-2024] - [INFO] 2024-04-29 17:28:49.028 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-747][TI-2024] - [INFO] 2024-04-29 17:28:49.029 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: null successfully
[WI-747][TI-2024] - [INFO] 2024-04-29 17:28:49.029 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-747][TI-2024] - [INFO] 2024-04-29 17:28:49.029 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-747][TI-2024] - [INFO] 2024-04-29 17:28:49.029 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-747][TI-2024] - [INFO] 2024-04-29 17:28:49.029 +0800 o.a.d.p.t.p.PythonTask:[165] - raw python script : import re

# define the table to send the data to
table_name = "filtered_data_persistence"

# Provided JSON data as strings
json_data = ''' 
{
  "user": "premiumplatinum",
  "content": "singapore is stupid",
  "url": "https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/",
  "context": "21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist",
  "score": 131,
  "type": "post",
  "id": "1c9itat",
  "datetime": "2024-04-21 22:10:42"
}
{
        "user": "premiumplatinum",
        "content": "s is stupid",
        "url": "https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/",
        "context": "21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist",
        "score": 131,
        "type": "post",
        "id": "1c9itat",
        "datetime": "2024-04-21 22:10:42"
}
'''

# process the kafka messages to individual JSON objects
json_objects = json_data.replace('}\n{', '},\n{').strip()
json_objects = re.sub(" +", " ",json_objects)   
json_objects = '[' + json_objects + ']'

# convert JSON string to a list of dicts
json_list = json.loads(json_objects)

# convert list of dictionaries into list of tuples containing only the values
values = [tuple(message.values()) for message in json_list]

# create the SQL Query
query = f'''
INSERT INTO {table_name} (user, content, url, context, score, type, id, datetime)
VALUES 
'''

for value in values:
    query += str(value) + ',\n'

# remove the last 2 character ,\n and change it to ; for the query
query = query[:-2] + ';'

# pass the query as a parameter downstream
print("#setValue(query=%s)" % query)
[WI-747][TI-2024] - [INFO] 2024-04-29 17:28:49.030 +0800 o.a.d.p.t.p.PythonTask:[131] - tenantCode :default, task dir:/tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_7/747/2024
[WI-747][TI-2024] - [INFO] 2024-04-29 17:28:49.030 +0800 o.a.d.p.t.p.PythonTask:[134] - generate python script file:/tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_7/747/2024/py_747_2024.py
[WI-747][TI-2024] - [INFO] 2024-04-29 17:28:49.030 +0800 o.a.d.p.t.p.PythonTask:[141] - #-*- encoding=utf8 -*-

import re

# define the table to send the data to
table_name = "filtered_data_persistence"

# Provided JSON data as strings
json_data = ''' 
{
  "user": "premiumplatinum",
  "content": "singapore is stupid",
  "url": "https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/",
  "context": "21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist",
  "score": 131,
  "type": "post",
  "id": "1c9itat",
  "datetime": "2024-04-21 22:10:42"
}
{
        "user": "premiumplatinum",
        "content": "s is stupid",
        "url": "https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/",
        "context": "21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist",
        "score": 131,
        "type": "post",
        "id": "1c9itat",
        "datetime": "2024-04-21 22:10:42"
}
'''

# process the kafka messages to individual JSON objects
json_objects = json_data.replace('}\n{', '},\n{').strip()
json_objects = re.sub(" +", " ",json_objects)   
json_objects = '[' + json_objects + ']'

# convert JSON string to a list of dicts
json_list = json.loads(json_objects)

# convert list of dictionaries into list of tuples containing only the values
values = [tuple(message.values()) for message in json_list]

# create the SQL Query
query = f'''
INSERT INTO {table_name} (user, content, url, context, score, type, id, datetime)
VALUES 
'''

for value in values:
    query += str(value) + ',\n'

# remove the last 2 character ,\n and change it to ; for the query
query = query[:-2] + ';'

# pass the query as a parameter downstream
print("#setValue(query=%s)" % query)
[WI-747][TI-2024] - [INFO] 2024-04-29 17:28:49.031 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-747][TI-2024] - [INFO] 2024-04-29 17:28:49.031 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-747][TI-2024] - [INFO] 2024-04-29 17:28:49.031 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export PYTHON_LAUNCHER=/bin/python3.11
${PYTHON_LAUNCHER} /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_7/747/2024/py_747_2024.py
[WI-747][TI-2024] - [INFO] 2024-04-29 17:28:49.031 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-747][TI-2024] - [INFO] 2024-04-29 17:28:49.031 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_7/747/2024/747_2024.sh
[WI-747][TI-2024] - [INFO] 2024-04-29 17:28:49.036 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 256
[WI-0][TI-2024] - [INFO] 2024-04-29 17:28:49.906 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=2024, success=true)
[WI-0][TI-2024] - [INFO] 2024-04-29 17:28:49.930 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=2024)
[WI-0][TI-0] - [INFO] 2024-04-29 17:28:50.037 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
	Traceback (most recent call last):
	  File "/tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_7/747/2024/py_747_2024.py", line 38, in <module>
	    json_list = json.loads(json_objects)
	                ^^^^
	NameError: name 'json' is not defined
[WI-747][TI-2024] - [INFO] 2024-04-29 17:28:50.040 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_7/747/2024, processId:256 ,exitStatusCode:1 ,processWaitForStatus:true ,processExitValue:1
[WI-747][TI-2024] - [INFO] 2024-04-29 17:28:50.041 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-747][TI-2024] - [INFO] 2024-04-29 17:28:50.041 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-747][TI-2024] - [INFO] 2024-04-29 17:28:50.041 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-747][TI-2024] - [INFO] 2024-04-29 17:28:50.042 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-747][TI-2024] - [INFO] 2024-04-29 17:28:50.050 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: FAILURE to master : 172.18.1.1:1234
[WI-747][TI-2024] - [INFO] 2024-04-29 17:28:50.051 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-747][TI-2024] - [INFO] 2024-04-29 17:28:50.051 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_7/747/2024
[WI-747][TI-2024] - [INFO] 2024-04-29 17:28:50.051 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_7/747/2024
[WI-747][TI-2024] - [INFO] 2024-04-29 17:28:50.051 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-2024] - [INFO] 2024-04-29 17:28:50.889 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=2024, success=true)
[WI-0][TI-0] - [INFO] 2024-04-29 17:28:50.978 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=2025, taskName=persist_to_postgre, firstSubmitTime=1714382930943, startTime=0, taskType=PYTHON, workflowInstanceHost=172.18.0.10:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13426477386080, processDefineVersion=7, appIds=null, processInstanceId=747, scheduleTime=0, globalParams=null, executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[{"prop":"query","direct":"OUT","type":"VARCHAR","value":""}],"rawScript":"import re\n\n# define the table to send the data to\ntable_name = \"filtered_data_persistence\"\n\n# Provided JSON data as strings\njson_data = ''' \n{\n  \"user\": \"premiumplatinum\",\n  \"content\": \"singapore is stupid\",\n  \"url\": \"https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/\",\n  \"context\": \"21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist\",\n  \"score\": 131,\n  \"type\": \"post\",\n  \"id\": \"1c9itat\",\n  \"datetime\": \"2024-04-21 22:10:42\"\n}\n{\n        \"user\": \"premiumplatinum\",\n        \"content\": \"s is stupid\",\n        \"url\": \"https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/\",\n        \"context\": \"21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist\",\n        \"score\": 131,\n        \"type\": \"post\",\n        \"id\": \"1c9itat\",\n        \"datetime\": \"2024-04-21 22:10:42\"\n}\n'''\n\n# process the kafka messages to individual JSON objects\njson_objects = json_data.replace('}\\n{', '},\\n{').strip()\njson_objects = re.sub(\" +\", \" \",json_objects)   \njson_objects = '[' + json_objects + ']'\n\n# convert JSON string to a list of dicts\njson_list = json.loads(json_objects)\n\n# convert list of dictionaries into list of tuples containing only the values\nvalues = [tuple(message.values()) for message in json_list]\n\n# create the SQL Query\nquery = f'''\nINSERT INTO {table_name} (user, content, url, context, score, type, id, datetime)\nVALUES \n'''\n\nfor value in values:\n    query += str(value) + ',\\n'\n\n# remove the last 2 character ,\\n and change it to ; for the query\nquery = query[:-2] + ';'\n\n# pass the query as a parameter downstream\nprint(\"#setValue(query=%s)\" % query)","resourceList":[]}, environmentConfig=export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='persist_to_postgre'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, query=Property{prop='query', direct=OUT, type=VARCHAR, value=''}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240429'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='2025'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13426451158240'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240429172850'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='747'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240428'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='es_filtered_data_persistence_subprocess'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13426477386080'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"query","direct":"OUT","type":"VARCHAR","value":""}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-747][TI-2025] - [INFO] 2024-04-29 17:28:50.980 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: persist_to_postgre to wait queue success
[WI-747][TI-2025] - [INFO] 2024-04-29 17:28:50.981 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-747][TI-2025] - [INFO] 2024-04-29 17:28:50.982 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-747][TI-2025] - [INFO] 2024-04-29 17:28:50.982 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-747][TI-2025] - [INFO] 2024-04-29 17:28:50.982 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-747][TI-2025] - [INFO] 2024-04-29 17:28:50.983 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1714382930983
[WI-747][TI-2025] - [INFO] 2024-04-29 17:28:50.983 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 747_2025
[WI-747][TI-2025] - [INFO] 2024-04-29 17:28:50.983 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 2025,
  "taskName" : "persist_to_postgre",
  "firstSubmitTime" : 1714382930943,
  "startTime" : 1714382930983,
  "taskType" : "PYTHON",
  "workflowInstanceHost" : "172.18.0.10:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240429/13426477386080/7/747/2025.log",
  "processId" : 0,
  "processDefineCode" : 13426477386080,
  "processDefineVersion" : 7,
  "processInstanceId" : 747,
  "scheduleTime" : 0,
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[{\"prop\":\"query\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"\"}],\"rawScript\":\"import re\\n\\n# define the table to send the data to\\ntable_name = \\\"filtered_data_persistence\\\"\\n\\n# Provided JSON data as strings\\njson_data = ''' \\n{\\n  \\\"user\\\": \\\"premiumplatinum\\\",\\n  \\\"content\\\": \\\"singapore is stupid\\\",\\n  \\\"url\\\": \\\"https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/\\\",\\n  \\\"context\\\": \\\"21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist\\\",\\n  \\\"score\\\": 131,\\n  \\\"type\\\": \\\"post\\\",\\n  \\\"id\\\": \\\"1c9itat\\\",\\n  \\\"datetime\\\": \\\"2024-04-21 22:10:42\\\"\\n}\\n{\\n        \\\"user\\\": \\\"premiumplatinum\\\",\\n        \\\"content\\\": \\\"s is stupid\\\",\\n        \\\"url\\\": \\\"https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/\\\",\\n        \\\"context\\\": \\\"21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist\\\",\\n        \\\"score\\\": 131,\\n        \\\"type\\\": \\\"post\\\",\\n        \\\"id\\\": \\\"1c9itat\\\",\\n        \\\"datetime\\\": \\\"2024-04-21 22:10:42\\\"\\n}\\n'''\\n\\n# process the kafka messages to individual JSON objects\\njson_objects = json_data.replace('}\\\\n{', '},\\\\n{').strip()\\njson_objects = re.sub(\\\" +\\\", \\\" \\\",json_objects)   \\njson_objects = '[' + json_objects + ']'\\n\\n# convert JSON string to a list of dicts\\njson_list = json.loads(json_objects)\\n\\n# convert list of dictionaries into list of tuples containing only the values\\nvalues = [tuple(message.values()) for message in json_list]\\n\\n# create the SQL Query\\nquery = f'''\\nINSERT INTO {table_name} (user, content, url, context, score, type, id, datetime)\\nVALUES \\n'''\\n\\nfor value in values:\\n    query += str(value) + ',\\\\n'\\n\\n# remove the last 2 character ,\\\\n and change it to ; for the query\\nquery = query[:-2] + ';'\\n\\n# pass the query as a parameter downstream\\nprint(\\\"#setValue(query=%s)\\\" % query)\",\"resourceList\":[]}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "persist_to_postgre"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "query" : {
      "prop" : "query",
      "direct" : "OUT",
      "type" : "VARCHAR",
      "value" : ""
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240429"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "2025"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13426451158240"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240429172850"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "747"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240428"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "es_filtered_data_persistence_subprocess"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13426477386080"
    }
  },
  "taskAppId" : "747_2025",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"query\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-747][TI-2025] - [INFO] 2024-04-29 17:28:50.983 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-747][TI-2025] - [INFO] 2024-04-29 17:28:50.984 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-747][TI-2025] - [INFO] 2024-04-29 17:28:50.984 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-747][TI-2025] - [INFO] 2024-04-29 17:28:50.988 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-747][TI-2025] - [INFO] 2024-04-29 17:28:50.989 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-747][TI-2025] - [INFO] 2024-04-29 17:28:50.989 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_7/747/2025 check successfully
[WI-747][TI-2025] - [INFO] 2024-04-29 17:28:50.994 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.python.PythonTaskChannel successfully
[WI-747][TI-2025] - [INFO] 2024-04-29 17:28:50.995 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-747][TI-2025] - [INFO] 2024-04-29 17:28:50.995 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-747][TI-2025] - [INFO] 2024-04-29 17:28:50.995 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: PYTHON create successfully
[WI-747][TI-2025] - [INFO] 2024-04-29 17:28:50.997 +0800 o.a.d.p.t.p.PythonTask:[75] - Initialize python task params {
  "localParams" : [ {
    "prop" : "query",
    "direct" : "OUT",
    "type" : "VARCHAR",
    "value" : ""
  } ],
  "varPool" : null,
  "rawScript" : "import re\n\n# define the table to send the data to\ntable_name = \"filtered_data_persistence\"\n\n# Provided JSON data as strings\njson_data = ''' \n{\n  \"user\": \"premiumplatinum\",\n  \"content\": \"singapore is stupid\",\n  \"url\": \"https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/\",\n  \"context\": \"21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist\",\n  \"score\": 131,\n  \"type\": \"post\",\n  \"id\": \"1c9itat\",\n  \"datetime\": \"2024-04-21 22:10:42\"\n}\n{\n        \"user\": \"premiumplatinum\",\n        \"content\": \"s is stupid\",\n        \"url\": \"https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/\",\n        \"context\": \"21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist\",\n        \"score\": 131,\n        \"type\": \"post\",\n        \"id\": \"1c9itat\",\n        \"datetime\": \"2024-04-21 22:10:42\"\n}\n'''\n\n# process the kafka messages to individual JSON objects\njson_objects = json_data.replace('}\\n{', '},\\n{').strip()\njson_objects = re.sub(\" +\", \" \",json_objects)   \njson_objects = '[' + json_objects + ']'\n\n# convert JSON string to a list of dicts\njson_list = json.loads(json_objects)\n\n# convert list of dictionaries into list of tuples containing only the values\nvalues = [tuple(message.values()) for message in json_list]\n\n# create the SQL Query\nquery = f'''\nINSERT INTO {table_name} (user, content, url, context, score, type, id, datetime)\nVALUES \n'''\n\nfor value in values:\n    query += str(value) + ',\\n'\n\n# remove the last 2 character ,\\n and change it to ; for the query\nquery = query[:-2] + ';'\n\n# pass the query as a parameter downstream\nprint(\"#setValue(query=%s)\" % query)",
  "resourceList" : [ ]
}
[WI-747][TI-2025] - [INFO] 2024-04-29 17:28:50.998 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-747][TI-2025] - [INFO] 2024-04-29 17:28:50.998 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"query","direct":"OUT","type":"VARCHAR","value":""}] successfully
[WI-747][TI-2025] - [INFO] 2024-04-29 17:28:50.998 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-747][TI-2025] - [INFO] 2024-04-29 17:28:50.999 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-747][TI-2025] - [INFO] 2024-04-29 17:28:50.999 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-747][TI-2025] - [INFO] 2024-04-29 17:28:50.999 +0800 o.a.d.p.t.p.PythonTask:[165] - raw python script : import re

# define the table to send the data to
table_name = "filtered_data_persistence"

# Provided JSON data as strings
json_data = ''' 
{
  "user": "premiumplatinum",
  "content": "singapore is stupid",
  "url": "https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/",
  "context": "21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist",
  "score": 131,
  "type": "post",
  "id": "1c9itat",
  "datetime": "2024-04-21 22:10:42"
}
{
        "user": "premiumplatinum",
        "content": "s is stupid",
        "url": "https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/",
        "context": "21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist",
        "score": 131,
        "type": "post",
        "id": "1c9itat",
        "datetime": "2024-04-21 22:10:42"
}
'''

# process the kafka messages to individual JSON objects
json_objects = json_data.replace('}\n{', '},\n{').strip()
json_objects = re.sub(" +", " ",json_objects)   
json_objects = '[' + json_objects + ']'

# convert JSON string to a list of dicts
json_list = json.loads(json_objects)

# convert list of dictionaries into list of tuples containing only the values
values = [tuple(message.values()) for message in json_list]

# create the SQL Query
query = f'''
INSERT INTO {table_name} (user, content, url, context, score, type, id, datetime)
VALUES 
'''

for value in values:
    query += str(value) + ',\n'

# remove the last 2 character ,\n and change it to ; for the query
query = query[:-2] + ';'

# pass the query as a parameter downstream
print("#setValue(query=%s)" % query)
[WI-747][TI-2025] - [INFO] 2024-04-29 17:28:50.999 +0800 o.a.d.p.t.p.PythonTask:[131] - tenantCode :default, task dir:/tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_7/747/2025
[WI-747][TI-2025] - [INFO] 2024-04-29 17:28:51.000 +0800 o.a.d.p.t.p.PythonTask:[134] - generate python script file:/tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_7/747/2025/py_747_2025.py
[WI-747][TI-2025] - [INFO] 2024-04-29 17:28:51.000 +0800 o.a.d.p.t.p.PythonTask:[141] - #-*- encoding=utf8 -*-

import re

# define the table to send the data to
table_name = "filtered_data_persistence"

# Provided JSON data as strings
json_data = ''' 
{
  "user": "premiumplatinum",
  "content": "singapore is stupid",
  "url": "https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/",
  "context": "21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist",
  "score": 131,
  "type": "post",
  "id": "1c9itat",
  "datetime": "2024-04-21 22:10:42"
}
{
        "user": "premiumplatinum",
        "content": "s is stupid",
        "url": "https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/",
        "context": "21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist",
        "score": 131,
        "type": "post",
        "id": "1c9itat",
        "datetime": "2024-04-21 22:10:42"
}
'''

# process the kafka messages to individual JSON objects
json_objects = json_data.replace('}\n{', '},\n{').strip()
json_objects = re.sub(" +", " ",json_objects)   
json_objects = '[' + json_objects + ']'

# convert JSON string to a list of dicts
json_list = json.loads(json_objects)

# convert list of dictionaries into list of tuples containing only the values
values = [tuple(message.values()) for message in json_list]

# create the SQL Query
query = f'''
INSERT INTO {table_name} (user, content, url, context, score, type, id, datetime)
VALUES 
'''

for value in values:
    query += str(value) + ',\n'

# remove the last 2 character ,\n and change it to ; for the query
query = query[:-2] + ';'

# pass the query as a parameter downstream
print("#setValue(query=%s)" % query)
[WI-747][TI-2025] - [INFO] 2024-04-29 17:28:51.000 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-747][TI-2025] - [INFO] 2024-04-29 17:28:51.004 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-747][TI-2025] - [INFO] 2024-04-29 17:28:51.007 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export PYTHON_LAUNCHER=/bin/python3.11
${PYTHON_LAUNCHER} /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_7/747/2025/py_747_2025.py
[WI-747][TI-2025] - [INFO] 2024-04-29 17:28:51.007 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-747][TI-2025] - [INFO] 2024-04-29 17:28:51.007 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_7/747/2025/747_2025.sh
[WI-747][TI-2025] - [INFO] 2024-04-29 17:28:51.036 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 267
[WI-0][TI-0] - [INFO] 2024-04-29 17:28:51.038 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
[WI-0][TI-2025] - [INFO] 2024-04-29 17:28:51.918 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=2025, success=true)
[WI-0][TI-2025] - [INFO] 2024-04-29 17:28:51.949 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=2025)
[WI-0][TI-0] - [INFO] 2024-04-29 17:28:52.054 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	Traceback (most recent call last):
	  File "/tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_7/747/2025/py_747_2025.py", line 38, in <module>
	    json_list = json.loads(json_objects)
	                ^^^^
	NameError: name 'json' is not defined
[WI-747][TI-2025] - [INFO] 2024-04-29 17:28:52.054 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_7/747/2025, processId:267 ,exitStatusCode:1 ,processWaitForStatus:true ,processExitValue:1
[WI-747][TI-2025] - [INFO] 2024-04-29 17:28:52.056 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-747][TI-2025] - [INFO] 2024-04-29 17:28:52.057 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-747][TI-2025] - [INFO] 2024-04-29 17:28:52.057 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-747][TI-2025] - [INFO] 2024-04-29 17:28:52.057 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-747][TI-2025] - [INFO] 2024-04-29 17:28:52.064 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: FAILURE to master : 172.18.1.1:1234
[WI-747][TI-2025] - [INFO] 2024-04-29 17:28:52.064 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-747][TI-2025] - [INFO] 2024-04-29 17:28:52.065 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_7/747/2025
[WI-747][TI-2025] - [INFO] 2024-04-29 17:28:52.065 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_7/747/2025
[WI-747][TI-2025] - [INFO] 2024-04-29 17:28:52.066 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-2025] - [INFO] 2024-04-29 17:28:52.904 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=2025, success=true)
[WI-0][TI-0] - [INFO] 2024-04-29 17:28:52.992 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=2026, taskName=persist_to_postgre, firstSubmitTime=1714382932974, startTime=0, taskType=PYTHON, workflowInstanceHost=172.18.0.10:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13426477386080, processDefineVersion=7, appIds=null, processInstanceId=747, scheduleTime=0, globalParams=null, executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[{"prop":"query","direct":"OUT","type":"VARCHAR","value":""}],"rawScript":"import re\n\n# define the table to send the data to\ntable_name = \"filtered_data_persistence\"\n\n# Provided JSON data as strings\njson_data = ''' \n{\n  \"user\": \"premiumplatinum\",\n  \"content\": \"singapore is stupid\",\n  \"url\": \"https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/\",\n  \"context\": \"21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist\",\n  \"score\": 131,\n  \"type\": \"post\",\n  \"id\": \"1c9itat\",\n  \"datetime\": \"2024-04-21 22:10:42\"\n}\n{\n        \"user\": \"premiumplatinum\",\n        \"content\": \"s is stupid\",\n        \"url\": \"https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/\",\n        \"context\": \"21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist\",\n        \"score\": 131,\n        \"type\": \"post\",\n        \"id\": \"1c9itat\",\n        \"datetime\": \"2024-04-21 22:10:42\"\n}\n'''\n\n# process the kafka messages to individual JSON objects\njson_objects = json_data.replace('}\\n{', '},\\n{').strip()\njson_objects = re.sub(\" +\", \" \",json_objects)   \njson_objects = '[' + json_objects + ']'\n\n# convert JSON string to a list of dicts\njson_list = json.loads(json_objects)\n\n# convert list of dictionaries into list of tuples containing only the values\nvalues = [tuple(message.values()) for message in json_list]\n\n# create the SQL Query\nquery = f'''\nINSERT INTO {table_name} (user, content, url, context, score, type, id, datetime)\nVALUES \n'''\n\nfor value in values:\n    query += str(value) + ',\\n'\n\n# remove the last 2 character ,\\n and change it to ; for the query\nquery = query[:-2] + ';'\n\n# pass the query as a parameter downstream\nprint(\"#setValue(query=%s)\" % query)","resourceList":[]}, environmentConfig=export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='persist_to_postgre'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, query=Property{prop='query', direct=OUT, type=VARCHAR, value=''}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240429'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='2026'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13426451158240'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240429172852'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='747'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240428'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='es_filtered_data_persistence_subprocess'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13426477386080'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"query","direct":"OUT","type":"VARCHAR","value":""}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-747][TI-2026] - [INFO] 2024-04-29 17:28:53.007 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: persist_to_postgre to wait queue success
[WI-747][TI-2026] - [INFO] 2024-04-29 17:28:53.009 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-747][TI-2026] - [INFO] 2024-04-29 17:28:53.012 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-747][TI-2026] - [INFO] 2024-04-29 17:28:53.013 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-747][TI-2026] - [INFO] 2024-04-29 17:28:53.013 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-747][TI-2026] - [INFO] 2024-04-29 17:28:53.013 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1714382933013
[WI-747][TI-2026] - [INFO] 2024-04-29 17:28:53.013 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 747_2026
[WI-747][TI-2026] - [INFO] 2024-04-29 17:28:53.017 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 2026,
  "taskName" : "persist_to_postgre",
  "firstSubmitTime" : 1714382932974,
  "startTime" : 1714382933013,
  "taskType" : "PYTHON",
  "workflowInstanceHost" : "172.18.0.10:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240429/13426477386080/7/747/2026.log",
  "processId" : 0,
  "processDefineCode" : 13426477386080,
  "processDefineVersion" : 7,
  "processInstanceId" : 747,
  "scheduleTime" : 0,
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[{\"prop\":\"query\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"\"}],\"rawScript\":\"import re\\n\\n# define the table to send the data to\\ntable_name = \\\"filtered_data_persistence\\\"\\n\\n# Provided JSON data as strings\\njson_data = ''' \\n{\\n  \\\"user\\\": \\\"premiumplatinum\\\",\\n  \\\"content\\\": \\\"singapore is stupid\\\",\\n  \\\"url\\\": \\\"https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/\\\",\\n  \\\"context\\\": \\\"21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist\\\",\\n  \\\"score\\\": 131,\\n  \\\"type\\\": \\\"post\\\",\\n  \\\"id\\\": \\\"1c9itat\\\",\\n  \\\"datetime\\\": \\\"2024-04-21 22:10:42\\\"\\n}\\n{\\n        \\\"user\\\": \\\"premiumplatinum\\\",\\n        \\\"content\\\": \\\"s is stupid\\\",\\n        \\\"url\\\": \\\"https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/\\\",\\n        \\\"context\\\": \\\"21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist\\\",\\n        \\\"score\\\": 131,\\n        \\\"type\\\": \\\"post\\\",\\n        \\\"id\\\": \\\"1c9itat\\\",\\n        \\\"datetime\\\": \\\"2024-04-21 22:10:42\\\"\\n}\\n'''\\n\\n# process the kafka messages to individual JSON objects\\njson_objects = json_data.replace('}\\\\n{', '},\\\\n{').strip()\\njson_objects = re.sub(\\\" +\\\", \\\" \\\",json_objects)   \\njson_objects = '[' + json_objects + ']'\\n\\n# convert JSON string to a list of dicts\\njson_list = json.loads(json_objects)\\n\\n# convert list of dictionaries into list of tuples containing only the values\\nvalues = [tuple(message.values()) for message in json_list]\\n\\n# create the SQL Query\\nquery = f'''\\nINSERT INTO {table_name} (user, content, url, context, score, type, id, datetime)\\nVALUES \\n'''\\n\\nfor value in values:\\n    query += str(value) + ',\\\\n'\\n\\n# remove the last 2 character ,\\\\n and change it to ; for the query\\nquery = query[:-2] + ';'\\n\\n# pass the query as a parameter downstream\\nprint(\\\"#setValue(query=%s)\\\" % query)\",\"resourceList\":[]}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "persist_to_postgre"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "query" : {
      "prop" : "query",
      "direct" : "OUT",
      "type" : "VARCHAR",
      "value" : ""
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240429"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "2026"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13426451158240"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240429172852"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "747"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240428"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "es_filtered_data_persistence_subprocess"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13426477386080"
    }
  },
  "taskAppId" : "747_2026",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"query\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-747][TI-2026] - [INFO] 2024-04-29 17:28:53.018 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-747][TI-2026] - [INFO] 2024-04-29 17:28:53.018 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-747][TI-2026] - [INFO] 2024-04-29 17:28:53.018 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-747][TI-2026] - [INFO] 2024-04-29 17:28:53.025 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-747][TI-2026] - [INFO] 2024-04-29 17:28:53.025 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-747][TI-2026] - [INFO] 2024-04-29 17:28:53.025 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_7/747/2026 check successfully
[WI-747][TI-2026] - [INFO] 2024-04-29 17:28:53.025 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.python.PythonTaskChannel successfully
[WI-747][TI-2026] - [INFO] 2024-04-29 17:28:53.026 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-747][TI-2026] - [INFO] 2024-04-29 17:28:53.026 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-747][TI-2026] - [INFO] 2024-04-29 17:28:53.026 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: PYTHON create successfully
[WI-747][TI-2026] - [INFO] 2024-04-29 17:28:53.027 +0800 o.a.d.p.t.p.PythonTask:[75] - Initialize python task params {
  "localParams" : [ {
    "prop" : "query",
    "direct" : "OUT",
    "type" : "VARCHAR",
    "value" : ""
  } ],
  "varPool" : null,
  "rawScript" : "import re\n\n# define the table to send the data to\ntable_name = \"filtered_data_persistence\"\n\n# Provided JSON data as strings\njson_data = ''' \n{\n  \"user\": \"premiumplatinum\",\n  \"content\": \"singapore is stupid\",\n  \"url\": \"https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/\",\n  \"context\": \"21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist\",\n  \"score\": 131,\n  \"type\": \"post\",\n  \"id\": \"1c9itat\",\n  \"datetime\": \"2024-04-21 22:10:42\"\n}\n{\n        \"user\": \"premiumplatinum\",\n        \"content\": \"s is stupid\",\n        \"url\": \"https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/\",\n        \"context\": \"21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist\",\n        \"score\": 131,\n        \"type\": \"post\",\n        \"id\": \"1c9itat\",\n        \"datetime\": \"2024-04-21 22:10:42\"\n}\n'''\n\n# process the kafka messages to individual JSON objects\njson_objects = json_data.replace('}\\n{', '},\\n{').strip()\njson_objects = re.sub(\" +\", \" \",json_objects)   \njson_objects = '[' + json_objects + ']'\n\n# convert JSON string to a list of dicts\njson_list = json.loads(json_objects)\n\n# convert list of dictionaries into list of tuples containing only the values\nvalues = [tuple(message.values()) for message in json_list]\n\n# create the SQL Query\nquery = f'''\nINSERT INTO {table_name} (user, content, url, context, score, type, id, datetime)\nVALUES \n'''\n\nfor value in values:\n    query += str(value) + ',\\n'\n\n# remove the last 2 character ,\\n and change it to ; for the query\nquery = query[:-2] + ';'\n\n# pass the query as a parameter downstream\nprint(\"#setValue(query=%s)\" % query)",
  "resourceList" : [ ]
}
[WI-747][TI-2026] - [INFO] 2024-04-29 17:28:53.027 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-747][TI-2026] - [INFO] 2024-04-29 17:28:53.027 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"query","direct":"OUT","type":"VARCHAR","value":""}] successfully
[WI-747][TI-2026] - [INFO] 2024-04-29 17:28:53.027 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-747][TI-2026] - [INFO] 2024-04-29 17:28:53.027 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-747][TI-2026] - [INFO] 2024-04-29 17:28:53.027 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-747][TI-2026] - [INFO] 2024-04-29 17:28:53.027 +0800 o.a.d.p.t.p.PythonTask:[165] - raw python script : import re

# define the table to send the data to
table_name = "filtered_data_persistence"

# Provided JSON data as strings
json_data = ''' 
{
  "user": "premiumplatinum",
  "content": "singapore is stupid",
  "url": "https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/",
  "context": "21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist",
  "score": 131,
  "type": "post",
  "id": "1c9itat",
  "datetime": "2024-04-21 22:10:42"
}
{
        "user": "premiumplatinum",
        "content": "s is stupid",
        "url": "https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/",
        "context": "21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist",
        "score": 131,
        "type": "post",
        "id": "1c9itat",
        "datetime": "2024-04-21 22:10:42"
}
'''

# process the kafka messages to individual JSON objects
json_objects = json_data.replace('}\n{', '},\n{').strip()
json_objects = re.sub(" +", " ",json_objects)   
json_objects = '[' + json_objects + ']'

# convert JSON string to a list of dicts
json_list = json.loads(json_objects)

# convert list of dictionaries into list of tuples containing only the values
values = [tuple(message.values()) for message in json_list]

# create the SQL Query
query = f'''
INSERT INTO {table_name} (user, content, url, context, score, type, id, datetime)
VALUES 
'''

for value in values:
    query += str(value) + ',\n'

# remove the last 2 character ,\n and change it to ; for the query
query = query[:-2] + ';'

# pass the query as a parameter downstream
print("#setValue(query=%s)" % query)
[WI-747][TI-2026] - [INFO] 2024-04-29 17:28:53.028 +0800 o.a.d.p.t.p.PythonTask:[131] - tenantCode :default, task dir:/tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_7/747/2026
[WI-747][TI-2026] - [INFO] 2024-04-29 17:28:53.029 +0800 o.a.d.p.t.p.PythonTask:[134] - generate python script file:/tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_7/747/2026/py_747_2026.py
[WI-747][TI-2026] - [INFO] 2024-04-29 17:28:53.029 +0800 o.a.d.p.t.p.PythonTask:[141] - #-*- encoding=utf8 -*-

import re

# define the table to send the data to
table_name = "filtered_data_persistence"

# Provided JSON data as strings
json_data = ''' 
{
  "user": "premiumplatinum",
  "content": "singapore is stupid",
  "url": "https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/",
  "context": "21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist",
  "score": 131,
  "type": "post",
  "id": "1c9itat",
  "datetime": "2024-04-21 22:10:42"
}
{
        "user": "premiumplatinum",
        "content": "s is stupid",
        "url": "https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/",
        "context": "21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist",
        "score": 131,
        "type": "post",
        "id": "1c9itat",
        "datetime": "2024-04-21 22:10:42"
}
'''

# process the kafka messages to individual JSON objects
json_objects = json_data.replace('}\n{', '},\n{').strip()
json_objects = re.sub(" +", " ",json_objects)   
json_objects = '[' + json_objects + ']'

# convert JSON string to a list of dicts
json_list = json.loads(json_objects)

# convert list of dictionaries into list of tuples containing only the values
values = [tuple(message.values()) for message in json_list]

# create the SQL Query
query = f'''
INSERT INTO {table_name} (user, content, url, context, score, type, id, datetime)
VALUES 
'''

for value in values:
    query += str(value) + ',\n'

# remove the last 2 character ,\n and change it to ; for the query
query = query[:-2] + ';'

# pass the query as a parameter downstream
print("#setValue(query=%s)" % query)
[WI-747][TI-2026] - [INFO] 2024-04-29 17:28:53.029 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-747][TI-2026] - [INFO] 2024-04-29 17:28:53.029 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-747][TI-2026] - [INFO] 2024-04-29 17:28:53.029 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export PYTHON_LAUNCHER=/bin/python3.11
${PYTHON_LAUNCHER} /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_7/747/2026/py_747_2026.py
[WI-747][TI-2026] - [INFO] 2024-04-29 17:28:53.029 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-747][TI-2026] - [INFO] 2024-04-29 17:28:53.030 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_7/747/2026/747_2026.sh
[WI-747][TI-2026] - [INFO] 2024-04-29 17:28:53.038 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 278
[WI-0][TI-2026] - [INFO] 2024-04-29 17:28:53.910 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=2026, success=true)
[WI-0][TI-2026] - [INFO] 2024-04-29 17:28:53.927 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=2026)
[WI-0][TI-0] - [INFO] 2024-04-29 17:28:54.045 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
	Traceback (most recent call last):
	  File "/tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_7/747/2026/py_747_2026.py", line 38, in <module>
	    json_list = json.loads(json_objects)
	                ^^^^
	NameError: name 'json' is not defined
[WI-747][TI-2026] - [INFO] 2024-04-29 17:28:54.049 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_7/747/2026, processId:278 ,exitStatusCode:1 ,processWaitForStatus:true ,processExitValue:1
[WI-747][TI-2026] - [INFO] 2024-04-29 17:28:54.049 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-747][TI-2026] - [INFO] 2024-04-29 17:28:54.049 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-747][TI-2026] - [INFO] 2024-04-29 17:28:54.050 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-747][TI-2026] - [INFO] 2024-04-29 17:28:54.050 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-747][TI-2026] - [INFO] 2024-04-29 17:28:54.057 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: FAILURE to master : 172.18.1.1:1234
[WI-747][TI-2026] - [INFO] 2024-04-29 17:28:54.060 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-747][TI-2026] - [INFO] 2024-04-29 17:28:54.060 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_7/747/2026
[WI-747][TI-2026] - [INFO] 2024-04-29 17:28:54.061 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_7/747/2026
[WI-747][TI-2026] - [INFO] 2024-04-29 17:28:54.061 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-2026] - [INFO] 2024-04-29 17:28:54.914 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=2026, success=true)
[WI-0][TI-0] - [INFO] 2024-04-29 17:28:55.024 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=2027, taskName=persist_to_postgre, firstSubmitTime=1714382935000, startTime=0, taskType=PYTHON, workflowInstanceHost=172.18.0.10:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13426477386080, processDefineVersion=7, appIds=null, processInstanceId=747, scheduleTime=0, globalParams=null, executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[{"prop":"query","direct":"OUT","type":"VARCHAR","value":""}],"rawScript":"import re\n\n# define the table to send the data to\ntable_name = \"filtered_data_persistence\"\n\n# Provided JSON data as strings\njson_data = ''' \n{\n  \"user\": \"premiumplatinum\",\n  \"content\": \"singapore is stupid\",\n  \"url\": \"https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/\",\n  \"context\": \"21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist\",\n  \"score\": 131,\n  \"type\": \"post\",\n  \"id\": \"1c9itat\",\n  \"datetime\": \"2024-04-21 22:10:42\"\n}\n{\n        \"user\": \"premiumplatinum\",\n        \"content\": \"s is stupid\",\n        \"url\": \"https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/\",\n        \"context\": \"21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist\",\n        \"score\": 131,\n        \"type\": \"post\",\n        \"id\": \"1c9itat\",\n        \"datetime\": \"2024-04-21 22:10:42\"\n}\n'''\n\n# process the kafka messages to individual JSON objects\njson_objects = json_data.replace('}\\n{', '},\\n{').strip()\njson_objects = re.sub(\" +\", \" \",json_objects)   \njson_objects = '[' + json_objects + ']'\n\n# convert JSON string to a list of dicts\njson_list = json.loads(json_objects)\n\n# convert list of dictionaries into list of tuples containing only the values\nvalues = [tuple(message.values()) for message in json_list]\n\n# create the SQL Query\nquery = f'''\nINSERT INTO {table_name} (user, content, url, context, score, type, id, datetime)\nVALUES \n'''\n\nfor value in values:\n    query += str(value) + ',\\n'\n\n# remove the last 2 character ,\\n and change it to ; for the query\nquery = query[:-2] + ';'\n\n# pass the query as a parameter downstream\nprint(\"#setValue(query=%s)\" % query)","resourceList":[]}, environmentConfig=export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='persist_to_postgre'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, query=Property{prop='query', direct=OUT, type=VARCHAR, value=''}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240429'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='2027'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13426451158240'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240429172855'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='747'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240428'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='es_filtered_data_persistence_subprocess'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13426477386080'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"query","direct":"OUT","type":"VARCHAR","value":""}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-747][TI-2027] - [INFO] 2024-04-29 17:28:55.027 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: persist_to_postgre to wait queue success
[WI-747][TI-2027] - [INFO] 2024-04-29 17:28:55.034 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-747][TI-2027] - [INFO] 2024-04-29 17:28:55.037 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-747][TI-2027] - [INFO] 2024-04-29 17:28:55.037 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-747][TI-2027] - [INFO] 2024-04-29 17:28:55.037 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-747][TI-2027] - [INFO] 2024-04-29 17:28:55.037 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1714382935037
[WI-747][TI-2027] - [INFO] 2024-04-29 17:28:55.038 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 747_2027
[WI-747][TI-2027] - [INFO] 2024-04-29 17:28:55.039 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 2027,
  "taskName" : "persist_to_postgre",
  "firstSubmitTime" : 1714382935000,
  "startTime" : 1714382935037,
  "taskType" : "PYTHON",
  "workflowInstanceHost" : "172.18.0.10:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240429/13426477386080/7/747/2027.log",
  "processId" : 0,
  "processDefineCode" : 13426477386080,
  "processDefineVersion" : 7,
  "processInstanceId" : 747,
  "scheduleTime" : 0,
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[{\"prop\":\"query\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"\"}],\"rawScript\":\"import re\\n\\n# define the table to send the data to\\ntable_name = \\\"filtered_data_persistence\\\"\\n\\n# Provided JSON data as strings\\njson_data = ''' \\n{\\n  \\\"user\\\": \\\"premiumplatinum\\\",\\n  \\\"content\\\": \\\"singapore is stupid\\\",\\n  \\\"url\\\": \\\"https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/\\\",\\n  \\\"context\\\": \\\"21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist\\\",\\n  \\\"score\\\": 131,\\n  \\\"type\\\": \\\"post\\\",\\n  \\\"id\\\": \\\"1c9itat\\\",\\n  \\\"datetime\\\": \\\"2024-04-21 22:10:42\\\"\\n}\\n{\\n        \\\"user\\\": \\\"premiumplatinum\\\",\\n        \\\"content\\\": \\\"s is stupid\\\",\\n        \\\"url\\\": \\\"https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/\\\",\\n        \\\"context\\\": \\\"21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist\\\",\\n        \\\"score\\\": 131,\\n        \\\"type\\\": \\\"post\\\",\\n        \\\"id\\\": \\\"1c9itat\\\",\\n        \\\"datetime\\\": \\\"2024-04-21 22:10:42\\\"\\n}\\n'''\\n\\n# process the kafka messages to individual JSON objects\\njson_objects = json_data.replace('}\\\\n{', '},\\\\n{').strip()\\njson_objects = re.sub(\\\" +\\\", \\\" \\\",json_objects)   \\njson_objects = '[' + json_objects + ']'\\n\\n# convert JSON string to a list of dicts\\njson_list = json.loads(json_objects)\\n\\n# convert list of dictionaries into list of tuples containing only the values\\nvalues = [tuple(message.values()) for message in json_list]\\n\\n# create the SQL Query\\nquery = f'''\\nINSERT INTO {table_name} (user, content, url, context, score, type, id, datetime)\\nVALUES \\n'''\\n\\nfor value in values:\\n    query += str(value) + ',\\\\n'\\n\\n# remove the last 2 character ,\\\\n and change it to ; for the query\\nquery = query[:-2] + ';'\\n\\n# pass the query as a parameter downstream\\nprint(\\\"#setValue(query=%s)\\\" % query)\",\"resourceList\":[]}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "persist_to_postgre"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "query" : {
      "prop" : "query",
      "direct" : "OUT",
      "type" : "VARCHAR",
      "value" : ""
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240429"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "2027"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13426451158240"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240429172855"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "747"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240428"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "es_filtered_data_persistence_subprocess"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13426477386080"
    }
  },
  "taskAppId" : "747_2027",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"query\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-747][TI-2027] - [INFO] 2024-04-29 17:28:55.040 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-747][TI-2027] - [INFO] 2024-04-29 17:28:55.040 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-747][TI-2027] - [INFO] 2024-04-29 17:28:55.040 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-747][TI-2027] - [INFO] 2024-04-29 17:28:55.063 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-747][TI-2027] - [INFO] 2024-04-29 17:28:55.063 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-747][TI-2027] - [INFO] 2024-04-29 17:28:55.065 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_7/747/2027 check successfully
[WI-747][TI-2027] - [INFO] 2024-04-29 17:28:55.065 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.python.PythonTaskChannel successfully
[WI-747][TI-2027] - [INFO] 2024-04-29 17:28:55.065 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-747][TI-2027] - [INFO] 2024-04-29 17:28:55.066 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-747][TI-2027] - [INFO] 2024-04-29 17:28:55.068 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: PYTHON create successfully
[WI-747][TI-2027] - [INFO] 2024-04-29 17:28:55.069 +0800 o.a.d.p.t.p.PythonTask:[75] - Initialize python task params {
  "localParams" : [ {
    "prop" : "query",
    "direct" : "OUT",
    "type" : "VARCHAR",
    "value" : ""
  } ],
  "varPool" : null,
  "rawScript" : "import re\n\n# define the table to send the data to\ntable_name = \"filtered_data_persistence\"\n\n# Provided JSON data as strings\njson_data = ''' \n{\n  \"user\": \"premiumplatinum\",\n  \"content\": \"singapore is stupid\",\n  \"url\": \"https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/\",\n  \"context\": \"21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist\",\n  \"score\": 131,\n  \"type\": \"post\",\n  \"id\": \"1c9itat\",\n  \"datetime\": \"2024-04-21 22:10:42\"\n}\n{\n        \"user\": \"premiumplatinum\",\n        \"content\": \"s is stupid\",\n        \"url\": \"https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/\",\n        \"context\": \"21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist\",\n        \"score\": 131,\n        \"type\": \"post\",\n        \"id\": \"1c9itat\",\n        \"datetime\": \"2024-04-21 22:10:42\"\n}\n'''\n\n# process the kafka messages to individual JSON objects\njson_objects = json_data.replace('}\\n{', '},\\n{').strip()\njson_objects = re.sub(\" +\", \" \",json_objects)   \njson_objects = '[' + json_objects + ']'\n\n# convert JSON string to a list of dicts\njson_list = json.loads(json_objects)\n\n# convert list of dictionaries into list of tuples containing only the values\nvalues = [tuple(message.values()) for message in json_list]\n\n# create the SQL Query\nquery = f'''\nINSERT INTO {table_name} (user, content, url, context, score, type, id, datetime)\nVALUES \n'''\n\nfor value in values:\n    query += str(value) + ',\\n'\n\n# remove the last 2 character ,\\n and change it to ; for the query\nquery = query[:-2] + ';'\n\n# pass the query as a parameter downstream\nprint(\"#setValue(query=%s)\" % query)",
  "resourceList" : [ ]
}
[WI-747][TI-2027] - [INFO] 2024-04-29 17:28:55.070 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-747][TI-2027] - [INFO] 2024-04-29 17:28:55.070 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"query","direct":"OUT","type":"VARCHAR","value":""}] successfully
[WI-747][TI-2027] - [INFO] 2024-04-29 17:28:55.070 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-747][TI-2027] - [INFO] 2024-04-29 17:28:55.070 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-747][TI-2027] - [INFO] 2024-04-29 17:28:55.070 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-747][TI-2027] - [INFO] 2024-04-29 17:28:55.071 +0800 o.a.d.p.t.p.PythonTask:[165] - raw python script : import re

# define the table to send the data to
table_name = "filtered_data_persistence"

# Provided JSON data as strings
json_data = ''' 
{
  "user": "premiumplatinum",
  "content": "singapore is stupid",
  "url": "https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/",
  "context": "21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist",
  "score": 131,
  "type": "post",
  "id": "1c9itat",
  "datetime": "2024-04-21 22:10:42"
}
{
        "user": "premiumplatinum",
        "content": "s is stupid",
        "url": "https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/",
        "context": "21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist",
        "score": 131,
        "type": "post",
        "id": "1c9itat",
        "datetime": "2024-04-21 22:10:42"
}
'''

# process the kafka messages to individual JSON objects
json_objects = json_data.replace('}\n{', '},\n{').strip()
json_objects = re.sub(" +", " ",json_objects)   
json_objects = '[' + json_objects + ']'

# convert JSON string to a list of dicts
json_list = json.loads(json_objects)

# convert list of dictionaries into list of tuples containing only the values
values = [tuple(message.values()) for message in json_list]

# create the SQL Query
query = f'''
INSERT INTO {table_name} (user, content, url, context, score, type, id, datetime)
VALUES 
'''

for value in values:
    query += str(value) + ',\n'

# remove the last 2 character ,\n and change it to ; for the query
query = query[:-2] + ';'

# pass the query as a parameter downstream
print("#setValue(query=%s)" % query)
[WI-747][TI-2027] - [INFO] 2024-04-29 17:28:55.072 +0800 o.a.d.p.t.p.PythonTask:[131] - tenantCode :default, task dir:/tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_7/747/2027
[WI-747][TI-2027] - [INFO] 2024-04-29 17:28:55.072 +0800 o.a.d.p.t.p.PythonTask:[134] - generate python script file:/tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_7/747/2027/py_747_2027.py
[WI-747][TI-2027] - [INFO] 2024-04-29 17:28:55.073 +0800 o.a.d.p.t.p.PythonTask:[141] - #-*- encoding=utf8 -*-

import re

# define the table to send the data to
table_name = "filtered_data_persistence"

# Provided JSON data as strings
json_data = ''' 
{
  "user": "premiumplatinum",
  "content": "singapore is stupid",
  "url": "https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/",
  "context": "21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist",
  "score": 131,
  "type": "post",
  "id": "1c9itat",
  "datetime": "2024-04-21 22:10:42"
}
{
        "user": "premiumplatinum",
        "content": "s is stupid",
        "url": "https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/",
        "context": "21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist",
        "score": 131,
        "type": "post",
        "id": "1c9itat",
        "datetime": "2024-04-21 22:10:42"
}
'''

# process the kafka messages to individual JSON objects
json_objects = json_data.replace('}\n{', '},\n{').strip()
json_objects = re.sub(" +", " ",json_objects)   
json_objects = '[' + json_objects + ']'

# convert JSON string to a list of dicts
json_list = json.loads(json_objects)

# convert list of dictionaries into list of tuples containing only the values
values = [tuple(message.values()) for message in json_list]

# create the SQL Query
query = f'''
INSERT INTO {table_name} (user, content, url, context, score, type, id, datetime)
VALUES 
'''

for value in values:
    query += str(value) + ',\n'

# remove the last 2 character ,\n and change it to ; for the query
query = query[:-2] + ';'

# pass the query as a parameter downstream
print("#setValue(query=%s)" % query)
[WI-747][TI-2027] - [INFO] 2024-04-29 17:28:55.075 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-747][TI-2027] - [INFO] 2024-04-29 17:28:55.075 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-747][TI-2027] - [INFO] 2024-04-29 17:28:55.076 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export PYTHON_LAUNCHER=/bin/python3.11
${PYTHON_LAUNCHER} /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_7/747/2027/py_747_2027.py
[WI-747][TI-2027] - [INFO] 2024-04-29 17:28:55.077 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-747][TI-2027] - [INFO] 2024-04-29 17:28:55.077 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_7/747/2027/747_2027.sh
[WI-747][TI-2027] - [INFO] 2024-04-29 17:28:55.087 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 289
[WI-0][TI-2027] - [INFO] 2024-04-29 17:28:55.921 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=2027, success=true)
[WI-0][TI-2027] - [INFO] 2024-04-29 17:28:55.957 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=2027)
[WI-0][TI-0] - [INFO] 2024-04-29 17:28:56.089 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
	Traceback (most recent call last):
	  File "/tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_7/747/2027/py_747_2027.py", line 38, in <module>
	    json_list = json.loads(json_objects)
	                ^^^^
	NameError: name 'json' is not defined
[WI-747][TI-2027] - [INFO] 2024-04-29 17:28:56.091 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_7/747/2027, processId:289 ,exitStatusCode:1 ,processWaitForStatus:true ,processExitValue:1
[WI-747][TI-2027] - [INFO] 2024-04-29 17:28:56.091 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-747][TI-2027] - [INFO] 2024-04-29 17:28:56.092 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-747][TI-2027] - [INFO] 2024-04-29 17:28:56.092 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-747][TI-2027] - [INFO] 2024-04-29 17:28:56.093 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-747][TI-2027] - [INFO] 2024-04-29 17:28:56.104 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: FAILURE to master : 172.18.1.1:1234
[WI-747][TI-2027] - [INFO] 2024-04-29 17:28:56.104 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-747][TI-2027] - [INFO] 2024-04-29 17:28:56.104 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_7/747/2027
[WI-747][TI-2027] - [INFO] 2024-04-29 17:28:56.114 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_7/747/2027
[WI-747][TI-2027] - [INFO] 2024-04-29 17:28:56.118 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-0] - [INFO] 2024-04-29 17:28:56.333 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7135135135135134 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-2027] - [INFO] 2024-04-29 17:28:56.928 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=2027, success=true)
[WI-0][TI-0] - [INFO] 2024-04-29 17:28:57.345 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7428571428571428 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-29 17:28:58.347 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.717741935483871 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-29 17:29:18.819 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7430167597765363 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-29 17:29:21.866 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7191011235955056 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-29 17:29:56.142 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=2028, taskName=consume_filtered_data, firstSubmitTime=1714382996131, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.10:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13426477386080, processDefineVersion=8, appIds=null, processInstanceId=748, scheduleTime=0, globalParams=null, executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[],"rawScript":"# /bin/kafka-console-consumer.sh \\\n#     --bootstrap-server kafka:9092 \\\n#     --topic reddit_post_filtered \\\n#     --max-messages 10 \\\n#     --from-beginning \\\n#     --group filtered_data_consumer \n#     --timeout-ms 15000","resourceList":[]}, environmentConfig=export JAVA_HOME=/opt/java/openjdk, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='consume_filtered_data'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='748'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240429'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240428'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='2028'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='es_filtered_data_persistence_subprocess'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13433255983872'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13426477386080'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240429172956'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=null, dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-748][TI-2028] - [INFO] 2024-04-29 17:29:56.144 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: consume_filtered_data to wait queue success
[WI-748][TI-2028] - [INFO] 2024-04-29 17:29:56.144 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2028] - [INFO] 2024-04-29 17:29:56.147 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-748][TI-2028] - [INFO] 2024-04-29 17:29:56.147 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2028] - [INFO] 2024-04-29 17:29:56.147 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-748][TI-2028] - [INFO] 2024-04-29 17:29:56.147 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1714382996147
[WI-748][TI-2028] - [INFO] 2024-04-29 17:29:56.147 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 748_2028
[WI-748][TI-2028] - [INFO] 2024-04-29 17:29:56.147 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 2028,
  "taskName" : "consume_filtered_data",
  "firstSubmitTime" : 1714382996131,
  "startTime" : 1714382996147,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.10:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240429/13426477386080/8/748/2028.log",
  "processId" : 0,
  "processDefineCode" : 13426477386080,
  "processDefineVersion" : 8,
  "processInstanceId" : 748,
  "scheduleTime" : 0,
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[],\"rawScript\":\"# /bin/kafka-console-consumer.sh \\\\\\n#     --bootstrap-server kafka:9092 \\\\\\n#     --topic reddit_post_filtered \\\\\\n#     --max-messages 10 \\\\\\n#     --from-beginning \\\\\\n#     --group filtered_data_consumer \\n#     --timeout-ms 15000\",\"resourceList\":[]}",
  "environmentConfig" : "export JAVA_HOME=/opt/java/openjdk",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "consume_filtered_data"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "748"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240429"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240428"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "2028"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "es_filtered_data_persistence_subprocess"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13433255983872"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13426477386080"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240429172956"
    }
  },
  "taskAppId" : "748_2028",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-748][TI-2028] - [INFO] 2024-04-29 17:29:56.148 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2028] - [INFO] 2024-04-29 17:29:56.148 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-748][TI-2028] - [INFO] 2024-04-29 17:29:56.148 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2028] - [INFO] 2024-04-29 17:29:56.152 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-748][TI-2028] - [INFO] 2024-04-29 17:29:56.152 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-748][TI-2028] - [INFO] 2024-04-29 17:29:56.153 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_8/748/2028 check successfully
[WI-748][TI-2028] - [INFO] 2024-04-29 17:29:56.153 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-748][TI-2028] - [INFO] 2024-04-29 17:29:56.153 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-748][TI-2028] - [INFO] 2024-04-29 17:29:56.154 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-748][TI-2028] - [INFO] 2024-04-29 17:29:56.154 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-748][TI-2028] - [INFO] 2024-04-29 17:29:56.154 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ ],
  "varPool" : null,
  "rawScript" : "# /bin/kafka-console-consumer.sh \\\n#     --bootstrap-server kafka:9092 \\\n#     --topic reddit_post_filtered \\\n#     --max-messages 10 \\\n#     --from-beginning \\\n#     --group filtered_data_consumer \n#     --timeout-ms 15000",
  "resourceList" : [ ]
}
[WI-748][TI-2028] - [INFO] 2024-04-29 17:29:56.154 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-748][TI-2028] - [INFO] 2024-04-29 17:29:56.154 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: null successfully
[WI-748][TI-2028] - [INFO] 2024-04-29 17:29:56.155 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2028] - [INFO] 2024-04-29 17:29:56.155 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-748][TI-2028] - [INFO] 2024-04-29 17:29:56.155 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2028] - [INFO] 2024-04-29 17:29:56.155 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-748][TI-2028] - [INFO] 2024-04-29 17:29:56.155 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-748][TI-2028] - [INFO] 2024-04-29 17:29:56.155 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export JAVA_HOME=/opt/java/openjdk
# /bin/kafka-console-consumer.sh \
#     --bootstrap-server kafka:9092 \
#     --topic reddit_post_filtered \
#     --max-messages 10 \
#     --from-beginning \
#     --group filtered_data_consumer 
#     --timeout-ms 15000
[WI-748][TI-2028] - [INFO] 2024-04-29 17:29:56.155 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-748][TI-2028] - [INFO] 2024-04-29 17:29:56.155 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_8/748/2028/748_2028.sh
[WI-748][TI-2028] - [INFO] 2024-04-29 17:29:56.172 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 311
[WI-0][TI-2028] - [INFO] 2024-04-29 17:29:56.883 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=2028, success=true)
[WI-0][TI-2028] - [INFO] 2024-04-29 17:29:56.891 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=2028)
[WI-0][TI-0] - [INFO] 2024-04-29 17:29:57.180 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
[WI-748][TI-2028] - [INFO] 2024-04-29 17:29:57.186 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_8/748/2028, processId:311 ,exitStatusCode:0 ,processWaitForStatus:true ,processExitValue:0
[WI-748][TI-2028] - [INFO] 2024-04-29 17:29:57.187 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2028] - [INFO] 2024-04-29 17:29:57.187 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-748][TI-2028] - [INFO] 2024-04-29 17:29:57.187 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2028] - [INFO] 2024-04-29 17:29:57.187 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-748][TI-2028] - [INFO] 2024-04-29 17:29:57.196 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: SUCCESS to master : 172.18.1.1:1234
[WI-748][TI-2028] - [INFO] 2024-04-29 17:29:57.196 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-748][TI-2028] - [INFO] 2024-04-29 17:29:57.197 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_8/748/2028
[WI-748][TI-2028] - [INFO] 2024-04-29 17:29:57.197 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_8/748/2028
[WI-748][TI-2028] - [INFO] 2024-04-29 17:29:57.197 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-2028] - [INFO] 2024-04-29 17:29:57.884 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=2028, success=true)
[WI-0][TI-0] - [INFO] 2024-04-29 17:29:57.927 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=2029, taskName=persist_to_postgre, firstSubmitTime=1714382997916, startTime=0, taskType=PYTHON, workflowInstanceHost=172.18.0.10:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13426477386080, processDefineVersion=8, appIds=null, processInstanceId=748, scheduleTime=0, globalParams=null, executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[{"prop":"query","direct":"OUT","type":"VARCHAR","value":""}],"rawScript":"import re\nimport json\n\n# define the table to send the data to\ntable_name = \"filtered_data_persistence\"\n\n# Provided JSON data as strings\njson_data = ''' \n{\n  \"user\": \"premiumplatinum\",\n  \"content\": \"singapore is stupid\",\n  \"url\": \"https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/\",\n  \"context\": \"21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist\",\n  \"score\": 131,\n  \"type\": \"post\",\n  \"id\": \"1c9itat\",\n  \"datetime\": \"2024-04-21 22:10:42\"\n}\n{\n        \"user\": \"premiumplatinum\",\n        \"content\": \"s is stupid\",\n        \"url\": \"https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/\",\n        \"context\": \"21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist\",\n        \"score\": 131,\n        \"type\": \"post\",\n        \"id\": \"1c9itat\",\n        \"datetime\": \"2024-04-21 22:10:42\"\n}\n'''\n\n# process the kafka messages to individual JSON objects\njson_objects = json_data.replace('}\\n{', '},\\n{').strip()\njson_objects = re.sub(\" +\", \" \",json_objects)   \njson_objects = '[' + json_objects + ']'\n\n# convert JSON string to a list of dicts\njson_list = json.loads(json_objects)\n\n# convert list of dictionaries into list of tuples containing only the values\nvalues = [tuple(message.values()) for message in json_list]\n\n# create the SQL Query\nquery = f'''\nINSERT INTO {table_name} (user, content, url, context, score, type, id, datetime)\nVALUES \n'''\n\nfor value in values:\n    query += str(value) + ',\\n'\n\n# remove the last 2 character ,\\n and change it to ; for the query\nquery = query[:-2] + ';'\n\n# pass the query as a parameter downstream\nprint(\"#setValue(query=%s)\" % query)","resourceList":[]}, environmentConfig=export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='persist_to_postgre'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='748'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240429'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240428'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='2029'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='es_filtered_data_persistence_subprocess'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13426451158240'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13426477386080'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240429172957'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=null, dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-748][TI-2029] - [INFO] 2024-04-29 17:29:57.931 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: persist_to_postgre to wait queue success
[WI-748][TI-2029] - [INFO] 2024-04-29 17:29:57.931 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2029] - [INFO] 2024-04-29 17:29:57.933 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-748][TI-2029] - [INFO] 2024-04-29 17:29:57.933 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2029] - [INFO] 2024-04-29 17:29:57.933 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-748][TI-2029] - [INFO] 2024-04-29 17:29:57.933 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1714382997933
[WI-748][TI-2029] - [INFO] 2024-04-29 17:29:57.933 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 748_2029
[WI-748][TI-2029] - [INFO] 2024-04-29 17:29:57.934 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 2029,
  "taskName" : "persist_to_postgre",
  "firstSubmitTime" : 1714382997916,
  "startTime" : 1714382997933,
  "taskType" : "PYTHON",
  "workflowInstanceHost" : "172.18.0.10:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240429/13426477386080/8/748/2029.log",
  "processId" : 0,
  "processDefineCode" : 13426477386080,
  "processDefineVersion" : 8,
  "processInstanceId" : 748,
  "scheduleTime" : 0,
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[{\"prop\":\"query\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"\"}],\"rawScript\":\"import re\\nimport json\\n\\n# define the table to send the data to\\ntable_name = \\\"filtered_data_persistence\\\"\\n\\n# Provided JSON data as strings\\njson_data = ''' \\n{\\n  \\\"user\\\": \\\"premiumplatinum\\\",\\n  \\\"content\\\": \\\"singapore is stupid\\\",\\n  \\\"url\\\": \\\"https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/\\\",\\n  \\\"context\\\": \\\"21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist\\\",\\n  \\\"score\\\": 131,\\n  \\\"type\\\": \\\"post\\\",\\n  \\\"id\\\": \\\"1c9itat\\\",\\n  \\\"datetime\\\": \\\"2024-04-21 22:10:42\\\"\\n}\\n{\\n        \\\"user\\\": \\\"premiumplatinum\\\",\\n        \\\"content\\\": \\\"s is stupid\\\",\\n        \\\"url\\\": \\\"https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/\\\",\\n        \\\"context\\\": \\\"21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist\\\",\\n        \\\"score\\\": 131,\\n        \\\"type\\\": \\\"post\\\",\\n        \\\"id\\\": \\\"1c9itat\\\",\\n        \\\"datetime\\\": \\\"2024-04-21 22:10:42\\\"\\n}\\n'''\\n\\n# process the kafka messages to individual JSON objects\\njson_objects = json_data.replace('}\\\\n{', '},\\\\n{').strip()\\njson_objects = re.sub(\\\" +\\\", \\\" \\\",json_objects)   \\njson_objects = '[' + json_objects + ']'\\n\\n# convert JSON string to a list of dicts\\njson_list = json.loads(json_objects)\\n\\n# convert list of dictionaries into list of tuples containing only the values\\nvalues = [tuple(message.values()) for message in json_list]\\n\\n# create the SQL Query\\nquery = f'''\\nINSERT INTO {table_name} (user, content, url, context, score, type, id, datetime)\\nVALUES \\n'''\\n\\nfor value in values:\\n    query += str(value) + ',\\\\n'\\n\\n# remove the last 2 character ,\\\\n and change it to ; for the query\\nquery = query[:-2] + ';'\\n\\n# pass the query as a parameter downstream\\nprint(\\\"#setValue(query=%s)\\\" % query)\",\"resourceList\":[]}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "persist_to_postgre"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "748"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240429"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240428"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "2029"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "es_filtered_data_persistence_subprocess"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13426451158240"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13426477386080"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240429172957"
    }
  },
  "taskAppId" : "748_2029",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-748][TI-2029] - [INFO] 2024-04-29 17:29:57.936 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2029] - [INFO] 2024-04-29 17:29:57.937 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-748][TI-2029] - [INFO] 2024-04-29 17:29:57.937 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2029] - [INFO] 2024-04-29 17:29:57.947 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-748][TI-2029] - [INFO] 2024-04-29 17:29:57.948 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-748][TI-2029] - [INFO] 2024-04-29 17:29:57.950 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_8/748/2029 check successfully
[WI-748][TI-2029] - [INFO] 2024-04-29 17:29:57.951 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.python.PythonTaskChannel successfully
[WI-748][TI-2029] - [INFO] 2024-04-29 17:29:57.951 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-748][TI-2029] - [INFO] 2024-04-29 17:29:57.951 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-748][TI-2029] - [INFO] 2024-04-29 17:29:57.951 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: PYTHON create successfully
[WI-748][TI-2029] - [INFO] 2024-04-29 17:29:57.952 +0800 o.a.d.p.t.p.PythonTask:[75] - Initialize python task params {
  "localParams" : [ {
    "prop" : "query",
    "direct" : "OUT",
    "type" : "VARCHAR",
    "value" : ""
  } ],
  "varPool" : null,
  "rawScript" : "import re\nimport json\n\n# define the table to send the data to\ntable_name = \"filtered_data_persistence\"\n\n# Provided JSON data as strings\njson_data = ''' \n{\n  \"user\": \"premiumplatinum\",\n  \"content\": \"singapore is stupid\",\n  \"url\": \"https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/\",\n  \"context\": \"21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist\",\n  \"score\": 131,\n  \"type\": \"post\",\n  \"id\": \"1c9itat\",\n  \"datetime\": \"2024-04-21 22:10:42\"\n}\n{\n        \"user\": \"premiumplatinum\",\n        \"content\": \"s is stupid\",\n        \"url\": \"https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/\",\n        \"context\": \"21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist\",\n        \"score\": 131,\n        \"type\": \"post\",\n        \"id\": \"1c9itat\",\n        \"datetime\": \"2024-04-21 22:10:42\"\n}\n'''\n\n# process the kafka messages to individual JSON objects\njson_objects = json_data.replace('}\\n{', '},\\n{').strip()\njson_objects = re.sub(\" +\", \" \",json_objects)   \njson_objects = '[' + json_objects + ']'\n\n# convert JSON string to a list of dicts\njson_list = json.loads(json_objects)\n\n# convert list of dictionaries into list of tuples containing only the values\nvalues = [tuple(message.values()) for message in json_list]\n\n# create the SQL Query\nquery = f'''\nINSERT INTO {table_name} (user, content, url, context, score, type, id, datetime)\nVALUES \n'''\n\nfor value in values:\n    query += str(value) + ',\\n'\n\n# remove the last 2 character ,\\n and change it to ; for the query\nquery = query[:-2] + ';'\n\n# pass the query as a parameter downstream\nprint(\"#setValue(query=%s)\" % query)",
  "resourceList" : [ ]
}
[WI-748][TI-2029] - [INFO] 2024-04-29 17:29:57.953 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-748][TI-2029] - [INFO] 2024-04-29 17:29:57.953 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: null successfully
[WI-748][TI-2029] - [INFO] 2024-04-29 17:29:57.953 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2029] - [INFO] 2024-04-29 17:29:57.953 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-748][TI-2029] - [INFO] 2024-04-29 17:29:57.953 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2029] - [INFO] 2024-04-29 17:29:57.954 +0800 o.a.d.p.t.p.PythonTask:[165] - raw python script : import re
import json

# define the table to send the data to
table_name = "filtered_data_persistence"

# Provided JSON data as strings
json_data = ''' 
{
  "user": "premiumplatinum",
  "content": "singapore is stupid",
  "url": "https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/",
  "context": "21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist",
  "score": 131,
  "type": "post",
  "id": "1c9itat",
  "datetime": "2024-04-21 22:10:42"
}
{
        "user": "premiumplatinum",
        "content": "s is stupid",
        "url": "https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/",
        "context": "21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist",
        "score": 131,
        "type": "post",
        "id": "1c9itat",
        "datetime": "2024-04-21 22:10:42"
}
'''

# process the kafka messages to individual JSON objects
json_objects = json_data.replace('}\n{', '},\n{').strip()
json_objects = re.sub(" +", " ",json_objects)   
json_objects = '[' + json_objects + ']'

# convert JSON string to a list of dicts
json_list = json.loads(json_objects)

# convert list of dictionaries into list of tuples containing only the values
values = [tuple(message.values()) for message in json_list]

# create the SQL Query
query = f'''
INSERT INTO {table_name} (user, content, url, context, score, type, id, datetime)
VALUES 
'''

for value in values:
    query += str(value) + ',\n'

# remove the last 2 character ,\n and change it to ; for the query
query = query[:-2] + ';'

# pass the query as a parameter downstream
print("#setValue(query=%s)" % query)
[WI-748][TI-2029] - [INFO] 2024-04-29 17:29:57.954 +0800 o.a.d.p.t.p.PythonTask:[131] - tenantCode :default, task dir:/tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_8/748/2029
[WI-748][TI-2029] - [INFO] 2024-04-29 17:29:57.954 +0800 o.a.d.p.t.p.PythonTask:[134] - generate python script file:/tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_8/748/2029/py_748_2029.py
[WI-748][TI-2029] - [INFO] 2024-04-29 17:29:57.954 +0800 o.a.d.p.t.p.PythonTask:[141] - #-*- encoding=utf8 -*-

import re
import json

# define the table to send the data to
table_name = "filtered_data_persistence"

# Provided JSON data as strings
json_data = ''' 
{
  "user": "premiumplatinum",
  "content": "singapore is stupid",
  "url": "https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/",
  "context": "21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist",
  "score": 131,
  "type": "post",
  "id": "1c9itat",
  "datetime": "2024-04-21 22:10:42"
}
{
        "user": "premiumplatinum",
        "content": "s is stupid",
        "url": "https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/",
        "context": "21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist",
        "score": 131,
        "type": "post",
        "id": "1c9itat",
        "datetime": "2024-04-21 22:10:42"
}
'''

# process the kafka messages to individual JSON objects
json_objects = json_data.replace('}\n{', '},\n{').strip()
json_objects = re.sub(" +", " ",json_objects)   
json_objects = '[' + json_objects + ']'

# convert JSON string to a list of dicts
json_list = json.loads(json_objects)

# convert list of dictionaries into list of tuples containing only the values
values = [tuple(message.values()) for message in json_list]

# create the SQL Query
query = f'''
INSERT INTO {table_name} (user, content, url, context, score, type, id, datetime)
VALUES 
'''

for value in values:
    query += str(value) + ',\n'

# remove the last 2 character ,\n and change it to ; for the query
query = query[:-2] + ';'

# pass the query as a parameter downstream
print("#setValue(query=%s)" % query)
[WI-748][TI-2029] - [INFO] 2024-04-29 17:29:57.955 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-748][TI-2029] - [INFO] 2024-04-29 17:29:57.955 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-748][TI-2029] - [INFO] 2024-04-29 17:29:57.955 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export PYTHON_LAUNCHER=/bin/python3.11
${PYTHON_LAUNCHER} /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_8/748/2029/py_748_2029.py
[WI-748][TI-2029] - [INFO] 2024-04-29 17:29:57.956 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-748][TI-2029] - [INFO] 2024-04-29 17:29:57.956 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_8/748/2029/748_2029.sh
[WI-748][TI-2029] - [INFO] 2024-04-29 17:29:57.961 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 322
[WI-0][TI-2029] - [INFO] 2024-04-29 17:29:58.909 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=2029, success=true)
[WI-0][TI-2029] - [INFO] 2024-04-29 17:29:58.951 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=2029)
[WI-0][TI-0] - [INFO] 2024-04-29 17:29:58.967 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
	#setValue(query=
	INSERT INTO filtered_data_persistence (user, content, url, context, score, type, id, datetime)
	VALUES 
	('premiumplatinum', 'singapore is stupid', 'https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/', '21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist', 131, 'post', '1c9itat', '2024-04-21 22:10:42'),
	('premiumplatinum', 's is stupid', 'https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/', '21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist', 131, 'post', '1c9itat', '2024-04-21 22:10:42');)
[WI-748][TI-2029] - [INFO] 2024-04-29 17:29:58.973 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_8/748/2029, processId:322 ,exitStatusCode:0 ,processWaitForStatus:true ,processExitValue:0
[WI-748][TI-2029] - [INFO] 2024-04-29 17:29:58.974 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2029] - [INFO] 2024-04-29 17:29:58.974 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-748][TI-2029] - [INFO] 2024-04-29 17:29:58.976 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2029] - [INFO] 2024-04-29 17:29:58.977 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-748][TI-2029] - [INFO] 2024-04-29 17:29:58.983 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: SUCCESS to master : 172.18.1.1:1234
[WI-748][TI-2029] - [INFO] 2024-04-29 17:29:58.983 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-748][TI-2029] - [INFO] 2024-04-29 17:29:58.984 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_8/748/2029
[WI-748][TI-2029] - [INFO] 2024-04-29 17:29:58.984 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_8/748/2029
[WI-748][TI-2029] - [INFO] 2024-04-29 17:29:58.985 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-2029] - [INFO] 2024-04-29 17:29:59.909 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=2029, success=true)
[WI-0][TI-0] - [INFO] 2024-04-29 17:30:00.057 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8337950138504155 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-29 17:30:00.179 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=2030, taskName=Persist in postgresql, firstSubmitTime=1714383000060, startTime=0, taskType=SQL, workflowInstanceHost=172.18.0.10:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13426477386080, processDefineVersion=8, appIds=null, processInstanceId=748, scheduleTime=0, globalParams=null, executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[],"resourceList":[],"type":"POSTGRESQL","datasource":1,"sql":"${query}","sqlType":"0","preStatements":[],"postStatements":[],"displayRows":10}, environmentConfig=export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='Persist in postgresql'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, query=Property{prop='query', direct=IN, type=VARCHAR, value=''}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240429'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='2030'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13427698681952'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240429173000'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='748'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240428'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='es_filtered_data_persistence_subprocess'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13426477386080'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=org.apache.dolphinscheduler.plugin.task.api.parameters.resource.ResourceParametersHelper@652d951a, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"query","direct":"IN","type":"VARCHAR","value":""}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.184 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.187 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.188 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.188 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.184 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: Persist in postgresql to wait queue success
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.188 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1714383000188
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.189 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 748_2030
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.202 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 2030,
  "taskName" : "Persist in postgresql",
  "firstSubmitTime" : 1714383000060,
  "startTime" : 1714383000188,
  "taskType" : "SQL",
  "workflowInstanceHost" : "172.18.0.10:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240429/13426477386080/8/748/2030.log",
  "processId" : 0,
  "processDefineCode" : 13426477386080,
  "processDefineVersion" : 8,
  "processInstanceId" : 748,
  "scheduleTime" : 0,
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[],\"resourceList\":[],\"type\":\"POSTGRESQL\",\"datasource\":1,\"sql\":\"${query}\",\"sqlType\":\"0\",\"preStatements\":[],\"postStatements\":[],\"displayRows\":10}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "Persist in postgresql"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "query" : {
      "prop" : "query",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : ""
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240429"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "2030"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13427698681952"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240429173000"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "748"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240428"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "es_filtered_data_persistence_subprocess"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13426477386080"
    }
  },
  "taskAppId" : "748_2030",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "resourceParametersHelper" : {
    "resourceMap" : {
      "DATASOURCE" : {
        "1" : {
          "resourceType" : "DATASOURCE",
          "type" : "POSTGRESQL",
          "connectionParams" : "{\"user\":\"root\",\"password\":\"******\",\"address\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432\",\"database\":\"persistence\",\"jdbcUrl\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432/persistence\",\"driverClassName\":\"org.postgresql.Driver\",\"validationQuery\":\"select version()\"}",
          "DATASOURCE" : null
        }
      }
    }
  },
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"query\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.205 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.206 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.206 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.212 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.214 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.214 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_8/748/2030 check successfully
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.215 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.sql.SqlTaskChannel successfully
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.228 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.229 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.237 +0800 o.a.d.p.t.s.SqlTask:[99] - Initialize sql task parameter {
  "localParams" : [ ],
  "varPool" : null,
  "type" : "POSTGRESQL",
  "datasource" : 1,
  "sql" : "${query}",
  "sqlType" : 0,
  "sendEmail" : null,
  "displayRows" : 10,
  "udfs" : null,
  "showType" : null,
  "connParams" : null,
  "preStatements" : [ ],
  "postStatements" : [ ],
  "groupId" : 0,
  "title" : null,
  "limit" : 0
}
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.241 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SQL create successfully
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.241 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.242 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"query","direct":"IN","type":"VARCHAR","value":""}] successfully
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.242 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.242 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.242 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.242 +0800 o.a.d.p.t.s.SqlTask:[119] - Full sql parameters: SqlParameters{type='POSTGRESQL', datasource=1, sql='${query}', sqlType=0, sendEmail=null, displayRows=10, limit=0, udfs='null', showType='null', connParams='null', groupId='0', title='null', preStatements=[], postStatements=[]}
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.242 +0800 o.a.d.p.t.s.SqlTask:[120] - sql type : POSTGRESQL, datasource : 1, sql : ${query} , localParams : [],udfs : null,showType : null,connParams : null,varPool : [Property{prop='query', direct=IN, type=VARCHAR, value=''}] ,query max result limit  0
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.271 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: HANA
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.272 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: HANA
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.273 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: SQLSERVER
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.274 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: SQLSERVER
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.277 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: SAGEMAKER
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.278 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: SAGEMAKER
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.280 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: DATABEND
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.280 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: DATABEND
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.333 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: AZURESQL
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.333 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: AZURESQL
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.337 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: HIVE
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.338 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: HIVE
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.342 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: DORIS
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.343 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: DORIS
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.344 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: POSTGRESQL
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.345 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: POSTGRESQL
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.347 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: MYSQL
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.347 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: MYSQL
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.349 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: REDSHIFT
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.350 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: REDSHIFT
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.357 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: SNOWFLAKE
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.357 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: SNOWFLAKE
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.360 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: STARROCKS
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.361 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: STARROCKS
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.369 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: SSH
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.369 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: SSH
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.381 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: ATHENA
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.383 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: ATHENA
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.398 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: PRESTO
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.398 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: PRESTO
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.406 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: OCEANBASE
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.407 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: OCEANBASE
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.469 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: ORACLE
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.469 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: ORACLE
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.472 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: CLICKHOUSE
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.473 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: CLICKHOUSE
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.483 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: VERTICA
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.486 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: VERTICA
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.491 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: KYUUBI
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.491 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: KYUUBI
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.499 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: DB2
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.499 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: DB2
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.503 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: TRINO
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.503 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: TRINO
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.509 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: SPARK
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.509 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: SPARK
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.513 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: DAMENG
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.513 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: DAMENG
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.516 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: ZEPPELIN
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.516 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: ZEPPELIN
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.831 +0800 o.a.d.p.t.a.AbstractTask:[206] - setSqlParamsMap: Property with paramName: query put in sqlParamsMap of content ${query} successfully.
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.834 +0800 o.a.d.p.t.s.SqlTask:[410] - after replace sql , preparing : ?
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.835 +0800 o.a.d.p.t.s.SqlTask:[420] - Sql Params are replaced sql , parameters:(VARCHAR)
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.839 +0800 o.a.d.p.t.s.SqlTask:[489] - can't find udf function resource
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.903 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[49] - Registering datasource plugin: hive
[WI-0][TI-2030] - [INFO] 2024-04-29 17:30:00.905 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=2030, success=true)
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.912 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[57] - Registered datasource plugin: hive
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.916 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[49] - Registering datasource plugin: vertica
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.922 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[57] - Registered datasource plugin: vertica
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.922 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[49] - Registering datasource plugin: doris
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.923 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[57] - Registered datasource plugin: doris
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.923 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[49] - Registering datasource plugin: ssh
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.924 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[57] - Registered datasource plugin: ssh
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.924 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[49] - Registering datasource plugin: databend
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.924 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[57] - Registered datasource plugin: databend
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.924 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[49] - Registering datasource plugin: sqlserver
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.924 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[57] - Registered datasource plugin: sqlserver
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.924 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[49] - Registering datasource plugin: postgresql
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.925 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[57] - Registered datasource plugin: postgresql
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.926 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[49] - Registering datasource plugin: redshift
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.927 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[57] - Registered datasource plugin: redshift
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.928 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[49] - Registering datasource plugin: spark
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.930 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[57] - Registered datasource plugin: spark
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.930 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[49] - Registering datasource plugin: oceanbase
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.931 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[57] - Registered datasource plugin: oceanbase
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.931 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[49] - Registering datasource plugin: starrocks
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.933 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[57] - Registered datasource plugin: starrocks
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.934 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[49] - Registering datasource plugin: mysql
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.934 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[57] - Registered datasource plugin: mysql
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.934 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[49] - Registering datasource plugin: hana
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.935 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[57] - Registered datasource plugin: hana
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.935 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[49] - Registering datasource plugin: sagemaker
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.936 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[57] - Registered datasource plugin: sagemaker
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.936 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[49] - Registering datasource plugin: dameng
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.937 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[57] - Registered datasource plugin: dameng
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.937 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[49] - Registering datasource plugin: snowflake
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.939 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[57] - Registered datasource plugin: snowflake
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.939 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[49] - Registering datasource plugin: oracle
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.940 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[57] - Registered datasource plugin: oracle
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.940 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[49] - Registering datasource plugin: kyuubi
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.942 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[57] - Registered datasource plugin: kyuubi
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.942 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[49] - Registering datasource plugin: zeppelin
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.943 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[57] - Registered datasource plugin: zeppelin
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.944 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[49] - Registering datasource plugin: trino
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.946 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[57] - Registered datasource plugin: trino
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.946 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[49] - Registering datasource plugin: db2
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.947 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[57] - Registered datasource plugin: db2
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.948 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[49] - Registering datasource plugin: clickhouse
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.949 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[57] - Registered datasource plugin: clickhouse
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.950 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[49] - Registering datasource plugin: azuresql
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.950 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[57] - Registered datasource plugin: azuresql
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.951 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[49] - Registering datasource plugin: athena
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.952 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[57] - Registered datasource plugin: athena
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.952 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[49] - Registering datasource plugin: presto
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:00.954 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[57] - Registered datasource plugin: presto
[WI-0][TI-0] - [INFO] 2024-04-29 17:30:01.090 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.1506493506493507 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-748][TI-2030] - [WARN] 2024-04-29 17:30:02.051 +0800 n.s.c.j.SnowflakeConnectString:[136] - Connect strings must start with jdbc:snowflake://
[WI-0][TI-0] - [INFO] 2024-04-29 17:30:02.091 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.0544412607449856 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-748][TI-2030] - [ERROR] 2024-04-29 17:30:02.439 +0800 o.a.d.p.t.s.SqlTask:[217] - execute sql error: Create adhoc connection error
[WI-748][TI-2030] - [ERROR] 2024-04-29 17:30:02.449 +0800 o.a.d.p.t.s.SqlTask:[165] - sql task error
java.sql.SQLException: Create adhoc connection error
	at org.apache.dolphinscheduler.plugin.datasource.api.client.BaseAdHocDataSourceClient.getConnection(BaseAdHocDataSourceClient.java:43)
	at org.apache.dolphinscheduler.plugin.datasource.api.plugin.DataSourceClientProvider.getAdHocConnection(DataSourceClientProvider.java:97)
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.executeFuncAndSql(SqlTask.java:189)
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.handle(SqlTask.java:159)
	at org.apache.dolphinscheduler.server.worker.runner.DefaultWorkerTaskExecutor.executeTask(DefaultWorkerTaskExecutor.java:54)
	at org.apache.dolphinscheduler.server.worker.runner.WorkerTaskExecutor.run(WorkerTaskExecutor.java:175)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.postgresql.util.PSQLException: FATAL: password authentication failed for user "root"
	at org.postgresql.core.v3.ConnectionFactoryImpl.doAuthentication(ConnectionFactoryImpl.java:646)
	at org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:180)
	at org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:235)
	at org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:49)
	at org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:247)
	at org.postgresql.Driver.makeConnection(Driver.java:434)
	at org.postgresql.Driver.connect(Driver.java:291)
	at java.sql.DriverManager.getConnection(DriverManager.java:664)
	at java.sql.DriverManager.getConnection(DriverManager.java:247)
	at org.apache.dolphinscheduler.plugin.datasource.postgresql.param.PostgreSQLDataSourceProcessor.getConnection(PostgreSQLDataSourceProcessor.java:117)
	at org.apache.dolphinscheduler.plugin.datasource.api.client.BaseAdHocDataSourceClient.getConnection(BaseAdHocDataSourceClient.java:41)
	... 8 common frames omitted
[WI-748][TI-2030] - [ERROR] 2024-04-29 17:30:02.450 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[181] - Task execute failed, due to meet an exception
org.apache.dolphinscheduler.plugin.task.api.TaskException: Execute sql task failed
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.handle(SqlTask.java:166)
	at org.apache.dolphinscheduler.server.worker.runner.DefaultWorkerTaskExecutor.executeTask(DefaultWorkerTaskExecutor.java:54)
	at org.apache.dolphinscheduler.server.worker.runner.WorkerTaskExecutor.run(WorkerTaskExecutor.java:175)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.sql.SQLException: Create adhoc connection error
	at org.apache.dolphinscheduler.plugin.datasource.api.client.BaseAdHocDataSourceClient.getConnection(BaseAdHocDataSourceClient.java:43)
	at org.apache.dolphinscheduler.plugin.datasource.api.plugin.DataSourceClientProvider.getAdHocConnection(DataSourceClientProvider.java:97)
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.executeFuncAndSql(SqlTask.java:189)
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.handle(SqlTask.java:159)
	... 5 common frames omitted
Caused by: org.postgresql.util.PSQLException: FATAL: password authentication failed for user "root"
	at org.postgresql.core.v3.ConnectionFactoryImpl.doAuthentication(ConnectionFactoryImpl.java:646)
	at org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:180)
	at org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:235)
	at org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:49)
	at org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:247)
	at org.postgresql.Driver.makeConnection(Driver.java:434)
	at org.postgresql.Driver.connect(Driver.java:291)
	at java.sql.DriverManager.getConnection(DriverManager.java:664)
	at java.sql.DriverManager.getConnection(DriverManager.java:247)
	at org.apache.dolphinscheduler.plugin.datasource.postgresql.param.PostgreSQLDataSourceProcessor.getConnection(PostgreSQLDataSourceProcessor.java:117)
	at org.apache.dolphinscheduler.plugin.datasource.api.client.BaseAdHocDataSourceClient.getConnection(BaseAdHocDataSourceClient.java:41)
	... 8 common frames omitted
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:02.450 +0800 o.a.d.p.t.a.u.ProcessUtils:[182] - Get appIds from worker 172.18.1.1:1234, taskLogPath: /opt/dolphinscheduler/logs/20240429/13426477386080/8/748/2030.log
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:02.451 +0800 o.a.d.p.t.a.u.LogUtils:[79] - Start finding appId in /opt/dolphinscheduler/logs/20240429/13426477386080/8/748/2030.log, fetch way: log 
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:02.455 +0800 o.a.d.p.t.a.u.ProcessUtils:[188] - The appId is empty
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:02.455 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[118] - Cancel the task successfully
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:02.461 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[125] - Get a exception when execute the task, will send the task status: FAILURE to master: 172.18.1.1:1234
[WI-748][TI-2030] - [INFO] 2024-04-29 17:30:02.463 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-2030] - [INFO] 2024-04-29 17:30:02.903 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=2030, success=true)
[WI-0][TI-0] - [INFO] 2024-04-29 17:30:03.027 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=2031, taskName=Persist in postgresql, firstSubmitTime=1714383002975, startTime=0, taskType=SQL, workflowInstanceHost=172.18.0.10:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13426477386080, processDefineVersion=8, appIds=null, processInstanceId=748, scheduleTime=0, globalParams=null, executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[],"resourceList":[],"type":"POSTGRESQL","datasource":1,"sql":"${query}","sqlType":"0","preStatements":[],"postStatements":[],"displayRows":10}, environmentConfig=export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='Persist in postgresql'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, query=Property{prop='query', direct=IN, type=VARCHAR, value=''}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240429'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='2031'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13427698681952'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240429173002'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='748'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240428'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='es_filtered_data_persistence_subprocess'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13426477386080'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=org.apache.dolphinscheduler.plugin.task.api.parameters.resource.ResourceParametersHelper@60a9ad00, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"query","direct":"IN","type":"VARCHAR","value":""}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-748][TI-2031] - [INFO] 2024-04-29 17:30:03.031 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: Persist in postgresql to wait queue success
[WI-748][TI-2031] - [INFO] 2024-04-29 17:30:03.034 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2031] - [INFO] 2024-04-29 17:30:03.036 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-748][TI-2031] - [INFO] 2024-04-29 17:30:03.044 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2031] - [INFO] 2024-04-29 17:30:03.044 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-748][TI-2031] - [INFO] 2024-04-29 17:30:03.044 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1714383003044
[WI-748][TI-2031] - [INFO] 2024-04-29 17:30:03.044 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 748_2031
[WI-748][TI-2031] - [INFO] 2024-04-29 17:30:03.044 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 2031,
  "taskName" : "Persist in postgresql",
  "firstSubmitTime" : 1714383002975,
  "startTime" : 1714383003044,
  "taskType" : "SQL",
  "workflowInstanceHost" : "172.18.0.10:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240429/13426477386080/8/748/2031.log",
  "processId" : 0,
  "processDefineCode" : 13426477386080,
  "processDefineVersion" : 8,
  "processInstanceId" : 748,
  "scheduleTime" : 0,
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[],\"resourceList\":[],\"type\":\"POSTGRESQL\",\"datasource\":1,\"sql\":\"${query}\",\"sqlType\":\"0\",\"preStatements\":[],\"postStatements\":[],\"displayRows\":10}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "Persist in postgresql"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "query" : {
      "prop" : "query",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : ""
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240429"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "2031"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13427698681952"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240429173002"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "748"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240428"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "es_filtered_data_persistence_subprocess"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13426477386080"
    }
  },
  "taskAppId" : "748_2031",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "resourceParametersHelper" : {
    "resourceMap" : {
      "DATASOURCE" : {
        "1" : {
          "resourceType" : "DATASOURCE",
          "type" : "POSTGRESQL",
          "connectionParams" : "{\"user\":\"root\",\"password\":\"******\",\"address\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432\",\"database\":\"persistence\",\"jdbcUrl\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432/persistence\",\"driverClassName\":\"org.postgresql.Driver\",\"validationQuery\":\"select version()\"}",
          "DATASOURCE" : null
        }
      }
    }
  },
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"query\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-748][TI-2031] - [INFO] 2024-04-29 17:30:03.045 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2031] - [INFO] 2024-04-29 17:30:03.045 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-748][TI-2031] - [INFO] 2024-04-29 17:30:03.045 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2031] - [INFO] 2024-04-29 17:30:03.071 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-748][TI-2031] - [INFO] 2024-04-29 17:30:03.073 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-748][TI-2031] - [INFO] 2024-04-29 17:30:03.076 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_8/748/2031 check successfully
[WI-748][TI-2031] - [INFO] 2024-04-29 17:30:03.076 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.sql.SqlTaskChannel successfully
[WI-748][TI-2031] - [INFO] 2024-04-29 17:30:03.077 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-748][TI-2031] - [INFO] 2024-04-29 17:30:03.084 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-748][TI-2031] - [INFO] 2024-04-29 17:30:03.085 +0800 o.a.d.p.t.s.SqlTask:[99] - Initialize sql task parameter {
  "localParams" : [ ],
  "varPool" : null,
  "type" : "POSTGRESQL",
  "datasource" : 1,
  "sql" : "${query}",
  "sqlType" : 0,
  "sendEmail" : null,
  "displayRows" : 10,
  "udfs" : null,
  "showType" : null,
  "connParams" : null,
  "preStatements" : [ ],
  "postStatements" : [ ],
  "groupId" : 0,
  "title" : null,
  "limit" : 0
}
[WI-748][TI-2031] - [INFO] 2024-04-29 17:30:03.087 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SQL create successfully
[WI-748][TI-2031] - [INFO] 2024-04-29 17:30:03.087 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-748][TI-2031] - [INFO] 2024-04-29 17:30:03.088 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"query","direct":"IN","type":"VARCHAR","value":""}] successfully
[WI-748][TI-2031] - [INFO] 2024-04-29 17:30:03.088 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2031] - [INFO] 2024-04-29 17:30:03.090 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-748][TI-2031] - [INFO] 2024-04-29 17:30:03.091 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2031] - [INFO] 2024-04-29 17:30:03.091 +0800 o.a.d.p.t.s.SqlTask:[119] - Full sql parameters: SqlParameters{type='POSTGRESQL', datasource=1, sql='${query}', sqlType=0, sendEmail=null, displayRows=10, limit=0, udfs='null', showType='null', connParams='null', groupId='0', title='null', preStatements=[], postStatements=[]}
[WI-748][TI-2031] - [INFO] 2024-04-29 17:30:03.091 +0800 o.a.d.p.t.s.SqlTask:[120] - sql type : POSTGRESQL, datasource : 1, sql : ${query} , localParams : [],udfs : null,showType : null,connParams : null,varPool : [Property{prop='query', direct=IN, type=VARCHAR, value=''}] ,query max result limit  0
[WI-748][TI-2031] - [INFO] 2024-04-29 17:30:03.092 +0800 o.a.d.p.t.a.AbstractTask:[206] - setSqlParamsMap: Property with paramName: query put in sqlParamsMap of content ${query} successfully.
[WI-748][TI-2031] - [INFO] 2024-04-29 17:30:03.093 +0800 o.a.d.p.t.s.SqlTask:[410] - after replace sql , preparing : ?
[WI-748][TI-2031] - [INFO] 2024-04-29 17:30:03.095 +0800 o.a.d.p.t.s.SqlTask:[420] - Sql Params are replaced sql , parameters:(VARCHAR)
[WI-0][TI-0] - [INFO] 2024-04-29 17:30:03.092 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9910979228486647 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-748][TI-2031] - [INFO] 2024-04-29 17:30:03.095 +0800 o.a.d.p.t.s.SqlTask:[489] - can't find udf function resource
[WI-748][TI-2031] - [WARN] 2024-04-29 17:30:03.100 +0800 n.s.c.j.SnowflakeConnectString:[136] - Connect strings must start with jdbc:snowflake://
[WI-748][TI-2031] - [ERROR] 2024-04-29 17:30:03.154 +0800 o.a.d.p.t.s.SqlTask:[217] - execute sql error: Create adhoc connection error
[WI-748][TI-2031] - [ERROR] 2024-04-29 17:30:03.155 +0800 o.a.d.p.t.s.SqlTask:[165] - sql task error
java.sql.SQLException: Create adhoc connection error
	at org.apache.dolphinscheduler.plugin.datasource.api.client.BaseAdHocDataSourceClient.getConnection(BaseAdHocDataSourceClient.java:43)
	at org.apache.dolphinscheduler.plugin.datasource.api.plugin.DataSourceClientProvider.getAdHocConnection(DataSourceClientProvider.java:97)
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.executeFuncAndSql(SqlTask.java:189)
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.handle(SqlTask.java:159)
	at org.apache.dolphinscheduler.server.worker.runner.DefaultWorkerTaskExecutor.executeTask(DefaultWorkerTaskExecutor.java:54)
	at org.apache.dolphinscheduler.server.worker.runner.WorkerTaskExecutor.run(WorkerTaskExecutor.java:175)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.postgresql.util.PSQLException: FATAL: password authentication failed for user "root"
	at org.postgresql.core.v3.ConnectionFactoryImpl.doAuthentication(ConnectionFactoryImpl.java:646)
	at org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:180)
	at org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:235)
	at org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:49)
	at org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:247)
	at org.postgresql.Driver.makeConnection(Driver.java:434)
	at org.postgresql.Driver.connect(Driver.java:291)
	at java.sql.DriverManager.getConnection(DriverManager.java:664)
	at java.sql.DriverManager.getConnection(DriverManager.java:247)
	at org.apache.dolphinscheduler.plugin.datasource.postgresql.param.PostgreSQLDataSourceProcessor.getConnection(PostgreSQLDataSourceProcessor.java:117)
	at org.apache.dolphinscheduler.plugin.datasource.api.client.BaseAdHocDataSourceClient.getConnection(BaseAdHocDataSourceClient.java:41)
	... 8 common frames omitted
[WI-748][TI-2031] - [ERROR] 2024-04-29 17:30:03.156 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[181] - Task execute failed, due to meet an exception
org.apache.dolphinscheduler.plugin.task.api.TaskException: Execute sql task failed
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.handle(SqlTask.java:166)
	at org.apache.dolphinscheduler.server.worker.runner.DefaultWorkerTaskExecutor.executeTask(DefaultWorkerTaskExecutor.java:54)
	at org.apache.dolphinscheduler.server.worker.runner.WorkerTaskExecutor.run(WorkerTaskExecutor.java:175)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.sql.SQLException: Create adhoc connection error
	at org.apache.dolphinscheduler.plugin.datasource.api.client.BaseAdHocDataSourceClient.getConnection(BaseAdHocDataSourceClient.java:43)
	at org.apache.dolphinscheduler.plugin.datasource.api.plugin.DataSourceClientProvider.getAdHocConnection(DataSourceClientProvider.java:97)
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.executeFuncAndSql(SqlTask.java:189)
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.handle(SqlTask.java:159)
	... 5 common frames omitted
Caused by: org.postgresql.util.PSQLException: FATAL: password authentication failed for user "root"
	at org.postgresql.core.v3.ConnectionFactoryImpl.doAuthentication(ConnectionFactoryImpl.java:646)
	at org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:180)
	at org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:235)
	at org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:49)
	at org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:247)
	at org.postgresql.Driver.makeConnection(Driver.java:434)
	at org.postgresql.Driver.connect(Driver.java:291)
	at java.sql.DriverManager.getConnection(DriverManager.java:664)
	at java.sql.DriverManager.getConnection(DriverManager.java:247)
	at org.apache.dolphinscheduler.plugin.datasource.postgresql.param.PostgreSQLDataSourceProcessor.getConnection(PostgreSQLDataSourceProcessor.java:117)
	at org.apache.dolphinscheduler.plugin.datasource.api.client.BaseAdHocDataSourceClient.getConnection(BaseAdHocDataSourceClient.java:41)
	... 8 common frames omitted
[WI-748][TI-2031] - [INFO] 2024-04-29 17:30:03.157 +0800 o.a.d.p.t.a.u.ProcessUtils:[182] - Get appIds from worker 172.18.1.1:1234, taskLogPath: /opt/dolphinscheduler/logs/20240429/13426477386080/8/748/2031.log
[WI-748][TI-2031] - [INFO] 2024-04-29 17:30:03.157 +0800 o.a.d.p.t.a.u.LogUtils:[79] - Start finding appId in /opt/dolphinscheduler/logs/20240429/13426477386080/8/748/2031.log, fetch way: log 
[WI-748][TI-2031] - [INFO] 2024-04-29 17:30:03.158 +0800 o.a.d.p.t.a.u.ProcessUtils:[188] - The appId is empty
[WI-748][TI-2031] - [INFO] 2024-04-29 17:30:03.158 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[118] - Cancel the task successfully
[WI-748][TI-2031] - [INFO] 2024-04-29 17:30:03.167 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[125] - Get a exception when execute the task, will send the task status: FAILURE to master: 172.18.1.1:1234
[WI-748][TI-2031] - [INFO] 2024-04-29 17:30:03.169 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-2031] - [INFO] 2024-04-29 17:30:03.905 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=2031, success=true)
[WI-0][TI-2031] - [INFO] 2024-04-29 17:30:03.927 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=2031, success=true)
[WI-0][TI-0] - [INFO] 2024-04-29 17:30:05.042 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=2032, taskName=Persist in postgresql, firstSubmitTime=1714383005022, startTime=0, taskType=SQL, workflowInstanceHost=172.18.0.10:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13426477386080, processDefineVersion=8, appIds=null, processInstanceId=748, scheduleTime=0, globalParams=null, executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[],"resourceList":[],"type":"POSTGRESQL","datasource":1,"sql":"${query}","sqlType":"0","preStatements":[],"postStatements":[],"displayRows":10}, environmentConfig=export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='Persist in postgresql'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, query=Property{prop='query', direct=IN, type=VARCHAR, value=''}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240429'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='2032'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13427698681952'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240429173005'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='748'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240428'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='es_filtered_data_persistence_subprocess'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13426477386080'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=org.apache.dolphinscheduler.plugin.task.api.parameters.resource.ResourceParametersHelper@29b8a113, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"query","direct":"IN","type":"VARCHAR","value":""}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-748][TI-2032] - [INFO] 2024-04-29 17:30:05.043 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: Persist in postgresql to wait queue success
[WI-748][TI-2032] - [INFO] 2024-04-29 17:30:05.044 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2032] - [INFO] 2024-04-29 17:30:05.046 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-748][TI-2032] - [INFO] 2024-04-29 17:30:05.046 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2032] - [INFO] 2024-04-29 17:30:05.046 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-748][TI-2032] - [INFO] 2024-04-29 17:30:05.046 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1714383005046
[WI-748][TI-2032] - [INFO] 2024-04-29 17:30:05.046 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 748_2032
[WI-748][TI-2032] - [INFO] 2024-04-29 17:30:05.046 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 2032,
  "taskName" : "Persist in postgresql",
  "firstSubmitTime" : 1714383005022,
  "startTime" : 1714383005046,
  "taskType" : "SQL",
  "workflowInstanceHost" : "172.18.0.10:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240429/13426477386080/8/748/2032.log",
  "processId" : 0,
  "processDefineCode" : 13426477386080,
  "processDefineVersion" : 8,
  "processInstanceId" : 748,
  "scheduleTime" : 0,
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[],\"resourceList\":[],\"type\":\"POSTGRESQL\",\"datasource\":1,\"sql\":\"${query}\",\"sqlType\":\"0\",\"preStatements\":[],\"postStatements\":[],\"displayRows\":10}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "Persist in postgresql"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "query" : {
      "prop" : "query",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : ""
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240429"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "2032"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13427698681952"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240429173005"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "748"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240428"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "es_filtered_data_persistence_subprocess"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13426477386080"
    }
  },
  "taskAppId" : "748_2032",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "resourceParametersHelper" : {
    "resourceMap" : {
      "DATASOURCE" : {
        "1" : {
          "resourceType" : "DATASOURCE",
          "type" : "POSTGRESQL",
          "connectionParams" : "{\"user\":\"root\",\"password\":\"******\",\"address\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432\",\"database\":\"persistence\",\"jdbcUrl\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432/persistence\",\"driverClassName\":\"org.postgresql.Driver\",\"validationQuery\":\"select version()\"}",
          "DATASOURCE" : null
        }
      }
    }
  },
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"query\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-748][TI-2032] - [INFO] 2024-04-29 17:30:05.047 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2032] - [INFO] 2024-04-29 17:30:05.047 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-748][TI-2032] - [INFO] 2024-04-29 17:30:05.047 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2032] - [INFO] 2024-04-29 17:30:05.051 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-748][TI-2032] - [INFO] 2024-04-29 17:30:05.051 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-748][TI-2032] - [INFO] 2024-04-29 17:30:05.052 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_8/748/2032 check successfully
[WI-748][TI-2032] - [INFO] 2024-04-29 17:30:05.053 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.sql.SqlTaskChannel successfully
[WI-748][TI-2032] - [INFO] 2024-04-29 17:30:05.053 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-748][TI-2032] - [INFO] 2024-04-29 17:30:05.053 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-748][TI-2032] - [INFO] 2024-04-29 17:30:05.060 +0800 o.a.d.p.t.s.SqlTask:[99] - Initialize sql task parameter {
  "localParams" : [ ],
  "varPool" : null,
  "type" : "POSTGRESQL",
  "datasource" : 1,
  "sql" : "${query}",
  "sqlType" : 0,
  "sendEmail" : null,
  "displayRows" : 10,
  "udfs" : null,
  "showType" : null,
  "connParams" : null,
  "preStatements" : [ ],
  "postStatements" : [ ],
  "groupId" : 0,
  "title" : null,
  "limit" : 0
}
[WI-748][TI-2032] - [INFO] 2024-04-29 17:30:05.061 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SQL create successfully
[WI-748][TI-2032] - [INFO] 2024-04-29 17:30:05.061 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-748][TI-2032] - [INFO] 2024-04-29 17:30:05.061 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"query","direct":"IN","type":"VARCHAR","value":""}] successfully
[WI-748][TI-2032] - [INFO] 2024-04-29 17:30:05.062 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2032] - [INFO] 2024-04-29 17:30:05.064 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-748][TI-2032] - [INFO] 2024-04-29 17:30:05.065 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2032] - [INFO] 2024-04-29 17:30:05.066 +0800 o.a.d.p.t.s.SqlTask:[119] - Full sql parameters: SqlParameters{type='POSTGRESQL', datasource=1, sql='${query}', sqlType=0, sendEmail=null, displayRows=10, limit=0, udfs='null', showType='null', connParams='null', groupId='0', title='null', preStatements=[], postStatements=[]}
[WI-748][TI-2032] - [INFO] 2024-04-29 17:30:05.069 +0800 o.a.d.p.t.s.SqlTask:[120] - sql type : POSTGRESQL, datasource : 1, sql : ${query} , localParams : [],udfs : null,showType : null,connParams : null,varPool : [Property{prop='query', direct=IN, type=VARCHAR, value=''}] ,query max result limit  0
[WI-748][TI-2032] - [INFO] 2024-04-29 17:30:05.078 +0800 o.a.d.p.t.a.AbstractTask:[206] - setSqlParamsMap: Property with paramName: query put in sqlParamsMap of content ${query} successfully.
[WI-748][TI-2032] - [INFO] 2024-04-29 17:30:05.080 +0800 o.a.d.p.t.s.SqlTask:[410] - after replace sql , preparing : ?
[WI-748][TI-2032] - [INFO] 2024-04-29 17:30:05.081 +0800 o.a.d.p.t.s.SqlTask:[420] - Sql Params are replaced sql , parameters:(VARCHAR)
[WI-748][TI-2032] - [INFO] 2024-04-29 17:30:05.083 +0800 o.a.d.p.t.s.SqlTask:[489] - can't find udf function resource
[WI-748][TI-2032] - [WARN] 2024-04-29 17:30:05.086 +0800 n.s.c.j.SnowflakeConnectString:[136] - Connect strings must start with jdbc:snowflake://
[WI-748][TI-2032] - [ERROR] 2024-04-29 17:30:05.124 +0800 o.a.d.p.t.s.SqlTask:[217] - execute sql error: Create adhoc connection error
[WI-748][TI-2032] - [ERROR] 2024-04-29 17:30:05.125 +0800 o.a.d.p.t.s.SqlTask:[165] - sql task error
java.sql.SQLException: Create adhoc connection error
	at org.apache.dolphinscheduler.plugin.datasource.api.client.BaseAdHocDataSourceClient.getConnection(BaseAdHocDataSourceClient.java:43)
	at org.apache.dolphinscheduler.plugin.datasource.api.plugin.DataSourceClientProvider.getAdHocConnection(DataSourceClientProvider.java:97)
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.executeFuncAndSql(SqlTask.java:189)
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.handle(SqlTask.java:159)
	at org.apache.dolphinscheduler.server.worker.runner.DefaultWorkerTaskExecutor.executeTask(DefaultWorkerTaskExecutor.java:54)
	at org.apache.dolphinscheduler.server.worker.runner.WorkerTaskExecutor.run(WorkerTaskExecutor.java:175)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.postgresql.util.PSQLException: FATAL: password authentication failed for user "root"
	at org.postgresql.core.v3.ConnectionFactoryImpl.doAuthentication(ConnectionFactoryImpl.java:646)
	at org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:180)
	at org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:235)
	at org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:49)
	at org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:247)
	at org.postgresql.Driver.makeConnection(Driver.java:434)
	at org.postgresql.Driver.connect(Driver.java:291)
	at java.sql.DriverManager.getConnection(DriverManager.java:664)
	at java.sql.DriverManager.getConnection(DriverManager.java:247)
	at org.apache.dolphinscheduler.plugin.datasource.postgresql.param.PostgreSQLDataSourceProcessor.getConnection(PostgreSQLDataSourceProcessor.java:117)
	at org.apache.dolphinscheduler.plugin.datasource.api.client.BaseAdHocDataSourceClient.getConnection(BaseAdHocDataSourceClient.java:41)
	... 8 common frames omitted
[WI-748][TI-2032] - [ERROR] 2024-04-29 17:30:05.130 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[181] - Task execute failed, due to meet an exception
org.apache.dolphinscheduler.plugin.task.api.TaskException: Execute sql task failed
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.handle(SqlTask.java:166)
	at org.apache.dolphinscheduler.server.worker.runner.DefaultWorkerTaskExecutor.executeTask(DefaultWorkerTaskExecutor.java:54)
	at org.apache.dolphinscheduler.server.worker.runner.WorkerTaskExecutor.run(WorkerTaskExecutor.java:175)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.sql.SQLException: Create adhoc connection error
	at org.apache.dolphinscheduler.plugin.datasource.api.client.BaseAdHocDataSourceClient.getConnection(BaseAdHocDataSourceClient.java:43)
	at org.apache.dolphinscheduler.plugin.datasource.api.plugin.DataSourceClientProvider.getAdHocConnection(DataSourceClientProvider.java:97)
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.executeFuncAndSql(SqlTask.java:189)
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.handle(SqlTask.java:159)
	... 5 common frames omitted
Caused by: org.postgresql.util.PSQLException: FATAL: password authentication failed for user "root"
	at org.postgresql.core.v3.ConnectionFactoryImpl.doAuthentication(ConnectionFactoryImpl.java:646)
	at org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:180)
	at org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:235)
	at org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:49)
	at org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:247)
	at org.postgresql.Driver.makeConnection(Driver.java:434)
	at org.postgresql.Driver.connect(Driver.java:291)
	at java.sql.DriverManager.getConnection(DriverManager.java:664)
	at java.sql.DriverManager.getConnection(DriverManager.java:247)
	at org.apache.dolphinscheduler.plugin.datasource.postgresql.param.PostgreSQLDataSourceProcessor.getConnection(PostgreSQLDataSourceProcessor.java:117)
	at org.apache.dolphinscheduler.plugin.datasource.api.client.BaseAdHocDataSourceClient.getConnection(BaseAdHocDataSourceClient.java:41)
	... 8 common frames omitted
[WI-748][TI-2032] - [INFO] 2024-04-29 17:30:05.130 +0800 o.a.d.p.t.a.u.ProcessUtils:[182] - Get appIds from worker 172.18.1.1:1234, taskLogPath: /opt/dolphinscheduler/logs/20240429/13426477386080/8/748/2032.log
[WI-748][TI-2032] - [INFO] 2024-04-29 17:30:05.131 +0800 o.a.d.p.t.a.u.LogUtils:[79] - Start finding appId in /opt/dolphinscheduler/logs/20240429/13426477386080/8/748/2032.log, fetch way: log 
[WI-748][TI-2032] - [INFO] 2024-04-29 17:30:05.131 +0800 o.a.d.p.t.a.u.ProcessUtils:[188] - The appId is empty
[WI-748][TI-2032] - [INFO] 2024-04-29 17:30:05.131 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[118] - Cancel the task successfully
[WI-748][TI-2032] - [INFO] 2024-04-29 17:30:05.156 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[125] - Get a exception when execute the task, will send the task status: FAILURE to master: 172.18.1.1:1234
[WI-748][TI-2032] - [INFO] 2024-04-29 17:30:05.157 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-2032] - [INFO] 2024-04-29 17:30:05.909 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=2032, success=true)
[WI-0][TI-2032] - [INFO] 2024-04-29 17:30:05.925 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=2032, success=true)
[WI-0][TI-0] - [INFO] 2024-04-29 17:30:06.969 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=2033, taskName=Persist in postgresql, firstSubmitTime=1714383006954, startTime=0, taskType=SQL, workflowInstanceHost=172.18.0.10:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13426477386080, processDefineVersion=8, appIds=null, processInstanceId=748, scheduleTime=0, globalParams=null, executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[],"resourceList":[],"type":"POSTGRESQL","datasource":1,"sql":"${query}","sqlType":"0","preStatements":[],"postStatements":[],"displayRows":10}, environmentConfig=export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='Persist in postgresql'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, query=Property{prop='query', direct=IN, type=VARCHAR, value=''}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240429'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='2033'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13427698681952'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240429173006'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='748'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240428'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='es_filtered_data_persistence_subprocess'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13426477386080'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=org.apache.dolphinscheduler.plugin.task.api.parameters.resource.ResourceParametersHelper@611a753, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"query","direct":"IN","type":"VARCHAR","value":""}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-748][TI-2033] - [INFO] 2024-04-29 17:30:06.974 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: Persist in postgresql to wait queue success
[WI-748][TI-2033] - [INFO] 2024-04-29 17:30:06.974 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2033] - [INFO] 2024-04-29 17:30:06.976 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-748][TI-2033] - [INFO] 2024-04-29 17:30:06.977 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2033] - [INFO] 2024-04-29 17:30:06.977 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-748][TI-2033] - [INFO] 2024-04-29 17:30:06.977 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1714383006977
[WI-748][TI-2033] - [INFO] 2024-04-29 17:30:06.977 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 748_2033
[WI-748][TI-2033] - [INFO] 2024-04-29 17:30:06.978 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 2033,
  "taskName" : "Persist in postgresql",
  "firstSubmitTime" : 1714383006954,
  "startTime" : 1714383006977,
  "taskType" : "SQL",
  "workflowInstanceHost" : "172.18.0.10:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240429/13426477386080/8/748/2033.log",
  "processId" : 0,
  "processDefineCode" : 13426477386080,
  "processDefineVersion" : 8,
  "processInstanceId" : 748,
  "scheduleTime" : 0,
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[],\"resourceList\":[],\"type\":\"POSTGRESQL\",\"datasource\":1,\"sql\":\"${query}\",\"sqlType\":\"0\",\"preStatements\":[],\"postStatements\":[],\"displayRows\":10}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "Persist in postgresql"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "query" : {
      "prop" : "query",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : ""
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240429"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "2033"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13427698681952"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240429173006"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "748"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240428"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "es_filtered_data_persistence_subprocess"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13426477386080"
    }
  },
  "taskAppId" : "748_2033",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "resourceParametersHelper" : {
    "resourceMap" : {
      "DATASOURCE" : {
        "1" : {
          "resourceType" : "DATASOURCE",
          "type" : "POSTGRESQL",
          "connectionParams" : "{\"user\":\"root\",\"password\":\"******\",\"address\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432\",\"database\":\"persistence\",\"jdbcUrl\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432/persistence\",\"driverClassName\":\"org.postgresql.Driver\",\"validationQuery\":\"select version()\"}",
          "DATASOURCE" : null
        }
      }
    }
  },
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"query\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-748][TI-2033] - [INFO] 2024-04-29 17:30:06.979 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2033] - [INFO] 2024-04-29 17:30:06.980 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-748][TI-2033] - [INFO] 2024-04-29 17:30:06.980 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2033] - [INFO] 2024-04-29 17:30:06.993 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-748][TI-2033] - [INFO] 2024-04-29 17:30:06.994 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-748][TI-2033] - [INFO] 2024-04-29 17:30:06.996 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_8/748/2033 check successfully
[WI-748][TI-2033] - [INFO] 2024-04-29 17:30:06.998 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.sql.SqlTaskChannel successfully
[WI-748][TI-2033] - [INFO] 2024-04-29 17:30:06.998 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-748][TI-2033] - [INFO] 2024-04-29 17:30:06.999 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-748][TI-2033] - [INFO] 2024-04-29 17:30:07.002 +0800 o.a.d.p.t.s.SqlTask:[99] - Initialize sql task parameter {
  "localParams" : [ ],
  "varPool" : null,
  "type" : "POSTGRESQL",
  "datasource" : 1,
  "sql" : "${query}",
  "sqlType" : 0,
  "sendEmail" : null,
  "displayRows" : 10,
  "udfs" : null,
  "showType" : null,
  "connParams" : null,
  "preStatements" : [ ],
  "postStatements" : [ ],
  "groupId" : 0,
  "title" : null,
  "limit" : 0
}
[WI-748][TI-2033] - [INFO] 2024-04-29 17:30:07.003 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SQL create successfully
[WI-748][TI-2033] - [INFO] 2024-04-29 17:30:07.003 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-748][TI-2033] - [INFO] 2024-04-29 17:30:07.003 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"query","direct":"IN","type":"VARCHAR","value":""}] successfully
[WI-748][TI-2033] - [INFO] 2024-04-29 17:30:07.004 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2033] - [INFO] 2024-04-29 17:30:07.004 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-748][TI-2033] - [INFO] 2024-04-29 17:30:07.004 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2033] - [INFO] 2024-04-29 17:30:07.004 +0800 o.a.d.p.t.s.SqlTask:[119] - Full sql parameters: SqlParameters{type='POSTGRESQL', datasource=1, sql='${query}', sqlType=0, sendEmail=null, displayRows=10, limit=0, udfs='null', showType='null', connParams='null', groupId='0', title='null', preStatements=[], postStatements=[]}
[WI-748][TI-2033] - [INFO] 2024-04-29 17:30:07.004 +0800 o.a.d.p.t.s.SqlTask:[120] - sql type : POSTGRESQL, datasource : 1, sql : ${query} , localParams : [],udfs : null,showType : null,connParams : null,varPool : [Property{prop='query', direct=IN, type=VARCHAR, value=''}] ,query max result limit  0
[WI-748][TI-2033] - [INFO] 2024-04-29 17:30:07.005 +0800 o.a.d.p.t.a.AbstractTask:[206] - setSqlParamsMap: Property with paramName: query put in sqlParamsMap of content ${query} successfully.
[WI-748][TI-2033] - [INFO] 2024-04-29 17:30:07.005 +0800 o.a.d.p.t.s.SqlTask:[410] - after replace sql , preparing : ?
[WI-748][TI-2033] - [INFO] 2024-04-29 17:30:07.005 +0800 o.a.d.p.t.s.SqlTask:[420] - Sql Params are replaced sql , parameters:(VARCHAR)
[WI-748][TI-2033] - [INFO] 2024-04-29 17:30:07.005 +0800 o.a.d.p.t.s.SqlTask:[489] - can't find udf function resource
[WI-748][TI-2033] - [WARN] 2024-04-29 17:30:07.006 +0800 n.s.c.j.SnowflakeConnectString:[136] - Connect strings must start with jdbc:snowflake://
[WI-748][TI-2033] - [ERROR] 2024-04-29 17:30:07.032 +0800 o.a.d.p.t.s.SqlTask:[217] - execute sql error: Create adhoc connection error
[WI-748][TI-2033] - [ERROR] 2024-04-29 17:30:07.034 +0800 o.a.d.p.t.s.SqlTask:[165] - sql task error
java.sql.SQLException: Create adhoc connection error
	at org.apache.dolphinscheduler.plugin.datasource.api.client.BaseAdHocDataSourceClient.getConnection(BaseAdHocDataSourceClient.java:43)
	at org.apache.dolphinscheduler.plugin.datasource.api.plugin.DataSourceClientProvider.getAdHocConnection(DataSourceClientProvider.java:97)
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.executeFuncAndSql(SqlTask.java:189)
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.handle(SqlTask.java:159)
	at org.apache.dolphinscheduler.server.worker.runner.DefaultWorkerTaskExecutor.executeTask(DefaultWorkerTaskExecutor.java:54)
	at org.apache.dolphinscheduler.server.worker.runner.WorkerTaskExecutor.run(WorkerTaskExecutor.java:175)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.postgresql.util.PSQLException: FATAL: password authentication failed for user "root"
	at org.postgresql.core.v3.ConnectionFactoryImpl.doAuthentication(ConnectionFactoryImpl.java:646)
	at org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:180)
	at org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:235)
	at org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:49)
	at org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:247)
	at org.postgresql.Driver.makeConnection(Driver.java:434)
	at org.postgresql.Driver.connect(Driver.java:291)
	at java.sql.DriverManager.getConnection(DriverManager.java:664)
	at java.sql.DriverManager.getConnection(DriverManager.java:247)
	at org.apache.dolphinscheduler.plugin.datasource.postgresql.param.PostgreSQLDataSourceProcessor.getConnection(PostgreSQLDataSourceProcessor.java:117)
	at org.apache.dolphinscheduler.plugin.datasource.api.client.BaseAdHocDataSourceClient.getConnection(BaseAdHocDataSourceClient.java:41)
	... 8 common frames omitted
[WI-748][TI-2033] - [ERROR] 2024-04-29 17:30:07.035 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[181] - Task execute failed, due to meet an exception
org.apache.dolphinscheduler.plugin.task.api.TaskException: Execute sql task failed
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.handle(SqlTask.java:166)
	at org.apache.dolphinscheduler.server.worker.runner.DefaultWorkerTaskExecutor.executeTask(DefaultWorkerTaskExecutor.java:54)
	at org.apache.dolphinscheduler.server.worker.runner.WorkerTaskExecutor.run(WorkerTaskExecutor.java:175)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.sql.SQLException: Create adhoc connection error
	at org.apache.dolphinscheduler.plugin.datasource.api.client.BaseAdHocDataSourceClient.getConnection(BaseAdHocDataSourceClient.java:43)
	at org.apache.dolphinscheduler.plugin.datasource.api.plugin.DataSourceClientProvider.getAdHocConnection(DataSourceClientProvider.java:97)
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.executeFuncAndSql(SqlTask.java:189)
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.handle(SqlTask.java:159)
	... 5 common frames omitted
Caused by: org.postgresql.util.PSQLException: FATAL: password authentication failed for user "root"
	at org.postgresql.core.v3.ConnectionFactoryImpl.doAuthentication(ConnectionFactoryImpl.java:646)
	at org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:180)
	at org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:235)
	at org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:49)
	at org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:247)
	at org.postgresql.Driver.makeConnection(Driver.java:434)
	at org.postgresql.Driver.connect(Driver.java:291)
	at java.sql.DriverManager.getConnection(DriverManager.java:664)
	at java.sql.DriverManager.getConnection(DriverManager.java:247)
	at org.apache.dolphinscheduler.plugin.datasource.postgresql.param.PostgreSQLDataSourceProcessor.getConnection(PostgreSQLDataSourceProcessor.java:117)
	at org.apache.dolphinscheduler.plugin.datasource.api.client.BaseAdHocDataSourceClient.getConnection(BaseAdHocDataSourceClient.java:41)
	... 8 common frames omitted
[WI-748][TI-2033] - [INFO] 2024-04-29 17:30:07.035 +0800 o.a.d.p.t.a.u.ProcessUtils:[182] - Get appIds from worker 172.18.1.1:1234, taskLogPath: /opt/dolphinscheduler/logs/20240429/13426477386080/8/748/2033.log
[WI-748][TI-2033] - [INFO] 2024-04-29 17:30:07.036 +0800 o.a.d.p.t.a.u.LogUtils:[79] - Start finding appId in /opt/dolphinscheduler/logs/20240429/13426477386080/8/748/2033.log, fetch way: log 
[WI-748][TI-2033] - [INFO] 2024-04-29 17:30:07.037 +0800 o.a.d.p.t.a.u.ProcessUtils:[188] - The appId is empty
[WI-748][TI-2033] - [INFO] 2024-04-29 17:30:07.037 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[118] - Cancel the task successfully
[WI-748][TI-2033] - [INFO] 2024-04-29 17:30:07.044 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[125] - Get a exception when execute the task, will send the task status: FAILURE to master: 172.18.1.1:1234
[WI-748][TI-2033] - [INFO] 2024-04-29 17:30:07.051 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-2033] - [INFO] 2024-04-29 17:30:07.925 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=2033, success=true)
[WI-0][TI-2033] - [INFO] 2024-04-29 17:30:07.946 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=2033, success=true)
[WI-0][TI-0] - [INFO] 2024-04-29 17:30:26.292 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7002967359050445 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-29 17:30:28.329 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7398373983739838 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-29 17:31:39.813 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7365439093484419 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-29 17:32:11.924 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7053824362606231 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [WARN] 2024-04-29 17:40:23.267 +0800 o.s.c.k.c.p.AbstractKubernetesProfileEnvironmentPostProcessor:[258] - Not running inside kubernetes. Skipping 'kubernetes' profile activation.
[WI-0][TI-0] - [WARN] 2024-04-29 17:40:26.086 +0800 o.s.c.k.c.p.AbstractKubernetesProfileEnvironmentPostProcessor:[258] - Not running inside kubernetes. Skipping 'kubernetes' profile activation.
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:26.097 +0800 o.a.d.s.w.WorkerServer:[634] - No active profile set, falling back to 1 default profile: "default"
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:35.564 +0800 o.s.c.c.s.GenericScope:[283] - BeanFactory id=7e7bf7c6-2cb3-34d2-a0d5-a56161c67d0e
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:37.079 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'org.springframework.cloud.commons.config.CommonsConfigAutoConfiguration' of type [org.springframework.cloud.commons.config.CommonsConfigAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:37.094 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'org.springframework.cloud.client.loadbalancer.LoadBalancerDefaultMappingsProviderAutoConfiguration' of type [org.springframework.cloud.client.loadbalancer.LoadBalancerDefaultMappingsProviderAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:37.114 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'loadBalancerClientsDefaultsMappingsProvider' of type [org.springframework.cloud.client.loadbalancer.LoadBalancerDefaultMappingsProviderAutoConfiguration$$Lambda$392/302905744] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:37.193 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'defaultsBindHandlerAdvisor' of type [org.springframework.cloud.commons.config.DefaultsBindHandlerAdvisor] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:37.408 +0800 o.a.d.c.u.NetUtils:[312] - Get all NetworkInterfaces: [name:eth0 (eth0), name:lo (lo)]
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:37.558 +0800 o.a.d.s.w.c.WorkerConfig:[98] - 
****************************Worker Configuration**************************************
  listen-port -> 1234
  exec-threads -> 100
  max-heartbeat-interval -> PT10S
  host-weight -> 100
  tenantConfig -> TenantConfig(autoCreateTenantEnabled=true, distributedTenantEnabled=false, defaultTenantEnabled=false)
  server-load-protection -> WorkerServerLoadProtection(enabled=true, maxCpuUsagePercentageThresholds=0.7, maxJVMMemoryUsagePercentageThresholds=0.7, maxSystemMemoryUsagePercentageThresholds=0.7, maxDiskUsagePercentageThresholds=0.7)
  registry-disconnect-strategy -> ConnectStrategyProperties(strategy=WAITING, maxWaitingTime=PT1M40S)
  task-execute-threads-full-policy: REJECT
  address -> 172.18.1.1:1234
  registry-path: /nodes/worker/172.18.1.1:1234
****************************Worker Configuration**************************************
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:37.559 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'workerConfig' of type [org.apache.dolphinscheduler.server.worker.config.WorkerConfig$$EnhancerBySpringCGLIB$$da954724] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:38.523 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'io.kubernetes.client.spring.extended.manifests.config.KubernetesManifestsAutoConfiguration' of type [io.kubernetes.client.spring.extended.manifests.config.KubernetesManifestsAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:38.631 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'kubernetes.manifests-io.kubernetes.client.spring.extended.manifests.config.KubernetesManifestsProperties' of type [io.kubernetes.client.spring.extended.manifests.config.KubernetesManifestsProperties] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:38.724 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'io.kubernetes.client.spring.extended.controller.config.KubernetesInformerAutoConfiguration' of type [io.kubernetes.client.spring.extended.controller.config.KubernetesInformerAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:38.913 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'defaultApiClient' of type [io.kubernetes.client.openapi.ApiClient] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:39.509 +0800 o.e.j.u.log:[170] - Logging initialized @25466ms to org.eclipse.jetty.util.log.Slf4jLog
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:40.986 +0800 o.s.b.w.e.j.JettyServletWebServerFactory:[166] - Server initialized with port: 1235
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:41.040 +0800 o.e.j.s.Server:[375] - jetty-9.4.48.v20220622; built: 2022-06-21T20:42:25.880Z; git: 6b67c5719d1f4371b33655ff2d047d24e171e49a; jvm 1.8.0_402-b06
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:41.659 +0800 o.e.j.s.h.C.application:[2368] - Initializing Spring embedded WebApplicationContext
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:41.663 +0800 o.s.b.w.s.c.ServletWebServerApplicationContext:[292] - Root WebApplicationContext: initialization completed in 15483 ms
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:47.219 +0800 o.e.j.s.session:[334] - DefaultSessionIdManager workerName=node0
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:47.219 +0800 o.e.j.s.session:[339] - No SessionScavenger set, using defaults
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:47.227 +0800 o.e.j.s.session:[132] - node0 Scavenging every 660000ms
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:47.300 +0800 o.e.j.s.h.ContextHandler:[921] - Started o.s.b.w.e.j.JettyEmbeddedWebAppContext@52433946{application,/,[file:///tmp/jetty-docbase.1235.4252375971071830339/],AVAILABLE}
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:47.310 +0800 o.e.j.s.Server:[415] - Started @33266ms
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:48.837 +0800 o.a.c.f.i.CuratorFrameworkImpl:[338] - Starting
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:48.865 +0800 o.a.z.ZooKeeper:[98] - Client environment:zookeeper.version=3.8.0-5a02a05eddb59aee6ac762f7ea82e92a68eb9c0f, built on 2022-02-25 08:49 UTC
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:48.869 +0800 o.a.z.ZooKeeper:[98] - Client environment:host.name=0725b5cf724f
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:48.870 +0800 o.a.z.ZooKeeper:[98] - Client environment:java.version=1.8.0_402
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:48.870 +0800 o.a.z.ZooKeeper:[98] - Client environment:java.vendor=Temurin
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:48.870 +0800 o.a.z.ZooKeeper:[98] - Client environment:java.home=/opt/java/openjdk
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:48.870 +0800 o.a.z.ZooKeeper:[98] - Client environment:java.class.path=/opt/dolphinscheduler/conf:/opt/dolphinscheduler/libs/kerb-client-1.0.1.jar:/opt/dolphinscheduler/libs/spring-cloud-starter-kubernetes-client-config-2.1.3.jar:/opt/dolphinscheduler/libs/oauth2-oidc-sdk-9.35.jar:/opt/dolphinscheduler/libs/jsqlparser-4.4.jar:/opt/dolphinscheduler/libs/reactive-streams-1.0.4.jar:/opt/dolphinscheduler/libs/kubernetes-model-extensions-5.10.2.jar:/opt/dolphinscheduler/libs/zookeeper-3.8.0.jar:/opt/dolphinscheduler/libs/kubernetes-model-apps-5.10.2.jar:/opt/dolphinscheduler/libs/grpc-api-1.41.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-pigeon-3.2.1.jar:/opt/dolphinscheduler/libs/client-java-api-13.0.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-obs-3.2.1.jar:/opt/dolphinscheduler/libs/spring-web-5.3.22.jar:/opt/dolphinscheduler/libs/aws-java-sdk-emr-1.12.300.jar:/opt/dolphinscheduler/libs/spring-context-5.3.22.jar:/opt/dolphinscheduler/libs/gapic-google-cloud-storage-v2-2.18.0-alpha.jar:/opt/dolphinscheduler/libs/spring-cloud-kubernetes-client-config-2.1.3.jar:/opt/dolphinscheduler/libs/jetty-io-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/annotations-13.0.jar:/opt/dolphinscheduler/libs/jpam-1.1.jar:/opt/dolphinscheduler/libs/joda-time-2.10.13.jar:/opt/dolphinscheduler/libs/spring-cloud-kubernetes-client-autoconfig-2.1.3.jar:/opt/dolphinscheduler/libs/kerb-identity-1.0.1.jar:/opt/dolphinscheduler/libs/vertica-jdbc-12.0.4-0.jar:/opt/dolphinscheduler/libs/grpc-googleapis-1.52.1.jar:/opt/dolphinscheduler/libs/aliyun-java-sdk-kms-2.11.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-dvc-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-hana-3.2.1.jar:/opt/dolphinscheduler/libs/kubernetes-httpclient-okhttp-6.0.0.jar:/opt/dolphinscheduler/libs/jline-2.12.jar:/opt/dolphinscheduler/libs/sshd-core-2.8.0.jar:/opt/dolphinscheduler/libs/jna-platform-5.10.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-sqlserver-3.2.1.jar:/opt/dolphinscheduler/libs/commons-beanutils-1.9.4.jar:/opt/dolphinscheduler/libs/grpc-services-1.41.0.jar:/opt/dolphinscheduler/libs/jmespath-java-1.12.300.jar:/opt/dolphinscheduler/libs/curator-client-5.3.0.jar:/opt/dolphinscheduler/libs/proto-google-common-protos-2.0.1.jar:/opt/dolphinscheduler/libs/mybatis-3.5.10.jar:/opt/dolphinscheduler/libs/jackson-annotations-2.13.4.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-all-3.2.1.jar:/opt/dolphinscheduler/libs/jakarta.xml.bind-api-2.3.3.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-jupyter-3.2.1.jar:/opt/dolphinscheduler/libs/mybatis-plus-extension-3.5.2.jar:/opt/dolphinscheduler/libs/j2objc-annotations-1.3.jar:/opt/dolphinscheduler/libs/Java-WebSocket-1.5.1.jar:/opt/dolphinscheduler/libs/azure-storage-common-12.20.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-sagemaker-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-databend-3.2.1.jar:/opt/dolphinscheduler/libs/google-auth-library-oauth2-http-1.15.0.jar:/opt/dolphinscheduler/libs/jetty-security-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-python-3.2.1.jar:/opt/dolphinscheduler/libs/snappy-java-1.1.10.1.jar:/opt/dolphinscheduler/libs/kubernetes-model-batch-5.10.2.jar:/opt/dolphinscheduler/libs/netty-transport-native-epoll-4.1.53.Final-linux-x86_64.jar:/opt/dolphinscheduler/libs/jackson-core-asl-1.9.13.jar:/opt/dolphinscheduler/libs/gson-fire-1.8.5.jar:/opt/dolphinscheduler/libs/clickhouse-jdbc-0.4.6.jar:/opt/dolphinscheduler/libs/grpc-netty-shaded-1.41.0.jar:/opt/dolphinscheduler/libs/caffeine-2.9.3.jar:/opt/dolphinscheduler/libs/aliyun-java-sdk-core-4.5.10.jar:/opt/dolphinscheduler/libs/jackson-module-jaxb-annotations-2.13.3.jar:/opt/dolphinscheduler/libs/jetty-http-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/jersey-servlet-1.19.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-dinky-3.2.1.jar:/opt/dolphinscheduler/libs/simpleclient_tracer_common-0.15.0.jar:/opt/dolphinscheduler/libs/netty-handler-4.1.53.Final.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-datafactory-3.2.1.jar:/opt/dolphinscheduler/libs/json-path-2.7.0.jar:/opt/dolphinscheduler/libs/mybatis-plus-annotation-3.5.2.jar:/opt/dolphinscheduler/libs/azure-resourcemanager-datafactory-1.0.0-beta.19.jar:/opt/dolphinscheduler/libs/commons-codec-1.11.jar:/opt/dolphinscheduler/libs/dolphinscheduler-extract-master-3.2.1.jar:/opt/dolphinscheduler/libs/spring-aop-5.3.22.jar:/opt/dolphinscheduler/libs/kubernetes-model-core-5.10.2.jar:/opt/dolphinscheduler/libs/kubernetes-model-networking-5.10.2.jar:/opt/dolphinscheduler/libs/kotlin-stdlib-jdk7-1.6.21.jar:/opt/dolphinscheduler/libs/kerby-xdr-1.0.1.jar:/opt/dolphinscheduler/libs/aliyun-java-sdk-ram-3.1.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-k8s-3.2.1.jar:/opt/dolphinscheduler/libs/guava-31.1-jre.jar:/opt/dolphinscheduler/libs/netty-codec-dns-4.1.53.Final.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-kubeflow-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-azure-sql-3.2.1.jar:/opt/dolphinscheduler/libs/HikariCP-4.0.3.jar:/opt/dolphinscheduler/libs/hive-metastore-2.3.9.jar:/opt/dolphinscheduler/libs/msal4j-1.13.3.jar:/opt/dolphinscheduler/libs/jackson-core-2.13.4.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-hive-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-mr-3.2.1.jar:/opt/dolphinscheduler/libs/kubernetes-model-node-5.10.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-common-3.2.1.jar:/opt/dolphinscheduler/libs/jose4j-0.7.8.jar:/opt/dolphinscheduler/libs/jul-to-slf4j-1.7.36.jar:/opt/dolphinscheduler/libs/azure-identity-1.7.1.jar:/opt/dolphinscheduler/libs/spring-boot-autoconfigure-2.7.3.jar:/opt/dolphinscheduler/libs/commons-math3-3.1.1.jar:/opt/dolphinscheduler/libs/jackson-jaxrs-json-provider-2.13.3.jar:/opt/dolphinscheduler/libs/perfmark-api-0.23.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-doris-3.2.1.jar:/opt/dolphinscheduler/libs/httpclient-4.5.13.jar:/opt/dolphinscheduler/libs/hive-service-2.3.9.jar:/opt/dolphinscheduler/libs/kerby-util-1.0.1.jar:/opt/dolphinscheduler/libs/commons-collections-3.2.2.jar:/opt/dolphinscheduler/libs/hadoop-yarn-client-3.2.4.jar:/opt/dolphinscheduler/libs/commons-text-1.8.jar:/opt/dolphinscheduler/libs/dolphinscheduler-worker-3.2.1.jar:/opt/dolphinscheduler/libs/hadoop-yarn-common-3.2.4.jar:/opt/dolphinscheduler/libs/zeppelin-client-0.10.1.jar:/opt/dolphinscheduler/libs/azure-core-management-1.10.1.jar:/opt/dolphinscheduler/libs/hadoop-mapreduce-client-jobclient-3.2.4.jar:/opt/dolphinscheduler/libs/jta-1.1.jar:/opt/dolphinscheduler/libs/annotations-4.1.1.4.jar:/opt/dolphinscheduler/libs/dolphinscheduler-extract-alert-3.2.1.jar:/opt/dolphinscheduler/libs/curator-framework-5.3.0.jar:/opt/dolphinscheduler/libs/hive-jdbc-2.3.9.jar:/opt/dolphinscheduler/libs/kyuubi-hive-jdbc-shaded-1.7.0.jar:/opt/dolphinscheduler/libs/client-java-proto-13.0.2.jar:/opt/dolphinscheduler/libs/checker-qual-3.19.0.jar:/opt/dolphinscheduler/libs/jetty-servlet-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/google-cloud-core-grpc-2.10.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-shell-3.2.1.jar:/opt/dolphinscheduler/libs/spring-security-rsa-1.0.10.RELEASE.jar:/opt/dolphinscheduler/libs/avro-1.7.7.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-postgresql-3.2.1.jar:/opt/dolphinscheduler/libs/netty-nio-client-2.17.282.jar:/opt/dolphinscheduler/libs/spring-webmvc-5.3.22.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-mysql-3.2.1.jar:/opt/dolphinscheduler/libs/opentracing-util-0.33.0.jar:/opt/dolphinscheduler/libs/auto-value-1.10.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-all-3.2.1.jar:/opt/dolphinscheduler/libs/jetcd-core-0.5.11.jar:/opt/dolphinscheduler/libs/grpc-context-1.41.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-datasync-3.2.1.jar:/opt/dolphinscheduler/libs/jackson-dataformat-cbor-2.13.3.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-gcs-3.2.1.jar:/opt/dolphinscheduler/libs/client-java-extended-13.0.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-redshift-3.2.1.jar:/opt/dolphinscheduler/libs/opencsv-2.3.jar:/opt/dolphinscheduler/libs/jcip-annotations-1.0-1.jar:/opt/dolphinscheduler/libs/accessors-smart-2.4.8.jar:/opt/dolphinscheduler/libs/hadoop-client-3.2.4.jar:/opt/dolphinscheduler/libs/commons-collections4-4.3.jar:/opt/dolphinscheduler/libs/metrics-core-4.2.11.jar:/opt/dolphinscheduler/libs/netty-resolver-4.1.53.Final.jar:/opt/dolphinscheduler/libs/parquet-hadoop-bundle-1.8.1.jar:/opt/dolphinscheduler/libs/bucket4j-core-6.2.0.jar:/opt/dolphinscheduler/libs/spring-cloud-starter-3.1.3.jar:/opt/dolphinscheduler/libs/mssql-jdbc-11.2.1.jre8.jar:/opt/dolphinscheduler/libs/netty-tcnative-boringssl-static-2.0.53.Final.jar:/opt/dolphinscheduler/libs/kubernetes-model-coordination-5.10.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-linkis-3.2.1.jar:/opt/dolphinscheduler/libs/commons-net-3.6.jar:/opt/dolphinscheduler/libs/netty-transport-native-kqueue-4.1.53.Final-osx-x86_64.jar:/opt/dolphinscheduler/libs/dolphinscheduler-meter-3.2.1.jar:/opt/dolphinscheduler/libs/kubernetes-client-api-6.0.0.jar:/opt/dolphinscheduler/libs/kubernetes-model-certificates-5.10.2.jar:/opt/dolphinscheduler/libs/opencensus-api-0.31.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-mlflow-3.2.1.jar:/opt/dolphinscheduler/libs/kotlin-stdlib-jdk8-1.6.21.jar:/opt/dolphinscheduler/libs/dolphinscheduler-registry-jdbc-3.2.1.jar:/opt/dolphinscheduler/libs/audience-annotations-0.12.0.jar:/opt/dolphinscheduler/libs/simpleclient_httpserver-0.15.0.jar:/opt/dolphinscheduler/libs/jetty-xml-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/kerby-asn1-1.0.1.jar:/opt/dolphinscheduler/libs/lang-tag-1.6.jar:/opt/dolphinscheduler/libs/api-common-2.6.0.jar:/opt/dolphinscheduler/libs/HdrHistogram-2.1.12.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-abs-3.2.1.jar:/opt/dolphinscheduler/libs/failsafe-2.4.4.jar:/opt/dolphinscheduler/libs/hbase-noop-htrace-4.1.1.jar:/opt/dolphinscheduler/libs/jamon-runtime-2.3.1.jar:/opt/dolphinscheduler/libs/jetty-util-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/threetenbp-1.6.5.jar:/opt/dolphinscheduler/libs/jakarta.activation-api-1.2.2.jar:/opt/dolphinscheduler/libs/kubernetes-model-common-5.10.2.jar:/opt/dolphinscheduler/libs/okhttp-4.9.3.jar:/opt/dolphinscheduler/libs/profiles-2.17.282.jar:/opt/dolphinscheduler/libs/hadoop-auth-3.2.4.jar:/opt/dolphinscheduler/libs/grpc-netty-1.41.0.jar:/opt/dolphinscheduler/libs/httpcore-nio-4.4.15.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-seatunnel-3.2.1.jar:/opt/dolphinscheduler/libs/aws-java-sdk-sagemaker-1.12.300.jar:/opt/dolphinscheduler/libs/oshi-core-6.1.1.jar:/opt/dolphinscheduler/libs/bonecp-0.8.0.RELEASE.jar:/opt/dolphinscheduler/libs/jackson-module-parameter-names-2.13.3.jar:/opt/dolphinscheduler/libs/bcutil-jdk15on-1.69.jar:/opt/dolphinscheduler/libs/aws-json-protocol-2.17.282.jar:/opt/dolphinscheduler/libs/dolphinscheduler-extract-base-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-all-3.2.1.jar:/opt/dolphinscheduler/libs/derby-10.14.2.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-snowflake-3.2.1.jar:/opt/dolphinscheduler/libs/netty-codec-http2-4.1.53.Final.jar:/opt/dolphinscheduler/libs/jetty-continuation-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/jackson-mapper-asl-1.9.13.jar:/opt/dolphinscheduler/libs/datanucleus-core-4.1.17.jar:/opt/dolphinscheduler/libs/netty-tcnative-boringssl-static-2.0.53.Final-osx-aarch_64.jar:/opt/dolphinscheduler/libs/failureaccess-1.0.1.jar:/opt/dolphinscheduler/libs/error_prone_annotations-2.5.1.jar:/opt/dolphinscheduler/libs/kerb-admin-1.0.1.jar:/opt/dolphinscheduler/libs/token-provider-1.0.1.jar:/opt/dolphinscheduler/libs/reactor-netty-core-1.0.22.jar:/opt/dolphinscheduler/libs/dolphinscheduler-registry-all-3.2.1.jar:/opt/dolphinscheduler/libs/jakarta.servlet-api-4.0.4.jar:/opt/dolphinscheduler/libs/http-client-spi-2.17.282.jar:/opt/dolphinscheduler/libs/regions-2.17.282.jar:/opt/dolphinscheduler/libs/logback-core-1.2.11.jar:/opt/dolphinscheduler/libs/json-1.8.jar:/opt/dolphinscheduler/libs/gax-grpc-2.23.0.jar:/opt/dolphinscheduler/libs/google-http-client-1.42.3.jar:/opt/dolphinscheduler/libs/hive-serde-2.3.9.jar:/opt/dolphinscheduler/libs/jettison-1.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-http-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-registry-zookeeper-3.2.1.jar:/opt/dolphinscheduler/libs/spring-security-crypto-5.7.3.jar:/opt/dolphinscheduler/libs/auth-2.17.282.jar:/opt/dolphinscheduler/libs/proto-google-cloud-storage-v2-2.18.0-alpha.jar:/opt/dolphinscheduler/libs/jetty-server-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/javax.annotation-api-1.3.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-starrocks-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-dataquality-3.2.1.jar:/opt/dolphinscheduler/libs/jcl-over-slf4j-1.7.36.jar:/opt/dolphinscheduler/libs/commons-lang3-3.12.0.jar:/opt/dolphinscheduler/libs/tomcat-embed-el-9.0.65.jar:/opt/dolphinscheduler/libs/opentracing-noop-0.33.0.jar:/opt/dolphinscheduler/libs/client-java-13.0.2.jar:/opt/dolphinscheduler/libs/spring-beans-5.3.22.jar:/opt/dolphinscheduler/libs/snakeyaml-1.33.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-ssh-3.2.1.jar:/opt/dolphinscheduler/libs/commons-pool-1.6.jar:/opt/dolphinscheduler/libs/javax.servlet-api-3.1.0.jar:/opt/dolphinscheduler/libs/hadoop-common-3.2.4.jar:/opt/dolphinscheduler/libs/kubernetes-model-apiextensions-5.10.2.jar:/opt/dolphinscheduler/libs/spring-boot-2.7.3.jar:/opt/dolphinscheduler/libs/bcprov-ext-jdk15on-1.69.jar:/opt/dolphinscheduler/libs/spring-boot-starter-2.7.3.jar:/opt/dolphinscheduler/libs/paranamer-2.3.jar:/opt/dolphinscheduler/libs/httpmime-4.5.13.jar:/opt/dolphinscheduler/libs/reactor-core-3.4.22.jar:/opt/dolphinscheduler/libs/azure-core-1.36.0.jar:/opt/dolphinscheduler/libs/bcpkix-jdk15on-1.69.jar:/opt/dolphinscheduler/libs/kubernetes-model-scheduling-5.10.2.jar:/opt/dolphinscheduler/libs/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/dolphinscheduler/libs/websocket-client-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/unirest-java-3.7.04-standalone.jar:/opt/dolphinscheduler/libs/hadoop-mapreduce-client-core-3.2.4.jar:/opt/dolphinscheduler/libs/google-auth-library-credentials-1.15.0.jar:/opt/dolphinscheduler/libs/azure-storage-internal-avro-12.6.0.jar:/opt/dolphinscheduler/libs/jackson-datatype-jdk8-2.13.3.jar:/opt/dolphinscheduler/libs/spring-expression-5.3.22.jar:/opt/dolphinscheduler/libs/aspectjweaver-1.9.7.jar:/opt/dolphinscheduler/libs/websocket-common-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/client-java-api-fluent-13.0.2.jar:/opt/dolphinscheduler/libs/mybatis-plus-3.5.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-athena-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-oss-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-openmldb-3.2.1.jar:/opt/dolphinscheduler/libs/curator-recipes-5.3.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-api-3.2.1.jar:/opt/dolphinscheduler/libs/netty-all-4.1.53.Final.jar:/opt/dolphinscheduler/libs/netty-resolver-dns-4.1.53.Final.jar:/opt/dolphinscheduler/libs/kubernetes-model-autoscaling-5.10.2.jar:/opt/dolphinscheduler/libs/kerb-util-1.0.1.jar:/opt/dolphinscheduler/libs/grpc-alts-1.41.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-presto-3.2.1.jar:/opt/dolphinscheduler/libs/kerb-simplekdc-1.0.1.jar:/opt/dolphinscheduler/libs/protobuf-java-util-3.17.2.jar:/opt/dolphinscheduler/libs/azure-core-http-netty-1.13.0.jar:/opt/dolphinscheduler/libs/transaction-api-1.1.jar:/opt/dolphinscheduler/libs/datanucleus-api-jdo-4.2.4.jar:/opt/dolphinscheduler/libs/zeppelin-common-0.10.1.jar:/opt/dolphinscheduler/libs/zt-zip-1.15.jar:/opt/dolphinscheduler/libs/animal-sniffer-annotations-1.19.jar:/opt/dolphinscheduler/libs/google-http-client-jackson2-1.42.3.jar:/opt/dolphinscheduler/libs/netty-buffer-4.1.53.Final.jar:/opt/dolphinscheduler/libs/jsr305-3.0.0.jar:/opt/dolphinscheduler/libs/netty-transport-classes-epoll-4.1.79.Final.jar:/opt/dolphinscheduler/libs/spring-boot-actuator-autoconfigure-2.7.3.jar:/opt/dolphinscheduler/libs/simpleclient-0.15.0.jar:/opt/dolphinscheduler/libs/aliyun-sdk-oss-3.15.1.jar:/opt/dolphinscheduler/libs/json-utils-2.17.282.jar:/opt/dolphinscheduler/libs/tephra-api-0.6.0.jar:/opt/dolphinscheduler/libs/spring-jdbc-5.3.22.jar:/opt/dolphinscheduler/libs/grpc-xds-1.41.0.jar:/opt/dolphinscheduler/libs/logback-classic-1.2.11.jar:/opt/dolphinscheduler/libs/google-cloud-storage-2.18.0.jar:/opt/dolphinscheduler/libs/micrometer-registry-prometheus-1.9.3.jar:/opt/dolphinscheduler/libs/grpc-core-1.41.0.jar:/opt/dolphinscheduler/libs/aws-java-sdk-kms-1.12.300.jar:/opt/dolphinscheduler/libs/kubernetes-model-rbac-5.10.2.jar:/opt/dolphinscheduler/libs/ini4j-0.5.4.jar:/opt/dolphinscheduler/libs/spring-boot-starter-web-2.7.3.jar:/opt/dolphinscheduler/libs/spring-cloud-commons-3.1.3.jar:/opt/dolphinscheduler/libs/netty-codec-http-4.1.53.Final.jar:/opt/dolphinscheduler/libs/jetty-client-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/jetcd-common-0.5.11.jar:/opt/dolphinscheduler/libs/metrics-spi-2.17.282.jar:/opt/dolphinscheduler/libs/utils-2.17.282.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-emr-3.2.1.jar:/opt/dolphinscheduler/libs/protocol-core-2.17.282.jar:/opt/dolphinscheduler/libs/micrometer-core-1.9.3.jar:/opt/dolphinscheduler/libs/netty-transport-native-unix-common-4.1.53.Final.jar:/opt/dolphinscheduler/libs/zjsonpatch-0.4.11.jar:/opt/dolphinscheduler/libs/annotations-2.17.282.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-sql-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-extract-common-3.2.1.jar:/opt/dolphinscheduler/libs/apache-client-2.17.282.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-oceanbase-3.2.1.jar:/opt/dolphinscheduler/libs/jdo-api-3.0.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-datax-3.2.1.jar:/opt/dolphinscheduler/libs/postgresql-42.4.1.jar:/opt/dolphinscheduler/libs/jetty-util-ajax-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/gax-2.23.0.jar:/opt/dolphinscheduler/libs/grpc-stub-1.41.0.jar:/opt/dolphinscheduler/libs/libfb303-0.9.3.jar:/opt/dolphinscheduler/libs/spring-core-5.3.22.jar:/opt/dolphinscheduler/libs/jaxb-api-2.3.1.jar:/opt/dolphinscheduler/libs/hive-service-rpc-2.3.9.jar:/opt/dolphinscheduler/libs/kubernetes-model-flowcontrol-5.10.2.jar:/opt/dolphinscheduler/libs/commons-logging-1.1.1.jar:/opt/dolphinscheduler/libs/mybatis-spring-2.0.7.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-oracle-3.2.1.jar:/opt/dolphinscheduler/libs/opencensus-proto-0.2.0.jar:/opt/dolphinscheduler/libs/grpc-protobuf-1.41.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-clickhouse-3.2.1.jar:/opt/dolphinscheduler/libs/spring-cloud-starter-bootstrap-3.1.3.jar:/opt/dolphinscheduler/libs/kubernetes-model-admissionregistration-5.10.2.jar:/opt/dolphinscheduler/libs/grpc-google-cloud-storage-v2-2.18.0-alpha.jar:/opt/dolphinscheduler/libs/esdk-obs-java-bundle-3.23.3.jar:/opt/dolphinscheduler/libs/dnsjava-2.1.7.jar:/opt/dolphinscheduler/libs/asm-9.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-spark-3.2.1.jar:/opt/dolphinscheduler/libs/netty-tcnative-boringssl-static-2.0.53.Final-linux-aarch_64.jar:/opt/dolphinscheduler/libs/re2j-1.6.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-vertica-3.2.1.jar:/opt/dolphinscheduler/libs/json-smart-2.4.8.jar:/opt/dolphinscheduler/libs/reactor-netty-http-1.0.22.jar:/opt/dolphinscheduler/libs/google-api-services-storage-v1-rev20220705-2.0.0.jar:/opt/dolphinscheduler/libs/kubernetes-client-6.0.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-kyuubi-3.2.1.jar:/opt/dolphinscheduler/libs/auto-value-annotations-1.10.1.jar:/opt/dolphinscheduler/libs/commons-cli-1.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-data-quality-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-chunjun-3.2.1.jar:/opt/dolphinscheduler/libs/kerb-server-1.0.1.jar:/opt/dolphinscheduler/libs/content-type-2.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-remoteshell-3.2.1.jar:/opt/dolphinscheduler/libs/opencensus-contrib-http-util-0.31.1.jar:/opt/dolphinscheduler/libs/druid-1.2.20.jar:/opt/dolphinscheduler/libs/javolution-5.5.1.jar:/opt/dolphinscheduler/libs/protobuf-java-3.17.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-db2-3.2.1.jar:/opt/dolphinscheduler/libs/aws-java-sdk-core-1.12.300.jar:/opt/dolphinscheduler/libs/spring-boot-starter-logging-2.7.3.jar:/opt/dolphinscheduler/libs/kerby-pkix-1.0.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-procedure-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-registry-etcd-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-sqoop-3.2.1.jar:/opt/dolphinscheduler/libs/zookeeper-jute-3.8.0.jar:/opt/dolphinscheduler/libs/netty-resolver-dns-native-macos-4.1.53.Final-osx-x86_64.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-sagemaker-3.2.1.jar:/opt/dolphinscheduler/libs/spring-boot-configuration-processor-2.6.1.jar:/opt/dolphinscheduler/libs/hive-common-2.3.9.jar:/opt/dolphinscheduler/libs/kerb-common-1.0.1.jar:/opt/dolphinscheduler/libs/stax-api-1.0.1.jar:/opt/dolphinscheduler/libs/kubernetes-model-storageclass-5.10.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-s3-3.2.1.jar:/opt/dolphinscheduler/libs/spring-boot-starter-jetty-2.7.3.jar:/opt/dolphinscheduler/libs/okio-2.8.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-dms-3.2.1.jar:/opt/dolphinscheduler/libs/simpleclient_common-0.15.0.jar:/opt/dolphinscheduler/libs/sdk-core-2.17.282.jar:/opt/dolphinscheduler/libs/javax.activation-api-1.2.0.jar:/opt/dolphinscheduler/libs/netty-handler-proxy-4.1.53.Final.jar:/opt/dolphinscheduler/libs/kerby-config-1.0.1.jar:/opt/dolphinscheduler/libs/netty-tcnative-classes-2.0.53.Final.jar:/opt/dolphinscheduler/libs/jackson-jaxrs-base-2.13.3.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-trino-3.2.1.jar:/opt/dolphinscheduler/libs/presto-jdbc-0.238.1.jar:/opt/dolphinscheduler/libs/websocket-api-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-flink-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-api-3.2.1.jar:/opt/dolphinscheduler/libs/kubernetes-model-metrics-5.10.2.jar:/opt/dolphinscheduler/libs/datasync-2.17.282.jar:/opt/dolphinscheduler/libs/hadoop-yarn-api-3.2.4.jar:/opt/dolphinscheduler/libs/google-http-client-apache-v2-1.42.3.jar:/opt/dolphinscheduler/libs/hadoop-annotations-3.2.4.jar:/opt/dolphinscheduler/libs/google-oauth-client-1.34.1.jar:/opt/dolphinscheduler/libs/sshd-common-2.8.0.jar:/opt/dolphinscheduler/libs/LatencyUtils-2.0.3.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-spark-3.2.1.jar:/opt/dolphinscheduler/libs/slf4j-api-1.7.36.jar:/opt/dolphinscheduler/libs/snowflake-jdbc-3.13.29.jar:/opt/dolphinscheduler/libs/jackson-datatype-jsr310-2.13.3.jar:/opt/dolphinscheduler/libs/trino-jdbc-402.jar:/opt/dolphinscheduler/libs/logging-interceptor-4.9.3.jar:/opt/dolphinscheduler/libs/simpleclient_tracer_otel_agent-0.15.0.jar:/opt/dolphinscheduler/libs/janino-3.0.16.jar:/opt/dolphinscheduler/libs/jackson-dataformat-yaml-2.13.3.jar:/opt/dolphinscheduler/libs/ion-java-1.0.2.jar:/opt/dolphinscheduler/libs/commons-dbcp-1.4.jar:/opt/dolphinscheduler/libs/jsp-api-2.1.jar:/opt/dolphinscheduler/libs/google-http-client-gson-1.42.3.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-hivecli-3.2.1.jar:/opt/dolphinscheduler/libs/spring-boot-actuator-2.7.3.jar:/opt/dolphinscheduler/libs/google-cloud-core-http-2.10.0.jar:/opt/dolphinscheduler/libs/DmJdbcDriver18-8.1.2.79.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-java-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-dameng-3.2.1.jar:/opt/dolphinscheduler/libs/sshd-sftp-2.8.0.jar:/opt/dolphinscheduler/libs/kerb-crypto-1.0.1.jar:/opt/dolphinscheduler/libs/conscrypt-openjdk-uber-2.5.2.jar:/opt/dolphinscheduler/libs/httpcore-4.4.15.jar:/opt/dolphinscheduler/libs/lz4-java-1.4.0.jar:/opt/dolphinscheduler/libs/guava-retrying-2.0.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-flink-stream-3.2.1.jar:/opt/dolphinscheduler/libs/spring-tx-5.3.22.jar:/opt/dolphinscheduler/libs/grpc-auth-1.41.0.jar:/opt/dolphinscheduler/libs/netty-tcnative-boringssl-static-2.0.53.Final-osx-x86_64.jar:/opt/dolphinscheduler/libs/databend-jdbc-0.0.7.jar:/opt/dolphinscheduler/libs/bcprov-jdk15on-1.69.jar:/opt/dolphinscheduler/libs/commons-lang-2.6.jar:/opt/dolphinscheduler/libs/kubernetes-model-policy-5.10.2.jar:/opt/dolphinscheduler/libs/commons-io-2.11.0.jar:/opt/dolphinscheduler/libs/grpc-grpclb-1.41.0.jar:/opt/dolphinscheduler/libs/netty-tcnative-boringssl-static-2.0.53.Final-linux-x86_64.jar:/opt/dolphinscheduler/libs/opentracing-api-0.33.0.jar:/opt/dolphinscheduler/libs/sshd-scp-2.8.0.jar:/opt/dolphinscheduler/libs/reload4j-1.2.18.3.jar:/opt/dolphinscheduler/libs/netty-tcnative-2.0.48.Final.jar:/opt/dolphinscheduler/libs/jdom2-2.0.6.1.jar:/opt/dolphinscheduler/libs/spring-boot-starter-json-2.7.3.jar:/opt/dolphinscheduler/libs/netty-transport-native-epoll-4.1.53.Final.jar:/opt/dolphinscheduler/libs/google-cloud-core-2.10.0.jar:/opt/dolphinscheduler/libs/javax.jdo-3.2.0-m3.jar:/opt/dolphinscheduler/libs/gax-httpjson-0.108.0.jar:/opt/dolphinscheduler/libs/mybatis-plus-core-3.5.2.jar:/opt/dolphinscheduler/libs/auto-service-annotations-1.0.1.jar:/opt/dolphinscheduler/libs/nimbus-jose-jwt-9.22.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-zeppelin-3.2.1.jar:/opt/dolphinscheduler/libs/commons-compress-1.21.jar:/opt/dolphinscheduler/libs/hadoop-hdfs-client-3.2.4.jar:/opt/dolphinscheduler/libs/msal4j-persistence-extension-1.1.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-pytorch-3.2.1.jar:/opt/dolphinscheduler/libs/netty-tcnative-boringssl-static-2.0.53.Final-windows-x86_64.jar:/opt/dolphinscheduler/libs/jetty-servlets-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/woodstox-core-6.4.0.jar:/opt/dolphinscheduler/libs/spring-cloud-kubernetes-commons-2.1.3.jar:/opt/dolphinscheduler/libs/grpc-protobuf-lite-1.41.0.jar:/opt/dolphinscheduler/libs/jetty-webapp-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/eventstream-1.0.1.jar:/opt/dolphinscheduler/libs/commons-compiler-3.1.7.jar:/opt/dolphinscheduler/libs/netty-transport-4.1.53.Final.jar:/opt/dolphinscheduler/libs/spring-cloud-context-3.1.3.jar:/opt/dolphinscheduler/libs/aws-java-sdk-dms-1.12.300.jar:/opt/dolphinscheduler/libs/hive-storage-api-2.4.0.jar:/opt/dolphinscheduler/libs/client-java-spring-integration-13.0.2.jar:/opt/dolphinscheduler/libs/spring-boot-starter-actuator-2.7.3.jar:/opt/dolphinscheduler/libs/third-party-jackson-core-2.17.282.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-hdfs-3.2.1.jar:/opt/dolphinscheduler/libs/netty-codec-4.1.53.Final.jar:/opt/dolphinscheduler/libs/google-http-client-appengine-1.42.3.jar:/opt/dolphinscheduler/libs/commons-configuration2-2.1.1.jar:/opt/dolphinscheduler/libs/datanucleus-rdbms-4.1.19.jar:/opt/dolphinscheduler/libs/swagger-annotations-1.6.2.jar:/opt/dolphinscheduler/libs/simpleclient_tracer_otel-0.15.0.jar:/opt/dolphinscheduler/libs/kotlin-stdlib-common-1.6.21.jar:/opt/dolphinscheduler/libs/aws-core-2.17.282.jar:/opt/dolphinscheduler/libs/kerb-core-1.0.1.jar:/opt/dolphinscheduler/libs/httpasyncclient-4.1.5.jar:/opt/dolphinscheduler/libs/dolphinscheduler-extract-worker-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-spi-3.2.1.jar:/opt/dolphinscheduler/libs/okhttp-2.7.5.jar:/opt/dolphinscheduler/libs/google-api-client-2.2.0.jar:/opt/dolphinscheduler/libs/kotlin-stdlib-1.6.21.jar:/opt/dolphinscheduler/libs/jakarta.websocket-api-1.1.2.jar:/opt/dolphinscheduler/libs/libthrift-0.9.3.jar:/opt/dolphinscheduler/libs/spring-boot-starter-aop-2.7.3.jar:/opt/dolphinscheduler/libs/netty-common-4.1.53.Final.jar:/opt/dolphinscheduler/libs/log4j-1.2-api-2.17.2.jar:/opt/dolphinscheduler/libs/jackson-databind-2.13.4.jar:/opt/dolphinscheduler/libs/jackson-dataformat-xml-2.13.3.jar:/opt/dolphinscheduler/libs/kubernetes-model-events-5.10.2.jar:/opt/dolphinscheduler/libs/gson-2.9.1.jar:/opt/dolphinscheduler/libs/proto-google-iam-v1-1.9.0.jar:/opt/dolphinscheduler/libs/netty-codec-socks-4.1.53.Final.jar:/opt/dolphinscheduler/libs/zjsonpatch-0.3.0.jar:/opt/dolphinscheduler/libs/hadoop-mapreduce-client-common-3.2.4.jar:/opt/dolphinscheduler/libs/dolphinscheduler-registry-api-3.2.1.jar:/opt/dolphinscheduler/libs/azure-storage-blob-12.21.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-zeppelin-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-api-3.2.1.jar:/opt/dolphinscheduler/libs/aws-java-sdk-s3-1.12.300.jar:/opt/dolphinscheduler/libs/stax2-api-4.2.1.jar:/opt/dolphinscheduler/libs/jakarta.annotation-api-1.3.5.jar:/opt/dolphinscheduler/libs/kubernetes-model-discovery-5.10.2.jar:/opt/dolphinscheduler/libs/jna-5.10.0.jar:/opt/dolphinscheduler/libs/spring-jcl-5.3.22.jar
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:48.871 +0800 o.a.z.ZooKeeper:[98] - Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:48.872 +0800 o.a.z.ZooKeeper:[98] - Client environment:java.io.tmpdir=/tmp
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:48.872 +0800 o.a.z.ZooKeeper:[98] - Client environment:java.compiler=<NA>
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:48.872 +0800 o.a.z.ZooKeeper:[98] - Client environment:os.name=Linux
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:48.872 +0800 o.a.z.ZooKeeper:[98] - Client environment:os.arch=amd64
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:48.872 +0800 o.a.z.ZooKeeper:[98] - Client environment:os.version=6.5.0-28-generic
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:48.872 +0800 o.a.z.ZooKeeper:[98] - Client environment:user.name=root
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:48.872 +0800 o.a.z.ZooKeeper:[98] - Client environment:user.home=/root
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:48.873 +0800 o.a.z.ZooKeeper:[98] - Client environment:user.dir=/opt/dolphinscheduler
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:48.873 +0800 o.a.z.ZooKeeper:[98] - Client environment:os.memory.free=3223MB
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:48.873 +0800 o.a.z.ZooKeeper:[98] - Client environment:os.memory.max=3840MB
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:48.873 +0800 o.a.z.ZooKeeper:[98] - Client environment:os.memory.total=3840MB
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:48.886 +0800 o.a.z.ZooKeeper:[637] - Initiating client connection, connectString=dolphinscheduler-zookeeper:2181 sessionTimeout=30000 watcher=org.apache.curator.ConnectionState@6996bbc4
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:48.910 +0800 o.a.z.c.X509Util:[77] - Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:48.918 +0800 o.a.z.ClientCnxnSocket:[239] - jute.maxbuffer value is 1048575 Bytes
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:48.978 +0800 o.a.z.ClientCnxn:[1732] - zookeeper.request.timeout value is 0. feature enabled=false
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:49.041 +0800 o.a.c.f.i.CuratorFrameworkImpl:[386] - Default schema
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:49.141 +0800 o.a.z.ClientCnxn:[1171] - Opening socket connection to server dolphinscheduler-zookeeper/172.18.0.6:2181.
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:49.281 +0800 o.a.z.ClientCnxn:[1173] - SASL config status: Will not attempt to authenticate using SASL (unknown error)
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:49.288 +0800 o.a.z.ClientCnxn:[1005] - Socket connection established, initiating session, client: /172.18.1.1:55808, server: dolphinscheduler-zookeeper/172.18.0.6:2181
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:49.494 +0800 o.a.z.ClientCnxn:[1444] - Session establishment complete on server dolphinscheduler-zookeeper/172.18.0.6:2181, session id = 0x10001f12a3f0001, negotiated timeout = 30000
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:49.778 +0800 o.a.c.f.s.ConnectionStateManager:[252] - State change: CONNECTED
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:50.277 +0800 o.a.c.f.i.EnsembleTracker:[201] - New config event received: {}
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:50.396 +0800 o.a.c.f.i.EnsembleTracker:[201] - New config event received: {}
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:50.876 +0800 o.a.d.s.w.r.WorkerRpcServer:[41] - WorkerRpcServer starting...
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:51.578 +0800 o.a.d.e.b.NettyRemotingServer:[112] - WorkerRpcServer bind success at port: 1234
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:51.580 +0800 o.a.d.s.w.r.WorkerRpcServer:[43] - WorkerRpcServer started...
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:51.760 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: JAVA - JavaTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:51.802 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: JAVA - JavaTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:52.099 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: JUPYTER - JupyterTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:52.101 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: JUPYTER - JupyterTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:52.102 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: SPARK - SparkTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:52.105 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: SPARK - SparkTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:52.114 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: FLINK_STREAM - FlinkStreamTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:52.118 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: FLINK_STREAM - FlinkStreamTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:52.128 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: PYTHON - PythonTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:52.129 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: PYTHON - PythonTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:52.144 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: DATASYNC - DatasyncTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:52.145 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: DATASYNC - DatasyncTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:52.160 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: DATA_FACTORY - DatafactoryTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:52.162 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: DATA_FACTORY - DatafactoryTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:52.163 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: CHUNJUN - ChunJunTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:52.165 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: CHUNJUN - ChunJunTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:52.166 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: REMOTESHELL - RemoteShellTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:52.168 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: REMOTESHELL - RemoteShellTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:52.178 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: PIGEON - PigeonTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:52.180 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: PIGEON - PigeonTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:52.547 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: SHELL - ShellTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:52.549 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: SHELL - ShellTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:52.549 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: PROCEDURE - ProcedureTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:52.551 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: PROCEDURE - ProcedureTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:52.554 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: MR - MapReduceTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:52.556 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: MR - MapReduceTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:52.560 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: SQOOP - SqoopTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:52.563 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: SQOOP - SqoopTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:52.563 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: PYTORCH - PytorchTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:52.565 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: PYTORCH - PytorchTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:52.566 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: K8S - K8sTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:52.568 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: K8S - K8sTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:52.568 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: SEATUNNEL - SeatunnelTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:52.571 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: SEATUNNEL - SeatunnelTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:52.571 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: SAGEMAKER - SagemakerTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:52.573 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: SAGEMAKER - SagemakerTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:52.574 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: HTTP - HttpTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:52.577 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: HTTP - HttpTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:52.578 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: EMR - EmrTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:52.582 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: EMR - EmrTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:52.583 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: DMS - DmsTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:52.585 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: DMS - DmsTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:52.586 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: DATA_QUALITY - DataQualityTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:52.588 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: DATA_QUALITY - DataQualityTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:52.588 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: KUBEFLOW - KubeflowTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:52.590 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: KUBEFLOW - KubeflowTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:52.591 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: SQL - SqlTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:52.593 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: SQL - SqlTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:52.594 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: DVC - DvcTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:52.595 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: DVC - DvcTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:52.596 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: DATAX - DataxTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:52.598 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: DATAX - DataxTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:52.599 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: ZEPPELIN - ZeppelinTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:52.602 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: ZEPPELIN - ZeppelinTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:52.603 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: DINKY - DinkyTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:52.605 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: DINKY - DinkyTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:52.606 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: MLFLOW - MlflowTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:52.608 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: MLFLOW - MlflowTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:52.608 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: OPENMLDB - OpenmldbTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:52.610 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: OPENMLDB - OpenmldbTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:52.611 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: LINKIS - LinkisTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:52.613 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: LINKIS - LinkisTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:52.634 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: FLINK - FlinkTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:52.636 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: FLINK - FlinkTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:52.636 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: HIVECLI - HiveCliTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:52.639 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: HIVECLI - HiveCliTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:52.731 +0800 o.a.d.c.u.JSONUtils:[72] - init timezone: sun.util.calendar.ZoneInfo[id="Asia/Shanghai",offset=28800000,dstSavings=0,useDaylight=false,transitions=31,lastRule=null]
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:53.066 +0800 o.a.d.s.w.r.WorkerRegistryClient:[104] - Worker node: 172.18.1.1:1234 registry to ZK /nodes/worker/172.18.1.1:1234 successfully
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:54.122 +0800 o.a.d.c.m.BaseHeartBeatTask:[48] - Starting WorkerHeartBeatTask...
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:54.129 +0800 o.a.d.c.m.BaseHeartBeatTask:[50] - Started WorkerHeartBeatTask, heartBeatInterval: 10000...
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:54.130 +0800 o.a.d.s.w.r.WorkerRegistryClient:[114] - Worker node: 172.18.1.1:1234 registry finished
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:54.156 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.2641509433962264 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:54.162 +0800 o.a.d.s.w.m.MessageRetryRunner:[69] - Message retry runner staring
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:54.303 +0800 o.a.d.s.w.m.MessageRetryRunner:[72] - Injected message sender: TaskInstanceExecutionFinishEventSender
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:54.424 +0800 o.a.d.s.w.m.MessageRetryRunner:[72] - Injected message sender: TaskInstanceExecutionInfoUpdateEventSender
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:54.425 +0800 o.a.d.s.w.m.MessageRetryRunner:[72] - Injected message sender: TaskInstanceExecutionRunningEventSender
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:54.426 +0800 o.a.d.s.w.m.MessageRetryRunner:[75] - Message retry runner started
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:55.343 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.2417061611374407 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:56.617 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.9134615384615383 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:57.645 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.4709677419354839 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:58.707 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.392156862745098 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-29 17:40:59.806 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.2425531914893617 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-29 17:41:00.971 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.1111111111111112 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-29 17:41:02.028 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.1330798479087452 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-29 17:41:03.977 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.2986577181208054 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-29 17:41:05.034 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.7248322147651005 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-29 17:41:06.065 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.3354827466016033 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-29 17:41:07.182 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.258829614304714 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-29 17:41:08.208 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.3106796116504855 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-29 17:41:09.475 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.8478260869565217 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-29 17:41:10.493 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.489795918367347 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-29 17:41:11.537 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.28125 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-29 17:41:12.542 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.2202643171806167 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-29 17:41:13.566 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.763157894736842 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-29 17:41:13.566 +0800 o.s.b.a.e.w.EndpointLinksResolver:[58] - Exposing 3 endpoint(s) beneath base path '/actuator'
[WI-0][TI-0] - [INFO] 2024-04-29 17:41:14.231 +0800 o.e.j.s.h.C.application:[2368] - Initializing Spring DispatcherServlet 'dispatcherServlet'
[WI-0][TI-0] - [INFO] 2024-04-29 17:41:14.247 +0800 o.s.w.s.DispatcherServlet:[525] - Initializing Servlet 'dispatcherServlet'
[WI-0][TI-0] - [INFO] 2024-04-29 17:41:14.257 +0800 o.s.w.s.DispatcherServlet:[547] - Completed initialization in 3 ms
[WI-0][TI-0] - [INFO] 2024-04-29 17:41:14.350 +0800 o.e.j.s.AbstractConnector:[333] - Started ServerConnector@acb5508{HTTP/1.1, (http/1.1)}{0.0.0.0:1235}
[WI-0][TI-0] - [INFO] 2024-04-29 17:41:14.359 +0800 o.s.b.w.e.j.JettyWebServer:[172] - Jetty started on port(s) 1235 (http/1.1) with context path '/'
[WI-0][TI-0] - [INFO] 2024-04-29 17:41:14.437 +0800 o.a.d.s.w.WorkerServer:[61] - Started WorkerServer in 57.239 seconds (JVM running for 60.394)
[WI-0][TI-0] - [INFO] 2024-04-29 17:41:14.572 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.281767955801105 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-29 17:41:15.584 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.2176470588235295 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-29 17:41:16.918 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9606986899563319 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-29 17:41:17.957 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9064039408866995 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-29 17:41:20.028 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9153846153846154 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-29 17:41:21.066 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.725609756097561 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-29 17:41:22.073 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7534246575342466 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-29 17:41:28.411 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8222222222222222 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-29 17:41:40.490 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8660968660968661 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-29 17:41:41.508 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.851063829787234 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-29 17:41:43.575 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8633333333333334 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-29 17:41:46.658 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8130311614730878 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-29 17:41:53.823 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7647058823529411 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-29 17:41:55.809 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=2034, taskName=consume_filtered_data, firstSubmitTime=1714383715239, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.12:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13426477386080, processDefineVersion=8, appIds=null, processInstanceId=748, scheduleTime=0, globalParams=null, executorId=1, cmdTypeIfComplement=7, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[],"rawScript":"# /bin/kafka-console-consumer.sh \\\n#     --bootstrap-server kafka:9092 \\\n#     --topic reddit_post_filtered \\\n#     --max-messages 10 \\\n#     --from-beginning \\\n#     --group filtered_data_consumer \n#     --timeout-ms 15000","resourceList":[]}, environmentConfig=export JAVA_HOME=/opt/java/openjdk, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='consume_filtered_data'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, query=Property{prop='query', direct=OUT, type=VARCHAR, value=''}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240429'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='2034'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13433255983872'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240429174155'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='748'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240428'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='es_filtered_data_persistence_subprocess'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13426477386080'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"query","direct":"OUT","type":"VARCHAR","value":""}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-0][TI-0] - [INFO] 2024-04-29 17:41:55.892 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8181818181818181 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-748][TI-2034] - [INFO] 2024-04-29 17:41:55.953 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: consume_filtered_data to wait queue success
[WI-748][TI-2034] - [INFO] 2024-04-29 17:41:55.966 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2034] - [INFO] 2024-04-29 17:41:55.970 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-748][TI-2034] - [INFO] 2024-04-29 17:41:55.970 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2034] - [INFO] 2024-04-29 17:41:55.971 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-748][TI-2034] - [INFO] 2024-04-29 17:41:55.972 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1714383715971
[WI-748][TI-2034] - [INFO] 2024-04-29 17:41:55.973 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 748_2034
[WI-748][TI-2034] - [INFO] 2024-04-29 17:41:55.992 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 2034,
  "taskName" : "consume_filtered_data",
  "firstSubmitTime" : 1714383715239,
  "startTime" : 1714383715971,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.12:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240429/13426477386080/8/748/2034.log",
  "processId" : 0,
  "processDefineCode" : 13426477386080,
  "processDefineVersion" : 8,
  "processInstanceId" : 748,
  "scheduleTime" : 0,
  "executorId" : 1,
  "cmdTypeIfComplement" : 7,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[],\"rawScript\":\"# /bin/kafka-console-consumer.sh \\\\\\n#     --bootstrap-server kafka:9092 \\\\\\n#     --topic reddit_post_filtered \\\\\\n#     --max-messages 10 \\\\\\n#     --from-beginning \\\\\\n#     --group filtered_data_consumer \\n#     --timeout-ms 15000\",\"resourceList\":[]}",
  "environmentConfig" : "export JAVA_HOME=/opt/java/openjdk",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "consume_filtered_data"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "query" : {
      "prop" : "query",
      "direct" : "OUT",
      "type" : "VARCHAR",
      "value" : ""
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240429"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "2034"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13433255983872"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240429174155"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "748"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240428"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "es_filtered_data_persistence_subprocess"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13426477386080"
    }
  },
  "taskAppId" : "748_2034",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"query\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-748][TI-2034] - [INFO] 2024-04-29 17:41:56.007 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2034] - [INFO] 2024-04-29 17:41:56.011 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-748][TI-2034] - [INFO] 2024-04-29 17:41:56.011 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2034] - [INFO] 2024-04-29 17:41:56.125 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-748][TI-2034] - [INFO] 2024-04-29 17:41:56.152 +0800 o.a.d.c.u.OSUtils:[231] - create linux os user: default
[WI-748][TI-2034] - [INFO] 2024-04-29 17:41:56.154 +0800 o.a.d.c.u.OSUtils:[233] - execute cmd: sudo useradd -g root
 default
[WI-748][TI-2034] - [INFO] 2024-04-29 17:41:56.250 +0800 o.a.d.c.u.OSUtils:[190] - create user default success
[WI-748][TI-2034] - [INFO] 2024-04-29 17:41:56.251 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-748][TI-2034] - [INFO] 2024-04-29 17:41:56.255 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_8/748/2034 check successfully
[WI-748][TI-2034] - [INFO] 2024-04-29 17:41:56.257 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-748][TI-2034] - [INFO] 2024-04-29 17:41:56.268 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-748][TI-2034] - [INFO] 2024-04-29 17:41:56.281 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-748][TI-2034] - [INFO] 2024-04-29 17:41:56.290 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-748][TI-2034] - [INFO] 2024-04-29 17:41:56.294 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ ],
  "varPool" : null,
  "rawScript" : "# /bin/kafka-console-consumer.sh \\\n#     --bootstrap-server kafka:9092 \\\n#     --topic reddit_post_filtered \\\n#     --max-messages 10 \\\n#     --from-beginning \\\n#     --group filtered_data_consumer \n#     --timeout-ms 15000",
  "resourceList" : [ ]
}
[WI-748][TI-2034] - [INFO] 2024-04-29 17:41:56.295 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-748][TI-2034] - [INFO] 2024-04-29 17:41:56.295 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"query","direct":"OUT","type":"VARCHAR","value":""}] successfully
[WI-748][TI-2034] - [INFO] 2024-04-29 17:41:56.301 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2034] - [INFO] 2024-04-29 17:41:56.302 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-748][TI-2034] - [INFO] 2024-04-29 17:41:56.303 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2034] - [INFO] 2024-04-29 17:41:56.331 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-748][TI-2034] - [INFO] 2024-04-29 17:41:56.333 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-748][TI-2034] - [INFO] 2024-04-29 17:41:56.333 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export JAVA_HOME=/opt/java/openjdk
# /bin/kafka-console-consumer.sh \
#     --bootstrap-server kafka:9092 \
#     --topic reddit_post_filtered \
#     --max-messages 10 \
#     --from-beginning \
#     --group filtered_data_consumer 
#     --timeout-ms 15000
[WI-748][TI-2034] - [INFO] 2024-04-29 17:41:56.333 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-748][TI-2034] - [INFO] 2024-04-29 17:41:56.336 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_8/748/2034/748_2034.sh
[WI-748][TI-2034] - [INFO] 2024-04-29 17:41:56.354 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 88
[WI-0][TI-2034] - [INFO] 2024-04-29 17:41:56.650 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=2034, success=true)
[WI-0][TI-2034] - [INFO] 2024-04-29 17:41:56.668 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=2034)
[WI-0][TI-0] - [INFO] 2024-04-29 17:41:57.356 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
[WI-748][TI-2034] - [INFO] 2024-04-29 17:41:57.361 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_8/748/2034, processId:88 ,exitStatusCode:0 ,processWaitForStatus:true ,processExitValue:0
[WI-748][TI-2034] - [INFO] 2024-04-29 17:41:57.362 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2034] - [INFO] 2024-04-29 17:41:57.363 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-748][TI-2034] - [INFO] 2024-04-29 17:41:57.364 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2034] - [INFO] 2024-04-29 17:41:57.369 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-748][TI-2034] - [INFO] 2024-04-29 17:41:57.380 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: SUCCESS to master : 172.18.1.1:1234
[WI-748][TI-2034] - [INFO] 2024-04-29 17:41:57.380 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-748][TI-2034] - [INFO] 2024-04-29 17:41:57.381 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_8/748/2034
[WI-748][TI-2034] - [INFO] 2024-04-29 17:41:57.394 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_8/748/2034
[WI-748][TI-2034] - [INFO] 2024-04-29 17:41:57.397 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-2034] - [INFO] 2024-04-29 17:41:57.641 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=2034, success=true)
[WI-0][TI-0] - [INFO] 2024-04-29 17:41:57.815 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=2035, taskName=persist_to_postgre, firstSubmitTime=1714383717790, startTime=0, taskType=PYTHON, workflowInstanceHost=172.18.0.12:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13426477386080, processDefineVersion=8, appIds=null, processInstanceId=748, scheduleTime=0, globalParams=null, executorId=1, cmdTypeIfComplement=7, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[{"prop":"query","direct":"OUT","type":"VARCHAR","value":""}],"rawScript":"import re\nimport json\n\n# define the table to send the data to\ntable_name = \"filtered_data_persistence\"\n\n# Provided JSON data as strings\njson_data = ''' \n{\n  \"user\": \"premiumplatinum\",\n  \"content\": \"singapore is stupid\",\n  \"url\": \"https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/\",\n  \"context\": \"21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist\",\n  \"score\": 131,\n  \"type\": \"post\",\n  \"id\": \"1c9itat\",\n  \"datetime\": \"2024-04-21 22:10:42\"\n}\n{\n        \"user\": \"premiumplatinum\",\n        \"content\": \"s is stupid\",\n        \"url\": \"https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/\",\n        \"context\": \"21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist\",\n        \"score\": 131,\n        \"type\": \"post\",\n        \"id\": \"1c9itat\",\n        \"datetime\": \"2024-04-21 22:10:42\"\n}\n'''\n\n# process the kafka messages to individual JSON objects\njson_objects = json_data.replace('}\\n{', '},\\n{').strip()\njson_objects = re.sub(\" +\", \" \",json_objects)   \njson_objects = '[' + json_objects + ']'\n\n# convert JSON string to a list of dicts\njson_list = json.loads(json_objects)\n\n# convert list of dictionaries into list of tuples containing only the values\nvalues = [tuple(message.values()) for message in json_list]\n\n# create the SQL Query\nquery = f'''\nINSERT INTO {table_name} (user, content, url, context, score, type, id, datetime)\nVALUES \n'''\n\nfor value in values:\n    query += str(value) + ',\\n'\n\n# remove the last 2 character ,\\n and change it to ; for the query\nquery = query[:-2] + ';'\n\n# pass the query as a parameter downstream\nprint(\"#setValue(query=%s)\" % query)","resourceList":[]}, environmentConfig=export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='persist_to_postgre'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, query=Property{prop='query', direct=IN, type=VARCHAR, value=''}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240429'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='2035'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13426451158240'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240429174157'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='748'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240428'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='es_filtered_data_persistence_subprocess'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13426477386080'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"query","direct":"IN","type":"VARCHAR","value":""}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-748][TI-2035] - [INFO] 2024-04-29 17:41:57.817 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: persist_to_postgre to wait queue success
[WI-748][TI-2035] - [INFO] 2024-04-29 17:41:57.817 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2035] - [INFO] 2024-04-29 17:41:57.818 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-748][TI-2035] - [INFO] 2024-04-29 17:41:57.819 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2035] - [INFO] 2024-04-29 17:41:57.819 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-748][TI-2035] - [INFO] 2024-04-29 17:41:57.820 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1714383717820
[WI-748][TI-2035] - [INFO] 2024-04-29 17:41:57.820 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 748_2035
[WI-748][TI-2035] - [INFO] 2024-04-29 17:41:57.823 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 2035,
  "taskName" : "persist_to_postgre",
  "firstSubmitTime" : 1714383717790,
  "startTime" : 1714383717820,
  "taskType" : "PYTHON",
  "workflowInstanceHost" : "172.18.0.12:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240429/13426477386080/8/748/2035.log",
  "processId" : 0,
  "processDefineCode" : 13426477386080,
  "processDefineVersion" : 8,
  "processInstanceId" : 748,
  "scheduleTime" : 0,
  "executorId" : 1,
  "cmdTypeIfComplement" : 7,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[{\"prop\":\"query\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"\"}],\"rawScript\":\"import re\\nimport json\\n\\n# define the table to send the data to\\ntable_name = \\\"filtered_data_persistence\\\"\\n\\n# Provided JSON data as strings\\njson_data = ''' \\n{\\n  \\\"user\\\": \\\"premiumplatinum\\\",\\n  \\\"content\\\": \\\"singapore is stupid\\\",\\n  \\\"url\\\": \\\"https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/\\\",\\n  \\\"context\\\": \\\"21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist\\\",\\n  \\\"score\\\": 131,\\n  \\\"type\\\": \\\"post\\\",\\n  \\\"id\\\": \\\"1c9itat\\\",\\n  \\\"datetime\\\": \\\"2024-04-21 22:10:42\\\"\\n}\\n{\\n        \\\"user\\\": \\\"premiumplatinum\\\",\\n        \\\"content\\\": \\\"s is stupid\\\",\\n        \\\"url\\\": \\\"https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/\\\",\\n        \\\"context\\\": \\\"21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist\\\",\\n        \\\"score\\\": 131,\\n        \\\"type\\\": \\\"post\\\",\\n        \\\"id\\\": \\\"1c9itat\\\",\\n        \\\"datetime\\\": \\\"2024-04-21 22:10:42\\\"\\n}\\n'''\\n\\n# process the kafka messages to individual JSON objects\\njson_objects = json_data.replace('}\\\\n{', '},\\\\n{').strip()\\njson_objects = re.sub(\\\" +\\\", \\\" \\\",json_objects)   \\njson_objects = '[' + json_objects + ']'\\n\\n# convert JSON string to a list of dicts\\njson_list = json.loads(json_objects)\\n\\n# convert list of dictionaries into list of tuples containing only the values\\nvalues = [tuple(message.values()) for message in json_list]\\n\\n# create the SQL Query\\nquery = f'''\\nINSERT INTO {table_name} (user, content, url, context, score, type, id, datetime)\\nVALUES \\n'''\\n\\nfor value in values:\\n    query += str(value) + ',\\\\n'\\n\\n# remove the last 2 character ,\\\\n and change it to ; for the query\\nquery = query[:-2] + ';'\\n\\n# pass the query as a parameter downstream\\nprint(\\\"#setValue(query=%s)\\\" % query)\",\"resourceList\":[]}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "persist_to_postgre"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "query" : {
      "prop" : "query",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : ""
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240429"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "2035"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13426451158240"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240429174157"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "748"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240428"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "es_filtered_data_persistence_subprocess"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13426477386080"
    }
  },
  "taskAppId" : "748_2035",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"query\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-748][TI-2035] - [INFO] 2024-04-29 17:41:57.824 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2035] - [INFO] 2024-04-29 17:41:57.825 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-748][TI-2035] - [INFO] 2024-04-29 17:41:57.825 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2035] - [INFO] 2024-04-29 17:41:57.835 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-748][TI-2035] - [INFO] 2024-04-29 17:41:57.836 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-748][TI-2035] - [INFO] 2024-04-29 17:41:57.838 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_8/748/2035 check successfully
[WI-748][TI-2035] - [INFO] 2024-04-29 17:41:57.838 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.python.PythonTaskChannel successfully
[WI-748][TI-2035] - [INFO] 2024-04-29 17:41:57.843 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-748][TI-2035] - [INFO] 2024-04-29 17:41:57.844 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-748][TI-2035] - [INFO] 2024-04-29 17:41:57.846 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: PYTHON create successfully
[WI-748][TI-2035] - [INFO] 2024-04-29 17:41:57.856 +0800 o.a.d.p.t.p.PythonTask:[75] - Initialize python task params {
  "localParams" : [ {
    "prop" : "query",
    "direct" : "OUT",
    "type" : "VARCHAR",
    "value" : ""
  } ],
  "varPool" : null,
  "rawScript" : "import re\nimport json\n\n# define the table to send the data to\ntable_name = \"filtered_data_persistence\"\n\n# Provided JSON data as strings\njson_data = ''' \n{\n  \"user\": \"premiumplatinum\",\n  \"content\": \"singapore is stupid\",\n  \"url\": \"https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/\",\n  \"context\": \"21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist\",\n  \"score\": 131,\n  \"type\": \"post\",\n  \"id\": \"1c9itat\",\n  \"datetime\": \"2024-04-21 22:10:42\"\n}\n{\n        \"user\": \"premiumplatinum\",\n        \"content\": \"s is stupid\",\n        \"url\": \"https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/\",\n        \"context\": \"21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist\",\n        \"score\": 131,\n        \"type\": \"post\",\n        \"id\": \"1c9itat\",\n        \"datetime\": \"2024-04-21 22:10:42\"\n}\n'''\n\n# process the kafka messages to individual JSON objects\njson_objects = json_data.replace('}\\n{', '},\\n{').strip()\njson_objects = re.sub(\" +\", \" \",json_objects)   \njson_objects = '[' + json_objects + ']'\n\n# convert JSON string to a list of dicts\njson_list = json.loads(json_objects)\n\n# convert list of dictionaries into list of tuples containing only the values\nvalues = [tuple(message.values()) for message in json_list]\n\n# create the SQL Query\nquery = f'''\nINSERT INTO {table_name} (user, content, url, context, score, type, id, datetime)\nVALUES \n'''\n\nfor value in values:\n    query += str(value) + ',\\n'\n\n# remove the last 2 character ,\\n and change it to ; for the query\nquery = query[:-2] + ';'\n\n# pass the query as a parameter downstream\nprint(\"#setValue(query=%s)\" % query)",
  "resourceList" : [ ]
}
[WI-748][TI-2035] - [INFO] 2024-04-29 17:41:57.858 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-748][TI-2035] - [INFO] 2024-04-29 17:41:57.858 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"query","direct":"IN","type":"VARCHAR","value":""}] successfully
[WI-748][TI-2035] - [INFO] 2024-04-29 17:41:57.858 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2035] - [INFO] 2024-04-29 17:41:57.859 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-748][TI-2035] - [INFO] 2024-04-29 17:41:57.859 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2035] - [INFO] 2024-04-29 17:41:57.859 +0800 o.a.d.p.t.p.PythonTask:[165] - raw python script : import re
import json

# define the table to send the data to
table_name = "filtered_data_persistence"

# Provided JSON data as strings
json_data = ''' 
{
  "user": "premiumplatinum",
  "content": "singapore is stupid",
  "url": "https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/",
  "context": "21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist",
  "score": 131,
  "type": "post",
  "id": "1c9itat",
  "datetime": "2024-04-21 22:10:42"
}
{
        "user": "premiumplatinum",
        "content": "s is stupid",
        "url": "https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/",
        "context": "21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist",
        "score": 131,
        "type": "post",
        "id": "1c9itat",
        "datetime": "2024-04-21 22:10:42"
}
'''

# process the kafka messages to individual JSON objects
json_objects = json_data.replace('}\n{', '},\n{').strip()
json_objects = re.sub(" +", " ",json_objects)   
json_objects = '[' + json_objects + ']'

# convert JSON string to a list of dicts
json_list = json.loads(json_objects)

# convert list of dictionaries into list of tuples containing only the values
values = [tuple(message.values()) for message in json_list]

# create the SQL Query
query = f'''
INSERT INTO {table_name} (user, content, url, context, score, type, id, datetime)
VALUES 
'''

for value in values:
    query += str(value) + ',\n'

# remove the last 2 character ,\n and change it to ; for the query
query = query[:-2] + ';'

# pass the query as a parameter downstream
print("#setValue(query=%s)" % query)
[WI-748][TI-2035] - [INFO] 2024-04-29 17:41:57.860 +0800 o.a.d.p.t.p.PythonTask:[131] - tenantCode :default, task dir:/tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_8/748/2035
[WI-748][TI-2035] - [INFO] 2024-04-29 17:41:57.861 +0800 o.a.d.p.t.p.PythonTask:[134] - generate python script file:/tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_8/748/2035/py_748_2035.py
[WI-748][TI-2035] - [INFO] 2024-04-29 17:41:57.862 +0800 o.a.d.p.t.p.PythonTask:[141] - #-*- encoding=utf8 -*-

import re
import json

# define the table to send the data to
table_name = "filtered_data_persistence"

# Provided JSON data as strings
json_data = ''' 
{
  "user": "premiumplatinum",
  "content": "singapore is stupid",
  "url": "https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/",
  "context": "21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist",
  "score": 131,
  "type": "post",
  "id": "1c9itat",
  "datetime": "2024-04-21 22:10:42"
}
{
        "user": "premiumplatinum",
        "content": "s is stupid",
        "url": "https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/",
        "context": "21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist",
        "score": 131,
        "type": "post",
        "id": "1c9itat",
        "datetime": "2024-04-21 22:10:42"
}
'''

# process the kafka messages to individual JSON objects
json_objects = json_data.replace('}\n{', '},\n{').strip()
json_objects = re.sub(" +", " ",json_objects)   
json_objects = '[' + json_objects + ']'

# convert JSON string to a list of dicts
json_list = json.loads(json_objects)

# convert list of dictionaries into list of tuples containing only the values
values = [tuple(message.values()) for message in json_list]

# create the SQL Query
query = f'''
INSERT INTO {table_name} (user, content, url, context, score, type, id, datetime)
VALUES 
'''

for value in values:
    query += str(value) + ',\n'

# remove the last 2 character ,\n and change it to ; for the query
query = query[:-2] + ';'

# pass the query as a parameter downstream
print("#setValue(query=%s)" % query)
[WI-748][TI-2035] - [INFO] 2024-04-29 17:41:57.873 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-748][TI-2035] - [INFO] 2024-04-29 17:41:57.874 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-748][TI-2035] - [INFO] 2024-04-29 17:41:57.875 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export PYTHON_LAUNCHER=/bin/python3.11
${PYTHON_LAUNCHER} /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_8/748/2035/py_748_2035.py
[WI-748][TI-2035] - [INFO] 2024-04-29 17:41:57.876 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-748][TI-2035] - [INFO] 2024-04-29 17:41:57.877 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_8/748/2035/748_2035.sh
[WI-748][TI-2035] - [INFO] 2024-04-29 17:41:57.880 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 102
[WI-0][TI-2035] - [INFO] 2024-04-29 17:41:58.650 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=2035, success=true)
[WI-0][TI-2035] - [INFO] 2024-04-29 17:41:58.663 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=2035)
[WI-0][TI-0] - [INFO] 2024-04-29 17:41:58.884 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
	#setValue(query=
	INSERT INTO filtered_data_persistence (user, content, url, context, score, type, id, datetime)
	VALUES 
	('premiumplatinum', 'singapore is stupid', 'https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/', '21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist', 131, 'post', '1c9itat', '2024-04-21 22:10:42'),
	('premiumplatinum', 's is stupid', 'https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/', '21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist', 131, 'post', '1c9itat', '2024-04-21 22:10:42');)
[WI-748][TI-2035] - [INFO] 2024-04-29 17:41:58.887 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_8/748/2035, processId:102 ,exitStatusCode:0 ,processWaitForStatus:true ,processExitValue:0
[WI-748][TI-2035] - [INFO] 2024-04-29 17:41:58.889 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2035] - [INFO] 2024-04-29 17:41:58.889 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-748][TI-2035] - [INFO] 2024-04-29 17:41:58.889 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2035] - [INFO] 2024-04-29 17:41:58.891 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-748][TI-2035] - [INFO] 2024-04-29 17:41:58.896 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: SUCCESS to master : 172.18.1.1:1234
[WI-748][TI-2035] - [INFO] 2024-04-29 17:41:58.896 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-748][TI-2035] - [INFO] 2024-04-29 17:41:58.896 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_8/748/2035
[WI-748][TI-2035] - [INFO] 2024-04-29 17:41:58.897 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_8/748/2035
[WI-748][TI-2035] - [INFO] 2024-04-29 17:41:58.898 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-2035] - [INFO] 2024-04-29 17:41:59.641 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=2035, success=true)
[WI-0][TI-0] - [INFO] 2024-04-29 17:41:59.852 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=2036, taskName=Persist in postgresql, firstSubmitTime=1714383719719, startTime=0, taskType=SQL, workflowInstanceHost=172.18.0.12:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13426477386080, processDefineVersion=8, appIds=null, processInstanceId=748, scheduleTime=0, globalParams=null, executorId=1, cmdTypeIfComplement=7, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[],"resourceList":[],"type":"POSTGRESQL","datasource":1,"sql":"${query}","sqlType":"0","preStatements":[],"postStatements":[],"displayRows":10}, environmentConfig=export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='Persist in postgresql'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, query=Property{prop='query', direct=IN, type=VARCHAR, value=''}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240429'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='2036'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13427698681952'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240429174159'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='748'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240428'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='es_filtered_data_persistence_subprocess'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13426477386080'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=org.apache.dolphinscheduler.plugin.task.api.parameters.resource.ResourceParametersHelper@67b6d1cb, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"query","direct":"IN","type":"VARCHAR","value":""}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-748][TI-2036] - [INFO] 2024-04-29 17:41:59.854 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: Persist in postgresql to wait queue success
[WI-748][TI-2036] - [INFO] 2024-04-29 17:41:59.854 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2036] - [INFO] 2024-04-29 17:41:59.857 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-748][TI-2036] - [INFO] 2024-04-29 17:41:59.858 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2036] - [INFO] 2024-04-29 17:41:59.858 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-748][TI-2036] - [INFO] 2024-04-29 17:41:59.858 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1714383719858
[WI-748][TI-2036] - [INFO] 2024-04-29 17:41:59.858 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 748_2036
[WI-748][TI-2036] - [INFO] 2024-04-29 17:41:59.863 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 2036,
  "taskName" : "Persist in postgresql",
  "firstSubmitTime" : 1714383719719,
  "startTime" : 1714383719858,
  "taskType" : "SQL",
  "workflowInstanceHost" : "172.18.0.12:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240429/13426477386080/8/748/2036.log",
  "processId" : 0,
  "processDefineCode" : 13426477386080,
  "processDefineVersion" : 8,
  "processInstanceId" : 748,
  "scheduleTime" : 0,
  "executorId" : 1,
  "cmdTypeIfComplement" : 7,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[],\"resourceList\":[],\"type\":\"POSTGRESQL\",\"datasource\":1,\"sql\":\"${query}\",\"sqlType\":\"0\",\"preStatements\":[],\"postStatements\":[],\"displayRows\":10}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "Persist in postgresql"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "query" : {
      "prop" : "query",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : ""
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240429"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "2036"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13427698681952"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240429174159"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "748"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240428"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "es_filtered_data_persistence_subprocess"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13426477386080"
    }
  },
  "taskAppId" : "748_2036",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "resourceParametersHelper" : {
    "resourceMap" : {
      "DATASOURCE" : {
        "1" : {
          "resourceType" : "DATASOURCE",
          "type" : "POSTGRESQL",
          "connectionParams" : "{\"user\":\"root\",\"password\":\"dolphinscheduler123\",\"address\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432\",\"database\":\"persistence\",\"jdbcUrl\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432/persistence\",\"driverClassName\":\"org.postgresql.Driver\",\"validationQuery\":\"select version()\"}",
          "DATASOURCE" : null
        }
      }
    }
  },
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"query\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-748][TI-2036] - [INFO] 2024-04-29 17:41:59.876 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2036] - [INFO] 2024-04-29 17:41:59.877 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-748][TI-2036] - [INFO] 2024-04-29 17:41:59.877 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2036] - [INFO] 2024-04-29 17:41:59.897 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-748][TI-2036] - [INFO] 2024-04-29 17:41:59.899 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-748][TI-2036] - [INFO] 2024-04-29 17:41:59.902 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_8/748/2036 check successfully
[WI-748][TI-2036] - [INFO] 2024-04-29 17:41:59.902 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.sql.SqlTaskChannel successfully
[WI-748][TI-2036] - [INFO] 2024-04-29 17:41:59.920 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-748][TI-2036] - [INFO] 2024-04-29 17:41:59.922 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-748][TI-2036] - [INFO] 2024-04-29 17:41:59.927 +0800 o.a.d.p.t.s.SqlTask:[99] - Initialize sql task parameter {
  "localParams" : [ ],
  "varPool" : null,
  "type" : "POSTGRESQL",
  "datasource" : 1,
  "sql" : "${query}",
  "sqlType" : 0,
  "sendEmail" : null,
  "displayRows" : 10,
  "udfs" : null,
  "showType" : null,
  "connParams" : null,
  "preStatements" : [ ],
  "postStatements" : [ ],
  "groupId" : 0,
  "title" : null,
  "limit" : 0
}
[WI-748][TI-2036] - [INFO] 2024-04-29 17:41:59.936 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SQL create successfully
[WI-748][TI-2036] - [INFO] 2024-04-29 17:41:59.937 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-748][TI-2036] - [INFO] 2024-04-29 17:41:59.937 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"query","direct":"IN","type":"VARCHAR","value":""}] successfully
[WI-748][TI-2036] - [INFO] 2024-04-29 17:41:59.940 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2036] - [INFO] 2024-04-29 17:41:59.940 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-748][TI-2036] - [INFO] 2024-04-29 17:41:59.940 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2036] - [INFO] 2024-04-29 17:41:59.940 +0800 o.a.d.p.t.s.SqlTask:[119] - Full sql parameters: SqlParameters{type='POSTGRESQL', datasource=1, sql='${query}', sqlType=0, sendEmail=null, displayRows=10, limit=0, udfs='null', showType='null', connParams='null', groupId='0', title='null', preStatements=[], postStatements=[]}
[WI-748][TI-2036] - [INFO] 2024-04-29 17:41:59.940 +0800 o.a.d.p.t.s.SqlTask:[120] - sql type : POSTGRESQL, datasource : 1, sql : ${query} , localParams : [],udfs : null,showType : null,connParams : null,varPool : [Property{prop='query', direct=IN, type=VARCHAR, value=''}] ,query max result limit  0
[WI-748][TI-2036] - [INFO] 2024-04-29 17:41:59.958 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: HANA
[WI-748][TI-2036] - [INFO] 2024-04-29 17:41:59.958 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: HANA
[WI-748][TI-2036] - [INFO] 2024-04-29 17:41:59.960 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: SQLSERVER
[WI-748][TI-2036] - [INFO] 2024-04-29 17:41:59.961 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: SQLSERVER
[WI-748][TI-2036] - [INFO] 2024-04-29 17:41:59.963 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: SAGEMAKER
[WI-748][TI-2036] - [INFO] 2024-04-29 17:41:59.963 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: SAGEMAKER
[WI-748][TI-2036] - [INFO] 2024-04-29 17:41:59.965 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: DATABEND
[WI-748][TI-2036] - [INFO] 2024-04-29 17:41:59.966 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: DATABEND
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:00.047 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: AZURESQL
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:00.048 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: AZURESQL
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:00.053 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: HIVE
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:00.053 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: HIVE
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:00.056 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: DORIS
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:00.057 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: DORIS
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:00.059 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: POSTGRESQL
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:00.059 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: POSTGRESQL
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:00.061 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: MYSQL
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:00.062 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: MYSQL
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:00.065 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: REDSHIFT
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:00.066 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: REDSHIFT
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:00.068 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: SNOWFLAKE
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:00.069 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: SNOWFLAKE
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:00.071 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: STARROCKS
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:00.072 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: STARROCKS
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:00.074 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: SSH
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:00.074 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: SSH
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:00.076 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: ATHENA
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:00.077 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: ATHENA
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:00.079 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: PRESTO
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:00.080 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: PRESTO
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:00.082 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: OCEANBASE
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:00.083 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: OCEANBASE
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:00.098 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: ORACLE
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:00.098 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: ORACLE
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:00.101 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: CLICKHOUSE
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:00.102 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: CLICKHOUSE
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:00.104 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: VERTICA
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:00.105 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: VERTICA
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:00.112 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: KYUUBI
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:00.115 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: KYUUBI
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:00.118 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: DB2
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:00.118 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: DB2
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:00.120 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: TRINO
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:00.121 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: TRINO
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:00.124 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: SPARK
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:00.125 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: SPARK
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:00.128 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: DAMENG
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:00.129 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: DAMENG
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:00.132 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: ZEPPELIN
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:00.132 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: ZEPPELIN
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:00.253 +0800 o.a.d.p.t.a.AbstractTask:[206] - setSqlParamsMap: Property with paramName: query put in sqlParamsMap of content ${query} successfully.
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:00.255 +0800 o.a.d.p.t.s.SqlTask:[410] - after replace sql , preparing : ?
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:00.255 +0800 o.a.d.p.t.s.SqlTask:[420] - Sql Params are replaced sql , parameters:(VARCHAR)
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:00.257 +0800 o.a.d.p.t.s.SqlTask:[489] - can't find udf function resource
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:00.285 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[49] - Registering datasource plugin: hive
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:00.295 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[57] - Registered datasource plugin: hive
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:00.296 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[49] - Registering datasource plugin: vertica
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:00.299 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[57] - Registered datasource plugin: vertica
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:00.300 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[49] - Registering datasource plugin: doris
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:00.303 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[57] - Registered datasource plugin: doris
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:00.307 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[49] - Registering datasource plugin: ssh
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:00.310 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[57] - Registered datasource plugin: ssh
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:00.310 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[49] - Registering datasource plugin: databend
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:00.311 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[57] - Registered datasource plugin: databend
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:00.311 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[49] - Registering datasource plugin: sqlserver
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:00.311 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[57] - Registered datasource plugin: sqlserver
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:00.311 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[49] - Registering datasource plugin: postgresql
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:00.312 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[57] - Registered datasource plugin: postgresql
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:00.312 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[49] - Registering datasource plugin: redshift
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:00.312 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[57] - Registered datasource plugin: redshift
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:00.312 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[49] - Registering datasource plugin: spark
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:00.312 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[57] - Registered datasource plugin: spark
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:00.313 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[49] - Registering datasource plugin: oceanbase
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:00.313 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[57] - Registered datasource plugin: oceanbase
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:00.313 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[49] - Registering datasource plugin: starrocks
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:00.313 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[57] - Registered datasource plugin: starrocks
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:00.313 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[49] - Registering datasource plugin: mysql
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:00.314 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[57] - Registered datasource plugin: mysql
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:00.314 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[49] - Registering datasource plugin: hana
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:00.314 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[57] - Registered datasource plugin: hana
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:00.314 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[49] - Registering datasource plugin: sagemaker
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:00.314 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[57] - Registered datasource plugin: sagemaker
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:00.314 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[49] - Registering datasource plugin: dameng
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:00.318 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[57] - Registered datasource plugin: dameng
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:00.318 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[49] - Registering datasource plugin: snowflake
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:00.319 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[57] - Registered datasource plugin: snowflake
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:00.319 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[49] - Registering datasource plugin: oracle
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:00.320 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[57] - Registered datasource plugin: oracle
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:00.321 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[49] - Registering datasource plugin: kyuubi
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:00.322 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[57] - Registered datasource plugin: kyuubi
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:00.322 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[49] - Registering datasource plugin: zeppelin
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:00.323 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[57] - Registered datasource plugin: zeppelin
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:00.324 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[49] - Registering datasource plugin: trino
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:00.325 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[57] - Registered datasource plugin: trino
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:00.326 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[49] - Registering datasource plugin: db2
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:00.327 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[57] - Registered datasource plugin: db2
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:00.328 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[49] - Registering datasource plugin: clickhouse
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:00.328 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[57] - Registered datasource plugin: clickhouse
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:00.329 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[49] - Registering datasource plugin: azuresql
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:00.329 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[57] - Registered datasource plugin: azuresql
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:00.330 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[49] - Registering datasource plugin: athena
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:00.331 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[57] - Registered datasource plugin: athena
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:00.331 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[49] - Registering datasource plugin: presto
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:00.333 +0800 o.a.d.p.d.a.p.DataSourcePluginManager:[57] - Registered datasource plugin: presto
[WI-0][TI-2036] - [INFO] 2024-04-29 17:42:00.694 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=2036, success=true)
[WI-0][TI-0] - [INFO] 2024-04-29 17:42:00.949 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.261168384879725 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-748][TI-2036] - [WARN] 2024-04-29 17:42:00.952 +0800 n.s.c.j.SnowflakeConnectString:[136] - Connect strings must start with jdbc:snowflake://
[WI-748][TI-2036] - [ERROR] 2024-04-29 17:42:01.137 +0800 o.a.d.p.t.s.SqlTask:[217] - execute sql error: Create adhoc connection error
[WI-748][TI-2036] - [ERROR] 2024-04-29 17:42:01.150 +0800 o.a.d.p.t.s.SqlTask:[165] - sql task error
java.sql.SQLException: Create adhoc connection error
	at org.apache.dolphinscheduler.plugin.datasource.api.client.BaseAdHocDataSourceClient.getConnection(BaseAdHocDataSourceClient.java:43)
	at org.apache.dolphinscheduler.plugin.datasource.api.plugin.DataSourceClientProvider.getAdHocConnection(DataSourceClientProvider.java:97)
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.executeFuncAndSql(SqlTask.java:189)
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.handle(SqlTask.java:159)
	at org.apache.dolphinscheduler.server.worker.runner.DefaultWorkerTaskExecutor.executeTask(DefaultWorkerTaskExecutor.java:54)
	at org.apache.dolphinscheduler.server.worker.runner.WorkerTaskExecutor.run(WorkerTaskExecutor.java:175)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.postgresql.util.PSQLException: FATAL: password authentication failed for user "root"
	at org.postgresql.core.v3.ConnectionFactoryImpl.doAuthentication(ConnectionFactoryImpl.java:646)
	at org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:180)
	at org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:235)
	at org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:49)
	at org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:247)
	at org.postgresql.Driver.makeConnection(Driver.java:434)
	at org.postgresql.Driver.connect(Driver.java:291)
	at java.sql.DriverManager.getConnection(DriverManager.java:664)
	at java.sql.DriverManager.getConnection(DriverManager.java:247)
	at org.apache.dolphinscheduler.plugin.datasource.postgresql.param.PostgreSQLDataSourceProcessor.getConnection(PostgreSQLDataSourceProcessor.java:117)
	at org.apache.dolphinscheduler.plugin.datasource.api.client.BaseAdHocDataSourceClient.getConnection(BaseAdHocDataSourceClient.java:41)
	... 8 common frames omitted
[WI-748][TI-2036] - [ERROR] 2024-04-29 17:42:01.151 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[181] - Task execute failed, due to meet an exception
org.apache.dolphinscheduler.plugin.task.api.TaskException: Execute sql task failed
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.handle(SqlTask.java:166)
	at org.apache.dolphinscheduler.server.worker.runner.DefaultWorkerTaskExecutor.executeTask(DefaultWorkerTaskExecutor.java:54)
	at org.apache.dolphinscheduler.server.worker.runner.WorkerTaskExecutor.run(WorkerTaskExecutor.java:175)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.sql.SQLException: Create adhoc connection error
	at org.apache.dolphinscheduler.plugin.datasource.api.client.BaseAdHocDataSourceClient.getConnection(BaseAdHocDataSourceClient.java:43)
	at org.apache.dolphinscheduler.plugin.datasource.api.plugin.DataSourceClientProvider.getAdHocConnection(DataSourceClientProvider.java:97)
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.executeFuncAndSql(SqlTask.java:189)
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.handle(SqlTask.java:159)
	... 5 common frames omitted
Caused by: org.postgresql.util.PSQLException: FATAL: password authentication failed for user "root"
	at org.postgresql.core.v3.ConnectionFactoryImpl.doAuthentication(ConnectionFactoryImpl.java:646)
	at org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:180)
	at org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:235)
	at org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:49)
	at org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:247)
	at org.postgresql.Driver.makeConnection(Driver.java:434)
	at org.postgresql.Driver.connect(Driver.java:291)
	at java.sql.DriverManager.getConnection(DriverManager.java:664)
	at java.sql.DriverManager.getConnection(DriverManager.java:247)
	at org.apache.dolphinscheduler.plugin.datasource.postgresql.param.PostgreSQLDataSourceProcessor.getConnection(PostgreSQLDataSourceProcessor.java:117)
	at org.apache.dolphinscheduler.plugin.datasource.api.client.BaseAdHocDataSourceClient.getConnection(BaseAdHocDataSourceClient.java:41)
	... 8 common frames omitted
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:01.151 +0800 o.a.d.p.t.a.u.ProcessUtils:[182] - Get appIds from worker 172.18.1.1:1234, taskLogPath: /opt/dolphinscheduler/logs/20240429/13426477386080/8/748/2036.log
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:01.152 +0800 o.a.d.p.t.a.u.LogUtils:[79] - Start finding appId in /opt/dolphinscheduler/logs/20240429/13426477386080/8/748/2036.log, fetch way: log 
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:01.154 +0800 o.a.d.p.t.a.u.ProcessUtils:[188] - The appId is empty
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:01.156 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[118] - Cancel the task successfully
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:01.166 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[125] - Get a exception when execute the task, will send the task status: FAILURE to master: 172.18.1.1:1234
[WI-748][TI-2036] - [INFO] 2024-04-29 17:42:01.167 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-2036] - [INFO] 2024-04-29 17:42:01.646 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=2036, success=true)
[WI-0][TI-0] - [INFO] 2024-04-29 17:42:01.724 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=2037, taskName=Persist in postgresql, firstSubmitTime=1714383721710, startTime=0, taskType=SQL, workflowInstanceHost=172.18.0.12:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13426477386080, processDefineVersion=8, appIds=null, processInstanceId=748, scheduleTime=0, globalParams=null, executorId=1, cmdTypeIfComplement=7, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[],"resourceList":[],"type":"POSTGRESQL","datasource":1,"sql":"${query}","sqlType":"0","preStatements":[],"postStatements":[],"displayRows":10}, environmentConfig=export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='Persist in postgresql'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, query=Property{prop='query', direct=IN, type=VARCHAR, value=''}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240429'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='2037'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13427698681952'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240429174201'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='748'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240428'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='es_filtered_data_persistence_subprocess'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13426477386080'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=org.apache.dolphinscheduler.plugin.task.api.parameters.resource.ResourceParametersHelper@6739c73d, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"query","direct":"IN","type":"VARCHAR","value":""}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-748][TI-2037] - [INFO] 2024-04-29 17:42:01.725 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: Persist in postgresql to wait queue success
[WI-748][TI-2037] - [INFO] 2024-04-29 17:42:01.725 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2037] - [INFO] 2024-04-29 17:42:01.726 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-748][TI-2037] - [INFO] 2024-04-29 17:42:01.727 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2037] - [INFO] 2024-04-29 17:42:01.727 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-748][TI-2037] - [INFO] 2024-04-29 17:42:01.727 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1714383721727
[WI-748][TI-2037] - [INFO] 2024-04-29 17:42:01.727 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 748_2037
[WI-748][TI-2037] - [INFO] 2024-04-29 17:42:01.728 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 2037,
  "taskName" : "Persist in postgresql",
  "firstSubmitTime" : 1714383721710,
  "startTime" : 1714383721727,
  "taskType" : "SQL",
  "workflowInstanceHost" : "172.18.0.12:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240429/13426477386080/8/748/2037.log",
  "processId" : 0,
  "processDefineCode" : 13426477386080,
  "processDefineVersion" : 8,
  "processInstanceId" : 748,
  "scheduleTime" : 0,
  "executorId" : 1,
  "cmdTypeIfComplement" : 7,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[],\"resourceList\":[],\"type\":\"POSTGRESQL\",\"datasource\":1,\"sql\":\"${query}\",\"sqlType\":\"0\",\"preStatements\":[],\"postStatements\":[],\"displayRows\":10}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "Persist in postgresql"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "query" : {
      "prop" : "query",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : ""
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240429"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "2037"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13427698681952"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240429174201"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "748"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240428"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "es_filtered_data_persistence_subprocess"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13426477386080"
    }
  },
  "taskAppId" : "748_2037",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "resourceParametersHelper" : {
    "resourceMap" : {
      "DATASOURCE" : {
        "1" : {
          "resourceType" : "DATASOURCE",
          "type" : "POSTGRESQL",
          "connectionParams" : "{\"user\":\"root\",\"password\":\"dolphinscheduler123\",\"address\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432\",\"database\":\"persistence\",\"jdbcUrl\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432/persistence\",\"driverClassName\":\"org.postgresql.Driver\",\"validationQuery\":\"select version()\"}",
          "DATASOURCE" : null
        }
      }
    }
  },
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"query\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-748][TI-2037] - [INFO] 2024-04-29 17:42:01.729 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2037] - [INFO] 2024-04-29 17:42:01.729 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-748][TI-2037] - [INFO] 2024-04-29 17:42:01.729 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2037] - [INFO] 2024-04-29 17:42:01.735 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-748][TI-2037] - [INFO] 2024-04-29 17:42:01.735 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-748][TI-2037] - [INFO] 2024-04-29 17:42:01.736 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_8/748/2037 check successfully
[WI-748][TI-2037] - [INFO] 2024-04-29 17:42:01.736 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.sql.SqlTaskChannel successfully
[WI-748][TI-2037] - [INFO] 2024-04-29 17:42:01.737 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-748][TI-2037] - [INFO] 2024-04-29 17:42:01.738 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-748][TI-2037] - [INFO] 2024-04-29 17:42:01.738 +0800 o.a.d.p.t.s.SqlTask:[99] - Initialize sql task parameter {
  "localParams" : [ ],
  "varPool" : null,
  "type" : "POSTGRESQL",
  "datasource" : 1,
  "sql" : "${query}",
  "sqlType" : 0,
  "sendEmail" : null,
  "displayRows" : 10,
  "udfs" : null,
  "showType" : null,
  "connParams" : null,
  "preStatements" : [ ],
  "postStatements" : [ ],
  "groupId" : 0,
  "title" : null,
  "limit" : 0
}
[WI-748][TI-2037] - [INFO] 2024-04-29 17:42:01.739 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SQL create successfully
[WI-748][TI-2037] - [INFO] 2024-04-29 17:42:01.740 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-748][TI-2037] - [INFO] 2024-04-29 17:42:01.740 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"query","direct":"IN","type":"VARCHAR","value":""}] successfully
[WI-748][TI-2037] - [INFO] 2024-04-29 17:42:01.740 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2037] - [INFO] 2024-04-29 17:42:01.741 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-748][TI-2037] - [INFO] 2024-04-29 17:42:01.741 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2037] - [INFO] 2024-04-29 17:42:01.741 +0800 o.a.d.p.t.s.SqlTask:[119] - Full sql parameters: SqlParameters{type='POSTGRESQL', datasource=1, sql='${query}', sqlType=0, sendEmail=null, displayRows=10, limit=0, udfs='null', showType='null', connParams='null', groupId='0', title='null', preStatements=[], postStatements=[]}
[WI-748][TI-2037] - [INFO] 2024-04-29 17:42:01.741 +0800 o.a.d.p.t.s.SqlTask:[120] - sql type : POSTGRESQL, datasource : 1, sql : ${query} , localParams : [],udfs : null,showType : null,connParams : null,varPool : [Property{prop='query', direct=IN, type=VARCHAR, value=''}] ,query max result limit  0
[WI-748][TI-2037] - [INFO] 2024-04-29 17:42:01.741 +0800 o.a.d.p.t.a.AbstractTask:[206] - setSqlParamsMap: Property with paramName: query put in sqlParamsMap of content ${query} successfully.
[WI-748][TI-2037] - [INFO] 2024-04-29 17:42:01.742 +0800 o.a.d.p.t.s.SqlTask:[410] - after replace sql , preparing : ?
[WI-748][TI-2037] - [INFO] 2024-04-29 17:42:01.742 +0800 o.a.d.p.t.s.SqlTask:[420] - Sql Params are replaced sql , parameters:(VARCHAR)
[WI-748][TI-2037] - [INFO] 2024-04-29 17:42:01.742 +0800 o.a.d.p.t.s.SqlTask:[489] - can't find udf function resource
[WI-748][TI-2037] - [WARN] 2024-04-29 17:42:01.745 +0800 n.s.c.j.SnowflakeConnectString:[136] - Connect strings must start with jdbc:snowflake://
[WI-748][TI-2037] - [ERROR] 2024-04-29 17:42:01.790 +0800 o.a.d.p.t.s.SqlTask:[217] - execute sql error: Create adhoc connection error
[WI-748][TI-2037] - [ERROR] 2024-04-29 17:42:01.791 +0800 o.a.d.p.t.s.SqlTask:[165] - sql task error
java.sql.SQLException: Create adhoc connection error
	at org.apache.dolphinscheduler.plugin.datasource.api.client.BaseAdHocDataSourceClient.getConnection(BaseAdHocDataSourceClient.java:43)
	at org.apache.dolphinscheduler.plugin.datasource.api.plugin.DataSourceClientProvider.getAdHocConnection(DataSourceClientProvider.java:97)
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.executeFuncAndSql(SqlTask.java:189)
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.handle(SqlTask.java:159)
	at org.apache.dolphinscheduler.server.worker.runner.DefaultWorkerTaskExecutor.executeTask(DefaultWorkerTaskExecutor.java:54)
	at org.apache.dolphinscheduler.server.worker.runner.WorkerTaskExecutor.run(WorkerTaskExecutor.java:175)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.postgresql.util.PSQLException: FATAL: password authentication failed for user "root"
	at org.postgresql.core.v3.ConnectionFactoryImpl.doAuthentication(ConnectionFactoryImpl.java:646)
	at org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:180)
	at org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:235)
	at org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:49)
	at org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:247)
	at org.postgresql.Driver.makeConnection(Driver.java:434)
	at org.postgresql.Driver.connect(Driver.java:291)
	at java.sql.DriverManager.getConnection(DriverManager.java:664)
	at java.sql.DriverManager.getConnection(DriverManager.java:247)
	at org.apache.dolphinscheduler.plugin.datasource.postgresql.param.PostgreSQLDataSourceProcessor.getConnection(PostgreSQLDataSourceProcessor.java:117)
	at org.apache.dolphinscheduler.plugin.datasource.api.client.BaseAdHocDataSourceClient.getConnection(BaseAdHocDataSourceClient.java:41)
	... 8 common frames omitted
[WI-748][TI-2037] - [ERROR] 2024-04-29 17:42:01.792 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[181] - Task execute failed, due to meet an exception
org.apache.dolphinscheduler.plugin.task.api.TaskException: Execute sql task failed
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.handle(SqlTask.java:166)
	at org.apache.dolphinscheduler.server.worker.runner.DefaultWorkerTaskExecutor.executeTask(DefaultWorkerTaskExecutor.java:54)
	at org.apache.dolphinscheduler.server.worker.runner.WorkerTaskExecutor.run(WorkerTaskExecutor.java:175)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.sql.SQLException: Create adhoc connection error
	at org.apache.dolphinscheduler.plugin.datasource.api.client.BaseAdHocDataSourceClient.getConnection(BaseAdHocDataSourceClient.java:43)
	at org.apache.dolphinscheduler.plugin.datasource.api.plugin.DataSourceClientProvider.getAdHocConnection(DataSourceClientProvider.java:97)
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.executeFuncAndSql(SqlTask.java:189)
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.handle(SqlTask.java:159)
	... 5 common frames omitted
Caused by: org.postgresql.util.PSQLException: FATAL: password authentication failed for user "root"
	at org.postgresql.core.v3.ConnectionFactoryImpl.doAuthentication(ConnectionFactoryImpl.java:646)
	at org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:180)
	at org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:235)
	at org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:49)
	at org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:247)
	at org.postgresql.Driver.makeConnection(Driver.java:434)
	at org.postgresql.Driver.connect(Driver.java:291)
	at java.sql.DriverManager.getConnection(DriverManager.java:664)
	at java.sql.DriverManager.getConnection(DriverManager.java:247)
	at org.apache.dolphinscheduler.plugin.datasource.postgresql.param.PostgreSQLDataSourceProcessor.getConnection(PostgreSQLDataSourceProcessor.java:117)
	at org.apache.dolphinscheduler.plugin.datasource.api.client.BaseAdHocDataSourceClient.getConnection(BaseAdHocDataSourceClient.java:41)
	... 8 common frames omitted
[WI-748][TI-2037] - [INFO] 2024-04-29 17:42:01.792 +0800 o.a.d.p.t.a.u.ProcessUtils:[182] - Get appIds from worker 172.18.1.1:1234, taskLogPath: /opt/dolphinscheduler/logs/20240429/13426477386080/8/748/2037.log
[WI-748][TI-2037] - [INFO] 2024-04-29 17:42:01.792 +0800 o.a.d.p.t.a.u.LogUtils:[79] - Start finding appId in /opt/dolphinscheduler/logs/20240429/13426477386080/8/748/2037.log, fetch way: log 
[WI-748][TI-2037] - [INFO] 2024-04-29 17:42:01.793 +0800 o.a.d.p.t.a.u.ProcessUtils:[188] - The appId is empty
[WI-748][TI-2037] - [INFO] 2024-04-29 17:42:01.793 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[118] - Cancel the task successfully
[WI-748][TI-2037] - [INFO] 2024-04-29 17:42:01.804 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[125] - Get a exception when execute the task, will send the task status: FAILURE to master: 172.18.1.1:1234
[WI-748][TI-2037] - [INFO] 2024-04-29 17:42:01.809 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-2037] - [INFO] 2024-04-29 17:42:02.649 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=2037, success=true)
[WI-0][TI-2037] - [INFO] 2024-04-29 17:42:02.661 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=2037, success=true)
[WI-0][TI-0] - [INFO] 2024-04-29 17:42:03.790 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=2038, taskName=Persist in postgresql, firstSubmitTime=1714383723714, startTime=0, taskType=SQL, workflowInstanceHost=172.18.0.12:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13426477386080, processDefineVersion=8, appIds=null, processInstanceId=748, scheduleTime=0, globalParams=null, executorId=1, cmdTypeIfComplement=7, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[],"resourceList":[],"type":"POSTGRESQL","datasource":1,"sql":"${query}","sqlType":"0","preStatements":[],"postStatements":[],"displayRows":10}, environmentConfig=export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='Persist in postgresql'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, query=Property{prop='query', direct=IN, type=VARCHAR, value=''}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240429'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='2038'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13427698681952'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240429174203'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='748'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240428'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='es_filtered_data_persistence_subprocess'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13426477386080'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=org.apache.dolphinscheduler.plugin.task.api.parameters.resource.ResourceParametersHelper@6fa29bfb, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"query","direct":"IN","type":"VARCHAR","value":""}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-748][TI-2038] - [INFO] 2024-04-29 17:42:03.791 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: Persist in postgresql to wait queue success
[WI-748][TI-2038] - [INFO] 2024-04-29 17:42:03.792 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2038] - [INFO] 2024-04-29 17:42:03.795 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-748][TI-2038] - [INFO] 2024-04-29 17:42:03.795 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2038] - [INFO] 2024-04-29 17:42:03.795 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-748][TI-2038] - [INFO] 2024-04-29 17:42:03.795 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1714383723795
[WI-748][TI-2038] - [INFO] 2024-04-29 17:42:03.795 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 748_2038
[WI-748][TI-2038] - [INFO] 2024-04-29 17:42:03.796 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 2038,
  "taskName" : "Persist in postgresql",
  "firstSubmitTime" : 1714383723714,
  "startTime" : 1714383723795,
  "taskType" : "SQL",
  "workflowInstanceHost" : "172.18.0.12:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240429/13426477386080/8/748/2038.log",
  "processId" : 0,
  "processDefineCode" : 13426477386080,
  "processDefineVersion" : 8,
  "processInstanceId" : 748,
  "scheduleTime" : 0,
  "executorId" : 1,
  "cmdTypeIfComplement" : 7,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[],\"resourceList\":[],\"type\":\"POSTGRESQL\",\"datasource\":1,\"sql\":\"${query}\",\"sqlType\":\"0\",\"preStatements\":[],\"postStatements\":[],\"displayRows\":10}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "Persist in postgresql"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "query" : {
      "prop" : "query",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : ""
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240429"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "2038"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13427698681952"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240429174203"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "748"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240428"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "es_filtered_data_persistence_subprocess"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13426477386080"
    }
  },
  "taskAppId" : "748_2038",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "resourceParametersHelper" : {
    "resourceMap" : {
      "DATASOURCE" : {
        "1" : {
          "resourceType" : "DATASOURCE",
          "type" : "POSTGRESQL",
          "connectionParams" : "{\"user\":\"root\",\"password\":\"dolphinscheduler123\",\"address\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432\",\"database\":\"persistence\",\"jdbcUrl\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432/persistence\",\"driverClassName\":\"org.postgresql.Driver\",\"validationQuery\":\"select version()\"}",
          "DATASOURCE" : null
        }
      }
    }
  },
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"query\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-748][TI-2038] - [INFO] 2024-04-29 17:42:03.797 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2038] - [INFO] 2024-04-29 17:42:03.797 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-748][TI-2038] - [INFO] 2024-04-29 17:42:03.797 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2038] - [INFO] 2024-04-29 17:42:03.820 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-748][TI-2038] - [INFO] 2024-04-29 17:42:03.821 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-748][TI-2038] - [INFO] 2024-04-29 17:42:03.821 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_8/748/2038 check successfully
[WI-748][TI-2038] - [INFO] 2024-04-29 17:42:03.822 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.sql.SqlTaskChannel successfully
[WI-748][TI-2038] - [INFO] 2024-04-29 17:42:03.822 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-748][TI-2038] - [INFO] 2024-04-29 17:42:03.823 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-748][TI-2038] - [INFO] 2024-04-29 17:42:03.823 +0800 o.a.d.p.t.s.SqlTask:[99] - Initialize sql task parameter {
  "localParams" : [ ],
  "varPool" : null,
  "type" : "POSTGRESQL",
  "datasource" : 1,
  "sql" : "${query}",
  "sqlType" : 0,
  "sendEmail" : null,
  "displayRows" : 10,
  "udfs" : null,
  "showType" : null,
  "connParams" : null,
  "preStatements" : [ ],
  "postStatements" : [ ],
  "groupId" : 0,
  "title" : null,
  "limit" : 0
}
[WI-748][TI-2038] - [INFO] 2024-04-29 17:42:03.823 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SQL create successfully
[WI-748][TI-2038] - [INFO] 2024-04-29 17:42:03.824 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-748][TI-2038] - [INFO] 2024-04-29 17:42:03.824 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"query","direct":"IN","type":"VARCHAR","value":""}] successfully
[WI-748][TI-2038] - [INFO] 2024-04-29 17:42:03.824 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2038] - [INFO] 2024-04-29 17:42:03.825 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-748][TI-2038] - [INFO] 2024-04-29 17:42:03.825 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2038] - [INFO] 2024-04-29 17:42:03.825 +0800 o.a.d.p.t.s.SqlTask:[119] - Full sql parameters: SqlParameters{type='POSTGRESQL', datasource=1, sql='${query}', sqlType=0, sendEmail=null, displayRows=10, limit=0, udfs='null', showType='null', connParams='null', groupId='0', title='null', preStatements=[], postStatements=[]}
[WI-748][TI-2038] - [INFO] 2024-04-29 17:42:03.840 +0800 o.a.d.p.t.s.SqlTask:[120] - sql type : POSTGRESQL, datasource : 1, sql : ${query} , localParams : [],udfs : null,showType : null,connParams : null,varPool : [Property{prop='query', direct=IN, type=VARCHAR, value=''}] ,query max result limit  0
[WI-748][TI-2038] - [INFO] 2024-04-29 17:42:03.848 +0800 o.a.d.p.t.a.AbstractTask:[206] - setSqlParamsMap: Property with paramName: query put in sqlParamsMap of content ${query} successfully.
[WI-748][TI-2038] - [INFO] 2024-04-29 17:42:03.849 +0800 o.a.d.p.t.s.SqlTask:[410] - after replace sql , preparing : ?
[WI-748][TI-2038] - [INFO] 2024-04-29 17:42:03.851 +0800 o.a.d.p.t.s.SqlTask:[420] - Sql Params are replaced sql , parameters:(VARCHAR)
[WI-748][TI-2038] - [INFO] 2024-04-29 17:42:03.851 +0800 o.a.d.p.t.s.SqlTask:[489] - can't find udf function resource
[WI-748][TI-2038] - [WARN] 2024-04-29 17:42:03.851 +0800 n.s.c.j.SnowflakeConnectString:[136] - Connect strings must start with jdbc:snowflake://
[WI-748][TI-2038] - [ERROR] 2024-04-29 17:42:03.917 +0800 o.a.d.p.t.s.SqlTask:[217] - execute sql error: Create adhoc connection error
[WI-748][TI-2038] - [ERROR] 2024-04-29 17:42:03.918 +0800 o.a.d.p.t.s.SqlTask:[165] - sql task error
java.sql.SQLException: Create adhoc connection error
	at org.apache.dolphinscheduler.plugin.datasource.api.client.BaseAdHocDataSourceClient.getConnection(BaseAdHocDataSourceClient.java:43)
	at org.apache.dolphinscheduler.plugin.datasource.api.plugin.DataSourceClientProvider.getAdHocConnection(DataSourceClientProvider.java:97)
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.executeFuncAndSql(SqlTask.java:189)
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.handle(SqlTask.java:159)
	at org.apache.dolphinscheduler.server.worker.runner.DefaultWorkerTaskExecutor.executeTask(DefaultWorkerTaskExecutor.java:54)
	at org.apache.dolphinscheduler.server.worker.runner.WorkerTaskExecutor.run(WorkerTaskExecutor.java:175)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.postgresql.util.PSQLException: FATAL: password authentication failed for user "root"
	at org.postgresql.core.v3.ConnectionFactoryImpl.doAuthentication(ConnectionFactoryImpl.java:646)
	at org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:180)
	at org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:235)
	at org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:49)
	at org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:247)
	at org.postgresql.Driver.makeConnection(Driver.java:434)
	at org.postgresql.Driver.connect(Driver.java:291)
	at java.sql.DriverManager.getConnection(DriverManager.java:664)
	at java.sql.DriverManager.getConnection(DriverManager.java:247)
	at org.apache.dolphinscheduler.plugin.datasource.postgresql.param.PostgreSQLDataSourceProcessor.getConnection(PostgreSQLDataSourceProcessor.java:117)
	at org.apache.dolphinscheduler.plugin.datasource.api.client.BaseAdHocDataSourceClient.getConnection(BaseAdHocDataSourceClient.java:41)
	... 8 common frames omitted
[WI-748][TI-2038] - [ERROR] 2024-04-29 17:42:03.925 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[181] - Task execute failed, due to meet an exception
org.apache.dolphinscheduler.plugin.task.api.TaskException: Execute sql task failed
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.handle(SqlTask.java:166)
	at org.apache.dolphinscheduler.server.worker.runner.DefaultWorkerTaskExecutor.executeTask(DefaultWorkerTaskExecutor.java:54)
	at org.apache.dolphinscheduler.server.worker.runner.WorkerTaskExecutor.run(WorkerTaskExecutor.java:175)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.sql.SQLException: Create adhoc connection error
	at org.apache.dolphinscheduler.plugin.datasource.api.client.BaseAdHocDataSourceClient.getConnection(BaseAdHocDataSourceClient.java:43)
	at org.apache.dolphinscheduler.plugin.datasource.api.plugin.DataSourceClientProvider.getAdHocConnection(DataSourceClientProvider.java:97)
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.executeFuncAndSql(SqlTask.java:189)
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.handle(SqlTask.java:159)
	... 5 common frames omitted
Caused by: org.postgresql.util.PSQLException: FATAL: password authentication failed for user "root"
	at org.postgresql.core.v3.ConnectionFactoryImpl.doAuthentication(ConnectionFactoryImpl.java:646)
	at org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:180)
	at org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:235)
	at org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:49)
	at org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:247)
	at org.postgresql.Driver.makeConnection(Driver.java:434)
	at org.postgresql.Driver.connect(Driver.java:291)
	at java.sql.DriverManager.getConnection(DriverManager.java:664)
	at java.sql.DriverManager.getConnection(DriverManager.java:247)
	at org.apache.dolphinscheduler.plugin.datasource.postgresql.param.PostgreSQLDataSourceProcessor.getConnection(PostgreSQLDataSourceProcessor.java:117)
	at org.apache.dolphinscheduler.plugin.datasource.api.client.BaseAdHocDataSourceClient.getConnection(BaseAdHocDataSourceClient.java:41)
	... 8 common frames omitted
[WI-748][TI-2038] - [INFO] 2024-04-29 17:42:03.925 +0800 o.a.d.p.t.a.u.ProcessUtils:[182] - Get appIds from worker 172.18.1.1:1234, taskLogPath: /opt/dolphinscheduler/logs/20240429/13426477386080/8/748/2038.log
[WI-748][TI-2038] - [INFO] 2024-04-29 17:42:03.926 +0800 o.a.d.p.t.a.u.LogUtils:[79] - Start finding appId in /opt/dolphinscheduler/logs/20240429/13426477386080/8/748/2038.log, fetch way: log 
[WI-748][TI-2038] - [INFO] 2024-04-29 17:42:03.926 +0800 o.a.d.p.t.a.u.ProcessUtils:[188] - The appId is empty
[WI-748][TI-2038] - [INFO] 2024-04-29 17:42:03.926 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[118] - Cancel the task successfully
[WI-748][TI-2038] - [INFO] 2024-04-29 17:42:03.932 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[125] - Get a exception when execute the task, will send the task status: FAILURE to master: 172.18.1.1:1234
[WI-748][TI-2038] - [INFO] 2024-04-29 17:42:03.933 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-0] - [INFO] 2024-04-29 17:42:03.992 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.858695652173913 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-2038] - [INFO] 2024-04-29 17:42:04.655 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=2038, success=true)
[WI-0][TI-2038] - [INFO] 2024-04-29 17:42:04.666 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=2038, success=true)
[WI-0][TI-0] - [INFO] 2024-04-29 17:42:05.779 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=2039, taskName=Persist in postgresql, firstSubmitTime=1714383725742, startTime=0, taskType=SQL, workflowInstanceHost=172.18.0.12:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13426477386080, processDefineVersion=8, appIds=null, processInstanceId=748, scheduleTime=0, globalParams=null, executorId=1, cmdTypeIfComplement=7, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[],"resourceList":[],"type":"POSTGRESQL","datasource":1,"sql":"${query}","sqlType":"0","preStatements":[],"postStatements":[],"displayRows":10}, environmentConfig=export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='Persist in postgresql'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, query=Property{prop='query', direct=IN, type=VARCHAR, value=''}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240429'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='2039'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13427698681952'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240429174205'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='748'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240428'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='es_filtered_data_persistence_subprocess'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13426477386080'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=org.apache.dolphinscheduler.plugin.task.api.parameters.resource.ResourceParametersHelper@423217de, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"query","direct":"IN","type":"VARCHAR","value":""}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-748][TI-2039] - [INFO] 2024-04-29 17:42:05.780 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: Persist in postgresql to wait queue success
[WI-748][TI-2039] - [INFO] 2024-04-29 17:42:05.781 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2039] - [INFO] 2024-04-29 17:42:05.783 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-748][TI-2039] - [INFO] 2024-04-29 17:42:05.783 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2039] - [INFO] 2024-04-29 17:42:05.783 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-748][TI-2039] - [INFO] 2024-04-29 17:42:05.783 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1714383725783
[WI-748][TI-2039] - [INFO] 2024-04-29 17:42:05.783 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 748_2039
[WI-748][TI-2039] - [INFO] 2024-04-29 17:42:05.784 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 2039,
  "taskName" : "Persist in postgresql",
  "firstSubmitTime" : 1714383725742,
  "startTime" : 1714383725783,
  "taskType" : "SQL",
  "workflowInstanceHost" : "172.18.0.12:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240429/13426477386080/8/748/2039.log",
  "processId" : 0,
  "processDefineCode" : 13426477386080,
  "processDefineVersion" : 8,
  "processInstanceId" : 748,
  "scheduleTime" : 0,
  "executorId" : 1,
  "cmdTypeIfComplement" : 7,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[],\"resourceList\":[],\"type\":\"POSTGRESQL\",\"datasource\":1,\"sql\":\"${query}\",\"sqlType\":\"0\",\"preStatements\":[],\"postStatements\":[],\"displayRows\":10}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "Persist in postgresql"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "query" : {
      "prop" : "query",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : ""
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240429"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "2039"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13427698681952"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240429174205"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "748"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240428"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "es_filtered_data_persistence_subprocess"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13426477386080"
    }
  },
  "taskAppId" : "748_2039",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "resourceParametersHelper" : {
    "resourceMap" : {
      "DATASOURCE" : {
        "1" : {
          "resourceType" : "DATASOURCE",
          "type" : "POSTGRESQL",
          "connectionParams" : "{\"user\":\"root\",\"password\":\"dolphinscheduler123\",\"address\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432\",\"database\":\"persistence\",\"jdbcUrl\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432/persistence\",\"driverClassName\":\"org.postgresql.Driver\",\"validationQuery\":\"select version()\"}",
          "DATASOURCE" : null
        }
      }
    }
  },
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"query\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-748][TI-2039] - [INFO] 2024-04-29 17:42:05.784 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2039] - [INFO] 2024-04-29 17:42:05.785 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-748][TI-2039] - [INFO] 2024-04-29 17:42:05.785 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2039] - [INFO] 2024-04-29 17:42:05.793 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-748][TI-2039] - [INFO] 2024-04-29 17:42:05.794 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-748][TI-2039] - [INFO] 2024-04-29 17:42:05.795 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_8/748/2039 check successfully
[WI-748][TI-2039] - [INFO] 2024-04-29 17:42:05.795 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.sql.SqlTaskChannel successfully
[WI-748][TI-2039] - [INFO] 2024-04-29 17:42:05.795 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-748][TI-2039] - [INFO] 2024-04-29 17:42:05.795 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-748][TI-2039] - [INFO] 2024-04-29 17:42:05.796 +0800 o.a.d.p.t.s.SqlTask:[99] - Initialize sql task parameter {
  "localParams" : [ ],
  "varPool" : null,
  "type" : "POSTGRESQL",
  "datasource" : 1,
  "sql" : "${query}",
  "sqlType" : 0,
  "sendEmail" : null,
  "displayRows" : 10,
  "udfs" : null,
  "showType" : null,
  "connParams" : null,
  "preStatements" : [ ],
  "postStatements" : [ ],
  "groupId" : 0,
  "title" : null,
  "limit" : 0
}
[WI-748][TI-2039] - [INFO] 2024-04-29 17:42:05.796 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SQL create successfully
[WI-748][TI-2039] - [INFO] 2024-04-29 17:42:05.796 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-748][TI-2039] - [INFO] 2024-04-29 17:42:05.796 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"query","direct":"IN","type":"VARCHAR","value":""}] successfully
[WI-748][TI-2039] - [INFO] 2024-04-29 17:42:05.796 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2039] - [INFO] 2024-04-29 17:42:05.797 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-748][TI-2039] - [INFO] 2024-04-29 17:42:05.797 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2039] - [INFO] 2024-04-29 17:42:05.797 +0800 o.a.d.p.t.s.SqlTask:[119] - Full sql parameters: SqlParameters{type='POSTGRESQL', datasource=1, sql='${query}', sqlType=0, sendEmail=null, displayRows=10, limit=0, udfs='null', showType='null', connParams='null', groupId='0', title='null', preStatements=[], postStatements=[]}
[WI-748][TI-2039] - [INFO] 2024-04-29 17:42:05.797 +0800 o.a.d.p.t.s.SqlTask:[120] - sql type : POSTGRESQL, datasource : 1, sql : ${query} , localParams : [],udfs : null,showType : null,connParams : null,varPool : [Property{prop='query', direct=IN, type=VARCHAR, value=''}] ,query max result limit  0
[WI-748][TI-2039] - [INFO] 2024-04-29 17:42:05.799 +0800 o.a.d.p.t.a.AbstractTask:[206] - setSqlParamsMap: Property with paramName: query put in sqlParamsMap of content ${query} successfully.
[WI-748][TI-2039] - [INFO] 2024-04-29 17:42:05.799 +0800 o.a.d.p.t.s.SqlTask:[410] - after replace sql , preparing : ?
[WI-748][TI-2039] - [INFO] 2024-04-29 17:42:05.799 +0800 o.a.d.p.t.s.SqlTask:[420] - Sql Params are replaced sql , parameters:(VARCHAR)
[WI-748][TI-2039] - [INFO] 2024-04-29 17:42:05.800 +0800 o.a.d.p.t.s.SqlTask:[489] - can't find udf function resource
[WI-748][TI-2039] - [WARN] 2024-04-29 17:42:05.800 +0800 n.s.c.j.SnowflakeConnectString:[136] - Connect strings must start with jdbc:snowflake://
[WI-748][TI-2039] - [ERROR] 2024-04-29 17:42:05.846 +0800 o.a.d.p.t.s.SqlTask:[217] - execute sql error: Create adhoc connection error
[WI-748][TI-2039] - [ERROR] 2024-04-29 17:42:05.847 +0800 o.a.d.p.t.s.SqlTask:[165] - sql task error
java.sql.SQLException: Create adhoc connection error
	at org.apache.dolphinscheduler.plugin.datasource.api.client.BaseAdHocDataSourceClient.getConnection(BaseAdHocDataSourceClient.java:43)
	at org.apache.dolphinscheduler.plugin.datasource.api.plugin.DataSourceClientProvider.getAdHocConnection(DataSourceClientProvider.java:97)
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.executeFuncAndSql(SqlTask.java:189)
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.handle(SqlTask.java:159)
	at org.apache.dolphinscheduler.server.worker.runner.DefaultWorkerTaskExecutor.executeTask(DefaultWorkerTaskExecutor.java:54)
	at org.apache.dolphinscheduler.server.worker.runner.WorkerTaskExecutor.run(WorkerTaskExecutor.java:175)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.postgresql.util.PSQLException: FATAL: password authentication failed for user "root"
	at org.postgresql.core.v3.ConnectionFactoryImpl.doAuthentication(ConnectionFactoryImpl.java:646)
	at org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:180)
	at org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:235)
	at org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:49)
	at org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:247)
	at org.postgresql.Driver.makeConnection(Driver.java:434)
	at org.postgresql.Driver.connect(Driver.java:291)
	at java.sql.DriverManager.getConnection(DriverManager.java:664)
	at java.sql.DriverManager.getConnection(DriverManager.java:247)
	at org.apache.dolphinscheduler.plugin.datasource.postgresql.param.PostgreSQLDataSourceProcessor.getConnection(PostgreSQLDataSourceProcessor.java:117)
	at org.apache.dolphinscheduler.plugin.datasource.api.client.BaseAdHocDataSourceClient.getConnection(BaseAdHocDataSourceClient.java:41)
	... 8 common frames omitted
[WI-748][TI-2039] - [ERROR] 2024-04-29 17:42:05.847 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[181] - Task execute failed, due to meet an exception
org.apache.dolphinscheduler.plugin.task.api.TaskException: Execute sql task failed
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.handle(SqlTask.java:166)
	at org.apache.dolphinscheduler.server.worker.runner.DefaultWorkerTaskExecutor.executeTask(DefaultWorkerTaskExecutor.java:54)
	at org.apache.dolphinscheduler.server.worker.runner.WorkerTaskExecutor.run(WorkerTaskExecutor.java:175)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.sql.SQLException: Create adhoc connection error
	at org.apache.dolphinscheduler.plugin.datasource.api.client.BaseAdHocDataSourceClient.getConnection(BaseAdHocDataSourceClient.java:43)
	at org.apache.dolphinscheduler.plugin.datasource.api.plugin.DataSourceClientProvider.getAdHocConnection(DataSourceClientProvider.java:97)
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.executeFuncAndSql(SqlTask.java:189)
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.handle(SqlTask.java:159)
	... 5 common frames omitted
Caused by: org.postgresql.util.PSQLException: FATAL: password authentication failed for user "root"
	at org.postgresql.core.v3.ConnectionFactoryImpl.doAuthentication(ConnectionFactoryImpl.java:646)
	at org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:180)
	at org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:235)
	at org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:49)
	at org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:247)
	at org.postgresql.Driver.makeConnection(Driver.java:434)
	at org.postgresql.Driver.connect(Driver.java:291)
	at java.sql.DriverManager.getConnection(DriverManager.java:664)
	at java.sql.DriverManager.getConnection(DriverManager.java:247)
	at org.apache.dolphinscheduler.plugin.datasource.postgresql.param.PostgreSQLDataSourceProcessor.getConnection(PostgreSQLDataSourceProcessor.java:117)
	at org.apache.dolphinscheduler.plugin.datasource.api.client.BaseAdHocDataSourceClient.getConnection(BaseAdHocDataSourceClient.java:41)
	... 8 common frames omitted
[WI-748][TI-2039] - [INFO] 2024-04-29 17:42:05.847 +0800 o.a.d.p.t.a.u.ProcessUtils:[182] - Get appIds from worker 172.18.1.1:1234, taskLogPath: /opt/dolphinscheduler/logs/20240429/13426477386080/8/748/2039.log
[WI-748][TI-2039] - [INFO] 2024-04-29 17:42:05.848 +0800 o.a.d.p.t.a.u.LogUtils:[79] - Start finding appId in /opt/dolphinscheduler/logs/20240429/13426477386080/8/748/2039.log, fetch way: log 
[WI-748][TI-2039] - [INFO] 2024-04-29 17:42:05.848 +0800 o.a.d.p.t.a.u.ProcessUtils:[188] - The appId is empty
[WI-748][TI-2039] - [INFO] 2024-04-29 17:42:05.848 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[118] - Cancel the task successfully
[WI-748][TI-2039] - [INFO] 2024-04-29 17:42:05.879 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[125] - Get a exception when execute the task, will send the task status: FAILURE to master: 172.18.1.1:1234
[WI-748][TI-2039] - [INFO] 2024-04-29 17:42:05.879 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-0] - [INFO] 2024-04-29 17:42:06.019 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7665615141955836 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-2039] - [INFO] 2024-04-29 17:42:06.673 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=2039, success=true)
[WI-0][TI-2039] - [INFO] 2024-04-29 17:42:06.682 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=2039, success=true)
[WI-0][TI-0] - [INFO] 2024-04-29 17:42:16.116 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7430167597765363 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-29 17:43:16.583 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7026239067055393 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-29 17:51:49.481 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7229916897506925 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-29 17:53:20.905 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7486033519553073 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-29 17:53:42.224 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=2040, taskName=consume_filtered_data, firstSubmitTime=1714384422198, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.12:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13426477386080, processDefineVersion=8, appIds=null, processInstanceId=748, scheduleTime=0, globalParams=null, executorId=1, cmdTypeIfComplement=7, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[],"rawScript":"# /bin/kafka-console-consumer.sh \\\n#     --bootstrap-server kafka:9092 \\\n#     --topic reddit_post_filtered \\\n#     --max-messages 10 \\\n#     --from-beginning \\\n#     --group filtered_data_consumer \n#     --timeout-ms 15000","resourceList":[]}, environmentConfig=export JAVA_HOME=/opt/java/openjdk, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='consume_filtered_data'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, query=Property{prop='query', direct=OUT, type=VARCHAR, value=''}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240429'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='2040'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13433255983872'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240429175342'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='748'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240428'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='es_filtered_data_persistence_subprocess'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13426477386080'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"query","direct":"OUT","type":"VARCHAR","value":""}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-748][TI-2040] - [INFO] 2024-04-29 17:53:42.226 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: consume_filtered_data to wait queue success
[WI-748][TI-2040] - [INFO] 2024-04-29 17:53:42.226 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2040] - [INFO] 2024-04-29 17:53:42.230 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-748][TI-2040] - [INFO] 2024-04-29 17:53:42.231 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2040] - [INFO] 2024-04-29 17:53:42.231 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-748][TI-2040] - [INFO] 2024-04-29 17:53:42.231 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1714384422231
[WI-748][TI-2040] - [INFO] 2024-04-29 17:53:42.231 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 748_2040
[WI-748][TI-2040] - [INFO] 2024-04-29 17:53:42.231 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 2040,
  "taskName" : "consume_filtered_data",
  "firstSubmitTime" : 1714384422198,
  "startTime" : 1714384422231,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.12:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240429/13426477386080/8/748/2040.log",
  "processId" : 0,
  "processDefineCode" : 13426477386080,
  "processDefineVersion" : 8,
  "processInstanceId" : 748,
  "scheduleTime" : 0,
  "executorId" : 1,
  "cmdTypeIfComplement" : 7,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[],\"rawScript\":\"# /bin/kafka-console-consumer.sh \\\\\\n#     --bootstrap-server kafka:9092 \\\\\\n#     --topic reddit_post_filtered \\\\\\n#     --max-messages 10 \\\\\\n#     --from-beginning \\\\\\n#     --group filtered_data_consumer \\n#     --timeout-ms 15000\",\"resourceList\":[]}",
  "environmentConfig" : "export JAVA_HOME=/opt/java/openjdk",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "consume_filtered_data"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "query" : {
      "prop" : "query",
      "direct" : "OUT",
      "type" : "VARCHAR",
      "value" : ""
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240429"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "2040"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13433255983872"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240429175342"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "748"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240428"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "es_filtered_data_persistence_subprocess"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13426477386080"
    }
  },
  "taskAppId" : "748_2040",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"query\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-748][TI-2040] - [INFO] 2024-04-29 17:53:42.232 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2040] - [INFO] 2024-04-29 17:53:42.232 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-748][TI-2040] - [INFO] 2024-04-29 17:53:42.232 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2040] - [INFO] 2024-04-29 17:53:42.248 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-748][TI-2040] - [INFO] 2024-04-29 17:53:42.250 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-748][TI-2040] - [INFO] 2024-04-29 17:53:42.252 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_8/748/2040 check successfully
[WI-748][TI-2040] - [INFO] 2024-04-29 17:53:42.252 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-748][TI-2040] - [INFO] 2024-04-29 17:53:42.254 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-748][TI-2040] - [INFO] 2024-04-29 17:53:42.255 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-748][TI-2040] - [INFO] 2024-04-29 17:53:42.255 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-748][TI-2040] - [INFO] 2024-04-29 17:53:42.259 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ ],
  "varPool" : null,
  "rawScript" : "# /bin/kafka-console-consumer.sh \\\n#     --bootstrap-server kafka:9092 \\\n#     --topic reddit_post_filtered \\\n#     --max-messages 10 \\\n#     --from-beginning \\\n#     --group filtered_data_consumer \n#     --timeout-ms 15000",
  "resourceList" : [ ]
}
[WI-748][TI-2040] - [INFO] 2024-04-29 17:53:42.259 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-748][TI-2040] - [INFO] 2024-04-29 17:53:42.260 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"query","direct":"OUT","type":"VARCHAR","value":""}] successfully
[WI-748][TI-2040] - [INFO] 2024-04-29 17:53:42.260 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2040] - [INFO] 2024-04-29 17:53:42.260 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-748][TI-2040] - [INFO] 2024-04-29 17:53:42.260 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2040] - [INFO] 2024-04-29 17:53:42.263 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-748][TI-2040] - [INFO] 2024-04-29 17:53:42.264 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-748][TI-2040] - [INFO] 2024-04-29 17:53:42.264 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export JAVA_HOME=/opt/java/openjdk
# /bin/kafka-console-consumer.sh \
#     --bootstrap-server kafka:9092 \
#     --topic reddit_post_filtered \
#     --max-messages 10 \
#     --from-beginning \
#     --group filtered_data_consumer 
#     --timeout-ms 15000
[WI-748][TI-2040] - [INFO] 2024-04-29 17:53:42.264 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-748][TI-2040] - [INFO] 2024-04-29 17:53:42.264 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_8/748/2040/748_2040.sh
[WI-748][TI-2040] - [INFO] 2024-04-29 17:53:42.269 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 266
[WI-0][TI-0] - [INFO] 2024-04-29 17:53:43.478 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
[WI-748][TI-2040] - [INFO] 2024-04-29 17:53:43.514 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_8/748/2040, processId:266 ,exitStatusCode:0 ,processWaitForStatus:true ,processExitValue:0
[WI-748][TI-2040] - [INFO] 2024-04-29 17:53:43.515 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2040] - [INFO] 2024-04-29 17:53:43.515 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-748][TI-2040] - [INFO] 2024-04-29 17:53:43.515 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2040] - [INFO] 2024-04-29 17:53:43.516 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-748][TI-2040] - [INFO] 2024-04-29 17:53:43.538 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: SUCCESS to master : 172.18.1.1:1234
[WI-748][TI-2040] - [INFO] 2024-04-29 17:53:43.542 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-748][TI-2040] - [INFO] 2024-04-29 17:53:43.542 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_8/748/2040
[WI-748][TI-2040] - [INFO] 2024-04-29 17:53:43.542 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_8/748/2040
[WI-748][TI-2040] - [INFO] 2024-04-29 17:53:43.543 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-2040] - [INFO] 2024-04-29 17:53:43.554 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=2040, success=true)
[WI-0][TI-2040] - [INFO] 2024-04-29 17:53:43.577 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=2040)
[WI-0][TI-2040] - [INFO] 2024-04-29 17:53:43.596 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=2040, success=true)
[WI-0][TI-0] - [INFO] 2024-04-29 17:53:43.726 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=2041, taskName=persist_to_postgre, firstSubmitTime=1714384423689, startTime=0, taskType=PYTHON, workflowInstanceHost=172.18.0.12:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13426477386080, processDefineVersion=8, appIds=null, processInstanceId=748, scheduleTime=0, globalParams=null, executorId=1, cmdTypeIfComplement=7, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[{"prop":"query","direct":"OUT","type":"VARCHAR","value":""}],"rawScript":"import re\nimport json\n\n# define the table to send the data to\ntable_name = \"filtered_data_persistence\"\n\n# Provided JSON data as strings\njson_data = ''' \n{\n  \"user\": \"premiumplatinum\",\n  \"content\": \"singapore is stupid\",\n  \"url\": \"https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/\",\n  \"context\": \"21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist\",\n  \"score\": 131,\n  \"type\": \"post\",\n  \"id\": \"1c9itat\",\n  \"datetime\": \"2024-04-21 22:10:42\"\n}\n{\n        \"user\": \"premiumplatinum\",\n        \"content\": \"s is stupid\",\n        \"url\": \"https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/\",\n        \"context\": \"21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist\",\n        \"score\": 131,\n        \"type\": \"post\",\n        \"id\": \"1c9itat\",\n        \"datetime\": \"2024-04-21 22:10:42\"\n}\n'''\n\n# process the kafka messages to individual JSON objects\njson_objects = json_data.replace('}\\n{', '},\\n{').strip()\njson_objects = re.sub(\" +\", \" \",json_objects)   \njson_objects = '[' + json_objects + ']'\n\n# convert JSON string to a list of dicts\njson_list = json.loads(json_objects)\n\n# convert list of dictionaries into list of tuples containing only the values\nvalues = [tuple(message.values()) for message in json_list]\n\n# create the SQL Query\nquery = f'''\nINSERT INTO {table_name} (user, content, url, context, score, type, id, datetime)\nVALUES \n'''\n\nfor value in values:\n    query += str(value) + ',\\n'\n\n# remove the last 2 character ,\\n and change it to ; for the query\nquery = query[:-2] + ';'\n\n# pass the query as a parameter downstream\nprint(\"#setValue(query=%s)\" % query)","resourceList":[]}, environmentConfig=export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='persist_to_postgre'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, query=Property{prop='query', direct=IN, type=VARCHAR, value=''}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240429'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='2041'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13426451158240'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240429175343'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='748'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240428'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='es_filtered_data_persistence_subprocess'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13426477386080'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"query","direct":"IN","type":"VARCHAR","value":""}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-748][TI-2041] - [INFO] 2024-04-29 17:53:43.729 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: persist_to_postgre to wait queue success
[WI-748][TI-2041] - [INFO] 2024-04-29 17:53:43.729 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2041] - [INFO] 2024-04-29 17:53:43.730 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-748][TI-2041] - [INFO] 2024-04-29 17:53:43.731 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2041] - [INFO] 2024-04-29 17:53:43.731 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-748][TI-2041] - [INFO] 2024-04-29 17:53:43.731 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1714384423731
[WI-748][TI-2041] - [INFO] 2024-04-29 17:53:43.731 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 748_2041
[WI-748][TI-2041] - [INFO] 2024-04-29 17:53:43.732 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 2041,
  "taskName" : "persist_to_postgre",
  "firstSubmitTime" : 1714384423689,
  "startTime" : 1714384423731,
  "taskType" : "PYTHON",
  "workflowInstanceHost" : "172.18.0.12:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240429/13426477386080/8/748/2041.log",
  "processId" : 0,
  "processDefineCode" : 13426477386080,
  "processDefineVersion" : 8,
  "processInstanceId" : 748,
  "scheduleTime" : 0,
  "executorId" : 1,
  "cmdTypeIfComplement" : 7,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[{\"prop\":\"query\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"\"}],\"rawScript\":\"import re\\nimport json\\n\\n# define the table to send the data to\\ntable_name = \\\"filtered_data_persistence\\\"\\n\\n# Provided JSON data as strings\\njson_data = ''' \\n{\\n  \\\"user\\\": \\\"premiumplatinum\\\",\\n  \\\"content\\\": \\\"singapore is stupid\\\",\\n  \\\"url\\\": \\\"https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/\\\",\\n  \\\"context\\\": \\\"21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist\\\",\\n  \\\"score\\\": 131,\\n  \\\"type\\\": \\\"post\\\",\\n  \\\"id\\\": \\\"1c9itat\\\",\\n  \\\"datetime\\\": \\\"2024-04-21 22:10:42\\\"\\n}\\n{\\n        \\\"user\\\": \\\"premiumplatinum\\\",\\n        \\\"content\\\": \\\"s is stupid\\\",\\n        \\\"url\\\": \\\"https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/\\\",\\n        \\\"context\\\": \\\"21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist\\\",\\n        \\\"score\\\": 131,\\n        \\\"type\\\": \\\"post\\\",\\n        \\\"id\\\": \\\"1c9itat\\\",\\n        \\\"datetime\\\": \\\"2024-04-21 22:10:42\\\"\\n}\\n'''\\n\\n# process the kafka messages to individual JSON objects\\njson_objects = json_data.replace('}\\\\n{', '},\\\\n{').strip()\\njson_objects = re.sub(\\\" +\\\", \\\" \\\",json_objects)   \\njson_objects = '[' + json_objects + ']'\\n\\n# convert JSON string to a list of dicts\\njson_list = json.loads(json_objects)\\n\\n# convert list of dictionaries into list of tuples containing only the values\\nvalues = [tuple(message.values()) for message in json_list]\\n\\n# create the SQL Query\\nquery = f'''\\nINSERT INTO {table_name} (user, content, url, context, score, type, id, datetime)\\nVALUES \\n'''\\n\\nfor value in values:\\n    query += str(value) + ',\\\\n'\\n\\n# remove the last 2 character ,\\\\n and change it to ; for the query\\nquery = query[:-2] + ';'\\n\\n# pass the query as a parameter downstream\\nprint(\\\"#setValue(query=%s)\\\" % query)\",\"resourceList\":[]}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "persist_to_postgre"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "query" : {
      "prop" : "query",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : ""
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240429"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "2041"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13426451158240"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240429175343"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "748"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240428"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "es_filtered_data_persistence_subprocess"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13426477386080"
    }
  },
  "taskAppId" : "748_2041",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"query\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-748][TI-2041] - [INFO] 2024-04-29 17:53:43.734 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2041] - [INFO] 2024-04-29 17:53:43.734 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-748][TI-2041] - [INFO] 2024-04-29 17:53:43.734 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2041] - [INFO] 2024-04-29 17:53:43.741 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-748][TI-2041] - [INFO] 2024-04-29 17:53:43.741 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-748][TI-2041] - [INFO] 2024-04-29 17:53:43.742 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_8/748/2041 check successfully
[WI-748][TI-2041] - [INFO] 2024-04-29 17:53:43.742 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.python.PythonTaskChannel successfully
[WI-748][TI-2041] - [INFO] 2024-04-29 17:53:43.742 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-748][TI-2041] - [INFO] 2024-04-29 17:53:43.743 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-748][TI-2041] - [INFO] 2024-04-29 17:53:43.744 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: PYTHON create successfully
[WI-748][TI-2041] - [INFO] 2024-04-29 17:53:43.746 +0800 o.a.d.p.t.p.PythonTask:[75] - Initialize python task params {
  "localParams" : [ {
    "prop" : "query",
    "direct" : "OUT",
    "type" : "VARCHAR",
    "value" : ""
  } ],
  "varPool" : null,
  "rawScript" : "import re\nimport json\n\n# define the table to send the data to\ntable_name = \"filtered_data_persistence\"\n\n# Provided JSON data as strings\njson_data = ''' \n{\n  \"user\": \"premiumplatinum\",\n  \"content\": \"singapore is stupid\",\n  \"url\": \"https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/\",\n  \"context\": \"21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist\",\n  \"score\": 131,\n  \"type\": \"post\",\n  \"id\": \"1c9itat\",\n  \"datetime\": \"2024-04-21 22:10:42\"\n}\n{\n        \"user\": \"premiumplatinum\",\n        \"content\": \"s is stupid\",\n        \"url\": \"https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/\",\n        \"context\": \"21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist\",\n        \"score\": 131,\n        \"type\": \"post\",\n        \"id\": \"1c9itat\",\n        \"datetime\": \"2024-04-21 22:10:42\"\n}\n'''\n\n# process the kafka messages to individual JSON objects\njson_objects = json_data.replace('}\\n{', '},\\n{').strip()\njson_objects = re.sub(\" +\", \" \",json_objects)   \njson_objects = '[' + json_objects + ']'\n\n# convert JSON string to a list of dicts\njson_list = json.loads(json_objects)\n\n# convert list of dictionaries into list of tuples containing only the values\nvalues = [tuple(message.values()) for message in json_list]\n\n# create the SQL Query\nquery = f'''\nINSERT INTO {table_name} (user, content, url, context, score, type, id, datetime)\nVALUES \n'''\n\nfor value in values:\n    query += str(value) + ',\\n'\n\n# remove the last 2 character ,\\n and change it to ; for the query\nquery = query[:-2] + ';'\n\n# pass the query as a parameter downstream\nprint(\"#setValue(query=%s)\" % query)",
  "resourceList" : [ ]
}
[WI-748][TI-2041] - [INFO] 2024-04-29 17:53:43.747 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-748][TI-2041] - [INFO] 2024-04-29 17:53:43.747 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"query","direct":"IN","type":"VARCHAR","value":""}] successfully
[WI-748][TI-2041] - [INFO] 2024-04-29 17:53:43.748 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2041] - [INFO] 2024-04-29 17:53:43.749 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-748][TI-2041] - [INFO] 2024-04-29 17:53:43.749 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2041] - [INFO] 2024-04-29 17:53:43.749 +0800 o.a.d.p.t.p.PythonTask:[165] - raw python script : import re
import json

# define the table to send the data to
table_name = "filtered_data_persistence"

# Provided JSON data as strings
json_data = ''' 
{
  "user": "premiumplatinum",
  "content": "singapore is stupid",
  "url": "https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/",
  "context": "21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist",
  "score": 131,
  "type": "post",
  "id": "1c9itat",
  "datetime": "2024-04-21 22:10:42"
}
{
        "user": "premiumplatinum",
        "content": "s is stupid",
        "url": "https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/",
        "context": "21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist",
        "score": 131,
        "type": "post",
        "id": "1c9itat",
        "datetime": "2024-04-21 22:10:42"
}
'''

# process the kafka messages to individual JSON objects
json_objects = json_data.replace('}\n{', '},\n{').strip()
json_objects = re.sub(" +", " ",json_objects)   
json_objects = '[' + json_objects + ']'

# convert JSON string to a list of dicts
json_list = json.loads(json_objects)

# convert list of dictionaries into list of tuples containing only the values
values = [tuple(message.values()) for message in json_list]

# create the SQL Query
query = f'''
INSERT INTO {table_name} (user, content, url, context, score, type, id, datetime)
VALUES 
'''

for value in values:
    query += str(value) + ',\n'

# remove the last 2 character ,\n and change it to ; for the query
query = query[:-2] + ';'

# pass the query as a parameter downstream
print("#setValue(query=%s)" % query)
[WI-748][TI-2041] - [INFO] 2024-04-29 17:53:43.751 +0800 o.a.d.p.t.p.PythonTask:[131] - tenantCode :default, task dir:/tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_8/748/2041
[WI-748][TI-2041] - [INFO] 2024-04-29 17:53:43.751 +0800 o.a.d.p.t.p.PythonTask:[134] - generate python script file:/tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_8/748/2041/py_748_2041.py
[WI-748][TI-2041] - [INFO] 2024-04-29 17:53:43.751 +0800 o.a.d.p.t.p.PythonTask:[141] - #-*- encoding=utf8 -*-

import re
import json

# define the table to send the data to
table_name = "filtered_data_persistence"

# Provided JSON data as strings
json_data = ''' 
{
  "user": "premiumplatinum",
  "content": "singapore is stupid",
  "url": "https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/",
  "context": "21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist",
  "score": 131,
  "type": "post",
  "id": "1c9itat",
  "datetime": "2024-04-21 22:10:42"
}
{
        "user": "premiumplatinum",
        "content": "s is stupid",
        "url": "https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/",
        "context": "21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist",
        "score": 131,
        "type": "post",
        "id": "1c9itat",
        "datetime": "2024-04-21 22:10:42"
}
'''

# process the kafka messages to individual JSON objects
json_objects = json_data.replace('}\n{', '},\n{').strip()
json_objects = re.sub(" +", " ",json_objects)   
json_objects = '[' + json_objects + ']'

# convert JSON string to a list of dicts
json_list = json.loads(json_objects)

# convert list of dictionaries into list of tuples containing only the values
values = [tuple(message.values()) for message in json_list]

# create the SQL Query
query = f'''
INSERT INTO {table_name} (user, content, url, context, score, type, id, datetime)
VALUES 
'''

for value in values:
    query += str(value) + ',\n'

# remove the last 2 character ,\n and change it to ; for the query
query = query[:-2] + ';'

# pass the query as a parameter downstream
print("#setValue(query=%s)" % query)
[WI-748][TI-2041] - [INFO] 2024-04-29 17:53:43.752 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-748][TI-2041] - [INFO] 2024-04-29 17:53:43.752 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-748][TI-2041] - [INFO] 2024-04-29 17:53:43.752 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export PYTHON_LAUNCHER=/bin/python3.11
${PYTHON_LAUNCHER} /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_8/748/2041/py_748_2041.py
[WI-748][TI-2041] - [INFO] 2024-04-29 17:53:43.752 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-748][TI-2041] - [INFO] 2024-04-29 17:53:43.753 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_8/748/2041/748_2041.sh
[WI-748][TI-2041] - [INFO] 2024-04-29 17:53:43.757 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 277
[WI-0][TI-2041] - [INFO] 2024-04-29 17:53:44.499 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=2041, success=true)
[WI-0][TI-2041] - [INFO] 2024-04-29 17:53:44.517 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=2041)
[WI-0][TI-0] - [INFO] 2024-04-29 17:53:44.757 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
	#setValue(query=
	INSERT INTO filtered_data_persistence (user, content, url, context, score, type, id, datetime)
	VALUES 
	('premiumplatinum', 'singapore is stupid', 'https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/', '21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist', 131, 'post', '1c9itat', '2024-04-21 22:10:42'),
	('premiumplatinum', 's is stupid', 'https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/', '21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist', 131, 'post', '1c9itat', '2024-04-21 22:10:42');)
[WI-748][TI-2041] - [INFO] 2024-04-29 17:53:44.767 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_8/748/2041, processId:277 ,exitStatusCode:0 ,processWaitForStatus:true ,processExitValue:0
[WI-748][TI-2041] - [INFO] 2024-04-29 17:53:44.767 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2041] - [INFO] 2024-04-29 17:53:44.769 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-748][TI-2041] - [INFO] 2024-04-29 17:53:44.769 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2041] - [INFO] 2024-04-29 17:53:44.770 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-748][TI-2041] - [INFO] 2024-04-29 17:53:44.773 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: SUCCESS to master : 172.18.1.1:1234
[WI-748][TI-2041] - [INFO] 2024-04-29 17:53:44.774 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-748][TI-2041] - [INFO] 2024-04-29 17:53:44.774 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_8/748/2041
[WI-748][TI-2041] - [INFO] 2024-04-29 17:53:44.775 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_8/748/2041
[WI-748][TI-2041] - [INFO] 2024-04-29 17:53:44.775 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-2041] - [INFO] 2024-04-29 17:53:45.498 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=2041, success=true)
[WI-0][TI-0] - [INFO] 2024-04-29 17:53:45.553 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=2042, taskName=Persist in postgresql, firstSubmitTime=1714384425545, startTime=0, taskType=SQL, workflowInstanceHost=172.18.0.12:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13426477386080, processDefineVersion=8, appIds=null, processInstanceId=748, scheduleTime=0, globalParams=null, executorId=1, cmdTypeIfComplement=7, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[],"resourceList":[],"type":"POSTGRESQL","datasource":1,"sql":"${query}","sqlType":"0","preStatements":[],"postStatements":[],"displayRows":10}, environmentConfig=export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='Persist in postgresql'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, query=Property{prop='query', direct=IN, type=VARCHAR, value=''}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240429'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='2042'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13427698681952'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240429175345'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='748'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240428'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='es_filtered_data_persistence_subprocess'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13426477386080'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=org.apache.dolphinscheduler.plugin.task.api.parameters.resource.ResourceParametersHelper@20586244, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"query","direct":"IN","type":"VARCHAR","value":""}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-748][TI-2042] - [INFO] 2024-04-29 17:53:45.554 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: Persist in postgresql to wait queue success
[WI-748][TI-2042] - [INFO] 2024-04-29 17:53:45.554 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2042] - [INFO] 2024-04-29 17:53:45.556 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-748][TI-2042] - [INFO] 2024-04-29 17:53:45.556 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2042] - [INFO] 2024-04-29 17:53:45.556 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-748][TI-2042] - [INFO] 2024-04-29 17:53:45.556 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1714384425556
[WI-748][TI-2042] - [INFO] 2024-04-29 17:53:45.556 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 748_2042
[WI-748][TI-2042] - [INFO] 2024-04-29 17:53:45.557 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 2042,
  "taskName" : "Persist in postgresql",
  "firstSubmitTime" : 1714384425545,
  "startTime" : 1714384425556,
  "taskType" : "SQL",
  "workflowInstanceHost" : "172.18.0.12:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240429/13426477386080/8/748/2042.log",
  "processId" : 0,
  "processDefineCode" : 13426477386080,
  "processDefineVersion" : 8,
  "processInstanceId" : 748,
  "scheduleTime" : 0,
  "executorId" : 1,
  "cmdTypeIfComplement" : 7,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[],\"resourceList\":[],\"type\":\"POSTGRESQL\",\"datasource\":1,\"sql\":\"${query}\",\"sqlType\":\"0\",\"preStatements\":[],\"postStatements\":[],\"displayRows\":10}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "Persist in postgresql"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "query" : {
      "prop" : "query",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : ""
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240429"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "2042"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13427698681952"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240429175345"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "748"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240428"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "es_filtered_data_persistence_subprocess"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13426477386080"
    }
  },
  "taskAppId" : "748_2042",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "resourceParametersHelper" : {
    "resourceMap" : {
      "DATASOURCE" : {
        "1" : {
          "resourceType" : "DATASOURCE",
          "type" : "POSTGRESQL",
          "connectionParams" : "{\"user\":\"root\",\"password\":\"******\",\"address\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432\",\"database\":\"persistence\",\"jdbcUrl\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432/persistence\",\"driverClassName\":\"org.postgresql.Driver\",\"validationQuery\":\"select version()\",\"other\":{\"password\":\"root\"}}",
          "DATASOURCE" : null
        }
      }
    }
  },
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"query\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-748][TI-2042] - [INFO] 2024-04-29 17:53:45.557 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2042] - [INFO] 2024-04-29 17:53:45.557 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-748][TI-2042] - [INFO] 2024-04-29 17:53:45.558 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2042] - [INFO] 2024-04-29 17:53:45.560 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-748][TI-2042] - [INFO] 2024-04-29 17:53:45.561 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-748][TI-2042] - [INFO] 2024-04-29 17:53:45.561 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_8/748/2042 check successfully
[WI-748][TI-2042] - [INFO] 2024-04-29 17:53:45.561 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.sql.SqlTaskChannel successfully
[WI-748][TI-2042] - [INFO] 2024-04-29 17:53:45.561 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-748][TI-2042] - [INFO] 2024-04-29 17:53:45.562 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-748][TI-2042] - [INFO] 2024-04-29 17:53:45.562 +0800 o.a.d.p.t.s.SqlTask:[99] - Initialize sql task parameter {
  "localParams" : [ ],
  "varPool" : null,
  "type" : "POSTGRESQL",
  "datasource" : 1,
  "sql" : "${query}",
  "sqlType" : 0,
  "sendEmail" : null,
  "displayRows" : 10,
  "udfs" : null,
  "showType" : null,
  "connParams" : null,
  "preStatements" : [ ],
  "postStatements" : [ ],
  "groupId" : 0,
  "title" : null,
  "limit" : 0
}
[WI-748][TI-2042] - [INFO] 2024-04-29 17:53:45.562 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SQL create successfully
[WI-748][TI-2042] - [INFO] 2024-04-29 17:53:45.562 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-748][TI-2042] - [INFO] 2024-04-29 17:53:45.562 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"query","direct":"IN","type":"VARCHAR","value":""}] successfully
[WI-748][TI-2042] - [INFO] 2024-04-29 17:53:45.563 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2042] - [INFO] 2024-04-29 17:53:45.563 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-748][TI-2042] - [INFO] 2024-04-29 17:53:45.563 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2042] - [INFO] 2024-04-29 17:53:45.563 +0800 o.a.d.p.t.s.SqlTask:[119] - Full sql parameters: SqlParameters{type='POSTGRESQL', datasource=1, sql='${query}', sqlType=0, sendEmail=null, displayRows=10, limit=0, udfs='null', showType='null', connParams='null', groupId='0', title='null', preStatements=[], postStatements=[]}
[WI-748][TI-2042] - [INFO] 2024-04-29 17:53:45.563 +0800 o.a.d.p.t.s.SqlTask:[120] - sql type : POSTGRESQL, datasource : 1, sql : ${query} , localParams : [],udfs : null,showType : null,connParams : null,varPool : [Property{prop='query', direct=IN, type=VARCHAR, value=''}] ,query max result limit  0
[WI-748][TI-2042] - [INFO] 2024-04-29 17:53:45.563 +0800 o.a.d.p.t.a.AbstractTask:[206] - setSqlParamsMap: Property with paramName: query put in sqlParamsMap of content ${query} successfully.
[WI-748][TI-2042] - [INFO] 2024-04-29 17:53:45.564 +0800 o.a.d.p.t.s.SqlTask:[410] - after replace sql , preparing : ?
[WI-748][TI-2042] - [INFO] 2024-04-29 17:53:45.564 +0800 o.a.d.p.t.s.SqlTask:[420] - Sql Params are replaced sql , parameters:(VARCHAR)
[WI-748][TI-2042] - [INFO] 2024-04-29 17:53:45.564 +0800 o.a.d.p.t.s.SqlTask:[489] - can't find udf function resource
[WI-748][TI-2042] - [WARN] 2024-04-29 17:53:45.565 +0800 n.s.c.j.SnowflakeConnectString:[136] - Connect strings must start with jdbc:snowflake://
[WI-748][TI-2042] - [INFO] 2024-04-29 17:53:45.651 +0800 o.a.d.p.t.s.SqlTask:[392] - prepare statement replace sql : ?, sql parameters : {1=Property{prop='query', direct=IN, type=VARCHAR, value=''}}
[WI-748][TI-2042] - [INFO] 2024-04-29 17:53:45.651 +0800 o.a.d.p.t.s.SqlTask:[316] - main statement execute query, for sql: ?
[WI-748][TI-2042] - [ERROR] 2024-04-29 17:53:45.663 +0800 o.a.d.p.t.s.SqlTask:[217] - execute sql error: ERROR: syntax error at or near "$1"
  Position: 1
[WI-748][TI-2042] - [ERROR] 2024-04-29 17:53:45.664 +0800 o.a.d.p.t.s.SqlTask:[165] - sql task error
org.postgresql.util.PSQLException: ERROR: syntax error at or near "$1"
  Position: 1
	at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2676)
	at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2366)
	at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:356)
	at org.postgresql.jdbc.PgStatement.executeInternal(PgStatement.java:490)
	at org.postgresql.jdbc.PgStatement.execute(PgStatement.java:408)
	at org.postgresql.jdbc.PgPreparedStatement.executeWithFlags(PgPreparedStatement.java:181)
	at org.postgresql.jdbc.PgPreparedStatement.executeQuery(PgPreparedStatement.java:133)
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.executeQuery(SqlTask.java:317)
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.executeFuncAndSql(SqlTask.java:205)
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.handle(SqlTask.java:159)
	at org.apache.dolphinscheduler.server.worker.runner.DefaultWorkerTaskExecutor.executeTask(DefaultWorkerTaskExecutor.java:54)
	at org.apache.dolphinscheduler.server.worker.runner.WorkerTaskExecutor.run(WorkerTaskExecutor.java:175)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
[WI-748][TI-2042] - [ERROR] 2024-04-29 17:53:45.664 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[181] - Task execute failed, due to meet an exception
org.apache.dolphinscheduler.plugin.task.api.TaskException: Execute sql task failed
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.handle(SqlTask.java:166)
	at org.apache.dolphinscheduler.server.worker.runner.DefaultWorkerTaskExecutor.executeTask(DefaultWorkerTaskExecutor.java:54)
	at org.apache.dolphinscheduler.server.worker.runner.WorkerTaskExecutor.run(WorkerTaskExecutor.java:175)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.postgresql.util.PSQLException: ERROR: syntax error at or near "$1"
  Position: 1
	at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2676)
	at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2366)
	at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:356)
	at org.postgresql.jdbc.PgStatement.executeInternal(PgStatement.java:490)
	at org.postgresql.jdbc.PgStatement.execute(PgStatement.java:408)
	at org.postgresql.jdbc.PgPreparedStatement.executeWithFlags(PgPreparedStatement.java:181)
	at org.postgresql.jdbc.PgPreparedStatement.executeQuery(PgPreparedStatement.java:133)
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.executeQuery(SqlTask.java:317)
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.executeFuncAndSql(SqlTask.java:205)
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.handle(SqlTask.java:159)
	... 5 common frames omitted
[WI-748][TI-2042] - [INFO] 2024-04-29 17:53:45.664 +0800 o.a.d.p.t.a.u.ProcessUtils:[182] - Get appIds from worker 172.18.1.1:1234, taskLogPath: /opt/dolphinscheduler/logs/20240429/13426477386080/8/748/2042.log
[WI-748][TI-2042] - [INFO] 2024-04-29 17:53:45.664 +0800 o.a.d.p.t.a.u.LogUtils:[79] - Start finding appId in /opt/dolphinscheduler/logs/20240429/13426477386080/8/748/2042.log, fetch way: log 
[WI-748][TI-2042] - [INFO] 2024-04-29 17:53:45.665 +0800 o.a.d.p.t.a.u.ProcessUtils:[188] - The appId is empty
[WI-748][TI-2042] - [INFO] 2024-04-29 17:53:45.665 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[118] - Cancel the task successfully
[WI-748][TI-2042] - [INFO] 2024-04-29 17:53:45.668 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[125] - Get a exception when execute the task, will send the task status: FAILURE to master: 172.18.1.1:1234
[WI-748][TI-2042] - [INFO] 2024-04-29 17:53:45.669 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-0] - [INFO] 2024-04-29 17:53:46.485 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7694610778443114 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-2042] - [INFO] 2024-04-29 17:53:46.512 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=2042, success=true)
[WI-0][TI-2042] - [INFO] 2024-04-29 17:53:46.524 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=2042, success=true)
[WI-0][TI-0] - [INFO] 2024-04-29 17:53:47.608 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=2043, taskName=Persist in postgresql, firstSubmitTime=1714384427587, startTime=0, taskType=SQL, workflowInstanceHost=172.18.0.12:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13426477386080, processDefineVersion=8, appIds=null, processInstanceId=748, scheduleTime=0, globalParams=null, executorId=1, cmdTypeIfComplement=7, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[],"resourceList":[],"type":"POSTGRESQL","datasource":1,"sql":"${query}","sqlType":"0","preStatements":[],"postStatements":[],"displayRows":10}, environmentConfig=export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='Persist in postgresql'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, query=Property{prop='query', direct=IN, type=VARCHAR, value=''}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240429'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='2043'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13427698681952'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240429175347'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='748'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240428'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='es_filtered_data_persistence_subprocess'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13426477386080'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=org.apache.dolphinscheduler.plugin.task.api.parameters.resource.ResourceParametersHelper@48ca7cae, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"query","direct":"IN","type":"VARCHAR","value":""}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-748][TI-2043] - [INFO] 2024-04-29 17:53:47.609 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: Persist in postgresql to wait queue success
[WI-748][TI-2043] - [INFO] 2024-04-29 17:53:47.610 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2043] - [INFO] 2024-04-29 17:53:47.612 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-748][TI-2043] - [INFO] 2024-04-29 17:53:47.612 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2043] - [INFO] 2024-04-29 17:53:47.612 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-748][TI-2043] - [INFO] 2024-04-29 17:53:47.612 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1714384427612
[WI-748][TI-2043] - [INFO] 2024-04-29 17:53:47.614 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 748_2043
[WI-748][TI-2043] - [INFO] 2024-04-29 17:53:47.615 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 2043,
  "taskName" : "Persist in postgresql",
  "firstSubmitTime" : 1714384427587,
  "startTime" : 1714384427612,
  "taskType" : "SQL",
  "workflowInstanceHost" : "172.18.0.12:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240429/13426477386080/8/748/2043.log",
  "processId" : 0,
  "processDefineCode" : 13426477386080,
  "processDefineVersion" : 8,
  "processInstanceId" : 748,
  "scheduleTime" : 0,
  "executorId" : 1,
  "cmdTypeIfComplement" : 7,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[],\"resourceList\":[],\"type\":\"POSTGRESQL\",\"datasource\":1,\"sql\":\"${query}\",\"sqlType\":\"0\",\"preStatements\":[],\"postStatements\":[],\"displayRows\":10}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "Persist in postgresql"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "query" : {
      "prop" : "query",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : ""
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240429"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "2043"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13427698681952"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240429175347"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "748"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240428"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "es_filtered_data_persistence_subprocess"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13426477386080"
    }
  },
  "taskAppId" : "748_2043",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "resourceParametersHelper" : {
    "resourceMap" : {
      "DATASOURCE" : {
        "1" : {
          "resourceType" : "DATASOURCE",
          "type" : "POSTGRESQL",
          "connectionParams" : "{\"user\":\"root\",\"password\":\"******\",\"address\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432\",\"database\":\"persistence\",\"jdbcUrl\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432/persistence\",\"driverClassName\":\"org.postgresql.Driver\",\"validationQuery\":\"select version()\",\"other\":{\"password\":\"root\"}}",
          "DATASOURCE" : null
        }
      }
    }
  },
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"query\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-748][TI-2043] - [INFO] 2024-04-29 17:53:47.615 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2043] - [INFO] 2024-04-29 17:53:47.615 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-748][TI-2043] - [INFO] 2024-04-29 17:53:47.615 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2043] - [INFO] 2024-04-29 17:53:47.629 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-748][TI-2043] - [INFO] 2024-04-29 17:53:47.630 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-748][TI-2043] - [INFO] 2024-04-29 17:53:47.630 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_8/748/2043 check successfully
[WI-748][TI-2043] - [INFO] 2024-04-29 17:53:47.631 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.sql.SqlTaskChannel successfully
[WI-748][TI-2043] - [INFO] 2024-04-29 17:53:47.631 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-748][TI-2043] - [INFO] 2024-04-29 17:53:47.632 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-748][TI-2043] - [INFO] 2024-04-29 17:53:47.633 +0800 o.a.d.p.t.s.SqlTask:[99] - Initialize sql task parameter {
  "localParams" : [ ],
  "varPool" : null,
  "type" : "POSTGRESQL",
  "datasource" : 1,
  "sql" : "${query}",
  "sqlType" : 0,
  "sendEmail" : null,
  "displayRows" : 10,
  "udfs" : null,
  "showType" : null,
  "connParams" : null,
  "preStatements" : [ ],
  "postStatements" : [ ],
  "groupId" : 0,
  "title" : null,
  "limit" : 0
}
[WI-748][TI-2043] - [INFO] 2024-04-29 17:53:47.633 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SQL create successfully
[WI-748][TI-2043] - [INFO] 2024-04-29 17:53:47.633 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-748][TI-2043] - [INFO] 2024-04-29 17:53:47.633 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"query","direct":"IN","type":"VARCHAR","value":""}] successfully
[WI-748][TI-2043] - [INFO] 2024-04-29 17:53:47.633 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2043] - [INFO] 2024-04-29 17:53:47.634 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-748][TI-2043] - [INFO] 2024-04-29 17:53:47.634 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2043] - [INFO] 2024-04-29 17:53:47.634 +0800 o.a.d.p.t.s.SqlTask:[119] - Full sql parameters: SqlParameters{type='POSTGRESQL', datasource=1, sql='${query}', sqlType=0, sendEmail=null, displayRows=10, limit=0, udfs='null', showType='null', connParams='null', groupId='0', title='null', preStatements=[], postStatements=[]}
[WI-748][TI-2043] - [INFO] 2024-04-29 17:53:47.634 +0800 o.a.d.p.t.s.SqlTask:[120] - sql type : POSTGRESQL, datasource : 1, sql : ${query} , localParams : [],udfs : null,showType : null,connParams : null,varPool : [Property{prop='query', direct=IN, type=VARCHAR, value=''}] ,query max result limit  0
[WI-748][TI-2043] - [INFO] 2024-04-29 17:53:47.634 +0800 o.a.d.p.t.a.AbstractTask:[206] - setSqlParamsMap: Property with paramName: query put in sqlParamsMap of content ${query} successfully.
[WI-748][TI-2043] - [INFO] 2024-04-29 17:53:47.635 +0800 o.a.d.p.t.s.SqlTask:[410] - after replace sql , preparing : ?
[WI-748][TI-2043] - [INFO] 2024-04-29 17:53:47.635 +0800 o.a.d.p.t.s.SqlTask:[420] - Sql Params are replaced sql , parameters:(VARCHAR)
[WI-748][TI-2043] - [INFO] 2024-04-29 17:53:47.635 +0800 o.a.d.p.t.s.SqlTask:[489] - can't find udf function resource
[WI-748][TI-2043] - [WARN] 2024-04-29 17:53:47.636 +0800 n.s.c.j.SnowflakeConnectString:[136] - Connect strings must start with jdbc:snowflake://
[WI-748][TI-2043] - [INFO] 2024-04-29 17:53:47.665 +0800 o.a.d.p.t.s.SqlTask:[392] - prepare statement replace sql : ?, sql parameters : {1=Property{prop='query', direct=IN, type=VARCHAR, value=''}}
[WI-748][TI-2043] - [INFO] 2024-04-29 17:53:47.666 +0800 o.a.d.p.t.s.SqlTask:[316] - main statement execute query, for sql: ?
[WI-748][TI-2043] - [ERROR] 2024-04-29 17:53:47.678 +0800 o.a.d.p.t.s.SqlTask:[217] - execute sql error: ERROR: syntax error at or near "$1"
  Position: 1
[WI-748][TI-2043] - [ERROR] 2024-04-29 17:53:47.679 +0800 o.a.d.p.t.s.SqlTask:[165] - sql task error
org.postgresql.util.PSQLException: ERROR: syntax error at or near "$1"
  Position: 1
	at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2676)
	at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2366)
	at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:356)
	at org.postgresql.jdbc.PgStatement.executeInternal(PgStatement.java:490)
	at org.postgresql.jdbc.PgStatement.execute(PgStatement.java:408)
	at org.postgresql.jdbc.PgPreparedStatement.executeWithFlags(PgPreparedStatement.java:181)
	at org.postgresql.jdbc.PgPreparedStatement.executeQuery(PgPreparedStatement.java:133)
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.executeQuery(SqlTask.java:317)
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.executeFuncAndSql(SqlTask.java:205)
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.handle(SqlTask.java:159)
	at org.apache.dolphinscheduler.server.worker.runner.DefaultWorkerTaskExecutor.executeTask(DefaultWorkerTaskExecutor.java:54)
	at org.apache.dolphinscheduler.server.worker.runner.WorkerTaskExecutor.run(WorkerTaskExecutor.java:175)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
[WI-748][TI-2043] - [ERROR] 2024-04-29 17:53:47.679 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[181] - Task execute failed, due to meet an exception
org.apache.dolphinscheduler.plugin.task.api.TaskException: Execute sql task failed
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.handle(SqlTask.java:166)
	at org.apache.dolphinscheduler.server.worker.runner.DefaultWorkerTaskExecutor.executeTask(DefaultWorkerTaskExecutor.java:54)
	at org.apache.dolphinscheduler.server.worker.runner.WorkerTaskExecutor.run(WorkerTaskExecutor.java:175)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.postgresql.util.PSQLException: ERROR: syntax error at or near "$1"
  Position: 1
	at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2676)
	at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2366)
	at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:356)
	at org.postgresql.jdbc.PgStatement.executeInternal(PgStatement.java:490)
	at org.postgresql.jdbc.PgStatement.execute(PgStatement.java:408)
	at org.postgresql.jdbc.PgPreparedStatement.executeWithFlags(PgPreparedStatement.java:181)
	at org.postgresql.jdbc.PgPreparedStatement.executeQuery(PgPreparedStatement.java:133)
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.executeQuery(SqlTask.java:317)
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.executeFuncAndSql(SqlTask.java:205)
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.handle(SqlTask.java:159)
	... 5 common frames omitted
[WI-748][TI-2043] - [INFO] 2024-04-29 17:53:47.679 +0800 o.a.d.p.t.a.u.ProcessUtils:[182] - Get appIds from worker 172.18.1.1:1234, taskLogPath: /opt/dolphinscheduler/logs/20240429/13426477386080/8/748/2043.log
[WI-748][TI-2043] - [INFO] 2024-04-29 17:53:47.680 +0800 o.a.d.p.t.a.u.LogUtils:[79] - Start finding appId in /opt/dolphinscheduler/logs/20240429/13426477386080/8/748/2043.log, fetch way: log 
[WI-748][TI-2043] - [INFO] 2024-04-29 17:53:47.682 +0800 o.a.d.p.t.a.u.ProcessUtils:[188] - The appId is empty
[WI-748][TI-2043] - [INFO] 2024-04-29 17:53:47.682 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[118] - Cancel the task successfully
[WI-748][TI-2043] - [INFO] 2024-04-29 17:53:47.690 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[125] - Get a exception when execute the task, will send the task status: FAILURE to master: 172.18.1.1:1234
[WI-748][TI-2043] - [INFO] 2024-04-29 17:53:47.691 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-2043] - [INFO] 2024-04-29 17:53:48.515 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=2043, success=true)
[WI-0][TI-2043] - [INFO] 2024-04-29 17:53:48.531 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=2043, success=true)
[WI-0][TI-0] - [INFO] 2024-04-29 17:53:49.634 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=2044, taskName=Persist in postgresql, firstSubmitTime=1714384429608, startTime=0, taskType=SQL, workflowInstanceHost=172.18.0.12:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13426477386080, processDefineVersion=8, appIds=null, processInstanceId=748, scheduleTime=0, globalParams=null, executorId=1, cmdTypeIfComplement=7, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[],"resourceList":[],"type":"POSTGRESQL","datasource":1,"sql":"${query}","sqlType":"0","preStatements":[],"postStatements":[],"displayRows":10}, environmentConfig=export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='Persist in postgresql'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, query=Property{prop='query', direct=IN, type=VARCHAR, value=''}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240429'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='2044'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13427698681952'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240429175349'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='748'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240428'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='es_filtered_data_persistence_subprocess'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13426477386080'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=org.apache.dolphinscheduler.plugin.task.api.parameters.resource.ResourceParametersHelper@3b607e1e, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"query","direct":"IN","type":"VARCHAR","value":""}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-748][TI-2044] - [INFO] 2024-04-29 17:53:49.636 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: Persist in postgresql to wait queue success
[WI-748][TI-2044] - [INFO] 2024-04-29 17:53:49.636 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2044] - [INFO] 2024-04-29 17:53:49.639 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-748][TI-2044] - [INFO] 2024-04-29 17:53:49.639 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2044] - [INFO] 2024-04-29 17:53:49.639 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-748][TI-2044] - [INFO] 2024-04-29 17:53:49.640 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1714384429640
[WI-748][TI-2044] - [INFO] 2024-04-29 17:53:49.640 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 748_2044
[WI-748][TI-2044] - [INFO] 2024-04-29 17:53:49.641 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 2044,
  "taskName" : "Persist in postgresql",
  "firstSubmitTime" : 1714384429608,
  "startTime" : 1714384429640,
  "taskType" : "SQL",
  "workflowInstanceHost" : "172.18.0.12:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240429/13426477386080/8/748/2044.log",
  "processId" : 0,
  "processDefineCode" : 13426477386080,
  "processDefineVersion" : 8,
  "processInstanceId" : 748,
  "scheduleTime" : 0,
  "executorId" : 1,
  "cmdTypeIfComplement" : 7,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[],\"resourceList\":[],\"type\":\"POSTGRESQL\",\"datasource\":1,\"sql\":\"${query}\",\"sqlType\":\"0\",\"preStatements\":[],\"postStatements\":[],\"displayRows\":10}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "Persist in postgresql"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "query" : {
      "prop" : "query",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : ""
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240429"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "2044"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13427698681952"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240429175349"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "748"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240428"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "es_filtered_data_persistence_subprocess"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13426477386080"
    }
  },
  "taskAppId" : "748_2044",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "resourceParametersHelper" : {
    "resourceMap" : {
      "DATASOURCE" : {
        "1" : {
          "resourceType" : "DATASOURCE",
          "type" : "POSTGRESQL",
          "connectionParams" : "{\"user\":\"root\",\"password\":\"******\",\"address\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432\",\"database\":\"persistence\",\"jdbcUrl\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432/persistence\",\"driverClassName\":\"org.postgresql.Driver\",\"validationQuery\":\"select version()\",\"other\":{\"password\":\"root\"}}",
          "DATASOURCE" : null
        }
      }
    }
  },
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"query\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-748][TI-2044] - [INFO] 2024-04-29 17:53:49.642 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2044] - [INFO] 2024-04-29 17:53:49.643 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-748][TI-2044] - [INFO] 2024-04-29 17:53:49.643 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2044] - [INFO] 2024-04-29 17:53:49.648 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-748][TI-2044] - [INFO] 2024-04-29 17:53:49.648 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-748][TI-2044] - [INFO] 2024-04-29 17:53:49.650 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_8/748/2044 check successfully
[WI-748][TI-2044] - [INFO] 2024-04-29 17:53:49.650 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.sql.SqlTaskChannel successfully
[WI-748][TI-2044] - [INFO] 2024-04-29 17:53:49.651 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-748][TI-2044] - [INFO] 2024-04-29 17:53:49.652 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-748][TI-2044] - [INFO] 2024-04-29 17:53:49.653 +0800 o.a.d.p.t.s.SqlTask:[99] - Initialize sql task parameter {
  "localParams" : [ ],
  "varPool" : null,
  "type" : "POSTGRESQL",
  "datasource" : 1,
  "sql" : "${query}",
  "sqlType" : 0,
  "sendEmail" : null,
  "displayRows" : 10,
  "udfs" : null,
  "showType" : null,
  "connParams" : null,
  "preStatements" : [ ],
  "postStatements" : [ ],
  "groupId" : 0,
  "title" : null,
  "limit" : 0
}
[WI-748][TI-2044] - [INFO] 2024-04-29 17:53:49.653 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SQL create successfully
[WI-748][TI-2044] - [INFO] 2024-04-29 17:53:49.653 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-748][TI-2044] - [INFO] 2024-04-29 17:53:49.654 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"query","direct":"IN","type":"VARCHAR","value":""}] successfully
[WI-748][TI-2044] - [INFO] 2024-04-29 17:53:49.654 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2044] - [INFO] 2024-04-29 17:53:49.654 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-748][TI-2044] - [INFO] 2024-04-29 17:53:49.655 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2044] - [INFO] 2024-04-29 17:53:49.655 +0800 o.a.d.p.t.s.SqlTask:[119] - Full sql parameters: SqlParameters{type='POSTGRESQL', datasource=1, sql='${query}', sqlType=0, sendEmail=null, displayRows=10, limit=0, udfs='null', showType='null', connParams='null', groupId='0', title='null', preStatements=[], postStatements=[]}
[WI-748][TI-2044] - [INFO] 2024-04-29 17:53:49.655 +0800 o.a.d.p.t.s.SqlTask:[120] - sql type : POSTGRESQL, datasource : 1, sql : ${query} , localParams : [],udfs : null,showType : null,connParams : null,varPool : [Property{prop='query', direct=IN, type=VARCHAR, value=''}] ,query max result limit  0
[WI-748][TI-2044] - [INFO] 2024-04-29 17:53:49.656 +0800 o.a.d.p.t.a.AbstractTask:[206] - setSqlParamsMap: Property with paramName: query put in sqlParamsMap of content ${query} successfully.
[WI-748][TI-2044] - [INFO] 2024-04-29 17:53:49.656 +0800 o.a.d.p.t.s.SqlTask:[410] - after replace sql , preparing : ?
[WI-748][TI-2044] - [INFO] 2024-04-29 17:53:49.656 +0800 o.a.d.p.t.s.SqlTask:[420] - Sql Params are replaced sql , parameters:(VARCHAR)
[WI-748][TI-2044] - [INFO] 2024-04-29 17:53:49.656 +0800 o.a.d.p.t.s.SqlTask:[489] - can't find udf function resource
[WI-748][TI-2044] - [WARN] 2024-04-29 17:53:49.657 +0800 n.s.c.j.SnowflakeConnectString:[136] - Connect strings must start with jdbc:snowflake://
[WI-748][TI-2044] - [INFO] 2024-04-29 17:53:49.688 +0800 o.a.d.p.t.s.SqlTask:[392] - prepare statement replace sql : ?, sql parameters : {1=Property{prop='query', direct=IN, type=VARCHAR, value=''}}
[WI-748][TI-2044] - [INFO] 2024-04-29 17:53:49.689 +0800 o.a.d.p.t.s.SqlTask:[316] - main statement execute query, for sql: ?
[WI-748][TI-2044] - [ERROR] 2024-04-29 17:53:49.693 +0800 o.a.d.p.t.s.SqlTask:[217] - execute sql error: ERROR: syntax error at or near "$1"
  Position: 1
[WI-748][TI-2044] - [ERROR] 2024-04-29 17:53:49.694 +0800 o.a.d.p.t.s.SqlTask:[165] - sql task error
org.postgresql.util.PSQLException: ERROR: syntax error at or near "$1"
  Position: 1
	at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2676)
	at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2366)
	at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:356)
	at org.postgresql.jdbc.PgStatement.executeInternal(PgStatement.java:490)
	at org.postgresql.jdbc.PgStatement.execute(PgStatement.java:408)
	at org.postgresql.jdbc.PgPreparedStatement.executeWithFlags(PgPreparedStatement.java:181)
	at org.postgresql.jdbc.PgPreparedStatement.executeQuery(PgPreparedStatement.java:133)
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.executeQuery(SqlTask.java:317)
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.executeFuncAndSql(SqlTask.java:205)
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.handle(SqlTask.java:159)
	at org.apache.dolphinscheduler.server.worker.runner.DefaultWorkerTaskExecutor.executeTask(DefaultWorkerTaskExecutor.java:54)
	at org.apache.dolphinscheduler.server.worker.runner.WorkerTaskExecutor.run(WorkerTaskExecutor.java:175)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
[WI-748][TI-2044] - [ERROR] 2024-04-29 17:53:49.694 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[181] - Task execute failed, due to meet an exception
org.apache.dolphinscheduler.plugin.task.api.TaskException: Execute sql task failed
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.handle(SqlTask.java:166)
	at org.apache.dolphinscheduler.server.worker.runner.DefaultWorkerTaskExecutor.executeTask(DefaultWorkerTaskExecutor.java:54)
	at org.apache.dolphinscheduler.server.worker.runner.WorkerTaskExecutor.run(WorkerTaskExecutor.java:175)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.postgresql.util.PSQLException: ERROR: syntax error at or near "$1"
  Position: 1
	at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2676)
	at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2366)
	at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:356)
	at org.postgresql.jdbc.PgStatement.executeInternal(PgStatement.java:490)
	at org.postgresql.jdbc.PgStatement.execute(PgStatement.java:408)
	at org.postgresql.jdbc.PgPreparedStatement.executeWithFlags(PgPreparedStatement.java:181)
	at org.postgresql.jdbc.PgPreparedStatement.executeQuery(PgPreparedStatement.java:133)
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.executeQuery(SqlTask.java:317)
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.executeFuncAndSql(SqlTask.java:205)
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.handle(SqlTask.java:159)
	... 5 common frames omitted
[WI-748][TI-2044] - [INFO] 2024-04-29 17:53:49.695 +0800 o.a.d.p.t.a.u.ProcessUtils:[182] - Get appIds from worker 172.18.1.1:1234, taskLogPath: /opt/dolphinscheduler/logs/20240429/13426477386080/8/748/2044.log
[WI-748][TI-2044] - [INFO] 2024-04-29 17:53:49.695 +0800 o.a.d.p.t.a.u.LogUtils:[79] - Start finding appId in /opt/dolphinscheduler/logs/20240429/13426477386080/8/748/2044.log, fetch way: log 
[WI-748][TI-2044] - [INFO] 2024-04-29 17:53:49.695 +0800 o.a.d.p.t.a.u.ProcessUtils:[188] - The appId is empty
[WI-748][TI-2044] - [INFO] 2024-04-29 17:53:49.695 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[118] - Cancel the task successfully
[WI-748][TI-2044] - [INFO] 2024-04-29 17:53:49.699 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[125] - Get a exception when execute the task, will send the task status: FAILURE to master: 172.18.1.1:1234
[WI-748][TI-2044] - [INFO] 2024-04-29 17:53:49.699 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-2044] - [INFO] 2024-04-29 17:53:50.518 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=2044, success=true)
[WI-0][TI-2044] - [INFO] 2024-04-29 17:53:50.530 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=2044, success=true)
[WI-0][TI-0] - [INFO] 2024-04-29 17:53:51.582 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=2045, taskName=Persist in postgresql, firstSubmitTime=1714384431559, startTime=0, taskType=SQL, workflowInstanceHost=172.18.0.12:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13426477386080, processDefineVersion=8, appIds=null, processInstanceId=748, scheduleTime=0, globalParams=null, executorId=1, cmdTypeIfComplement=7, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[],"resourceList":[],"type":"POSTGRESQL","datasource":1,"sql":"${query}","sqlType":"0","preStatements":[],"postStatements":[],"displayRows":10}, environmentConfig=export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='Persist in postgresql'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, query=Property{prop='query', direct=IN, type=VARCHAR, value=''}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240429'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='2045'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13427698681952'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240429175351'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='748'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240428'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='es_filtered_data_persistence_subprocess'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13426477386080'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=org.apache.dolphinscheduler.plugin.task.api.parameters.resource.ResourceParametersHelper@3508d681, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"query","direct":"IN","type":"VARCHAR","value":""}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-748][TI-2045] - [INFO] 2024-04-29 17:53:51.583 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: Persist in postgresql to wait queue success
[WI-748][TI-2045] - [INFO] 2024-04-29 17:53:51.584 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2045] - [INFO] 2024-04-29 17:53:51.587 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-748][TI-2045] - [INFO] 2024-04-29 17:53:51.587 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2045] - [INFO] 2024-04-29 17:53:51.588 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-748][TI-2045] - [INFO] 2024-04-29 17:53:51.588 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1714384431588
[WI-748][TI-2045] - [INFO] 2024-04-29 17:53:51.588 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 748_2045
[WI-748][TI-2045] - [INFO] 2024-04-29 17:53:51.588 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 2045,
  "taskName" : "Persist in postgresql",
  "firstSubmitTime" : 1714384431559,
  "startTime" : 1714384431588,
  "taskType" : "SQL",
  "workflowInstanceHost" : "172.18.0.12:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240429/13426477386080/8/748/2045.log",
  "processId" : 0,
  "processDefineCode" : 13426477386080,
  "processDefineVersion" : 8,
  "processInstanceId" : 748,
  "scheduleTime" : 0,
  "executorId" : 1,
  "cmdTypeIfComplement" : 7,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[],\"resourceList\":[],\"type\":\"POSTGRESQL\",\"datasource\":1,\"sql\":\"${query}\",\"sqlType\":\"0\",\"preStatements\":[],\"postStatements\":[],\"displayRows\":10}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "Persist in postgresql"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "query" : {
      "prop" : "query",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : ""
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240429"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "2045"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13427698681952"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240429175351"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "748"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240428"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "es_filtered_data_persistence_subprocess"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13426477386080"
    }
  },
  "taskAppId" : "748_2045",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "resourceParametersHelper" : {
    "resourceMap" : {
      "DATASOURCE" : {
        "1" : {
          "resourceType" : "DATASOURCE",
          "type" : "POSTGRESQL",
          "connectionParams" : "{\"user\":\"root\",\"password\":\"******\",\"address\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432\",\"database\":\"persistence\",\"jdbcUrl\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432/persistence\",\"driverClassName\":\"org.postgresql.Driver\",\"validationQuery\":\"select version()\",\"other\":{\"password\":\"root\"}}",
          "DATASOURCE" : null
        }
      }
    }
  },
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"query\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-748][TI-2045] - [INFO] 2024-04-29 17:53:51.589 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2045] - [INFO] 2024-04-29 17:53:51.589 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-748][TI-2045] - [INFO] 2024-04-29 17:53:51.589 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2045] - [INFO] 2024-04-29 17:53:51.591 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-748][TI-2045] - [INFO] 2024-04-29 17:53:51.592 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-748][TI-2045] - [INFO] 2024-04-29 17:53:51.592 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_8/748/2045 check successfully
[WI-748][TI-2045] - [INFO] 2024-04-29 17:53:51.592 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.sql.SqlTaskChannel successfully
[WI-748][TI-2045] - [INFO] 2024-04-29 17:53:51.593 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-748][TI-2045] - [INFO] 2024-04-29 17:53:51.593 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-748][TI-2045] - [INFO] 2024-04-29 17:53:51.595 +0800 o.a.d.p.t.s.SqlTask:[99] - Initialize sql task parameter {
  "localParams" : [ ],
  "varPool" : null,
  "type" : "POSTGRESQL",
  "datasource" : 1,
  "sql" : "${query}",
  "sqlType" : 0,
  "sendEmail" : null,
  "displayRows" : 10,
  "udfs" : null,
  "showType" : null,
  "connParams" : null,
  "preStatements" : [ ],
  "postStatements" : [ ],
  "groupId" : 0,
  "title" : null,
  "limit" : 0
}
[WI-748][TI-2045] - [INFO] 2024-04-29 17:53:51.595 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SQL create successfully
[WI-748][TI-2045] - [INFO] 2024-04-29 17:53:51.595 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-748][TI-2045] - [INFO] 2024-04-29 17:53:51.595 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"query","direct":"IN","type":"VARCHAR","value":""}] successfully
[WI-748][TI-2045] - [INFO] 2024-04-29 17:53:51.595 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2045] - [INFO] 2024-04-29 17:53:51.595 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-748][TI-2045] - [INFO] 2024-04-29 17:53:51.595 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-748][TI-2045] - [INFO] 2024-04-29 17:53:51.595 +0800 o.a.d.p.t.s.SqlTask:[119] - Full sql parameters: SqlParameters{type='POSTGRESQL', datasource=1, sql='${query}', sqlType=0, sendEmail=null, displayRows=10, limit=0, udfs='null', showType='null', connParams='null', groupId='0', title='null', preStatements=[], postStatements=[]}
[WI-748][TI-2045] - [INFO] 2024-04-29 17:53:51.596 +0800 o.a.d.p.t.s.SqlTask:[120] - sql type : POSTGRESQL, datasource : 1, sql : ${query} , localParams : [],udfs : null,showType : null,connParams : null,varPool : [Property{prop='query', direct=IN, type=VARCHAR, value=''}] ,query max result limit  0
[WI-748][TI-2045] - [INFO] 2024-04-29 17:53:51.596 +0800 o.a.d.p.t.a.AbstractTask:[206] - setSqlParamsMap: Property with paramName: query put in sqlParamsMap of content ${query} successfully.
[WI-748][TI-2045] - [INFO] 2024-04-29 17:53:51.597 +0800 o.a.d.p.t.s.SqlTask:[410] - after replace sql , preparing : ?
[WI-748][TI-2045] - [INFO] 2024-04-29 17:53:51.597 +0800 o.a.d.p.t.s.SqlTask:[420] - Sql Params are replaced sql , parameters:(VARCHAR)
[WI-748][TI-2045] - [INFO] 2024-04-29 17:53:51.597 +0800 o.a.d.p.t.s.SqlTask:[489] - can't find udf function resource
[WI-748][TI-2045] - [WARN] 2024-04-29 17:53:51.598 +0800 n.s.c.j.SnowflakeConnectString:[136] - Connect strings must start with jdbc:snowflake://
[WI-748][TI-2045] - [INFO] 2024-04-29 17:53:51.631 +0800 o.a.d.p.t.s.SqlTask:[392] - prepare statement replace sql : ?, sql parameters : {1=Property{prop='query', direct=IN, type=VARCHAR, value=''}}
[WI-748][TI-2045] - [INFO] 2024-04-29 17:53:51.631 +0800 o.a.d.p.t.s.SqlTask:[316] - main statement execute query, for sql: ?
[WI-748][TI-2045] - [ERROR] 2024-04-29 17:53:51.637 +0800 o.a.d.p.t.s.SqlTask:[217] - execute sql error: ERROR: syntax error at or near "$1"
  Position: 1
[WI-748][TI-2045] - [ERROR] 2024-04-29 17:53:51.638 +0800 o.a.d.p.t.s.SqlTask:[165] - sql task error
org.postgresql.util.PSQLException: ERROR: syntax error at or near "$1"
  Position: 1
	at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2676)
	at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2366)
	at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:356)
	at org.postgresql.jdbc.PgStatement.executeInternal(PgStatement.java:490)
	at org.postgresql.jdbc.PgStatement.execute(PgStatement.java:408)
	at org.postgresql.jdbc.PgPreparedStatement.executeWithFlags(PgPreparedStatement.java:181)
	at org.postgresql.jdbc.PgPreparedStatement.executeQuery(PgPreparedStatement.java:133)
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.executeQuery(SqlTask.java:317)
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.executeFuncAndSql(SqlTask.java:205)
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.handle(SqlTask.java:159)
	at org.apache.dolphinscheduler.server.worker.runner.DefaultWorkerTaskExecutor.executeTask(DefaultWorkerTaskExecutor.java:54)
	at org.apache.dolphinscheduler.server.worker.runner.WorkerTaskExecutor.run(WorkerTaskExecutor.java:175)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
[WI-748][TI-2045] - [ERROR] 2024-04-29 17:53:51.641 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[181] - Task execute failed, due to meet an exception
org.apache.dolphinscheduler.plugin.task.api.TaskException: Execute sql task failed
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.handle(SqlTask.java:166)
	at org.apache.dolphinscheduler.server.worker.runner.DefaultWorkerTaskExecutor.executeTask(DefaultWorkerTaskExecutor.java:54)
	at org.apache.dolphinscheduler.server.worker.runner.WorkerTaskExecutor.run(WorkerTaskExecutor.java:175)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.postgresql.util.PSQLException: ERROR: syntax error at or near "$1"
  Position: 1
	at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2676)
	at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2366)
	at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:356)
	at org.postgresql.jdbc.PgStatement.executeInternal(PgStatement.java:490)
	at org.postgresql.jdbc.PgStatement.execute(PgStatement.java:408)
	at org.postgresql.jdbc.PgPreparedStatement.executeWithFlags(PgPreparedStatement.java:181)
	at org.postgresql.jdbc.PgPreparedStatement.executeQuery(PgPreparedStatement.java:133)
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.executeQuery(SqlTask.java:317)
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.executeFuncAndSql(SqlTask.java:205)
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.handle(SqlTask.java:159)
	... 5 common frames omitted
[WI-748][TI-2045] - [INFO] 2024-04-29 17:53:51.642 +0800 o.a.d.p.t.a.u.ProcessUtils:[182] - Get appIds from worker 172.18.1.1:1234, taskLogPath: /opt/dolphinscheduler/logs/20240429/13426477386080/8/748/2045.log
[WI-748][TI-2045] - [INFO] 2024-04-29 17:53:51.642 +0800 o.a.d.p.t.a.u.LogUtils:[79] - Start finding appId in /opt/dolphinscheduler/logs/20240429/13426477386080/8/748/2045.log, fetch way: log 
[WI-748][TI-2045] - [INFO] 2024-04-29 17:53:51.643 +0800 o.a.d.p.t.a.u.ProcessUtils:[188] - The appId is empty
[WI-748][TI-2045] - [INFO] 2024-04-29 17:53:51.645 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[118] - Cancel the task successfully
[WI-748][TI-2045] - [INFO] 2024-04-29 17:53:51.649 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[125] - Get a exception when execute the task, will send the task status: FAILURE to master: 172.18.1.1:1234
[WI-748][TI-2045] - [INFO] 2024-04-29 17:53:51.650 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-2045] - [INFO] 2024-04-29 17:53:52.521 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=2045, success=true)
[WI-0][TI-2045] - [INFO] 2024-04-29 17:53:52.528 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=2045, success=true)
[WI-0][TI-0] - [INFO] 2024-04-29 17:53:59.555 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7569832402234637 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-29 17:55:36.909 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7039106145251397 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-29 17:55:39.948 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7134328358208956 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-29 17:55:41.970 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7159420289855072 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-29 17:55:43.007 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8073878627968337 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-29 17:55:51.037 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7626666666666667 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-29 17:55:58.164 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7442528735632183 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-29 17:55:59.206 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7014325207338528 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-29 17:56:00.212 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7337365898196759 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-29 17:56:05.243 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7138810198300283 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-29 17:56:06.302 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.710594315245478 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-29 17:56:39.632 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7346938775510203 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-29 17:56:48.305 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=2046, taskName=consume_filtered_data, firstSubmitTime=1714384608294, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.12:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13426477386080, processDefineVersion=9, appIds=null, processInstanceId=749, scheduleTime=0, globalParams=null, executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[],"rawScript":"# /bin/kafka-console-consumer.sh \\\n#     --bootstrap-server kafka:9092 \\\n#     --topic reddit_post_filtered \\\n#     --max-messages 10 \\\n#     --from-beginning \\\n#     --group filtered_data_consumer \n#     --timeout-ms 15000","resourceList":[]}, environmentConfig=export JAVA_HOME=/opt/java/openjdk, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='consume_filtered_data'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='749'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240429'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240428'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='2046'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='es_filtered_data_persistence_subprocess'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13433255983872'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13426477386080'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240429175648'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=null, dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-749][TI-2046] - [INFO] 2024-04-29 17:56:48.306 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: consume_filtered_data to wait queue success
[WI-749][TI-2046] - [INFO] 2024-04-29 17:56:48.307 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-749][TI-2046] - [INFO] 2024-04-29 17:56:48.312 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-749][TI-2046] - [INFO] 2024-04-29 17:56:48.312 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-749][TI-2046] - [INFO] 2024-04-29 17:56:48.312 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-749][TI-2046] - [INFO] 2024-04-29 17:56:48.312 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1714384608312
[WI-749][TI-2046] - [INFO] 2024-04-29 17:56:48.313 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 749_2046
[WI-749][TI-2046] - [INFO] 2024-04-29 17:56:48.313 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 2046,
  "taskName" : "consume_filtered_data",
  "firstSubmitTime" : 1714384608294,
  "startTime" : 1714384608312,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.12:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240429/13426477386080/9/749/2046.log",
  "processId" : 0,
  "processDefineCode" : 13426477386080,
  "processDefineVersion" : 9,
  "processInstanceId" : 749,
  "scheduleTime" : 0,
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[],\"rawScript\":\"# /bin/kafka-console-consumer.sh \\\\\\n#     --bootstrap-server kafka:9092 \\\\\\n#     --topic reddit_post_filtered \\\\\\n#     --max-messages 10 \\\\\\n#     --from-beginning \\\\\\n#     --group filtered_data_consumer \\n#     --timeout-ms 15000\",\"resourceList\":[]}",
  "environmentConfig" : "export JAVA_HOME=/opt/java/openjdk",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "consume_filtered_data"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "749"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240429"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240428"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "2046"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "es_filtered_data_persistence_subprocess"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13433255983872"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13426477386080"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240429175648"
    }
  },
  "taskAppId" : "749_2046",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-749][TI-2046] - [INFO] 2024-04-29 17:56:48.313 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-749][TI-2046] - [INFO] 2024-04-29 17:56:48.314 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-749][TI-2046] - [INFO] 2024-04-29 17:56:48.314 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-749][TI-2046] - [INFO] 2024-04-29 17:56:48.317 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-749][TI-2046] - [INFO] 2024-04-29 17:56:48.317 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-749][TI-2046] - [INFO] 2024-04-29 17:56:48.318 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_9/749/2046 check successfully
[WI-749][TI-2046] - [INFO] 2024-04-29 17:56:48.318 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-749][TI-2046] - [INFO] 2024-04-29 17:56:48.318 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-749][TI-2046] - [INFO] 2024-04-29 17:56:48.318 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-749][TI-2046] - [INFO] 2024-04-29 17:56:48.319 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-749][TI-2046] - [INFO] 2024-04-29 17:56:48.319 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ ],
  "varPool" : null,
  "rawScript" : "# /bin/kafka-console-consumer.sh \\\n#     --bootstrap-server kafka:9092 \\\n#     --topic reddit_post_filtered \\\n#     --max-messages 10 \\\n#     --from-beginning \\\n#     --group filtered_data_consumer \n#     --timeout-ms 15000",
  "resourceList" : [ ]
}
[WI-749][TI-2046] - [INFO] 2024-04-29 17:56:48.319 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-749][TI-2046] - [INFO] 2024-04-29 17:56:48.319 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: null successfully
[WI-749][TI-2046] - [INFO] 2024-04-29 17:56:48.319 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-749][TI-2046] - [INFO] 2024-04-29 17:56:48.320 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-749][TI-2046] - [INFO] 2024-04-29 17:56:48.320 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-749][TI-2046] - [INFO] 2024-04-29 17:56:48.320 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-749][TI-2046] - [INFO] 2024-04-29 17:56:48.321 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-749][TI-2046] - [INFO] 2024-04-29 17:56:48.321 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export JAVA_HOME=/opt/java/openjdk
# /bin/kafka-console-consumer.sh \
#     --bootstrap-server kafka:9092 \
#     --topic reddit_post_filtered \
#     --max-messages 10 \
#     --from-beginning \
#     --group filtered_data_consumer 
#     --timeout-ms 15000
[WI-749][TI-2046] - [INFO] 2024-04-29 17:56:48.321 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-749][TI-2046] - [INFO] 2024-04-29 17:56:48.322 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_9/749/2046/749_2046.sh
[WI-749][TI-2046] - [INFO] 2024-04-29 17:56:48.327 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 328
[WI-0][TI-2046] - [INFO] 2024-04-29 17:56:48.931 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=2046, success=true)
[WI-0][TI-2046] - [INFO] 2024-04-29 17:56:48.941 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=2046)
[WI-0][TI-0] - [INFO] 2024-04-29 17:56:49.329 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
[WI-749][TI-2046] - [INFO] 2024-04-29 17:56:49.333 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_9/749/2046, processId:328 ,exitStatusCode:0 ,processWaitForStatus:true ,processExitValue:0
[WI-749][TI-2046] - [INFO] 2024-04-29 17:56:49.333 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-749][TI-2046] - [INFO] 2024-04-29 17:56:49.333 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-749][TI-2046] - [INFO] 2024-04-29 17:56:49.334 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-749][TI-2046] - [INFO] 2024-04-29 17:56:49.336 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-749][TI-2046] - [INFO] 2024-04-29 17:56:49.341 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: SUCCESS to master : 172.18.1.1:1234
[WI-749][TI-2046] - [INFO] 2024-04-29 17:56:49.342 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-749][TI-2046] - [INFO] 2024-04-29 17:56:49.343 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_9/749/2046
[WI-749][TI-2046] - [INFO] 2024-04-29 17:56:49.344 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_9/749/2046
[WI-749][TI-2046] - [INFO] 2024-04-29 17:56:49.345 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-2046] - [INFO] 2024-04-29 17:56:49.935 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=2046, success=true)
[WI-0][TI-0] - [INFO] 2024-04-29 17:56:50.077 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=2047, taskName=persist_to_postgre, firstSubmitTime=1714384610065, startTime=0, taskType=PYTHON, workflowInstanceHost=172.18.0.12:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13426477386080, processDefineVersion=9, appIds=null, processInstanceId=749, scheduleTime=0, globalParams=null, executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[{"prop":"query","direct":"OUT","type":"VARCHAR","value":""}],"rawScript":"import re\nimport json\n\n# define the table to send the data to\ntable_name = \"filtered_data_persistence\"\n\n# Provided JSON data as strings\njson_data = ''' \n{\n  \"user\": \"premiumplatinum\",\n  \"content\": \"singapore is stupid\",\n  \"url\": \"https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/\",\n  \"context\": \"21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist\",\n  \"score\": 131,\n  \"type\": \"post\",\n  \"id\": \"1c9itat\",\n  \"datetime\": \"2024-04-21 22:10:42\"\n}\n{\n        \"user\": \"premiumplatinum\",\n        \"content\": \"s is stupid\",\n        \"url\": \"https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/\",\n        \"context\": \"21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist\",\n        \"score\": 131,\n        \"type\": \"post\",\n        \"id\": \"1c9itat\",\n        \"datetime\": \"2024-04-21 22:10:42\"\n}\n'''\n\n# process the kafka messages to individual JSON objects\njson_objects = json_data.replace('}\\n{', '},\\n{').strip()\njson_objects = re.sub(\" +\", \" \",json_objects)   \njson_objects = '[' + json_objects + ']'\n\n# convert JSON string to a list of dicts\njson_list = json.loads(json_objects)\n\n# convert list of dictionaries into list of tuples containing only the values\nvalues = [tuple(message.values()) for message in json_list]\n\n# create the SQL Query\nquery = f'''\nINSERT INTO {table_name} (user, content, url, context, score, type, id, datetime)\nVALUES \n'''\n\nfor value in values:\n    query += str(value) + ',\\n'\n\n# remove the last 2 character ,\\n and change it to ; for the query\nquery = query[:-2] + ';'\n\n# pass the query as a parameter downstream\nprint(\"#{setValue(query=%s)}\" % query)","resourceList":[]}, environmentConfig=export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='persist_to_postgre'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='749'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240429'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240428'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='2047'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='es_filtered_data_persistence_subprocess'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13426451158240'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13426477386080'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240429175650'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=null, dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-749][TI-2047] - [INFO] 2024-04-29 17:56:50.078 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: persist_to_postgre to wait queue success
[WI-749][TI-2047] - [INFO] 2024-04-29 17:56:50.078 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-749][TI-2047] - [INFO] 2024-04-29 17:56:50.080 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-749][TI-2047] - [INFO] 2024-04-29 17:56:50.080 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-749][TI-2047] - [INFO] 2024-04-29 17:56:50.080 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-749][TI-2047] - [INFO] 2024-04-29 17:56:50.081 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1714384610080
[WI-749][TI-2047] - [INFO] 2024-04-29 17:56:50.081 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 749_2047
[WI-749][TI-2047] - [INFO] 2024-04-29 17:56:50.081 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 2047,
  "taskName" : "persist_to_postgre",
  "firstSubmitTime" : 1714384610065,
  "startTime" : 1714384610080,
  "taskType" : "PYTHON",
  "workflowInstanceHost" : "172.18.0.12:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240429/13426477386080/9/749/2047.log",
  "processId" : 0,
  "processDefineCode" : 13426477386080,
  "processDefineVersion" : 9,
  "processInstanceId" : 749,
  "scheduleTime" : 0,
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[{\"prop\":\"query\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"\"}],\"rawScript\":\"import re\\nimport json\\n\\n# define the table to send the data to\\ntable_name = \\\"filtered_data_persistence\\\"\\n\\n# Provided JSON data as strings\\njson_data = ''' \\n{\\n  \\\"user\\\": \\\"premiumplatinum\\\",\\n  \\\"content\\\": \\\"singapore is stupid\\\",\\n  \\\"url\\\": \\\"https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/\\\",\\n  \\\"context\\\": \\\"21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist\\\",\\n  \\\"score\\\": 131,\\n  \\\"type\\\": \\\"post\\\",\\n  \\\"id\\\": \\\"1c9itat\\\",\\n  \\\"datetime\\\": \\\"2024-04-21 22:10:42\\\"\\n}\\n{\\n        \\\"user\\\": \\\"premiumplatinum\\\",\\n        \\\"content\\\": \\\"s is stupid\\\",\\n        \\\"url\\\": \\\"https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/\\\",\\n        \\\"context\\\": \\\"21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist\\\",\\n        \\\"score\\\": 131,\\n        \\\"type\\\": \\\"post\\\",\\n        \\\"id\\\": \\\"1c9itat\\\",\\n        \\\"datetime\\\": \\\"2024-04-21 22:10:42\\\"\\n}\\n'''\\n\\n# process the kafka messages to individual JSON objects\\njson_objects = json_data.replace('}\\\\n{', '},\\\\n{').strip()\\njson_objects = re.sub(\\\" +\\\", \\\" \\\",json_objects)   \\njson_objects = '[' + json_objects + ']'\\n\\n# convert JSON string to a list of dicts\\njson_list = json.loads(json_objects)\\n\\n# convert list of dictionaries into list of tuples containing only the values\\nvalues = [tuple(message.values()) for message in json_list]\\n\\n# create the SQL Query\\nquery = f'''\\nINSERT INTO {table_name} (user, content, url, context, score, type, id, datetime)\\nVALUES \\n'''\\n\\nfor value in values:\\n    query += str(value) + ',\\\\n'\\n\\n# remove the last 2 character ,\\\\n and change it to ; for the query\\nquery = query[:-2] + ';'\\n\\n# pass the query as a parameter downstream\\nprint(\\\"#{setValue(query=%s)}\\\" % query)\",\"resourceList\":[]}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "persist_to_postgre"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "749"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240429"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240428"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "2047"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "es_filtered_data_persistence_subprocess"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13426451158240"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13426477386080"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240429175650"
    }
  },
  "taskAppId" : "749_2047",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-749][TI-2047] - [INFO] 2024-04-29 17:56:50.082 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-749][TI-2047] - [INFO] 2024-04-29 17:56:50.082 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-749][TI-2047] - [INFO] 2024-04-29 17:56:50.082 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-749][TI-2047] - [INFO] 2024-04-29 17:56:50.091 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-749][TI-2047] - [INFO] 2024-04-29 17:56:50.094 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-749][TI-2047] - [INFO] 2024-04-29 17:56:50.095 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_9/749/2047 check successfully
[WI-749][TI-2047] - [INFO] 2024-04-29 17:56:50.095 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.python.PythonTaskChannel successfully
[WI-749][TI-2047] - [INFO] 2024-04-29 17:56:50.095 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-749][TI-2047] - [INFO] 2024-04-29 17:56:50.095 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-749][TI-2047] - [INFO] 2024-04-29 17:56:50.095 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: PYTHON create successfully
[WI-749][TI-2047] - [INFO] 2024-04-29 17:56:50.096 +0800 o.a.d.p.t.p.PythonTask:[75] - Initialize python task params {
  "localParams" : [ {
    "prop" : "query",
    "direct" : "OUT",
    "type" : "VARCHAR",
    "value" : ""
  } ],
  "varPool" : null,
  "rawScript" : "import re\nimport json\n\n# define the table to send the data to\ntable_name = \"filtered_data_persistence\"\n\n# Provided JSON data as strings\njson_data = ''' \n{\n  \"user\": \"premiumplatinum\",\n  \"content\": \"singapore is stupid\",\n  \"url\": \"https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/\",\n  \"context\": \"21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist\",\n  \"score\": 131,\n  \"type\": \"post\",\n  \"id\": \"1c9itat\",\n  \"datetime\": \"2024-04-21 22:10:42\"\n}\n{\n        \"user\": \"premiumplatinum\",\n        \"content\": \"s is stupid\",\n        \"url\": \"https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/\",\n        \"context\": \"21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist\",\n        \"score\": 131,\n        \"type\": \"post\",\n        \"id\": \"1c9itat\",\n        \"datetime\": \"2024-04-21 22:10:42\"\n}\n'''\n\n# process the kafka messages to individual JSON objects\njson_objects = json_data.replace('}\\n{', '},\\n{').strip()\njson_objects = re.sub(\" +\", \" \",json_objects)   \njson_objects = '[' + json_objects + ']'\n\n# convert JSON string to a list of dicts\njson_list = json.loads(json_objects)\n\n# convert list of dictionaries into list of tuples containing only the values\nvalues = [tuple(message.values()) for message in json_list]\n\n# create the SQL Query\nquery = f'''\nINSERT INTO {table_name} (user, content, url, context, score, type, id, datetime)\nVALUES \n'''\n\nfor value in values:\n    query += str(value) + ',\\n'\n\n# remove the last 2 character ,\\n and change it to ; for the query\nquery = query[:-2] + ';'\n\n# pass the query as a parameter downstream\nprint(\"#{setValue(query=%s)}\" % query)",
  "resourceList" : [ ]
}
[WI-749][TI-2047] - [INFO] 2024-04-29 17:56:50.096 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-749][TI-2047] - [INFO] 2024-04-29 17:56:50.100 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: null successfully
[WI-749][TI-2047] - [INFO] 2024-04-29 17:56:50.102 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-749][TI-2047] - [INFO] 2024-04-29 17:56:50.102 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-749][TI-2047] - [INFO] 2024-04-29 17:56:50.102 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-749][TI-2047] - [INFO] 2024-04-29 17:56:50.102 +0800 o.a.d.p.t.p.PythonTask:[165] - raw python script : import re
import json

# define the table to send the data to
table_name = "filtered_data_persistence"

# Provided JSON data as strings
json_data = ''' 
{
  "user": "premiumplatinum",
  "content": "singapore is stupid",
  "url": "https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/",
  "context": "21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist",
  "score": 131,
  "type": "post",
  "id": "1c9itat",
  "datetime": "2024-04-21 22:10:42"
}
{
        "user": "premiumplatinum",
        "content": "s is stupid",
        "url": "https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/",
        "context": "21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist",
        "score": 131,
        "type": "post",
        "id": "1c9itat",
        "datetime": "2024-04-21 22:10:42"
}
'''

# process the kafka messages to individual JSON objects
json_objects = json_data.replace('}\n{', '},\n{').strip()
json_objects = re.sub(" +", " ",json_objects)   
json_objects = '[' + json_objects + ']'

# convert JSON string to a list of dicts
json_list = json.loads(json_objects)

# convert list of dictionaries into list of tuples containing only the values
values = [tuple(message.values()) for message in json_list]

# create the SQL Query
query = f'''
INSERT INTO {table_name} (user, content, url, context, score, type, id, datetime)
VALUES 
'''

for value in values:
    query += str(value) + ',\n'

# remove the last 2 character ,\n and change it to ; for the query
query = query[:-2] + ';'

# pass the query as a parameter downstream
print("#{setValue(query=%s)}" % query)
[WI-749][TI-2047] - [INFO] 2024-04-29 17:56:50.104 +0800 o.a.d.p.t.p.PythonTask:[131] - tenantCode :default, task dir:/tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_9/749/2047
[WI-749][TI-2047] - [INFO] 2024-04-29 17:56:50.105 +0800 o.a.d.p.t.p.PythonTask:[134] - generate python script file:/tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_9/749/2047/py_749_2047.py
[WI-749][TI-2047] - [INFO] 2024-04-29 17:56:50.106 +0800 o.a.d.p.t.p.PythonTask:[141] - #-*- encoding=utf8 -*-

import re
import json

# define the table to send the data to
table_name = "filtered_data_persistence"

# Provided JSON data as strings
json_data = ''' 
{
  "user": "premiumplatinum",
  "content": "singapore is stupid",
  "url": "https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/",
  "context": "21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist",
  "score": 131,
  "type": "post",
  "id": "1c9itat",
  "datetime": "2024-04-21 22:10:42"
}
{
        "user": "premiumplatinum",
        "content": "s is stupid",
        "url": "https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/",
        "context": "21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist",
        "score": 131,
        "type": "post",
        "id": "1c9itat",
        "datetime": "2024-04-21 22:10:42"
}
'''

# process the kafka messages to individual JSON objects
json_objects = json_data.replace('}\n{', '},\n{').strip()
json_objects = re.sub(" +", " ",json_objects)   
json_objects = '[' + json_objects + ']'

# convert JSON string to a list of dicts
json_list = json.loads(json_objects)

# convert list of dictionaries into list of tuples containing only the values
values = [tuple(message.values()) for message in json_list]

# create the SQL Query
query = f'''
INSERT INTO {table_name} (user, content, url, context, score, type, id, datetime)
VALUES 
'''

for value in values:
    query += str(value) + ',\n'

# remove the last 2 character ,\n and change it to ; for the query
query = query[:-2] + ';'

# pass the query as a parameter downstream
print("#{setValue(query=%s)}" % query)
[WI-749][TI-2047] - [INFO] 2024-04-29 17:56:50.109 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-749][TI-2047] - [INFO] 2024-04-29 17:56:50.109 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-749][TI-2047] - [INFO] 2024-04-29 17:56:50.110 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export PYTHON_LAUNCHER=/bin/python3.11
${PYTHON_LAUNCHER} /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_9/749/2047/py_749_2047.py
[WI-749][TI-2047] - [INFO] 2024-04-29 17:56:50.110 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-749][TI-2047] - [INFO] 2024-04-29 17:56:50.110 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_9/749/2047/749_2047.sh
[WI-749][TI-2047] - [INFO] 2024-04-29 17:56:50.129 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 345
[WI-0][TI-0] - [INFO] 2024-04-29 17:56:50.132 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
[WI-0][TI-2047] - [INFO] 2024-04-29 17:56:50.938 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=2047, success=true)
[WI-0][TI-2047] - [INFO] 2024-04-29 17:56:50.947 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=2047)
[WI-0][TI-0] - [INFO] 2024-04-29 17:56:51.147 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	#{setValue(query=
	INSERT INTO filtered_data_persistence (user, content, url, context, score, type, id, datetime)
	VALUES 
	('premiumplatinum', 'singapore is stupid', 'https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/', '21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist', 131, 'post', '1c9itat', '2024-04-21 22:10:42'),
	('premiumplatinum', 's is stupid', 'https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/', '21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist', 131, 'post', '1c9itat', '2024-04-21 22:10:42');)}
[WI-749][TI-2047] - [INFO] 2024-04-29 17:56:51.149 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_9/749/2047, processId:345 ,exitStatusCode:0 ,processWaitForStatus:true ,processExitValue:0
[WI-749][TI-2047] - [INFO] 2024-04-29 17:56:51.149 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-749][TI-2047] - [INFO] 2024-04-29 17:56:51.150 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-749][TI-2047] - [INFO] 2024-04-29 17:56:51.150 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-749][TI-2047] - [INFO] 2024-04-29 17:56:51.151 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-749][TI-2047] - [INFO] 2024-04-29 17:56:51.169 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: SUCCESS to master : 172.18.1.1:1234
[WI-749][TI-2047] - [INFO] 2024-04-29 17:56:51.170 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-749][TI-2047] - [INFO] 2024-04-29 17:56:51.170 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_9/749/2047
[WI-749][TI-2047] - [INFO] 2024-04-29 17:56:51.171 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_9/749/2047
[WI-749][TI-2047] - [INFO] 2024-04-29 17:56:51.171 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-2047] - [INFO] 2024-04-29 17:56:51.946 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=2047, success=true)
[WI-0][TI-0] - [INFO] 2024-04-29 17:56:52.093 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=2048, taskName=Persist in postgresql, firstSubmitTime=1714384612070, startTime=0, taskType=SQL, workflowInstanceHost=172.18.0.12:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13426477386080, processDefineVersion=9, appIds=null, processInstanceId=749, scheduleTime=0, globalParams=null, executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[],"resourceList":[],"type":"POSTGRESQL","datasource":1,"sql":"${query}","sqlType":"0","preStatements":[],"postStatements":[],"displayRows":10}, environmentConfig=export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='Persist in postgresql'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, query=Property{prop='query', direct=IN, type=VARCHAR, value='
INSERT INTO filtered_data_persistence (user, content, url, context, score, type, id, datetime)
VALUES 
('premiumplatinum', 'singapore is stupid', 'https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/', '21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist', 131, 'post', '1c9itat', '2024-04-21 22:10:42'),
('premiumplatinum', 's is stupid', 'https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/', '21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist', 131, 'post', '1c9itat', '2024-04-21 22:10:42');'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240429'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='2048'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13427698681952'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240429175652'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='749'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240428'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='es_filtered_data_persistence_subprocess'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13426477386080'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=org.apache.dolphinscheduler.plugin.task.api.parameters.resource.ResourceParametersHelper@235e9166, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"query","direct":"IN","type":"VARCHAR","value":"\nINSERT INTO filtered_data_persistence (user, content, url, context, score, type, id, datetime)\nVALUES \n('premiumplatinum', 'singapore is stupid', 'https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/', '21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist', 131, 'post', '1c9itat', '2024-04-21 22:10:42'),\n('premiumplatinum', 's is stupid', 'https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/', '21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist', 131, 'post', '1c9itat', '2024-04-21 22:10:42');"}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-749][TI-2048] - [INFO] 2024-04-29 17:56:52.094 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: Persist in postgresql to wait queue success
[WI-749][TI-2048] - [INFO] 2024-04-29 17:56:52.095 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-749][TI-2048] - [INFO] 2024-04-29 17:56:52.095 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-749][TI-2048] - [INFO] 2024-04-29 17:56:52.096 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-749][TI-2048] - [INFO] 2024-04-29 17:56:52.096 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-749][TI-2048] - [INFO] 2024-04-29 17:56:52.096 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1714384612096
[WI-749][TI-2048] - [INFO] 2024-04-29 17:56:52.096 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 749_2048
[WI-749][TI-2048] - [INFO] 2024-04-29 17:56:52.096 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 2048,
  "taskName" : "Persist in postgresql",
  "firstSubmitTime" : 1714384612070,
  "startTime" : 1714384612096,
  "taskType" : "SQL",
  "workflowInstanceHost" : "172.18.0.12:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240429/13426477386080/9/749/2048.log",
  "processId" : 0,
  "processDefineCode" : 13426477386080,
  "processDefineVersion" : 9,
  "processInstanceId" : 749,
  "scheduleTime" : 0,
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[],\"resourceList\":[],\"type\":\"POSTGRESQL\",\"datasource\":1,\"sql\":\"${query}\",\"sqlType\":\"0\",\"preStatements\":[],\"postStatements\":[],\"displayRows\":10}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "Persist in postgresql"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "query" : {
      "prop" : "query",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "\nINSERT INTO filtered_data_persistence (user, content, url, context, score, type, id, datetime)\nVALUES \n('premiumplatinum', 'singapore is stupid', 'https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/', '21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist', 131, 'post', '1c9itat', '2024-04-21 22:10:42'),\n('premiumplatinum', 's is stupid', 'https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/', '21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist', 131, 'post', '1c9itat', '2024-04-21 22:10:42');"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240429"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "2048"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13427698681952"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240429175652"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "749"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240428"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "es_filtered_data_persistence_subprocess"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13426477386080"
    }
  },
  "taskAppId" : "749_2048",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "resourceParametersHelper" : {
    "resourceMap" : {
      "DATASOURCE" : {
        "1" : {
          "resourceType" : "DATASOURCE",
          "type" : "POSTGRESQL",
          "connectionParams" : "{\"user\":\"root\",\"password\":\"******\",\"address\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432\",\"database\":\"persistence\",\"jdbcUrl\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432/persistence\",\"driverClassName\":\"org.postgresql.Driver\",\"validationQuery\":\"select version()\",\"other\":{\"password\":\"root\"}}",
          "DATASOURCE" : null
        }
      }
    }
  },
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"query\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"\\nINSERT INTO filtered_data_persistence (user, content, url, context, score, type, id, datetime)\\nVALUES \\n('premiumplatinum', 'singapore is stupid', 'https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/', '21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist', 131, 'post', '1c9itat', '2024-04-21 22:10:42'),\\n('premiumplatinum', 's is stupid', 'https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/', '21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist', 131, 'post', '1c9itat', '2024-04-21 22:10:42');\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-749][TI-2048] - [INFO] 2024-04-29 17:56:52.097 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-749][TI-2048] - [INFO] 2024-04-29 17:56:52.097 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-749][TI-2048] - [INFO] 2024-04-29 17:56:52.097 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-749][TI-2048] - [INFO] 2024-04-29 17:56:52.112 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-749][TI-2048] - [INFO] 2024-04-29 17:56:52.114 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-749][TI-2048] - [INFO] 2024-04-29 17:56:52.115 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_9/749/2048 check successfully
[WI-749][TI-2048] - [INFO] 2024-04-29 17:56:52.116 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.sql.SqlTaskChannel successfully
[WI-749][TI-2048] - [INFO] 2024-04-29 17:56:52.116 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-749][TI-2048] - [INFO] 2024-04-29 17:56:52.117 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-749][TI-2048] - [INFO] 2024-04-29 17:56:52.117 +0800 o.a.d.p.t.s.SqlTask:[99] - Initialize sql task parameter {
  "localParams" : [ ],
  "varPool" : null,
  "type" : "POSTGRESQL",
  "datasource" : 1,
  "sql" : "${query}",
  "sqlType" : 0,
  "sendEmail" : null,
  "displayRows" : 10,
  "udfs" : null,
  "showType" : null,
  "connParams" : null,
  "preStatements" : [ ],
  "postStatements" : [ ],
  "groupId" : 0,
  "title" : null,
  "limit" : 0
}
[WI-749][TI-2048] - [INFO] 2024-04-29 17:56:52.117 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SQL create successfully
[WI-749][TI-2048] - [INFO] 2024-04-29 17:56:52.117 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-749][TI-2048] - [INFO] 2024-04-29 17:56:52.117 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"query","direct":"IN","type":"VARCHAR","value":"\nINSERT INTO filtered_data_persistence (user, content, url, context, score, type, id, datetime)\nVALUES \n('premiumplatinum', 'singapore is stupid', 'https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/', '21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist', 131, 'post', '1c9itat', '2024-04-21 22:10:42'),\n('premiumplatinum', 's is stupid', 'https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/', '21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist', 131, 'post', '1c9itat', '2024-04-21 22:10:42');"}] successfully
[WI-749][TI-2048] - [INFO] 2024-04-29 17:56:52.118 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-749][TI-2048] - [INFO] 2024-04-29 17:56:52.118 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-749][TI-2048] - [INFO] 2024-04-29 17:56:52.118 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-749][TI-2048] - [INFO] 2024-04-29 17:56:52.118 +0800 o.a.d.p.t.s.SqlTask:[119] - Full sql parameters: SqlParameters{type='POSTGRESQL', datasource=1, sql='${query}', sqlType=0, sendEmail=null, displayRows=10, limit=0, udfs='null', showType='null', connParams='null', groupId='0', title='null', preStatements=[], postStatements=[]}
[WI-749][TI-2048] - [INFO] 2024-04-29 17:56:52.118 +0800 o.a.d.p.t.s.SqlTask:[120] - sql type : POSTGRESQL, datasource : 1, sql : ${query} , localParams : [],udfs : null,showType : null,connParams : null,varPool : [Property{prop='query', direct=IN, type=VARCHAR, value='
INSERT INTO filtered_data_persistence (user, content, url, context, score, type, id, datetime)
VALUES 
('premiumplatinum', 'singapore is stupid', 'https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/', '21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist', 131, 'post', '1c9itat', '2024-04-21 22:10:42'),
('premiumplatinum', 's is stupid', 'https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/', '21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist', 131, 'post', '1c9itat', '2024-04-21 22:10:42');'}] ,query max result limit  0
[WI-749][TI-2048] - [INFO] 2024-04-29 17:56:52.119 +0800 o.a.d.p.t.a.AbstractTask:[206] - setSqlParamsMap: Property with paramName: query put in sqlParamsMap of content ${query} successfully.
[WI-749][TI-2048] - [INFO] 2024-04-29 17:56:52.119 +0800 o.a.d.p.t.s.SqlTask:[410] - after replace sql , preparing : ?
[WI-749][TI-2048] - [INFO] 2024-04-29 17:56:52.122 +0800 o.a.d.p.t.s.SqlTask:[420] - Sql Params are replaced sql , parameters:
INSERT INTO filtered_data_persistence (user, content, url, context, score, type, id, datetime)
VALUES 
('premiumplatinum', 'singapore is stupid', 'https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/', '21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist', 131, 'post', '1c9itat', '2024-04-21 22:10:42'),
('premiumplatinum', 's is stupid', 'https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/', '21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist', 131, 'post', '1c9itat', '2024-04-21 22:10:42');(VARCHAR)
[WI-749][TI-2048] - [INFO] 2024-04-29 17:56:52.122 +0800 o.a.d.p.t.s.SqlTask:[489] - can't find udf function resource
[WI-749][TI-2048] - [WARN] 2024-04-29 17:56:52.123 +0800 n.s.c.j.SnowflakeConnectString:[136] - Connect strings must start with jdbc:snowflake://
[WI-749][TI-2048] - [INFO] 2024-04-29 17:56:52.160 +0800 o.a.d.p.t.s.SqlTask:[392] - prepare statement replace sql : ?, sql parameters : {1=Property{prop='query', direct=IN, type=VARCHAR, value='
INSERT INTO filtered_data_persistence (user, content, url, context, score, type, id, datetime)
VALUES 
('premiumplatinum', 'singapore is stupid', 'https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/', '21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist', 131, 'post', '1c9itat', '2024-04-21 22:10:42'),
('premiumplatinum', 's is stupid', 'https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/', '21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist', 131, 'post', '1c9itat', '2024-04-21 22:10:42');'}}
[WI-749][TI-2048] - [INFO] 2024-04-29 17:56:52.161 +0800 o.a.d.p.t.s.SqlTask:[316] - main statement execute query, for sql: ?
[WI-749][TI-2048] - [ERROR] 2024-04-29 17:56:52.172 +0800 o.a.d.p.t.s.SqlTask:[217] - execute sql error: ERROR: syntax error at or near "$1"
  Position: 1
[WI-749][TI-2048] - [ERROR] 2024-04-29 17:56:52.179 +0800 o.a.d.p.t.s.SqlTask:[165] - sql task error
org.postgresql.util.PSQLException: ERROR: syntax error at or near "$1"
  Position: 1
	at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2676)
	at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2366)
	at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:356)
	at org.postgresql.jdbc.PgStatement.executeInternal(PgStatement.java:490)
	at org.postgresql.jdbc.PgStatement.execute(PgStatement.java:408)
	at org.postgresql.jdbc.PgPreparedStatement.executeWithFlags(PgPreparedStatement.java:181)
	at org.postgresql.jdbc.PgPreparedStatement.executeQuery(PgPreparedStatement.java:133)
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.executeQuery(SqlTask.java:317)
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.executeFuncAndSql(SqlTask.java:205)
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.handle(SqlTask.java:159)
	at org.apache.dolphinscheduler.server.worker.runner.DefaultWorkerTaskExecutor.executeTask(DefaultWorkerTaskExecutor.java:54)
	at org.apache.dolphinscheduler.server.worker.runner.WorkerTaskExecutor.run(WorkerTaskExecutor.java:175)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
[WI-749][TI-2048] - [ERROR] 2024-04-29 17:56:52.180 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[181] - Task execute failed, due to meet an exception
org.apache.dolphinscheduler.plugin.task.api.TaskException: Execute sql task failed
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.handle(SqlTask.java:166)
	at org.apache.dolphinscheduler.server.worker.runner.DefaultWorkerTaskExecutor.executeTask(DefaultWorkerTaskExecutor.java:54)
	at org.apache.dolphinscheduler.server.worker.runner.WorkerTaskExecutor.run(WorkerTaskExecutor.java:175)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.postgresql.util.PSQLException: ERROR: syntax error at or near "$1"
  Position: 1
	at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2676)
	at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2366)
	at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:356)
	at org.postgresql.jdbc.PgStatement.executeInternal(PgStatement.java:490)
	at org.postgresql.jdbc.PgStatement.execute(PgStatement.java:408)
	at org.postgresql.jdbc.PgPreparedStatement.executeWithFlags(PgPreparedStatement.java:181)
	at org.postgresql.jdbc.PgPreparedStatement.executeQuery(PgPreparedStatement.java:133)
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.executeQuery(SqlTask.java:317)
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.executeFuncAndSql(SqlTask.java:205)
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.handle(SqlTask.java:159)
	... 5 common frames omitted
[WI-749][TI-2048] - [INFO] 2024-04-29 17:56:52.180 +0800 o.a.d.p.t.a.u.ProcessUtils:[182] - Get appIds from worker 172.18.1.1:1234, taskLogPath: /opt/dolphinscheduler/logs/20240429/13426477386080/9/749/2048.log
[WI-749][TI-2048] - [INFO] 2024-04-29 17:56:52.181 +0800 o.a.d.p.t.a.u.LogUtils:[79] - Start finding appId in /opt/dolphinscheduler/logs/20240429/13426477386080/9/749/2048.log, fetch way: log 
[WI-749][TI-2048] - [INFO] 2024-04-29 17:56:52.181 +0800 o.a.d.p.t.a.u.ProcessUtils:[188] - The appId is empty
[WI-749][TI-2048] - [INFO] 2024-04-29 17:56:52.181 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[118] - Cancel the task successfully
[WI-749][TI-2048] - [INFO] 2024-04-29 17:56:52.188 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[125] - Get a exception when execute the task, will send the task status: FAILURE to master: 172.18.1.1:1234
[WI-749][TI-2048] - [INFO] 2024-04-29 17:56:52.189 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-2048] - [INFO] 2024-04-29 17:56:52.950 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=2048, success=true)
[WI-0][TI-2048] - [INFO] 2024-04-29 17:56:52.987 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=2048, success=true)
[WI-0][TI-0] - [INFO] 2024-04-29 17:56:53.696 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7977839335180056 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-29 17:56:54.108 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=2049, taskName=Persist in postgresql, firstSubmitTime=1714384614066, startTime=0, taskType=SQL, workflowInstanceHost=172.18.0.12:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13426477386080, processDefineVersion=9, appIds=null, processInstanceId=749, scheduleTime=0, globalParams=null, executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[],"resourceList":[],"type":"POSTGRESQL","datasource":1,"sql":"${query}","sqlType":"0","preStatements":[],"postStatements":[],"displayRows":10}, environmentConfig=export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='Persist in postgresql'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, query=Property{prop='query', direct=IN, type=VARCHAR, value='
INSERT INTO filtered_data_persistence (user, content, url, context, score, type, id, datetime)
VALUES 
('premiumplatinum', 'singapore is stupid', 'https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/', '21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist', 131, 'post', '1c9itat', '2024-04-21 22:10:42'),
('premiumplatinum', 's is stupid', 'https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/', '21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist', 131, 'post', '1c9itat', '2024-04-21 22:10:42');'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240429'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='2049'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13427698681952'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240429175654'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='749'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240428'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='es_filtered_data_persistence_subprocess'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13426477386080'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=org.apache.dolphinscheduler.plugin.task.api.parameters.resource.ResourceParametersHelper@2b0ece6e, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"query","direct":"IN","type":"VARCHAR","value":"\nINSERT INTO filtered_data_persistence (user, content, url, context, score, type, id, datetime)\nVALUES \n('premiumplatinum', 'singapore is stupid', 'https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/', '21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist', 131, 'post', '1c9itat', '2024-04-21 22:10:42'),\n('premiumplatinum', 's is stupid', 'https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/', '21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist', 131, 'post', '1c9itat', '2024-04-21 22:10:42');"}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-749][TI-2049] - [INFO] 2024-04-29 17:56:54.109 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: Persist in postgresql to wait queue success
[WI-749][TI-2049] - [INFO] 2024-04-29 17:56:54.115 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-749][TI-2049] - [INFO] 2024-04-29 17:56:54.120 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-749][TI-2049] - [INFO] 2024-04-29 17:56:54.120 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-749][TI-2049] - [INFO] 2024-04-29 17:56:54.120 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-749][TI-2049] - [INFO] 2024-04-29 17:56:54.120 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1714384614120
[WI-749][TI-2049] - [INFO] 2024-04-29 17:56:54.120 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 749_2049
[WI-749][TI-2049] - [INFO] 2024-04-29 17:56:54.138 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 2049,
  "taskName" : "Persist in postgresql",
  "firstSubmitTime" : 1714384614066,
  "startTime" : 1714384614120,
  "taskType" : "SQL",
  "workflowInstanceHost" : "172.18.0.12:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240429/13426477386080/9/749/2049.log",
  "processId" : 0,
  "processDefineCode" : 13426477386080,
  "processDefineVersion" : 9,
  "processInstanceId" : 749,
  "scheduleTime" : 0,
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[],\"resourceList\":[],\"type\":\"POSTGRESQL\",\"datasource\":1,\"sql\":\"${query}\",\"sqlType\":\"0\",\"preStatements\":[],\"postStatements\":[],\"displayRows\":10}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "Persist in postgresql"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "query" : {
      "prop" : "query",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "\nINSERT INTO filtered_data_persistence (user, content, url, context, score, type, id, datetime)\nVALUES \n('premiumplatinum', 'singapore is stupid', 'https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/', '21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist', 131, 'post', '1c9itat', '2024-04-21 22:10:42'),\n('premiumplatinum', 's is stupid', 'https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/', '21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist', 131, 'post', '1c9itat', '2024-04-21 22:10:42');"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240429"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "2049"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13427698681952"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240429175654"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "749"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240428"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "es_filtered_data_persistence_subprocess"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13426477386080"
    }
  },
  "taskAppId" : "749_2049",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "resourceParametersHelper" : {
    "resourceMap" : {
      "DATASOURCE" : {
        "1" : {
          "resourceType" : "DATASOURCE",
          "type" : "POSTGRESQL",
          "connectionParams" : "{\"user\":\"root\",\"password\":\"******\",\"address\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432\",\"database\":\"persistence\",\"jdbcUrl\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432/persistence\",\"driverClassName\":\"org.postgresql.Driver\",\"validationQuery\":\"select version()\",\"other\":{\"password\":\"root\"}}",
          "DATASOURCE" : null
        }
      }
    }
  },
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"query\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"\\nINSERT INTO filtered_data_persistence (user, content, url, context, score, type, id, datetime)\\nVALUES \\n('premiumplatinum', 'singapore is stupid', 'https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/', '21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist', 131, 'post', '1c9itat', '2024-04-21 22:10:42'),\\n('premiumplatinum', 's is stupid', 'https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/', '21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist', 131, 'post', '1c9itat', '2024-04-21 22:10:42');\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-749][TI-2049] - [INFO] 2024-04-29 17:56:54.140 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-749][TI-2049] - [INFO] 2024-04-29 17:56:54.141 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-749][TI-2049] - [INFO] 2024-04-29 17:56:54.142 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-749][TI-2049] - [INFO] 2024-04-29 17:56:54.153 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-749][TI-2049] - [INFO] 2024-04-29 17:56:54.154 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-749][TI-2049] - [INFO] 2024-04-29 17:56:54.155 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_9/749/2049 check successfully
[WI-749][TI-2049] - [INFO] 2024-04-29 17:56:54.155 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.sql.SqlTaskChannel successfully
[WI-749][TI-2049] - [INFO] 2024-04-29 17:56:54.156 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-749][TI-2049] - [INFO] 2024-04-29 17:56:54.157 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-749][TI-2049] - [INFO] 2024-04-29 17:56:54.158 +0800 o.a.d.p.t.s.SqlTask:[99] - Initialize sql task parameter {
  "localParams" : [ ],
  "varPool" : null,
  "type" : "POSTGRESQL",
  "datasource" : 1,
  "sql" : "${query}",
  "sqlType" : 0,
  "sendEmail" : null,
  "displayRows" : 10,
  "udfs" : null,
  "showType" : null,
  "connParams" : null,
  "preStatements" : [ ],
  "postStatements" : [ ],
  "groupId" : 0,
  "title" : null,
  "limit" : 0
}
[WI-749][TI-2049] - [INFO] 2024-04-29 17:56:54.158 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SQL create successfully
[WI-749][TI-2049] - [INFO] 2024-04-29 17:56:54.158 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-749][TI-2049] - [INFO] 2024-04-29 17:56:54.159 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"query","direct":"IN","type":"VARCHAR","value":"\nINSERT INTO filtered_data_persistence (user, content, url, context, score, type, id, datetime)\nVALUES \n('premiumplatinum', 'singapore is stupid', 'https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/', '21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist', 131, 'post', '1c9itat', '2024-04-21 22:10:42'),\n('premiumplatinum', 's is stupid', 'https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/', '21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist', 131, 'post', '1c9itat', '2024-04-21 22:10:42');"}] successfully
[WI-749][TI-2049] - [INFO] 2024-04-29 17:56:54.159 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-749][TI-2049] - [INFO] 2024-04-29 17:56:54.159 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-749][TI-2049] - [INFO] 2024-04-29 17:56:54.159 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-749][TI-2049] - [INFO] 2024-04-29 17:56:54.159 +0800 o.a.d.p.t.s.SqlTask:[119] - Full sql parameters: SqlParameters{type='POSTGRESQL', datasource=1, sql='${query}', sqlType=0, sendEmail=null, displayRows=10, limit=0, udfs='null', showType='null', connParams='null', groupId='0', title='null', preStatements=[], postStatements=[]}
[WI-749][TI-2049] - [INFO] 2024-04-29 17:56:54.159 +0800 o.a.d.p.t.s.SqlTask:[120] - sql type : POSTGRESQL, datasource : 1, sql : ${query} , localParams : [],udfs : null,showType : null,connParams : null,varPool : [Property{prop='query', direct=IN, type=VARCHAR, value='
INSERT INTO filtered_data_persistence (user, content, url, context, score, type, id, datetime)
VALUES 
('premiumplatinum', 'singapore is stupid', 'https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/', '21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist', 131, 'post', '1c9itat', '2024-04-21 22:10:42'),
('premiumplatinum', 's is stupid', 'https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/', '21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist', 131, 'post', '1c9itat', '2024-04-21 22:10:42');'}] ,query max result limit  0
[WI-749][TI-2049] - [INFO] 2024-04-29 17:56:54.160 +0800 o.a.d.p.t.a.AbstractTask:[206] - setSqlParamsMap: Property with paramName: query put in sqlParamsMap of content ${query} successfully.
[WI-749][TI-2049] - [INFO] 2024-04-29 17:56:54.161 +0800 o.a.d.p.t.s.SqlTask:[410] - after replace sql , preparing : ?
[WI-749][TI-2049] - [INFO] 2024-04-29 17:56:54.161 +0800 o.a.d.p.t.s.SqlTask:[420] - Sql Params are replaced sql , parameters:
INSERT INTO filtered_data_persistence (user, content, url, context, score, type, id, datetime)
VALUES 
('premiumplatinum', 'singapore is stupid', 'https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/', '21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist', 131, 'post', '1c9itat', '2024-04-21 22:10:42'),
('premiumplatinum', 's is stupid', 'https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/', '21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist', 131, 'post', '1c9itat', '2024-04-21 22:10:42');(VARCHAR)
[WI-749][TI-2049] - [INFO] 2024-04-29 17:56:54.161 +0800 o.a.d.p.t.s.SqlTask:[489] - can't find udf function resource
[WI-749][TI-2049] - [WARN] 2024-04-29 17:56:54.162 +0800 n.s.c.j.SnowflakeConnectString:[136] - Connect strings must start with jdbc:snowflake://
[WI-749][TI-2049] - [INFO] 2024-04-29 17:56:54.195 +0800 o.a.d.p.t.s.SqlTask:[392] - prepare statement replace sql : ?, sql parameters : {1=Property{prop='query', direct=IN, type=VARCHAR, value='
INSERT INTO filtered_data_persistence (user, content, url, context, score, type, id, datetime)
VALUES 
('premiumplatinum', 'singapore is stupid', 'https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/', '21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist', 131, 'post', '1c9itat', '2024-04-21 22:10:42'),
('premiumplatinum', 's is stupid', 'https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/', '21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist', 131, 'post', '1c9itat', '2024-04-21 22:10:42');'}}
[WI-749][TI-2049] - [INFO] 2024-04-29 17:56:54.195 +0800 o.a.d.p.t.s.SqlTask:[316] - main statement execute query, for sql: ?
[WI-749][TI-2049] - [ERROR] 2024-04-29 17:56:54.197 +0800 o.a.d.p.t.s.SqlTask:[217] - execute sql error: ERROR: syntax error at or near "$1"
  Position: 1
[WI-749][TI-2049] - [ERROR] 2024-04-29 17:56:54.197 +0800 o.a.d.p.t.s.SqlTask:[165] - sql task error
org.postgresql.util.PSQLException: ERROR: syntax error at or near "$1"
  Position: 1
	at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2676)
	at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2366)
	at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:356)
	at org.postgresql.jdbc.PgStatement.executeInternal(PgStatement.java:490)
	at org.postgresql.jdbc.PgStatement.execute(PgStatement.java:408)
	at org.postgresql.jdbc.PgPreparedStatement.executeWithFlags(PgPreparedStatement.java:181)
	at org.postgresql.jdbc.PgPreparedStatement.executeQuery(PgPreparedStatement.java:133)
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.executeQuery(SqlTask.java:317)
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.executeFuncAndSql(SqlTask.java:205)
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.handle(SqlTask.java:159)
	at org.apache.dolphinscheduler.server.worker.runner.DefaultWorkerTaskExecutor.executeTask(DefaultWorkerTaskExecutor.java:54)
	at org.apache.dolphinscheduler.server.worker.runner.WorkerTaskExecutor.run(WorkerTaskExecutor.java:175)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
[WI-749][TI-2049] - [ERROR] 2024-04-29 17:56:54.197 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[181] - Task execute failed, due to meet an exception
org.apache.dolphinscheduler.plugin.task.api.TaskException: Execute sql task failed
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.handle(SqlTask.java:166)
	at org.apache.dolphinscheduler.server.worker.runner.DefaultWorkerTaskExecutor.executeTask(DefaultWorkerTaskExecutor.java:54)
	at org.apache.dolphinscheduler.server.worker.runner.WorkerTaskExecutor.run(WorkerTaskExecutor.java:175)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.postgresql.util.PSQLException: ERROR: syntax error at or near "$1"
  Position: 1
	at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2676)
	at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2366)
	at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:356)
	at org.postgresql.jdbc.PgStatement.executeInternal(PgStatement.java:490)
	at org.postgresql.jdbc.PgStatement.execute(PgStatement.java:408)
	at org.postgresql.jdbc.PgPreparedStatement.executeWithFlags(PgPreparedStatement.java:181)
	at org.postgresql.jdbc.PgPreparedStatement.executeQuery(PgPreparedStatement.java:133)
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.executeQuery(SqlTask.java:317)
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.executeFuncAndSql(SqlTask.java:205)
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.handle(SqlTask.java:159)
	... 5 common frames omitted
[WI-749][TI-2049] - [INFO] 2024-04-29 17:56:54.198 +0800 o.a.d.p.t.a.u.ProcessUtils:[182] - Get appIds from worker 172.18.1.1:1234, taskLogPath: /opt/dolphinscheduler/logs/20240429/13426477386080/9/749/2049.log
[WI-749][TI-2049] - [INFO] 2024-04-29 17:56:54.198 +0800 o.a.d.p.t.a.u.LogUtils:[79] - Start finding appId in /opt/dolphinscheduler/logs/20240429/13426477386080/9/749/2049.log, fetch way: log 
[WI-749][TI-2049] - [INFO] 2024-04-29 17:56:54.198 +0800 o.a.d.p.t.a.u.ProcessUtils:[188] - The appId is empty
[WI-749][TI-2049] - [INFO] 2024-04-29 17:56:54.198 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[118] - Cancel the task successfully
[WI-749][TI-2049] - [INFO] 2024-04-29 17:56:54.212 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[125] - Get a exception when execute the task, will send the task status: FAILURE to master: 172.18.1.1:1234
[WI-749][TI-2049] - [INFO] 2024-04-29 17:56:54.212 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-2049] - [INFO] 2024-04-29 17:56:54.958 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=2049, success=true)
[WI-0][TI-2049] - [INFO] 2024-04-29 17:56:54.975 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=2049, success=true)
[WI-0][TI-0] - [INFO] 2024-04-29 17:56:56.048 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=2050, taskName=Persist in postgresql, firstSubmitTime=1714384616018, startTime=0, taskType=SQL, workflowInstanceHost=172.18.0.12:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13426477386080, processDefineVersion=9, appIds=null, processInstanceId=749, scheduleTime=0, globalParams=null, executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[],"resourceList":[],"type":"POSTGRESQL","datasource":1,"sql":"${query}","sqlType":"0","preStatements":[],"postStatements":[],"displayRows":10}, environmentConfig=export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='Persist in postgresql'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, query=Property{prop='query', direct=IN, type=VARCHAR, value='
INSERT INTO filtered_data_persistence (user, content, url, context, score, type, id, datetime)
VALUES 
('premiumplatinum', 'singapore is stupid', 'https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/', '21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist', 131, 'post', '1c9itat', '2024-04-21 22:10:42'),
('premiumplatinum', 's is stupid', 'https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/', '21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist', 131, 'post', '1c9itat', '2024-04-21 22:10:42');'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240429'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='2050'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13427698681952'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240429175656'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='749'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240428'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='es_filtered_data_persistence_subprocess'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13426477386080'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=org.apache.dolphinscheduler.plugin.task.api.parameters.resource.ResourceParametersHelper@6a8fccd2, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"query","direct":"IN","type":"VARCHAR","value":"\nINSERT INTO filtered_data_persistence (user, content, url, context, score, type, id, datetime)\nVALUES \n('premiumplatinum', 'singapore is stupid', 'https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/', '21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist', 131, 'post', '1c9itat', '2024-04-21 22:10:42'),\n('premiumplatinum', 's is stupid', 'https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/', '21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist', 131, 'post', '1c9itat', '2024-04-21 22:10:42');"}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-749][TI-2050] - [INFO] 2024-04-29 17:56:56.050 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: Persist in postgresql to wait queue success
[WI-749][TI-2050] - [INFO] 2024-04-29 17:56:56.054 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-749][TI-2050] - [INFO] 2024-04-29 17:56:56.075 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-749][TI-2050] - [INFO] 2024-04-29 17:56:56.076 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-749][TI-2050] - [INFO] 2024-04-29 17:56:56.076 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-749][TI-2050] - [INFO] 2024-04-29 17:56:56.076 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1714384616076
[WI-749][TI-2050] - [INFO] 2024-04-29 17:56:56.076 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 749_2050
[WI-749][TI-2050] - [INFO] 2024-04-29 17:56:56.077 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 2050,
  "taskName" : "Persist in postgresql",
  "firstSubmitTime" : 1714384616018,
  "startTime" : 1714384616076,
  "taskType" : "SQL",
  "workflowInstanceHost" : "172.18.0.12:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240429/13426477386080/9/749/2050.log",
  "processId" : 0,
  "processDefineCode" : 13426477386080,
  "processDefineVersion" : 9,
  "processInstanceId" : 749,
  "scheduleTime" : 0,
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[],\"resourceList\":[],\"type\":\"POSTGRESQL\",\"datasource\":1,\"sql\":\"${query}\",\"sqlType\":\"0\",\"preStatements\":[],\"postStatements\":[],\"displayRows\":10}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "Persist in postgresql"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "query" : {
      "prop" : "query",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "\nINSERT INTO filtered_data_persistence (user, content, url, context, score, type, id, datetime)\nVALUES \n('premiumplatinum', 'singapore is stupid', 'https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/', '21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist', 131, 'post', '1c9itat', '2024-04-21 22:10:42'),\n('premiumplatinum', 's is stupid', 'https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/', '21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist', 131, 'post', '1c9itat', '2024-04-21 22:10:42');"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240429"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "2050"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13427698681952"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240429175656"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "749"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240428"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "es_filtered_data_persistence_subprocess"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13426477386080"
    }
  },
  "taskAppId" : "749_2050",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "resourceParametersHelper" : {
    "resourceMap" : {
      "DATASOURCE" : {
        "1" : {
          "resourceType" : "DATASOURCE",
          "type" : "POSTGRESQL",
          "connectionParams" : "{\"user\":\"root\",\"password\":\"******\",\"address\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432\",\"database\":\"persistence\",\"jdbcUrl\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432/persistence\",\"driverClassName\":\"org.postgresql.Driver\",\"validationQuery\":\"select version()\",\"other\":{\"password\":\"root\"}}",
          "DATASOURCE" : null
        }
      }
    }
  },
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"query\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"\\nINSERT INTO filtered_data_persistence (user, content, url, context, score, type, id, datetime)\\nVALUES \\n('premiumplatinum', 'singapore is stupid', 'https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/', '21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist', 131, 'post', '1c9itat', '2024-04-21 22:10:42'),\\n('premiumplatinum', 's is stupid', 'https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/', '21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist', 131, 'post', '1c9itat', '2024-04-21 22:10:42');\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-749][TI-2050] - [INFO] 2024-04-29 17:56:56.078 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-749][TI-2050] - [INFO] 2024-04-29 17:56:56.078 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-749][TI-2050] - [INFO] 2024-04-29 17:56:56.078 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-749][TI-2050] - [INFO] 2024-04-29 17:56:56.110 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-749][TI-2050] - [INFO] 2024-04-29 17:56:56.110 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-749][TI-2050] - [INFO] 2024-04-29 17:56:56.111 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_9/749/2050 check successfully
[WI-749][TI-2050] - [INFO] 2024-04-29 17:56:56.112 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.sql.SqlTaskChannel successfully
[WI-749][TI-2050] - [INFO] 2024-04-29 17:56:56.113 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-749][TI-2050] - [INFO] 2024-04-29 17:56:56.114 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-749][TI-2050] - [INFO] 2024-04-29 17:56:56.137 +0800 o.a.d.p.t.s.SqlTask:[99] - Initialize sql task parameter {
  "localParams" : [ ],
  "varPool" : null,
  "type" : "POSTGRESQL",
  "datasource" : 1,
  "sql" : "${query}",
  "sqlType" : 0,
  "sendEmail" : null,
  "displayRows" : 10,
  "udfs" : null,
  "showType" : null,
  "connParams" : null,
  "preStatements" : [ ],
  "postStatements" : [ ],
  "groupId" : 0,
  "title" : null,
  "limit" : 0
}
[WI-749][TI-2050] - [INFO] 2024-04-29 17:56:56.138 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SQL create successfully
[WI-749][TI-2050] - [INFO] 2024-04-29 17:56:56.138 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-749][TI-2050] - [INFO] 2024-04-29 17:56:56.138 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"query","direct":"IN","type":"VARCHAR","value":"\nINSERT INTO filtered_data_persistence (user, content, url, context, score, type, id, datetime)\nVALUES \n('premiumplatinum', 'singapore is stupid', 'https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/', '21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist', 131, 'post', '1c9itat', '2024-04-21 22:10:42'),\n('premiumplatinum', 's is stupid', 'https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/', '21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist', 131, 'post', '1c9itat', '2024-04-21 22:10:42');"}] successfully
[WI-749][TI-2050] - [INFO] 2024-04-29 17:56:56.139 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-749][TI-2050] - [INFO] 2024-04-29 17:56:56.139 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-749][TI-2050] - [INFO] 2024-04-29 17:56:56.139 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-749][TI-2050] - [INFO] 2024-04-29 17:56:56.139 +0800 o.a.d.p.t.s.SqlTask:[119] - Full sql parameters: SqlParameters{type='POSTGRESQL', datasource=1, sql='${query}', sqlType=0, sendEmail=null, displayRows=10, limit=0, udfs='null', showType='null', connParams='null', groupId='0', title='null', preStatements=[], postStatements=[]}
[WI-749][TI-2050] - [INFO] 2024-04-29 17:56:56.139 +0800 o.a.d.p.t.s.SqlTask:[120] - sql type : POSTGRESQL, datasource : 1, sql : ${query} , localParams : [],udfs : null,showType : null,connParams : null,varPool : [Property{prop='query', direct=IN, type=VARCHAR, value='
INSERT INTO filtered_data_persistence (user, content, url, context, score, type, id, datetime)
VALUES 
('premiumplatinum', 'singapore is stupid', 'https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/', '21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist', 131, 'post', '1c9itat', '2024-04-21 22:10:42'),
('premiumplatinum', 's is stupid', 'https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/', '21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist', 131, 'post', '1c9itat', '2024-04-21 22:10:42');'}] ,query max result limit  0
[WI-749][TI-2050] - [INFO] 2024-04-29 17:56:56.140 +0800 o.a.d.p.t.a.AbstractTask:[206] - setSqlParamsMap: Property with paramName: query put in sqlParamsMap of content ${query} successfully.
[WI-749][TI-2050] - [INFO] 2024-04-29 17:56:56.140 +0800 o.a.d.p.t.s.SqlTask:[410] - after replace sql , preparing : ?
[WI-749][TI-2050] - [INFO] 2024-04-29 17:56:56.140 +0800 o.a.d.p.t.s.SqlTask:[420] - Sql Params are replaced sql , parameters:
INSERT INTO filtered_data_persistence (user, content, url, context, score, type, id, datetime)
VALUES 
('premiumplatinum', 'singapore is stupid', 'https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/', '21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist', 131, 'post', '1c9itat', '2024-04-21 22:10:42'),
('premiumplatinum', 's is stupid', 'https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/', '21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist', 131, 'post', '1c9itat', '2024-04-21 22:10:42');(VARCHAR)
[WI-749][TI-2050] - [INFO] 2024-04-29 17:56:56.141 +0800 o.a.d.p.t.s.SqlTask:[489] - can't find udf function resource
[WI-749][TI-2050] - [WARN] 2024-04-29 17:56:56.142 +0800 n.s.c.j.SnowflakeConnectString:[136] - Connect strings must start with jdbc:snowflake://
[WI-749][TI-2050] - [INFO] 2024-04-29 17:56:56.205 +0800 o.a.d.p.t.s.SqlTask:[392] - prepare statement replace sql : ?, sql parameters : {1=Property{prop='query', direct=IN, type=VARCHAR, value='
INSERT INTO filtered_data_persistence (user, content, url, context, score, type, id, datetime)
VALUES 
('premiumplatinum', 'singapore is stupid', 'https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/', '21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist', 131, 'post', '1c9itat', '2024-04-21 22:10:42'),
('premiumplatinum', 's is stupid', 'https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/', '21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist', 131, 'post', '1c9itat', '2024-04-21 22:10:42');'}}
[WI-749][TI-2050] - [INFO] 2024-04-29 17:56:56.205 +0800 o.a.d.p.t.s.SqlTask:[316] - main statement execute query, for sql: ?
[WI-749][TI-2050] - [ERROR] 2024-04-29 17:56:56.216 +0800 o.a.d.p.t.s.SqlTask:[217] - execute sql error: ERROR: syntax error at or near "$1"
  Position: 1
[WI-749][TI-2050] - [ERROR] 2024-04-29 17:56:56.217 +0800 o.a.d.p.t.s.SqlTask:[165] - sql task error
org.postgresql.util.PSQLException: ERROR: syntax error at or near "$1"
  Position: 1
	at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2676)
	at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2366)
	at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:356)
	at org.postgresql.jdbc.PgStatement.executeInternal(PgStatement.java:490)
	at org.postgresql.jdbc.PgStatement.execute(PgStatement.java:408)
	at org.postgresql.jdbc.PgPreparedStatement.executeWithFlags(PgPreparedStatement.java:181)
	at org.postgresql.jdbc.PgPreparedStatement.executeQuery(PgPreparedStatement.java:133)
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.executeQuery(SqlTask.java:317)
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.executeFuncAndSql(SqlTask.java:205)
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.handle(SqlTask.java:159)
	at org.apache.dolphinscheduler.server.worker.runner.DefaultWorkerTaskExecutor.executeTask(DefaultWorkerTaskExecutor.java:54)
	at org.apache.dolphinscheduler.server.worker.runner.WorkerTaskExecutor.run(WorkerTaskExecutor.java:175)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
[WI-749][TI-2050] - [ERROR] 2024-04-29 17:56:56.217 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[181] - Task execute failed, due to meet an exception
org.apache.dolphinscheduler.plugin.task.api.TaskException: Execute sql task failed
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.handle(SqlTask.java:166)
	at org.apache.dolphinscheduler.server.worker.runner.DefaultWorkerTaskExecutor.executeTask(DefaultWorkerTaskExecutor.java:54)
	at org.apache.dolphinscheduler.server.worker.runner.WorkerTaskExecutor.run(WorkerTaskExecutor.java:175)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.postgresql.util.PSQLException: ERROR: syntax error at or near "$1"
  Position: 1
	at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2676)
	at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2366)
	at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:356)
	at org.postgresql.jdbc.PgStatement.executeInternal(PgStatement.java:490)
	at org.postgresql.jdbc.PgStatement.execute(PgStatement.java:408)
	at org.postgresql.jdbc.PgPreparedStatement.executeWithFlags(PgPreparedStatement.java:181)
	at org.postgresql.jdbc.PgPreparedStatement.executeQuery(PgPreparedStatement.java:133)
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.executeQuery(SqlTask.java:317)
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.executeFuncAndSql(SqlTask.java:205)
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.handle(SqlTask.java:159)
	... 5 common frames omitted
[WI-749][TI-2050] - [INFO] 2024-04-29 17:56:56.217 +0800 o.a.d.p.t.a.u.ProcessUtils:[182] - Get appIds from worker 172.18.1.1:1234, taskLogPath: /opt/dolphinscheduler/logs/20240429/13426477386080/9/749/2050.log
[WI-749][TI-2050] - [INFO] 2024-04-29 17:56:56.218 +0800 o.a.d.p.t.a.u.LogUtils:[79] - Start finding appId in /opt/dolphinscheduler/logs/20240429/13426477386080/9/749/2050.log, fetch way: log 
[WI-749][TI-2050] - [INFO] 2024-04-29 17:56:56.218 +0800 o.a.d.p.t.a.u.ProcessUtils:[188] - The appId is empty
[WI-749][TI-2050] - [INFO] 2024-04-29 17:56:56.219 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[118] - Cancel the task successfully
[WI-749][TI-2050] - [INFO] 2024-04-29 17:56:56.225 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[125] - Get a exception when execute the task, will send the task status: FAILURE to master: 172.18.1.1:1234
[WI-749][TI-2050] - [INFO] 2024-04-29 17:56:56.226 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-0] - [INFO] 2024-04-29 17:56:56.720 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8041543026706232 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-2050] - [INFO] 2024-04-29 17:56:56.950 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=2050, success=true)
[WI-0][TI-2050] - [INFO] 2024-04-29 17:56:56.997 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=2050, success=true)
[WI-0][TI-0] - [INFO] 2024-04-29 17:56:58.108 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=2051, taskName=Persist in postgresql, firstSubmitTime=1714384618095, startTime=0, taskType=SQL, workflowInstanceHost=172.18.0.12:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13426477386080, processDefineVersion=9, appIds=null, processInstanceId=749, scheduleTime=0, globalParams=null, executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[],"resourceList":[],"type":"POSTGRESQL","datasource":1,"sql":"${query}","sqlType":"0","preStatements":[],"postStatements":[],"displayRows":10}, environmentConfig=export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='Persist in postgresql'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, query=Property{prop='query', direct=IN, type=VARCHAR, value='
INSERT INTO filtered_data_persistence (user, content, url, context, score, type, id, datetime)
VALUES 
('premiumplatinum', 'singapore is stupid', 'https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/', '21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist', 131, 'post', '1c9itat', '2024-04-21 22:10:42'),
('premiumplatinum', 's is stupid', 'https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/', '21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist', 131, 'post', '1c9itat', '2024-04-21 22:10:42');'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240429'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='2051'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13427698681952'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240429175658'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='749'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240428'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='es_filtered_data_persistence_subprocess'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13426477386080'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=org.apache.dolphinscheduler.plugin.task.api.parameters.resource.ResourceParametersHelper@4209752e, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"query","direct":"IN","type":"VARCHAR","value":"\nINSERT INTO filtered_data_persistence (user, content, url, context, score, type, id, datetime)\nVALUES \n('premiumplatinum', 'singapore is stupid', 'https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/', '21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist', 131, 'post', '1c9itat', '2024-04-21 22:10:42'),\n('premiumplatinum', 's is stupid', 'https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/', '21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist', 131, 'post', '1c9itat', '2024-04-21 22:10:42');"}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-749][TI-2051] - [INFO] 2024-04-29 17:56:58.109 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: Persist in postgresql to wait queue success
[WI-749][TI-2051] - [INFO] 2024-04-29 17:56:58.109 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-749][TI-2051] - [INFO] 2024-04-29 17:56:58.111 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-749][TI-2051] - [INFO] 2024-04-29 17:56:58.112 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-749][TI-2051] - [INFO] 2024-04-29 17:56:58.112 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-749][TI-2051] - [INFO] 2024-04-29 17:56:58.112 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1714384618112
[WI-749][TI-2051] - [INFO] 2024-04-29 17:56:58.112 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 749_2051
[WI-749][TI-2051] - [INFO] 2024-04-29 17:56:58.113 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 2051,
  "taskName" : "Persist in postgresql",
  "firstSubmitTime" : 1714384618095,
  "startTime" : 1714384618112,
  "taskType" : "SQL",
  "workflowInstanceHost" : "172.18.0.12:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240429/13426477386080/9/749/2051.log",
  "processId" : 0,
  "processDefineCode" : 13426477386080,
  "processDefineVersion" : 9,
  "processInstanceId" : 749,
  "scheduleTime" : 0,
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[],\"resourceList\":[],\"type\":\"POSTGRESQL\",\"datasource\":1,\"sql\":\"${query}\",\"sqlType\":\"0\",\"preStatements\":[],\"postStatements\":[],\"displayRows\":10}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "Persist in postgresql"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "query" : {
      "prop" : "query",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "\nINSERT INTO filtered_data_persistence (user, content, url, context, score, type, id, datetime)\nVALUES \n('premiumplatinum', 'singapore is stupid', 'https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/', '21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist', 131, 'post', '1c9itat', '2024-04-21 22:10:42'),\n('premiumplatinum', 's is stupid', 'https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/', '21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist', 131, 'post', '1c9itat', '2024-04-21 22:10:42');"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240429"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "2051"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13427698681952"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240429175658"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "749"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240428"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "es_filtered_data_persistence_subprocess"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13426477386080"
    }
  },
  "taskAppId" : "749_2051",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "resourceParametersHelper" : {
    "resourceMap" : {
      "DATASOURCE" : {
        "1" : {
          "resourceType" : "DATASOURCE",
          "type" : "POSTGRESQL",
          "connectionParams" : "{\"user\":\"root\",\"password\":\"******\",\"address\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432\",\"database\":\"persistence\",\"jdbcUrl\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432/persistence\",\"driverClassName\":\"org.postgresql.Driver\",\"validationQuery\":\"select version()\",\"other\":{\"password\":\"root\"}}",
          "DATASOURCE" : null
        }
      }
    }
  },
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"query\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"\\nINSERT INTO filtered_data_persistence (user, content, url, context, score, type, id, datetime)\\nVALUES \\n('premiumplatinum', 'singapore is stupid', 'https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/', '21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist', 131, 'post', '1c9itat', '2024-04-21 22:10:42'),\\n('premiumplatinum', 's is stupid', 'https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/', '21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist', 131, 'post', '1c9itat', '2024-04-21 22:10:42');\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-749][TI-2051] - [INFO] 2024-04-29 17:56:58.114 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-749][TI-2051] - [INFO] 2024-04-29 17:56:58.114 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-749][TI-2051] - [INFO] 2024-04-29 17:56:58.114 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-749][TI-2051] - [INFO] 2024-04-29 17:56:58.117 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-749][TI-2051] - [INFO] 2024-04-29 17:56:58.118 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-749][TI-2051] - [INFO] 2024-04-29 17:56:58.119 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_9/749/2051 check successfully
[WI-749][TI-2051] - [INFO] 2024-04-29 17:56:58.119 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.sql.SqlTaskChannel successfully
[WI-749][TI-2051] - [INFO] 2024-04-29 17:56:58.120 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-749][TI-2051] - [INFO] 2024-04-29 17:56:58.120 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-749][TI-2051] - [INFO] 2024-04-29 17:56:58.121 +0800 o.a.d.p.t.s.SqlTask:[99] - Initialize sql task parameter {
  "localParams" : [ ],
  "varPool" : null,
  "type" : "POSTGRESQL",
  "datasource" : 1,
  "sql" : "${query}",
  "sqlType" : 0,
  "sendEmail" : null,
  "displayRows" : 10,
  "udfs" : null,
  "showType" : null,
  "connParams" : null,
  "preStatements" : [ ],
  "postStatements" : [ ],
  "groupId" : 0,
  "title" : null,
  "limit" : 0
}
[WI-749][TI-2051] - [INFO] 2024-04-29 17:56:58.121 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SQL create successfully
[WI-749][TI-2051] - [INFO] 2024-04-29 17:56:58.122 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-749][TI-2051] - [INFO] 2024-04-29 17:56:58.122 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"query","direct":"IN","type":"VARCHAR","value":"\nINSERT INTO filtered_data_persistence (user, content, url, context, score, type, id, datetime)\nVALUES \n('premiumplatinum', 'singapore is stupid', 'https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/', '21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist', 131, 'post', '1c9itat', '2024-04-21 22:10:42'),\n('premiumplatinum', 's is stupid', 'https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/', '21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist', 131, 'post', '1c9itat', '2024-04-21 22:10:42');"}] successfully
[WI-749][TI-2051] - [INFO] 2024-04-29 17:56:58.122 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-749][TI-2051] - [INFO] 2024-04-29 17:56:58.123 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-749][TI-2051] - [INFO] 2024-04-29 17:56:58.123 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-749][TI-2051] - [INFO] 2024-04-29 17:56:58.123 +0800 o.a.d.p.t.s.SqlTask:[119] - Full sql parameters: SqlParameters{type='POSTGRESQL', datasource=1, sql='${query}', sqlType=0, sendEmail=null, displayRows=10, limit=0, udfs='null', showType='null', connParams='null', groupId='0', title='null', preStatements=[], postStatements=[]}
[WI-749][TI-2051] - [INFO] 2024-04-29 17:56:58.124 +0800 o.a.d.p.t.s.SqlTask:[120] - sql type : POSTGRESQL, datasource : 1, sql : ${query} , localParams : [],udfs : null,showType : null,connParams : null,varPool : [Property{prop='query', direct=IN, type=VARCHAR, value='
INSERT INTO filtered_data_persistence (user, content, url, context, score, type, id, datetime)
VALUES 
('premiumplatinum', 'singapore is stupid', 'https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/', '21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist', 131, 'post', '1c9itat', '2024-04-21 22:10:42'),
('premiumplatinum', 's is stupid', 'https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/', '21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist', 131, 'post', '1c9itat', '2024-04-21 22:10:42');'}] ,query max result limit  0
[WI-749][TI-2051] - [INFO] 2024-04-29 17:56:58.125 +0800 o.a.d.p.t.a.AbstractTask:[206] - setSqlParamsMap: Property with paramName: query put in sqlParamsMap of content ${query} successfully.
[WI-749][TI-2051] - [INFO] 2024-04-29 17:56:58.125 +0800 o.a.d.p.t.s.SqlTask:[410] - after replace sql , preparing : ?
[WI-749][TI-2051] - [INFO] 2024-04-29 17:56:58.126 +0800 o.a.d.p.t.s.SqlTask:[420] - Sql Params are replaced sql , parameters:
INSERT INTO filtered_data_persistence (user, content, url, context, score, type, id, datetime)
VALUES 
('premiumplatinum', 'singapore is stupid', 'https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/', '21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist', 131, 'post', '1c9itat', '2024-04-21 22:10:42'),
('premiumplatinum', 's is stupid', 'https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/', '21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist', 131, 'post', '1c9itat', '2024-04-21 22:10:42');(VARCHAR)
[WI-749][TI-2051] - [INFO] 2024-04-29 17:56:58.126 +0800 o.a.d.p.t.s.SqlTask:[489] - can't find udf function resource
[WI-749][TI-2051] - [WARN] 2024-04-29 17:56:58.126 +0800 n.s.c.j.SnowflakeConnectString:[136] - Connect strings must start with jdbc:snowflake://
[WI-749][TI-2051] - [INFO] 2024-04-29 17:56:58.148 +0800 o.a.d.p.t.s.SqlTask:[392] - prepare statement replace sql : ?, sql parameters : {1=Property{prop='query', direct=IN, type=VARCHAR, value='
INSERT INTO filtered_data_persistence (user, content, url, context, score, type, id, datetime)
VALUES 
('premiumplatinum', 'singapore is stupid', 'https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/', '21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist', 131, 'post', '1c9itat', '2024-04-21 22:10:42'),
('premiumplatinum', 's is stupid', 'https://www.reddit.com/r/singapore/comments/1c9itat/21apr2024_orchard_road_camcar_turning_right_into/', '21apr2024 orchard road camcar turning right into centrepoint get tbone by cyclist', 131, 'post', '1c9itat', '2024-04-21 22:10:42');'}}
[WI-749][TI-2051] - [INFO] 2024-04-29 17:56:58.148 +0800 o.a.d.p.t.s.SqlTask:[316] - main statement execute query, for sql: ?
[WI-749][TI-2051] - [ERROR] 2024-04-29 17:56:58.149 +0800 o.a.d.p.t.s.SqlTask:[217] - execute sql error: ERROR: syntax error at or near "$1"
  Position: 1
[WI-749][TI-2051] - [ERROR] 2024-04-29 17:56:58.150 +0800 o.a.d.p.t.s.SqlTask:[165] - sql task error
org.postgresql.util.PSQLException: ERROR: syntax error at or near "$1"
  Position: 1
	at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2676)
	at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2366)
	at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:356)
	at org.postgresql.jdbc.PgStatement.executeInternal(PgStatement.java:490)
	at org.postgresql.jdbc.PgStatement.execute(PgStatement.java:408)
	at org.postgresql.jdbc.PgPreparedStatement.executeWithFlags(PgPreparedStatement.java:181)
	at org.postgresql.jdbc.PgPreparedStatement.executeQuery(PgPreparedStatement.java:133)
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.executeQuery(SqlTask.java:317)
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.executeFuncAndSql(SqlTask.java:205)
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.handle(SqlTask.java:159)
	at org.apache.dolphinscheduler.server.worker.runner.DefaultWorkerTaskExecutor.executeTask(DefaultWorkerTaskExecutor.java:54)
	at org.apache.dolphinscheduler.server.worker.runner.WorkerTaskExecutor.run(WorkerTaskExecutor.java:175)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
[WI-749][TI-2051] - [ERROR] 2024-04-29 17:56:58.150 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[181] - Task execute failed, due to meet an exception
org.apache.dolphinscheduler.plugin.task.api.TaskException: Execute sql task failed
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.handle(SqlTask.java:166)
	at org.apache.dolphinscheduler.server.worker.runner.DefaultWorkerTaskExecutor.executeTask(DefaultWorkerTaskExecutor.java:54)
	at org.apache.dolphinscheduler.server.worker.runner.WorkerTaskExecutor.run(WorkerTaskExecutor.java:175)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.postgresql.util.PSQLException: ERROR: syntax error at or near "$1"
  Position: 1
	at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2676)
	at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2366)
	at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:356)
	at org.postgresql.jdbc.PgStatement.executeInternal(PgStatement.java:490)
	at org.postgresql.jdbc.PgStatement.execute(PgStatement.java:408)
	at org.postgresql.jdbc.PgPreparedStatement.executeWithFlags(PgPreparedStatement.java:181)
	at org.postgresql.jdbc.PgPreparedStatement.executeQuery(PgPreparedStatement.java:133)
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.executeQuery(SqlTask.java:317)
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.executeFuncAndSql(SqlTask.java:205)
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.handle(SqlTask.java:159)
	... 5 common frames omitted
[WI-749][TI-2051] - [INFO] 2024-04-29 17:56:58.150 +0800 o.a.d.p.t.a.u.ProcessUtils:[182] - Get appIds from worker 172.18.1.1:1234, taskLogPath: /opt/dolphinscheduler/logs/20240429/13426477386080/9/749/2051.log
[WI-749][TI-2051] - [INFO] 2024-04-29 17:56:58.150 +0800 o.a.d.p.t.a.u.LogUtils:[79] - Start finding appId in /opt/dolphinscheduler/logs/20240429/13426477386080/9/749/2051.log, fetch way: log 
[WI-749][TI-2051] - [INFO] 2024-04-29 17:56:58.151 +0800 o.a.d.p.t.a.u.ProcessUtils:[188] - The appId is empty
[WI-749][TI-2051] - [INFO] 2024-04-29 17:56:58.151 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[118] - Cancel the task successfully
[WI-749][TI-2051] - [INFO] 2024-04-29 17:56:58.154 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[125] - Get a exception when execute the task, will send the task status: FAILURE to master: 172.18.1.1:1234
[WI-749][TI-2051] - [INFO] 2024-04-29 17:56:58.155 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-2051] - [INFO] 2024-04-29 17:56:58.968 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=2051, success=true)
[WI-0][TI-2051] - [INFO] 2024-04-29 17:56:58.988 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=2051, success=true)
[WI-0][TI-0] - [INFO] 2024-04-29 17:57:05.770 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7718309859154929 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-29 17:57:06.796 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7479224376731302 is over then the MaxCpuUsagePercentageThresholds 0.7
