[WI-0][TI-0] - [WARN] 2024-05-07 10:01:19.817 +0800 o.s.c.k.c.p.AbstractKubernetesProfileEnvironmentPostProcessor:[258] - Not running inside kubernetes. Skipping 'kubernetes' profile activation.
[WI-0][TI-0] - [WARN] 2024-05-07 10:01:27.365 +0800 o.s.c.k.c.p.AbstractKubernetesProfileEnvironmentPostProcessor:[258] - Not running inside kubernetes. Skipping 'kubernetes' profile activation.
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:27.430 +0800 o.a.d.s.w.WorkerServer:[634] - No active profile set, falling back to 1 default profile: "default"
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:40.029 +0800 o.s.c.c.s.GenericScope:[283] - BeanFactory id=7e7bf7c6-2cb3-34d2-a0d5-a56161c67d0e
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:41.180 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'org.springframework.cloud.commons.config.CommonsConfigAutoConfiguration' of type [org.springframework.cloud.commons.config.CommonsConfigAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:41.216 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'org.springframework.cloud.client.loadbalancer.LoadBalancerDefaultMappingsProviderAutoConfiguration' of type [org.springframework.cloud.client.loadbalancer.LoadBalancerDefaultMappingsProviderAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:41.219 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'loadBalancerClientsDefaultsMappingsProvider' of type [org.springframework.cloud.client.loadbalancer.LoadBalancerDefaultMappingsProviderAutoConfiguration$$Lambda$392/189820624] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:41.227 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'defaultsBindHandlerAdvisor' of type [org.springframework.cloud.commons.config.DefaultsBindHandlerAdvisor] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:41.263 +0800 o.a.d.c.u.NetUtils:[312] - Get all NetworkInterfaces: [name:eth0 (eth0), name:lo (lo)]
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:41.296 +0800 o.a.d.s.w.c.WorkerConfig:[98] - 
****************************Worker Configuration**************************************
  listen-port -> 1234
  exec-threads -> 100
  max-heartbeat-interval -> PT10S
  host-weight -> 100
  tenantConfig -> TenantConfig(autoCreateTenantEnabled=true, distributedTenantEnabled=false, defaultTenantEnabled=false)
  server-load-protection -> WorkerServerLoadProtection(enabled=true, maxCpuUsagePercentageThresholds=0.7, maxJVMMemoryUsagePercentageThresholds=0.7, maxSystemMemoryUsagePercentageThresholds=0.7, maxDiskUsagePercentageThresholds=0.7)
  registry-disconnect-strategy -> ConnectStrategyProperties(strategy=WAITING, maxWaitingTime=PT1M40S)
  task-execute-threads-full-policy: REJECT
  address -> 172.18.1.1:1234
  registry-path: /nodes/worker/172.18.1.1:1234
****************************Worker Configuration**************************************
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:41.297 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'workerConfig' of type [org.apache.dolphinscheduler.server.worker.config.WorkerConfig$$EnhancerBySpringCGLIB$$153d90bb] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:41.627 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'io.kubernetes.client.spring.extended.manifests.config.KubernetesManifestsAutoConfiguration' of type [io.kubernetes.client.spring.extended.manifests.config.KubernetesManifestsAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:41.654 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'kubernetes.manifests-io.kubernetes.client.spring.extended.manifests.config.KubernetesManifestsProperties' of type [io.kubernetes.client.spring.extended.manifests.config.KubernetesManifestsProperties] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:41.683 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'io.kubernetes.client.spring.extended.controller.config.KubernetesInformerAutoConfiguration' of type [io.kubernetes.client.spring.extended.controller.config.KubernetesInformerAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:41.756 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'defaultApiClient' of type [io.kubernetes.client.openapi.ApiClient] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:42.555 +0800 o.e.j.u.log:[170] - Logging initialized @37642ms to org.eclipse.jetty.util.log.Slf4jLog
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:44.704 +0800 o.s.b.w.e.j.JettyServletWebServerFactory:[166] - Server initialized with port: 1235
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:44.708 +0800 o.e.j.s.Server:[375] - jetty-9.4.48.v20220622; built: 2022-06-21T20:42:25.880Z; git: 6b67c5719d1f4371b33655ff2d047d24e171e49a; jvm 1.8.0_402-b06
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:45.463 +0800 o.e.j.s.h.C.application:[2368] - Initializing Spring embedded WebApplicationContext
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:45.464 +0800 o.s.b.w.s.c.ServletWebServerApplicationContext:[292] - Root WebApplicationContext: initialization completed in 17623 ms
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:47.547 +0800 o.e.j.s.session:[334] - DefaultSessionIdManager workerName=node0
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:47.550 +0800 o.e.j.s.session:[339] - No SessionScavenger set, using defaults
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:47.553 +0800 o.e.j.s.session:[132] - node0 Scavenging every 660000ms
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:47.798 +0800 o.e.j.s.h.ContextHandler:[921] - Started o.s.b.w.e.j.JettyEmbeddedWebAppContext@5403431a{application,/,[file:///tmp/jetty-docbase.1235.2308644928809038141/],AVAILABLE}
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:47.804 +0800 o.e.j.s.Server:[415] - Started @42891ms
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:49.104 +0800 o.a.c.f.i.CuratorFrameworkImpl:[338] - Starting
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:49.117 +0800 o.a.z.ZooKeeper:[98] - Client environment:zookeeper.version=3.8.0-5a02a05eddb59aee6ac762f7ea82e92a68eb9c0f, built on 2022-02-25 08:49 UTC
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:49.117 +0800 o.a.z.ZooKeeper:[98] - Client environment:host.name=6461fa46f54d
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:49.117 +0800 o.a.z.ZooKeeper:[98] - Client environment:java.version=1.8.0_402
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:49.118 +0800 o.a.z.ZooKeeper:[98] - Client environment:java.vendor=Temurin
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:49.118 +0800 o.a.z.ZooKeeper:[98] - Client environment:java.home=/opt/java/openjdk
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:49.118 +0800 o.a.z.ZooKeeper:[98] - Client environment:java.class.path=/opt/dolphinscheduler/conf:/opt/dolphinscheduler/libs/kerb-client-1.0.1.jar:/opt/dolphinscheduler/libs/spring-cloud-starter-kubernetes-client-config-2.1.3.jar:/opt/dolphinscheduler/libs/oauth2-oidc-sdk-9.35.jar:/opt/dolphinscheduler/libs/jsqlparser-4.4.jar:/opt/dolphinscheduler/libs/reactive-streams-1.0.4.jar:/opt/dolphinscheduler/libs/kubernetes-model-extensions-5.10.2.jar:/opt/dolphinscheduler/libs/zookeeper-3.8.0.jar:/opt/dolphinscheduler/libs/kubernetes-model-apps-5.10.2.jar:/opt/dolphinscheduler/libs/grpc-api-1.41.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-pigeon-3.2.1.jar:/opt/dolphinscheduler/libs/client-java-api-13.0.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-obs-3.2.1.jar:/opt/dolphinscheduler/libs/spring-web-5.3.22.jar:/opt/dolphinscheduler/libs/aws-java-sdk-emr-1.12.300.jar:/opt/dolphinscheduler/libs/spring-context-5.3.22.jar:/opt/dolphinscheduler/libs/gapic-google-cloud-storage-v2-2.18.0-alpha.jar:/opt/dolphinscheduler/libs/spring-cloud-kubernetes-client-config-2.1.3.jar:/opt/dolphinscheduler/libs/jetty-io-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/annotations-13.0.jar:/opt/dolphinscheduler/libs/jpam-1.1.jar:/opt/dolphinscheduler/libs/joda-time-2.10.13.jar:/opt/dolphinscheduler/libs/spring-cloud-kubernetes-client-autoconfig-2.1.3.jar:/opt/dolphinscheduler/libs/kerb-identity-1.0.1.jar:/opt/dolphinscheduler/libs/vertica-jdbc-12.0.4-0.jar:/opt/dolphinscheduler/libs/grpc-googleapis-1.52.1.jar:/opt/dolphinscheduler/libs/aliyun-java-sdk-kms-2.11.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-dvc-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-hana-3.2.1.jar:/opt/dolphinscheduler/libs/kubernetes-httpclient-okhttp-6.0.0.jar:/opt/dolphinscheduler/libs/jline-2.12.jar:/opt/dolphinscheduler/libs/sshd-core-2.8.0.jar:/opt/dolphinscheduler/libs/jna-platform-5.10.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-sqlserver-3.2.1.jar:/opt/dolphinscheduler/libs/commons-beanutils-1.9.4.jar:/opt/dolphinscheduler/libs/grpc-services-1.41.0.jar:/opt/dolphinscheduler/libs/jmespath-java-1.12.300.jar:/opt/dolphinscheduler/libs/curator-client-5.3.0.jar:/opt/dolphinscheduler/libs/proto-google-common-protos-2.0.1.jar:/opt/dolphinscheduler/libs/mybatis-3.5.10.jar:/opt/dolphinscheduler/libs/jackson-annotations-2.13.4.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-all-3.2.1.jar:/opt/dolphinscheduler/libs/jakarta.xml.bind-api-2.3.3.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-jupyter-3.2.1.jar:/opt/dolphinscheduler/libs/mybatis-plus-extension-3.5.2.jar:/opt/dolphinscheduler/libs/j2objc-annotations-1.3.jar:/opt/dolphinscheduler/libs/Java-WebSocket-1.5.1.jar:/opt/dolphinscheduler/libs/azure-storage-common-12.20.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-sagemaker-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-databend-3.2.1.jar:/opt/dolphinscheduler/libs/google-auth-library-oauth2-http-1.15.0.jar:/opt/dolphinscheduler/libs/jetty-security-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-python-3.2.1.jar:/opt/dolphinscheduler/libs/snappy-java-1.1.10.1.jar:/opt/dolphinscheduler/libs/kubernetes-model-batch-5.10.2.jar:/opt/dolphinscheduler/libs/netty-transport-native-epoll-4.1.53.Final-linux-x86_64.jar:/opt/dolphinscheduler/libs/jackson-core-asl-1.9.13.jar:/opt/dolphinscheduler/libs/gson-fire-1.8.5.jar:/opt/dolphinscheduler/libs/clickhouse-jdbc-0.4.6.jar:/opt/dolphinscheduler/libs/grpc-netty-shaded-1.41.0.jar:/opt/dolphinscheduler/libs/caffeine-2.9.3.jar:/opt/dolphinscheduler/libs/aliyun-java-sdk-core-4.5.10.jar:/opt/dolphinscheduler/libs/jackson-module-jaxb-annotations-2.13.3.jar:/opt/dolphinscheduler/libs/jetty-http-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/jersey-servlet-1.19.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-dinky-3.2.1.jar:/opt/dolphinscheduler/libs/simpleclient_tracer_common-0.15.0.jar:/opt/dolphinscheduler/libs/netty-handler-4.1.53.Final.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-datafactory-3.2.1.jar:/opt/dolphinscheduler/libs/json-path-2.7.0.jar:/opt/dolphinscheduler/libs/mybatis-plus-annotation-3.5.2.jar:/opt/dolphinscheduler/libs/azure-resourcemanager-datafactory-1.0.0-beta.19.jar:/opt/dolphinscheduler/libs/commons-codec-1.11.jar:/opt/dolphinscheduler/libs/dolphinscheduler-extract-master-3.2.1.jar:/opt/dolphinscheduler/libs/spring-aop-5.3.22.jar:/opt/dolphinscheduler/libs/kubernetes-model-core-5.10.2.jar:/opt/dolphinscheduler/libs/kubernetes-model-networking-5.10.2.jar:/opt/dolphinscheduler/libs/kotlin-stdlib-jdk7-1.6.21.jar:/opt/dolphinscheduler/libs/kerby-xdr-1.0.1.jar:/opt/dolphinscheduler/libs/aliyun-java-sdk-ram-3.1.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-k8s-3.2.1.jar:/opt/dolphinscheduler/libs/guava-31.1-jre.jar:/opt/dolphinscheduler/libs/netty-codec-dns-4.1.53.Final.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-kubeflow-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-azure-sql-3.2.1.jar:/opt/dolphinscheduler/libs/HikariCP-4.0.3.jar:/opt/dolphinscheduler/libs/hive-metastore-2.3.9.jar:/opt/dolphinscheduler/libs/msal4j-1.13.3.jar:/opt/dolphinscheduler/libs/jackson-core-2.13.4.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-hive-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-mr-3.2.1.jar:/opt/dolphinscheduler/libs/kubernetes-model-node-5.10.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-common-3.2.1.jar:/opt/dolphinscheduler/libs/jose4j-0.7.8.jar:/opt/dolphinscheduler/libs/jul-to-slf4j-1.7.36.jar:/opt/dolphinscheduler/libs/azure-identity-1.7.1.jar:/opt/dolphinscheduler/libs/spring-boot-autoconfigure-2.7.3.jar:/opt/dolphinscheduler/libs/commons-math3-3.1.1.jar:/opt/dolphinscheduler/libs/jackson-jaxrs-json-provider-2.13.3.jar:/opt/dolphinscheduler/libs/perfmark-api-0.23.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-doris-3.2.1.jar:/opt/dolphinscheduler/libs/httpclient-4.5.13.jar:/opt/dolphinscheduler/libs/hive-service-2.3.9.jar:/opt/dolphinscheduler/libs/kerby-util-1.0.1.jar:/opt/dolphinscheduler/libs/commons-collections-3.2.2.jar:/opt/dolphinscheduler/libs/hadoop-yarn-client-3.2.4.jar:/opt/dolphinscheduler/libs/commons-text-1.8.jar:/opt/dolphinscheduler/libs/dolphinscheduler-worker-3.2.1.jar:/opt/dolphinscheduler/libs/hadoop-yarn-common-3.2.4.jar:/opt/dolphinscheduler/libs/zeppelin-client-0.10.1.jar:/opt/dolphinscheduler/libs/azure-core-management-1.10.1.jar:/opt/dolphinscheduler/libs/hadoop-mapreduce-client-jobclient-3.2.4.jar:/opt/dolphinscheduler/libs/jta-1.1.jar:/opt/dolphinscheduler/libs/annotations-4.1.1.4.jar:/opt/dolphinscheduler/libs/dolphinscheduler-extract-alert-3.2.1.jar:/opt/dolphinscheduler/libs/curator-framework-5.3.0.jar:/opt/dolphinscheduler/libs/hive-jdbc-2.3.9.jar:/opt/dolphinscheduler/libs/kyuubi-hive-jdbc-shaded-1.7.0.jar:/opt/dolphinscheduler/libs/client-java-proto-13.0.2.jar:/opt/dolphinscheduler/libs/checker-qual-3.19.0.jar:/opt/dolphinscheduler/libs/jetty-servlet-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/google-cloud-core-grpc-2.10.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-shell-3.2.1.jar:/opt/dolphinscheduler/libs/spring-security-rsa-1.0.10.RELEASE.jar:/opt/dolphinscheduler/libs/avro-1.7.7.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-postgresql-3.2.1.jar:/opt/dolphinscheduler/libs/netty-nio-client-2.17.282.jar:/opt/dolphinscheduler/libs/spring-webmvc-5.3.22.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-mysql-3.2.1.jar:/opt/dolphinscheduler/libs/opentracing-util-0.33.0.jar:/opt/dolphinscheduler/libs/auto-value-1.10.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-all-3.2.1.jar:/opt/dolphinscheduler/libs/jetcd-core-0.5.11.jar:/opt/dolphinscheduler/libs/grpc-context-1.41.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-datasync-3.2.1.jar:/opt/dolphinscheduler/libs/jackson-dataformat-cbor-2.13.3.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-gcs-3.2.1.jar:/opt/dolphinscheduler/libs/client-java-extended-13.0.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-redshift-3.2.1.jar:/opt/dolphinscheduler/libs/opencsv-2.3.jar:/opt/dolphinscheduler/libs/jcip-annotations-1.0-1.jar:/opt/dolphinscheduler/libs/accessors-smart-2.4.8.jar:/opt/dolphinscheduler/libs/hadoop-client-3.2.4.jar:/opt/dolphinscheduler/libs/commons-collections4-4.3.jar:/opt/dolphinscheduler/libs/metrics-core-4.2.11.jar:/opt/dolphinscheduler/libs/netty-resolver-4.1.53.Final.jar:/opt/dolphinscheduler/libs/parquet-hadoop-bundle-1.8.1.jar:/opt/dolphinscheduler/libs/bucket4j-core-6.2.0.jar:/opt/dolphinscheduler/libs/spring-cloud-starter-3.1.3.jar:/opt/dolphinscheduler/libs/mssql-jdbc-11.2.1.jre8.jar:/opt/dolphinscheduler/libs/netty-tcnative-boringssl-static-2.0.53.Final.jar:/opt/dolphinscheduler/libs/kubernetes-model-coordination-5.10.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-linkis-3.2.1.jar:/opt/dolphinscheduler/libs/commons-net-3.6.jar:/opt/dolphinscheduler/libs/netty-transport-native-kqueue-4.1.53.Final-osx-x86_64.jar:/opt/dolphinscheduler/libs/dolphinscheduler-meter-3.2.1.jar:/opt/dolphinscheduler/libs/kubernetes-client-api-6.0.0.jar:/opt/dolphinscheduler/libs/kubernetes-model-certificates-5.10.2.jar:/opt/dolphinscheduler/libs/opencensus-api-0.31.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-mlflow-3.2.1.jar:/opt/dolphinscheduler/libs/kotlin-stdlib-jdk8-1.6.21.jar:/opt/dolphinscheduler/libs/dolphinscheduler-registry-jdbc-3.2.1.jar:/opt/dolphinscheduler/libs/audience-annotations-0.12.0.jar:/opt/dolphinscheduler/libs/simpleclient_httpserver-0.15.0.jar:/opt/dolphinscheduler/libs/jetty-xml-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/kerby-asn1-1.0.1.jar:/opt/dolphinscheduler/libs/lang-tag-1.6.jar:/opt/dolphinscheduler/libs/api-common-2.6.0.jar:/opt/dolphinscheduler/libs/HdrHistogram-2.1.12.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-abs-3.2.1.jar:/opt/dolphinscheduler/libs/failsafe-2.4.4.jar:/opt/dolphinscheduler/libs/hbase-noop-htrace-4.1.1.jar:/opt/dolphinscheduler/libs/jamon-runtime-2.3.1.jar:/opt/dolphinscheduler/libs/jetty-util-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/threetenbp-1.6.5.jar:/opt/dolphinscheduler/libs/jakarta.activation-api-1.2.2.jar:/opt/dolphinscheduler/libs/kubernetes-model-common-5.10.2.jar:/opt/dolphinscheduler/libs/okhttp-4.9.3.jar:/opt/dolphinscheduler/libs/profiles-2.17.282.jar:/opt/dolphinscheduler/libs/hadoop-auth-3.2.4.jar:/opt/dolphinscheduler/libs/grpc-netty-1.41.0.jar:/opt/dolphinscheduler/libs/httpcore-nio-4.4.15.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-seatunnel-3.2.1.jar:/opt/dolphinscheduler/libs/aws-java-sdk-sagemaker-1.12.300.jar:/opt/dolphinscheduler/libs/oshi-core-6.1.1.jar:/opt/dolphinscheduler/libs/bonecp-0.8.0.RELEASE.jar:/opt/dolphinscheduler/libs/jackson-module-parameter-names-2.13.3.jar:/opt/dolphinscheduler/libs/bcutil-jdk15on-1.69.jar:/opt/dolphinscheduler/libs/aws-json-protocol-2.17.282.jar:/opt/dolphinscheduler/libs/dolphinscheduler-extract-base-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-all-3.2.1.jar:/opt/dolphinscheduler/libs/derby-10.14.2.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-snowflake-3.2.1.jar:/opt/dolphinscheduler/libs/netty-codec-http2-4.1.53.Final.jar:/opt/dolphinscheduler/libs/jetty-continuation-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/jackson-mapper-asl-1.9.13.jar:/opt/dolphinscheduler/libs/datanucleus-core-4.1.17.jar:/opt/dolphinscheduler/libs/netty-tcnative-boringssl-static-2.0.53.Final-osx-aarch_64.jar:/opt/dolphinscheduler/libs/failureaccess-1.0.1.jar:/opt/dolphinscheduler/libs/error_prone_annotations-2.5.1.jar:/opt/dolphinscheduler/libs/kerb-admin-1.0.1.jar:/opt/dolphinscheduler/libs/token-provider-1.0.1.jar:/opt/dolphinscheduler/libs/reactor-netty-core-1.0.22.jar:/opt/dolphinscheduler/libs/dolphinscheduler-registry-all-3.2.1.jar:/opt/dolphinscheduler/libs/jakarta.servlet-api-4.0.4.jar:/opt/dolphinscheduler/libs/http-client-spi-2.17.282.jar:/opt/dolphinscheduler/libs/regions-2.17.282.jar:/opt/dolphinscheduler/libs/logback-core-1.2.11.jar:/opt/dolphinscheduler/libs/json-1.8.jar:/opt/dolphinscheduler/libs/gax-grpc-2.23.0.jar:/opt/dolphinscheduler/libs/google-http-client-1.42.3.jar:/opt/dolphinscheduler/libs/hive-serde-2.3.9.jar:/opt/dolphinscheduler/libs/jettison-1.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-http-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-registry-zookeeper-3.2.1.jar:/opt/dolphinscheduler/libs/spring-security-crypto-5.7.3.jar:/opt/dolphinscheduler/libs/auth-2.17.282.jar:/opt/dolphinscheduler/libs/proto-google-cloud-storage-v2-2.18.0-alpha.jar:/opt/dolphinscheduler/libs/jetty-server-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/javax.annotation-api-1.3.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-starrocks-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-dataquality-3.2.1.jar:/opt/dolphinscheduler/libs/jcl-over-slf4j-1.7.36.jar:/opt/dolphinscheduler/libs/commons-lang3-3.12.0.jar:/opt/dolphinscheduler/libs/tomcat-embed-el-9.0.65.jar:/opt/dolphinscheduler/libs/opentracing-noop-0.33.0.jar:/opt/dolphinscheduler/libs/client-java-13.0.2.jar:/opt/dolphinscheduler/libs/spring-beans-5.3.22.jar:/opt/dolphinscheduler/libs/snakeyaml-1.33.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-ssh-3.2.1.jar:/opt/dolphinscheduler/libs/commons-pool-1.6.jar:/opt/dolphinscheduler/libs/javax.servlet-api-3.1.0.jar:/opt/dolphinscheduler/libs/hadoop-common-3.2.4.jar:/opt/dolphinscheduler/libs/kubernetes-model-apiextensions-5.10.2.jar:/opt/dolphinscheduler/libs/spring-boot-2.7.3.jar:/opt/dolphinscheduler/libs/bcprov-ext-jdk15on-1.69.jar:/opt/dolphinscheduler/libs/spring-boot-starter-2.7.3.jar:/opt/dolphinscheduler/libs/paranamer-2.3.jar:/opt/dolphinscheduler/libs/httpmime-4.5.13.jar:/opt/dolphinscheduler/libs/reactor-core-3.4.22.jar:/opt/dolphinscheduler/libs/azure-core-1.36.0.jar:/opt/dolphinscheduler/libs/bcpkix-jdk15on-1.69.jar:/opt/dolphinscheduler/libs/kubernetes-model-scheduling-5.10.2.jar:/opt/dolphinscheduler/libs/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/dolphinscheduler/libs/websocket-client-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/unirest-java-3.7.04-standalone.jar:/opt/dolphinscheduler/libs/hadoop-mapreduce-client-core-3.2.4.jar:/opt/dolphinscheduler/libs/google-auth-library-credentials-1.15.0.jar:/opt/dolphinscheduler/libs/azure-storage-internal-avro-12.6.0.jar:/opt/dolphinscheduler/libs/jackson-datatype-jdk8-2.13.3.jar:/opt/dolphinscheduler/libs/spring-expression-5.3.22.jar:/opt/dolphinscheduler/libs/aspectjweaver-1.9.7.jar:/opt/dolphinscheduler/libs/websocket-common-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/client-java-api-fluent-13.0.2.jar:/opt/dolphinscheduler/libs/mybatis-plus-3.5.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-athena-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-oss-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-openmldb-3.2.1.jar:/opt/dolphinscheduler/libs/curator-recipes-5.3.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-api-3.2.1.jar:/opt/dolphinscheduler/libs/netty-all-4.1.53.Final.jar:/opt/dolphinscheduler/libs/netty-resolver-dns-4.1.53.Final.jar:/opt/dolphinscheduler/libs/kubernetes-model-autoscaling-5.10.2.jar:/opt/dolphinscheduler/libs/kerb-util-1.0.1.jar:/opt/dolphinscheduler/libs/grpc-alts-1.41.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-presto-3.2.1.jar:/opt/dolphinscheduler/libs/kerb-simplekdc-1.0.1.jar:/opt/dolphinscheduler/libs/protobuf-java-util-3.17.2.jar:/opt/dolphinscheduler/libs/azure-core-http-netty-1.13.0.jar:/opt/dolphinscheduler/libs/transaction-api-1.1.jar:/opt/dolphinscheduler/libs/datanucleus-api-jdo-4.2.4.jar:/opt/dolphinscheduler/libs/zeppelin-common-0.10.1.jar:/opt/dolphinscheduler/libs/zt-zip-1.15.jar:/opt/dolphinscheduler/libs/animal-sniffer-annotations-1.19.jar:/opt/dolphinscheduler/libs/google-http-client-jackson2-1.42.3.jar:/opt/dolphinscheduler/libs/netty-buffer-4.1.53.Final.jar:/opt/dolphinscheduler/libs/jsr305-3.0.0.jar:/opt/dolphinscheduler/libs/netty-transport-classes-epoll-4.1.79.Final.jar:/opt/dolphinscheduler/libs/spring-boot-actuator-autoconfigure-2.7.3.jar:/opt/dolphinscheduler/libs/simpleclient-0.15.0.jar:/opt/dolphinscheduler/libs/aliyun-sdk-oss-3.15.1.jar:/opt/dolphinscheduler/libs/json-utils-2.17.282.jar:/opt/dolphinscheduler/libs/tephra-api-0.6.0.jar:/opt/dolphinscheduler/libs/spring-jdbc-5.3.22.jar:/opt/dolphinscheduler/libs/grpc-xds-1.41.0.jar:/opt/dolphinscheduler/libs/logback-classic-1.2.11.jar:/opt/dolphinscheduler/libs/google-cloud-storage-2.18.0.jar:/opt/dolphinscheduler/libs/micrometer-registry-prometheus-1.9.3.jar:/opt/dolphinscheduler/libs/grpc-core-1.41.0.jar:/opt/dolphinscheduler/libs/aws-java-sdk-kms-1.12.300.jar:/opt/dolphinscheduler/libs/kubernetes-model-rbac-5.10.2.jar:/opt/dolphinscheduler/libs/ini4j-0.5.4.jar:/opt/dolphinscheduler/libs/spring-boot-starter-web-2.7.3.jar:/opt/dolphinscheduler/libs/spring-cloud-commons-3.1.3.jar:/opt/dolphinscheduler/libs/netty-codec-http-4.1.53.Final.jar:/opt/dolphinscheduler/libs/jetty-client-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/jetcd-common-0.5.11.jar:/opt/dolphinscheduler/libs/metrics-spi-2.17.282.jar:/opt/dolphinscheduler/libs/utils-2.17.282.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-emr-3.2.1.jar:/opt/dolphinscheduler/libs/protocol-core-2.17.282.jar:/opt/dolphinscheduler/libs/micrometer-core-1.9.3.jar:/opt/dolphinscheduler/libs/netty-transport-native-unix-common-4.1.53.Final.jar:/opt/dolphinscheduler/libs/zjsonpatch-0.4.11.jar:/opt/dolphinscheduler/libs/annotations-2.17.282.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-sql-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-extract-common-3.2.1.jar:/opt/dolphinscheduler/libs/apache-client-2.17.282.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-oceanbase-3.2.1.jar:/opt/dolphinscheduler/libs/jdo-api-3.0.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-datax-3.2.1.jar:/opt/dolphinscheduler/libs/postgresql-42.4.1.jar:/opt/dolphinscheduler/libs/jetty-util-ajax-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/gax-2.23.0.jar:/opt/dolphinscheduler/libs/grpc-stub-1.41.0.jar:/opt/dolphinscheduler/libs/libfb303-0.9.3.jar:/opt/dolphinscheduler/libs/spring-core-5.3.22.jar:/opt/dolphinscheduler/libs/jaxb-api-2.3.1.jar:/opt/dolphinscheduler/libs/hive-service-rpc-2.3.9.jar:/opt/dolphinscheduler/libs/kubernetes-model-flowcontrol-5.10.2.jar:/opt/dolphinscheduler/libs/commons-logging-1.1.1.jar:/opt/dolphinscheduler/libs/mybatis-spring-2.0.7.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-oracle-3.2.1.jar:/opt/dolphinscheduler/libs/opencensus-proto-0.2.0.jar:/opt/dolphinscheduler/libs/grpc-protobuf-1.41.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-clickhouse-3.2.1.jar:/opt/dolphinscheduler/libs/spring-cloud-starter-bootstrap-3.1.3.jar:/opt/dolphinscheduler/libs/kubernetes-model-admissionregistration-5.10.2.jar:/opt/dolphinscheduler/libs/grpc-google-cloud-storage-v2-2.18.0-alpha.jar:/opt/dolphinscheduler/libs/esdk-obs-java-bundle-3.23.3.jar:/opt/dolphinscheduler/libs/dnsjava-2.1.7.jar:/opt/dolphinscheduler/libs/asm-9.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-spark-3.2.1.jar:/opt/dolphinscheduler/libs/netty-tcnative-boringssl-static-2.0.53.Final-linux-aarch_64.jar:/opt/dolphinscheduler/libs/re2j-1.6.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-vertica-3.2.1.jar:/opt/dolphinscheduler/libs/json-smart-2.4.8.jar:/opt/dolphinscheduler/libs/reactor-netty-http-1.0.22.jar:/opt/dolphinscheduler/libs/google-api-services-storage-v1-rev20220705-2.0.0.jar:/opt/dolphinscheduler/libs/kubernetes-client-6.0.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-kyuubi-3.2.1.jar:/opt/dolphinscheduler/libs/auto-value-annotations-1.10.1.jar:/opt/dolphinscheduler/libs/commons-cli-1.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-data-quality-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-chunjun-3.2.1.jar:/opt/dolphinscheduler/libs/kerb-server-1.0.1.jar:/opt/dolphinscheduler/libs/content-type-2.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-remoteshell-3.2.1.jar:/opt/dolphinscheduler/libs/opencensus-contrib-http-util-0.31.1.jar:/opt/dolphinscheduler/libs/druid-1.2.20.jar:/opt/dolphinscheduler/libs/javolution-5.5.1.jar:/opt/dolphinscheduler/libs/protobuf-java-3.17.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-db2-3.2.1.jar:/opt/dolphinscheduler/libs/aws-java-sdk-core-1.12.300.jar:/opt/dolphinscheduler/libs/spring-boot-starter-logging-2.7.3.jar:/opt/dolphinscheduler/libs/kerby-pkix-1.0.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-procedure-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-registry-etcd-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-sqoop-3.2.1.jar:/opt/dolphinscheduler/libs/zookeeper-jute-3.8.0.jar:/opt/dolphinscheduler/libs/netty-resolver-dns-native-macos-4.1.53.Final-osx-x86_64.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-sagemaker-3.2.1.jar:/opt/dolphinscheduler/libs/spring-boot-configuration-processor-2.6.1.jar:/opt/dolphinscheduler/libs/hive-common-2.3.9.jar:/opt/dolphinscheduler/libs/kerb-common-1.0.1.jar:/opt/dolphinscheduler/libs/stax-api-1.0.1.jar:/opt/dolphinscheduler/libs/kubernetes-model-storageclass-5.10.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-s3-3.2.1.jar:/opt/dolphinscheduler/libs/spring-boot-starter-jetty-2.7.3.jar:/opt/dolphinscheduler/libs/okio-2.8.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-dms-3.2.1.jar:/opt/dolphinscheduler/libs/simpleclient_common-0.15.0.jar:/opt/dolphinscheduler/libs/sdk-core-2.17.282.jar:/opt/dolphinscheduler/libs/javax.activation-api-1.2.0.jar:/opt/dolphinscheduler/libs/netty-handler-proxy-4.1.53.Final.jar:/opt/dolphinscheduler/libs/kerby-config-1.0.1.jar:/opt/dolphinscheduler/libs/netty-tcnative-classes-2.0.53.Final.jar:/opt/dolphinscheduler/libs/jackson-jaxrs-base-2.13.3.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-trino-3.2.1.jar:/opt/dolphinscheduler/libs/presto-jdbc-0.238.1.jar:/opt/dolphinscheduler/libs/websocket-api-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-flink-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-api-3.2.1.jar:/opt/dolphinscheduler/libs/kubernetes-model-metrics-5.10.2.jar:/opt/dolphinscheduler/libs/datasync-2.17.282.jar:/opt/dolphinscheduler/libs/hadoop-yarn-api-3.2.4.jar:/opt/dolphinscheduler/libs/google-http-client-apache-v2-1.42.3.jar:/opt/dolphinscheduler/libs/hadoop-annotations-3.2.4.jar:/opt/dolphinscheduler/libs/google-oauth-client-1.34.1.jar:/opt/dolphinscheduler/libs/sshd-common-2.8.0.jar:/opt/dolphinscheduler/libs/LatencyUtils-2.0.3.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-spark-3.2.1.jar:/opt/dolphinscheduler/libs/slf4j-api-1.7.36.jar:/opt/dolphinscheduler/libs/snowflake-jdbc-3.13.29.jar:/opt/dolphinscheduler/libs/jackson-datatype-jsr310-2.13.3.jar:/opt/dolphinscheduler/libs/trino-jdbc-402.jar:/opt/dolphinscheduler/libs/logging-interceptor-4.9.3.jar:/opt/dolphinscheduler/libs/simpleclient_tracer_otel_agent-0.15.0.jar:/opt/dolphinscheduler/libs/janino-3.0.16.jar:/opt/dolphinscheduler/libs/jackson-dataformat-yaml-2.13.3.jar:/opt/dolphinscheduler/libs/ion-java-1.0.2.jar:/opt/dolphinscheduler/libs/commons-dbcp-1.4.jar:/opt/dolphinscheduler/libs/jsp-api-2.1.jar:/opt/dolphinscheduler/libs/google-http-client-gson-1.42.3.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-hivecli-3.2.1.jar:/opt/dolphinscheduler/libs/spring-boot-actuator-2.7.3.jar:/opt/dolphinscheduler/libs/google-cloud-core-http-2.10.0.jar:/opt/dolphinscheduler/libs/DmJdbcDriver18-8.1.2.79.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-java-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-dameng-3.2.1.jar:/opt/dolphinscheduler/libs/sshd-sftp-2.8.0.jar:/opt/dolphinscheduler/libs/kerb-crypto-1.0.1.jar:/opt/dolphinscheduler/libs/conscrypt-openjdk-uber-2.5.2.jar:/opt/dolphinscheduler/libs/httpcore-4.4.15.jar:/opt/dolphinscheduler/libs/lz4-java-1.4.0.jar:/opt/dolphinscheduler/libs/guava-retrying-2.0.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-flink-stream-3.2.1.jar:/opt/dolphinscheduler/libs/spring-tx-5.3.22.jar:/opt/dolphinscheduler/libs/grpc-auth-1.41.0.jar:/opt/dolphinscheduler/libs/netty-tcnative-boringssl-static-2.0.53.Final-osx-x86_64.jar:/opt/dolphinscheduler/libs/databend-jdbc-0.0.7.jar:/opt/dolphinscheduler/libs/bcprov-jdk15on-1.69.jar:/opt/dolphinscheduler/libs/commons-lang-2.6.jar:/opt/dolphinscheduler/libs/kubernetes-model-policy-5.10.2.jar:/opt/dolphinscheduler/libs/commons-io-2.11.0.jar:/opt/dolphinscheduler/libs/grpc-grpclb-1.41.0.jar:/opt/dolphinscheduler/libs/netty-tcnative-boringssl-static-2.0.53.Final-linux-x86_64.jar:/opt/dolphinscheduler/libs/opentracing-api-0.33.0.jar:/opt/dolphinscheduler/libs/sshd-scp-2.8.0.jar:/opt/dolphinscheduler/libs/reload4j-1.2.18.3.jar:/opt/dolphinscheduler/libs/netty-tcnative-2.0.48.Final.jar:/opt/dolphinscheduler/libs/jdom2-2.0.6.1.jar:/opt/dolphinscheduler/libs/spring-boot-starter-json-2.7.3.jar:/opt/dolphinscheduler/libs/netty-transport-native-epoll-4.1.53.Final.jar:/opt/dolphinscheduler/libs/google-cloud-core-2.10.0.jar:/opt/dolphinscheduler/libs/javax.jdo-3.2.0-m3.jar:/opt/dolphinscheduler/libs/gax-httpjson-0.108.0.jar:/opt/dolphinscheduler/libs/mybatis-plus-core-3.5.2.jar:/opt/dolphinscheduler/libs/auto-service-annotations-1.0.1.jar:/opt/dolphinscheduler/libs/nimbus-jose-jwt-9.22.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-zeppelin-3.2.1.jar:/opt/dolphinscheduler/libs/commons-compress-1.21.jar:/opt/dolphinscheduler/libs/hadoop-hdfs-client-3.2.4.jar:/opt/dolphinscheduler/libs/msal4j-persistence-extension-1.1.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-pytorch-3.2.1.jar:/opt/dolphinscheduler/libs/netty-tcnative-boringssl-static-2.0.53.Final-windows-x86_64.jar:/opt/dolphinscheduler/libs/jetty-servlets-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/woodstox-core-6.4.0.jar:/opt/dolphinscheduler/libs/spring-cloud-kubernetes-commons-2.1.3.jar:/opt/dolphinscheduler/libs/grpc-protobuf-lite-1.41.0.jar:/opt/dolphinscheduler/libs/jetty-webapp-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/eventstream-1.0.1.jar:/opt/dolphinscheduler/libs/commons-compiler-3.1.7.jar:/opt/dolphinscheduler/libs/netty-transport-4.1.53.Final.jar:/opt/dolphinscheduler/libs/spring-cloud-context-3.1.3.jar:/opt/dolphinscheduler/libs/aws-java-sdk-dms-1.12.300.jar:/opt/dolphinscheduler/libs/hive-storage-api-2.4.0.jar:/opt/dolphinscheduler/libs/client-java-spring-integration-13.0.2.jar:/opt/dolphinscheduler/libs/spring-boot-starter-actuator-2.7.3.jar:/opt/dolphinscheduler/libs/third-party-jackson-core-2.17.282.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-hdfs-3.2.1.jar:/opt/dolphinscheduler/libs/netty-codec-4.1.53.Final.jar:/opt/dolphinscheduler/libs/google-http-client-appengine-1.42.3.jar:/opt/dolphinscheduler/libs/commons-configuration2-2.1.1.jar:/opt/dolphinscheduler/libs/datanucleus-rdbms-4.1.19.jar:/opt/dolphinscheduler/libs/swagger-annotations-1.6.2.jar:/opt/dolphinscheduler/libs/simpleclient_tracer_otel-0.15.0.jar:/opt/dolphinscheduler/libs/kotlin-stdlib-common-1.6.21.jar:/opt/dolphinscheduler/libs/aws-core-2.17.282.jar:/opt/dolphinscheduler/libs/kerb-core-1.0.1.jar:/opt/dolphinscheduler/libs/httpasyncclient-4.1.5.jar:/opt/dolphinscheduler/libs/dolphinscheduler-extract-worker-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-spi-3.2.1.jar:/opt/dolphinscheduler/libs/okhttp-2.7.5.jar:/opt/dolphinscheduler/libs/google-api-client-2.2.0.jar:/opt/dolphinscheduler/libs/kotlin-stdlib-1.6.21.jar:/opt/dolphinscheduler/libs/jakarta.websocket-api-1.1.2.jar:/opt/dolphinscheduler/libs/libthrift-0.9.3.jar:/opt/dolphinscheduler/libs/spring-boot-starter-aop-2.7.3.jar:/opt/dolphinscheduler/libs/netty-common-4.1.53.Final.jar:/opt/dolphinscheduler/libs/log4j-1.2-api-2.17.2.jar:/opt/dolphinscheduler/libs/jackson-databind-2.13.4.jar:/opt/dolphinscheduler/libs/jackson-dataformat-xml-2.13.3.jar:/opt/dolphinscheduler/libs/kubernetes-model-events-5.10.2.jar:/opt/dolphinscheduler/libs/gson-2.9.1.jar:/opt/dolphinscheduler/libs/proto-google-iam-v1-1.9.0.jar:/opt/dolphinscheduler/libs/netty-codec-socks-4.1.53.Final.jar:/opt/dolphinscheduler/libs/zjsonpatch-0.3.0.jar:/opt/dolphinscheduler/libs/hadoop-mapreduce-client-common-3.2.4.jar:/opt/dolphinscheduler/libs/dolphinscheduler-registry-api-3.2.1.jar:/opt/dolphinscheduler/libs/azure-storage-blob-12.21.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-zeppelin-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-api-3.2.1.jar:/opt/dolphinscheduler/libs/aws-java-sdk-s3-1.12.300.jar:/opt/dolphinscheduler/libs/stax2-api-4.2.1.jar:/opt/dolphinscheduler/libs/jakarta.annotation-api-1.3.5.jar:/opt/dolphinscheduler/libs/kubernetes-model-discovery-5.10.2.jar:/opt/dolphinscheduler/libs/jna-5.10.0.jar:/opt/dolphinscheduler/libs/spring-jcl-5.3.22.jar
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:49.118 +0800 o.a.z.ZooKeeper:[98] - Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:49.119 +0800 o.a.z.ZooKeeper:[98] - Client environment:java.io.tmpdir=/tmp
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:49.119 +0800 o.a.z.ZooKeeper:[98] - Client environment:java.compiler=<NA>
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:49.119 +0800 o.a.z.ZooKeeper:[98] - Client environment:os.name=Linux
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:49.119 +0800 o.a.z.ZooKeeper:[98] - Client environment:os.arch=amd64
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:49.119 +0800 o.a.z.ZooKeeper:[98] - Client environment:os.version=6.5.0-28-generic
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:49.120 +0800 o.a.z.ZooKeeper:[98] - Client environment:user.name=root
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:49.120 +0800 o.a.z.ZooKeeper:[98] - Client environment:user.home=/root
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:49.120 +0800 o.a.z.ZooKeeper:[98] - Client environment:user.dir=/opt/dolphinscheduler
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:49.120 +0800 o.a.z.ZooKeeper:[98] - Client environment:os.memory.free=3198MB
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:49.120 +0800 o.a.z.ZooKeeper:[98] - Client environment:os.memory.max=3840MB
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:49.121 +0800 o.a.z.ZooKeeper:[98] - Client environment:os.memory.total=3840MB
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:49.123 +0800 o.a.z.ZooKeeper:[637] - Initiating client connection, connectString=dolphinscheduler-zookeeper:2181 sessionTimeout=30000 watcher=org.apache.curator.ConnectionState@1de08775
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:49.133 +0800 o.a.z.c.X509Util:[77] - Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:49.137 +0800 o.a.z.ClientCnxnSocket:[239] - jute.maxbuffer value is 1048575 Bytes
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:49.208 +0800 o.a.z.ClientCnxn:[1732] - zookeeper.request.timeout value is 0. feature enabled=false
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:49.287 +0800 o.a.c.f.i.CuratorFrameworkImpl:[386] - Default schema
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:49.349 +0800 o.a.z.ClientCnxn:[1171] - Opening socket connection to server dolphinscheduler-zookeeper/172.18.0.5:2181.
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:49.404 +0800 o.a.z.ClientCnxn:[1173] - SASL config status: Will not attempt to authenticate using SASL (unknown error)
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:49.457 +0800 o.a.z.ClientCnxn:[1005] - Socket connection established, initiating session, client: /172.18.1.1:45662, server: dolphinscheduler-zookeeper/172.18.0.5:2181
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:49.487 +0800 o.a.z.ClientCnxn:[1444] - Session establishment complete on server dolphinscheduler-zookeeper/172.18.0.5:2181, session id = 0x100007d5bdb0000, negotiated timeout = 30000
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:49.494 +0800 o.a.c.f.s.ConnectionStateManager:[252] - State change: CONNECTED
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:49.591 +0800 o.a.c.f.i.EnsembleTracker:[201] - New config event received: {}
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:49.592 +0800 o.a.c.f.i.EnsembleTracker:[201] - New config event received: {}
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:50.400 +0800 o.a.d.s.w.r.WorkerRpcServer:[41] - WorkerRpcServer starting...
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:51.286 +0800 o.a.d.e.b.NettyRemotingServer:[112] - WorkerRpcServer bind success at port: 1234
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:51.294 +0800 o.a.d.s.w.r.WorkerRpcServer:[43] - WorkerRpcServer started...
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:51.818 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: JAVA - JavaTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:52.074 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: JAVA - JavaTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:52.074 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: JUPYTER - JupyterTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:52.100 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: JUPYTER - JupyterTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:52.101 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: SPARK - SparkTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:52.103 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: SPARK - SparkTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:52.103 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: FLINK_STREAM - FlinkStreamTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:52.106 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: FLINK_STREAM - FlinkStreamTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:52.106 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: PYTHON - PythonTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:52.107 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: PYTHON - PythonTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:52.107 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: DATASYNC - DatasyncTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:52.108 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: DATASYNC - DatasyncTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:52.108 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: DATA_FACTORY - DatafactoryTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:52.109 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: DATA_FACTORY - DatafactoryTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:52.109 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: CHUNJUN - ChunJunTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:52.329 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: CHUNJUN - ChunJunTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:52.330 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: REMOTESHELL - RemoteShellTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:52.369 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: REMOTESHELL - RemoteShellTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:52.377 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: PIGEON - PigeonTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:52.382 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: PIGEON - PigeonTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:52.383 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: SHELL - ShellTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:52.390 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: SHELL - ShellTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:52.392 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: PROCEDURE - ProcedureTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:52.414 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: PROCEDURE - ProcedureTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:52.423 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: MR - MapReduceTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:52.425 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: MR - MapReduceTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:52.426 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: SQOOP - SqoopTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:52.427 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: SQOOP - SqoopTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:52.428 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: PYTORCH - PytorchTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:52.470 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: PYTORCH - PytorchTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:52.470 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: K8S - K8sTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:52.578 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: K8S - K8sTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:52.658 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: SEATUNNEL - SeatunnelTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:52.680 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: SEATUNNEL - SeatunnelTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:52.680 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: SAGEMAKER - SagemakerTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:52.731 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: SAGEMAKER - SagemakerTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:52.731 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: HTTP - HttpTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:52.739 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: HTTP - HttpTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:52.739 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: EMR - EmrTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:52.753 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: EMR - EmrTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:52.754 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: DMS - DmsTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:52.795 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: DMS - DmsTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:52.796 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: DATA_QUALITY - DataQualityTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:52.799 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: DATA_QUALITY - DataQualityTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:52.800 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: KUBEFLOW - KubeflowTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:52.810 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: KUBEFLOW - KubeflowTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:52.812 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: SQL - SqlTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:52.817 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: SQL - SqlTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:52.819 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: DVC - DvcTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:52.821 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: DVC - DvcTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:52.823 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: DATAX - DataxTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:52.826 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: DATAX - DataxTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:52.837 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: ZEPPELIN - ZeppelinTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:52.840 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: ZEPPELIN - ZeppelinTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:52.841 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: DINKY - DinkyTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:52.846 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: DINKY - DinkyTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:52.846 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: MLFLOW - MlflowTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:52.849 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: MLFLOW - MlflowTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:52.849 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: OPENMLDB - OpenmldbTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:52.855 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: OPENMLDB - OpenmldbTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:52.856 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: LINKIS - LinkisTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:52.871 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: LINKIS - LinkisTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:52.884 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: FLINK - FlinkTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:52.886 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: FLINK - FlinkTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:52.889 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: HIVECLI - HiveCliTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:52.894 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: HIVECLI - HiveCliTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:53.022 +0800 o.a.d.c.u.JSONUtils:[72] - init timezone: sun.util.calendar.ZoneInfo[id="Asia/Shanghai",offset=28800000,dstSavings=0,useDaylight=false,transitions=31,lastRule=null]
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:53.248 +0800 o.a.d.s.w.r.WorkerRegistryClient:[104] - Worker node: 172.18.1.1:1234 registry to ZK /nodes/worker/172.18.1.1:1234 successfully
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:54.269 +0800 o.a.d.c.m.BaseHeartBeatTask:[48] - Starting WorkerHeartBeatTask...
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:54.287 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.0424242424242425 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:54.278 +0800 o.a.d.c.m.BaseHeartBeatTask:[50] - Started WorkerHeartBeatTask, heartBeatInterval: 10000...
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:54.342 +0800 o.a.d.s.w.r.WorkerRegistryClient:[114] - Worker node: 172.18.1.1:1234 registry finished
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:54.354 +0800 o.a.d.s.w.m.MessageRetryRunner:[69] - Message retry runner staring
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:54.450 +0800 o.a.d.s.w.m.MessageRetryRunner:[72] - Injected message sender: TaskInstanceExecutionFinishEventSender
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:54.451 +0800 o.a.d.s.w.m.MessageRetryRunner:[72] - Injected message sender: TaskInstanceExecutionInfoUpdateEventSender
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:54.451 +0800 o.a.d.s.w.m.MessageRetryRunner:[72] - Injected message sender: TaskInstanceExecutionRunningEventSender
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:54.488 +0800 o.a.d.s.w.m.MessageRetryRunner:[75] - Message retry runner started
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:55.353 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.275 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:56.361 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.2647058823529411 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:57.677 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.4425287356321839 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:58.823 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.2350230414746544 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:01:59.925 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.349462365591398 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:02:01.068 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.1681818181818182 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:02:02.241 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.3970588235294117 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:02:04.175 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.09375 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:02:05.181 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.2864321608040203 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:02:06.238 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.4975369458128078 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:02:07.448 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.2625482625482625 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:02:08.513 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 2.0 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:02:09.790 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.988888888888889 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:02:10.843 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.9291338582677164 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:02:11.857 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.9913793103448276 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:02:13.152 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.3725490196078431 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:02:13.274 +0800 o.s.b.a.e.w.EndpointLinksResolver:[58] - Exposing 3 endpoint(s) beneath base path '/actuator'
[WI-0][TI-0] - [INFO] 2024-05-07 10:02:13.800 +0800 o.e.j.s.h.C.application:[2368] - Initializing Spring DispatcherServlet 'dispatcherServlet'
[WI-0][TI-0] - [INFO] 2024-05-07 10:02:13.806 +0800 o.s.w.s.DispatcherServlet:[525] - Initializing Servlet 'dispatcherServlet'
[WI-0][TI-0] - [INFO] 2024-05-07 10:02:13.827 +0800 o.s.w.s.DispatcherServlet:[547] - Completed initialization in 20 ms
[WI-0][TI-0] - [INFO] 2024-05-07 10:02:14.143 +0800 o.e.j.s.AbstractConnector:[333] - Started ServerConnector@1f45db49{HTTP/1.1, (http/1.1)}{0.0.0.0:1235}
[WI-0][TI-0] - [INFO] 2024-05-07 10:02:14.145 +0800 o.s.b.w.e.j.JettyWebServer:[172] - Jetty started on port(s) 1235 (http/1.1) with context path '/'
[WI-0][TI-0] - [INFO] 2024-05-07 10:02:14.244 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.9508196721311477 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:02:14.352 +0800 o.a.d.s.w.WorkerServer:[61] - Started WorkerServer in 65.128 seconds (JVM running for 69.439)
[WI-0][TI-0] - [INFO] 2024-05-07 10:02:15.246 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.0042194092827004 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:02:16.297 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8976109215017065 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:02:17.306 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8072916666666667 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:02:18.310 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.88212927756654 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:02:20.467 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.013157894736842 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:02:21.531 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.0142857142857142 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:02:22.550 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9330357142857142 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:02:23.585 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9519650655021834 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:02:24.698 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8986486486486487 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:02:25.704 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7486910994764397 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:02:26.807 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8135593220338984 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:02:30.863 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8130081300813009 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-3952] - [INFO] 2024-05-07 10:02:33.445 +0800 o.a.d.s.w.r.o.UpdateWorkflowHostOperationFunction:[49] - Received UpdateWorkflowHostRequest: UpdateWorkflowHostRequest(taskInstanceId=3952, workflowHost=172.18.0.11:5678)
[WI-0][TI-0] - [INFO] 2024-05-07 10:02:33.629 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=3953, taskName=[null check] filtered data persistence, firstSubmitTime=1715047353503, startTime=0, taskType=DATA_QUALITY, workflowInstanceHost=172.18.0.11:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13505298546272, processDefineVersion=21, appIds=null, processInstanceId=1059, scheduleTime=0, globalParams=null, executorId=1, cmdTypeIfComplement=2, tenantCode=default, processDefineId=0, projectId=0, projectCode=13001194483488, taskParams={"localParams":[],"resourceList":[],"ruleId":6,"ruleInputParameter":{"check_type":"0","comparison_type":1,"comparison_name":"0","failure_strategy":"0","operator":"0","src_connector_type":1,"src_datasource_id":6,"src_database":"persistence","src_field":"content","src_table":"filtered_data_persistence","threshold":"0"},"sparkParameters":{"deployMode":"local","driverCores":1,"driverMemory":"512M","executorCores":1,"executorMemory":"1G","numExecutors":1,"others":"--conf spark.driver.extraJavaOptions=\"-Divy.cache.dir=/tmp -Divy.home=/tmp\" \\\n--packages org.postgresql:postgresql:42.7.3","yarnQueue":""}}, environmentConfig=export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export PYSPARK_DRIVER_PYTHON=/bin/python3.11
export PYSPARK_PYTHON=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='[null check] filtered data persistence'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13001194483488'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='1059'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240507'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240506'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='3953'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='qualti_test'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13505264408800'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13505298546272'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240507100233'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=null, dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=org.apache.dolphinscheduler.plugin.task.api.DataQualityTaskExecutionContext@72647f74, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-1059][TI-3953] - [INFO] 2024-05-07 10:02:33.673 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: [null check] filtered data persistence to wait queue success
[WI-1059][TI-3953] - [INFO] 2024-05-07 10:02:33.675 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-1059][TI-3953] - [INFO] 2024-05-07 10:02:33.679 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-1059][TI-3953] - [INFO] 2024-05-07 10:02:33.680 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-1059][TI-3953] - [INFO] 2024-05-07 10:02:33.681 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-1059][TI-3953] - [INFO] 2024-05-07 10:02:33.681 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1715047353681
[WI-1059][TI-3953] - [INFO] 2024-05-07 10:02:33.681 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 1059_3953
[WI-1059][TI-3953] - [INFO] 2024-05-07 10:02:33.698 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 3953,
  "taskName" : "[null check] filtered data persistence",
  "firstSubmitTime" : 1715047353503,
  "startTime" : 1715047353681,
  "taskType" : "DATA_QUALITY",
  "workflowInstanceHost" : "172.18.0.11:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240507/13505298546272/21/1059/3953.log",
  "processId" : 0,
  "processDefineCode" : 13505298546272,
  "processDefineVersion" : 21,
  "processInstanceId" : 1059,
  "scheduleTime" : 0,
  "executorId" : 1,
  "cmdTypeIfComplement" : 2,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13001194483488,
  "taskParams" : "{\"localParams\":[],\"resourceList\":[],\"ruleId\":6,\"ruleInputParameter\":{\"check_type\":\"0\",\"comparison_type\":1,\"comparison_name\":\"0\",\"failure_strategy\":\"0\",\"operator\":\"0\",\"src_connector_type\":1,\"src_datasource_id\":6,\"src_database\":\"persistence\",\"src_field\":\"content\",\"src_table\":\"filtered_data_persistence\",\"threshold\":\"0\"},\"sparkParameters\":{\"deployMode\":\"local\",\"driverCores\":1,\"driverMemory\":\"512M\",\"executorCores\":1,\"executorMemory\":\"1G\",\"numExecutors\":1,\"others\":\"--conf spark.driver.extraJavaOptions=\\\"-Divy.cache.dir=/tmp -Divy.home=/tmp\\\" \\\\\\n--packages org.postgresql:postgresql:42.7.3\",\"yarnQueue\":\"\"}}",
  "environmentConfig" : "export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3\nexport JAVA_HOME=/opt/java/openjdk\nexport PYSPARK_DRIVER_PYTHON=/bin/python3.11\nexport PYSPARK_PYTHON=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "[null check] filtered data persistence"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13001194483488"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1059"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240507"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240506"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "3953"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "qualti_test"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13505264408800"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13505298546272"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240507100233"
    }
  },
  "taskAppId" : "1059_3953",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "dryRun" : 0,
  "paramsMap" : { },
  "dataQualityTaskExecutionContext" : {
    "ruleId" : 6,
    "ruleName" : "$t(uniqueness_check)",
    "ruleType" : 0,
    "ruleInputEntryList" : "[{\"id\":1,\"field\":\"src_connector_type\",\"type\":\"select\",\"title\":\"$t(src_connector_type)\",\"data\":\"\",\"options\":\"[{\\\"label\\\":\\\"HIVE\\\",\\\"value\\\":\\\"HIVE\\\"},{\\\"label\\\":\\\"JDBC\\\",\\\"value\\\":\\\"JDBC\\\"}]\",\"placeholder\":\"please select source connector type\",\"optionSourceType\":2,\"dataType\":2,\"inputType\":0,\"isShow\":true,\"canEdit\":true,\"isEmit\":true,\"isValidate\":false,\"valuesMap\":null,\"index\":1,\"createTime\":null,\"updateTime\":null},{\"id\":2,\"field\":\"src_datasource_id\",\"type\":\"select\",\"title\":\"$t(src_datasource_id)\",\"data\":\"\",\"options\":null,\"placeholder\":\"please select source datasource id\",\"optionSourceType\":1,\"dataType\":2,\"inputType\":0,\"isShow\":true,\"canEdit\":true,\"isEmit\":true,\"isValidate\":false,\"valuesMap\":null,\"index\":2,\"createTime\":null,\"updateTime\":null},{\"id\":30,\"field\":\"src_database\",\"type\":\"select\",\"title\":\"$t(src_database)\",\"data\":null,\"options\":null,\"placeholder\":\"Please select source database\",\"optionSourceType\":0,\"dataType\":0,\"inputType\":0,\"isShow\":true,\"canEdit\":true,\"isEmit\":true,\"isValidate\":true,\"valuesMap\":null,\"index\":2,\"createTime\":null,\"updateTime\":null},{\"id\":3,\"field\":\"src_table\",\"type\":\"select\",\"title\":\"$t(src_table)\",\"data\":null,\"options\":null,\"placeholder\":\"Please enter source table name\",\"optionSourceType\":0,\"dataType\":0,\"inputType\":0,\"isShow\":true,\"canEdit\":true,\"isEmit\":true,\"isValidate\":true,\"valuesMap\":null,\"index\":3,\"createTime\":null,\"updateTime\":null},{\"id\":4,\"field\":\"src_filter\",\"type\":\"input\",\"title\":\"$t(src_filter)\",\"data\":null,\"options\":null,\"placeholder\":\"Please enter filter expression\",\"optionSourceType\":0,\"dataType\":3,\"inputType\":0,\"isShow\":true,\"canEdit\":true,\"isEmit\":false,\"isValidate\":false,\"valuesMap\":null,\"index\":4,\"createTime\":null,\"updateTime\":null},{\"id\":5,\"field\":\"src_field\",\"type\":\"select\",\"title\":\"$t(src_field)\",\"data\":null,\"options\":null,\"placeholder\":\"Please enter column, only single column is supported\",\"optionSourceType\":0,\"dataType\":0,\"inputType\":0,\"isShow\":true,\"canEdit\":true,\"isEmit\":false,\"isValidate\":true,\"valuesMap\":null,\"index\":5,\"createTime\":null,\"updateTime\":null},{\"id\":6,\"field\":\"statistics_name\",\"type\":\"input\",\"title\":\"$t(statistics_name)\",\"data\":\"duplicate_count.duplicates\",\"options\":null,\"placeholder\":\"Please enter statistics name, the alias in statistics execute sql\",\"optionSourceType\":0,\"dataType\":0,\"inputType\":1,\"isShow\":false,\"canEdit\":false,\"isEmit\":false,\"isValidate\":true,\"valuesMap\":\"{\\\"statistics_name\\\":\\\"duplicate_count.duplicates\\\"}\",\"index\":6,\"createTime\":null,\"updateTime\":null},{\"id\":7,\"field\":\"check_type\",\"type\":\"select\",\"title\":\"$t(check_type)\",\"data\":\"0\",\"options\":\"[{\\\"label\\\":\\\"Expected - Actual\\\",\\\"value\\\":\\\"0\\\"},{\\\"label\\\":\\\"Actual - Expected\\\",\\\"value\\\":\\\"1\\\"},{\\\"label\\\":\\\"Actual / Expected\\\",\\\"value\\\":\\\"2\\\"},{\\\"label\\\":\\\"(Expected - Actual) / Expected\\\",\\\"value\\\":\\\"3\\\"}]\",\"placeholder\":\"please select check type\",\"optionSourceType\":0,\"dataType\":0,\"inputType\":3,\"isShow\":true,\"canEdit\":true,\"isEmit\":true,\"isValidate\":false,\"valuesMap\":null,\"index\":7,\"createTime\":null,\"updateTime\":null},{\"id\":8,\"field\":\"operator\",\"type\":\"select\",\"title\":\"$t(operator)\",\"data\":\"0\",\"options\":\"[{\\\"label\\\":\\\"=\\\",\\\"value\\\":\\\"0\\\"},{\\\"label\\\":\\\"<\\\",\\\"value\\\":\\\"1\\\"},{\\\"label\\\":\\\"<=\\\",\\\"value\\\":\\\"2\\\"},{\\\"label\\\":\\\">\\\",\\\"value\\\":\\\"3\\\"},{\\\"label\\\":\\\">=\\\",\\\"value\\\":\\\"4\\\"},{\\\"label\\\":\\\"!=\\\",\\\"value\\\":\\\"5\\\"}]\",\"placeholder\":\"please select operator\",\"optionSourceType\":0,\"dataType\":0,\"inputType\":3,\"isShow\":true,\"canEdit\":true,\"isEmit\":false,\"isValidate\":false,\"valuesMap\":null,\"index\":8,\"createTime\":null,\"updateTime\":null},{\"id\":9,\"field\":\"threshold\",\"type\":\"input\",\"title\":\"$t(threshold)\",\"data\":null,\"options\":null,\"placeholder\":\"Please enter threshold, number is needed\",\"optionSourceType\":0,\"dataType\":2,\"inputType\":3,\"isShow\":true,\"canEdit\":true,\"isEmit\":false,\"isValidate\":true,\"valuesMap\":null,\"index\":9,\"createTime\":null,\"updateTime\":null},{\"id\":10,\"field\":\"failure_strategy\",\"type\":\"select\",\"title\":\"$t(failure_strategy)\",\"data\":\"0\",\"options\":\"[{\\\"label\\\":\\\"Alert\\\",\\\"value\\\":\\\"0\\\"},{\\\"label\\\":\\\"Block\\\",\\\"value\\\":\\\"1\\\"}]\",\"placeholder\":\"please select failure strategy\",\"optionSourceType\":0,\"dataType\":0,\"inputType\":3,\"isShow\":true,\"canEdit\":true,\"isEmit\":false,\"isValidate\":false,\"valuesMap\":null,\"index\":10,\"createTime\":null,\"updateTime\":null},{\"id\":17,\"field\":\"comparison_name\",\"type\":\"input\",\"title\":\"$t(comparison_name)\",\"data\":null,\"options\":null,\"placeholder\":\"Please enter comparison name, the alias in comparison execute sql\",\"optionSourceType\":0,\"dataType\":0,\"inputType\":0,\"isShow\":false,\"canEdit\":false,\"isEmit\":false,\"isValidate\":true,\"valuesMap\":\"\",\"index\":11,\"createTime\":null,\"updateTime\":null},{\"id\":19,\"field\":\"comparison_type\",\"type\":\"select\",\"title\":\"$t(comparison_type)\",\"data\":\"\",\"options\":null,\"placeholder\":\"Please enter comparison title\",\"optionSourceType\":3,\"dataType\":0,\"inputType\":2,\"isShow\":true,\"canEdit\":false,\"isEmit\":true,\"isValidate\":false,\"valuesMap\":null,\"index\":12,\"createTime\":null,\"updateTime\":null}]",
    "executeSqlList" : "[{\"id\":6,\"index\":1,\"sql\":\"SELECT ${src_field} FROM ${src_table} group by ${src_field} having count(*) > 1\",\"tableAlias\":\"duplicate_items\",\"type\":0,\"createTime\":\"2021-03-03 11:31:24\",\"updateTime\":\"2021-03-03 11:31:24\",\"errorOutputSql\":true},{\"id\":7,\"index\":1,\"sql\":\"SELECT COUNT(*) AS duplicates FROM duplicate_items\",\"tableAlias\":\"duplicate_count\",\"type\":1,\"createTime\":\"2021-03-03 11:31:24\",\"updateTime\":\"2021-03-03 11:31:24\",\"errorOutputSql\":false}]",
    "comparisonNeedStatisticsValueTable" : false,
    "compareWithFixedValue" : true,
    "hdfsPath" : "hdfs://mycluster:8020/user/default/data_quality_error_data",
    "sourceConnectorType" : "JDBC",
    "sourceType" : 1,
    "sourceConnectionParams" : "{\"user\":\"root\",\"password\":\"root\",\"address\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432\",\"database\":\"persistence\",\"jdbcUrl\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432/persistence\",\"driverClassName\":\"org.postgresql.Driver\",\"validationQuery\":\"select version()\",\"other\":{\"password\":\"root\"}}",
    "targetConnectorType" : null,
    "targetType" : 0,
    "targetConnectionParams" : null,
    "writerConnectorType" : "JDBC",
    "writerType" : 1,
    "writerTable" : "t_ds_dq_execute_result",
    "writerConnectionParams" : "{\"user\":\"root\",\"password\":\"root\",\"address\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432\",\"database\":\"dolphinscheduler\",\"jdbcUrl\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432/dolphinscheduler\"}",
    "statisticsValueConnectorType" : "JDBC",
    "statisticsValueType" : 1,
    "statisticsValueTable" : "t_ds_dq_task_statistics_value",
    "statisticsValueWriterConnectionParams" : "{\"user\":\"root\",\"password\":\"root\",\"address\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432\",\"database\":\"dolphinscheduler\",\"jdbcUrl\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432/dolphinscheduler\"}"
  },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-1059][TI-3953] - [INFO] 2024-05-07 10:02:33.701 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-1059][TI-3953] - [INFO] 2024-05-07 10:02:33.702 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-1059][TI-3953] - [INFO] 2024-05-07 10:02:33.702 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-1059][TI-3953] - [INFO] 2024-05-07 10:02:33.768 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-1059][TI-3953] - [INFO] 2024-05-07 10:02:33.788 +0800 o.a.d.c.u.OSUtils:[231] - create linux os user: default
[WI-1059][TI-3953] - [INFO] 2024-05-07 10:02:33.788 +0800 o.a.d.c.u.OSUtils:[233] - execute cmd: sudo useradd -g root
 default
[WI-1059][TI-3953] - [INFO] 2024-05-07 10:02:33.857 +0800 o.a.d.c.u.OSUtils:[190] - create user default success
[WI-1059][TI-3953] - [INFO] 2024-05-07 10:02:33.858 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-1059][TI-3953] - [INFO] 2024-05-07 10:02:33.861 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13001194483488/13505298546272_21/1059/3953 check successfully
[WI-1059][TI-3953] - [INFO] 2024-05-07 10:02:33.863 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.dq.DataQualityTaskChannel successfully
[WI-1059][TI-3953] - [INFO] 2024-05-07 10:02:33.873 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-1059][TI-3953] - [INFO] 2024-05-07 10:02:33.882 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-0][TI-0] - [INFO] 2024-05-07 10:02:33.885 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7588849217248008 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-1059][TI-3953] - [INFO] 2024-05-07 10:02:33.898 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: DATA_QUALITY create successfully
[WI-1059][TI-3953] - [INFO] 2024-05-07 10:02:33.909 +0800 o.a.d.p.t.d.DataQualityTask:[89] - Initialize data quality task params {
  "localParams" : [ ],
  "varPool" : null,
  "ruleId" : 6,
  "ruleInputParameter" : {
    "check_type" : "0",
    "comparison_type" : "1",
    "comparison_name" : "0",
    "failure_strategy" : "0",
    "operator" : "0",
    "src_connector_type" : "1",
    "src_datasource_id" : "6",
    "src_database" : "persistence",
    "src_field" : "content",
    "src_table" : "filtered_data_persistence",
    "threshold" : "0"
  },
  "sparkParameters" : {
    "localParams" : null,
    "varPool" : null,
    "mainJar" : null,
    "mainClass" : null,
    "deployMode" : "local",
    "mainArgs" : null,
    "driverCores" : 1,
    "driverMemory" : "512M",
    "numExecutors" : 1,
    "executorCores" : 1,
    "executorMemory" : "1G",
    "appName" : null,
    "yarnQueue" : "",
    "others" : "--conf spark.driver.extraJavaOptions=\"-Divy.cache.dir=/tmp -Divy.home=/tmp\" \\\n--packages org.postgresql:postgresql:42.7.3",
    "programType" : null,
    "resourceList" : [ ]
  }
}
[WI-1059][TI-3953] - [INFO] 2024-05-07 10:02:33.954 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: HANA
[WI-1059][TI-3953] - [INFO] 2024-05-07 10:02:33.955 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: HANA
[WI-1059][TI-3953] - [INFO] 2024-05-07 10:02:33.957 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: SQLSERVER
[WI-1059][TI-3953] - [INFO] 2024-05-07 10:02:33.958 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: SQLSERVER
[WI-1059][TI-3953] - [INFO] 2024-05-07 10:02:33.959 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: SAGEMAKER
[WI-1059][TI-3953] - [INFO] 2024-05-07 10:02:33.959 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: SAGEMAKER
[WI-1059][TI-3953] - [INFO] 2024-05-07 10:02:33.960 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: DATABEND
[WI-1059][TI-3953] - [INFO] 2024-05-07 10:02:33.961 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: DATABEND
[WI-1059][TI-3953] - [INFO] 2024-05-07 10:02:33.994 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: AZURESQL
[WI-1059][TI-3953] - [INFO] 2024-05-07 10:02:33.994 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: AZURESQL
[WI-1059][TI-3953] - [INFO] 2024-05-07 10:02:33.997 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: HIVE
[WI-1059][TI-3953] - [INFO] 2024-05-07 10:02:33.998 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: HIVE
[WI-1059][TI-3953] - [INFO] 2024-05-07 10:02:33.999 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: DORIS
[WI-1059][TI-3953] - [INFO] 2024-05-07 10:02:34.000 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: DORIS
[WI-1059][TI-3953] - [INFO] 2024-05-07 10:02:34.002 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: POSTGRESQL
[WI-1059][TI-3953] - [INFO] 2024-05-07 10:02:34.002 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: POSTGRESQL
[WI-1059][TI-3953] - [INFO] 2024-05-07 10:02:34.005 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: MYSQL
[WI-1059][TI-3953] - [INFO] 2024-05-07 10:02:34.005 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: MYSQL
[WI-1059][TI-3953] - [INFO] 2024-05-07 10:02:34.007 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: REDSHIFT
[WI-1059][TI-3953] - [INFO] 2024-05-07 10:02:34.008 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: REDSHIFT
[WI-1059][TI-3953] - [INFO] 2024-05-07 10:02:34.010 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: SNOWFLAKE
[WI-1059][TI-3953] - [INFO] 2024-05-07 10:02:34.011 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: SNOWFLAKE
[WI-1059][TI-3953] - [INFO] 2024-05-07 10:02:34.014 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: STARROCKS
[WI-1059][TI-3953] - [INFO] 2024-05-07 10:02:34.014 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: STARROCKS
[WI-1059][TI-3953] - [INFO] 2024-05-07 10:02:34.015 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: SSH
[WI-1059][TI-3953] - [INFO] 2024-05-07 10:02:34.016 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: SSH
[WI-1059][TI-3953] - [INFO] 2024-05-07 10:02:34.017 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: ATHENA
[WI-1059][TI-3953] - [INFO] 2024-05-07 10:02:34.018 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: ATHENA
[WI-1059][TI-3953] - [INFO] 2024-05-07 10:02:34.020 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: PRESTO
[WI-1059][TI-3953] - [INFO] 2024-05-07 10:02:34.021 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: PRESTO
[WI-1059][TI-3953] - [INFO] 2024-05-07 10:02:34.023 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: OCEANBASE
[WI-1059][TI-3953] - [INFO] 2024-05-07 10:02:34.024 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: OCEANBASE
[WI-1059][TI-3953] - [INFO] 2024-05-07 10:02:34.033 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: ORACLE
[WI-1059][TI-3953] - [INFO] 2024-05-07 10:02:34.034 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: ORACLE
[WI-1059][TI-3953] - [INFO] 2024-05-07 10:02:34.036 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: CLICKHOUSE
[WI-1059][TI-3953] - [INFO] 2024-05-07 10:02:34.036 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: CLICKHOUSE
[WI-1059][TI-3953] - [INFO] 2024-05-07 10:02:34.039 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: VERTICA
[WI-1059][TI-3953] - [INFO] 2024-05-07 10:02:34.039 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: VERTICA
[WI-1059][TI-3953] - [INFO] 2024-05-07 10:02:34.042 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: KYUUBI
[WI-1059][TI-3953] - [INFO] 2024-05-07 10:02:34.042 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: KYUUBI
[WI-1059][TI-3953] - [INFO] 2024-05-07 10:02:34.046 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: DB2
[WI-1059][TI-3953] - [INFO] 2024-05-07 10:02:34.046 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: DB2
[WI-1059][TI-3953] - [INFO] 2024-05-07 10:02:34.049 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: TRINO
[WI-1059][TI-3953] - [INFO] 2024-05-07 10:02:34.050 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: TRINO
[WI-1059][TI-3953] - [INFO] 2024-05-07 10:02:34.052 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: SPARK
[WI-1059][TI-3953] - [INFO] 2024-05-07 10:02:34.053 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: SPARK
[WI-1059][TI-3953] - [INFO] 2024-05-07 10:02:34.056 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: DAMENG
[WI-1059][TI-3953] - [INFO] 2024-05-07 10:02:34.056 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: DAMENG
[WI-1059][TI-3953] - [INFO] 2024-05-07 10:02:34.059 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: ZEPPELIN
[WI-1059][TI-3953] - [INFO] 2024-05-07 10:02:34.059 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: ZEPPELIN
[WI-1059][TI-3953] - [INFO] 2024-05-07 10:02:34.076 +0800 o.a.d.p.t.d.DataQualityTask:[119] - data quality configuration: {
  "name" : "$t(uniqueness_check)",
  "env" : {
    "type" : "batch",
    "config" : null
  },
  "readers" : [ {
    "type" : "JDBC",
    "config" : {
      "database" : "persistence",
      "password" : "root",
      "driver" : "org.postgresql.Driver",
      "user" : "root",
      "output_table" : "persistence_filtered_data_persistence",
      "table" : "filtered_data_persistence",
      "url" : "jdbc:postgresql://dolphinscheduler-postgresql:5432/persistence?password=root"
    }
  } ],
  "transformers" : [ {
    "type" : "sql",
    "config" : {
      "index" : 1,
      "output_table" : "duplicate_items",
      "sql" : "SELECT content FROM persistence_filtered_data_persistence group by content having count(*) > 1"
    }
  }, {
    "type" : "sql",
    "config" : {
      "index" : 2,
      "output_table" : "duplicate_count",
      "sql" : "SELECT COUNT(*) AS duplicates FROM duplicate_items"
    }
  } ],
  "writers" : [ {
    "type" : "JDBC",
    "config" : {
      "database" : "dolphinscheduler",
      "password" : "root",
      "driver" : "org.postgresql.Driver",
      "user" : "root",
      "table" : "t_ds_dq_execute_result",
      "url" : "jdbc:postgresql://dolphinscheduler-postgresql:5432/dolphinscheduler",
      "sql" : "select 0 as rule_type,'$t(uniqueness_check)' as rule_name,0 as process_definition_id,1059 as process_instance_id,3953 as task_instance_id,duplicate_count.duplicates AS statistics_value,0 AS comparison_value,1 AS comparison_type,0 as check_type,0 as threshold,0 as operator,0 as failure_strategy,'hdfs://mycluster:8020/user/default/data_quality_error_data/0_1059_[null check] filtered data persistence' as error_output_path,'2024-05-07 10:02:33' as create_time,'2024-05-07 10:02:33' as update_time from duplicate_count "
    }
  }, {
    "type" : "JDBC",
    "config" : {
      "database" : "dolphinscheduler",
      "password" : "root",
      "driver" : "org.postgresql.Driver",
      "user" : "root",
      "table" : "t_ds_dq_task_statistics_value",
      "url" : "jdbc:postgresql://dolphinscheduler-postgresql:5432/dolphinscheduler",
      "sql" : "select 0 as process_definition_id,3953 as task_instance_id,6 as rule_id,'KA0AXXWVHWW+GZX4BPZXFGFZ0F0OYMUQ+BVYG4+ZIKG=' as unique_code,'duplicate_count.duplicates'AS statistics_name,duplicate_count.duplicates AS statistics_value,'2024-05-07 10:02:33' as data_time,'2024-05-07 10:02:33' as create_time,'2024-05-07 10:02:33' as update_time from duplicate_count"
    }
  }, {
    "type" : "hdfs_file",
    "config" : {
      "path" : "hdfs://mycluster:8020/user/default/data_quality_error_data/0_1059_[null check] filtered data persistence",
      "input_table" : "duplicate_items"
    }
  } ]
}
[WI-1059][TI-3953] - [INFO] 2024-05-07 10:02:34.082 +0800 o.a.d.p.d.a.u.CommonUtils:[136] - Trying to get data quality jar in path
[WI-1059][TI-3953] - [INFO] 2024-05-07 10:02:34.082 +0800 o.a.d.p.d.a.u.CommonUtils:[147] - data quality jar path is empty, will try to auto discover it from build-in rules.
[WI-1059][TI-3953] - [INFO] 2024-05-07 10:02:34.083 +0800 o.a.d.p.d.a.u.CommonUtils:[187] - Try to get data quality jar from path /opt/dolphinscheduler/conf/../libs
[WI-1059][TI-3953] - [INFO] 2024-05-07 10:02:34.086 +0800 o.a.d.p.d.a.u.CommonUtils:[182] - get default data quality jar name: /opt/dolphinscheduler/conf/../libs/dolphinscheduler-data-quality-3.2.1.jar
[WI-1059][TI-3953] - [INFO] 2024-05-07 10:02:34.086 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-1059][TI-3953] - [INFO] 2024-05-07 10:02:34.086 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: null successfully
[WI-1059][TI-3953] - [INFO] 2024-05-07 10:02:34.089 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-1059][TI-3953] - [INFO] 2024-05-07 10:02:34.090 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-1059][TI-3953] - [INFO] 2024-05-07 10:02:34.090 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-1059][TI-3953] - [INFO] 2024-05-07 10:02:34.097 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-1059][TI-3953] - [INFO] 2024-05-07 10:02:34.098 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-1059][TI-3953] - [INFO] 2024-05-07 10:02:34.098 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export PYSPARK_DRIVER_PYTHON=/bin/python3.11
export PYSPARK_PYTHON=/bin/python3.11
${SPARK_HOME}/bin/spark-submit --master local --driver-cores 1 --driver-memory 512M --num-executors 1 --executor-cores 1 --executor-memory 1G --conf spark.driver.extraJavaOptions="-Divy.cache.dir=/tmp -Divy.home=/tmp" \
--packages org.postgresql:postgresql:42.7.3 /opt/dolphinscheduler/conf/../libs/dolphinscheduler-data-quality-3.2.1.jar "{\"name\":\"$t(uniqueness_check)\",\"env\":{\"type\":\"batch\",\"config\":null},\"readers\":[{\"type\":\"JDBC\",\"config\":{\"database\":\"persistence\",\"password\":\"root\",\"driver\":\"org.postgresql.Driver\",\"user\":\"root\",\"output_table\":\"persistence_filtered_data_persistence\",\"table\":\"filtered_data_persistence\",\"url\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432/persistence?password=root\"} }],\"transformers\":[{\"type\":\"sql\",\"config\":{\"index\":1,\"output_table\":\"duplicate_items\",\"sql\":\"SELECT content FROM persistence_filtered_data_persistence group by content having count(*) > 1\"} },{\"type\":\"sql\",\"config\":{\"index\":2,\"output_table\":\"duplicate_count\",\"sql\":\"SELECT COUNT(*) AS duplicates FROM duplicate_items\"} }],\"writers\":[{\"type\":\"JDBC\",\"config\":{\"database\":\"dolphinscheduler\",\"password\":\"root\",\"driver\":\"org.postgresql.Driver\",\"user\":\"root\",\"table\":\"t_ds_dq_execute_result\",\"url\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432/dolphinscheduler\",\"sql\":\"select 0 as rule_type,'$t(uniqueness_check)' as rule_name,0 as process_definition_id,1059 as process_instance_id,3953 as task_instance_id,duplicate_count.duplicates AS statistics_value,0 AS comparison_value,1 AS comparison_type,0 as check_type,0 as threshold,0 as operator,0 as failure_strategy,'hdfs://mycluster:8020/user/default/data_quality_error_data/0_1059_[null check] filtered data persistence' as error_output_path,'2024-05-07 10:02:33' as create_time,'2024-05-07 10:02:33' as update_time from duplicate_count \"} },{\"type\":\"JDBC\",\"config\":{\"database\":\"dolphinscheduler\",\"password\":\"root\",\"driver\":\"org.postgresql.Driver\",\"user\":\"root\",\"table\":\"t_ds_dq_task_statistics_value\",\"url\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432/dolphinscheduler\",\"sql\":\"select 0 as process_definition_id,3953 as task_instance_id,6 as rule_id,'KA0AXXWVHWW+GZX4BPZXFGFZ0F0OYMUQ+BVYG4+ZIKG=' as unique_code,'duplicate_count.duplicates'AS statistics_name,duplicate_count.duplicates AS statistics_value,'2024-05-07 10:02:33' as data_time,'2024-05-07 10:02:33' as create_time,'2024-05-07 10:02:33' as update_time from duplicate_count\"} },{\"type\":\"hdfs_file\",\"config\":{\"path\":\"hdfs://mycluster:8020/user/default/data_quality_error_data/0_1059_[null check] filtered data persistence\",\"input_table\":\"duplicate_items\"} }]}"
[WI-1059][TI-3953] - [INFO] 2024-05-07 10:02:34.099 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-1059][TI-3953] - [INFO] 2024-05-07 10:02:34.101 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13001194483488/13505298546272_21/1059/3953/1059_3953.sh
[WI-1059][TI-3953] - [INFO] 2024-05-07 10:02:34.106 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 85
[WI-0][TI-3953] - [INFO] 2024-05-07 10:02:34.223 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=3953, success=true)
[WI-0][TI-3953] - [INFO] 2024-05-07 10:02:34.260 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=3953)
[WI-0][TI-0] - [INFO] 2024-05-07 10:02:34.904 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7485875706214689 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:02:35.109 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
[WI-0][TI-0] - [INFO] 2024-05-07 10:02:36.919 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8166089965397924 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:02:37.113 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	:: loading settings :: url = jar:file:/opt/spark-3.5.1-bin-hadoop3/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml
	Ivy Default Cache set to: /tmp
	The jars for the packages stored in: /tmp/jars
	org.postgresql#postgresql added as a dependency
	:: resolving dependencies :: org.apache.spark#spark-submit-parent-884b116c-eca6-48d2-ab37-0dbf4ac5c7f6;1.0
		confs: [default]
[WI-0][TI-0] - [INFO] 2024-05-07 10:02:38.114 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
		found org.postgresql#postgresql;42.7.3 in central
[WI-0][TI-0] - [INFO] 2024-05-07 10:02:39.117 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
		found org.checkerframework#checker-qual;3.42.0 in central
	downloading https://repo1.maven.org/maven2/org/postgresql/postgresql/42.7.3/postgresql-42.7.3.jar ...
[WI-0][TI-0] - [INFO] 2024-05-07 10:02:40.119 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
		[SUCCESSFUL ] org.postgresql#postgresql;42.7.3!postgresql.jar (1288ms)
	downloading https://repo1.maven.org/maven2/org/checkerframework/checker-qual/3.42.0/checker-qual-3.42.0.jar ...
[WI-0][TI-0] - [INFO] 2024-05-07 10:02:41.120 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
		[SUCCESSFUL ] org.checkerframework#checker-qual;3.42.0!checker-qual.jar (398ms)
	:: resolution report :: resolve 1772ms :: artifacts dl 1691ms
		:: modules in use:
		org.checkerframework#checker-qual;3.42.0 from central in [default]
		org.postgresql#postgresql;42.7.3 from central in [default]
		---------------------------------------------------------------------
		|                  |            modules            ||   artifacts   |
		|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
		---------------------------------------------------------------------
		|      default     |   2   |   2   |   2   |   0   ||   2   |   2   |
		---------------------------------------------------------------------
	:: retrieving :: org.apache.spark#spark-submit-parent-884b116c-eca6-48d2-ab37-0dbf4ac5c7f6
		confs: [default]
		2 artifacts copied, 0 already retrieved (1289kB/9ms)
	24/05/07 10:02:40 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[WI-0][TI-0] - [INFO] 2024-05-07 10:02:42.681 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:02:41 INFO SparkContext: Running Spark version 3.5.1
	24/05/07 10:02:41 INFO SparkContext: OS info Linux, 6.5.0-28-generic, amd64
	24/05/07 10:02:41 INFO SparkContext: Java version 1.8.0_402
	24/05/07 10:02:41 INFO ResourceUtils: ==============================================================
	24/05/07 10:02:41 INFO ResourceUtils: No custom resources configured for spark.driver.
	24/05/07 10:02:41 INFO ResourceUtils: ==============================================================
	24/05/07 10:02:41 INFO SparkContext: Submitted application: (uniqueness_check)
	24/05/07 10:02:41 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
	24/05/07 10:02:41 INFO ResourceProfile: Limiting resource is cpu
	24/05/07 10:02:41 INFO ResourceProfileManager: Added ResourceProfile id: 0
	24/05/07 10:02:41 INFO SecurityManager: Changing view acls to: default
	24/05/07 10:02:41 INFO SecurityManager: Changing modify acls to: default
	24/05/07 10:02:41 INFO SecurityManager: Changing view acls groups to: 
	24/05/07 10:02:41 INFO SecurityManager: Changing modify acls groups to: 
	24/05/07 10:02:41 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: default; groups with view permissions: EMPTY; users with modify permissions: default; groups with modify permissions: EMPTY
	24/05/07 10:02:41 INFO Utils: Successfully started service 'sparkDriver' on port 34761.
	24/05/07 10:02:41 INFO SparkEnv: Registering MapOutputTracker
	24/05/07 10:02:41 INFO SparkEnv: Registering BlockManagerMaster
	24/05/07 10:02:41 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
	24/05/07 10:02:41 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
	24/05/07 10:02:41 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
	24/05/07 10:02:41 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-1f7060de-1f6a-4214-ae05-0066b609485d
	24/05/07 10:02:41 INFO MemoryStore: MemoryStore started with capacity 93.3 MiB
	24/05/07 10:02:41 INFO SparkEnv: Registering OutputCommitCoordinator
[WI-0][TI-0] - [INFO] 2024-05-07 10:02:43.683 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:02:42 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
	24/05/07 10:02:42 INFO Utils: Successfully started service 'SparkUI' on port 4040.
	24/05/07 10:02:43 INFO SparkContext: Added JAR file:///tmp/jars/org.postgresql_postgresql-42.7.3.jar at spark://6461fa46f54d:34761/jars/org.postgresql_postgresql-42.7.3.jar with timestamp 1715047361115
	24/05/07 10:02:43 INFO SparkContext: Added JAR file:///tmp/jars/org.checkerframework_checker-qual-3.42.0.jar at spark://6461fa46f54d:34761/jars/org.checkerframework_checker-qual-3.42.0.jar with timestamp 1715047361115
	24/05/07 10:02:43 INFO SparkContext: Added JAR file:/opt/dolphinscheduler/libs/dolphinscheduler-data-quality-3.2.1.jar at spark://6461fa46f54d:34761/jars/dolphinscheduler-data-quality-3.2.1.jar with timestamp 1715047361115
	24/05/07 10:02:43 INFO Executor: Starting executor ID driver on host 6461fa46f54d
	24/05/07 10:02:43 INFO Executor: OS info Linux, 6.5.0-28-generic, amd64
	24/05/07 10:02:43 INFO Executor: Java version 1.8.0_402
	24/05/07 10:02:43 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
	24/05/07 10:02:43 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@358ab600 for default.
	24/05/07 10:02:43 INFO Executor: Fetching spark://6461fa46f54d:34761/jars/org.postgresql_postgresql-42.7.3.jar with timestamp 1715047361115
	24/05/07 10:02:43 INFO TransportClientFactory: Successfully created connection to 6461fa46f54d/172.18.1.1:34761 after 38 ms (0 ms spent in bootstraps)
	24/05/07 10:02:43 INFO Utils: Fetching spark://6461fa46f54d:34761/jars/org.postgresql_postgresql-42.7.3.jar to /tmp/spark-40047faf-aaa6-4890-834d-c2600d8a772b/userFiles-bbaeb230-f12f-4f55-a7fd-2b9cf3cc7f2d/fetchFileTemp2869377552116017474.tmp
	24/05/07 10:02:43 INFO Executor: Adding file:/tmp/spark-40047faf-aaa6-4890-834d-c2600d8a772b/userFiles-bbaeb230-f12f-4f55-a7fd-2b9cf3cc7f2d/org.postgresql_postgresql-42.7.3.jar to class loader default
	24/05/07 10:02:43 INFO Executor: Fetching spark://6461fa46f54d:34761/jars/org.checkerframework_checker-qual-3.42.0.jar with timestamp 1715047361115
	24/05/07 10:02:43 INFO Utils: Fetching spark://6461fa46f54d:34761/jars/org.checkerframework_checker-qual-3.42.0.jar to /tmp/spark-40047faf-aaa6-4890-834d-c2600d8a772b/userFiles-bbaeb230-f12f-4f55-a7fd-2b9cf3cc7f2d/fetchFileTemp7842952594091065122.tmp
	24/05/07 10:02:43 INFO Executor: Adding file:/tmp/spark-40047faf-aaa6-4890-834d-c2600d8a772b/userFiles-bbaeb230-f12f-4f55-a7fd-2b9cf3cc7f2d/org.checkerframework_checker-qual-3.42.0.jar to class loader default
	24/05/07 10:02:43 INFO Executor: Fetching spark://6461fa46f54d:34761/jars/dolphinscheduler-data-quality-3.2.1.jar with timestamp 1715047361115
	24/05/07 10:02:43 INFO Utils: Fetching spark://6461fa46f54d:34761/jars/dolphinscheduler-data-quality-3.2.1.jar to /tmp/spark-40047faf-aaa6-4890-834d-c2600d8a772b/userFiles-bbaeb230-f12f-4f55-a7fd-2b9cf3cc7f2d/fetchFileTemp753520520338404288.tmp
	24/05/07 10:02:43 INFO Executor: Adding file:/tmp/spark-40047faf-aaa6-4890-834d-c2600d8a772b/userFiles-bbaeb230-f12f-4f55-a7fd-2b9cf3cc7f2d/dolphinscheduler-data-quality-3.2.1.jar to class loader default
	24/05/07 10:02:43 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39615.
	24/05/07 10:02:43 INFO NettyBlockTransferService: Server created on 6461fa46f54d:39615
	24/05/07 10:02:43 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
	24/05/07 10:02:43 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 6461fa46f54d, 39615, None)
	24/05/07 10:02:43 INFO BlockManagerMasterEndpoint: Registering block manager 6461fa46f54d:39615 with 93.3 MiB RAM, BlockManagerId(driver, 6461fa46f54d, 39615, None)
	24/05/07 10:02:43 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 6461fa46f54d, 39615, None)
	24/05/07 10:02:43 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 6461fa46f54d, 39615, None)
[WI-0][TI-0] - [INFO] 2024-05-07 10:02:44.712 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:02:43 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
	24/05/07 10:02:43 INFO SharedState: Warehouse path is 'file:/tmp/dolphinscheduler/exec/process/default/13001194483488/13505298546272_21/1059/3953/spark-warehouse'.
[WI-0][TI-0] - [INFO] 2024-05-07 10:02:47.790 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:02:47 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
[WI-0][TI-0] - [INFO] 2024-05-07 10:02:48.794 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7015384615384614 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:02:48.795 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:02:48 INFO CodeGenerator: Code generated in 372.58566 ms
	24/05/07 10:02:48 INFO DAGScheduler: Registering RDD 2 (save at JdbcWriter.java:87) as input to shuffle 0
	24/05/07 10:02:48 INFO DAGScheduler: Got map stage job 0 (save at JdbcWriter.java:87) with 1 output partitions
	24/05/07 10:02:48 INFO DAGScheduler: Final stage: ShuffleMapStage 0 (save at JdbcWriter.java:87)
	24/05/07 10:02:48 INFO DAGScheduler: Parents of final stage: List()
	24/05/07 10:02:48 INFO DAGScheduler: Missing parents: List()
	24/05/07 10:02:48 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[2] at save at JdbcWriter.java:87), which has no missing parents
	24/05/07 10:02:48 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 34.8 KiB, free 93.3 MiB)
	24/05/07 10:02:48 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 16.4 KiB, free 93.2 MiB)
	24/05/07 10:02:48 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 6461fa46f54d:39615 (size: 16.4 KiB, free: 93.3 MiB)
	24/05/07 10:02:48 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1585
	24/05/07 10:02:48 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[2] at save at JdbcWriter.java:87) (first 15 tasks are for partitions Vector(0))
	24/05/07 10:02:48 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
	24/05/07 10:02:48 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (6461fa46f54d, executor driver, partition 0, PROCESS_LOCAL, 7878 bytes) 
[WI-0][TI-0] - [INFO] 2024-05-07 10:02:49.800 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:02:48 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
	24/05/07 10:02:49 INFO CodeGenerator: Code generated in 48.614377 ms
	24/05/07 10:02:49 INFO CodeGenerator: Code generated in 18.558708 ms
	24/05/07 10:02:49 INFO CodeGenerator: Code generated in 6.823372 ms
	24/05/07 10:02:49 INFO CodeGenerator: Code generated in 11.027887 ms
	24/05/07 10:02:49 INFO CodeGenerator: Code generated in 10.606566 ms
	24/05/07 10:02:49 INFO JDBCRDD: closed connection
	24/05/07 10:02:49 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 2491 bytes result sent to driver
	24/05/07 10:02:49 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 629 ms on 6461fa46f54d (executor driver) (1/1)
	24/05/07 10:02:49 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
	24/05/07 10:02:49 INFO DAGScheduler: ShuffleMapStage 0 (save at JdbcWriter.java:87) finished in 0.869 s
	24/05/07 10:02:49 INFO DAGScheduler: looking for newly runnable stages
	24/05/07 10:02:49 INFO DAGScheduler: running: Set()
	24/05/07 10:02:49 INFO DAGScheduler: waiting: Set()
	24/05/07 10:02:49 INFO DAGScheduler: failed: Set()
	24/05/07 10:02:49 INFO ShufflePartitionsUtil: For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
	24/05/07 10:02:49 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
	24/05/07 10:02:49 INFO CodeGenerator: Code generated in 18.111815 ms
	24/05/07 10:02:49 INFO DAGScheduler: Registering RDD 5 (save at JdbcWriter.java:87) as input to shuffle 1
	24/05/07 10:02:49 INFO DAGScheduler: Got map stage job 1 (save at JdbcWriter.java:87) with 1 output partitions
	24/05/07 10:02:49 INFO DAGScheduler: Final stage: ShuffleMapStage 2 (save at JdbcWriter.java:87)
	24/05/07 10:02:49 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
	24/05/07 10:02:49 INFO DAGScheduler: Missing parents: List()
	24/05/07 10:02:49 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[5] at save at JdbcWriter.java:87), which has no missing parents
	24/05/07 10:02:49 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 40.5 KiB, free 93.2 MiB)
	24/05/07 10:02:49 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 19.1 KiB, free 93.2 MiB)
[WI-0][TI-0] - [INFO] 2024-05-07 10:02:50.807 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:02:49 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1585
	24/05/07 10:02:49 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[5] at save at JdbcWriter.java:87) (first 15 tasks are for partitions Vector(0))
	24/05/07 10:02:49 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
	24/05/07 10:02:49 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 6461fa46f54d:39615 in memory (size: 16.4 KiB, free: 93.3 MiB)
	24/05/07 10:02:49 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 1) (6461fa46f54d, executor driver, partition 0, NODE_LOCAL, 8032 bytes) 
	24/05/07 10:02:49 INFO Executor: Running task 0.0 in stage 2.0 (TID 1)
	24/05/07 10:02:49 INFO ShuffleBlockFetcherIterator: Getting 1 (2.9 KiB) non-empty blocks including 1 (2.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
	24/05/07 10:02:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 36 ms
	24/05/07 10:02:49 INFO CodeGenerator: Code generated in 11.626111 ms
	24/05/07 10:02:49 INFO Executor: Finished task 0.0 in stage 2.0 (TID 1). 5420 bytes result sent to driver
	24/05/07 10:02:49 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 1) in 119 ms on 6461fa46f54d (executor driver) (1/1)
	24/05/07 10:02:49 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
	24/05/07 10:02:49 INFO DAGScheduler: ShuffleMapStage 2 (save at JdbcWriter.java:87) finished in 0.260 s
	24/05/07 10:02:49 INFO DAGScheduler: looking for newly runnable stages
	24/05/07 10:02:49 INFO DAGScheduler: running: Set()
	24/05/07 10:02:49 INFO DAGScheduler: waiting: Set()
	24/05/07 10:02:49 INFO DAGScheduler: failed: Set()
	24/05/07 10:02:49 INFO CodeGenerator: Code generated in 27.550099 ms
	24/05/07 10:02:50 INFO SparkContext: Starting job: save at JdbcWriter.java:87
	24/05/07 10:02:50 INFO DAGScheduler: Got job 2 (save at JdbcWriter.java:87) with 1 output partitions
	24/05/07 10:02:50 INFO DAGScheduler: Final stage: ResultStage 5 (save at JdbcWriter.java:87)
	24/05/07 10:02:50 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
	24/05/07 10:02:50 INFO DAGScheduler: Missing parents: List()
	24/05/07 10:02:50 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[10] at save at JdbcWriter.java:87), which has no missing parents
	24/05/07 10:02:50 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 51.4 KiB, free 93.2 MiB)
	24/05/07 10:02:50 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 23.1 KiB, free 93.2 MiB)
	24/05/07 10:02:50 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 6461fa46f54d:39615 (size: 23.1 KiB, free: 93.3 MiB)
	24/05/07 10:02:50 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1585
	24/05/07 10:02:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[10] at save at JdbcWriter.java:87) (first 15 tasks are for partitions Vector(0))
	24/05/07 10:02:50 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
	24/05/07 10:02:50 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 2) (6461fa46f54d, executor driver, partition 0, NODE_LOCAL, 8043 bytes) 
	24/05/07 10:02:50 INFO Executor: Running task 0.0 in stage 5.0 (TID 2)
	24/05/07 10:02:50 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
	24/05/07 10:02:50 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
	24/05/07 10:02:50 INFO CodeGenerator: Code generated in 20.968912 ms
	24/05/07 10:02:50 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 6461fa46f54d:39615 in memory (size: 19.1 KiB, free: 93.3 MiB)
[WI-0][TI-0] - [INFO] 2024-05-07 10:02:51.820 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:02:51 INFO CodeGenerator: Code generated in 19.842322 ms
	24/05/07 10:02:51 INFO Executor: Finished task 0.0 in stage 5.0 (TID 2). 6711 bytes result sent to driver
	24/05/07 10:02:51 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 2) in 1225 ms on 6461fa46f54d (executor driver) (1/1)
	24/05/07 10:02:51 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
	24/05/07 10:02:51 INFO DAGScheduler: ResultStage 5 (save at JdbcWriter.java:87) finished in 1.310 s
	24/05/07 10:02:51 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
	24/05/07 10:02:51 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
	24/05/07 10:02:51 INFO DAGScheduler: Job 2 finished: save at JdbcWriter.java:87, took 1.330438 s
	24/05/07 10:02:51 INFO DAGScheduler: Registering RDD 13 (save at JdbcWriter.java:87) as input to shuffle 2
	24/05/07 10:02:51 INFO DAGScheduler: Got map stage job 3 (save at JdbcWriter.java:87) with 1 output partitions
	24/05/07 10:02:51 INFO DAGScheduler: Final stage: ShuffleMapStage 6 (save at JdbcWriter.java:87)
	24/05/07 10:02:51 INFO DAGScheduler: Parents of final stage: List()
	24/05/07 10:02:51 INFO DAGScheduler: Missing parents: List()
	24/05/07 10:02:51 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[13] at save at JdbcWriter.java:87), which has no missing parents
	24/05/07 10:02:51 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 34.8 KiB, free 93.2 MiB)
	24/05/07 10:02:51 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 16.5 KiB, free 93.2 MiB)
	24/05/07 10:02:51 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 6461fa46f54d:39615 (size: 16.5 KiB, free: 93.3 MiB)
	24/05/07 10:02:51 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1585
	24/05/07 10:02:51 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[13] at save at JdbcWriter.java:87) (first 15 tasks are for partitions Vector(0))
	24/05/07 10:02:51 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0
	24/05/07 10:02:51 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 3) (6461fa46f54d, executor driver, partition 0, PROCESS_LOCAL, 7878 bytes) 
	24/05/07 10:02:51 INFO Executor: Running task 0.0 in stage 6.0 (TID 3)
	24/05/07 10:02:51 INFO JDBCRDD: closed connection
	24/05/07 10:02:51 INFO Executor: Finished task 0.0 in stage 6.0 (TID 3). 2448 bytes result sent to driver
	24/05/07 10:02:51 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 3) in 64 ms on 6461fa46f54d (executor driver) (1/1)
	24/05/07 10:02:51 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
	24/05/07 10:02:51 INFO DAGScheduler: ShuffleMapStage 6 (save at JdbcWriter.java:87) finished in 0.073 s
	24/05/07 10:02:51 INFO DAGScheduler: looking for newly runnable stages
	24/05/07 10:02:51 INFO DAGScheduler: running: Set()
	24/05/07 10:02:51 INFO DAGScheduler: waiting: Set()
	24/05/07 10:02:51 INFO DAGScheduler: failed: Set()
	24/05/07 10:02:51 INFO ShufflePartitionsUtil: For shuffle(2), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[WI-0][TI-0] - [INFO] 2024-05-07 10:02:52.824 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:02:51 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
	24/05/07 10:02:51 INFO DAGScheduler: Registering RDD 16 (save at JdbcWriter.java:87) as input to shuffle 3
	24/05/07 10:02:51 INFO DAGScheduler: Got map stage job 4 (save at JdbcWriter.java:87) with 1 output partitions
	24/05/07 10:02:51 INFO DAGScheduler: Final stage: ShuffleMapStage 8 (save at JdbcWriter.java:87)
	24/05/07 10:02:51 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
	24/05/07 10:02:51 INFO DAGScheduler: Missing parents: List()
	24/05/07 10:02:51 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 6461fa46f54d:39615 in memory (size: 16.5 KiB, free: 93.3 MiB)
	24/05/07 10:02:51 INFO DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[16] at save at JdbcWriter.java:87), which has no missing parents
	24/05/07 10:02:51 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 6461fa46f54d:39615 in memory (size: 23.1 KiB, free: 93.3 MiB)
	24/05/07 10:02:51 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 40.6 KiB, free 93.3 MiB)
	24/05/07 10:02:51 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 19.1 KiB, free 93.2 MiB)
	24/05/07 10:02:51 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 6461fa46f54d:39615 (size: 19.1 KiB, free: 93.3 MiB)
	24/05/07 10:02:51 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1585
	24/05/07 10:02:51 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[16] at save at JdbcWriter.java:87) (first 15 tasks are for partitions Vector(0))
	24/05/07 10:02:51 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0
	24/05/07 10:02:51 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 4) (6461fa46f54d, executor driver, partition 0, NODE_LOCAL, 8032 bytes) 
	24/05/07 10:02:51 INFO Executor: Running task 0.0 in stage 8.0 (TID 4)
	24/05/07 10:02:51 INFO ShuffleBlockFetcherIterator: Getting 1 (2.9 KiB) non-empty blocks including 1 (2.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
	24/05/07 10:02:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
	24/05/07 10:02:51 INFO Executor: Finished task 0.0 in stage 8.0 (TID 4). 5420 bytes result sent to driver
	24/05/07 10:02:51 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 4) in 28 ms on 6461fa46f54d (executor driver) (1/1)
	24/05/07 10:02:51 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
	24/05/07 10:02:51 INFO DAGScheduler: ShuffleMapStage 8 (save at JdbcWriter.java:87) finished in 0.043 s
	24/05/07 10:02:51 INFO DAGScheduler: looking for newly runnable stages
	24/05/07 10:02:51 INFO DAGScheduler: running: Set()
	24/05/07 10:02:51 INFO DAGScheduler: waiting: Set()
	24/05/07 10:02:51 INFO DAGScheduler: failed: Set()
	24/05/07 10:02:51 INFO CodeGenerator: Code generated in 8.473902 ms
	24/05/07 10:02:51 INFO SparkContext: Starting job: save at JdbcWriter.java:87
	24/05/07 10:02:51 INFO DAGScheduler: Got job 5 (save at JdbcWriter.java:87) with 1 output partitions
	24/05/07 10:02:51 INFO DAGScheduler: Final stage: ResultStage 11 (save at JdbcWriter.java:87)
	24/05/07 10:02:51 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)
	24/05/07 10:02:51 INFO DAGScheduler: Missing parents: List()
	24/05/07 10:02:51 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[21] at save at JdbcWriter.java:87), which has no missing parents
	24/05/07 10:02:52 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 49.2 KiB, free 93.2 MiB)
	24/05/07 10:02:52 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 22.7 KiB, free 93.2 MiB)
	24/05/07 10:02:52 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 6461fa46f54d:39615 (size: 22.7 KiB, free: 93.3 MiB)
	24/05/07 10:02:52 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1585
	24/05/07 10:02:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[21] at save at JdbcWriter.java:87) (first 15 tasks are for partitions Vector(0))
	24/05/07 10:02:52 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks resource profile 0
	24/05/07 10:02:52 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 5) (6461fa46f54d, executor driver, partition 0, NODE_LOCAL, 8043 bytes) 
	24/05/07 10:02:52 INFO Executor: Running task 0.0 in stage 11.0 (TID 5)
	24/05/07 10:02:52 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
	24/05/07 10:02:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
	24/05/07 10:02:52 INFO CodeGenerator: Code generated in 22.18341 ms
	24/05/07 10:02:52 INFO CodeGenerator: Code generated in 9.269482 ms
	24/05/07 10:02:52 INFO Executor: Finished task 0.0 in stage 11.0 (TID 5). 6625 bytes result sent to driver
	24/05/07 10:02:52 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 5) in 84 ms on 6461fa46f54d (executor driver) (1/1)
	24/05/07 10:02:52 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
	24/05/07 10:02:52 INFO DAGScheduler: ResultStage 11 (save at JdbcWriter.java:87) finished in 0.124 s
	24/05/07 10:02:52 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
	24/05/07 10:02:52 INFO TaskSchedulerImpl: Killing all running tasks in stage 11: Stage finished
	24/05/07 10:02:52 INFO DAGScheduler: Job 5 finished: save at JdbcWriter.java:87, took 0.135869 s
	24/05/07 10:02:52 WARN FileSystem: Failed to initialize fileystem hdfs://mycluster:8020/user/default/data_quality_error_data/0_1059_%5Bnull%20check%5D%20filtered%20data%20persistence: java.lang.IllegalArgumentException: java.net.UnknownHostException: mycluster
	Exception in thread "main" java.lang.IllegalArgumentException: java.net.UnknownHostException: mycluster
		at org.apache.hadoop.security.SecurityUtil.buildTokenService(SecurityUtil.java:466)
		at org.apache.hadoop.hdfs.NameNodeProxiesClient.createProxyWithClientProtocol(NameNodeProxiesClient.java:134)
		at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:374)
		at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:308)
		at org.apache.hadoop.hdfs.DistributedFileSystem.initDFSClient(DistributedFileSystem.java:202)
		at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:187)
		at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469)
		at org.apache.hadoop.fs.FileSystem.access$300(FileSystem.java:174)
		at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3574)
		at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3521)
		at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540)
		at org.apache.hadoop.fs.Path.getFileSystem(Path.java:365)
		at org.apache.spark.sql.execution.datasources.DataSource.planForWritingFileFormat(DataSource.scala:454)
		at org.apache.spark.sql.execution.datasources.DataSource.planForWriting(DataSource.scala:530)
		at org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)
		at org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)
		at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:240)
		at org.apache.spark.sql.DataFrameWriter.csv(DataFrameWriter.scala:850)
		at org.apache.dolphinscheduler.data.quality.flow.batch.writer.file.BaseFileWriter.outputImpl(BaseFileWriter.java:114)
		at org.apache.dolphinscheduler.data.quality.flow.batch.writer.file.HdfsFileWriter.write(HdfsFileWriter.java:40)
		at org.apache.dolphinscheduler.data.quality.execution.SparkBatchExecution.executeWriter(SparkBatchExecution.java:132)
		at org.apache.dolphinscheduler.data.quality.execution.SparkBatchExecution.execute(SparkBatchExecution.java:58)
		at org.apache.dolphinscheduler.data.quality.context.DataQualityContext.execute(DataQualityContext.java:62)
		at org.apache.dolphinscheduler.data.quality.DataQualityApplication.main(DataQualityApplication.java:78)
		at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
		at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
		at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
		at java.lang.reflect.Method.invoke(Method.java:498)
		at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
		at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:1029)
		at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:194)
		at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:217)
		at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:91)
		at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1120)
		at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1129)
		at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
	Caused by: java.net.UnknownHostException: mycluster
		... 36 more
	24/05/07 10:02:52 INFO SparkContext: Invoking stop() from shutdown hook
	24/05/07 10:02:52 INFO SparkContext: SparkContext is stopping with exitCode 0.
	24/05/07 10:02:52 INFO SparkUI: Stopped Spark web UI at http://6461fa46f54d:4040
	24/05/07 10:02:52 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
	24/05/07 10:02:52 INFO MemoryStore: MemoryStore cleared
	24/05/07 10:02:52 INFO BlockManager: BlockManager stopped
	24/05/07 10:02:52 INFO BlockManagerMaster: BlockManagerMaster stopped
	24/05/07 10:02:52 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
	24/05/07 10:02:52 INFO SparkContext: Successfully stopped SparkContext
	24/05/07 10:02:52 INFO ShutdownHookManager: Shutdown hook called
	24/05/07 10:02:52 INFO ShutdownHookManager: Deleting directory /tmp/spark-40047faf-aaa6-4890-834d-c2600d8a772b
	24/05/07 10:02:52 INFO ShutdownHookManager: Deleting directory /tmp/spark-9e8846a4-6665-4868-8175-7dee23b8a090
[WI-1059][TI-3953] - [INFO] 2024-05-07 10:02:52.827 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13001194483488/13505298546272_21/1059/3953, processId:85 ,exitStatusCode:1 ,processWaitForStatus:true ,processExitValue:1
[WI-1059][TI-3953] - [INFO] 2024-05-07 10:02:52.827 +0800 o.a.d.p.t.a.u.LogUtils:[79] - Start finding appId in /opt/dolphinscheduler/logs/20240507/13505298546272/21/1059/3953.log, fetch way: log 
[WI-1059][TI-3953] - [INFO] 2024-05-07 10:02:52.836 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-1059][TI-3953] - [INFO] 2024-05-07 10:02:52.837 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-1059][TI-3953] - [INFO] 2024-05-07 10:02:52.837 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-1059][TI-3953] - [INFO] 2024-05-07 10:02:52.839 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-1059][TI-3953] - [INFO] 2024-05-07 10:02:52.846 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: FAILURE to master : 172.18.1.1:1234
[WI-1059][TI-3953] - [INFO] 2024-05-07 10:02:52.847 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-1059][TI-3953] - [INFO] 2024-05-07 10:02:52.848 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13001194483488/13505298546272_21/1059/3953
[WI-1059][TI-3953] - [INFO] 2024-05-07 10:02:52.858 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13001194483488/13505298546272_21/1059/3953
[WI-1059][TI-3953] - [INFO] 2024-05-07 10:02:52.861 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-3953] - [INFO] 2024-05-07 10:06:54.517 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=3953, processInstanceId=1059, status=6, startTime=1715047353681, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.11:5678, logPath=/opt/dolphinscheduler/logs/20240507/13505298546272/21/1059/3953.log, executePath=/tmp/dolphinscheduler/exec/process/default/13001194483488/13505298546272_21/1059/3953, endTime=1715047372838, processId=85, appIds=, varPool=[], eventCreateTime=0, eventSendTime=0)
[WI-0][TI-3953] - [INFO] 2024-05-07 10:06:54.535 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=3953, processInstanceId=1059, status=6, startTime=1715047353681, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.11:5678, logPath=/opt/dolphinscheduler/logs/20240507/13505298546272/21/1059/3953.log, executePath=/tmp/dolphinscheduler/exec/process/default/13001194483488/13505298546272_21/1059/3953, endTime=1715047372838, processId=85, appIds=, varPool=[], eventCreateTime=0, eventSendTime=1715047614517)
[WI-0][TI-0] - [WARN] 2024-05-07 10:22:37.223 +0800 o.s.c.k.c.p.AbstractKubernetesProfileEnvironmentPostProcessor:[258] - Not running inside kubernetes. Skipping 'kubernetes' profile activation.
[WI-0][TI-0] - [WARN] 2024-05-07 10:22:41.684 +0800 o.s.c.k.c.p.AbstractKubernetesProfileEnvironmentPostProcessor:[258] - Not running inside kubernetes. Skipping 'kubernetes' profile activation.
[WI-0][TI-0] - [INFO] 2024-05-07 10:22:41.690 +0800 o.a.d.s.w.WorkerServer:[634] - No active profile set, falling back to 1 default profile: "default"
[WI-0][TI-0] - [INFO] 2024-05-07 10:22:51.533 +0800 o.s.c.c.s.GenericScope:[283] - BeanFactory id=7e7bf7c6-2cb3-34d2-a0d5-a56161c67d0e
[WI-0][TI-0] - [INFO] 2024-05-07 10:22:53.594 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'org.springframework.cloud.commons.config.CommonsConfigAutoConfiguration' of type [org.springframework.cloud.commons.config.CommonsConfigAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-05-07 10:22:53.647 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'org.springframework.cloud.client.loadbalancer.LoadBalancerDefaultMappingsProviderAutoConfiguration' of type [org.springframework.cloud.client.loadbalancer.LoadBalancerDefaultMappingsProviderAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-05-07 10:22:53.653 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'loadBalancerClientsDefaultsMappingsProvider' of type [org.springframework.cloud.client.loadbalancer.LoadBalancerDefaultMappingsProviderAutoConfiguration$$Lambda$392/302905744] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-05-07 10:22:53.664 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'defaultsBindHandlerAdvisor' of type [org.springframework.cloud.commons.config.DefaultsBindHandlerAdvisor] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-05-07 10:22:53.715 +0800 o.a.d.c.u.NetUtils:[312] - Get all NetworkInterfaces: [name:eth0 (eth0), name:lo (lo)]
[WI-0][TI-0] - [INFO] 2024-05-07 10:22:54.258 +0800 o.a.d.s.w.c.WorkerConfig:[98] - 
****************************Worker Configuration**************************************
  listen-port -> 1234
  exec-threads -> 100
  max-heartbeat-interval -> PT10S
  host-weight -> 100
  tenantConfig -> TenantConfig(autoCreateTenantEnabled=true, distributedTenantEnabled=false, defaultTenantEnabled=false)
  server-load-protection -> WorkerServerLoadProtection(enabled=true, maxCpuUsagePercentageThresholds=0.7, maxJVMMemoryUsagePercentageThresholds=0.7, maxSystemMemoryUsagePercentageThresholds=0.7, maxDiskUsagePercentageThresholds=0.7)
  registry-disconnect-strategy -> ConnectStrategyProperties(strategy=WAITING, maxWaitingTime=PT1M40S)
  task-execute-threads-full-policy: REJECT
  address -> 172.18.1.1:1234
  registry-path: /nodes/worker/172.18.1.1:1234
****************************Worker Configuration**************************************
[WI-0][TI-0] - [INFO] 2024-05-07 10:22:54.259 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'workerConfig' of type [org.apache.dolphinscheduler.server.worker.config.WorkerConfig$$EnhancerBySpringCGLIB$$da954724] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-05-07 10:22:54.889 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'io.kubernetes.client.spring.extended.manifests.config.KubernetesManifestsAutoConfiguration' of type [io.kubernetes.client.spring.extended.manifests.config.KubernetesManifestsAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-05-07 10:22:55.018 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'kubernetes.manifests-io.kubernetes.client.spring.extended.manifests.config.KubernetesManifestsProperties' of type [io.kubernetes.client.spring.extended.manifests.config.KubernetesManifestsProperties] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-05-07 10:22:55.342 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'io.kubernetes.client.spring.extended.controller.config.KubernetesInformerAutoConfiguration' of type [io.kubernetes.client.spring.extended.controller.config.KubernetesInformerAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-05-07 10:22:55.411 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'defaultApiClient' of type [io.kubernetes.client.openapi.ApiClient] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-05-07 10:22:56.632 +0800 o.e.j.u.log:[170] - Logging initialized @36776ms to org.eclipse.jetty.util.log.Slf4jLog
[WI-0][TI-0] - [INFO] 2024-05-07 10:22:59.200 +0800 o.s.b.w.e.j.JettyServletWebServerFactory:[166] - Server initialized with port: 1235
[WI-0][TI-0] - [INFO] 2024-05-07 10:22:59.204 +0800 o.e.j.s.Server:[375] - jetty-9.4.48.v20220622; built: 2022-06-21T20:42:25.880Z; git: 6b67c5719d1f4371b33655ff2d047d24e171e49a; jvm 1.8.0_402-b06
[WI-0][TI-0] - [INFO] 2024-05-07 10:22:59.386 +0800 o.e.j.s.h.C.application:[2368] - Initializing Spring embedded WebApplicationContext
[WI-0][TI-0] - [INFO] 2024-05-07 10:22:59.387 +0800 o.s.b.w.s.c.ServletWebServerApplicationContext:[292] - Root WebApplicationContext: initialization completed in 17550 ms
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:03.443 +0800 o.e.j.s.session:[334] - DefaultSessionIdManager workerName=node0
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:03.444 +0800 o.e.j.s.session:[339] - No SessionScavenger set, using defaults
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:03.476 +0800 o.e.j.s.session:[132] - node0 Scavenging every 660000ms
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:03.648 +0800 o.e.j.s.h.ContextHandler:[921] - Started o.s.b.w.e.j.JettyEmbeddedWebAppContext@52433946{application,/,[file:///tmp/jetty-docbase.1235.8258803550455519496/],AVAILABLE}
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:03.649 +0800 o.e.j.s.Server:[415] - Started @43798ms
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:05.106 +0800 o.a.c.f.i.CuratorFrameworkImpl:[338] - Starting
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:05.134 +0800 o.a.z.ZooKeeper:[98] - Client environment:zookeeper.version=3.8.0-5a02a05eddb59aee6ac762f7ea82e92a68eb9c0f, built on 2022-02-25 08:49 UTC
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:05.135 +0800 o.a.z.ZooKeeper:[98] - Client environment:host.name=93296e29990d
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:05.138 +0800 o.a.z.ZooKeeper:[98] - Client environment:java.version=1.8.0_402
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:05.139 +0800 o.a.z.ZooKeeper:[98] - Client environment:java.vendor=Temurin
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:05.139 +0800 o.a.z.ZooKeeper:[98] - Client environment:java.home=/opt/java/openjdk
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:05.140 +0800 o.a.z.ZooKeeper:[98] - Client environment:java.class.path=/opt/dolphinscheduler/conf:/opt/dolphinscheduler/libs/kerb-client-1.0.1.jar:/opt/dolphinscheduler/libs/spring-cloud-starter-kubernetes-client-config-2.1.3.jar:/opt/dolphinscheduler/libs/oauth2-oidc-sdk-9.35.jar:/opt/dolphinscheduler/libs/jsqlparser-4.4.jar:/opt/dolphinscheduler/libs/reactive-streams-1.0.4.jar:/opt/dolphinscheduler/libs/kubernetes-model-extensions-5.10.2.jar:/opt/dolphinscheduler/libs/zookeeper-3.8.0.jar:/opt/dolphinscheduler/libs/kubernetes-model-apps-5.10.2.jar:/opt/dolphinscheduler/libs/grpc-api-1.41.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-pigeon-3.2.1.jar:/opt/dolphinscheduler/libs/client-java-api-13.0.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-obs-3.2.1.jar:/opt/dolphinscheduler/libs/spring-web-5.3.22.jar:/opt/dolphinscheduler/libs/aws-java-sdk-emr-1.12.300.jar:/opt/dolphinscheduler/libs/spring-context-5.3.22.jar:/opt/dolphinscheduler/libs/gapic-google-cloud-storage-v2-2.18.0-alpha.jar:/opt/dolphinscheduler/libs/spring-cloud-kubernetes-client-config-2.1.3.jar:/opt/dolphinscheduler/libs/jetty-io-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/annotations-13.0.jar:/opt/dolphinscheduler/libs/jpam-1.1.jar:/opt/dolphinscheduler/libs/joda-time-2.10.13.jar:/opt/dolphinscheduler/libs/spring-cloud-kubernetes-client-autoconfig-2.1.3.jar:/opt/dolphinscheduler/libs/kerb-identity-1.0.1.jar:/opt/dolphinscheduler/libs/vertica-jdbc-12.0.4-0.jar:/opt/dolphinscheduler/libs/grpc-googleapis-1.52.1.jar:/opt/dolphinscheduler/libs/aliyun-java-sdk-kms-2.11.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-dvc-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-hana-3.2.1.jar:/opt/dolphinscheduler/libs/kubernetes-httpclient-okhttp-6.0.0.jar:/opt/dolphinscheduler/libs/jline-2.12.jar:/opt/dolphinscheduler/libs/sshd-core-2.8.0.jar:/opt/dolphinscheduler/libs/jna-platform-5.10.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-sqlserver-3.2.1.jar:/opt/dolphinscheduler/libs/commons-beanutils-1.9.4.jar:/opt/dolphinscheduler/libs/grpc-services-1.41.0.jar:/opt/dolphinscheduler/libs/jmespath-java-1.12.300.jar:/opt/dolphinscheduler/libs/curator-client-5.3.0.jar:/opt/dolphinscheduler/libs/proto-google-common-protos-2.0.1.jar:/opt/dolphinscheduler/libs/mybatis-3.5.10.jar:/opt/dolphinscheduler/libs/jackson-annotations-2.13.4.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-all-3.2.1.jar:/opt/dolphinscheduler/libs/jakarta.xml.bind-api-2.3.3.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-jupyter-3.2.1.jar:/opt/dolphinscheduler/libs/mybatis-plus-extension-3.5.2.jar:/opt/dolphinscheduler/libs/j2objc-annotations-1.3.jar:/opt/dolphinscheduler/libs/Java-WebSocket-1.5.1.jar:/opt/dolphinscheduler/libs/azure-storage-common-12.20.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-sagemaker-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-databend-3.2.1.jar:/opt/dolphinscheduler/libs/google-auth-library-oauth2-http-1.15.0.jar:/opt/dolphinscheduler/libs/jetty-security-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-python-3.2.1.jar:/opt/dolphinscheduler/libs/snappy-java-1.1.10.1.jar:/opt/dolphinscheduler/libs/kubernetes-model-batch-5.10.2.jar:/opt/dolphinscheduler/libs/netty-transport-native-epoll-4.1.53.Final-linux-x86_64.jar:/opt/dolphinscheduler/libs/jackson-core-asl-1.9.13.jar:/opt/dolphinscheduler/libs/gson-fire-1.8.5.jar:/opt/dolphinscheduler/libs/clickhouse-jdbc-0.4.6.jar:/opt/dolphinscheduler/libs/grpc-netty-shaded-1.41.0.jar:/opt/dolphinscheduler/libs/caffeine-2.9.3.jar:/opt/dolphinscheduler/libs/aliyun-java-sdk-core-4.5.10.jar:/opt/dolphinscheduler/libs/jackson-module-jaxb-annotations-2.13.3.jar:/opt/dolphinscheduler/libs/jetty-http-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/jersey-servlet-1.19.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-dinky-3.2.1.jar:/opt/dolphinscheduler/libs/simpleclient_tracer_common-0.15.0.jar:/opt/dolphinscheduler/libs/netty-handler-4.1.53.Final.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-datafactory-3.2.1.jar:/opt/dolphinscheduler/libs/json-path-2.7.0.jar:/opt/dolphinscheduler/libs/mybatis-plus-annotation-3.5.2.jar:/opt/dolphinscheduler/libs/azure-resourcemanager-datafactory-1.0.0-beta.19.jar:/opt/dolphinscheduler/libs/commons-codec-1.11.jar:/opt/dolphinscheduler/libs/dolphinscheduler-extract-master-3.2.1.jar:/opt/dolphinscheduler/libs/spring-aop-5.3.22.jar:/opt/dolphinscheduler/libs/kubernetes-model-core-5.10.2.jar:/opt/dolphinscheduler/libs/kubernetes-model-networking-5.10.2.jar:/opt/dolphinscheduler/libs/kotlin-stdlib-jdk7-1.6.21.jar:/opt/dolphinscheduler/libs/kerby-xdr-1.0.1.jar:/opt/dolphinscheduler/libs/aliyun-java-sdk-ram-3.1.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-k8s-3.2.1.jar:/opt/dolphinscheduler/libs/guava-31.1-jre.jar:/opt/dolphinscheduler/libs/netty-codec-dns-4.1.53.Final.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-kubeflow-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-azure-sql-3.2.1.jar:/opt/dolphinscheduler/libs/HikariCP-4.0.3.jar:/opt/dolphinscheduler/libs/hive-metastore-2.3.9.jar:/opt/dolphinscheduler/libs/msal4j-1.13.3.jar:/opt/dolphinscheduler/libs/jackson-core-2.13.4.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-hive-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-mr-3.2.1.jar:/opt/dolphinscheduler/libs/kubernetes-model-node-5.10.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-common-3.2.1.jar:/opt/dolphinscheduler/libs/jose4j-0.7.8.jar:/opt/dolphinscheduler/libs/jul-to-slf4j-1.7.36.jar:/opt/dolphinscheduler/libs/azure-identity-1.7.1.jar:/opt/dolphinscheduler/libs/spring-boot-autoconfigure-2.7.3.jar:/opt/dolphinscheduler/libs/commons-math3-3.1.1.jar:/opt/dolphinscheduler/libs/jackson-jaxrs-json-provider-2.13.3.jar:/opt/dolphinscheduler/libs/perfmark-api-0.23.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-doris-3.2.1.jar:/opt/dolphinscheduler/libs/httpclient-4.5.13.jar:/opt/dolphinscheduler/libs/hive-service-2.3.9.jar:/opt/dolphinscheduler/libs/kerby-util-1.0.1.jar:/opt/dolphinscheduler/libs/commons-collections-3.2.2.jar:/opt/dolphinscheduler/libs/hadoop-yarn-client-3.2.4.jar:/opt/dolphinscheduler/libs/commons-text-1.8.jar:/opt/dolphinscheduler/libs/dolphinscheduler-worker-3.2.1.jar:/opt/dolphinscheduler/libs/hadoop-yarn-common-3.2.4.jar:/opt/dolphinscheduler/libs/zeppelin-client-0.10.1.jar:/opt/dolphinscheduler/libs/azure-core-management-1.10.1.jar:/opt/dolphinscheduler/libs/hadoop-mapreduce-client-jobclient-3.2.4.jar:/opt/dolphinscheduler/libs/jta-1.1.jar:/opt/dolphinscheduler/libs/annotations-4.1.1.4.jar:/opt/dolphinscheduler/libs/dolphinscheduler-extract-alert-3.2.1.jar:/opt/dolphinscheduler/libs/curator-framework-5.3.0.jar:/opt/dolphinscheduler/libs/hive-jdbc-2.3.9.jar:/opt/dolphinscheduler/libs/kyuubi-hive-jdbc-shaded-1.7.0.jar:/opt/dolphinscheduler/libs/client-java-proto-13.0.2.jar:/opt/dolphinscheduler/libs/checker-qual-3.19.0.jar:/opt/dolphinscheduler/libs/jetty-servlet-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/google-cloud-core-grpc-2.10.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-shell-3.2.1.jar:/opt/dolphinscheduler/libs/spring-security-rsa-1.0.10.RELEASE.jar:/opt/dolphinscheduler/libs/avro-1.7.7.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-postgresql-3.2.1.jar:/opt/dolphinscheduler/libs/netty-nio-client-2.17.282.jar:/opt/dolphinscheduler/libs/spring-webmvc-5.3.22.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-mysql-3.2.1.jar:/opt/dolphinscheduler/libs/opentracing-util-0.33.0.jar:/opt/dolphinscheduler/libs/auto-value-1.10.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-all-3.2.1.jar:/opt/dolphinscheduler/libs/jetcd-core-0.5.11.jar:/opt/dolphinscheduler/libs/grpc-context-1.41.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-datasync-3.2.1.jar:/opt/dolphinscheduler/libs/jackson-dataformat-cbor-2.13.3.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-gcs-3.2.1.jar:/opt/dolphinscheduler/libs/client-java-extended-13.0.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-redshift-3.2.1.jar:/opt/dolphinscheduler/libs/opencsv-2.3.jar:/opt/dolphinscheduler/libs/jcip-annotations-1.0-1.jar:/opt/dolphinscheduler/libs/accessors-smart-2.4.8.jar:/opt/dolphinscheduler/libs/hadoop-client-3.2.4.jar:/opt/dolphinscheduler/libs/commons-collections4-4.3.jar:/opt/dolphinscheduler/libs/metrics-core-4.2.11.jar:/opt/dolphinscheduler/libs/netty-resolver-4.1.53.Final.jar:/opt/dolphinscheduler/libs/parquet-hadoop-bundle-1.8.1.jar:/opt/dolphinscheduler/libs/bucket4j-core-6.2.0.jar:/opt/dolphinscheduler/libs/spring-cloud-starter-3.1.3.jar:/opt/dolphinscheduler/libs/mssql-jdbc-11.2.1.jre8.jar:/opt/dolphinscheduler/libs/netty-tcnative-boringssl-static-2.0.53.Final.jar:/opt/dolphinscheduler/libs/kubernetes-model-coordination-5.10.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-linkis-3.2.1.jar:/opt/dolphinscheduler/libs/commons-net-3.6.jar:/opt/dolphinscheduler/libs/netty-transport-native-kqueue-4.1.53.Final-osx-x86_64.jar:/opt/dolphinscheduler/libs/dolphinscheduler-meter-3.2.1.jar:/opt/dolphinscheduler/libs/kubernetes-client-api-6.0.0.jar:/opt/dolphinscheduler/libs/kubernetes-model-certificates-5.10.2.jar:/opt/dolphinscheduler/libs/opencensus-api-0.31.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-mlflow-3.2.1.jar:/opt/dolphinscheduler/libs/kotlin-stdlib-jdk8-1.6.21.jar:/opt/dolphinscheduler/libs/dolphinscheduler-registry-jdbc-3.2.1.jar:/opt/dolphinscheduler/libs/audience-annotations-0.12.0.jar:/opt/dolphinscheduler/libs/simpleclient_httpserver-0.15.0.jar:/opt/dolphinscheduler/libs/jetty-xml-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/kerby-asn1-1.0.1.jar:/opt/dolphinscheduler/libs/lang-tag-1.6.jar:/opt/dolphinscheduler/libs/api-common-2.6.0.jar:/opt/dolphinscheduler/libs/HdrHistogram-2.1.12.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-abs-3.2.1.jar:/opt/dolphinscheduler/libs/failsafe-2.4.4.jar:/opt/dolphinscheduler/libs/hbase-noop-htrace-4.1.1.jar:/opt/dolphinscheduler/libs/jamon-runtime-2.3.1.jar:/opt/dolphinscheduler/libs/jetty-util-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/threetenbp-1.6.5.jar:/opt/dolphinscheduler/libs/jakarta.activation-api-1.2.2.jar:/opt/dolphinscheduler/libs/kubernetes-model-common-5.10.2.jar:/opt/dolphinscheduler/libs/okhttp-4.9.3.jar:/opt/dolphinscheduler/libs/profiles-2.17.282.jar:/opt/dolphinscheduler/libs/hadoop-auth-3.2.4.jar:/opt/dolphinscheduler/libs/grpc-netty-1.41.0.jar:/opt/dolphinscheduler/libs/httpcore-nio-4.4.15.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-seatunnel-3.2.1.jar:/opt/dolphinscheduler/libs/aws-java-sdk-sagemaker-1.12.300.jar:/opt/dolphinscheduler/libs/oshi-core-6.1.1.jar:/opt/dolphinscheduler/libs/bonecp-0.8.0.RELEASE.jar:/opt/dolphinscheduler/libs/jackson-module-parameter-names-2.13.3.jar:/opt/dolphinscheduler/libs/bcutil-jdk15on-1.69.jar:/opt/dolphinscheduler/libs/aws-json-protocol-2.17.282.jar:/opt/dolphinscheduler/libs/dolphinscheduler-extract-base-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-all-3.2.1.jar:/opt/dolphinscheduler/libs/derby-10.14.2.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-snowflake-3.2.1.jar:/opt/dolphinscheduler/libs/netty-codec-http2-4.1.53.Final.jar:/opt/dolphinscheduler/libs/jetty-continuation-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/jackson-mapper-asl-1.9.13.jar:/opt/dolphinscheduler/libs/datanucleus-core-4.1.17.jar:/opt/dolphinscheduler/libs/netty-tcnative-boringssl-static-2.0.53.Final-osx-aarch_64.jar:/opt/dolphinscheduler/libs/failureaccess-1.0.1.jar:/opt/dolphinscheduler/libs/error_prone_annotations-2.5.1.jar:/opt/dolphinscheduler/libs/kerb-admin-1.0.1.jar:/opt/dolphinscheduler/libs/token-provider-1.0.1.jar:/opt/dolphinscheduler/libs/reactor-netty-core-1.0.22.jar:/opt/dolphinscheduler/libs/dolphinscheduler-registry-all-3.2.1.jar:/opt/dolphinscheduler/libs/jakarta.servlet-api-4.0.4.jar:/opt/dolphinscheduler/libs/http-client-spi-2.17.282.jar:/opt/dolphinscheduler/libs/regions-2.17.282.jar:/opt/dolphinscheduler/libs/logback-core-1.2.11.jar:/opt/dolphinscheduler/libs/json-1.8.jar:/opt/dolphinscheduler/libs/gax-grpc-2.23.0.jar:/opt/dolphinscheduler/libs/google-http-client-1.42.3.jar:/opt/dolphinscheduler/libs/hive-serde-2.3.9.jar:/opt/dolphinscheduler/libs/jettison-1.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-http-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-registry-zookeeper-3.2.1.jar:/opt/dolphinscheduler/libs/spring-security-crypto-5.7.3.jar:/opt/dolphinscheduler/libs/auth-2.17.282.jar:/opt/dolphinscheduler/libs/proto-google-cloud-storage-v2-2.18.0-alpha.jar:/opt/dolphinscheduler/libs/jetty-server-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/javax.annotation-api-1.3.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-starrocks-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-dataquality-3.2.1.jar:/opt/dolphinscheduler/libs/jcl-over-slf4j-1.7.36.jar:/opt/dolphinscheduler/libs/commons-lang3-3.12.0.jar:/opt/dolphinscheduler/libs/tomcat-embed-el-9.0.65.jar:/opt/dolphinscheduler/libs/opentracing-noop-0.33.0.jar:/opt/dolphinscheduler/libs/client-java-13.0.2.jar:/opt/dolphinscheduler/libs/spring-beans-5.3.22.jar:/opt/dolphinscheduler/libs/snakeyaml-1.33.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-ssh-3.2.1.jar:/opt/dolphinscheduler/libs/commons-pool-1.6.jar:/opt/dolphinscheduler/libs/javax.servlet-api-3.1.0.jar:/opt/dolphinscheduler/libs/hadoop-common-3.2.4.jar:/opt/dolphinscheduler/libs/kubernetes-model-apiextensions-5.10.2.jar:/opt/dolphinscheduler/libs/spring-boot-2.7.3.jar:/opt/dolphinscheduler/libs/bcprov-ext-jdk15on-1.69.jar:/opt/dolphinscheduler/libs/spring-boot-starter-2.7.3.jar:/opt/dolphinscheduler/libs/paranamer-2.3.jar:/opt/dolphinscheduler/libs/httpmime-4.5.13.jar:/opt/dolphinscheduler/libs/reactor-core-3.4.22.jar:/opt/dolphinscheduler/libs/azure-core-1.36.0.jar:/opt/dolphinscheduler/libs/bcpkix-jdk15on-1.69.jar:/opt/dolphinscheduler/libs/kubernetes-model-scheduling-5.10.2.jar:/opt/dolphinscheduler/libs/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/dolphinscheduler/libs/websocket-client-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/unirest-java-3.7.04-standalone.jar:/opt/dolphinscheduler/libs/hadoop-mapreduce-client-core-3.2.4.jar:/opt/dolphinscheduler/libs/google-auth-library-credentials-1.15.0.jar:/opt/dolphinscheduler/libs/azure-storage-internal-avro-12.6.0.jar:/opt/dolphinscheduler/libs/jackson-datatype-jdk8-2.13.3.jar:/opt/dolphinscheduler/libs/spring-expression-5.3.22.jar:/opt/dolphinscheduler/libs/aspectjweaver-1.9.7.jar:/opt/dolphinscheduler/libs/websocket-common-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/client-java-api-fluent-13.0.2.jar:/opt/dolphinscheduler/libs/mybatis-plus-3.5.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-athena-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-oss-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-openmldb-3.2.1.jar:/opt/dolphinscheduler/libs/curator-recipes-5.3.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-api-3.2.1.jar:/opt/dolphinscheduler/libs/netty-all-4.1.53.Final.jar:/opt/dolphinscheduler/libs/netty-resolver-dns-4.1.53.Final.jar:/opt/dolphinscheduler/libs/kubernetes-model-autoscaling-5.10.2.jar:/opt/dolphinscheduler/libs/kerb-util-1.0.1.jar:/opt/dolphinscheduler/libs/grpc-alts-1.41.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-presto-3.2.1.jar:/opt/dolphinscheduler/libs/kerb-simplekdc-1.0.1.jar:/opt/dolphinscheduler/libs/protobuf-java-util-3.17.2.jar:/opt/dolphinscheduler/libs/azure-core-http-netty-1.13.0.jar:/opt/dolphinscheduler/libs/transaction-api-1.1.jar:/opt/dolphinscheduler/libs/datanucleus-api-jdo-4.2.4.jar:/opt/dolphinscheduler/libs/zeppelin-common-0.10.1.jar:/opt/dolphinscheduler/libs/zt-zip-1.15.jar:/opt/dolphinscheduler/libs/animal-sniffer-annotations-1.19.jar:/opt/dolphinscheduler/libs/google-http-client-jackson2-1.42.3.jar:/opt/dolphinscheduler/libs/netty-buffer-4.1.53.Final.jar:/opt/dolphinscheduler/libs/jsr305-3.0.0.jar:/opt/dolphinscheduler/libs/netty-transport-classes-epoll-4.1.79.Final.jar:/opt/dolphinscheduler/libs/spring-boot-actuator-autoconfigure-2.7.3.jar:/opt/dolphinscheduler/libs/simpleclient-0.15.0.jar:/opt/dolphinscheduler/libs/aliyun-sdk-oss-3.15.1.jar:/opt/dolphinscheduler/libs/json-utils-2.17.282.jar:/opt/dolphinscheduler/libs/tephra-api-0.6.0.jar:/opt/dolphinscheduler/libs/spring-jdbc-5.3.22.jar:/opt/dolphinscheduler/libs/grpc-xds-1.41.0.jar:/opt/dolphinscheduler/libs/logback-classic-1.2.11.jar:/opt/dolphinscheduler/libs/google-cloud-storage-2.18.0.jar:/opt/dolphinscheduler/libs/micrometer-registry-prometheus-1.9.3.jar:/opt/dolphinscheduler/libs/grpc-core-1.41.0.jar:/opt/dolphinscheduler/libs/aws-java-sdk-kms-1.12.300.jar:/opt/dolphinscheduler/libs/kubernetes-model-rbac-5.10.2.jar:/opt/dolphinscheduler/libs/ini4j-0.5.4.jar:/opt/dolphinscheduler/libs/spring-boot-starter-web-2.7.3.jar:/opt/dolphinscheduler/libs/spring-cloud-commons-3.1.3.jar:/opt/dolphinscheduler/libs/netty-codec-http-4.1.53.Final.jar:/opt/dolphinscheduler/libs/jetty-client-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/jetcd-common-0.5.11.jar:/opt/dolphinscheduler/libs/metrics-spi-2.17.282.jar:/opt/dolphinscheduler/libs/utils-2.17.282.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-emr-3.2.1.jar:/opt/dolphinscheduler/libs/protocol-core-2.17.282.jar:/opt/dolphinscheduler/libs/micrometer-core-1.9.3.jar:/opt/dolphinscheduler/libs/netty-transport-native-unix-common-4.1.53.Final.jar:/opt/dolphinscheduler/libs/zjsonpatch-0.4.11.jar:/opt/dolphinscheduler/libs/annotations-2.17.282.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-sql-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-extract-common-3.2.1.jar:/opt/dolphinscheduler/libs/apache-client-2.17.282.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-oceanbase-3.2.1.jar:/opt/dolphinscheduler/libs/jdo-api-3.0.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-datax-3.2.1.jar:/opt/dolphinscheduler/libs/postgresql-42.4.1.jar:/opt/dolphinscheduler/libs/jetty-util-ajax-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/gax-2.23.0.jar:/opt/dolphinscheduler/libs/grpc-stub-1.41.0.jar:/opt/dolphinscheduler/libs/libfb303-0.9.3.jar:/opt/dolphinscheduler/libs/spring-core-5.3.22.jar:/opt/dolphinscheduler/libs/jaxb-api-2.3.1.jar:/opt/dolphinscheduler/libs/hive-service-rpc-2.3.9.jar:/opt/dolphinscheduler/libs/kubernetes-model-flowcontrol-5.10.2.jar:/opt/dolphinscheduler/libs/commons-logging-1.1.1.jar:/opt/dolphinscheduler/libs/mybatis-spring-2.0.7.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-oracle-3.2.1.jar:/opt/dolphinscheduler/libs/opencensus-proto-0.2.0.jar:/opt/dolphinscheduler/libs/grpc-protobuf-1.41.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-clickhouse-3.2.1.jar:/opt/dolphinscheduler/libs/spring-cloud-starter-bootstrap-3.1.3.jar:/opt/dolphinscheduler/libs/kubernetes-model-admissionregistration-5.10.2.jar:/opt/dolphinscheduler/libs/grpc-google-cloud-storage-v2-2.18.0-alpha.jar:/opt/dolphinscheduler/libs/esdk-obs-java-bundle-3.23.3.jar:/opt/dolphinscheduler/libs/dnsjava-2.1.7.jar:/opt/dolphinscheduler/libs/asm-9.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-spark-3.2.1.jar:/opt/dolphinscheduler/libs/netty-tcnative-boringssl-static-2.0.53.Final-linux-aarch_64.jar:/opt/dolphinscheduler/libs/re2j-1.6.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-vertica-3.2.1.jar:/opt/dolphinscheduler/libs/json-smart-2.4.8.jar:/opt/dolphinscheduler/libs/reactor-netty-http-1.0.22.jar:/opt/dolphinscheduler/libs/google-api-services-storage-v1-rev20220705-2.0.0.jar:/opt/dolphinscheduler/libs/kubernetes-client-6.0.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-kyuubi-3.2.1.jar:/opt/dolphinscheduler/libs/auto-value-annotations-1.10.1.jar:/opt/dolphinscheduler/libs/commons-cli-1.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-data-quality-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-chunjun-3.2.1.jar:/opt/dolphinscheduler/libs/kerb-server-1.0.1.jar:/opt/dolphinscheduler/libs/content-type-2.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-remoteshell-3.2.1.jar:/opt/dolphinscheduler/libs/opencensus-contrib-http-util-0.31.1.jar:/opt/dolphinscheduler/libs/druid-1.2.20.jar:/opt/dolphinscheduler/libs/javolution-5.5.1.jar:/opt/dolphinscheduler/libs/protobuf-java-3.17.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-db2-3.2.1.jar:/opt/dolphinscheduler/libs/aws-java-sdk-core-1.12.300.jar:/opt/dolphinscheduler/libs/spring-boot-starter-logging-2.7.3.jar:/opt/dolphinscheduler/libs/kerby-pkix-1.0.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-procedure-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-registry-etcd-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-sqoop-3.2.1.jar:/opt/dolphinscheduler/libs/zookeeper-jute-3.8.0.jar:/opt/dolphinscheduler/libs/netty-resolver-dns-native-macos-4.1.53.Final-osx-x86_64.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-sagemaker-3.2.1.jar:/opt/dolphinscheduler/libs/spring-boot-configuration-processor-2.6.1.jar:/opt/dolphinscheduler/libs/hive-common-2.3.9.jar:/opt/dolphinscheduler/libs/kerb-common-1.0.1.jar:/opt/dolphinscheduler/libs/stax-api-1.0.1.jar:/opt/dolphinscheduler/libs/kubernetes-model-storageclass-5.10.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-s3-3.2.1.jar:/opt/dolphinscheduler/libs/spring-boot-starter-jetty-2.7.3.jar:/opt/dolphinscheduler/libs/okio-2.8.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-dms-3.2.1.jar:/opt/dolphinscheduler/libs/simpleclient_common-0.15.0.jar:/opt/dolphinscheduler/libs/sdk-core-2.17.282.jar:/opt/dolphinscheduler/libs/javax.activation-api-1.2.0.jar:/opt/dolphinscheduler/libs/netty-handler-proxy-4.1.53.Final.jar:/opt/dolphinscheduler/libs/kerby-config-1.0.1.jar:/opt/dolphinscheduler/libs/netty-tcnative-classes-2.0.53.Final.jar:/opt/dolphinscheduler/libs/jackson-jaxrs-base-2.13.3.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-trino-3.2.1.jar:/opt/dolphinscheduler/libs/presto-jdbc-0.238.1.jar:/opt/dolphinscheduler/libs/websocket-api-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-flink-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-api-3.2.1.jar:/opt/dolphinscheduler/libs/kubernetes-model-metrics-5.10.2.jar:/opt/dolphinscheduler/libs/datasync-2.17.282.jar:/opt/dolphinscheduler/libs/hadoop-yarn-api-3.2.4.jar:/opt/dolphinscheduler/libs/google-http-client-apache-v2-1.42.3.jar:/opt/dolphinscheduler/libs/hadoop-annotations-3.2.4.jar:/opt/dolphinscheduler/libs/google-oauth-client-1.34.1.jar:/opt/dolphinscheduler/libs/sshd-common-2.8.0.jar:/opt/dolphinscheduler/libs/LatencyUtils-2.0.3.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-spark-3.2.1.jar:/opt/dolphinscheduler/libs/slf4j-api-1.7.36.jar:/opt/dolphinscheduler/libs/snowflake-jdbc-3.13.29.jar:/opt/dolphinscheduler/libs/jackson-datatype-jsr310-2.13.3.jar:/opt/dolphinscheduler/libs/trino-jdbc-402.jar:/opt/dolphinscheduler/libs/logging-interceptor-4.9.3.jar:/opt/dolphinscheduler/libs/simpleclient_tracer_otel_agent-0.15.0.jar:/opt/dolphinscheduler/libs/janino-3.0.16.jar:/opt/dolphinscheduler/libs/jackson-dataformat-yaml-2.13.3.jar:/opt/dolphinscheduler/libs/ion-java-1.0.2.jar:/opt/dolphinscheduler/libs/commons-dbcp-1.4.jar:/opt/dolphinscheduler/libs/jsp-api-2.1.jar:/opt/dolphinscheduler/libs/google-http-client-gson-1.42.3.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-hivecli-3.2.1.jar:/opt/dolphinscheduler/libs/spring-boot-actuator-2.7.3.jar:/opt/dolphinscheduler/libs/google-cloud-core-http-2.10.0.jar:/opt/dolphinscheduler/libs/DmJdbcDriver18-8.1.2.79.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-java-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-dameng-3.2.1.jar:/opt/dolphinscheduler/libs/sshd-sftp-2.8.0.jar:/opt/dolphinscheduler/libs/kerb-crypto-1.0.1.jar:/opt/dolphinscheduler/libs/conscrypt-openjdk-uber-2.5.2.jar:/opt/dolphinscheduler/libs/httpcore-4.4.15.jar:/opt/dolphinscheduler/libs/lz4-java-1.4.0.jar:/opt/dolphinscheduler/libs/guava-retrying-2.0.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-flink-stream-3.2.1.jar:/opt/dolphinscheduler/libs/spring-tx-5.3.22.jar:/opt/dolphinscheduler/libs/grpc-auth-1.41.0.jar:/opt/dolphinscheduler/libs/netty-tcnative-boringssl-static-2.0.53.Final-osx-x86_64.jar:/opt/dolphinscheduler/libs/databend-jdbc-0.0.7.jar:/opt/dolphinscheduler/libs/bcprov-jdk15on-1.69.jar:/opt/dolphinscheduler/libs/commons-lang-2.6.jar:/opt/dolphinscheduler/libs/kubernetes-model-policy-5.10.2.jar:/opt/dolphinscheduler/libs/commons-io-2.11.0.jar:/opt/dolphinscheduler/libs/grpc-grpclb-1.41.0.jar:/opt/dolphinscheduler/libs/netty-tcnative-boringssl-static-2.0.53.Final-linux-x86_64.jar:/opt/dolphinscheduler/libs/opentracing-api-0.33.0.jar:/opt/dolphinscheduler/libs/sshd-scp-2.8.0.jar:/opt/dolphinscheduler/libs/reload4j-1.2.18.3.jar:/opt/dolphinscheduler/libs/netty-tcnative-2.0.48.Final.jar:/opt/dolphinscheduler/libs/jdom2-2.0.6.1.jar:/opt/dolphinscheduler/libs/spring-boot-starter-json-2.7.3.jar:/opt/dolphinscheduler/libs/netty-transport-native-epoll-4.1.53.Final.jar:/opt/dolphinscheduler/libs/google-cloud-core-2.10.0.jar:/opt/dolphinscheduler/libs/javax.jdo-3.2.0-m3.jar:/opt/dolphinscheduler/libs/gax-httpjson-0.108.0.jar:/opt/dolphinscheduler/libs/mybatis-plus-core-3.5.2.jar:/opt/dolphinscheduler/libs/auto-service-annotations-1.0.1.jar:/opt/dolphinscheduler/libs/nimbus-jose-jwt-9.22.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-zeppelin-3.2.1.jar:/opt/dolphinscheduler/libs/commons-compress-1.21.jar:/opt/dolphinscheduler/libs/hadoop-hdfs-client-3.2.4.jar:/opt/dolphinscheduler/libs/msal4j-persistence-extension-1.1.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-pytorch-3.2.1.jar:/opt/dolphinscheduler/libs/netty-tcnative-boringssl-static-2.0.53.Final-windows-x86_64.jar:/opt/dolphinscheduler/libs/jetty-servlets-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/woodstox-core-6.4.0.jar:/opt/dolphinscheduler/libs/spring-cloud-kubernetes-commons-2.1.3.jar:/opt/dolphinscheduler/libs/grpc-protobuf-lite-1.41.0.jar:/opt/dolphinscheduler/libs/jetty-webapp-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/eventstream-1.0.1.jar:/opt/dolphinscheduler/libs/commons-compiler-3.1.7.jar:/opt/dolphinscheduler/libs/netty-transport-4.1.53.Final.jar:/opt/dolphinscheduler/libs/spring-cloud-context-3.1.3.jar:/opt/dolphinscheduler/libs/aws-java-sdk-dms-1.12.300.jar:/opt/dolphinscheduler/libs/hive-storage-api-2.4.0.jar:/opt/dolphinscheduler/libs/client-java-spring-integration-13.0.2.jar:/opt/dolphinscheduler/libs/spring-boot-starter-actuator-2.7.3.jar:/opt/dolphinscheduler/libs/third-party-jackson-core-2.17.282.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-hdfs-3.2.1.jar:/opt/dolphinscheduler/libs/netty-codec-4.1.53.Final.jar:/opt/dolphinscheduler/libs/google-http-client-appengine-1.42.3.jar:/opt/dolphinscheduler/libs/commons-configuration2-2.1.1.jar:/opt/dolphinscheduler/libs/datanucleus-rdbms-4.1.19.jar:/opt/dolphinscheduler/libs/swagger-annotations-1.6.2.jar:/opt/dolphinscheduler/libs/simpleclient_tracer_otel-0.15.0.jar:/opt/dolphinscheduler/libs/kotlin-stdlib-common-1.6.21.jar:/opt/dolphinscheduler/libs/aws-core-2.17.282.jar:/opt/dolphinscheduler/libs/kerb-core-1.0.1.jar:/opt/dolphinscheduler/libs/httpasyncclient-4.1.5.jar:/opt/dolphinscheduler/libs/dolphinscheduler-extract-worker-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-spi-3.2.1.jar:/opt/dolphinscheduler/libs/okhttp-2.7.5.jar:/opt/dolphinscheduler/libs/google-api-client-2.2.0.jar:/opt/dolphinscheduler/libs/kotlin-stdlib-1.6.21.jar:/opt/dolphinscheduler/libs/jakarta.websocket-api-1.1.2.jar:/opt/dolphinscheduler/libs/libthrift-0.9.3.jar:/opt/dolphinscheduler/libs/spring-boot-starter-aop-2.7.3.jar:/opt/dolphinscheduler/libs/netty-common-4.1.53.Final.jar:/opt/dolphinscheduler/libs/log4j-1.2-api-2.17.2.jar:/opt/dolphinscheduler/libs/jackson-databind-2.13.4.jar:/opt/dolphinscheduler/libs/jackson-dataformat-xml-2.13.3.jar:/opt/dolphinscheduler/libs/kubernetes-model-events-5.10.2.jar:/opt/dolphinscheduler/libs/gson-2.9.1.jar:/opt/dolphinscheduler/libs/proto-google-iam-v1-1.9.0.jar:/opt/dolphinscheduler/libs/netty-codec-socks-4.1.53.Final.jar:/opt/dolphinscheduler/libs/zjsonpatch-0.3.0.jar:/opt/dolphinscheduler/libs/hadoop-mapreduce-client-common-3.2.4.jar:/opt/dolphinscheduler/libs/dolphinscheduler-registry-api-3.2.1.jar:/opt/dolphinscheduler/libs/azure-storage-blob-12.21.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-zeppelin-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-api-3.2.1.jar:/opt/dolphinscheduler/libs/aws-java-sdk-s3-1.12.300.jar:/opt/dolphinscheduler/libs/stax2-api-4.2.1.jar:/opt/dolphinscheduler/libs/jakarta.annotation-api-1.3.5.jar:/opt/dolphinscheduler/libs/kubernetes-model-discovery-5.10.2.jar:/opt/dolphinscheduler/libs/jna-5.10.0.jar:/opt/dolphinscheduler/libs/spring-jcl-5.3.22.jar
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:05.141 +0800 o.a.z.ZooKeeper:[98] - Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:05.142 +0800 o.a.z.ZooKeeper:[98] - Client environment:java.io.tmpdir=/tmp
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:05.142 +0800 o.a.z.ZooKeeper:[98] - Client environment:java.compiler=<NA>
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:05.142 +0800 o.a.z.ZooKeeper:[98] - Client environment:os.name=Linux
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:05.142 +0800 o.a.z.ZooKeeper:[98] - Client environment:os.arch=amd64
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:05.142 +0800 o.a.z.ZooKeeper:[98] - Client environment:os.version=6.5.0-28-generic
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:05.143 +0800 o.a.z.ZooKeeper:[98] - Client environment:user.name=root
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:05.143 +0800 o.a.z.ZooKeeper:[98] - Client environment:user.home=/root
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:05.143 +0800 o.a.z.ZooKeeper:[98] - Client environment:user.dir=/opt/dolphinscheduler
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:05.143 +0800 o.a.z.ZooKeeper:[98] - Client environment:os.memory.free=3215MB
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:05.143 +0800 o.a.z.ZooKeeper:[98] - Client environment:os.memory.max=3840MB
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:05.144 +0800 o.a.z.ZooKeeper:[98] - Client environment:os.memory.total=3840MB
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:05.146 +0800 o.a.z.ZooKeeper:[637] - Initiating client connection, connectString=dolphinscheduler-zookeeper:2181 sessionTimeout=30000 watcher=org.apache.curator.ConnectionState@6996bbc4
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:05.149 +0800 o.a.z.c.X509Util:[77] - Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:05.160 +0800 o.a.z.ClientCnxnSocket:[239] - jute.maxbuffer value is 1048575 Bytes
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:05.168 +0800 o.a.z.ClientCnxn:[1732] - zookeeper.request.timeout value is 0. feature enabled=false
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:05.303 +0800 o.a.c.f.i.CuratorFrameworkImpl:[386] - Default schema
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:05.411 +0800 o.a.z.ClientCnxn:[1171] - Opening socket connection to server dolphinscheduler-zookeeper/172.18.0.7:2181.
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:05.427 +0800 o.a.z.ClientCnxn:[1173] - SASL config status: Will not attempt to authenticate using SASL (unknown error)
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:05.464 +0800 o.a.z.ClientCnxn:[1005] - Socket connection established, initiating session, client: /172.18.1.1:49072, server: dolphinscheduler-zookeeper/172.18.0.7:2181
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:05.519 +0800 o.a.z.ClientCnxn:[1444] - Session establishment complete on server dolphinscheduler-zookeeper/172.18.0.7:2181, session id = 0x1000090c2e00001, negotiated timeout = 30000
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:05.565 +0800 o.a.c.f.s.ConnectionStateManager:[252] - State change: CONNECTED
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:05.802 +0800 o.a.c.f.i.EnsembleTracker:[201] - New config event received: {}
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:05.803 +0800 o.a.c.f.i.EnsembleTracker:[201] - New config event received: {}
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:07.275 +0800 o.a.d.s.w.r.WorkerRpcServer:[41] - WorkerRpcServer starting...
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:08.190 +0800 o.a.d.e.b.NettyRemotingServer:[112] - WorkerRpcServer bind success at port: 1234
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:08.190 +0800 o.a.d.s.w.r.WorkerRpcServer:[43] - WorkerRpcServer started...
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:08.222 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: JAVA - JavaTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:08.464 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: JAVA - JavaTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:08.487 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: JUPYTER - JupyterTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:08.562 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: JUPYTER - JupyterTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:08.562 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: SPARK - SparkTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:08.564 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: SPARK - SparkTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:09.174 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: FLINK_STREAM - FlinkStreamTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:09.179 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: FLINK_STREAM - FlinkStreamTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:09.232 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: PYTHON - PythonTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:09.248 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: PYTHON - PythonTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:09.255 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: DATASYNC - DatasyncTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:09.287 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: DATASYNC - DatasyncTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:09.288 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: DATA_FACTORY - DatafactoryTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:09.292 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: DATA_FACTORY - DatafactoryTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:09.308 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: CHUNJUN - ChunJunTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:09.345 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: CHUNJUN - ChunJunTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:09.352 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: REMOTESHELL - RemoteShellTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:09.378 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: REMOTESHELL - RemoteShellTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:09.397 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: PIGEON - PigeonTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:09.401 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: PIGEON - PigeonTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:09.409 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: SHELL - ShellTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:09.411 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: SHELL - ShellTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:09.413 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: PROCEDURE - ProcedureTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:09.422 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: PROCEDURE - ProcedureTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:09.424 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: MR - MapReduceTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:09.426 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: MR - MapReduceTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:09.429 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: SQOOP - SqoopTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:09.446 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: SQOOP - SqoopTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:09.455 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: PYTORCH - PytorchTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:09.467 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: PYTORCH - PytorchTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:09.487 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: K8S - K8sTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:09.492 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: K8S - K8sTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:09.493 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: SEATUNNEL - SeatunnelTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:10.479 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: SEATUNNEL - SeatunnelTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:10.479 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: SAGEMAKER - SagemakerTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:10.481 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: SAGEMAKER - SagemakerTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:10.481 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: HTTP - HttpTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:10.493 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: HTTP - HttpTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:10.494 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: EMR - EmrTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:10.503 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: EMR - EmrTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:10.514 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: DMS - DmsTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:10.522 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: DMS - DmsTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:10.522 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: DATA_QUALITY - DataQualityTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:10.526 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: DATA_QUALITY - DataQualityTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:10.527 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: KUBEFLOW - KubeflowTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:10.534 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: KUBEFLOW - KubeflowTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:10.535 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: SQL - SqlTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:10.537 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: SQL - SqlTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:10.537 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: DVC - DvcTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:10.541 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: DVC - DvcTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:10.542 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: DATAX - DataxTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:10.544 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: DATAX - DataxTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:10.551 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: ZEPPELIN - ZeppelinTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:10.555 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: ZEPPELIN - ZeppelinTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:10.556 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: DINKY - DinkyTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:10.558 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: DINKY - DinkyTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:10.559 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: MLFLOW - MlflowTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:10.567 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: MLFLOW - MlflowTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:10.568 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: OPENMLDB - OpenmldbTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:10.569 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: OPENMLDB - OpenmldbTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:10.569 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: LINKIS - LinkisTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:10.570 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: LINKIS - LinkisTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:10.571 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: FLINK - FlinkTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:10.572 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: FLINK - FlinkTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:10.581 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: HIVECLI - HiveCliTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:10.583 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: HIVECLI - HiveCliTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:10.896 +0800 o.a.d.c.u.JSONUtils:[72] - init timezone: sun.util.calendar.ZoneInfo[id="Asia/Shanghai",offset=28800000,dstSavings=0,useDaylight=false,transitions=31,lastRule=null]
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:11.087 +0800 o.a.d.s.w.r.WorkerRegistryClient:[104] - Worker node: 172.18.1.1:1234 registry to ZK /nodes/worker/172.18.1.1:1234 successfully
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:12.212 +0800 o.a.d.c.m.BaseHeartBeatTask:[48] - Starting WorkerHeartBeatTask...
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:12.215 +0800 o.a.d.c.m.BaseHeartBeatTask:[50] - Started WorkerHeartBeatTask, heartBeatInterval: 10000...
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:12.215 +0800 o.a.d.s.w.r.WorkerRegistryClient:[114] - Worker node: 172.18.1.1:1234 registry finished
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:12.216 +0800 o.a.d.s.w.m.MessageRetryRunner:[69] - Message retry runner staring
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:12.234 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.0494505494505495 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:12.292 +0800 o.a.d.s.w.m.MessageRetryRunner:[72] - Injected message sender: TaskInstanceExecutionFinishEventSender
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:12.293 +0800 o.a.d.s.w.m.MessageRetryRunner:[72] - Injected message sender: TaskInstanceExecutionInfoUpdateEventSender
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:12.293 +0800 o.a.d.s.w.m.MessageRetryRunner:[72] - Injected message sender: TaskInstanceExecutionRunningEventSender
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:12.293 +0800 o.a.d.s.w.m.MessageRetryRunner:[75] - Message retry runner started
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:13.338 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.3149293838270215 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:14.401 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.3266666666666667 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:15.457 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.3380773641956 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:16.470 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.425925925925926 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:17.489 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.5314685314685315 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:20.034 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.2305555555555556 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:21.091 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.3396226415094339 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:22.123 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.3043478260869565 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:23.130 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.1365853658536587 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:24.411 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.467248908296943 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:25.462 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.4968944099378882 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:26.495 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.4 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:27.614 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.9456521739130435 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:28.352 +0800 o.s.b.a.e.w.EndpointLinksResolver:[58] - Exposing 3 endpoint(s) beneath base path '/actuator'
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:28.618 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.7721518987341771 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:28.593 +0800 o.e.j.s.h.C.application:[2368] - Initializing Spring DispatcherServlet 'dispatcherServlet'
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:28.621 +0800 o.s.w.s.DispatcherServlet:[525] - Initializing Servlet 'dispatcherServlet'
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:28.623 +0800 o.s.w.s.DispatcherServlet:[547] - Completed initialization in 2 ms
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:28.810 +0800 o.e.j.s.AbstractConnector:[333] - Started ServerConnector@acb5508{HTTP/1.1, (http/1.1)}{0.0.0.0:1235}
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:28.813 +0800 o.s.b.w.e.j.JettyWebServer:[172] - Jetty started on port(s) 1235 (http/1.1) with context path '/'
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:29.173 +0800 o.a.d.s.w.WorkerServer:[61] - Started WorkerServer in 64.159 seconds (JVM running for 69.323)
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:29.636 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.5740678676162547 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:30.639 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9460431654676259 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:31.645 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8516026363932536 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:32.876 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8165467625899281 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:33.885 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9457831325301204 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:34.903 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9427083333333334 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:35.939 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9705882352941176 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:36.951 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9166666666666666 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:37.958 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8142857142857143 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:40.150 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8857142857142857 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:41.223 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8647110739502044 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:42.255 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7500393081761006 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:43.265 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8169014084507042 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:44.278 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7317073170731707 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:45.284 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9458333333333333 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:46.286 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7305699481865284 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:47.290 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9228187919463087 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-3953] - [INFO] 2024-05-07 10:23:55.924 +0800 o.a.d.s.w.r.o.UpdateWorkflowHostOperationFunction:[49] - Received UpdateWorkflowHostRequest: UpdateWorkflowHostRequest(taskInstanceId=3953, workflowHost=172.18.0.15:5678)
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:56.217 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=3954, taskName=[null check] filtered data persistence, firstSubmitTime=1715048636037, startTime=0, taskType=DATA_QUALITY, workflowInstanceHost=172.18.0.15:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13505298546272, processDefineVersion=21, appIds=null, processInstanceId=1059, scheduleTime=0, globalParams=null, executorId=1, cmdTypeIfComplement=2, tenantCode=default, processDefineId=0, projectId=0, projectCode=13001194483488, taskParams={"localParams":[],"resourceList":[],"ruleId":6,"ruleInputParameter":{"check_type":"0","comparison_type":1,"comparison_name":"0","failure_strategy":"0","operator":"0","src_connector_type":1,"src_datasource_id":6,"src_database":"persistence","src_field":"content","src_table":"filtered_data_persistence","threshold":"0"},"sparkParameters":{"deployMode":"local","driverCores":1,"driverMemory":"512M","executorCores":1,"executorMemory":"1G","numExecutors":1,"others":"--conf spark.driver.extraJavaOptions=\"-Divy.cache.dir=/tmp -Divy.home=/tmp\" \\\n--packages org.postgresql:postgresql:42.7.3","yarnQueue":""}}, environmentConfig=export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export PYSPARK_DRIVER_PYTHON=/bin/python3.11
export PYSPARK_PYTHON=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='[null check] filtered data persistence'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13001194483488'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='1059'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240507'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240506'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='3954'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='qualti_test'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13505264408800'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13505298546272'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240507102356'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=null, dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=org.apache.dolphinscheduler.plugin.task.api.DataQualityTaskExecutionContext@4cc0068d, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-1059][TI-3954] - [INFO] 2024-05-07 10:23:56.253 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: [null check] filtered data persistence to wait queue success
[WI-1059][TI-3954] - [INFO] 2024-05-07 10:23:56.261 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-1059][TI-3954] - [INFO] 2024-05-07 10:23:56.268 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-1059][TI-3954] - [INFO] 2024-05-07 10:23:56.268 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-1059][TI-3954] - [INFO] 2024-05-07 10:23:56.269 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-1059][TI-3954] - [INFO] 2024-05-07 10:23:56.269 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1715048636269
[WI-1059][TI-3954] - [INFO] 2024-05-07 10:23:56.270 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 1059_3954
[WI-1059][TI-3954] - [INFO] 2024-05-07 10:23:56.276 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 3954,
  "taskName" : "[null check] filtered data persistence",
  "firstSubmitTime" : 1715048636037,
  "startTime" : 1715048636269,
  "taskType" : "DATA_QUALITY",
  "workflowInstanceHost" : "172.18.0.15:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240507/13505298546272/21/1059/3954.log",
  "processId" : 0,
  "processDefineCode" : 13505298546272,
  "processDefineVersion" : 21,
  "processInstanceId" : 1059,
  "scheduleTime" : 0,
  "executorId" : 1,
  "cmdTypeIfComplement" : 2,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13001194483488,
  "taskParams" : "{\"localParams\":[],\"resourceList\":[],\"ruleId\":6,\"ruleInputParameter\":{\"check_type\":\"0\",\"comparison_type\":1,\"comparison_name\":\"0\",\"failure_strategy\":\"0\",\"operator\":\"0\",\"src_connector_type\":1,\"src_datasource_id\":6,\"src_database\":\"persistence\",\"src_field\":\"content\",\"src_table\":\"filtered_data_persistence\",\"threshold\":\"0\"},\"sparkParameters\":{\"deployMode\":\"local\",\"driverCores\":1,\"driverMemory\":\"512M\",\"executorCores\":1,\"executorMemory\":\"1G\",\"numExecutors\":1,\"others\":\"--conf spark.driver.extraJavaOptions=\\\"-Divy.cache.dir=/tmp -Divy.home=/tmp\\\" \\\\\\n--packages org.postgresql:postgresql:42.7.3\",\"yarnQueue\":\"\"}}",
  "environmentConfig" : "export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3\nexport JAVA_HOME=/opt/java/openjdk\nexport PYSPARK_DRIVER_PYTHON=/bin/python3.11\nexport PYSPARK_PYTHON=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "[null check] filtered data persistence"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13001194483488"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1059"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240507"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240506"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "3954"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "qualti_test"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13505264408800"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13505298546272"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240507102356"
    }
  },
  "taskAppId" : "1059_3954",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "dryRun" : 0,
  "paramsMap" : { },
  "dataQualityTaskExecutionContext" : {
    "ruleId" : 6,
    "ruleName" : "$t(uniqueness_check)",
    "ruleType" : 0,
    "ruleInputEntryList" : "[{\"id\":1,\"field\":\"src_connector_type\",\"type\":\"select\",\"title\":\"$t(src_connector_type)\",\"data\":\"\",\"options\":\"[{\\\"label\\\":\\\"HIVE\\\",\\\"value\\\":\\\"HIVE\\\"},{\\\"label\\\":\\\"JDBC\\\",\\\"value\\\":\\\"JDBC\\\"}]\",\"placeholder\":\"please select source connector type\",\"optionSourceType\":2,\"dataType\":2,\"inputType\":0,\"isShow\":true,\"canEdit\":true,\"isEmit\":true,\"isValidate\":false,\"valuesMap\":null,\"index\":1,\"createTime\":null,\"updateTime\":null},{\"id\":2,\"field\":\"src_datasource_id\",\"type\":\"select\",\"title\":\"$t(src_datasource_id)\",\"data\":\"\",\"options\":null,\"placeholder\":\"please select source datasource id\",\"optionSourceType\":1,\"dataType\":2,\"inputType\":0,\"isShow\":true,\"canEdit\":true,\"isEmit\":true,\"isValidate\":false,\"valuesMap\":null,\"index\":2,\"createTime\":null,\"updateTime\":null},{\"id\":30,\"field\":\"src_database\",\"type\":\"select\",\"title\":\"$t(src_database)\",\"data\":null,\"options\":null,\"placeholder\":\"Please select source database\",\"optionSourceType\":0,\"dataType\":0,\"inputType\":0,\"isShow\":true,\"canEdit\":true,\"isEmit\":true,\"isValidate\":true,\"valuesMap\":null,\"index\":2,\"createTime\":null,\"updateTime\":null},{\"id\":3,\"field\":\"src_table\",\"type\":\"select\",\"title\":\"$t(src_table)\",\"data\":null,\"options\":null,\"placeholder\":\"Please enter source table name\",\"optionSourceType\":0,\"dataType\":0,\"inputType\":0,\"isShow\":true,\"canEdit\":true,\"isEmit\":true,\"isValidate\":true,\"valuesMap\":null,\"index\":3,\"createTime\":null,\"updateTime\":null},{\"id\":4,\"field\":\"src_filter\",\"type\":\"input\",\"title\":\"$t(src_filter)\",\"data\":null,\"options\":null,\"placeholder\":\"Please enter filter expression\",\"optionSourceType\":0,\"dataType\":3,\"inputType\":0,\"isShow\":true,\"canEdit\":true,\"isEmit\":false,\"isValidate\":false,\"valuesMap\":null,\"index\":4,\"createTime\":null,\"updateTime\":null},{\"id\":5,\"field\":\"src_field\",\"type\":\"select\",\"title\":\"$t(src_field)\",\"data\":null,\"options\":null,\"placeholder\":\"Please enter column, only single column is supported\",\"optionSourceType\":0,\"dataType\":0,\"inputType\":0,\"isShow\":true,\"canEdit\":true,\"isEmit\":false,\"isValidate\":true,\"valuesMap\":null,\"index\":5,\"createTime\":null,\"updateTime\":null},{\"id\":6,\"field\":\"statistics_name\",\"type\":\"input\",\"title\":\"$t(statistics_name)\",\"data\":\"duplicate_count.duplicates\",\"options\":null,\"placeholder\":\"Please enter statistics name, the alias in statistics execute sql\",\"optionSourceType\":0,\"dataType\":0,\"inputType\":1,\"isShow\":false,\"canEdit\":false,\"isEmit\":false,\"isValidate\":true,\"valuesMap\":\"{\\\"statistics_name\\\":\\\"duplicate_count.duplicates\\\"}\",\"index\":6,\"createTime\":null,\"updateTime\":null},{\"id\":7,\"field\":\"check_type\",\"type\":\"select\",\"title\":\"$t(check_type)\",\"data\":\"0\",\"options\":\"[{\\\"label\\\":\\\"Expected - Actual\\\",\\\"value\\\":\\\"0\\\"},{\\\"label\\\":\\\"Actual - Expected\\\",\\\"value\\\":\\\"1\\\"},{\\\"label\\\":\\\"Actual / Expected\\\",\\\"value\\\":\\\"2\\\"},{\\\"label\\\":\\\"(Expected - Actual) / Expected\\\",\\\"value\\\":\\\"3\\\"}]\",\"placeholder\":\"please select check type\",\"optionSourceType\":0,\"dataType\":0,\"inputType\":3,\"isShow\":true,\"canEdit\":true,\"isEmit\":true,\"isValidate\":false,\"valuesMap\":null,\"index\":7,\"createTime\":null,\"updateTime\":null},{\"id\":8,\"field\":\"operator\",\"type\":\"select\",\"title\":\"$t(operator)\",\"data\":\"0\",\"options\":\"[{\\\"label\\\":\\\"=\\\",\\\"value\\\":\\\"0\\\"},{\\\"label\\\":\\\"<\\\",\\\"value\\\":\\\"1\\\"},{\\\"label\\\":\\\"<=\\\",\\\"value\\\":\\\"2\\\"},{\\\"label\\\":\\\">\\\",\\\"value\\\":\\\"3\\\"},{\\\"label\\\":\\\">=\\\",\\\"value\\\":\\\"4\\\"},{\\\"label\\\":\\\"!=\\\",\\\"value\\\":\\\"5\\\"}]\",\"placeholder\":\"please select operator\",\"optionSourceType\":0,\"dataType\":0,\"inputType\":3,\"isShow\":true,\"canEdit\":true,\"isEmit\":false,\"isValidate\":false,\"valuesMap\":null,\"index\":8,\"createTime\":null,\"updateTime\":null},{\"id\":9,\"field\":\"threshold\",\"type\":\"input\",\"title\":\"$t(threshold)\",\"data\":null,\"options\":null,\"placeholder\":\"Please enter threshold, number is needed\",\"optionSourceType\":0,\"dataType\":2,\"inputType\":3,\"isShow\":true,\"canEdit\":true,\"isEmit\":false,\"isValidate\":true,\"valuesMap\":null,\"index\":9,\"createTime\":null,\"updateTime\":null},{\"id\":10,\"field\":\"failure_strategy\",\"type\":\"select\",\"title\":\"$t(failure_strategy)\",\"data\":\"0\",\"options\":\"[{\\\"label\\\":\\\"Alert\\\",\\\"value\\\":\\\"0\\\"},{\\\"label\\\":\\\"Block\\\",\\\"value\\\":\\\"1\\\"}]\",\"placeholder\":\"please select failure strategy\",\"optionSourceType\":0,\"dataType\":0,\"inputType\":3,\"isShow\":true,\"canEdit\":true,\"isEmit\":false,\"isValidate\":false,\"valuesMap\":null,\"index\":10,\"createTime\":null,\"updateTime\":null},{\"id\":17,\"field\":\"comparison_name\",\"type\":\"input\",\"title\":\"$t(comparison_name)\",\"data\":null,\"options\":null,\"placeholder\":\"Please enter comparison name, the alias in comparison execute sql\",\"optionSourceType\":0,\"dataType\":0,\"inputType\":0,\"isShow\":false,\"canEdit\":false,\"isEmit\":false,\"isValidate\":true,\"valuesMap\":\"\",\"index\":11,\"createTime\":null,\"updateTime\":null},{\"id\":19,\"field\":\"comparison_type\",\"type\":\"select\",\"title\":\"$t(comparison_type)\",\"data\":\"\",\"options\":null,\"placeholder\":\"Please enter comparison title\",\"optionSourceType\":3,\"dataType\":0,\"inputType\":2,\"isShow\":true,\"canEdit\":false,\"isEmit\":true,\"isValidate\":false,\"valuesMap\":null,\"index\":12,\"createTime\":null,\"updateTime\":null}]",
    "executeSqlList" : "[{\"id\":6,\"index\":1,\"sql\":\"SELECT ${src_field} FROM ${src_table} group by ${src_field} having count(*) > 1\",\"tableAlias\":\"duplicate_items\",\"type\":0,\"createTime\":\"2021-03-03 11:31:24\",\"updateTime\":\"2021-03-03 11:31:24\",\"errorOutputSql\":true},{\"id\":7,\"index\":1,\"sql\":\"SELECT COUNT(*) AS duplicates FROM duplicate_items\",\"tableAlias\":\"duplicate_count\",\"type\":1,\"createTime\":\"2021-03-03 11:31:24\",\"updateTime\":\"2021-03-03 11:31:24\",\"errorOutputSql\":false}]",
    "comparisonNeedStatisticsValueTable" : false,
    "compareWithFixedValue" : true,
    "hdfsPath" : "hdfs://mycluster:8020/user/default/data_quality_error_data",
    "sourceConnectorType" : "JDBC",
    "sourceType" : 1,
    "sourceConnectionParams" : "{\"user\":\"root\",\"password\":\"root\",\"address\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432\",\"database\":\"persistence\",\"jdbcUrl\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432/persistence\",\"driverClassName\":\"org.postgresql.Driver\",\"validationQuery\":\"select version()\",\"other\":{\"password\":\"root\"}}",
    "targetConnectorType" : null,
    "targetType" : 0,
    "targetConnectionParams" : null,
    "writerConnectorType" : "JDBC",
    "writerType" : 1,
    "writerTable" : "t_ds_dq_execute_result",
    "writerConnectionParams" : "{\"user\":\"root\",\"password\":\"root\",\"address\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432\",\"database\":\"dolphinscheduler\",\"jdbcUrl\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432/dolphinscheduler\"}",
    "statisticsValueConnectorType" : "JDBC",
    "statisticsValueType" : 1,
    "statisticsValueTable" : "t_ds_dq_task_statistics_value",
    "statisticsValueWriterConnectionParams" : "{\"user\":\"root\",\"password\":\"root\",\"address\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432\",\"database\":\"dolphinscheduler\",\"jdbcUrl\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432/dolphinscheduler\"}"
  },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-1059][TI-3954] - [INFO] 2024-05-07 10:23:56.282 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-1059][TI-3954] - [INFO] 2024-05-07 10:23:56.283 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-1059][TI-3954] - [INFO] 2024-05-07 10:23:56.283 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:56.335 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7602523659305994 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-1059][TI-3954] - [INFO] 2024-05-07 10:23:56.368 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-1059][TI-3954] - [INFO] 2024-05-07 10:23:56.388 +0800 o.a.d.c.u.OSUtils:[231] - create linux os user: default
[WI-1059][TI-3954] - [INFO] 2024-05-07 10:23:56.392 +0800 o.a.d.c.u.OSUtils:[233] - execute cmd: sudo useradd -g root
 default
[WI-1059][TI-3954] - [INFO] 2024-05-07 10:23:56.456 +0800 o.a.d.c.u.OSUtils:[190] - create user default success
[WI-1059][TI-3954] - [INFO] 2024-05-07 10:23:56.456 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-1059][TI-3954] - [INFO] 2024-05-07 10:23:56.460 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13001194483488/13505298546272_21/1059/3954 check successfully
[WI-1059][TI-3954] - [INFO] 2024-05-07 10:23:56.461 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.dq.DataQualityTaskChannel successfully
[WI-1059][TI-3954] - [INFO] 2024-05-07 10:23:56.473 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-1059][TI-3954] - [INFO] 2024-05-07 10:23:56.481 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-1059][TI-3954] - [INFO] 2024-05-07 10:23:56.484 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: DATA_QUALITY create successfully
[WI-1059][TI-3954] - [INFO] 2024-05-07 10:23:56.491 +0800 o.a.d.p.t.d.DataQualityTask:[89] - Initialize data quality task params {
  "localParams" : [ ],
  "varPool" : null,
  "ruleId" : 6,
  "ruleInputParameter" : {
    "check_type" : "0",
    "comparison_type" : "1",
    "comparison_name" : "0",
    "failure_strategy" : "0",
    "operator" : "0",
    "src_connector_type" : "1",
    "src_datasource_id" : "6",
    "src_database" : "persistence",
    "src_field" : "content",
    "src_table" : "filtered_data_persistence",
    "threshold" : "0"
  },
  "sparkParameters" : {
    "localParams" : null,
    "varPool" : null,
    "mainJar" : null,
    "mainClass" : null,
    "deployMode" : "local",
    "mainArgs" : null,
    "driverCores" : 1,
    "driverMemory" : "512M",
    "numExecutors" : 1,
    "executorCores" : 1,
    "executorMemory" : "1G",
    "appName" : null,
    "yarnQueue" : "",
    "others" : "--conf spark.driver.extraJavaOptions=\"-Divy.cache.dir=/tmp -Divy.home=/tmp\" \\\n--packages org.postgresql:postgresql:42.7.3",
    "programType" : null,
    "resourceList" : [ ]
  }
}
[WI-1059][TI-3954] - [INFO] 2024-05-07 10:23:56.537 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: HANA
[WI-1059][TI-3954] - [INFO] 2024-05-07 10:23:56.537 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: HANA
[WI-1059][TI-3954] - [INFO] 2024-05-07 10:23:56.539 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: SQLSERVER
[WI-1059][TI-3954] - [INFO] 2024-05-07 10:23:56.539 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: SQLSERVER
[WI-1059][TI-3954] - [INFO] 2024-05-07 10:23:56.542 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: SAGEMAKER
[WI-1059][TI-3954] - [INFO] 2024-05-07 10:23:56.542 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: SAGEMAKER
[WI-1059][TI-3954] - [INFO] 2024-05-07 10:23:56.544 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: DATABEND
[WI-1059][TI-3954] - [INFO] 2024-05-07 10:23:56.544 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: DATABEND
[WI-0][TI-3954] - [INFO] 2024-05-07 10:23:56.552 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=3954, success=true)
[WI-1059][TI-3954] - [INFO] 2024-05-07 10:23:56.613 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: AZURESQL
[WI-1059][TI-3954] - [INFO] 2024-05-07 10:23:56.614 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: AZURESQL
[WI-1059][TI-3954] - [INFO] 2024-05-07 10:23:56.618 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: HIVE
[WI-1059][TI-3954] - [INFO] 2024-05-07 10:23:56.618 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: HIVE
[WI-1059][TI-3954] - [INFO] 2024-05-07 10:23:56.621 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: DORIS
[WI-1059][TI-3954] - [INFO] 2024-05-07 10:23:56.622 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: DORIS
[WI-1059][TI-3954] - [INFO] 2024-05-07 10:23:56.624 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: POSTGRESQL
[WI-1059][TI-3954] - [INFO] 2024-05-07 10:23:56.624 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: POSTGRESQL
[WI-1059][TI-3954] - [INFO] 2024-05-07 10:23:56.627 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: MYSQL
[WI-1059][TI-3954] - [INFO] 2024-05-07 10:23:56.627 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: MYSQL
[WI-1059][TI-3954] - [INFO] 2024-05-07 10:23:56.632 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: REDSHIFT
[WI-1059][TI-3954] - [INFO] 2024-05-07 10:23:56.633 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: REDSHIFT
[WI-1059][TI-3954] - [INFO] 2024-05-07 10:23:56.635 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: SNOWFLAKE
[WI-1059][TI-3954] - [INFO] 2024-05-07 10:23:56.635 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: SNOWFLAKE
[WI-1059][TI-3954] - [INFO] 2024-05-07 10:23:56.638 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: STARROCKS
[WI-1059][TI-3954] - [INFO] 2024-05-07 10:23:56.638 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: STARROCKS
[WI-1059][TI-3954] - [INFO] 2024-05-07 10:23:56.640 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: SSH
[WI-1059][TI-3954] - [INFO] 2024-05-07 10:23:56.640 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: SSH
[WI-1059][TI-3954] - [INFO] 2024-05-07 10:23:56.643 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: ATHENA
[WI-1059][TI-3954] - [INFO] 2024-05-07 10:23:56.643 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: ATHENA
[WI-1059][TI-3954] - [INFO] 2024-05-07 10:23:56.646 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: PRESTO
[WI-1059][TI-3954] - [INFO] 2024-05-07 10:23:56.647 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: PRESTO
[WI-1059][TI-3954] - [INFO] 2024-05-07 10:23:56.650 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: OCEANBASE
[WI-1059][TI-3954] - [INFO] 2024-05-07 10:23:56.651 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: OCEANBASE
[WI-1059][TI-3954] - [INFO] 2024-05-07 10:23:56.666 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: ORACLE
[WI-1059][TI-3954] - [INFO] 2024-05-07 10:23:56.667 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: ORACLE
[WI-1059][TI-3954] - [INFO] 2024-05-07 10:23:56.670 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: CLICKHOUSE
[WI-1059][TI-3954] - [INFO] 2024-05-07 10:23:56.671 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: CLICKHOUSE
[WI-1059][TI-3954] - [INFO] 2024-05-07 10:23:56.674 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: VERTICA
[WI-1059][TI-3954] - [INFO] 2024-05-07 10:23:56.675 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: VERTICA
[WI-1059][TI-3954] - [INFO] 2024-05-07 10:23:56.678 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: KYUUBI
[WI-1059][TI-3954] - [INFO] 2024-05-07 10:23:56.679 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: KYUUBI
[WI-1059][TI-3954] - [INFO] 2024-05-07 10:23:56.682 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: DB2
[WI-1059][TI-3954] - [INFO] 2024-05-07 10:23:56.682 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: DB2
[WI-1059][TI-3954] - [INFO] 2024-05-07 10:23:56.686 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: TRINO
[WI-1059][TI-3954] - [INFO] 2024-05-07 10:23:56.686 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: TRINO
[WI-1059][TI-3954] - [INFO] 2024-05-07 10:23:56.689 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: SPARK
[WI-1059][TI-3954] - [INFO] 2024-05-07 10:23:56.690 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: SPARK
[WI-1059][TI-3954] - [INFO] 2024-05-07 10:23:56.694 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: DAMENG
[WI-1059][TI-3954] - [INFO] 2024-05-07 10:23:56.694 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: DAMENG
[WI-1059][TI-3954] - [INFO] 2024-05-07 10:23:56.702 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: ZEPPELIN
[WI-1059][TI-3954] - [INFO] 2024-05-07 10:23:56.702 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: ZEPPELIN
[WI-1059][TI-3954] - [INFO] 2024-05-07 10:23:56.718 +0800 o.a.d.p.t.d.DataQualityTask:[119] - data quality configuration: {
  "name" : "$t(uniqueness_check)",
  "env" : {
    "type" : "batch",
    "config" : null
  },
  "readers" : [ {
    "type" : "JDBC",
    "config" : {
      "database" : "persistence",
      "password" : "root",
      "driver" : "org.postgresql.Driver",
      "user" : "root",
      "output_table" : "persistence_filtered_data_persistence",
      "table" : "filtered_data_persistence",
      "url" : "jdbc:postgresql://dolphinscheduler-postgresql:5432/persistence?password=root"
    }
  } ],
  "transformers" : [ {
    "type" : "sql",
    "config" : {
      "index" : 1,
      "output_table" : "duplicate_items",
      "sql" : "SELECT content FROM persistence_filtered_data_persistence group by content having count(*) > 1"
    }
  }, {
    "type" : "sql",
    "config" : {
      "index" : 2,
      "output_table" : "duplicate_count",
      "sql" : "SELECT COUNT(*) AS duplicates FROM duplicate_items"
    }
  } ],
  "writers" : [ {
    "type" : "JDBC",
    "config" : {
      "database" : "dolphinscheduler",
      "password" : "root",
      "driver" : "org.postgresql.Driver",
      "user" : "root",
      "table" : "t_ds_dq_execute_result",
      "url" : "jdbc:postgresql://dolphinscheduler-postgresql:5432/dolphinscheduler",
      "sql" : "select 0 as rule_type,'$t(uniqueness_check)' as rule_name,0 as process_definition_id,1059 as process_instance_id,3954 as task_instance_id,duplicate_count.duplicates AS statistics_value,0 AS comparison_value,1 AS comparison_type,0 as check_type,0 as threshold,0 as operator,0 as failure_strategy,'hdfs://mycluster:8020/user/default/data_quality_error_data/0_1059_[null check] filtered data persistence' as error_output_path,'2024-05-07 10:23:56' as create_time,'2024-05-07 10:23:56' as update_time from duplicate_count "
    }
  }, {
    "type" : "JDBC",
    "config" : {
      "database" : "dolphinscheduler",
      "password" : "root",
      "driver" : "org.postgresql.Driver",
      "user" : "root",
      "table" : "t_ds_dq_task_statistics_value",
      "url" : "jdbc:postgresql://dolphinscheduler-postgresql:5432/dolphinscheduler",
      "sql" : "select 0 as process_definition_id,3954 as task_instance_id,6 as rule_id,'KA0AXXWVHWW+GZX4BPZXFGFZ0F0OYMUQ+BVYG4+ZIKG=' as unique_code,'duplicate_count.duplicates'AS statistics_name,duplicate_count.duplicates AS statistics_value,'2024-05-07 10:23:56' as data_time,'2024-05-07 10:23:56' as create_time,'2024-05-07 10:23:56' as update_time from duplicate_count"
    }
  }, {
    "type" : "hdfs_file",
    "config" : {
      "path" : "hdfs://mycluster:8020/user/default/data_quality_error_data/0_1059_[null check] filtered data persistence",
      "input_table" : "duplicate_items"
    }
  } ]
}
[WI-1059][TI-3954] - [INFO] 2024-05-07 10:23:56.740 +0800 o.a.d.p.d.a.u.CommonUtils:[136] - Trying to get data quality jar in path
[WI-1059][TI-3954] - [INFO] 2024-05-07 10:23:56.741 +0800 o.a.d.p.d.a.u.CommonUtils:[147] - data quality jar path is empty, will try to auto discover it from build-in rules.
[WI-1059][TI-3954] - [INFO] 2024-05-07 10:23:56.742 +0800 o.a.d.p.d.a.u.CommonUtils:[187] - Try to get data quality jar from path /opt/dolphinscheduler/conf/../libs
[WI-1059][TI-3954] - [INFO] 2024-05-07 10:23:56.744 +0800 o.a.d.p.d.a.u.CommonUtils:[182] - get default data quality jar name: /opt/dolphinscheduler/conf/../libs/dolphinscheduler-data-quality-3.2.1.jar
[WI-1059][TI-3954] - [INFO] 2024-05-07 10:23:56.745 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-1059][TI-3954] - [INFO] 2024-05-07 10:23:56.753 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: null successfully
[WI-1059][TI-3954] - [INFO] 2024-05-07 10:23:56.757 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-1059][TI-3954] - [INFO] 2024-05-07 10:23:56.757 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-1059][TI-3954] - [INFO] 2024-05-07 10:23:56.758 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-1059][TI-3954] - [INFO] 2024-05-07 10:23:56.768 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-1059][TI-3954] - [INFO] 2024-05-07 10:23:56.769 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-1059][TI-3954] - [INFO] 2024-05-07 10:23:56.769 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export PYSPARK_DRIVER_PYTHON=/bin/python3.11
export PYSPARK_PYTHON=/bin/python3.11
${SPARK_HOME}/bin/spark-submit --master local --driver-cores 1 --driver-memory 512M --num-executors 1 --executor-cores 1 --executor-memory 1G --conf spark.driver.extraJavaOptions="-Divy.cache.dir=/tmp -Divy.home=/tmp" \
--packages org.postgresql:postgresql:42.7.3 /opt/dolphinscheduler/conf/../libs/dolphinscheduler-data-quality-3.2.1.jar "{\"name\":\"$t(uniqueness_check)\",\"env\":{\"type\":\"batch\",\"config\":null},\"readers\":[{\"type\":\"JDBC\",\"config\":{\"database\":\"persistence\",\"password\":\"root\",\"driver\":\"org.postgresql.Driver\",\"user\":\"root\",\"output_table\":\"persistence_filtered_data_persistence\",\"table\":\"filtered_data_persistence\",\"url\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432/persistence?password=root\"} }],\"transformers\":[{\"type\":\"sql\",\"config\":{\"index\":1,\"output_table\":\"duplicate_items\",\"sql\":\"SELECT content FROM persistence_filtered_data_persistence group by content having count(*) > 1\"} },{\"type\":\"sql\",\"config\":{\"index\":2,\"output_table\":\"duplicate_count\",\"sql\":\"SELECT COUNT(*) AS duplicates FROM duplicate_items\"} }],\"writers\":[{\"type\":\"JDBC\",\"config\":{\"database\":\"dolphinscheduler\",\"password\":\"root\",\"driver\":\"org.postgresql.Driver\",\"user\":\"root\",\"table\":\"t_ds_dq_execute_result\",\"url\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432/dolphinscheduler\",\"sql\":\"select 0 as rule_type,'$t(uniqueness_check)' as rule_name,0 as process_definition_id,1059 as process_instance_id,3954 as task_instance_id,duplicate_count.duplicates AS statistics_value,0 AS comparison_value,1 AS comparison_type,0 as check_type,0 as threshold,0 as operator,0 as failure_strategy,'hdfs://mycluster:8020/user/default/data_quality_error_data/0_1059_[null check] filtered data persistence' as error_output_path,'2024-05-07 10:23:56' as create_time,'2024-05-07 10:23:56' as update_time from duplicate_count \"} },{\"type\":\"JDBC\",\"config\":{\"database\":\"dolphinscheduler\",\"password\":\"root\",\"driver\":\"org.postgresql.Driver\",\"user\":\"root\",\"table\":\"t_ds_dq_task_statistics_value\",\"url\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432/dolphinscheduler\",\"sql\":\"select 0 as process_definition_id,3954 as task_instance_id,6 as rule_id,'KA0AXXWVHWW+GZX4BPZXFGFZ0F0OYMUQ+BVYG4+ZIKG=' as unique_code,'duplicate_count.duplicates'AS statistics_name,duplicate_count.duplicates AS statistics_value,'2024-05-07 10:23:56' as data_time,'2024-05-07 10:23:56' as create_time,'2024-05-07 10:23:56' as update_time from duplicate_count\"} },{\"type\":\"hdfs_file\",\"config\":{\"path\":\"hdfs://mycluster:8020/user/default/data_quality_error_data/0_1059_[null check] filtered data persistence\",\"input_table\":\"duplicate_items\"} }]}"
[WI-1059][TI-3954] - [INFO] 2024-05-07 10:23:56.769 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-1059][TI-3954] - [INFO] 2024-05-07 10:23:56.771 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13001194483488/13505298546272_21/1059/3954/1059_3954.sh
[WI-1059][TI-3954] - [INFO] 2024-05-07 10:23:56.780 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 91
[WI-0][TI-3954] - [INFO] 2024-05-07 10:23:57.529 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=3954)
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:57.779 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
[WI-0][TI-0] - [INFO] 2024-05-07 10:23:58.782 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	:: loading settings :: url = jar:file:/opt/spark-3.5.1-bin-hadoop3/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml
	Ivy Default Cache set to: /tmp
	The jars for the packages stored in: /tmp/jars
	org.postgresql#postgresql added as a dependency
	:: resolving dependencies :: org.apache.spark#spark-submit-parent-5fcbe154-a48e-4cc2-8ee3-c6ac52617ce2;1.0
		confs: [default]
[WI-0][TI-0] - [INFO] 2024-05-07 10:24:00.794 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
		found org.postgresql#postgresql;42.7.3 in central
		found org.checkerframework#checker-qual;3.42.0 in central
	downloading https://repo1.maven.org/maven2/org/postgresql/postgresql/42.7.3/postgresql-42.7.3.jar ...
[WI-0][TI-0] - [INFO] 2024-05-07 10:24:01.813 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
		[SUCCESSFUL ] org.postgresql#postgresql;42.7.3!postgresql.jar (1236ms)
[WI-0][TI-0] - [INFO] 2024-05-07 10:24:02.817 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	downloading https://repo1.maven.org/maven2/org/checkerframework/checker-qual/3.42.0/checker-qual-3.42.0.jar ...
		[SUCCESSFUL ] org.checkerframework#checker-qual;3.42.0!checker-qual.jar (376ms)
	:: resolution report :: resolve 1825ms :: artifacts dl 1617ms
		:: modules in use:
		org.checkerframework#checker-qual;3.42.0 from central in [default]
		org.postgresql#postgresql;42.7.3 from central in [default]
		---------------------------------------------------------------------
		|                  |            modules            ||   artifacts   |
		|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
		---------------------------------------------------------------------
		|      default     |   2   |   2   |   2   |   0   ||   2   |   2   |
		---------------------------------------------------------------------
	:: retrieving :: org.apache.spark#spark-submit-parent-5fcbe154-a48e-4cc2-8ee3-c6ac52617ce2
		confs: [default]
		2 artifacts copied, 0 already retrieved (1289kB/9ms)
	24/05/07 10:24:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[WI-0][TI-0] - [INFO] 2024-05-07 10:24:03.821 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:24:03 INFO SparkContext: Running Spark version 3.5.1
	24/05/07 10:24:03 INFO SparkContext: OS info Linux, 6.5.0-28-generic, amd64
	24/05/07 10:24:03 INFO SparkContext: Java version 1.8.0_402
	24/05/07 10:24:03 INFO ResourceUtils: ==============================================================
	24/05/07 10:24:03 INFO ResourceUtils: No custom resources configured for spark.driver.
	24/05/07 10:24:03 INFO ResourceUtils: ==============================================================
	24/05/07 10:24:03 INFO SparkContext: Submitted application: (uniqueness_check)
	24/05/07 10:24:03 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
	24/05/07 10:24:03 INFO ResourceProfile: Limiting resource is cpu
	24/05/07 10:24:03 INFO ResourceProfileManager: Added ResourceProfile id: 0
	24/05/07 10:24:03 INFO SecurityManager: Changing view acls to: default
	24/05/07 10:24:03 INFO SecurityManager: Changing modify acls to: default
	24/05/07 10:24:03 INFO SecurityManager: Changing view acls groups to: 
	24/05/07 10:24:03 INFO SecurityManager: Changing modify acls groups to: 
	24/05/07 10:24:03 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: default; groups with view permissions: EMPTY; users with modify permissions: default; groups with modify permissions: EMPTY
	24/05/07 10:24:03 INFO Utils: Successfully started service 'sparkDriver' on port 34011.
	24/05/07 10:24:03 INFO SparkEnv: Registering MapOutputTracker
	24/05/07 10:24:03 INFO SparkEnv: Registering BlockManagerMaster
	24/05/07 10:24:03 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
	24/05/07 10:24:03 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
	24/05/07 10:24:03 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
	24/05/07 10:24:03 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-f96d7e15-9eb8-4cb3-ade2-5a0bf1b191a6
	24/05/07 10:24:03 INFO MemoryStore: MemoryStore started with capacity 93.3 MiB
	24/05/07 10:24:03 INFO SparkEnv: Registering OutputCommitCoordinator
	24/05/07 10:24:03 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
[WI-0][TI-0] - [INFO] 2024-05-07 10:24:04.823 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:24:03 INFO Utils: Successfully started service 'SparkUI' on port 4040.
	24/05/07 10:24:03 INFO SparkContext: Added JAR file:///tmp/jars/org.postgresql_postgresql-42.7.3.jar at spark://93296e29990d:34011/jars/org.postgresql_postgresql-42.7.3.jar with timestamp 1715048643013
	24/05/07 10:24:03 INFO SparkContext: Added JAR file:///tmp/jars/org.checkerframework_checker-qual-3.42.0.jar at spark://93296e29990d:34011/jars/org.checkerframework_checker-qual-3.42.0.jar with timestamp 1715048643013
	24/05/07 10:24:03 INFO SparkContext: Added JAR file:/opt/dolphinscheduler/libs/dolphinscheduler-data-quality-3.2.1.jar at spark://93296e29990d:34011/jars/dolphinscheduler-data-quality-3.2.1.jar with timestamp 1715048643013
	24/05/07 10:24:04 INFO Executor: Starting executor ID driver on host 93296e29990d
	24/05/07 10:24:04 INFO Executor: OS info Linux, 6.5.0-28-generic, amd64
	24/05/07 10:24:04 INFO Executor: Java version 1.8.0_402
	24/05/07 10:24:04 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
	24/05/07 10:24:04 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@358ab600 for default.
	24/05/07 10:24:04 INFO Executor: Fetching spark://93296e29990d:34011/jars/dolphinscheduler-data-quality-3.2.1.jar with timestamp 1715048643013
	24/05/07 10:24:04 INFO TransportClientFactory: Successfully created connection to 93296e29990d/172.18.1.1:34011 after 42 ms (0 ms spent in bootstraps)
	24/05/07 10:24:04 INFO Utils: Fetching spark://93296e29990d:34011/jars/dolphinscheduler-data-quality-3.2.1.jar to /tmp/spark-aaa810ff-5311-4a2f-8e34-cfd91b159550/userFiles-ed7ee51f-bd53-4c0c-bfac-a8f659735742/fetchFileTemp9099177365491809554.tmp
	24/05/07 10:24:04 INFO Executor: Adding file:/tmp/spark-aaa810ff-5311-4a2f-8e34-cfd91b159550/userFiles-ed7ee51f-bd53-4c0c-bfac-a8f659735742/dolphinscheduler-data-quality-3.2.1.jar to class loader default
	24/05/07 10:24:04 INFO Executor: Fetching spark://93296e29990d:34011/jars/org.checkerframework_checker-qual-3.42.0.jar with timestamp 1715048643013
	24/05/07 10:24:04 INFO Utils: Fetching spark://93296e29990d:34011/jars/org.checkerframework_checker-qual-3.42.0.jar to /tmp/spark-aaa810ff-5311-4a2f-8e34-cfd91b159550/userFiles-ed7ee51f-bd53-4c0c-bfac-a8f659735742/fetchFileTemp2569806744374901649.tmp
	24/05/07 10:24:04 INFO Executor: Adding file:/tmp/spark-aaa810ff-5311-4a2f-8e34-cfd91b159550/userFiles-ed7ee51f-bd53-4c0c-bfac-a8f659735742/org.checkerframework_checker-qual-3.42.0.jar to class loader default
	24/05/07 10:24:04 INFO Executor: Fetching spark://93296e29990d:34011/jars/org.postgresql_postgresql-42.7.3.jar with timestamp 1715048643013
	24/05/07 10:24:04 INFO Utils: Fetching spark://93296e29990d:34011/jars/org.postgresql_postgresql-42.7.3.jar to /tmp/spark-aaa810ff-5311-4a2f-8e34-cfd91b159550/userFiles-ed7ee51f-bd53-4c0c-bfac-a8f659735742/fetchFileTemp5266166787798683129.tmp
	24/05/07 10:24:04 INFO Executor: Adding file:/tmp/spark-aaa810ff-5311-4a2f-8e34-cfd91b159550/userFiles-ed7ee51f-bd53-4c0c-bfac-a8f659735742/org.postgresql_postgresql-42.7.3.jar to class loader default
	24/05/07 10:24:04 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37283.
	24/05/07 10:24:04 INFO NettyBlockTransferService: Server created on 93296e29990d:37283
	24/05/07 10:24:04 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
	24/05/07 10:24:04 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 93296e29990d, 37283, None)
	24/05/07 10:24:04 INFO BlockManagerMasterEndpoint: Registering block manager 93296e29990d:37283 with 93.3 MiB RAM, BlockManagerId(driver, 93296e29990d, 37283, None)
	24/05/07 10:24:04 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 93296e29990d, 37283, None)
	24/05/07 10:24:04 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 93296e29990d, 37283, None)
	24/05/07 10:24:04 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
	24/05/07 10:24:04 INFO SharedState: Warehouse path is 'file:/tmp/dolphinscheduler/exec/process/default/13001194483488/13505298546272_21/1059/3954/spark-warehouse'.
[WI-0][TI-0] - [INFO] 2024-05-07 10:24:07.387 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7251908396946565 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:24:08.399 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8761609907120743 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:24:09.402 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9636363636363636 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:24:09.849 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:24:09 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
[WI-0][TI-0] - [INFO] 2024-05-07 10:24:10.408 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9076305220883534 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:24:10.850 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:24:10 INFO CodeGenerator: Code generated in 643.546265 ms
[WI-0][TI-0] - [INFO] 2024-05-07 10:24:11.411 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8852941176470588 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:24:11.852 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:24:10 INFO DAGScheduler: Registering RDD 2 (save at JdbcWriter.java:87) as input to shuffle 0
	24/05/07 10:24:10 INFO DAGScheduler: Got map stage job 0 (save at JdbcWriter.java:87) with 1 output partitions
	24/05/07 10:24:10 INFO DAGScheduler: Final stage: ShuffleMapStage 0 (save at JdbcWriter.java:87)
	24/05/07 10:24:10 INFO DAGScheduler: Parents of final stage: List()
	24/05/07 10:24:10 INFO DAGScheduler: Missing parents: List()
	24/05/07 10:24:10 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[2] at save at JdbcWriter.java:87), which has no missing parents
	24/05/07 10:24:11 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 34.8 KiB, free 93.3 MiB)
	24/05/07 10:24:11 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 16.4 KiB, free 93.2 MiB)
	24/05/07 10:24:11 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 93296e29990d:37283 (size: 16.4 KiB, free: 93.3 MiB)
	24/05/07 10:24:11 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1585
	24/05/07 10:24:11 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[2] at save at JdbcWriter.java:87) (first 15 tasks are for partitions Vector(0))
	24/05/07 10:24:11 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
	24/05/07 10:24:11 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (93296e29990d, executor driver, partition 0, PROCESS_LOCAL, 7878 bytes) 
	24/05/07 10:24:11 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
[WI-0][TI-0] - [INFO] 2024-05-07 10:24:12.423 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9370629370629371 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:24:12.855 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:24:12 INFO CodeGenerator: Code generated in 80.223678 ms
	24/05/07 10:24:12 INFO CodeGenerator: Code generated in 30.314859 ms
	24/05/07 10:24:12 INFO CodeGenerator: Code generated in 5.777824 ms
	24/05/07 10:24:12 INFO CodeGenerator: Code generated in 11.54051 ms
	24/05/07 10:24:12 INFO CodeGenerator: Code generated in 6.048235 ms
	24/05/07 10:24:12 INFO JDBCRDD: closed connection
	24/05/07 10:24:12 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 2491 bytes result sent to driver
	24/05/07 10:24:12 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1078 ms on 93296e29990d (executor driver) (1/1)
	24/05/07 10:24:12 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
	24/05/07 10:24:12 INFO DAGScheduler: ShuffleMapStage 0 (save at JdbcWriter.java:87) finished in 1.502 s
	24/05/07 10:24:12 INFO DAGScheduler: looking for newly runnable stages
	24/05/07 10:24:12 INFO DAGScheduler: running: Set()
	24/05/07 10:24:12 INFO DAGScheduler: waiting: Set()
	24/05/07 10:24:12 INFO DAGScheduler: failed: Set()
	24/05/07 10:24:12 INFO ShufflePartitionsUtil: For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
	24/05/07 10:24:12 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[WI-0][TI-0] - [INFO] 2024-05-07 10:24:13.433 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9050847457627118 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:24:13.858 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:24:12 INFO CodeGenerator: Code generated in 37.649639 ms
	24/05/07 10:24:12 INFO DAGScheduler: Registering RDD 5 (save at JdbcWriter.java:87) as input to shuffle 1
	24/05/07 10:24:12 INFO DAGScheduler: Got map stage job 1 (save at JdbcWriter.java:87) with 1 output partitions
	24/05/07 10:24:12 INFO DAGScheduler: Final stage: ShuffleMapStage 2 (save at JdbcWriter.java:87)
	24/05/07 10:24:12 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
	24/05/07 10:24:12 INFO DAGScheduler: Missing parents: List()
	24/05/07 10:24:12 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[5] at save at JdbcWriter.java:87), which has no missing parents
	24/05/07 10:24:13 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 40.5 KiB, free 93.2 MiB)
	24/05/07 10:24:13 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 19.1 KiB, free 93.2 MiB)
	24/05/07 10:24:13 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 93296e29990d:37283 (size: 19.1 KiB, free: 93.3 MiB)
	24/05/07 10:24:13 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1585
	24/05/07 10:24:13 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[5] at save at JdbcWriter.java:87) (first 15 tasks are for partitions Vector(0))
	24/05/07 10:24:13 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
	24/05/07 10:24:13 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 1) (93296e29990d, executor driver, partition 0, NODE_LOCAL, 8032 bytes) 
	24/05/07 10:24:13 INFO Executor: Running task 0.0 in stage 2.0 (TID 1)
	24/05/07 10:24:13 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 93296e29990d:37283 in memory (size: 16.4 KiB, free: 93.3 MiB)
	24/05/07 10:24:13 INFO ShuffleBlockFetcherIterator: Getting 1 (2.9 KiB) non-empty blocks including 1 (2.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
	24/05/07 10:24:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 56 ms
	24/05/07 10:24:13 INFO CodeGenerator: Code generated in 28.963861 ms
	24/05/07 10:24:13 INFO Executor: Finished task 0.0 in stage 2.0 (TID 1). 5420 bytes result sent to driver
	24/05/07 10:24:13 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 1) in 310 ms on 93296e29990d (executor driver) (1/1)
	24/05/07 10:24:13 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
	24/05/07 10:24:13 INFO DAGScheduler: ShuffleMapStage 2 (save at JdbcWriter.java:87) finished in 0.349 s
	24/05/07 10:24:13 INFO DAGScheduler: looking for newly runnable stages
	24/05/07 10:24:13 INFO DAGScheduler: running: Set()
	24/05/07 10:24:13 INFO DAGScheduler: waiting: Set()
	24/05/07 10:24:13 INFO DAGScheduler: failed: Set()
	24/05/07 10:24:13 INFO CodeGenerator: Code generated in 52.176464 ms
	24/05/07 10:24:13 INFO SparkContext: Starting job: save at JdbcWriter.java:87
	24/05/07 10:24:13 INFO DAGScheduler: Got job 2 (save at JdbcWriter.java:87) with 1 output partitions
	24/05/07 10:24:13 INFO DAGScheduler: Final stage: ResultStage 5 (save at JdbcWriter.java:87)
	24/05/07 10:24:13 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
	24/05/07 10:24:13 INFO DAGScheduler: Missing parents: List()
	24/05/07 10:24:13 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[10] at save at JdbcWriter.java:87), which has no missing parents
[WI-0][TI-0] - [INFO] 2024-05-07 10:24:14.451 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9176470588235295 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:24:14.864 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:24:13 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 51.4 KiB, free 93.2 MiB)
	24/05/07 10:24:13 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 23.1 KiB, free 93.2 MiB)
	24/05/07 10:24:13 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 93296e29990d:37283 (size: 23.1 KiB, free: 93.3 MiB)
	24/05/07 10:24:13 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1585
	24/05/07 10:24:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[10] at save at JdbcWriter.java:87) (first 15 tasks are for partitions Vector(0))
	24/05/07 10:24:14 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
	24/05/07 10:24:14 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 2) (93296e29990d, executor driver, partition 0, NODE_LOCAL, 8043 bytes) 
	24/05/07 10:24:14 INFO Executor: Running task 0.0 in stage 5.0 (TID 2)
	24/05/07 10:24:14 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
	24/05/07 10:24:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
	24/05/07 10:24:14 INFO CodeGenerator: Code generated in 32.788628 ms
	24/05/07 10:24:14 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 93296e29990d:37283 in memory (size: 19.1 KiB, free: 93.3 MiB)
[WI-0][TI-0] - [INFO] 2024-05-07 10:24:15.453 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8208955223880597 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:24:16.461 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9233870967741935 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:24:16.880 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:24:16 INFO CodeGenerator: Code generated in 12.477669 ms
	24/05/07 10:24:16 INFO Executor: Finished task 0.0 in stage 5.0 (TID 2). 6711 bytes result sent to driver
	24/05/07 10:24:16 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 2) in 2251 ms on 93296e29990d (executor driver) (1/1)
	24/05/07 10:24:16 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
	24/05/07 10:24:16 INFO DAGScheduler: ResultStage 5 (save at JdbcWriter.java:87) finished in 2.554 s
	24/05/07 10:24:16 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
	24/05/07 10:24:16 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
	24/05/07 10:24:16 INFO DAGScheduler: Job 2 finished: save at JdbcWriter.java:87, took 2.604611 s
	24/05/07 10:24:16 INFO DAGScheduler: Registering RDD 13 (save at JdbcWriter.java:87) as input to shuffle 2
	24/05/07 10:24:16 INFO DAGScheduler: Got map stage job 3 (save at JdbcWriter.java:87) with 1 output partitions
	24/05/07 10:24:16 INFO DAGScheduler: Final stage: ShuffleMapStage 6 (save at JdbcWriter.java:87)
	24/05/07 10:24:16 INFO DAGScheduler: Parents of final stage: List()
	24/05/07 10:24:16 INFO DAGScheduler: Missing parents: List()
	24/05/07 10:24:16 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[13] at save at JdbcWriter.java:87), which has no missing parents
	24/05/07 10:24:16 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 34.8 KiB, free 93.2 MiB)
	24/05/07 10:24:16 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 16.5 KiB, free 93.2 MiB)
	24/05/07 10:24:16 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 93296e29990d:37283 (size: 16.5 KiB, free: 93.3 MiB)
	24/05/07 10:24:16 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1585
	24/05/07 10:24:16 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[13] at save at JdbcWriter.java:87) (first 15 tasks are for partitions Vector(0))
	24/05/07 10:24:16 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0
	24/05/07 10:24:16 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 3) (93296e29990d, executor driver, partition 0, PROCESS_LOCAL, 7878 bytes) 
	24/05/07 10:24:16 INFO Executor: Running task 0.0 in stage 6.0 (TID 3)
	24/05/07 10:24:16 INFO JDBCRDD: closed connection
[WI-0][TI-0] - [INFO] 2024-05-07 10:24:17.488 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.869942196531792 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:24:17.901 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:24:17 INFO Executor: Finished task 0.0 in stage 6.0 (TID 3). 2534 bytes result sent to driver
	24/05/07 10:24:17 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 93296e29990d:37283 in memory (size: 23.1 KiB, free: 93.3 MiB)
	24/05/07 10:24:17 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 3) in 267 ms on 93296e29990d (executor driver) (1/1)
	24/05/07 10:24:17 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
	24/05/07 10:24:17 INFO DAGScheduler: ShuffleMapStage 6 (save at JdbcWriter.java:87) finished in 0.291 s
	24/05/07 10:24:17 INFO DAGScheduler: looking for newly runnable stages
	24/05/07 10:24:17 INFO DAGScheduler: running: Set()
	24/05/07 10:24:17 INFO DAGScheduler: waiting: Set()
	24/05/07 10:24:17 INFO DAGScheduler: failed: Set()
	24/05/07 10:24:17 INFO ShufflePartitionsUtil: For shuffle(2), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
	24/05/07 10:24:17 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
	24/05/07 10:24:17 INFO DAGScheduler: Registering RDD 16 (save at JdbcWriter.java:87) as input to shuffle 3
	24/05/07 10:24:17 INFO DAGScheduler: Got map stage job 4 (save at JdbcWriter.java:87) with 1 output partitions
	24/05/07 10:24:17 INFO DAGScheduler: Final stage: ShuffleMapStage 8 (save at JdbcWriter.java:87)
	24/05/07 10:24:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
	24/05/07 10:24:17 INFO DAGScheduler: Missing parents: List()
	24/05/07 10:24:17 INFO DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[16] at save at JdbcWriter.java:87), which has no missing parents
	24/05/07 10:24:17 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 40.6 KiB, free 93.2 MiB)
	24/05/07 10:24:17 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 19.1 KiB, free 93.2 MiB)
	24/05/07 10:24:17 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 93296e29990d:37283 (size: 19.1 KiB, free: 93.3 MiB)
	24/05/07 10:24:17 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1585
	24/05/07 10:24:17 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[16] at save at JdbcWriter.java:87) (first 15 tasks are for partitions Vector(0))
	24/05/07 10:24:17 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0
	24/05/07 10:24:17 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 4) (93296e29990d, executor driver, partition 0, NODE_LOCAL, 8032 bytes) 
	24/05/07 10:24:17 INFO Executor: Running task 0.0 in stage 8.0 (TID 4)
	24/05/07 10:24:17 INFO ShuffleBlockFetcherIterator: Getting 1 (2.9 KiB) non-empty blocks including 1 (2.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
	24/05/07 10:24:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
	24/05/07 10:24:17 INFO Executor: Finished task 0.0 in stage 8.0 (TID 4). 5420 bytes result sent to driver
	24/05/07 10:24:17 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 4) in 33 ms on 93296e29990d (executor driver) (1/1)
	24/05/07 10:24:17 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
	24/05/07 10:24:17 INFO DAGScheduler: ShuffleMapStage 8 (save at JdbcWriter.java:87) finished in 0.045 s
	24/05/07 10:24:17 INFO DAGScheduler: looking for newly runnable stages
	24/05/07 10:24:17 INFO DAGScheduler: running: Set()
	24/05/07 10:24:17 INFO DAGScheduler: waiting: Set()
	24/05/07 10:24:17 INFO DAGScheduler: failed: Set()
	24/05/07 10:24:17 INFO CodeGenerator: Code generated in 12.141847 ms
	24/05/07 10:24:17 INFO SparkContext: Starting job: save at JdbcWriter.java:87
	24/05/07 10:24:17 INFO DAGScheduler: Got job 5 (save at JdbcWriter.java:87) with 1 output partitions
	24/05/07 10:24:17 INFO DAGScheduler: Final stage: ResultStage 11 (save at JdbcWriter.java:87)
	24/05/07 10:24:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)
	24/05/07 10:24:17 INFO DAGScheduler: Missing parents: List()
	24/05/07 10:24:17 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[21] at save at JdbcWriter.java:87), which has no missing parents
	24/05/07 10:24:17 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 49.2 KiB, free 93.1 MiB)
	24/05/07 10:24:17 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 22.7 KiB, free 93.1 MiB)
	24/05/07 10:24:17 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 93296e29990d:37283 (size: 22.7 KiB, free: 93.2 MiB)
	24/05/07 10:24:17 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1585
	24/05/07 10:24:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[21] at save at JdbcWriter.java:87) (first 15 tasks are for partitions Vector(0))
	24/05/07 10:24:17 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks resource profile 0
	24/05/07 10:24:17 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 5) (93296e29990d, executor driver, partition 0, NODE_LOCAL, 8043 bytes) 
	24/05/07 10:24:17 INFO Executor: Running task 0.0 in stage 11.0 (TID 5)
	24/05/07 10:24:17 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
	24/05/07 10:24:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
	24/05/07 10:24:17 INFO CodeGenerator: Code generated in 9.744732 ms
	24/05/07 10:24:17 INFO CodeGenerator: Code generated in 19.980518 ms
	24/05/07 10:24:17 INFO Executor: Finished task 0.0 in stage 11.0 (TID 5). 6625 bytes result sent to driver
	24/05/07 10:24:17 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 5) in 93 ms on 93296e29990d (executor driver) (1/1)
	24/05/07 10:24:17 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
	24/05/07 10:24:17 INFO DAGScheduler: ResultStage 11 (save at JdbcWriter.java:87) finished in 0.126 s
	24/05/07 10:24:17 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
	24/05/07 10:24:17 INFO TaskSchedulerImpl: Killing all running tasks in stage 11: Stage finished
	24/05/07 10:24:17 INFO DAGScheduler: Job 5 finished: save at JdbcWriter.java:87, took 0.135655 s
	24/05/07 10:24:17 WARN FileSystem: Failed to initialize fileystem hdfs://mycluster:8020/user/default/data_quality_error_data/0_1059_%5Bnull%20check%5D%20filtered%20data%20persistence: java.lang.IllegalArgumentException: java.net.UnknownHostException: mycluster
	Exception in thread "main" java.lang.IllegalArgumentException: java.net.UnknownHostException: mycluster
		at org.apache.hadoop.security.SecurityUtil.buildTokenService(SecurityUtil.java:466)
		at org.apache.hadoop.hdfs.NameNodeProxiesClient.createProxyWithClientProtocol(NameNodeProxiesClient.java:134)
		at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:374)
		at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:308)
		at org.apache.hadoop.hdfs.DistributedFileSystem.initDFSClient(DistributedFileSystem.java:202)
		at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:187)
		at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469)
		at org.apache.hadoop.fs.FileSystem.access$300(FileSystem.java:174)
		at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3574)
		at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3521)
		at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540)
		at org.apache.hadoop.fs.Path.getFileSystem(Path.java:365)
		at org.apache.spark.sql.execution.datasources.DataSource.planForWritingFileFormat(DataSource.scala:454)
		at org.apache.spark.sql.execution.datasources.DataSource.planForWriting(DataSource.scala:530)
		at org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)
		at org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)
		at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:240)
		at org.apache.spark.sql.DataFrameWriter.csv(DataFrameWriter.scala:850)
		at org.apache.dolphinscheduler.data.quality.flow.batch.writer.file.BaseFileWriter.outputImpl(BaseFileWriter.java:114)
		at org.apache.dolphinscheduler.data.quality.flow.batch.writer.file.HdfsFileWriter.write(HdfsFileWriter.java:40)
		at org.apache.dolphinscheduler.data.quality.execution.SparkBatchExecution.executeWriter(SparkBatchExecution.java:132)
		at org.apache.dolphinscheduler.data.quality.execution.SparkBatchExecution.execute(SparkBatchExecution.java:58)
		at org.apache.dolphinscheduler.data.quality.context.DataQualityContext.execute(DataQualityContext.java:62)
		at org.apache.dolphinscheduler.data.quality.DataQualityApplication.main(DataQualityApplication.java:78)
		at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
		at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
		at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
		at java.lang.reflect.Method.invoke(Method.java:498)
		at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
		at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:1029)
		at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:194)
		at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:217)
		at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:91)
		at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1120)
		at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1129)
		at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
	Caused by: java.net.UnknownHostException: mycluster
		... 36 more
	24/05/07 10:24:17 INFO SparkContext: Invoking stop() from shutdown hook
	24/05/07 10:24:17 INFO SparkContext: SparkContext is stopping with exitCode 0.
	24/05/07 10:24:17 INFO SparkUI: Stopped Spark web UI at http://93296e29990d:4040
	24/05/07 10:24:17 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
	24/05/07 10:24:17 INFO MemoryStore: MemoryStore cleared
	24/05/07 10:24:17 INFO BlockManager: BlockManager stopped
	24/05/07 10:24:17 INFO BlockManagerMaster: BlockManagerMaster stopped
	24/05/07 10:24:17 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
	24/05/07 10:24:17 INFO SparkContext: Successfully stopped SparkContext
	24/05/07 10:24:17 INFO ShutdownHookManager: Shutdown hook called
	24/05/07 10:24:17 INFO ShutdownHookManager: Deleting directory /tmp/spark-aaa810ff-5311-4a2f-8e34-cfd91b159550
	24/05/07 10:24:17 INFO ShutdownHookManager: Deleting directory /tmp/spark-5a957982-65e6-4c9f-bbd3-a61daa198aeb
[WI-1059][TI-3954] - [INFO] 2024-05-07 10:24:17.903 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13001194483488/13505298546272_21/1059/3954, processId:91 ,exitStatusCode:1 ,processWaitForStatus:true ,processExitValue:1
[WI-1059][TI-3954] - [INFO] 2024-05-07 10:24:17.905 +0800 o.a.d.p.t.a.u.LogUtils:[79] - Start finding appId in /opt/dolphinscheduler/logs/20240507/13505298546272/21/1059/3954.log, fetch way: log 
[WI-1059][TI-3954] - [INFO] 2024-05-07 10:24:17.908 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-1059][TI-3954] - [INFO] 2024-05-07 10:24:17.909 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-1059][TI-3954] - [INFO] 2024-05-07 10:24:17.909 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-1059][TI-3954] - [INFO] 2024-05-07 10:24:17.911 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-1059][TI-3954] - [INFO] 2024-05-07 10:24:17.919 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: FAILURE to master : 172.18.1.1:1234
[WI-1059][TI-3954] - [INFO] 2024-05-07 10:24:17.920 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-1059][TI-3954] - [INFO] 2024-05-07 10:24:17.920 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13001194483488/13505298546272_21/1059/3954
[WI-1059][TI-3954] - [INFO] 2024-05-07 10:24:17.951 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13001194483488/13505298546272_21/1059/3954
[WI-1059][TI-3954] - [INFO] 2024-05-07 10:24:17.958 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-0] - [INFO] 2024-05-07 10:24:22.560 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7371601208459215 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:24:26.625 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7252044621564956 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [WARN] 2024-05-07 10:29:44.539 +0800 o.s.c.k.c.p.AbstractKubernetesProfileEnvironmentPostProcessor:[258] - Not running inside kubernetes. Skipping 'kubernetes' profile activation.
[WI-0][TI-0] - [WARN] 2024-05-07 10:29:49.378 +0800 o.s.c.k.c.p.AbstractKubernetesProfileEnvironmentPostProcessor:[258] - Not running inside kubernetes. Skipping 'kubernetes' profile activation.
[WI-0][TI-0] - [INFO] 2024-05-07 10:29:49.442 +0800 o.a.d.s.w.WorkerServer:[634] - No active profile set, falling back to 1 default profile: "default"
[WI-0][TI-0] - [INFO] 2024-05-07 10:29:57.656 +0800 o.s.c.c.s.GenericScope:[283] - BeanFactory id=7e7bf7c6-2cb3-34d2-a0d5-a56161c67d0e
[WI-0][TI-0] - [INFO] 2024-05-07 10:29:59.397 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'org.springframework.cloud.commons.config.CommonsConfigAutoConfiguration' of type [org.springframework.cloud.commons.config.CommonsConfigAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-05-07 10:29:59.427 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'org.springframework.cloud.client.loadbalancer.LoadBalancerDefaultMappingsProviderAutoConfiguration' of type [org.springframework.cloud.client.loadbalancer.LoadBalancerDefaultMappingsProviderAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-05-07 10:29:59.430 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'loadBalancerClientsDefaultsMappingsProvider' of type [org.springframework.cloud.client.loadbalancer.LoadBalancerDefaultMappingsProviderAutoConfiguration$$Lambda$392/302905744] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-05-07 10:29:59.438 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'defaultsBindHandlerAdvisor' of type [org.springframework.cloud.commons.config.DefaultsBindHandlerAdvisor] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-05-07 10:29:59.704 +0800 o.a.d.c.u.NetUtils:[312] - Get all NetworkInterfaces: [name:eth0 (eth0), name:lo (lo)]
[WI-0][TI-0] - [INFO] 2024-05-07 10:29:59.802 +0800 o.a.d.s.w.c.WorkerConfig:[98] - 
****************************Worker Configuration**************************************
  listen-port -> 1234
  exec-threads -> 100
  max-heartbeat-interval -> PT10S
  host-weight -> 100
  tenantConfig -> TenantConfig(autoCreateTenantEnabled=true, distributedTenantEnabled=false, defaultTenantEnabled=false)
  server-load-protection -> WorkerServerLoadProtection(enabled=true, maxCpuUsagePercentageThresholds=0.7, maxJVMMemoryUsagePercentageThresholds=0.7, maxSystemMemoryUsagePercentageThresholds=0.7, maxDiskUsagePercentageThresholds=0.7)
  registry-disconnect-strategy -> ConnectStrategyProperties(strategy=WAITING, maxWaitingTime=PT1M40S)
  task-execute-threads-full-policy: REJECT
  address -> 172.18.1.1:1234
  registry-path: /nodes/worker/172.18.1.1:1234
****************************Worker Configuration**************************************
[WI-0][TI-0] - [INFO] 2024-05-07 10:29:59.815 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'workerConfig' of type [org.apache.dolphinscheduler.server.worker.config.WorkerConfig$$EnhancerBySpringCGLIB$$da954724] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:00.256 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'io.kubernetes.client.spring.extended.manifests.config.KubernetesManifestsAutoConfiguration' of type [io.kubernetes.client.spring.extended.manifests.config.KubernetesManifestsAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:00.370 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'kubernetes.manifests-io.kubernetes.client.spring.extended.manifests.config.KubernetesManifestsProperties' of type [io.kubernetes.client.spring.extended.manifests.config.KubernetesManifestsProperties] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:00.407 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'io.kubernetes.client.spring.extended.controller.config.KubernetesInformerAutoConfiguration' of type [io.kubernetes.client.spring.extended.controller.config.KubernetesInformerAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:00.450 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'defaultApiClient' of type [io.kubernetes.client.openapi.ApiClient] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:02.085 +0800 o.e.j.u.log:[170] - Logging initialized @31807ms to org.eclipse.jetty.util.log.Slf4jLog
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:03.233 +0800 o.s.b.w.e.j.JettyServletWebServerFactory:[166] - Server initialized with port: 1235
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:03.255 +0800 o.e.j.s.Server:[375] - jetty-9.4.48.v20220622; built: 2022-06-21T20:42:25.880Z; git: 6b67c5719d1f4371b33655ff2d047d24e171e49a; jvm 1.8.0_402-b06
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:03.788 +0800 o.e.j.s.h.C.application:[2368] - Initializing Spring embedded WebApplicationContext
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:03.878 +0800 o.s.b.w.s.c.ServletWebServerApplicationContext:[292] - Root WebApplicationContext: initialization completed in 14401 ms
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:05.973 +0800 o.e.j.s.session:[334] - DefaultSessionIdManager workerName=node0
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:06.058 +0800 o.e.j.s.session:[339] - No SessionScavenger set, using defaults
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:06.074 +0800 o.e.j.s.session:[132] - node0 Scavenging every 600000ms
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:06.098 +0800 o.e.j.s.h.ContextHandler:[921] - Started o.s.b.w.e.j.JettyEmbeddedWebAppContext@52433946{application,/,[file:///tmp/jetty-docbase.1235.1063917492611583482/],AVAILABLE}
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:06.114 +0800 o.e.j.s.Server:[415] - Started @35832ms
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:06.660 +0800 o.a.c.f.i.CuratorFrameworkImpl:[338] - Starting
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:06.681 +0800 o.a.z.ZooKeeper:[98] - Client environment:zookeeper.version=3.8.0-5a02a05eddb59aee6ac762f7ea82e92a68eb9c0f, built on 2022-02-25 08:49 UTC
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:06.682 +0800 o.a.z.ZooKeeper:[98] - Client environment:host.name=b2617105c628
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:06.682 +0800 o.a.z.ZooKeeper:[98] - Client environment:java.version=1.8.0_402
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:06.692 +0800 o.a.z.ZooKeeper:[98] - Client environment:java.vendor=Temurin
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:06.693 +0800 o.a.z.ZooKeeper:[98] - Client environment:java.home=/opt/java/openjdk
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:06.693 +0800 o.a.z.ZooKeeper:[98] - Client environment:java.class.path=/opt/dolphinscheduler/conf:/opt/dolphinscheduler/libs/kerb-client-1.0.1.jar:/opt/dolphinscheduler/libs/spring-cloud-starter-kubernetes-client-config-2.1.3.jar:/opt/dolphinscheduler/libs/oauth2-oidc-sdk-9.35.jar:/opt/dolphinscheduler/libs/jsqlparser-4.4.jar:/opt/dolphinscheduler/libs/reactive-streams-1.0.4.jar:/opt/dolphinscheduler/libs/kubernetes-model-extensions-5.10.2.jar:/opt/dolphinscheduler/libs/zookeeper-3.8.0.jar:/opt/dolphinscheduler/libs/kubernetes-model-apps-5.10.2.jar:/opt/dolphinscheduler/libs/grpc-api-1.41.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-pigeon-3.2.1.jar:/opt/dolphinscheduler/libs/client-java-api-13.0.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-obs-3.2.1.jar:/opt/dolphinscheduler/libs/spring-web-5.3.22.jar:/opt/dolphinscheduler/libs/aws-java-sdk-emr-1.12.300.jar:/opt/dolphinscheduler/libs/spring-context-5.3.22.jar:/opt/dolphinscheduler/libs/gapic-google-cloud-storage-v2-2.18.0-alpha.jar:/opt/dolphinscheduler/libs/spring-cloud-kubernetes-client-config-2.1.3.jar:/opt/dolphinscheduler/libs/jetty-io-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/annotations-13.0.jar:/opt/dolphinscheduler/libs/jpam-1.1.jar:/opt/dolphinscheduler/libs/joda-time-2.10.13.jar:/opt/dolphinscheduler/libs/spring-cloud-kubernetes-client-autoconfig-2.1.3.jar:/opt/dolphinscheduler/libs/kerb-identity-1.0.1.jar:/opt/dolphinscheduler/libs/vertica-jdbc-12.0.4-0.jar:/opt/dolphinscheduler/libs/grpc-googleapis-1.52.1.jar:/opt/dolphinscheduler/libs/aliyun-java-sdk-kms-2.11.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-dvc-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-hana-3.2.1.jar:/opt/dolphinscheduler/libs/kubernetes-httpclient-okhttp-6.0.0.jar:/opt/dolphinscheduler/libs/jline-2.12.jar:/opt/dolphinscheduler/libs/sshd-core-2.8.0.jar:/opt/dolphinscheduler/libs/jna-platform-5.10.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-sqlserver-3.2.1.jar:/opt/dolphinscheduler/libs/commons-beanutils-1.9.4.jar:/opt/dolphinscheduler/libs/grpc-services-1.41.0.jar:/opt/dolphinscheduler/libs/jmespath-java-1.12.300.jar:/opt/dolphinscheduler/libs/curator-client-5.3.0.jar:/opt/dolphinscheduler/libs/proto-google-common-protos-2.0.1.jar:/opt/dolphinscheduler/libs/mybatis-3.5.10.jar:/opt/dolphinscheduler/libs/jackson-annotations-2.13.4.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-all-3.2.1.jar:/opt/dolphinscheduler/libs/jakarta.xml.bind-api-2.3.3.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-jupyter-3.2.1.jar:/opt/dolphinscheduler/libs/mybatis-plus-extension-3.5.2.jar:/opt/dolphinscheduler/libs/j2objc-annotations-1.3.jar:/opt/dolphinscheduler/libs/Java-WebSocket-1.5.1.jar:/opt/dolphinscheduler/libs/azure-storage-common-12.20.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-sagemaker-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-databend-3.2.1.jar:/opt/dolphinscheduler/libs/google-auth-library-oauth2-http-1.15.0.jar:/opt/dolphinscheduler/libs/jetty-security-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-python-3.2.1.jar:/opt/dolphinscheduler/libs/snappy-java-1.1.10.1.jar:/opt/dolphinscheduler/libs/kubernetes-model-batch-5.10.2.jar:/opt/dolphinscheduler/libs/netty-transport-native-epoll-4.1.53.Final-linux-x86_64.jar:/opt/dolphinscheduler/libs/jackson-core-asl-1.9.13.jar:/opt/dolphinscheduler/libs/gson-fire-1.8.5.jar:/opt/dolphinscheduler/libs/clickhouse-jdbc-0.4.6.jar:/opt/dolphinscheduler/libs/grpc-netty-shaded-1.41.0.jar:/opt/dolphinscheduler/libs/caffeine-2.9.3.jar:/opt/dolphinscheduler/libs/aliyun-java-sdk-core-4.5.10.jar:/opt/dolphinscheduler/libs/jackson-module-jaxb-annotations-2.13.3.jar:/opt/dolphinscheduler/libs/jetty-http-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/jersey-servlet-1.19.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-dinky-3.2.1.jar:/opt/dolphinscheduler/libs/simpleclient_tracer_common-0.15.0.jar:/opt/dolphinscheduler/libs/netty-handler-4.1.53.Final.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-datafactory-3.2.1.jar:/opt/dolphinscheduler/libs/json-path-2.7.0.jar:/opt/dolphinscheduler/libs/mybatis-plus-annotation-3.5.2.jar:/opt/dolphinscheduler/libs/azure-resourcemanager-datafactory-1.0.0-beta.19.jar:/opt/dolphinscheduler/libs/commons-codec-1.11.jar:/opt/dolphinscheduler/libs/dolphinscheduler-extract-master-3.2.1.jar:/opt/dolphinscheduler/libs/spring-aop-5.3.22.jar:/opt/dolphinscheduler/libs/kubernetes-model-core-5.10.2.jar:/opt/dolphinscheduler/libs/kubernetes-model-networking-5.10.2.jar:/opt/dolphinscheduler/libs/kotlin-stdlib-jdk7-1.6.21.jar:/opt/dolphinscheduler/libs/kerby-xdr-1.0.1.jar:/opt/dolphinscheduler/libs/aliyun-java-sdk-ram-3.1.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-k8s-3.2.1.jar:/opt/dolphinscheduler/libs/guava-31.1-jre.jar:/opt/dolphinscheduler/libs/netty-codec-dns-4.1.53.Final.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-kubeflow-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-azure-sql-3.2.1.jar:/opt/dolphinscheduler/libs/HikariCP-4.0.3.jar:/opt/dolphinscheduler/libs/hive-metastore-2.3.9.jar:/opt/dolphinscheduler/libs/msal4j-1.13.3.jar:/opt/dolphinscheduler/libs/jackson-core-2.13.4.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-hive-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-mr-3.2.1.jar:/opt/dolphinscheduler/libs/kubernetes-model-node-5.10.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-common-3.2.1.jar:/opt/dolphinscheduler/libs/jose4j-0.7.8.jar:/opt/dolphinscheduler/libs/jul-to-slf4j-1.7.36.jar:/opt/dolphinscheduler/libs/azure-identity-1.7.1.jar:/opt/dolphinscheduler/libs/spring-boot-autoconfigure-2.7.3.jar:/opt/dolphinscheduler/libs/commons-math3-3.1.1.jar:/opt/dolphinscheduler/libs/jackson-jaxrs-json-provider-2.13.3.jar:/opt/dolphinscheduler/libs/perfmark-api-0.23.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-doris-3.2.1.jar:/opt/dolphinscheduler/libs/httpclient-4.5.13.jar:/opt/dolphinscheduler/libs/hive-service-2.3.9.jar:/opt/dolphinscheduler/libs/kerby-util-1.0.1.jar:/opt/dolphinscheduler/libs/commons-collections-3.2.2.jar:/opt/dolphinscheduler/libs/hadoop-yarn-client-3.2.4.jar:/opt/dolphinscheduler/libs/commons-text-1.8.jar:/opt/dolphinscheduler/libs/dolphinscheduler-worker-3.2.1.jar:/opt/dolphinscheduler/libs/hadoop-yarn-common-3.2.4.jar:/opt/dolphinscheduler/libs/zeppelin-client-0.10.1.jar:/opt/dolphinscheduler/libs/azure-core-management-1.10.1.jar:/opt/dolphinscheduler/libs/hadoop-mapreduce-client-jobclient-3.2.4.jar:/opt/dolphinscheduler/libs/jta-1.1.jar:/opt/dolphinscheduler/libs/annotations-4.1.1.4.jar:/opt/dolphinscheduler/libs/dolphinscheduler-extract-alert-3.2.1.jar:/opt/dolphinscheduler/libs/curator-framework-5.3.0.jar:/opt/dolphinscheduler/libs/hive-jdbc-2.3.9.jar:/opt/dolphinscheduler/libs/kyuubi-hive-jdbc-shaded-1.7.0.jar:/opt/dolphinscheduler/libs/client-java-proto-13.0.2.jar:/opt/dolphinscheduler/libs/checker-qual-3.19.0.jar:/opt/dolphinscheduler/libs/jetty-servlet-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/google-cloud-core-grpc-2.10.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-shell-3.2.1.jar:/opt/dolphinscheduler/libs/spring-security-rsa-1.0.10.RELEASE.jar:/opt/dolphinscheduler/libs/avro-1.7.7.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-postgresql-3.2.1.jar:/opt/dolphinscheduler/libs/netty-nio-client-2.17.282.jar:/opt/dolphinscheduler/libs/spring-webmvc-5.3.22.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-mysql-3.2.1.jar:/opt/dolphinscheduler/libs/opentracing-util-0.33.0.jar:/opt/dolphinscheduler/libs/auto-value-1.10.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-all-3.2.1.jar:/opt/dolphinscheduler/libs/jetcd-core-0.5.11.jar:/opt/dolphinscheduler/libs/grpc-context-1.41.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-datasync-3.2.1.jar:/opt/dolphinscheduler/libs/jackson-dataformat-cbor-2.13.3.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-gcs-3.2.1.jar:/opt/dolphinscheduler/libs/client-java-extended-13.0.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-redshift-3.2.1.jar:/opt/dolphinscheduler/libs/opencsv-2.3.jar:/opt/dolphinscheduler/libs/jcip-annotations-1.0-1.jar:/opt/dolphinscheduler/libs/accessors-smart-2.4.8.jar:/opt/dolphinscheduler/libs/hadoop-client-3.2.4.jar:/opt/dolphinscheduler/libs/commons-collections4-4.3.jar:/opt/dolphinscheduler/libs/metrics-core-4.2.11.jar:/opt/dolphinscheduler/libs/netty-resolver-4.1.53.Final.jar:/opt/dolphinscheduler/libs/parquet-hadoop-bundle-1.8.1.jar:/opt/dolphinscheduler/libs/bucket4j-core-6.2.0.jar:/opt/dolphinscheduler/libs/spring-cloud-starter-3.1.3.jar:/opt/dolphinscheduler/libs/mssql-jdbc-11.2.1.jre8.jar:/opt/dolphinscheduler/libs/netty-tcnative-boringssl-static-2.0.53.Final.jar:/opt/dolphinscheduler/libs/kubernetes-model-coordination-5.10.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-linkis-3.2.1.jar:/opt/dolphinscheduler/libs/commons-net-3.6.jar:/opt/dolphinscheduler/libs/netty-transport-native-kqueue-4.1.53.Final-osx-x86_64.jar:/opt/dolphinscheduler/libs/dolphinscheduler-meter-3.2.1.jar:/opt/dolphinscheduler/libs/kubernetes-client-api-6.0.0.jar:/opt/dolphinscheduler/libs/kubernetes-model-certificates-5.10.2.jar:/opt/dolphinscheduler/libs/opencensus-api-0.31.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-mlflow-3.2.1.jar:/opt/dolphinscheduler/libs/kotlin-stdlib-jdk8-1.6.21.jar:/opt/dolphinscheduler/libs/dolphinscheduler-registry-jdbc-3.2.1.jar:/opt/dolphinscheduler/libs/audience-annotations-0.12.0.jar:/opt/dolphinscheduler/libs/simpleclient_httpserver-0.15.0.jar:/opt/dolphinscheduler/libs/jetty-xml-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/kerby-asn1-1.0.1.jar:/opt/dolphinscheduler/libs/lang-tag-1.6.jar:/opt/dolphinscheduler/libs/api-common-2.6.0.jar:/opt/dolphinscheduler/libs/HdrHistogram-2.1.12.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-abs-3.2.1.jar:/opt/dolphinscheduler/libs/failsafe-2.4.4.jar:/opt/dolphinscheduler/libs/hbase-noop-htrace-4.1.1.jar:/opt/dolphinscheduler/libs/jamon-runtime-2.3.1.jar:/opt/dolphinscheduler/libs/jetty-util-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/threetenbp-1.6.5.jar:/opt/dolphinscheduler/libs/jakarta.activation-api-1.2.2.jar:/opt/dolphinscheduler/libs/kubernetes-model-common-5.10.2.jar:/opt/dolphinscheduler/libs/okhttp-4.9.3.jar:/opt/dolphinscheduler/libs/profiles-2.17.282.jar:/opt/dolphinscheduler/libs/hadoop-auth-3.2.4.jar:/opt/dolphinscheduler/libs/grpc-netty-1.41.0.jar:/opt/dolphinscheduler/libs/httpcore-nio-4.4.15.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-seatunnel-3.2.1.jar:/opt/dolphinscheduler/libs/aws-java-sdk-sagemaker-1.12.300.jar:/opt/dolphinscheduler/libs/oshi-core-6.1.1.jar:/opt/dolphinscheduler/libs/bonecp-0.8.0.RELEASE.jar:/opt/dolphinscheduler/libs/jackson-module-parameter-names-2.13.3.jar:/opt/dolphinscheduler/libs/bcutil-jdk15on-1.69.jar:/opt/dolphinscheduler/libs/aws-json-protocol-2.17.282.jar:/opt/dolphinscheduler/libs/dolphinscheduler-extract-base-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-all-3.2.1.jar:/opt/dolphinscheduler/libs/derby-10.14.2.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-snowflake-3.2.1.jar:/opt/dolphinscheduler/libs/netty-codec-http2-4.1.53.Final.jar:/opt/dolphinscheduler/libs/jetty-continuation-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/jackson-mapper-asl-1.9.13.jar:/opt/dolphinscheduler/libs/datanucleus-core-4.1.17.jar:/opt/dolphinscheduler/libs/netty-tcnative-boringssl-static-2.0.53.Final-osx-aarch_64.jar:/opt/dolphinscheduler/libs/failureaccess-1.0.1.jar:/opt/dolphinscheduler/libs/error_prone_annotations-2.5.1.jar:/opt/dolphinscheduler/libs/kerb-admin-1.0.1.jar:/opt/dolphinscheduler/libs/token-provider-1.0.1.jar:/opt/dolphinscheduler/libs/reactor-netty-core-1.0.22.jar:/opt/dolphinscheduler/libs/dolphinscheduler-registry-all-3.2.1.jar:/opt/dolphinscheduler/libs/jakarta.servlet-api-4.0.4.jar:/opt/dolphinscheduler/libs/http-client-spi-2.17.282.jar:/opt/dolphinscheduler/libs/regions-2.17.282.jar:/opt/dolphinscheduler/libs/logback-core-1.2.11.jar:/opt/dolphinscheduler/libs/json-1.8.jar:/opt/dolphinscheduler/libs/gax-grpc-2.23.0.jar:/opt/dolphinscheduler/libs/google-http-client-1.42.3.jar:/opt/dolphinscheduler/libs/hive-serde-2.3.9.jar:/opt/dolphinscheduler/libs/jettison-1.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-http-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-registry-zookeeper-3.2.1.jar:/opt/dolphinscheduler/libs/spring-security-crypto-5.7.3.jar:/opt/dolphinscheduler/libs/auth-2.17.282.jar:/opt/dolphinscheduler/libs/proto-google-cloud-storage-v2-2.18.0-alpha.jar:/opt/dolphinscheduler/libs/jetty-server-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/javax.annotation-api-1.3.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-starrocks-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-dataquality-3.2.1.jar:/opt/dolphinscheduler/libs/jcl-over-slf4j-1.7.36.jar:/opt/dolphinscheduler/libs/commons-lang3-3.12.0.jar:/opt/dolphinscheduler/libs/tomcat-embed-el-9.0.65.jar:/opt/dolphinscheduler/libs/opentracing-noop-0.33.0.jar:/opt/dolphinscheduler/libs/client-java-13.0.2.jar:/opt/dolphinscheduler/libs/spring-beans-5.3.22.jar:/opt/dolphinscheduler/libs/snakeyaml-1.33.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-ssh-3.2.1.jar:/opt/dolphinscheduler/libs/commons-pool-1.6.jar:/opt/dolphinscheduler/libs/javax.servlet-api-3.1.0.jar:/opt/dolphinscheduler/libs/hadoop-common-3.2.4.jar:/opt/dolphinscheduler/libs/kubernetes-model-apiextensions-5.10.2.jar:/opt/dolphinscheduler/libs/spring-boot-2.7.3.jar:/opt/dolphinscheduler/libs/bcprov-ext-jdk15on-1.69.jar:/opt/dolphinscheduler/libs/spring-boot-starter-2.7.3.jar:/opt/dolphinscheduler/libs/paranamer-2.3.jar:/opt/dolphinscheduler/libs/httpmime-4.5.13.jar:/opt/dolphinscheduler/libs/reactor-core-3.4.22.jar:/opt/dolphinscheduler/libs/azure-core-1.36.0.jar:/opt/dolphinscheduler/libs/bcpkix-jdk15on-1.69.jar:/opt/dolphinscheduler/libs/kubernetes-model-scheduling-5.10.2.jar:/opt/dolphinscheduler/libs/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/dolphinscheduler/libs/websocket-client-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/unirest-java-3.7.04-standalone.jar:/opt/dolphinscheduler/libs/hadoop-mapreduce-client-core-3.2.4.jar:/opt/dolphinscheduler/libs/google-auth-library-credentials-1.15.0.jar:/opt/dolphinscheduler/libs/azure-storage-internal-avro-12.6.0.jar:/opt/dolphinscheduler/libs/jackson-datatype-jdk8-2.13.3.jar:/opt/dolphinscheduler/libs/spring-expression-5.3.22.jar:/opt/dolphinscheduler/libs/aspectjweaver-1.9.7.jar:/opt/dolphinscheduler/libs/websocket-common-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/client-java-api-fluent-13.0.2.jar:/opt/dolphinscheduler/libs/mybatis-plus-3.5.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-athena-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-oss-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-openmldb-3.2.1.jar:/opt/dolphinscheduler/libs/curator-recipes-5.3.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-api-3.2.1.jar:/opt/dolphinscheduler/libs/netty-all-4.1.53.Final.jar:/opt/dolphinscheduler/libs/netty-resolver-dns-4.1.53.Final.jar:/opt/dolphinscheduler/libs/kubernetes-model-autoscaling-5.10.2.jar:/opt/dolphinscheduler/libs/kerb-util-1.0.1.jar:/opt/dolphinscheduler/libs/grpc-alts-1.41.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-presto-3.2.1.jar:/opt/dolphinscheduler/libs/kerb-simplekdc-1.0.1.jar:/opt/dolphinscheduler/libs/protobuf-java-util-3.17.2.jar:/opt/dolphinscheduler/libs/azure-core-http-netty-1.13.0.jar:/opt/dolphinscheduler/libs/transaction-api-1.1.jar:/opt/dolphinscheduler/libs/datanucleus-api-jdo-4.2.4.jar:/opt/dolphinscheduler/libs/zeppelin-common-0.10.1.jar:/opt/dolphinscheduler/libs/zt-zip-1.15.jar:/opt/dolphinscheduler/libs/animal-sniffer-annotations-1.19.jar:/opt/dolphinscheduler/libs/google-http-client-jackson2-1.42.3.jar:/opt/dolphinscheduler/libs/netty-buffer-4.1.53.Final.jar:/opt/dolphinscheduler/libs/jsr305-3.0.0.jar:/opt/dolphinscheduler/libs/netty-transport-classes-epoll-4.1.79.Final.jar:/opt/dolphinscheduler/libs/spring-boot-actuator-autoconfigure-2.7.3.jar:/opt/dolphinscheduler/libs/simpleclient-0.15.0.jar:/opt/dolphinscheduler/libs/aliyun-sdk-oss-3.15.1.jar:/opt/dolphinscheduler/libs/json-utils-2.17.282.jar:/opt/dolphinscheduler/libs/tephra-api-0.6.0.jar:/opt/dolphinscheduler/libs/spring-jdbc-5.3.22.jar:/opt/dolphinscheduler/libs/grpc-xds-1.41.0.jar:/opt/dolphinscheduler/libs/logback-classic-1.2.11.jar:/opt/dolphinscheduler/libs/google-cloud-storage-2.18.0.jar:/opt/dolphinscheduler/libs/micrometer-registry-prometheus-1.9.3.jar:/opt/dolphinscheduler/libs/grpc-core-1.41.0.jar:/opt/dolphinscheduler/libs/aws-java-sdk-kms-1.12.300.jar:/opt/dolphinscheduler/libs/kubernetes-model-rbac-5.10.2.jar:/opt/dolphinscheduler/libs/ini4j-0.5.4.jar:/opt/dolphinscheduler/libs/spring-boot-starter-web-2.7.3.jar:/opt/dolphinscheduler/libs/spring-cloud-commons-3.1.3.jar:/opt/dolphinscheduler/libs/netty-codec-http-4.1.53.Final.jar:/opt/dolphinscheduler/libs/jetty-client-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/jetcd-common-0.5.11.jar:/opt/dolphinscheduler/libs/metrics-spi-2.17.282.jar:/opt/dolphinscheduler/libs/utils-2.17.282.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-emr-3.2.1.jar:/opt/dolphinscheduler/libs/protocol-core-2.17.282.jar:/opt/dolphinscheduler/libs/micrometer-core-1.9.3.jar:/opt/dolphinscheduler/libs/netty-transport-native-unix-common-4.1.53.Final.jar:/opt/dolphinscheduler/libs/zjsonpatch-0.4.11.jar:/opt/dolphinscheduler/libs/annotations-2.17.282.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-sql-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-extract-common-3.2.1.jar:/opt/dolphinscheduler/libs/apache-client-2.17.282.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-oceanbase-3.2.1.jar:/opt/dolphinscheduler/libs/jdo-api-3.0.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-datax-3.2.1.jar:/opt/dolphinscheduler/libs/postgresql-42.4.1.jar:/opt/dolphinscheduler/libs/jetty-util-ajax-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/gax-2.23.0.jar:/opt/dolphinscheduler/libs/grpc-stub-1.41.0.jar:/opt/dolphinscheduler/libs/libfb303-0.9.3.jar:/opt/dolphinscheduler/libs/spring-core-5.3.22.jar:/opt/dolphinscheduler/libs/jaxb-api-2.3.1.jar:/opt/dolphinscheduler/libs/hive-service-rpc-2.3.9.jar:/opt/dolphinscheduler/libs/kubernetes-model-flowcontrol-5.10.2.jar:/opt/dolphinscheduler/libs/commons-logging-1.1.1.jar:/opt/dolphinscheduler/libs/mybatis-spring-2.0.7.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-oracle-3.2.1.jar:/opt/dolphinscheduler/libs/opencensus-proto-0.2.0.jar:/opt/dolphinscheduler/libs/grpc-protobuf-1.41.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-clickhouse-3.2.1.jar:/opt/dolphinscheduler/libs/spring-cloud-starter-bootstrap-3.1.3.jar:/opt/dolphinscheduler/libs/kubernetes-model-admissionregistration-5.10.2.jar:/opt/dolphinscheduler/libs/grpc-google-cloud-storage-v2-2.18.0-alpha.jar:/opt/dolphinscheduler/libs/esdk-obs-java-bundle-3.23.3.jar:/opt/dolphinscheduler/libs/dnsjava-2.1.7.jar:/opt/dolphinscheduler/libs/asm-9.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-spark-3.2.1.jar:/opt/dolphinscheduler/libs/netty-tcnative-boringssl-static-2.0.53.Final-linux-aarch_64.jar:/opt/dolphinscheduler/libs/re2j-1.6.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-vertica-3.2.1.jar:/opt/dolphinscheduler/libs/json-smart-2.4.8.jar:/opt/dolphinscheduler/libs/reactor-netty-http-1.0.22.jar:/opt/dolphinscheduler/libs/google-api-services-storage-v1-rev20220705-2.0.0.jar:/opt/dolphinscheduler/libs/kubernetes-client-6.0.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-kyuubi-3.2.1.jar:/opt/dolphinscheduler/libs/auto-value-annotations-1.10.1.jar:/opt/dolphinscheduler/libs/commons-cli-1.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-data-quality-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-chunjun-3.2.1.jar:/opt/dolphinscheduler/libs/kerb-server-1.0.1.jar:/opt/dolphinscheduler/libs/content-type-2.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-remoteshell-3.2.1.jar:/opt/dolphinscheduler/libs/opencensus-contrib-http-util-0.31.1.jar:/opt/dolphinscheduler/libs/druid-1.2.20.jar:/opt/dolphinscheduler/libs/javolution-5.5.1.jar:/opt/dolphinscheduler/libs/protobuf-java-3.17.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-db2-3.2.1.jar:/opt/dolphinscheduler/libs/aws-java-sdk-core-1.12.300.jar:/opt/dolphinscheduler/libs/spring-boot-starter-logging-2.7.3.jar:/opt/dolphinscheduler/libs/kerby-pkix-1.0.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-procedure-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-registry-etcd-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-sqoop-3.2.1.jar:/opt/dolphinscheduler/libs/zookeeper-jute-3.8.0.jar:/opt/dolphinscheduler/libs/netty-resolver-dns-native-macos-4.1.53.Final-osx-x86_64.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-sagemaker-3.2.1.jar:/opt/dolphinscheduler/libs/spring-boot-configuration-processor-2.6.1.jar:/opt/dolphinscheduler/libs/hive-common-2.3.9.jar:/opt/dolphinscheduler/libs/kerb-common-1.0.1.jar:/opt/dolphinscheduler/libs/stax-api-1.0.1.jar:/opt/dolphinscheduler/libs/kubernetes-model-storageclass-5.10.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-s3-3.2.1.jar:/opt/dolphinscheduler/libs/spring-boot-starter-jetty-2.7.3.jar:/opt/dolphinscheduler/libs/okio-2.8.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-dms-3.2.1.jar:/opt/dolphinscheduler/libs/simpleclient_common-0.15.0.jar:/opt/dolphinscheduler/libs/sdk-core-2.17.282.jar:/opt/dolphinscheduler/libs/javax.activation-api-1.2.0.jar:/opt/dolphinscheduler/libs/netty-handler-proxy-4.1.53.Final.jar:/opt/dolphinscheduler/libs/kerby-config-1.0.1.jar:/opt/dolphinscheduler/libs/netty-tcnative-classes-2.0.53.Final.jar:/opt/dolphinscheduler/libs/jackson-jaxrs-base-2.13.3.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-trino-3.2.1.jar:/opt/dolphinscheduler/libs/presto-jdbc-0.238.1.jar:/opt/dolphinscheduler/libs/websocket-api-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-flink-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-api-3.2.1.jar:/opt/dolphinscheduler/libs/kubernetes-model-metrics-5.10.2.jar:/opt/dolphinscheduler/libs/datasync-2.17.282.jar:/opt/dolphinscheduler/libs/hadoop-yarn-api-3.2.4.jar:/opt/dolphinscheduler/libs/google-http-client-apache-v2-1.42.3.jar:/opt/dolphinscheduler/libs/hadoop-annotations-3.2.4.jar:/opt/dolphinscheduler/libs/google-oauth-client-1.34.1.jar:/opt/dolphinscheduler/libs/sshd-common-2.8.0.jar:/opt/dolphinscheduler/libs/LatencyUtils-2.0.3.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-spark-3.2.1.jar:/opt/dolphinscheduler/libs/slf4j-api-1.7.36.jar:/opt/dolphinscheduler/libs/snowflake-jdbc-3.13.29.jar:/opt/dolphinscheduler/libs/jackson-datatype-jsr310-2.13.3.jar:/opt/dolphinscheduler/libs/trino-jdbc-402.jar:/opt/dolphinscheduler/libs/logging-interceptor-4.9.3.jar:/opt/dolphinscheduler/libs/simpleclient_tracer_otel_agent-0.15.0.jar:/opt/dolphinscheduler/libs/janino-3.0.16.jar:/opt/dolphinscheduler/libs/jackson-dataformat-yaml-2.13.3.jar:/opt/dolphinscheduler/libs/ion-java-1.0.2.jar:/opt/dolphinscheduler/libs/commons-dbcp-1.4.jar:/opt/dolphinscheduler/libs/jsp-api-2.1.jar:/opt/dolphinscheduler/libs/google-http-client-gson-1.42.3.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-hivecli-3.2.1.jar:/opt/dolphinscheduler/libs/spring-boot-actuator-2.7.3.jar:/opt/dolphinscheduler/libs/google-cloud-core-http-2.10.0.jar:/opt/dolphinscheduler/libs/DmJdbcDriver18-8.1.2.79.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-java-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-dameng-3.2.1.jar:/opt/dolphinscheduler/libs/sshd-sftp-2.8.0.jar:/opt/dolphinscheduler/libs/kerb-crypto-1.0.1.jar:/opt/dolphinscheduler/libs/conscrypt-openjdk-uber-2.5.2.jar:/opt/dolphinscheduler/libs/httpcore-4.4.15.jar:/opt/dolphinscheduler/libs/lz4-java-1.4.0.jar:/opt/dolphinscheduler/libs/guava-retrying-2.0.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-flink-stream-3.2.1.jar:/opt/dolphinscheduler/libs/spring-tx-5.3.22.jar:/opt/dolphinscheduler/libs/grpc-auth-1.41.0.jar:/opt/dolphinscheduler/libs/netty-tcnative-boringssl-static-2.0.53.Final-osx-x86_64.jar:/opt/dolphinscheduler/libs/databend-jdbc-0.0.7.jar:/opt/dolphinscheduler/libs/bcprov-jdk15on-1.69.jar:/opt/dolphinscheduler/libs/commons-lang-2.6.jar:/opt/dolphinscheduler/libs/kubernetes-model-policy-5.10.2.jar:/opt/dolphinscheduler/libs/commons-io-2.11.0.jar:/opt/dolphinscheduler/libs/grpc-grpclb-1.41.0.jar:/opt/dolphinscheduler/libs/netty-tcnative-boringssl-static-2.0.53.Final-linux-x86_64.jar:/opt/dolphinscheduler/libs/opentracing-api-0.33.0.jar:/opt/dolphinscheduler/libs/sshd-scp-2.8.0.jar:/opt/dolphinscheduler/libs/reload4j-1.2.18.3.jar:/opt/dolphinscheduler/libs/netty-tcnative-2.0.48.Final.jar:/opt/dolphinscheduler/libs/jdom2-2.0.6.1.jar:/opt/dolphinscheduler/libs/spring-boot-starter-json-2.7.3.jar:/opt/dolphinscheduler/libs/netty-transport-native-epoll-4.1.53.Final.jar:/opt/dolphinscheduler/libs/google-cloud-core-2.10.0.jar:/opt/dolphinscheduler/libs/javax.jdo-3.2.0-m3.jar:/opt/dolphinscheduler/libs/gax-httpjson-0.108.0.jar:/opt/dolphinscheduler/libs/mybatis-plus-core-3.5.2.jar:/opt/dolphinscheduler/libs/auto-service-annotations-1.0.1.jar:/opt/dolphinscheduler/libs/nimbus-jose-jwt-9.22.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-zeppelin-3.2.1.jar:/opt/dolphinscheduler/libs/commons-compress-1.21.jar:/opt/dolphinscheduler/libs/hadoop-hdfs-client-3.2.4.jar:/opt/dolphinscheduler/libs/msal4j-persistence-extension-1.1.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-pytorch-3.2.1.jar:/opt/dolphinscheduler/libs/netty-tcnative-boringssl-static-2.0.53.Final-windows-x86_64.jar:/opt/dolphinscheduler/libs/jetty-servlets-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/woodstox-core-6.4.0.jar:/opt/dolphinscheduler/libs/spring-cloud-kubernetes-commons-2.1.3.jar:/opt/dolphinscheduler/libs/grpc-protobuf-lite-1.41.0.jar:/opt/dolphinscheduler/libs/jetty-webapp-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/eventstream-1.0.1.jar:/opt/dolphinscheduler/libs/commons-compiler-3.1.7.jar:/opt/dolphinscheduler/libs/netty-transport-4.1.53.Final.jar:/opt/dolphinscheduler/libs/spring-cloud-context-3.1.3.jar:/opt/dolphinscheduler/libs/aws-java-sdk-dms-1.12.300.jar:/opt/dolphinscheduler/libs/hive-storage-api-2.4.0.jar:/opt/dolphinscheduler/libs/client-java-spring-integration-13.0.2.jar:/opt/dolphinscheduler/libs/spring-boot-starter-actuator-2.7.3.jar:/opt/dolphinscheduler/libs/third-party-jackson-core-2.17.282.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-hdfs-3.2.1.jar:/opt/dolphinscheduler/libs/netty-codec-4.1.53.Final.jar:/opt/dolphinscheduler/libs/google-http-client-appengine-1.42.3.jar:/opt/dolphinscheduler/libs/commons-configuration2-2.1.1.jar:/opt/dolphinscheduler/libs/datanucleus-rdbms-4.1.19.jar:/opt/dolphinscheduler/libs/swagger-annotations-1.6.2.jar:/opt/dolphinscheduler/libs/simpleclient_tracer_otel-0.15.0.jar:/opt/dolphinscheduler/libs/kotlin-stdlib-common-1.6.21.jar:/opt/dolphinscheduler/libs/aws-core-2.17.282.jar:/opt/dolphinscheduler/libs/kerb-core-1.0.1.jar:/opt/dolphinscheduler/libs/httpasyncclient-4.1.5.jar:/opt/dolphinscheduler/libs/dolphinscheduler-extract-worker-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-spi-3.2.1.jar:/opt/dolphinscheduler/libs/okhttp-2.7.5.jar:/opt/dolphinscheduler/libs/google-api-client-2.2.0.jar:/opt/dolphinscheduler/libs/kotlin-stdlib-1.6.21.jar:/opt/dolphinscheduler/libs/jakarta.websocket-api-1.1.2.jar:/opt/dolphinscheduler/libs/libthrift-0.9.3.jar:/opt/dolphinscheduler/libs/spring-boot-starter-aop-2.7.3.jar:/opt/dolphinscheduler/libs/netty-common-4.1.53.Final.jar:/opt/dolphinscheduler/libs/log4j-1.2-api-2.17.2.jar:/opt/dolphinscheduler/libs/jackson-databind-2.13.4.jar:/opt/dolphinscheduler/libs/jackson-dataformat-xml-2.13.3.jar:/opt/dolphinscheduler/libs/kubernetes-model-events-5.10.2.jar:/opt/dolphinscheduler/libs/gson-2.9.1.jar:/opt/dolphinscheduler/libs/proto-google-iam-v1-1.9.0.jar:/opt/dolphinscheduler/libs/netty-codec-socks-4.1.53.Final.jar:/opt/dolphinscheduler/libs/zjsonpatch-0.3.0.jar:/opt/dolphinscheduler/libs/hadoop-mapreduce-client-common-3.2.4.jar:/opt/dolphinscheduler/libs/dolphinscheduler-registry-api-3.2.1.jar:/opt/dolphinscheduler/libs/azure-storage-blob-12.21.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-zeppelin-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-api-3.2.1.jar:/opt/dolphinscheduler/libs/aws-java-sdk-s3-1.12.300.jar:/opt/dolphinscheduler/libs/stax2-api-4.2.1.jar:/opt/dolphinscheduler/libs/jakarta.annotation-api-1.3.5.jar:/opt/dolphinscheduler/libs/kubernetes-model-discovery-5.10.2.jar:/opt/dolphinscheduler/libs/jna-5.10.0.jar:/opt/dolphinscheduler/libs/spring-jcl-5.3.22.jar
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:06.694 +0800 o.a.z.ZooKeeper:[98] - Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:06.694 +0800 o.a.z.ZooKeeper:[98] - Client environment:java.io.tmpdir=/tmp
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:06.695 +0800 o.a.z.ZooKeeper:[98] - Client environment:java.compiler=<NA>
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:06.695 +0800 o.a.z.ZooKeeper:[98] - Client environment:os.name=Linux
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:06.695 +0800 o.a.z.ZooKeeper:[98] - Client environment:os.arch=amd64
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:06.695 +0800 o.a.z.ZooKeeper:[98] - Client environment:os.version=6.5.0-28-generic
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:06.696 +0800 o.a.z.ZooKeeper:[98] - Client environment:user.name=root
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:06.700 +0800 o.a.z.ZooKeeper:[98] - Client environment:user.home=/root
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:06.702 +0800 o.a.z.ZooKeeper:[98] - Client environment:user.dir=/opt/dolphinscheduler
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:06.704 +0800 o.a.z.ZooKeeper:[98] - Client environment:os.memory.free=3242MB
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:06.709 +0800 o.a.z.ZooKeeper:[98] - Client environment:os.memory.max=3840MB
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:06.713 +0800 o.a.z.ZooKeeper:[98] - Client environment:os.memory.total=3840MB
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:06.717 +0800 o.a.z.ZooKeeper:[637] - Initiating client connection, connectString=dolphinscheduler-zookeeper:2181 sessionTimeout=30000 watcher=org.apache.curator.ConnectionState@6996bbc4
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:06.723 +0800 o.a.z.c.X509Util:[77] - Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:06.747 +0800 o.a.z.ClientCnxnSocket:[239] - jute.maxbuffer value is 1048575 Bytes
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:06.768 +0800 o.a.z.ClientCnxn:[1732] - zookeeper.request.timeout value is 0. feature enabled=false
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:06.823 +0800 o.a.c.f.i.CuratorFrameworkImpl:[386] - Default schema
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:06.852 +0800 o.a.z.ClientCnxn:[1171] - Opening socket connection to server dolphinscheduler-zookeeper/172.18.0.5:2181.
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:06.895 +0800 o.a.z.ClientCnxn:[1173] - SASL config status: Will not attempt to authenticate using SASL (unknown error)
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:06.907 +0800 o.a.z.ClientCnxn:[1005] - Socket connection established, initiating session, client: /172.18.1.1:60196, server: dolphinscheduler-zookeeper/172.18.0.5:2181
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:06.982 +0800 o.a.z.ClientCnxn:[1444] - Session establishment complete on server dolphinscheduler-zookeeper/172.18.0.5:2181, session id = 0x1000097517b0000, negotiated timeout = 30000
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:07.017 +0800 o.a.c.f.s.ConnectionStateManager:[252] - State change: CONNECTED
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:07.194 +0800 o.a.c.f.i.EnsembleTracker:[201] - New config event received: {}
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:07.195 +0800 o.a.c.f.i.EnsembleTracker:[201] - New config event received: {}
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:07.603 +0800 o.a.d.s.w.r.WorkerRpcServer:[41] - WorkerRpcServer starting...
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:07.943 +0800 o.a.d.e.b.NettyRemotingServer:[112] - WorkerRpcServer bind success at port: 1234
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:07.943 +0800 o.a.d.s.w.r.WorkerRpcServer:[43] - WorkerRpcServer started...
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:08.388 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: JAVA - JavaTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:08.424 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: JAVA - JavaTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:08.432 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: JUPYTER - JupyterTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:08.438 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: JUPYTER - JupyterTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:08.455 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: SPARK - SparkTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:08.460 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: SPARK - SparkTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:08.489 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: FLINK_STREAM - FlinkStreamTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:08.522 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: FLINK_STREAM - FlinkStreamTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:08.522 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: PYTHON - PythonTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:08.523 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: PYTHON - PythonTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:08.524 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: DATASYNC - DatasyncTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:08.532 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: DATASYNC - DatasyncTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:08.533 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: DATA_FACTORY - DatafactoryTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:08.543 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: DATA_FACTORY - DatafactoryTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:08.543 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: CHUNJUN - ChunJunTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:08.567 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: CHUNJUN - ChunJunTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:08.568 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: REMOTESHELL - RemoteShellTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:08.577 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: REMOTESHELL - RemoteShellTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:08.577 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: PIGEON - PigeonTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:08.585 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: PIGEON - PigeonTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:08.586 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: SHELL - ShellTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:08.588 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: SHELL - ShellTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:08.588 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: PROCEDURE - ProcedureTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:08.590 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: PROCEDURE - ProcedureTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:08.598 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: MR - MapReduceTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:08.602 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: MR - MapReduceTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:08.603 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: SQOOP - SqoopTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:08.610 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: SQOOP - SqoopTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:08.610 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: PYTORCH - PytorchTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:08.613 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: PYTORCH - PytorchTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:08.614 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: K8S - K8sTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:08.630 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: K8S - K8sTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:08.630 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: SEATUNNEL - SeatunnelTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:08.638 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: SEATUNNEL - SeatunnelTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:08.639 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: SAGEMAKER - SagemakerTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:08.641 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: SAGEMAKER - SagemakerTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:08.641 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: HTTP - HttpTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:08.649 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: HTTP - HttpTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:08.650 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: EMR - EmrTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:08.675 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: EMR - EmrTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:08.675 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: DMS - DmsTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:08.711 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: DMS - DmsTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:08.711 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: DATA_QUALITY - DataQualityTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:08.715 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: DATA_QUALITY - DataQualityTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:08.715 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: KUBEFLOW - KubeflowTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:08.717 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: KUBEFLOW - KubeflowTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:08.718 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: SQL - SqlTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:08.722 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: SQL - SqlTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:08.722 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: DVC - DvcTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:08.731 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: DVC - DvcTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:08.731 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: DATAX - DataxTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:08.735 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: DATAX - DataxTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:08.735 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: ZEPPELIN - ZeppelinTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:08.747 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: ZEPPELIN - ZeppelinTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:08.748 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: DINKY - DinkyTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:08.749 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: DINKY - DinkyTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:08.772 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: MLFLOW - MlflowTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:08.783 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: MLFLOW - MlflowTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:08.786 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: OPENMLDB - OpenmldbTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:08.817 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: OPENMLDB - OpenmldbTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:08.817 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: LINKIS - LinkisTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:08.825 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: LINKIS - LinkisTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:08.826 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: FLINK - FlinkTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:08.830 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: FLINK - FlinkTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:08.833 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: HIVECLI - HiveCliTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:08.840 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: HIVECLI - HiveCliTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:08.912 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.0 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [WARN] 2024-05-07 10:30:08.984 +0800 o.a.d.s.w.r.WorkerRegistryClient:[96] - Worker node is BUSY: WorkerHeartBeat(startupTime=1715049008983, reportTime=1715049008983, cpuUsage=1.0, jvmMemoryUsage=0.0271457036336263, memoryUsage=0.512699299881713, diskUsage=0.0, serverStatus=BUSY, processId=7, host=172.18.1.1, port=1234, workerHostWeight=100, threadPoolUsage=0)
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:08.996 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.0 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [WARN] 2024-05-07 10:30:10.028 +0800 o.a.d.s.w.r.WorkerRegistryClient:[96] - Worker node is BUSY: WorkerHeartBeat(startupTime=1715049008983, reportTime=1715049009007, cpuUsage=1.0, jvmMemoryUsage=0.0271457036336263, memoryUsage=0.512699299881713, diskUsage=0.0, serverStatus=BUSY, processId=7, host=172.18.1.1, port=1234, workerHostWeight=100, threadPoolUsage=0)
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:10.033 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.072538860103627 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [WARN] 2024-05-07 10:30:11.054 +0800 o.a.d.s.w.r.WorkerRegistryClient:[96] - Worker node is BUSY: WorkerHeartBeat(startupTime=1715049008983, reportTime=1715049010034, cpuUsage=1.072538860103627, jvmMemoryUsage=0.027252960205078124, memoryUsage=0.5135292376085465, diskUsage=0.0, serverStatus=BUSY, processId=7, host=172.18.1.1, port=1234, workerHostWeight=100, threadPoolUsage=0)
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:11.063 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9880952380952381 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [WARN] 2024-05-07 10:30:12.072 +0800 o.a.d.s.w.r.WorkerRegistryClient:[96] - Worker node is BUSY: WorkerHeartBeat(startupTime=1715049008983, reportTime=1715049011063, cpuUsage=0.9880952380952381, jvmMemoryUsage=0.027252960205078124, memoryUsage=0.5133236421103324, diskUsage=0.0, serverStatus=BUSY, processId=7, host=172.18.1.1, port=1234, workerHostWeight=100, threadPoolUsage=0)
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:12.074 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.0 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [WARN] 2024-05-07 10:30:13.105 +0800 o.a.d.s.w.r.WorkerRegistryClient:[96] - Worker node is BUSY: WorkerHeartBeat(startupTime=1715049008983, reportTime=1715049012104, cpuUsage=1.0, jvmMemoryUsage=0.027252960205078124, memoryUsage=0.5147580385553198, diskUsage=0.0, serverStatus=BUSY, processId=7, host=172.18.1.1, port=1234, workerHostWeight=100, threadPoolUsage=0)
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:13.108 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.0071428571428571 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [WARN] 2024-05-07 10:30:14.135 +0800 o.a.d.s.w.r.WorkerRegistryClient:[96] - Worker node is BUSY: WorkerHeartBeat(startupTime=1715049008983, reportTime=1715049013109, cpuUsage=1.0071428571428571, jvmMemoryUsage=0.027252960205078124, memoryUsage=0.514846917847101, diskUsage=0.0, serverStatus=BUSY, processId=7, host=172.18.1.1, port=1234, workerHostWeight=100, threadPoolUsage=0)
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:14.145 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.007748031496063 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [WARN] 2024-05-07 10:30:15.242 +0800 o.a.d.s.w.r.WorkerRegistryClient:[96] - Worker node is BUSY: WorkerHeartBeat(startupTime=1715049008983, reportTime=1715049014152, cpuUsage=1.007748031496063, jvmMemoryUsage=0.027252960205078124, memoryUsage=0.5168804044624165, diskUsage=0.0, serverStatus=BUSY, processId=7, host=172.18.1.1, port=1234, workerHostWeight=100, threadPoolUsage=0)
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:15.250 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9952153110047847 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [WARN] 2024-05-07 10:30:16.273 +0800 o.a.d.s.w.r.WorkerRegistryClient:[96] - Worker node is BUSY: WorkerHeartBeat(startupTime=1715049008983, reportTime=1715049015250, cpuUsage=0.9952153110047847, jvmMemoryUsage=0.027252960205078124, memoryUsage=0.5198140175965091, diskUsage=0.0, serverStatus=BUSY, processId=7, host=172.18.1.1, port=1234, workerHostWeight=100, threadPoolUsage=0)
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:16.287 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.0044444444444445 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [WARN] 2024-05-07 10:30:17.289 +0800 o.a.d.s.w.r.WorkerRegistryClient:[96] - Worker node is BUSY: WorkerHeartBeat(startupTime=1715049008983, reportTime=1715049016288, cpuUsage=1.0044444444444445, jvmMemoryUsage=0.027252960205078124, memoryUsage=0.5202963915604042, diskUsage=0.0, serverStatus=BUSY, processId=7, host=172.18.1.1, port=1234, workerHostWeight=100, threadPoolUsage=0)
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:17.290 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9962686567164178 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [WARN] 2024-05-07 10:30:18.294 +0800 o.a.d.s.w.r.WorkerRegistryClient:[96] - Worker node is BUSY: WorkerHeartBeat(startupTime=1715049008983, reportTime=1715049017290, cpuUsage=0.9962686567164178, jvmMemoryUsage=0.027252960205078124, memoryUsage=0.5199182071913487, diskUsage=0.0, serverStatus=BUSY, processId=7, host=172.18.1.1, port=1234, workerHostWeight=100, threadPoolUsage=0)
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:18.297 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9700598802395209 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [WARN] 2024-05-07 10:30:19.353 +0800 o.a.d.s.w.r.WorkerRegistryClient:[96] - Worker node is BUSY: WorkerHeartBeat(startupTime=1715049008983, reportTime=1715049018298, cpuUsage=0.9700598802395209, jvmMemoryUsage=0.027252960205078124, memoryUsage=0.522981460813677, diskUsage=0.0, serverStatus=BUSY, processId=7, host=172.18.1.1, port=1234, workerHostWeight=100, threadPoolUsage=0)
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:19.355 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9928057553956835 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [WARN] 2024-05-07 10:30:20.357 +0800 o.a.d.s.w.r.WorkerRegistryClient:[96] - Worker node is BUSY: WorkerHeartBeat(startupTime=1715049008983, reportTime=1715049019355, cpuUsage=0.9928057553956835, jvmMemoryUsage=0.027252960205078124, memoryUsage=0.5252531518843703, diskUsage=0.0, serverStatus=BUSY, processId=7, host=172.18.1.1, port=1234, workerHostWeight=100, threadPoolUsage=0)
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:20.369 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.985 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [WARN] 2024-05-07 10:30:21.378 +0800 o.a.d.s.w.r.WorkerRegistryClient:[96] - Worker node is BUSY: WorkerHeartBeat(startupTime=1715049008983, reportTime=1715049020370, cpuUsage=0.985, jvmMemoryUsage=0.027252960205078124, memoryUsage=0.528079791732158, diskUsage=0.0, serverStatus=BUSY, processId=7, host=172.18.1.1, port=1234, workerHostWeight=100, threadPoolUsage=0)
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:21.381 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.005 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [WARN] 2024-05-07 10:30:22.383 +0800 o.a.d.s.w.r.WorkerRegistryClient:[96] - Worker node is BUSY: WorkerHeartBeat(startupTime=1715049008983, reportTime=1715049021382, cpuUsage=1.005, jvmMemoryUsage=0.027252960205078124, memoryUsage=0.5295157788579826, diskUsage=0.0, serverStatus=BUSY, processId=7, host=172.18.1.1, port=1234, workerHostWeight=100, threadPoolUsage=0)
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:22.385 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9861751152073732 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [WARN] 2024-05-07 10:30:23.457 +0800 o.a.d.s.w.r.WorkerRegistryClient:[96] - Worker node is BUSY: WorkerHeartBeat(startupTime=1715049008983, reportTime=1715049022385, cpuUsage=0.9861751152073732, jvmMemoryUsage=0.027252960205078124, memoryUsage=0.5326931638303833, diskUsage=0.0, serverStatus=BUSY, processId=7, host=172.18.1.1, port=1234, workerHostWeight=100, threadPoolUsage=0)
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:23.464 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.990990990990991 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [WARN] 2024-05-07 10:30:24.491 +0800 o.a.d.s.w.r.WorkerRegistryClient:[96] - Worker node is BUSY: WorkerHeartBeat(startupTime=1715049008983, reportTime=1715049023472, cpuUsage=0.990990990990991, jvmMemoryUsage=0.027252960205078124, memoryUsage=0.5312468372791166, diskUsage=0.0, serverStatus=BUSY, processId=7, host=172.18.1.1, port=1234, workerHostWeight=100, threadPoolUsage=0)
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:24.545 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9998513563730955 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [WARN] 2024-05-07 10:30:25.627 +0800 o.a.d.s.w.r.WorkerRegistryClient:[96] - Worker node is BUSY: WorkerHeartBeat(startupTime=1715049008983, reportTime=1715049024545, cpuUsage=0.9998513563730955, jvmMemoryUsage=0.027257474263509114, memoryUsage=0.5332473172670592, diskUsage=0.0, serverStatus=BUSY, processId=7, host=172.18.1.1, port=1234, workerHostWeight=100, threadPoolUsage=0)
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:25.629 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9844961240310077 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [WARN] 2024-05-07 10:30:26.630 +0800 o.a.d.s.w.r.WorkerRegistryClient:[96] - Worker node is BUSY: WorkerHeartBeat(startupTime=1715049008983, reportTime=1715049025629, cpuUsage=0.9844961240310077, jvmMemoryUsage=0.027257474263509114, memoryUsage=0.5376232802503255, diskUsage=0.0, serverStatus=BUSY, processId=7, host=172.18.1.1, port=1234, workerHostWeight=100, threadPoolUsage=0)
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:26.631 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.0 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [WARN] 2024-05-07 10:30:27.634 +0800 o.a.d.s.w.r.WorkerRegistryClient:[96] - Worker node is BUSY: WorkerHeartBeat(startupTime=1715049008983, reportTime=1715049026631, cpuUsage=1.0, jvmMemoryUsage=0.027257474263509114, memoryUsage=0.5378437883813888, diskUsage=0.0, serverStatus=BUSY, processId=7, host=172.18.1.1, port=1234, workerHostWeight=100, threadPoolUsage=0)
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:27.635 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9955947136563876 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [WARN] 2024-05-07 10:30:28.644 +0800 o.a.d.s.w.r.WorkerRegistryClient:[96] - Worker node is BUSY: WorkerHeartBeat(startupTime=1715049008983, reportTime=1715049027636, cpuUsage=0.9955947136563876, jvmMemoryUsage=0.027257474263509114, memoryUsage=0.538853075372622, diskUsage=0.0, serverStatus=BUSY, processId=7, host=172.18.1.1, port=1234, workerHostWeight=100, threadPoolUsage=0)
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:28.647 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.010989010989011 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [WARN] 2024-05-07 10:30:29.649 +0800 o.a.d.s.w.r.WorkerRegistryClient:[96] - Worker node is BUSY: WorkerHeartBeat(startupTime=1715049008983, reportTime=1715049028647, cpuUsage=1.010989010989011, jvmMemoryUsage=0.027257474263509114, memoryUsage=0.5402862788069814, diskUsage=0.0, serverStatus=BUSY, processId=7, host=172.18.1.1, port=1234, workerHostWeight=100, threadPoolUsage=0)
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:29.650 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.98 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [WARN] 2024-05-07 10:30:30.665 +0800 o.a.d.s.w.r.WorkerRegistryClient:[96] - Worker node is BUSY: WorkerHeartBeat(startupTime=1715049008983, reportTime=1715049029650, cpuUsage=0.98, jvmMemoryUsage=0.027257474263509114, memoryUsage=0.5371937964242688, diskUsage=0.0, serverStatus=BUSY, processId=7, host=172.18.1.1, port=1234, workerHostWeight=100, threadPoolUsage=0)
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:30.667 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8396226415094339 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [WARN] 2024-05-07 10:30:31.671 +0800 o.a.d.s.w.r.WorkerRegistryClient:[96] - Worker node is BUSY: WorkerHeartBeat(startupTime=1715049008983, reportTime=1715049030670, cpuUsage=0.8396226415094339, jvmMemoryUsage=0.027257474263509114, memoryUsage=0.5478843646611959, diskUsage=0.0, serverStatus=BUSY, processId=7, host=172.18.1.1, port=1234, workerHostWeight=100, threadPoolUsage=0)
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:31.674 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.0114285714285713 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [WARN] 2024-05-07 10:30:32.685 +0800 o.a.d.s.w.r.WorkerRegistryClient:[96] - Worker node is BUSY: WorkerHeartBeat(startupTime=1715049008983, reportTime=1715049031674, cpuUsage=1.0114285714285713, jvmMemoryUsage=0.027257474263509114, memoryUsage=0.5506505586371683, diskUsage=0.0, serverStatus=BUSY, processId=7, host=172.18.1.1, port=1234, workerHostWeight=100, threadPoolUsage=0)
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:32.686 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9924528301886792 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [WARN] 2024-05-07 10:30:33.796 +0800 o.a.d.s.w.r.WorkerRegistryClient:[96] - Worker node is BUSY: WorkerHeartBeat(startupTime=1715049008983, reportTime=1715049032687, cpuUsage=0.9924528301886792, jvmMemoryUsage=0.027257474263509114, memoryUsage=0.5562074033069857, diskUsage=0.0, serverStatus=BUSY, processId=7, host=172.18.1.1, port=1234, workerHostWeight=100, threadPoolUsage=0)
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:33.797 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8551401869158879 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [WARN] 2024-05-07 10:30:34.799 +0800 o.a.d.s.w.r.WorkerRegistryClient:[96] - Worker node is BUSY: WorkerHeartBeat(startupTime=1715049008983, reportTime=1715049033798, cpuUsage=0.8551401869158879, jvmMemoryUsage=0.027257474263509114, memoryUsage=0.5575835410663089, diskUsage=0.0, serverStatus=BUSY, processId=7, host=172.18.1.1, port=1234, workerHostWeight=100, threadPoolUsage=0)
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:35.990 +0800 o.a.d.c.u.JSONUtils:[72] - init timezone: sun.util.calendar.ZoneInfo[id="Asia/Shanghai",offset=28800000,dstSavings=0,useDaylight=false,transitions=31,lastRule=null]
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:36.099 +0800 o.a.d.s.w.r.WorkerRegistryClient:[104] - Worker node: 172.18.1.1:1234 registry to ZK /nodes/worker/172.18.1.1:1234 successfully
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:37.187 +0800 o.a.d.c.m.BaseHeartBeatTask:[48] - Starting WorkerHeartBeatTask...
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:37.192 +0800 o.a.d.c.m.BaseHeartBeatTask:[50] - Started WorkerHeartBeatTask, heartBeatInterval: 10000...
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:37.193 +0800 o.a.d.s.w.r.WorkerRegistryClient:[114] - Worker node: 172.18.1.1:1234 registry finished
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:37.195 +0800 o.a.d.s.w.m.MessageRetryRunner:[69] - Message retry runner staring
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:37.225 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8252212389380531 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:37.413 +0800 o.a.d.s.w.m.MessageRetryRunner:[72] - Injected message sender: TaskInstanceExecutionFinishEventSender
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:37.414 +0800 o.a.d.s.w.m.MessageRetryRunner:[72] - Injected message sender: TaskInstanceExecutionInfoUpdateEventSender
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:37.414 +0800 o.a.d.s.w.m.MessageRetryRunner:[72] - Injected message sender: TaskInstanceExecutionRunningEventSender
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:37.425 +0800 o.a.d.s.w.m.MessageRetryRunner:[75] - Message retry runner started
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:38.419 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.6646706586826348 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:39.421 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.3452380952380953 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:40.426 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.5776699029126213 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:41.475 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.7142857142857142 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:42.530 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.9782608695652173 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:43.691 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.459349593495935 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:44.701 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.8588235294117648 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:45.523 +0800 o.s.b.a.e.w.EndpointLinksResolver:[58] - Exposing 3 endpoint(s) beneath base path '/actuator'
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:45.750 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.530701754385965 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:45.825 +0800 o.e.j.s.h.C.application:[2368] - Initializing Spring DispatcherServlet 'dispatcherServlet'
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:45.825 +0800 o.s.w.s.DispatcherServlet:[525] - Initializing Servlet 'dispatcherServlet'
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:45.827 +0800 o.s.w.s.DispatcherServlet:[547] - Completed initialization in 1 ms
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:45.891 +0800 o.e.j.s.AbstractConnector:[333] - Started ServerConnector@acb5508{HTTP/1.1, (http/1.1)}{0.0.0.0:1235}
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:45.893 +0800 o.s.b.w.e.j.JettyWebServer:[172] - Jetty started on port(s) 1235 (http/1.1) with context path '/'
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:45.915 +0800 o.a.d.s.w.WorkerServer:[61] - Started WorkerServer in 70.858 seconds (JVM running for 75.637)
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:46.845 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9158878504672896 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:50.943 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9483870967741935 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-3954] - [INFO] 2024-05-07 10:30:51.057 +0800 o.a.d.s.w.r.o.UpdateWorkflowHostOperationFunction:[49] - Received UpdateWorkflowHostRequest: UpdateWorkflowHostRequest(taskInstanceId=3954, workflowHost=172.18.0.15:5678)
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:51.527 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=3955, taskName=[null check] filtered data persistence, firstSubmitTime=1715049051144, startTime=0, taskType=DATA_QUALITY, workflowInstanceHost=172.18.0.15:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13505298546272, processDefineVersion=21, appIds=null, processInstanceId=1059, scheduleTime=0, globalParams=null, executorId=1, cmdTypeIfComplement=2, tenantCode=default, processDefineId=0, projectId=0, projectCode=13001194483488, taskParams={"localParams":[],"resourceList":[],"ruleId":6,"ruleInputParameter":{"check_type":"0","comparison_type":1,"comparison_name":"0","failure_strategy":"0","operator":"0","src_connector_type":1,"src_datasource_id":6,"src_database":"persistence","src_field":"content","src_table":"filtered_data_persistence","threshold":"0"},"sparkParameters":{"deployMode":"local","driverCores":1,"driverMemory":"512M","executorCores":1,"executorMemory":"1G","numExecutors":1,"others":"--conf spark.driver.extraJavaOptions=\"-Divy.cache.dir=/tmp -Divy.home=/tmp\" \\\n--packages org.postgresql:postgresql:42.7.3","yarnQueue":""}}, environmentConfig=export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export PYSPARK_DRIVER_PYTHON=/bin/python3.11
export PYSPARK_PYTHON=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='[null check] filtered data persistence'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13001194483488'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='1059'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240507'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240506'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='3955'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='qualti_test'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13505264408800'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13505298546272'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240507103051'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=null, dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=org.apache.dolphinscheduler.plugin.task.api.DataQualityTaskExecutionContext@7a93be1, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-1059][TI-3955] - [INFO] 2024-05-07 10:30:51.639 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: [null check] filtered data persistence to wait queue success
[WI-1059][TI-3955] - [INFO] 2024-05-07 10:30:51.642 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-1059][TI-3955] - [INFO] 2024-05-07 10:30:51.671 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-1059][TI-3955] - [INFO] 2024-05-07 10:30:51.674 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-1059][TI-3955] - [INFO] 2024-05-07 10:30:51.675 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-1059][TI-3955] - [INFO] 2024-05-07 10:30:51.676 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1715049051676
[WI-1059][TI-3955] - [INFO] 2024-05-07 10:30:51.677 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 1059_3955
[WI-1059][TI-3955] - [INFO] 2024-05-07 10:30:51.717 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 3955,
  "taskName" : "[null check] filtered data persistence",
  "firstSubmitTime" : 1715049051144,
  "startTime" : 1715049051676,
  "taskType" : "DATA_QUALITY",
  "workflowInstanceHost" : "172.18.0.15:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240507/13505298546272/21/1059/3955.log",
  "processId" : 0,
  "processDefineCode" : 13505298546272,
  "processDefineVersion" : 21,
  "processInstanceId" : 1059,
  "scheduleTime" : 0,
  "executorId" : 1,
  "cmdTypeIfComplement" : 2,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13001194483488,
  "taskParams" : "{\"localParams\":[],\"resourceList\":[],\"ruleId\":6,\"ruleInputParameter\":{\"check_type\":\"0\",\"comparison_type\":1,\"comparison_name\":\"0\",\"failure_strategy\":\"0\",\"operator\":\"0\",\"src_connector_type\":1,\"src_datasource_id\":6,\"src_database\":\"persistence\",\"src_field\":\"content\",\"src_table\":\"filtered_data_persistence\",\"threshold\":\"0\"},\"sparkParameters\":{\"deployMode\":\"local\",\"driverCores\":1,\"driverMemory\":\"512M\",\"executorCores\":1,\"executorMemory\":\"1G\",\"numExecutors\":1,\"others\":\"--conf spark.driver.extraJavaOptions=\\\"-Divy.cache.dir=/tmp -Divy.home=/tmp\\\" \\\\\\n--packages org.postgresql:postgresql:42.7.3\",\"yarnQueue\":\"\"}}",
  "environmentConfig" : "export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3\nexport JAVA_HOME=/opt/java/openjdk\nexport PYSPARK_DRIVER_PYTHON=/bin/python3.11\nexport PYSPARK_PYTHON=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "[null check] filtered data persistence"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13001194483488"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1059"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240507"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240506"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "3955"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "qualti_test"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13505264408800"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13505298546272"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240507103051"
    }
  },
  "taskAppId" : "1059_3955",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "dryRun" : 0,
  "paramsMap" : { },
  "dataQualityTaskExecutionContext" : {
    "ruleId" : 6,
    "ruleName" : "$t(uniqueness_check)",
    "ruleType" : 0,
    "ruleInputEntryList" : "[{\"id\":1,\"field\":\"src_connector_type\",\"type\":\"select\",\"title\":\"$t(src_connector_type)\",\"data\":\"\",\"options\":\"[{\\\"label\\\":\\\"HIVE\\\",\\\"value\\\":\\\"HIVE\\\"},{\\\"label\\\":\\\"JDBC\\\",\\\"value\\\":\\\"JDBC\\\"}]\",\"placeholder\":\"please select source connector type\",\"optionSourceType\":2,\"dataType\":2,\"inputType\":0,\"isShow\":true,\"canEdit\":true,\"isEmit\":true,\"isValidate\":false,\"valuesMap\":null,\"index\":1,\"createTime\":null,\"updateTime\":null},{\"id\":2,\"field\":\"src_datasource_id\",\"type\":\"select\",\"title\":\"$t(src_datasource_id)\",\"data\":\"\",\"options\":null,\"placeholder\":\"please select source datasource id\",\"optionSourceType\":1,\"dataType\":2,\"inputType\":0,\"isShow\":true,\"canEdit\":true,\"isEmit\":true,\"isValidate\":false,\"valuesMap\":null,\"index\":2,\"createTime\":null,\"updateTime\":null},{\"id\":30,\"field\":\"src_database\",\"type\":\"select\",\"title\":\"$t(src_database)\",\"data\":null,\"options\":null,\"placeholder\":\"Please select source database\",\"optionSourceType\":0,\"dataType\":0,\"inputType\":0,\"isShow\":true,\"canEdit\":true,\"isEmit\":true,\"isValidate\":true,\"valuesMap\":null,\"index\":2,\"createTime\":null,\"updateTime\":null},{\"id\":3,\"field\":\"src_table\",\"type\":\"select\",\"title\":\"$t(src_table)\",\"data\":null,\"options\":null,\"placeholder\":\"Please enter source table name\",\"optionSourceType\":0,\"dataType\":0,\"inputType\":0,\"isShow\":true,\"canEdit\":true,\"isEmit\":true,\"isValidate\":true,\"valuesMap\":null,\"index\":3,\"createTime\":null,\"updateTime\":null},{\"id\":4,\"field\":\"src_filter\",\"type\":\"input\",\"title\":\"$t(src_filter)\",\"data\":null,\"options\":null,\"placeholder\":\"Please enter filter expression\",\"optionSourceType\":0,\"dataType\":3,\"inputType\":0,\"isShow\":true,\"canEdit\":true,\"isEmit\":false,\"isValidate\":false,\"valuesMap\":null,\"index\":4,\"createTime\":null,\"updateTime\":null},{\"id\":5,\"field\":\"src_field\",\"type\":\"select\",\"title\":\"$t(src_field)\",\"data\":null,\"options\":null,\"placeholder\":\"Please enter column, only single column is supported\",\"optionSourceType\":0,\"dataType\":0,\"inputType\":0,\"isShow\":true,\"canEdit\":true,\"isEmit\":false,\"isValidate\":true,\"valuesMap\":null,\"index\":5,\"createTime\":null,\"updateTime\":null},{\"id\":6,\"field\":\"statistics_name\",\"type\":\"input\",\"title\":\"$t(statistics_name)\",\"data\":\"duplicate_count.duplicates\",\"options\":null,\"placeholder\":\"Please enter statistics name, the alias in statistics execute sql\",\"optionSourceType\":0,\"dataType\":0,\"inputType\":1,\"isShow\":false,\"canEdit\":false,\"isEmit\":false,\"isValidate\":true,\"valuesMap\":\"{\\\"statistics_name\\\":\\\"duplicate_count.duplicates\\\"}\",\"index\":6,\"createTime\":null,\"updateTime\":null},{\"id\":7,\"field\":\"check_type\",\"type\":\"select\",\"title\":\"$t(check_type)\",\"data\":\"0\",\"options\":\"[{\\\"label\\\":\\\"Expected - Actual\\\",\\\"value\\\":\\\"0\\\"},{\\\"label\\\":\\\"Actual - Expected\\\",\\\"value\\\":\\\"1\\\"},{\\\"label\\\":\\\"Actual / Expected\\\",\\\"value\\\":\\\"2\\\"},{\\\"label\\\":\\\"(Expected - Actual) / Expected\\\",\\\"value\\\":\\\"3\\\"}]\",\"placeholder\":\"please select check type\",\"optionSourceType\":0,\"dataType\":0,\"inputType\":3,\"isShow\":true,\"canEdit\":true,\"isEmit\":true,\"isValidate\":false,\"valuesMap\":null,\"index\":7,\"createTime\":null,\"updateTime\":null},{\"id\":8,\"field\":\"operator\",\"type\":\"select\",\"title\":\"$t(operator)\",\"data\":\"0\",\"options\":\"[{\\\"label\\\":\\\"=\\\",\\\"value\\\":\\\"0\\\"},{\\\"label\\\":\\\"<\\\",\\\"value\\\":\\\"1\\\"},{\\\"label\\\":\\\"<=\\\",\\\"value\\\":\\\"2\\\"},{\\\"label\\\":\\\">\\\",\\\"value\\\":\\\"3\\\"},{\\\"label\\\":\\\">=\\\",\\\"value\\\":\\\"4\\\"},{\\\"label\\\":\\\"!=\\\",\\\"value\\\":\\\"5\\\"}]\",\"placeholder\":\"please select operator\",\"optionSourceType\":0,\"dataType\":0,\"inputType\":3,\"isShow\":true,\"canEdit\":true,\"isEmit\":false,\"isValidate\":false,\"valuesMap\":null,\"index\":8,\"createTime\":null,\"updateTime\":null},{\"id\":9,\"field\":\"threshold\",\"type\":\"input\",\"title\":\"$t(threshold)\",\"data\":null,\"options\":null,\"placeholder\":\"Please enter threshold, number is needed\",\"optionSourceType\":0,\"dataType\":2,\"inputType\":3,\"isShow\":true,\"canEdit\":true,\"isEmit\":false,\"isValidate\":true,\"valuesMap\":null,\"index\":9,\"createTime\":null,\"updateTime\":null},{\"id\":10,\"field\":\"failure_strategy\",\"type\":\"select\",\"title\":\"$t(failure_strategy)\",\"data\":\"0\",\"options\":\"[{\\\"label\\\":\\\"Alert\\\",\\\"value\\\":\\\"0\\\"},{\\\"label\\\":\\\"Block\\\",\\\"value\\\":\\\"1\\\"}]\",\"placeholder\":\"please select failure strategy\",\"optionSourceType\":0,\"dataType\":0,\"inputType\":3,\"isShow\":true,\"canEdit\":true,\"isEmit\":false,\"isValidate\":false,\"valuesMap\":null,\"index\":10,\"createTime\":null,\"updateTime\":null},{\"id\":17,\"field\":\"comparison_name\",\"type\":\"input\",\"title\":\"$t(comparison_name)\",\"data\":null,\"options\":null,\"placeholder\":\"Please enter comparison name, the alias in comparison execute sql\",\"optionSourceType\":0,\"dataType\":0,\"inputType\":0,\"isShow\":false,\"canEdit\":false,\"isEmit\":false,\"isValidate\":true,\"valuesMap\":\"\",\"index\":11,\"createTime\":null,\"updateTime\":null},{\"id\":19,\"field\":\"comparison_type\",\"type\":\"select\",\"title\":\"$t(comparison_type)\",\"data\":\"\",\"options\":null,\"placeholder\":\"Please enter comparison title\",\"optionSourceType\":3,\"dataType\":0,\"inputType\":2,\"isShow\":true,\"canEdit\":false,\"isEmit\":true,\"isValidate\":false,\"valuesMap\":null,\"index\":12,\"createTime\":null,\"updateTime\":null}]",
    "executeSqlList" : "[{\"id\":6,\"index\":1,\"sql\":\"SELECT ${src_field} FROM ${src_table} group by ${src_field} having count(*) > 1\",\"tableAlias\":\"duplicate_items\",\"type\":0,\"createTime\":\"2021-03-03 11:31:24\",\"updateTime\":\"2021-03-03 11:31:24\",\"errorOutputSql\":true},{\"id\":7,\"index\":1,\"sql\":\"SELECT COUNT(*) AS duplicates FROM duplicate_items\",\"tableAlias\":\"duplicate_count\",\"type\":1,\"createTime\":\"2021-03-03 11:31:24\",\"updateTime\":\"2021-03-03 11:31:24\",\"errorOutputSql\":false}]",
    "comparisonNeedStatisticsValueTable" : false,
    "compareWithFixedValue" : true,
    "hdfsPath" : "hdfs://mycluster:8020/user/default/data_quality_error_data",
    "sourceConnectorType" : "JDBC",
    "sourceType" : 1,
    "sourceConnectionParams" : "{\"user\":\"root\",\"password\":\"root\",\"address\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432\",\"database\":\"persistence\",\"jdbcUrl\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432/persistence\",\"driverClassName\":\"org.postgresql.Driver\",\"validationQuery\":\"select version()\",\"other\":{\"password\":\"root\"}}",
    "targetConnectorType" : null,
    "targetType" : 0,
    "targetConnectionParams" : null,
    "writerConnectorType" : "JDBC",
    "writerType" : 1,
    "writerTable" : "t_ds_dq_execute_result",
    "writerConnectionParams" : "{\"user\":\"root\",\"password\":\"root\",\"address\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432\",\"database\":\"dolphinscheduler\",\"jdbcUrl\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432/dolphinscheduler\"}",
    "statisticsValueConnectorType" : "JDBC",
    "statisticsValueType" : 1,
    "statisticsValueTable" : "t_ds_dq_task_statistics_value",
    "statisticsValueWriterConnectionParams" : "{\"user\":\"root\",\"password\":\"root\",\"address\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432\",\"database\":\"dolphinscheduler\",\"jdbcUrl\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432/dolphinscheduler\"}"
  },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-1059][TI-3955] - [INFO] 2024-05-07 10:30:51.726 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-1059][TI-3955] - [INFO] 2024-05-07 10:30:51.727 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-1059][TI-3955] - [INFO] 2024-05-07 10:30:51.727 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:52.126 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.1894273127753303 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-1059][TI-3955] - [INFO] 2024-05-07 10:30:52.186 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-1059][TI-3955] - [INFO] 2024-05-07 10:30:52.215 +0800 o.a.d.c.u.OSUtils:[231] - create linux os user: default
[WI-1059][TI-3955] - [INFO] 2024-05-07 10:30:52.216 +0800 o.a.d.c.u.OSUtils:[233] - execute cmd: sudo useradd -g root
 default
[WI-1059][TI-3955] - [INFO] 2024-05-07 10:30:52.353 +0800 o.a.d.c.u.OSUtils:[190] - create user default success
[WI-1059][TI-3955] - [INFO] 2024-05-07 10:30:52.354 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-1059][TI-3955] - [INFO] 2024-05-07 10:30:52.357 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13001194483488/13505298546272_21/1059/3955 check successfully
[WI-1059][TI-3955] - [INFO] 2024-05-07 10:30:52.358 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.dq.DataQualityTaskChannel successfully
[WI-1059][TI-3955] - [INFO] 2024-05-07 10:30:52.464 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-1059][TI-3955] - [INFO] 2024-05-07 10:30:52.474 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-1059][TI-3955] - [INFO] 2024-05-07 10:30:52.477 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: DATA_QUALITY create successfully
[WI-1059][TI-3955] - [INFO] 2024-05-07 10:30:52.482 +0800 o.a.d.p.t.d.DataQualityTask:[89] - Initialize data quality task params {
  "localParams" : [ ],
  "varPool" : null,
  "ruleId" : 6,
  "ruleInputParameter" : {
    "check_type" : "0",
    "comparison_type" : "1",
    "comparison_name" : "0",
    "failure_strategy" : "0",
    "operator" : "0",
    "src_connector_type" : "1",
    "src_datasource_id" : "6",
    "src_database" : "persistence",
    "src_field" : "content",
    "src_table" : "filtered_data_persistence",
    "threshold" : "0"
  },
  "sparkParameters" : {
    "localParams" : null,
    "varPool" : null,
    "mainJar" : null,
    "mainClass" : null,
    "deployMode" : "local",
    "mainArgs" : null,
    "driverCores" : 1,
    "driverMemory" : "512M",
    "numExecutors" : 1,
    "executorCores" : 1,
    "executorMemory" : "1G",
    "appName" : null,
    "yarnQueue" : "",
    "others" : "--conf spark.driver.extraJavaOptions=\"-Divy.cache.dir=/tmp -Divy.home=/tmp\" \\\n--packages org.postgresql:postgresql:42.7.3",
    "programType" : null,
    "resourceList" : [ ]
  }
}
[WI-1059][TI-3955] - [INFO] 2024-05-07 10:30:52.520 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: HANA
[WI-1059][TI-3955] - [INFO] 2024-05-07 10:30:52.521 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: HANA
[WI-1059][TI-3955] - [INFO] 2024-05-07 10:30:52.524 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: SQLSERVER
[WI-1059][TI-3955] - [INFO] 2024-05-07 10:30:52.526 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: SQLSERVER
[WI-1059][TI-3955] - [INFO] 2024-05-07 10:30:52.528 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: SAGEMAKER
[WI-1059][TI-3955] - [INFO] 2024-05-07 10:30:52.528 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: SAGEMAKER
[WI-1059][TI-3955] - [INFO] 2024-05-07 10:30:52.530 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: DATABEND
[WI-1059][TI-3955] - [INFO] 2024-05-07 10:30:52.531 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: DATABEND
[WI-1059][TI-3955] - [INFO] 2024-05-07 10:30:52.651 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: AZURESQL
[WI-1059][TI-3955] - [INFO] 2024-05-07 10:30:52.654 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: AZURESQL
[WI-1059][TI-3955] - [INFO] 2024-05-07 10:30:52.658 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: HIVE
[WI-1059][TI-3955] - [INFO] 2024-05-07 10:30:52.659 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: HIVE
[WI-1059][TI-3955] - [INFO] 2024-05-07 10:30:52.662 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: DORIS
[WI-1059][TI-3955] - [INFO] 2024-05-07 10:30:52.662 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: DORIS
[WI-1059][TI-3955] - [INFO] 2024-05-07 10:30:52.668 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: POSTGRESQL
[WI-1059][TI-3955] - [INFO] 2024-05-07 10:30:52.668 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: POSTGRESQL
[WI-1059][TI-3955] - [INFO] 2024-05-07 10:30:52.672 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: MYSQL
[WI-1059][TI-3955] - [INFO] 2024-05-07 10:30:52.672 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: MYSQL
[WI-1059][TI-3955] - [INFO] 2024-05-07 10:30:52.674 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: REDSHIFT
[WI-1059][TI-3955] - [INFO] 2024-05-07 10:30:52.675 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: REDSHIFT
[WI-1059][TI-3955] - [INFO] 2024-05-07 10:30:52.678 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: SNOWFLAKE
[WI-1059][TI-3955] - [INFO] 2024-05-07 10:30:52.679 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: SNOWFLAKE
[WI-1059][TI-3955] - [INFO] 2024-05-07 10:30:52.681 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: STARROCKS
[WI-1059][TI-3955] - [INFO] 2024-05-07 10:30:52.682 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: STARROCKS
[WI-1059][TI-3955] - [INFO] 2024-05-07 10:30:52.684 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: SSH
[WI-1059][TI-3955] - [INFO] 2024-05-07 10:30:52.684 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: SSH
[WI-1059][TI-3955] - [INFO] 2024-05-07 10:30:52.695 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: ATHENA
[WI-0][TI-3955] - [INFO] 2024-05-07 10:30:52.697 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=3955, success=true)
[WI-1059][TI-3955] - [INFO] 2024-05-07 10:30:52.697 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: ATHENA
[WI-1059][TI-3955] - [INFO] 2024-05-07 10:30:52.716 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: PRESTO
[WI-1059][TI-3955] - [INFO] 2024-05-07 10:30:52.718 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: PRESTO
[WI-1059][TI-3955] - [INFO] 2024-05-07 10:30:52.721 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: OCEANBASE
[WI-1059][TI-3955] - [INFO] 2024-05-07 10:30:52.724 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: OCEANBASE
[WI-1059][TI-3955] - [INFO] 2024-05-07 10:30:52.739 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: ORACLE
[WI-1059][TI-3955] - [INFO] 2024-05-07 10:30:52.751 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: ORACLE
[WI-1059][TI-3955] - [INFO] 2024-05-07 10:30:52.756 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: CLICKHOUSE
[WI-1059][TI-3955] - [INFO] 2024-05-07 10:30:52.759 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: CLICKHOUSE
[WI-1059][TI-3955] - [INFO] 2024-05-07 10:30:52.764 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: VERTICA
[WI-1059][TI-3955] - [INFO] 2024-05-07 10:30:52.764 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: VERTICA
[WI-1059][TI-3955] - [INFO] 2024-05-07 10:30:52.768 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: KYUUBI
[WI-1059][TI-3955] - [INFO] 2024-05-07 10:30:52.769 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: KYUUBI
[WI-1059][TI-3955] - [INFO] 2024-05-07 10:30:52.772 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: DB2
[WI-1059][TI-3955] - [INFO] 2024-05-07 10:30:52.776 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: DB2
[WI-1059][TI-3955] - [INFO] 2024-05-07 10:30:52.783 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: TRINO
[WI-1059][TI-3955] - [INFO] 2024-05-07 10:30:52.785 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: TRINO
[WI-1059][TI-3955] - [INFO] 2024-05-07 10:30:52.788 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: SPARK
[WI-1059][TI-3955] - [INFO] 2024-05-07 10:30:52.793 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: SPARK
[WI-1059][TI-3955] - [INFO] 2024-05-07 10:30:52.799 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: DAMENG
[WI-1059][TI-3955] - [INFO] 2024-05-07 10:30:52.800 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: DAMENG
[WI-1059][TI-3955] - [INFO] 2024-05-07 10:30:52.804 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: ZEPPELIN
[WI-1059][TI-3955] - [INFO] 2024-05-07 10:30:52.805 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: ZEPPELIN
[WI-1059][TI-3955] - [INFO] 2024-05-07 10:30:52.822 +0800 o.a.d.p.t.d.DataQualityTask:[119] - data quality configuration: {
  "name" : "$t(uniqueness_check)",
  "env" : {
    "type" : "batch",
    "config" : null
  },
  "readers" : [ {
    "type" : "JDBC",
    "config" : {
      "database" : "persistence",
      "password" : "root",
      "driver" : "org.postgresql.Driver",
      "user" : "root",
      "output_table" : "persistence_filtered_data_persistence",
      "table" : "filtered_data_persistence",
      "url" : "jdbc:postgresql://dolphinscheduler-postgresql:5432/persistence?password=root"
    }
  } ],
  "transformers" : [ {
    "type" : "sql",
    "config" : {
      "index" : 1,
      "output_table" : "duplicate_items",
      "sql" : "SELECT content FROM persistence_filtered_data_persistence group by content having count(*) > 1"
    }
  }, {
    "type" : "sql",
    "config" : {
      "index" : 2,
      "output_table" : "duplicate_count",
      "sql" : "SELECT COUNT(*) AS duplicates FROM duplicate_items"
    }
  } ],
  "writers" : [ {
    "type" : "JDBC",
    "config" : {
      "database" : "dolphinscheduler",
      "password" : "root",
      "driver" : "org.postgresql.Driver",
      "user" : "root",
      "table" : "t_ds_dq_execute_result",
      "url" : "jdbc:postgresql://dolphinscheduler-postgresql:5432/dolphinscheduler",
      "sql" : "select 0 as rule_type,'$t(uniqueness_check)' as rule_name,0 as process_definition_id,1059 as process_instance_id,3955 as task_instance_id,duplicate_count.duplicates AS statistics_value,0 AS comparison_value,1 AS comparison_type,0 as check_type,0 as threshold,0 as operator,0 as failure_strategy,'hdfs://mycluster:8020/user/default/data_quality_error_data/0_1059_[null check] filtered data persistence' as error_output_path,'2024-05-07 10:30:52' as create_time,'2024-05-07 10:30:52' as update_time from duplicate_count "
    }
  }, {
    "type" : "JDBC",
    "config" : {
      "database" : "dolphinscheduler",
      "password" : "root",
      "driver" : "org.postgresql.Driver",
      "user" : "root",
      "table" : "t_ds_dq_task_statistics_value",
      "url" : "jdbc:postgresql://dolphinscheduler-postgresql:5432/dolphinscheduler",
      "sql" : "select 0 as process_definition_id,3955 as task_instance_id,6 as rule_id,'KA0AXXWVHWW+GZX4BPZXFGFZ0F0OYMUQ+BVYG4+ZIKG=' as unique_code,'duplicate_count.duplicates'AS statistics_name,duplicate_count.duplicates AS statistics_value,'2024-05-07 10:30:52' as data_time,'2024-05-07 10:30:52' as create_time,'2024-05-07 10:30:52' as update_time from duplicate_count"
    }
  }, {
    "type" : "hdfs_file",
    "config" : {
      "path" : "hdfs://mycluster:8020/user/default/data_quality_error_data/0_1059_[null check] filtered data persistence",
      "input_table" : "duplicate_items"
    }
  } ]
}
[WI-1059][TI-3955] - [INFO] 2024-05-07 10:30:52.834 +0800 o.a.d.p.d.a.u.CommonUtils:[136] - Trying to get data quality jar in path
[WI-1059][TI-3955] - [INFO] 2024-05-07 10:30:52.835 +0800 o.a.d.p.d.a.u.CommonUtils:[147] - data quality jar path is empty, will try to auto discover it from build-in rules.
[WI-1059][TI-3955] - [INFO] 2024-05-07 10:30:52.836 +0800 o.a.d.p.d.a.u.CommonUtils:[187] - Try to get data quality jar from path /opt/dolphinscheduler/conf/../libs
[WI-1059][TI-3955] - [INFO] 2024-05-07 10:30:52.838 +0800 o.a.d.p.d.a.u.CommonUtils:[182] - get default data quality jar name: /opt/dolphinscheduler/conf/../libs/dolphinscheduler-data-quality-3.2.1.jar
[WI-1059][TI-3955] - [INFO] 2024-05-07 10:30:52.839 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-1059][TI-3955] - [INFO] 2024-05-07 10:30:52.839 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: null successfully
[WI-1059][TI-3955] - [INFO] 2024-05-07 10:30:52.855 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-1059][TI-3955] - [INFO] 2024-05-07 10:30:52.856 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-1059][TI-3955] - [INFO] 2024-05-07 10:30:52.856 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-1059][TI-3955] - [INFO] 2024-05-07 10:30:52.864 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-1059][TI-3955] - [INFO] 2024-05-07 10:30:52.864 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-1059][TI-3955] - [INFO] 2024-05-07 10:30:52.864 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export PYSPARK_DRIVER_PYTHON=/bin/python3.11
export PYSPARK_PYTHON=/bin/python3.11
${SPARK_HOME}/bin/spark-submit --master local --driver-cores 1 --driver-memory 512M --num-executors 1 --executor-cores 1 --executor-memory 1G --conf spark.driver.extraJavaOptions="-Divy.cache.dir=/tmp -Divy.home=/tmp" \
--packages org.postgresql:postgresql:42.7.3 /opt/dolphinscheduler/conf/../libs/dolphinscheduler-data-quality-3.2.1.jar "{\"name\":\"$t(uniqueness_check)\",\"env\":{\"type\":\"batch\",\"config\":null},\"readers\":[{\"type\":\"JDBC\",\"config\":{\"database\":\"persistence\",\"password\":\"root\",\"driver\":\"org.postgresql.Driver\",\"user\":\"root\",\"output_table\":\"persistence_filtered_data_persistence\",\"table\":\"filtered_data_persistence\",\"url\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432/persistence?password=root\"} }],\"transformers\":[{\"type\":\"sql\",\"config\":{\"index\":1,\"output_table\":\"duplicate_items\",\"sql\":\"SELECT content FROM persistence_filtered_data_persistence group by content having count(*) > 1\"} },{\"type\":\"sql\",\"config\":{\"index\":2,\"output_table\":\"duplicate_count\",\"sql\":\"SELECT COUNT(*) AS duplicates FROM duplicate_items\"} }],\"writers\":[{\"type\":\"JDBC\",\"config\":{\"database\":\"dolphinscheduler\",\"password\":\"root\",\"driver\":\"org.postgresql.Driver\",\"user\":\"root\",\"table\":\"t_ds_dq_execute_result\",\"url\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432/dolphinscheduler\",\"sql\":\"select 0 as rule_type,'$t(uniqueness_check)' as rule_name,0 as process_definition_id,1059 as process_instance_id,3955 as task_instance_id,duplicate_count.duplicates AS statistics_value,0 AS comparison_value,1 AS comparison_type,0 as check_type,0 as threshold,0 as operator,0 as failure_strategy,'hdfs://mycluster:8020/user/default/data_quality_error_data/0_1059_[null check] filtered data persistence' as error_output_path,'2024-05-07 10:30:52' as create_time,'2024-05-07 10:30:52' as update_time from duplicate_count \"} },{\"type\":\"JDBC\",\"config\":{\"database\":\"dolphinscheduler\",\"password\":\"root\",\"driver\":\"org.postgresql.Driver\",\"user\":\"root\",\"table\":\"t_ds_dq_task_statistics_value\",\"url\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432/dolphinscheduler\",\"sql\":\"select 0 as process_definition_id,3955 as task_instance_id,6 as rule_id,'KA0AXXWVHWW+GZX4BPZXFGFZ0F0OYMUQ+BVYG4+ZIKG=' as unique_code,'duplicate_count.duplicates'AS statistics_name,duplicate_count.duplicates AS statistics_value,'2024-05-07 10:30:52' as data_time,'2024-05-07 10:30:52' as create_time,'2024-05-07 10:30:52' as update_time from duplicate_count\"} },{\"type\":\"hdfs_file\",\"config\":{\"path\":\"hdfs://mycluster:8020/user/default/data_quality_error_data/0_1059_[null check] filtered data persistence\",\"input_table\":\"duplicate_items\"} }]}"
[WI-1059][TI-3955] - [INFO] 2024-05-07 10:30:52.865 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-1059][TI-3955] - [INFO] 2024-05-07 10:30:52.886 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13001194483488/13505298546272_21/1059/3955/1059_3955.sh
[WI-1059][TI-3955] - [INFO] 2024-05-07 10:30:53.030 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 85
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:53.131 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.2938596491228072 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-3955] - [INFO] 2024-05-07 10:30:53.700 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=3955)
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:54.144 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7489361702127659 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:54.162 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:55.148 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8579545454545454 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:56.198 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	:: loading settings :: url = jar:file:/opt/spark-3.5.1-bin-hadoop3/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml
	Ivy Default Cache set to: /tmp
	The jars for the packages stored in: /tmp/jars
	org.postgresql#postgresql added as a dependency
	:: resolving dependencies :: org.apache.spark#spark-submit-parent-832f6793-96b9-45b7-8fcc-051597f450da;1.0
		confs: [default]
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:56.203 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.75 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:30:58.210 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
		found org.postgresql#postgresql;42.7.3 in central
		found org.checkerframework#checker-qual;3.42.0 in central
	downloading https://repo1.maven.org/maven2/org/postgresql/postgresql/42.7.3/postgresql-42.7.3.jar ...
[WI-0][TI-0] - [INFO] 2024-05-07 10:31:00.218 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
		[SUCCESSFUL ] org.postgresql#postgresql;42.7.3!postgresql.jar (1287ms)
	downloading https://repo1.maven.org/maven2/org/checkerframework/checker-qual/3.42.0/checker-qual-3.42.0.jar ...
		[SUCCESSFUL ] org.checkerframework#checker-qual;3.42.0!checker-qual.jar (387ms)
	:: resolution report :: resolve 2011ms :: artifacts dl 1679ms
		:: modules in use:
		org.checkerframework#checker-qual;3.42.0 from central in [default]
		org.postgresql#postgresql;42.7.3 from central in [default]
		---------------------------------------------------------------------
		|                  |            modules            ||   artifacts   |
		|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
		---------------------------------------------------------------------
		|      default     |   2   |   2   |   2   |   0   ||   2   |   2   |
		---------------------------------------------------------------------
	:: retrieving :: org.apache.spark#spark-submit-parent-832f6793-96b9-45b7-8fcc-051597f450da
		confs: [default]
		2 artifacts copied, 0 already retrieved (1289kB/7ms)
	24/05/07 10:30:59 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[WI-0][TI-0] - [INFO] 2024-05-07 10:31:01.221 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:31:00 INFO SparkContext: Running Spark version 3.5.1
	24/05/07 10:31:00 INFO SparkContext: OS info Linux, 6.5.0-28-generic, amd64
	24/05/07 10:31:00 INFO SparkContext: Java version 1.8.0_402
	24/05/07 10:31:00 INFO ResourceUtils: ==============================================================
	24/05/07 10:31:00 INFO ResourceUtils: No custom resources configured for spark.driver.
	24/05/07 10:31:00 INFO ResourceUtils: ==============================================================
	24/05/07 10:31:00 INFO SparkContext: Submitted application: (uniqueness_check)
	24/05/07 10:31:00 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
	24/05/07 10:31:00 INFO ResourceProfile: Limiting resource is cpu
	24/05/07 10:31:00 INFO ResourceProfileManager: Added ResourceProfile id: 0
	24/05/07 10:31:00 INFO SecurityManager: Changing view acls to: default
	24/05/07 10:31:00 INFO SecurityManager: Changing modify acls to: default
	24/05/07 10:31:00 INFO SecurityManager: Changing view acls groups to: 
	24/05/07 10:31:00 INFO SecurityManager: Changing modify acls groups to: 
	24/05/07 10:31:00 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: default; groups with view permissions: EMPTY; users with modify permissions: default; groups with modify permissions: EMPTY
	24/05/07 10:31:00 INFO Utils: Successfully started service 'sparkDriver' on port 35309.
	24/05/07 10:31:00 INFO SparkEnv: Registering MapOutputTracker
	24/05/07 10:31:00 INFO SparkEnv: Registering BlockManagerMaster
	24/05/07 10:31:00 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
	24/05/07 10:31:00 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
	24/05/07 10:31:00 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
	24/05/07 10:31:00 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-40fe77a0-0af0-46eb-b067-50f117e2a9e3
	24/05/07 10:31:00 INFO MemoryStore: MemoryStore started with capacity 93.3 MiB
	24/05/07 10:31:00 INFO SparkEnv: Registering OutputCommitCoordinator
	24/05/07 10:31:01 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
	24/05/07 10:31:01 INFO Utils: Successfully started service 'SparkUI' on port 4040.
[WI-0][TI-0] - [INFO] 2024-05-07 10:31:02.224 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:31:01 INFO SparkContext: Added JAR file:///tmp/jars/org.postgresql_postgresql-42.7.3.jar at spark://b2617105c628:35309/jars/org.postgresql_postgresql-42.7.3.jar with timestamp 1715049060320
	24/05/07 10:31:01 INFO SparkContext: Added JAR file:///tmp/jars/org.checkerframework_checker-qual-3.42.0.jar at spark://b2617105c628:35309/jars/org.checkerframework_checker-qual-3.42.0.jar with timestamp 1715049060320
	24/05/07 10:31:01 INFO SparkContext: Added JAR file:/opt/dolphinscheduler/libs/dolphinscheduler-data-quality-3.2.1.jar at spark://b2617105c628:35309/jars/dolphinscheduler-data-quality-3.2.1.jar with timestamp 1715049060320
	24/05/07 10:31:01 INFO Executor: Starting executor ID driver on host b2617105c628
	24/05/07 10:31:01 INFO Executor: OS info Linux, 6.5.0-28-generic, amd64
	24/05/07 10:31:01 INFO Executor: Java version 1.8.0_402
	24/05/07 10:31:01 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
	24/05/07 10:31:01 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@358ab600 for default.
	24/05/07 10:31:01 INFO Executor: Fetching spark://b2617105c628:35309/jars/org.checkerframework_checker-qual-3.42.0.jar with timestamp 1715049060320
	24/05/07 10:31:01 INFO TransportClientFactory: Successfully created connection to b2617105c628/172.18.1.1:35309 after 105 ms (0 ms spent in bootstraps)
	24/05/07 10:31:01 INFO Utils: Fetching spark://b2617105c628:35309/jars/org.checkerframework_checker-qual-3.42.0.jar to /tmp/spark-f7198339-6a69-477a-b068-4c3bdefce3ec/userFiles-c0f3ba86-185d-4de6-939a-af3e7fd56f85/fetchFileTemp3285322979692643715.tmp
	24/05/07 10:31:01 INFO Executor: Adding file:/tmp/spark-f7198339-6a69-477a-b068-4c3bdefce3ec/userFiles-c0f3ba86-185d-4de6-939a-af3e7fd56f85/org.checkerframework_checker-qual-3.42.0.jar to class loader default
	24/05/07 10:31:01 INFO Executor: Fetching spark://b2617105c628:35309/jars/org.postgresql_postgresql-42.7.3.jar with timestamp 1715049060320
	24/05/07 10:31:01 INFO Utils: Fetching spark://b2617105c628:35309/jars/org.postgresql_postgresql-42.7.3.jar to /tmp/spark-f7198339-6a69-477a-b068-4c3bdefce3ec/userFiles-c0f3ba86-185d-4de6-939a-af3e7fd56f85/fetchFileTemp625331496706870590.tmp
	24/05/07 10:31:01 INFO Executor: Adding file:/tmp/spark-f7198339-6a69-477a-b068-4c3bdefce3ec/userFiles-c0f3ba86-185d-4de6-939a-af3e7fd56f85/org.postgresql_postgresql-42.7.3.jar to class loader default
	24/05/07 10:31:01 INFO Executor: Fetching spark://b2617105c628:35309/jars/dolphinscheduler-data-quality-3.2.1.jar with timestamp 1715049060320
	24/05/07 10:31:01 INFO Utils: Fetching spark://b2617105c628:35309/jars/dolphinscheduler-data-quality-3.2.1.jar to /tmp/spark-f7198339-6a69-477a-b068-4c3bdefce3ec/userFiles-c0f3ba86-185d-4de6-939a-af3e7fd56f85/fetchFileTemp4579467117465686834.tmp
	24/05/07 10:31:01 INFO Executor: Adding file:/tmp/spark-f7198339-6a69-477a-b068-4c3bdefce3ec/userFiles-c0f3ba86-185d-4de6-939a-af3e7fd56f85/dolphinscheduler-data-quality-3.2.1.jar to class loader default
	24/05/07 10:31:01 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38005.
	24/05/07 10:31:01 INFO NettyBlockTransferService: Server created on b2617105c628:38005
	24/05/07 10:31:01 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
	24/05/07 10:31:01 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, b2617105c628, 38005, None)
	24/05/07 10:31:01 INFO BlockManagerMasterEndpoint: Registering block manager b2617105c628:38005 with 93.3 MiB RAM, BlockManagerId(driver, b2617105c628, 38005, None)
	24/05/07 10:31:01 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, b2617105c628, 38005, None)
	24/05/07 10:31:01 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, b2617105c628, 38005, None)
	24/05/07 10:31:02 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
	24/05/07 10:31:02 INFO SharedState: Warehouse path is 'file:/tmp/dolphinscheduler/exec/process/default/13001194483488/13505298546272_21/1059/3955/spark-warehouse'.
[WI-0][TI-0] - [INFO] 2024-05-07 10:31:06.288 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:31:05 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
[WI-0][TI-0] - [INFO] 2024-05-07 10:31:07.310 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:31:06 INFO CodeGenerator: Code generated in 287.031173 ms
	24/05/07 10:31:06 INFO DAGScheduler: Registering RDD 2 (save at JdbcWriter.java:87) as input to shuffle 0
	24/05/07 10:31:06 INFO DAGScheduler: Got map stage job 0 (save at JdbcWriter.java:87) with 1 output partitions
	24/05/07 10:31:06 INFO DAGScheduler: Final stage: ShuffleMapStage 0 (save at JdbcWriter.java:87)
	24/05/07 10:31:06 INFO DAGScheduler: Parents of final stage: List()
	24/05/07 10:31:06 INFO DAGScheduler: Missing parents: List()
	24/05/07 10:31:06 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[2] at save at JdbcWriter.java:87), which has no missing parents
	24/05/07 10:31:06 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 34.8 KiB, free 93.3 MiB)
	24/05/07 10:31:06 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 16.4 KiB, free 93.2 MiB)
	24/05/07 10:31:06 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on b2617105c628:38005 (size: 16.4 KiB, free: 93.3 MiB)
	24/05/07 10:31:06 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1585
	24/05/07 10:31:06 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[2] at save at JdbcWriter.java:87) (first 15 tasks are for partitions Vector(0))
	24/05/07 10:31:06 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
	24/05/07 10:31:06 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (b2617105c628, executor driver, partition 0, PROCESS_LOCAL, 7878 bytes) 
	24/05/07 10:31:06 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
	24/05/07 10:31:07 INFO CodeGenerator: Code generated in 41.233825 ms
	24/05/07 10:31:07 INFO CodeGenerator: Code generated in 12.927751 ms
	24/05/07 10:31:07 INFO CodeGenerator: Code generated in 5.722979 ms
	24/05/07 10:31:07 INFO CodeGenerator: Code generated in 10.37387 ms
	24/05/07 10:31:07 INFO CodeGenerator: Code generated in 6.104729 ms
	24/05/07 10:31:07 INFO JDBCRDD: closed connection
[WI-0][TI-0] - [INFO] 2024-05-07 10:31:08.314 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:31:07 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 2491 bytes result sent to driver
	24/05/07 10:31:07 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 474 ms on b2617105c628 (executor driver) (1/1)
	24/05/07 10:31:07 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
	24/05/07 10:31:07 INFO DAGScheduler: ShuffleMapStage 0 (save at JdbcWriter.java:87) finished in 0.782 s
	24/05/07 10:31:07 INFO DAGScheduler: looking for newly runnable stages
	24/05/07 10:31:07 INFO DAGScheduler: running: Set()
	24/05/07 10:31:07 INFO DAGScheduler: waiting: Set()
	24/05/07 10:31:07 INFO DAGScheduler: failed: Set()
	24/05/07 10:31:07 INFO ShufflePartitionsUtil: For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
	24/05/07 10:31:07 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
	24/05/07 10:31:07 INFO CodeGenerator: Code generated in 15.265528 ms
	24/05/07 10:31:07 INFO DAGScheduler: Registering RDD 5 (save at JdbcWriter.java:87) as input to shuffle 1
	24/05/07 10:31:07 INFO DAGScheduler: Got map stage job 1 (save at JdbcWriter.java:87) with 1 output partitions
	24/05/07 10:31:07 INFO DAGScheduler: Final stage: ShuffleMapStage 2 (save at JdbcWriter.java:87)
	24/05/07 10:31:07 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
	24/05/07 10:31:07 INFO DAGScheduler: Missing parents: List()
	24/05/07 10:31:07 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[5] at save at JdbcWriter.java:87), which has no missing parents
	24/05/07 10:31:07 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 40.5 KiB, free 93.2 MiB)
	24/05/07 10:31:07 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 19.1 KiB, free 93.2 MiB)
	24/05/07 10:31:07 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on b2617105c628:38005 (size: 19.1 KiB, free: 93.3 MiB)
	24/05/07 10:31:07 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1585
	24/05/07 10:31:07 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[5] at save at JdbcWriter.java:87) (first 15 tasks are for partitions Vector(0))
	24/05/07 10:31:07 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
	24/05/07 10:31:07 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 1) (b2617105c628, executor driver, partition 0, NODE_LOCAL, 8032 bytes) 
	24/05/07 10:31:07 INFO Executor: Running task 0.0 in stage 2.0 (TID 1)
	24/05/07 10:31:07 INFO ShuffleBlockFetcherIterator: Getting 1 (2.9 KiB) non-empty blocks including 1 (2.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
	24/05/07 10:31:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 45 ms
	24/05/07 10:31:07 INFO CodeGenerator: Code generated in 17.571962 ms
	24/05/07 10:31:07 INFO BlockManagerInfo: Removed broadcast_0_piece0 on b2617105c628:38005 in memory (size: 16.4 KiB, free: 93.3 MiB)
	24/05/07 10:31:07 INFO Executor: Finished task 0.0 in stage 2.0 (TID 1). 5463 bytes result sent to driver
	24/05/07 10:31:07 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 1) in 171 ms on b2617105c628 (executor driver) (1/1)
	24/05/07 10:31:07 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
	24/05/07 10:31:07 INFO DAGScheduler: ShuffleMapStage 2 (save at JdbcWriter.java:87) finished in 0.186 s
	24/05/07 10:31:07 INFO DAGScheduler: looking for newly runnable stages
	24/05/07 10:31:07 INFO DAGScheduler: running: Set()
	24/05/07 10:31:07 INFO DAGScheduler: waiting: Set()
	24/05/07 10:31:07 INFO DAGScheduler: failed: Set()
	24/05/07 10:31:07 INFO CodeGenerator: Code generated in 10.69701 ms
	24/05/07 10:31:07 INFO SparkContext: Starting job: save at JdbcWriter.java:87
	24/05/07 10:31:07 INFO DAGScheduler: Got job 2 (save at JdbcWriter.java:87) with 1 output partitions
	24/05/07 10:31:07 INFO DAGScheduler: Final stage: ResultStage 5 (save at JdbcWriter.java:87)
	24/05/07 10:31:07 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
	24/05/07 10:31:07 INFO DAGScheduler: Missing parents: List()
	24/05/07 10:31:07 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[10] at save at JdbcWriter.java:87), which has no missing parents
	24/05/07 10:31:07 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 51.4 KiB, free 93.2 MiB)
	24/05/07 10:31:07 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 23.1 KiB, free 93.2 MiB)
	24/05/07 10:31:07 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on b2617105c628:38005 (size: 23.1 KiB, free: 93.3 MiB)
	24/05/07 10:31:07 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1585
	24/05/07 10:31:07 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[10] at save at JdbcWriter.java:87) (first 15 tasks are for partitions Vector(0))
	24/05/07 10:31:07 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
	24/05/07 10:31:07 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 2) (b2617105c628, executor driver, partition 0, NODE_LOCAL, 8043 bytes) 
	24/05/07 10:31:07 INFO Executor: Running task 0.0 in stage 5.0 (TID 2)
	24/05/07 10:31:08 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
	24/05/07 10:31:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
	24/05/07 10:31:08 INFO CodeGenerator: Code generated in 8.385942 ms
[WI-0][TI-0] - [INFO] 2024-05-07 10:31:09.319 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:31:08 INFO BlockManagerInfo: Removed broadcast_1_piece0 on b2617105c628:38005 in memory (size: 19.1 KiB, free: 93.3 MiB)
	24/05/07 10:31:09 INFO CodeGenerator: Code generated in 11.078951 ms
	24/05/07 10:31:09 INFO Executor: Finished task 0.0 in stage 5.0 (TID 2). 6668 bytes result sent to driver
	24/05/07 10:31:09 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 2) in 1268 ms on b2617105c628 (executor driver) (1/1)
	24/05/07 10:31:09 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
	24/05/07 10:31:09 INFO DAGScheduler: ResultStage 5 (save at JdbcWriter.java:87) finished in 1.399 s
	24/05/07 10:31:09 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
	24/05/07 10:31:09 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
	24/05/07 10:31:09 INFO DAGScheduler: Job 2 finished: save at JdbcWriter.java:87, took 1.419057 s
[WI-0][TI-0] - [INFO] 2024-05-07 10:31:10.322 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:31:09 INFO DAGScheduler: Registering RDD 13 (save at JdbcWriter.java:87) as input to shuffle 2
	24/05/07 10:31:09 INFO DAGScheduler: Got map stage job 3 (save at JdbcWriter.java:87) with 1 output partitions
	24/05/07 10:31:09 INFO DAGScheduler: Final stage: ShuffleMapStage 6 (save at JdbcWriter.java:87)
	24/05/07 10:31:09 INFO DAGScheduler: Parents of final stage: List()
	24/05/07 10:31:09 INFO DAGScheduler: Missing parents: List()
	24/05/07 10:31:09 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[13] at save at JdbcWriter.java:87), which has no missing parents
	24/05/07 10:31:09 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 34.8 KiB, free 93.2 MiB)
	24/05/07 10:31:09 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 16.5 KiB, free 93.2 MiB)
	24/05/07 10:31:09 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on b2617105c628:38005 (size: 16.5 KiB, free: 93.3 MiB)
	24/05/07 10:31:09 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1585
	24/05/07 10:31:09 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[13] at save at JdbcWriter.java:87) (first 15 tasks are for partitions Vector(0))
	24/05/07 10:31:09 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0
	24/05/07 10:31:09 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 3) (b2617105c628, executor driver, partition 0, PROCESS_LOCAL, 7878 bytes) 
	24/05/07 10:31:09 INFO Executor: Running task 0.0 in stage 6.0 (TID 3)
	24/05/07 10:31:09 INFO JDBCRDD: closed connection
	24/05/07 10:31:09 INFO Executor: Finished task 0.0 in stage 6.0 (TID 3). 2448 bytes result sent to driver
	24/05/07 10:31:09 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 3) in 71 ms on b2617105c628 (executor driver) (1/1)
	24/05/07 10:31:09 INFO DAGScheduler: ShuffleMapStage 6 (save at JdbcWriter.java:87) finished in 0.082 s
	24/05/07 10:31:09 INFO DAGScheduler: looking for newly runnable stages
	24/05/07 10:31:09 INFO DAGScheduler: running: Set()
	24/05/07 10:31:09 INFO DAGScheduler: waiting: Set()
	24/05/07 10:31:09 INFO DAGScheduler: failed: Set()
	24/05/07 10:31:09 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
	24/05/07 10:31:09 INFO ShufflePartitionsUtil: For shuffle(2), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
	24/05/07 10:31:09 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
	24/05/07 10:31:09 INFO DAGScheduler: Registering RDD 16 (save at JdbcWriter.java:87) as input to shuffle 3
	24/05/07 10:31:09 INFO DAGScheduler: Got map stage job 4 (save at JdbcWriter.java:87) with 1 output partitions
	24/05/07 10:31:09 INFO DAGScheduler: Final stage: ShuffleMapStage 8 (save at JdbcWriter.java:87)
	24/05/07 10:31:09 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
	24/05/07 10:31:09 INFO DAGScheduler: Missing parents: List()
	24/05/07 10:31:09 INFO DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[16] at save at JdbcWriter.java:87), which has no missing parents
	24/05/07 10:31:09 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 40.6 KiB, free 93.1 MiB)
	24/05/07 10:31:09 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 19.1 KiB, free 93.1 MiB)
	24/05/07 10:31:09 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on b2617105c628:38005 (size: 19.1 KiB, free: 93.2 MiB)
	24/05/07 10:31:09 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1585
	24/05/07 10:31:09 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[16] at save at JdbcWriter.java:87) (first 15 tasks are for partitions Vector(0))
	24/05/07 10:31:09 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0
	24/05/07 10:31:09 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 4) (b2617105c628, executor driver, partition 0, NODE_LOCAL, 8032 bytes) 
	24/05/07 10:31:09 INFO Executor: Running task 0.0 in stage 8.0 (TID 4)
	24/05/07 10:31:09 INFO ShuffleBlockFetcherIterator: Getting 1 (2.9 KiB) non-empty blocks including 1 (2.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
	24/05/07 10:31:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
	24/05/07 10:31:09 INFO Executor: Finished task 0.0 in stage 8.0 (TID 4). 5420 bytes result sent to driver
	24/05/07 10:31:09 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 4) in 20 ms on b2617105c628 (executor driver) (1/1)
	24/05/07 10:31:09 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
	24/05/07 10:31:09 INFO DAGScheduler: ShuffleMapStage 8 (save at JdbcWriter.java:87) finished in 0.034 s
	24/05/07 10:31:09 INFO DAGScheduler: looking for newly runnable stages
	24/05/07 10:31:09 INFO DAGScheduler: running: Set()
	24/05/07 10:31:09 INFO DAGScheduler: waiting: Set()
	24/05/07 10:31:09 INFO DAGScheduler: failed: Set()
	24/05/07 10:31:09 INFO BlockManagerInfo: Removed broadcast_3_piece0 on b2617105c628:38005 in memory (size: 16.5 KiB, free: 93.3 MiB)
	24/05/07 10:31:09 INFO BlockManagerInfo: Removed broadcast_2_piece0 on b2617105c628:38005 in memory (size: 23.1 KiB, free: 93.3 MiB)
	24/05/07 10:31:09 INFO CodeGenerator: Code generated in 22.762151 ms
	24/05/07 10:31:09 INFO BlockManagerInfo: Removed broadcast_4_piece0 on b2617105c628:38005 in memory (size: 19.1 KiB, free: 93.3 MiB)
	24/05/07 10:31:09 INFO SparkContext: Starting job: save at JdbcWriter.java:87
	24/05/07 10:31:09 INFO DAGScheduler: Got job 5 (save at JdbcWriter.java:87) with 1 output partitions
	24/05/07 10:31:09 INFO DAGScheduler: Final stage: ResultStage 11 (save at JdbcWriter.java:87)
	24/05/07 10:31:09 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)
	24/05/07 10:31:09 INFO DAGScheduler: Missing parents: List()
	24/05/07 10:31:09 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[21] at save at JdbcWriter.java:87), which has no missing parents
	24/05/07 10:31:09 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 49.2 KiB, free 93.3 MiB)
	24/05/07 10:31:09 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 22.7 KiB, free 93.2 MiB)
	24/05/07 10:31:09 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on b2617105c628:38005 (size: 22.7 KiB, free: 93.3 MiB)
	24/05/07 10:31:09 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1585
	24/05/07 10:31:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[21] at save at JdbcWriter.java:87) (first 15 tasks are for partitions Vector(0))
	24/05/07 10:31:09 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks resource profile 0
	24/05/07 10:31:09 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 5) (b2617105c628, executor driver, partition 0, NODE_LOCAL, 8043 bytes) 
	24/05/07 10:31:09 INFO Executor: Running task 0.0 in stage 11.0 (TID 5)
	24/05/07 10:31:09 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
	24/05/07 10:31:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
	24/05/07 10:31:09 INFO CodeGenerator: Code generated in 6.356732 ms
	24/05/07 10:31:09 INFO CodeGenerator: Code generated in 7.823624 ms
	24/05/07 10:31:09 INFO Executor: Finished task 0.0 in stage 11.0 (TID 5). 6668 bytes result sent to driver
	24/05/07 10:31:09 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 5) in 86 ms on b2617105c628 (executor driver) (1/1)
	24/05/07 10:31:09 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
	24/05/07 10:31:09 INFO DAGScheduler: ResultStage 11 (save at JdbcWriter.java:87) finished in 0.123 s
	24/05/07 10:31:09 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
	24/05/07 10:31:09 INFO TaskSchedulerImpl: Killing all running tasks in stage 11: Stage finished
	24/05/07 10:31:09 INFO DAGScheduler: Job 5 finished: save at JdbcWriter.java:87, took 0.133679 s
	24/05/07 10:31:09 WARN FileSystem: Failed to initialize fileystem hdfs://mycluster:8020/user/default/data_quality_error_data/0_1059_%5Bnull%20check%5D%20filtered%20data%20persistence: java.lang.IllegalArgumentException: java.net.UnknownHostException: mycluster
	Exception in thread "main" java.lang.IllegalArgumentException: java.net.UnknownHostException: mycluster
		at org.apache.hadoop.security.SecurityUtil.buildTokenService(SecurityUtil.java:466)
		at org.apache.hadoop.hdfs.NameNodeProxiesClient.createProxyWithClientProtocol(NameNodeProxiesClient.java:134)
		at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:374)
		at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:308)
		at org.apache.hadoop.hdfs.DistributedFileSystem.initDFSClient(DistributedFileSystem.java:202)
		at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:187)
		at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469)
		at org.apache.hadoop.fs.FileSystem.access$300(FileSystem.java:174)
		at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3574)
		at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3521)
		at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540)
		at org.apache.hadoop.fs.Path.getFileSystem(Path.java:365)
		at org.apache.spark.sql.execution.datasources.DataSource.planForWritingFileFormat(DataSource.scala:454)
		at org.apache.spark.sql.execution.datasources.DataSource.planForWriting(DataSource.scala:530)
		at org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)
		at org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)
		at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:240)
		at org.apache.spark.sql.DataFrameWriter.csv(DataFrameWriter.scala:850)
		at org.apache.dolphinscheduler.data.quality.flow.batch.writer.file.BaseFileWriter.outputImpl(BaseFileWriter.java:114)
		at org.apache.dolphinscheduler.data.quality.flow.batch.writer.file.HdfsFileWriter.write(HdfsFileWriter.java:40)
		at org.apache.dolphinscheduler.data.quality.execution.SparkBatchExecution.executeWriter(SparkBatchExecution.java:132)
		at org.apache.dolphinscheduler.data.quality.execution.SparkBatchExecution.execute(SparkBatchExecution.java:58)
		at org.apache.dolphinscheduler.data.quality.context.DataQualityContext.execute(DataQualityContext.java:62)
		at org.apache.dolphinscheduler.data.quality.DataQualityApplication.main(DataQualityApplication.java:78)
		at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
		at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
		at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
		at java.lang.reflect.Method.invoke(Method.java:498)
		at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
		at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:1029)
		at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:194)
		at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:217)
		at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:91)
		at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1120)
		at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1129)
		at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
	Caused by: java.net.UnknownHostException: mycluster
		... 36 more
	24/05/07 10:31:09 INFO SparkContext: Invoking stop() from shutdown hook
	24/05/07 10:31:09 INFO SparkContext: SparkContext is stopping with exitCode 0.
	24/05/07 10:31:09 INFO SparkUI: Stopped Spark web UI at http://b2617105c628:4040
	24/05/07 10:31:09 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
	24/05/07 10:31:10 INFO MemoryStore: MemoryStore cleared
	24/05/07 10:31:10 INFO BlockManager: BlockManager stopped
	24/05/07 10:31:10 INFO BlockManagerMaster: BlockManagerMaster stopped
	24/05/07 10:31:10 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
	24/05/07 10:31:10 INFO SparkContext: Successfully stopped SparkContext
	24/05/07 10:31:10 INFO ShutdownHookManager: Shutdown hook called
	24/05/07 10:31:10 INFO ShutdownHookManager: Deleting directory /tmp/spark-b3a0b02e-7bb1-495a-b2f5-5ec3741e396e
	24/05/07 10:31:10 INFO ShutdownHookManager: Deleting directory /tmp/spark-f7198339-6a69-477a-b068-4c3bdefce3ec
[WI-1059][TI-3955] - [INFO] 2024-05-07 10:31:10.325 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13001194483488/13505298546272_21/1059/3955, processId:85 ,exitStatusCode:1 ,processWaitForStatus:true ,processExitValue:1
[WI-1059][TI-3955] - [INFO] 2024-05-07 10:31:10.327 +0800 o.a.d.p.t.a.u.LogUtils:[79] - Start finding appId in /opt/dolphinscheduler/logs/20240507/13505298546272/21/1059/3955.log, fetch way: log 
[WI-1059][TI-3955] - [INFO] 2024-05-07 10:31:10.330 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-1059][TI-3955] - [INFO] 2024-05-07 10:31:10.330 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-1059][TI-3955] - [INFO] 2024-05-07 10:31:10.330 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-1059][TI-3955] - [INFO] 2024-05-07 10:31:10.332 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-1059][TI-3955] - [INFO] 2024-05-07 10:31:10.342 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: FAILURE to master : 172.18.1.1:1234
[WI-1059][TI-3955] - [INFO] 2024-05-07 10:31:10.345 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-1059][TI-3955] - [INFO] 2024-05-07 10:31:10.348 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13001194483488/13505298546272_21/1059/3955
[WI-1059][TI-3955] - [INFO] 2024-05-07 10:31:10.360 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13001194483488/13505298546272_21/1059/3955
[WI-1059][TI-3955] - [INFO] 2024-05-07 10:31:10.365 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-0] - [INFO] 2024-05-07 10:33:23.937 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7655367231638418 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:33:24.977 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7395833333333334 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:33:25.980 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8684931506849315 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:33:26.985 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8348082595870207 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:33:27.987 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.939799331103679 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:33:28.989 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8474576271186441 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:33:29.992 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7705882352941176 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:33:31.006 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8850174216027874 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:33:32.010 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8257142857142857 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:33:33.014 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7959770114942528 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:33:34.015 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8525073746312685 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:33:35.030 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8997134670487106 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:33:35.373 +0800 o.a.d.s.w.r.o.TaskInstanceKillOperationFunction:[55] - Receive TaskInstanceKillRequest: TaskInstanceKillRequest(taskInstanceId=3955)
[WI-0][TI-3955] - [ERROR] 2024-05-07 10:33:35.373 +0800 o.a.d.s.w.r.o.TaskInstanceKillOperationFunction:[62] - Cannot find WorkerTaskExecutor for taskInstance: 3955
[WI-0][TI-0] - [INFO] 2024-05-07 10:33:36.032 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8444444444444443 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:33:40.172 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=3956, taskName=[null check] filtered data persistence, firstSubmitTime=1715049220108, startTime=0, taskType=DATA_QUALITY, workflowInstanceHost=172.18.0.15:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13505298546272, processDefineVersion=21, appIds=null, processInstanceId=1060, scheduleTime=0, globalParams=null, executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13001194483488, taskParams={"localParams":[],"resourceList":[],"ruleId":6,"ruleInputParameter":{"check_type":"0","comparison_type":1,"comparison_name":"0","failure_strategy":"0","operator":"0","src_connector_type":1,"src_datasource_id":6,"src_database":"persistence","src_field":"content","src_table":"filtered_data_persistence","threshold":"0"},"sparkParameters":{"deployMode":"local","driverCores":1,"driverMemory":"512M","executorCores":1,"executorMemory":"1G","numExecutors":1,"others":"--conf spark.driver.extraJavaOptions=\"-Divy.cache.dir=/tmp -Divy.home=/tmp\" \\\n--packages org.postgresql:postgresql:42.7.3","yarnQueue":""}}, environmentConfig=export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export PYSPARK_DRIVER_PYTHON=/bin/python3.11
export PYSPARK_PYTHON=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='[null check] filtered data persistence'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13001194483488'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='1060'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240507'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240506'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='3956'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='qualti_test'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13505264408800'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13505298546272'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240507103340'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=null, dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=org.apache.dolphinscheduler.plugin.task.api.DataQualityTaskExecutionContext@5a52fdb5, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-1060][TI-3956] - [INFO] 2024-05-07 10:33:40.178 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: [null check] filtered data persistence to wait queue success
[WI-1060][TI-3956] - [INFO] 2024-05-07 10:33:40.178 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-1060][TI-3956] - [INFO] 2024-05-07 10:33:40.205 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-1060][TI-3956] - [INFO] 2024-05-07 10:33:40.206 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-1060][TI-3956] - [INFO] 2024-05-07 10:33:40.206 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-1060][TI-3956] - [INFO] 2024-05-07 10:33:40.207 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1715049220207
[WI-1060][TI-3956] - [INFO] 2024-05-07 10:33:40.207 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 1060_3956
[WI-1060][TI-3956] - [INFO] 2024-05-07 10:33:40.215 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 3956,
  "taskName" : "[null check] filtered data persistence",
  "firstSubmitTime" : 1715049220108,
  "startTime" : 1715049220207,
  "taskType" : "DATA_QUALITY",
  "workflowInstanceHost" : "172.18.0.15:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240507/13505298546272/21/1060/3956.log",
  "processId" : 0,
  "processDefineCode" : 13505298546272,
  "processDefineVersion" : 21,
  "processInstanceId" : 1060,
  "scheduleTime" : 0,
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13001194483488,
  "taskParams" : "{\"localParams\":[],\"resourceList\":[],\"ruleId\":6,\"ruleInputParameter\":{\"check_type\":\"0\",\"comparison_type\":1,\"comparison_name\":\"0\",\"failure_strategy\":\"0\",\"operator\":\"0\",\"src_connector_type\":1,\"src_datasource_id\":6,\"src_database\":\"persistence\",\"src_field\":\"content\",\"src_table\":\"filtered_data_persistence\",\"threshold\":\"0\"},\"sparkParameters\":{\"deployMode\":\"local\",\"driverCores\":1,\"driverMemory\":\"512M\",\"executorCores\":1,\"executorMemory\":\"1G\",\"numExecutors\":1,\"others\":\"--conf spark.driver.extraJavaOptions=\\\"-Divy.cache.dir=/tmp -Divy.home=/tmp\\\" \\\\\\n--packages org.postgresql:postgresql:42.7.3\",\"yarnQueue\":\"\"}}",
  "environmentConfig" : "export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3\nexport JAVA_HOME=/opt/java/openjdk\nexport PYSPARK_DRIVER_PYTHON=/bin/python3.11\nexport PYSPARK_PYTHON=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "[null check] filtered data persistence"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13001194483488"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1060"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240507"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240506"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "3956"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "qualti_test"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13505264408800"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13505298546272"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240507103340"
    }
  },
  "taskAppId" : "1060_3956",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "dryRun" : 0,
  "paramsMap" : { },
  "dataQualityTaskExecutionContext" : {
    "ruleId" : 6,
    "ruleName" : "$t(uniqueness_check)",
    "ruleType" : 0,
    "ruleInputEntryList" : "[{\"id\":1,\"field\":\"src_connector_type\",\"type\":\"select\",\"title\":\"$t(src_connector_type)\",\"data\":\"\",\"options\":\"[{\\\"label\\\":\\\"HIVE\\\",\\\"value\\\":\\\"HIVE\\\"},{\\\"label\\\":\\\"JDBC\\\",\\\"value\\\":\\\"JDBC\\\"}]\",\"placeholder\":\"please select source connector type\",\"optionSourceType\":2,\"dataType\":2,\"inputType\":0,\"isShow\":true,\"canEdit\":true,\"isEmit\":true,\"isValidate\":false,\"valuesMap\":null,\"index\":1,\"createTime\":null,\"updateTime\":null},{\"id\":2,\"field\":\"src_datasource_id\",\"type\":\"select\",\"title\":\"$t(src_datasource_id)\",\"data\":\"\",\"options\":null,\"placeholder\":\"please select source datasource id\",\"optionSourceType\":1,\"dataType\":2,\"inputType\":0,\"isShow\":true,\"canEdit\":true,\"isEmit\":true,\"isValidate\":false,\"valuesMap\":null,\"index\":2,\"createTime\":null,\"updateTime\":null},{\"id\":30,\"field\":\"src_database\",\"type\":\"select\",\"title\":\"$t(src_database)\",\"data\":null,\"options\":null,\"placeholder\":\"Please select source database\",\"optionSourceType\":0,\"dataType\":0,\"inputType\":0,\"isShow\":true,\"canEdit\":true,\"isEmit\":true,\"isValidate\":true,\"valuesMap\":null,\"index\":2,\"createTime\":null,\"updateTime\":null},{\"id\":3,\"field\":\"src_table\",\"type\":\"select\",\"title\":\"$t(src_table)\",\"data\":null,\"options\":null,\"placeholder\":\"Please enter source table name\",\"optionSourceType\":0,\"dataType\":0,\"inputType\":0,\"isShow\":true,\"canEdit\":true,\"isEmit\":true,\"isValidate\":true,\"valuesMap\":null,\"index\":3,\"createTime\":null,\"updateTime\":null},{\"id\":4,\"field\":\"src_filter\",\"type\":\"input\",\"title\":\"$t(src_filter)\",\"data\":null,\"options\":null,\"placeholder\":\"Please enter filter expression\",\"optionSourceType\":0,\"dataType\":3,\"inputType\":0,\"isShow\":true,\"canEdit\":true,\"isEmit\":false,\"isValidate\":false,\"valuesMap\":null,\"index\":4,\"createTime\":null,\"updateTime\":null},{\"id\":5,\"field\":\"src_field\",\"type\":\"select\",\"title\":\"$t(src_field)\",\"data\":null,\"options\":null,\"placeholder\":\"Please enter column, only single column is supported\",\"optionSourceType\":0,\"dataType\":0,\"inputType\":0,\"isShow\":true,\"canEdit\":true,\"isEmit\":false,\"isValidate\":true,\"valuesMap\":null,\"index\":5,\"createTime\":null,\"updateTime\":null},{\"id\":6,\"field\":\"statistics_name\",\"type\":\"input\",\"title\":\"$t(statistics_name)\",\"data\":\"duplicate_count.duplicates\",\"options\":null,\"placeholder\":\"Please enter statistics name, the alias in statistics execute sql\",\"optionSourceType\":0,\"dataType\":0,\"inputType\":1,\"isShow\":false,\"canEdit\":false,\"isEmit\":false,\"isValidate\":true,\"valuesMap\":\"{\\\"statistics_name\\\":\\\"duplicate_count.duplicates\\\"}\",\"index\":6,\"createTime\":null,\"updateTime\":null},{\"id\":7,\"field\":\"check_type\",\"type\":\"select\",\"title\":\"$t(check_type)\",\"data\":\"0\",\"options\":\"[{\\\"label\\\":\\\"Expected - Actual\\\",\\\"value\\\":\\\"0\\\"},{\\\"label\\\":\\\"Actual - Expected\\\",\\\"value\\\":\\\"1\\\"},{\\\"label\\\":\\\"Actual / Expected\\\",\\\"value\\\":\\\"2\\\"},{\\\"label\\\":\\\"(Expected - Actual) / Expected\\\",\\\"value\\\":\\\"3\\\"}]\",\"placeholder\":\"please select check type\",\"optionSourceType\":0,\"dataType\":0,\"inputType\":3,\"isShow\":true,\"canEdit\":true,\"isEmit\":true,\"isValidate\":false,\"valuesMap\":null,\"index\":7,\"createTime\":null,\"updateTime\":null},{\"id\":8,\"field\":\"operator\",\"type\":\"select\",\"title\":\"$t(operator)\",\"data\":\"0\",\"options\":\"[{\\\"label\\\":\\\"=\\\",\\\"value\\\":\\\"0\\\"},{\\\"label\\\":\\\"<\\\",\\\"value\\\":\\\"1\\\"},{\\\"label\\\":\\\"<=\\\",\\\"value\\\":\\\"2\\\"},{\\\"label\\\":\\\">\\\",\\\"value\\\":\\\"3\\\"},{\\\"label\\\":\\\">=\\\",\\\"value\\\":\\\"4\\\"},{\\\"label\\\":\\\"!=\\\",\\\"value\\\":\\\"5\\\"}]\",\"placeholder\":\"please select operator\",\"optionSourceType\":0,\"dataType\":0,\"inputType\":3,\"isShow\":true,\"canEdit\":true,\"isEmit\":false,\"isValidate\":false,\"valuesMap\":null,\"index\":8,\"createTime\":null,\"updateTime\":null},{\"id\":9,\"field\":\"threshold\",\"type\":\"input\",\"title\":\"$t(threshold)\",\"data\":null,\"options\":null,\"placeholder\":\"Please enter threshold, number is needed\",\"optionSourceType\":0,\"dataType\":2,\"inputType\":3,\"isShow\":true,\"canEdit\":true,\"isEmit\":false,\"isValidate\":true,\"valuesMap\":null,\"index\":9,\"createTime\":null,\"updateTime\":null},{\"id\":10,\"field\":\"failure_strategy\",\"type\":\"select\",\"title\":\"$t(failure_strategy)\",\"data\":\"0\",\"options\":\"[{\\\"label\\\":\\\"Alert\\\",\\\"value\\\":\\\"0\\\"},{\\\"label\\\":\\\"Block\\\",\\\"value\\\":\\\"1\\\"}]\",\"placeholder\":\"please select failure strategy\",\"optionSourceType\":0,\"dataType\":0,\"inputType\":3,\"isShow\":true,\"canEdit\":true,\"isEmit\":false,\"isValidate\":false,\"valuesMap\":null,\"index\":10,\"createTime\":null,\"updateTime\":null},{\"id\":17,\"field\":\"comparison_name\",\"type\":\"input\",\"title\":\"$t(comparison_name)\",\"data\":null,\"options\":null,\"placeholder\":\"Please enter comparison name, the alias in comparison execute sql\",\"optionSourceType\":0,\"dataType\":0,\"inputType\":0,\"isShow\":false,\"canEdit\":false,\"isEmit\":false,\"isValidate\":true,\"valuesMap\":\"\",\"index\":11,\"createTime\":null,\"updateTime\":null},{\"id\":19,\"field\":\"comparison_type\",\"type\":\"select\",\"title\":\"$t(comparison_type)\",\"data\":\"\",\"options\":null,\"placeholder\":\"Please enter comparison title\",\"optionSourceType\":3,\"dataType\":0,\"inputType\":2,\"isShow\":true,\"canEdit\":false,\"isEmit\":true,\"isValidate\":false,\"valuesMap\":null,\"index\":12,\"createTime\":null,\"updateTime\":null}]",
    "executeSqlList" : "[{\"id\":6,\"index\":1,\"sql\":\"SELECT ${src_field} FROM ${src_table} group by ${src_field} having count(*) > 1\",\"tableAlias\":\"duplicate_items\",\"type\":0,\"createTime\":\"2021-03-03 11:31:24\",\"updateTime\":\"2021-03-03 11:31:24\",\"errorOutputSql\":true},{\"id\":7,\"index\":1,\"sql\":\"SELECT COUNT(*) AS duplicates FROM duplicate_items\",\"tableAlias\":\"duplicate_count\",\"type\":1,\"createTime\":\"2021-03-03 11:31:24\",\"updateTime\":\"2021-03-03 11:31:24\",\"errorOutputSql\":false}]",
    "comparisonNeedStatisticsValueTable" : false,
    "compareWithFixedValue" : true,
    "hdfsPath" : "hdfs://mycluster:8020/user/default/data_quality_error_data",
    "sourceConnectorType" : "JDBC",
    "sourceType" : 1,
    "sourceConnectionParams" : "{\"user\":\"root\",\"password\":\"root\",\"address\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432\",\"database\":\"persistence\",\"jdbcUrl\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432/persistence\",\"driverClassName\":\"org.postgresql.Driver\",\"validationQuery\":\"select version()\",\"other\":{\"password\":\"root\"}}",
    "targetConnectorType" : null,
    "targetType" : 0,
    "targetConnectionParams" : null,
    "writerConnectorType" : "JDBC",
    "writerType" : 1,
    "writerTable" : "t_ds_dq_execute_result",
    "writerConnectionParams" : "{\"user\":\"root\",\"password\":\"root\",\"address\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432\",\"database\":\"dolphinscheduler\",\"jdbcUrl\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432/dolphinscheduler\"}",
    "statisticsValueConnectorType" : "JDBC",
    "statisticsValueType" : 1,
    "statisticsValueTable" : "t_ds_dq_task_statistics_value",
    "statisticsValueWriterConnectionParams" : "{\"user\":\"root\",\"password\":\"root\",\"address\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432\",\"database\":\"dolphinscheduler\",\"jdbcUrl\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432/dolphinscheduler\"}"
  },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-1060][TI-3956] - [INFO] 2024-05-07 10:33:40.218 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-1060][TI-3956] - [INFO] 2024-05-07 10:33:40.224 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-1060][TI-3956] - [INFO] 2024-05-07 10:33:40.225 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-1060][TI-3956] - [INFO] 2024-05-07 10:33:40.231 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-1060][TI-3956] - [INFO] 2024-05-07 10:33:40.231 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-1060][TI-3956] - [INFO] 2024-05-07 10:33:40.232 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13001194483488/13505298546272_21/1060/3956 check successfully
[WI-1060][TI-3956] - [INFO] 2024-05-07 10:33:40.232 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.dq.DataQualityTaskChannel successfully
[WI-1060][TI-3956] - [INFO] 2024-05-07 10:33:40.233 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-1060][TI-3956] - [INFO] 2024-05-07 10:33:40.233 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-1060][TI-3956] - [INFO] 2024-05-07 10:33:40.234 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: DATA_QUALITY create successfully
[WI-1060][TI-3956] - [INFO] 2024-05-07 10:33:40.234 +0800 o.a.d.p.t.d.DataQualityTask:[89] - Initialize data quality task params {
  "localParams" : [ ],
  "varPool" : null,
  "ruleId" : 6,
  "ruleInputParameter" : {
    "check_type" : "0",
    "comparison_type" : "1",
    "comparison_name" : "0",
    "failure_strategy" : "0",
    "operator" : "0",
    "src_connector_type" : "1",
    "src_datasource_id" : "6",
    "src_database" : "persistence",
    "src_field" : "content",
    "src_table" : "filtered_data_persistence",
    "threshold" : "0"
  },
  "sparkParameters" : {
    "localParams" : null,
    "varPool" : null,
    "mainJar" : null,
    "mainClass" : null,
    "deployMode" : "local",
    "mainArgs" : null,
    "driverCores" : 1,
    "driverMemory" : "512M",
    "numExecutors" : 1,
    "executorCores" : 1,
    "executorMemory" : "1G",
    "appName" : null,
    "yarnQueue" : "",
    "others" : "--conf spark.driver.extraJavaOptions=\"-Divy.cache.dir=/tmp -Divy.home=/tmp\" \\\n--packages org.postgresql:postgresql:42.7.3",
    "programType" : null,
    "resourceList" : [ ]
  }
}
[WI-1060][TI-3956] - [INFO] 2024-05-07 10:33:40.244 +0800 o.a.d.p.t.d.DataQualityTask:[119] - data quality configuration: {
  "name" : "$t(uniqueness_check)",
  "env" : {
    "type" : "batch",
    "config" : null
  },
  "readers" : [ {
    "type" : "JDBC",
    "config" : {
      "database" : "persistence",
      "password" : "root",
      "driver" : "org.postgresql.Driver",
      "user" : "root",
      "output_table" : "persistence_filtered_data_persistence",
      "table" : "filtered_data_persistence",
      "url" : "jdbc:postgresql://dolphinscheduler-postgresql:5432/persistence?password=root"
    }
  } ],
  "transformers" : [ {
    "type" : "sql",
    "config" : {
      "index" : 1,
      "output_table" : "duplicate_items",
      "sql" : "SELECT content FROM persistence_filtered_data_persistence group by content having count(*) > 1"
    }
  }, {
    "type" : "sql",
    "config" : {
      "index" : 2,
      "output_table" : "duplicate_count",
      "sql" : "SELECT COUNT(*) AS duplicates FROM duplicate_items"
    }
  } ],
  "writers" : [ {
    "type" : "JDBC",
    "config" : {
      "database" : "dolphinscheduler",
      "password" : "root",
      "driver" : "org.postgresql.Driver",
      "user" : "root",
      "table" : "t_ds_dq_execute_result",
      "url" : "jdbc:postgresql://dolphinscheduler-postgresql:5432/dolphinscheduler",
      "sql" : "select 0 as rule_type,'$t(uniqueness_check)' as rule_name,0 as process_definition_id,1060 as process_instance_id,3956 as task_instance_id,duplicate_count.duplicates AS statistics_value,0 AS comparison_value,1 AS comparison_type,0 as check_type,0 as threshold,0 as operator,0 as failure_strategy,'hdfs://mycluster:8020/user/default/data_quality_error_data/0_1060_[null check] filtered data persistence' as error_output_path,'2024-05-07 10:33:40' as create_time,'2024-05-07 10:33:40' as update_time from duplicate_count "
    }
  }, {
    "type" : "JDBC",
    "config" : {
      "database" : "dolphinscheduler",
      "password" : "root",
      "driver" : "org.postgresql.Driver",
      "user" : "root",
      "table" : "t_ds_dq_task_statistics_value",
      "url" : "jdbc:postgresql://dolphinscheduler-postgresql:5432/dolphinscheduler",
      "sql" : "select 0 as process_definition_id,3956 as task_instance_id,6 as rule_id,'KA0AXXWVHWW+GZX4BPZXFGFZ0F0OYMUQ+BVYG4+ZIKG=' as unique_code,'duplicate_count.duplicates'AS statistics_name,duplicate_count.duplicates AS statistics_value,'2024-05-07 10:33:40' as data_time,'2024-05-07 10:33:40' as create_time,'2024-05-07 10:33:40' as update_time from duplicate_count"
    }
  }, {
    "type" : "hdfs_file",
    "config" : {
      "path" : "hdfs://mycluster:8020/user/default/data_quality_error_data/0_1060_[null check] filtered data persistence",
      "input_table" : "duplicate_items"
    }
  } ]
}
[WI-1060][TI-3956] - [INFO] 2024-05-07 10:33:40.246 +0800 o.a.d.p.d.a.u.CommonUtils:[136] - Trying to get data quality jar in path
[WI-1060][TI-3956] - [INFO] 2024-05-07 10:33:40.246 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-1060][TI-3956] - [INFO] 2024-05-07 10:33:40.246 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: null successfully
[WI-1060][TI-3956] - [INFO] 2024-05-07 10:33:40.247 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-1060][TI-3956] - [INFO] 2024-05-07 10:33:40.247 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-1060][TI-3956] - [INFO] 2024-05-07 10:33:40.247 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-1060][TI-3956] - [INFO] 2024-05-07 10:33:40.248 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-1060][TI-3956] - [INFO] 2024-05-07 10:33:40.248 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-1060][TI-3956] - [INFO] 2024-05-07 10:33:40.248 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export PYSPARK_DRIVER_PYTHON=/bin/python3.11
export PYSPARK_PYTHON=/bin/python3.11
${SPARK_HOME}/bin/spark-submit --master local --driver-cores 1 --driver-memory 512M --num-executors 1 --executor-cores 1 --executor-memory 1G --conf spark.driver.extraJavaOptions="-Divy.cache.dir=/tmp -Divy.home=/tmp" \
--packages org.postgresql:postgresql:42.7.3 /opt/dolphinscheduler/conf/../libs/dolphinscheduler-data-quality-3.2.1.jar "{\"name\":\"$t(uniqueness_check)\",\"env\":{\"type\":\"batch\",\"config\":null},\"readers\":[{\"type\":\"JDBC\",\"config\":{\"database\":\"persistence\",\"password\":\"root\",\"driver\":\"org.postgresql.Driver\",\"user\":\"root\",\"output_table\":\"persistence_filtered_data_persistence\",\"table\":\"filtered_data_persistence\",\"url\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432/persistence?password=root\"} }],\"transformers\":[{\"type\":\"sql\",\"config\":{\"index\":1,\"output_table\":\"duplicate_items\",\"sql\":\"SELECT content FROM persistence_filtered_data_persistence group by content having count(*) > 1\"} },{\"type\":\"sql\",\"config\":{\"index\":2,\"output_table\":\"duplicate_count\",\"sql\":\"SELECT COUNT(*) AS duplicates FROM duplicate_items\"} }],\"writers\":[{\"type\":\"JDBC\",\"config\":{\"database\":\"dolphinscheduler\",\"password\":\"root\",\"driver\":\"org.postgresql.Driver\",\"user\":\"root\",\"table\":\"t_ds_dq_execute_result\",\"url\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432/dolphinscheduler\",\"sql\":\"select 0 as rule_type,'$t(uniqueness_check)' as rule_name,0 as process_definition_id,1060 as process_instance_id,3956 as task_instance_id,duplicate_count.duplicates AS statistics_value,0 AS comparison_value,1 AS comparison_type,0 as check_type,0 as threshold,0 as operator,0 as failure_strategy,'hdfs://mycluster:8020/user/default/data_quality_error_data/0_1060_[null check] filtered data persistence' as error_output_path,'2024-05-07 10:33:40' as create_time,'2024-05-07 10:33:40' as update_time from duplicate_count \"} },{\"type\":\"JDBC\",\"config\":{\"database\":\"dolphinscheduler\",\"password\":\"root\",\"driver\":\"org.postgresql.Driver\",\"user\":\"root\",\"table\":\"t_ds_dq_task_statistics_value\",\"url\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432/dolphinscheduler\",\"sql\":\"select 0 as process_definition_id,3956 as task_instance_id,6 as rule_id,'KA0AXXWVHWW+GZX4BPZXFGFZ0F0OYMUQ+BVYG4+ZIKG=' as unique_code,'duplicate_count.duplicates'AS statistics_name,duplicate_count.duplicates AS statistics_value,'2024-05-07 10:33:40' as data_time,'2024-05-07 10:33:40' as create_time,'2024-05-07 10:33:40' as update_time from duplicate_count\"} },{\"type\":\"hdfs_file\",\"config\":{\"path\":\"hdfs://mycluster:8020/user/default/data_quality_error_data/0_1060_[null check] filtered data persistence\",\"input_table\":\"duplicate_items\"} }]}"
[WI-1060][TI-3956] - [INFO] 2024-05-07 10:33:40.249 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-1060][TI-3956] - [INFO] 2024-05-07 10:33:40.249 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13001194483488/13505298546272_21/1060/3956/1060_3956.sh
[WI-1060][TI-3956] - [INFO] 2024-05-07 10:33:40.256 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 265
[WI-0][TI-3956] - [INFO] 2024-05-07 10:33:41.051 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=3956, success=true)
[WI-0][TI-0] - [INFO] 2024-05-07 10:33:41.078 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8065395095367848 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-3956] - [INFO] 2024-05-07 10:33:41.093 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=3956)
[WI-0][TI-0] - [INFO] 2024-05-07 10:33:41.260 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
[WI-0][TI-0] - [INFO] 2024-05-07 10:33:43.272 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	:: loading settings :: url = jar:file:/opt/spark-3.5.1-bin-hadoop3/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml
	Ivy Default Cache set to: /tmp
	The jars for the packages stored in: /tmp/jars
	org.postgresql#postgresql added as a dependency
	:: resolving dependencies :: org.apache.spark#spark-submit-parent-b4ed4fd9-379b-4041-ac50-39071c9c33a1;1.0
		confs: [default]
		found org.postgresql#postgresql;42.7.3 in central
		found org.checkerframework#checker-qual;3.42.0 in central
	:: resolution report :: resolve 121ms :: artifacts dl 20ms
		:: modules in use:
		org.checkerframework#checker-qual;3.42.0 from central in [default]
		org.postgresql#postgresql;42.7.3 from central in [default]
		---------------------------------------------------------------------
		|                  |            modules            ||   artifacts   |
		|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
		---------------------------------------------------------------------
		|      default     |   2   |   0   |   0   |   0   ||   2   |   0   |
		---------------------------------------------------------------------
	:: retrieving :: org.apache.spark#spark-submit-parent-b4ed4fd9-379b-4041-ac50-39071c9c33a1
		confs: [default]
		0 artifacts copied, 2 already retrieved (0kB/15ms)
	24/05/07 10:33:42 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[WI-0][TI-0] - [INFO] 2024-05-07 10:33:44.139 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8982035928143712 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:33:44.274 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:33:43 INFO SparkContext: Running Spark version 3.5.1
	24/05/07 10:33:43 INFO SparkContext: OS info Linux, 6.5.0-28-generic, amd64
	24/05/07 10:33:43 INFO SparkContext: Java version 1.8.0_402
	24/05/07 10:33:43 INFO ResourceUtils: ==============================================================
	24/05/07 10:33:43 INFO ResourceUtils: No custom resources configured for spark.driver.
	24/05/07 10:33:43 INFO ResourceUtils: ==============================================================
	24/05/07 10:33:43 INFO SparkContext: Submitted application: (uniqueness_check)
	24/05/07 10:33:43 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
	24/05/07 10:33:43 INFO ResourceProfile: Limiting resource is cpu
	24/05/07 10:33:43 INFO ResourceProfileManager: Added ResourceProfile id: 0
	24/05/07 10:33:43 INFO SecurityManager: Changing view acls to: default
	24/05/07 10:33:43 INFO SecurityManager: Changing modify acls to: default
	24/05/07 10:33:43 INFO SecurityManager: Changing view acls groups to: 
	24/05/07 10:33:43 INFO SecurityManager: Changing modify acls groups to: 
	24/05/07 10:33:43 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: default; groups with view permissions: EMPTY; users with modify permissions: default; groups with modify permissions: EMPTY
[WI-0][TI-0] - [INFO] 2024-05-07 10:33:45.175 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8961038961038961 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:33:45.275 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:33:44 INFO Utils: Successfully started service 'sparkDriver' on port 38209.
	24/05/07 10:33:44 INFO SparkEnv: Registering MapOutputTracker
	24/05/07 10:33:44 INFO SparkEnv: Registering BlockManagerMaster
	24/05/07 10:33:44 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
	24/05/07 10:33:44 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
	24/05/07 10:33:44 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
	24/05/07 10:33:44 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-ba70e33a-4f31-4bf5-ad5f-93b614a8cdfc
	24/05/07 10:33:44 INFO MemoryStore: MemoryStore started with capacity 93.3 MiB
	24/05/07 10:33:44 INFO SparkEnv: Registering OutputCommitCoordinator
	24/05/07 10:33:44 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
	24/05/07 10:33:45 INFO Utils: Successfully started service 'SparkUI' on port 4040.
	24/05/07 10:33:45 INFO SparkContext: Added JAR file:///tmp/jars/org.postgresql_postgresql-42.7.3.jar at spark://b2617105c628:38209/jars/org.postgresql_postgresql-42.7.3.jar with timestamp 1715049223601
	24/05/07 10:33:45 INFO SparkContext: Added JAR file:///tmp/jars/org.checkerframework_checker-qual-3.42.0.jar at spark://b2617105c628:38209/jars/org.checkerframework_checker-qual-3.42.0.jar with timestamp 1715049223601
	24/05/07 10:33:45 INFO SparkContext: Added JAR file:/opt/dolphinscheduler/libs/dolphinscheduler-data-quality-3.2.1.jar at spark://b2617105c628:38209/jars/dolphinscheduler-data-quality-3.2.1.jar with timestamp 1715049223601
	24/05/07 10:33:45 INFO Executor: Starting executor ID driver on host b2617105c628
	24/05/07 10:33:45 INFO Executor: OS info Linux, 6.5.0-28-generic, amd64
	24/05/07 10:33:45 INFO Executor: Java version 1.8.0_402
	24/05/07 10:33:45 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
	24/05/07 10:33:45 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@698fee9a for default.
[WI-0][TI-0] - [INFO] 2024-05-07 10:33:46.178 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9323943661971832 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:33:46.281 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:33:45 INFO Executor: Fetching spark://b2617105c628:38209/jars/dolphinscheduler-data-quality-3.2.1.jar with timestamp 1715049223601
	24/05/07 10:33:45 INFO TransportClientFactory: Successfully created connection to b2617105c628/172.18.1.1:38209 after 97 ms (0 ms spent in bootstraps)
	24/05/07 10:33:45 INFO Utils: Fetching spark://b2617105c628:38209/jars/dolphinscheduler-data-quality-3.2.1.jar to /tmp/spark-36a10755-857a-4e6b-a97e-7dfcdd7492f5/userFiles-2e74390d-e611-437f-997b-e939a0221d46/fetchFileTemp1772252173042196596.tmp
	24/05/07 10:33:45 INFO Executor: Adding file:/tmp/spark-36a10755-857a-4e6b-a97e-7dfcdd7492f5/userFiles-2e74390d-e611-437f-997b-e939a0221d46/dolphinscheduler-data-quality-3.2.1.jar to class loader default
	24/05/07 10:33:45 INFO Executor: Fetching spark://b2617105c628:38209/jars/org.postgresql_postgresql-42.7.3.jar with timestamp 1715049223601
	24/05/07 10:33:45 INFO Utils: Fetching spark://b2617105c628:38209/jars/org.postgresql_postgresql-42.7.3.jar to /tmp/spark-36a10755-857a-4e6b-a97e-7dfcdd7492f5/userFiles-2e74390d-e611-437f-997b-e939a0221d46/fetchFileTemp6315770192253306821.tmp
	24/05/07 10:33:45 INFO Executor: Adding file:/tmp/spark-36a10755-857a-4e6b-a97e-7dfcdd7492f5/userFiles-2e74390d-e611-437f-997b-e939a0221d46/org.postgresql_postgresql-42.7.3.jar to class loader default
	24/05/07 10:33:45 INFO Executor: Fetching spark://b2617105c628:38209/jars/org.checkerframework_checker-qual-3.42.0.jar with timestamp 1715049223601
	24/05/07 10:33:45 INFO Utils: Fetching spark://b2617105c628:38209/jars/org.checkerframework_checker-qual-3.42.0.jar to /tmp/spark-36a10755-857a-4e6b-a97e-7dfcdd7492f5/userFiles-2e74390d-e611-437f-997b-e939a0221d46/fetchFileTemp6987180291264576299.tmp
	24/05/07 10:33:45 INFO Executor: Adding file:/tmp/spark-36a10755-857a-4e6b-a97e-7dfcdd7492f5/userFiles-2e74390d-e611-437f-997b-e939a0221d46/org.checkerframework_checker-qual-3.42.0.jar to class loader default
	24/05/07 10:33:45 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39665.
	24/05/07 10:33:45 INFO NettyBlockTransferService: Server created on b2617105c628:39665
	24/05/07 10:33:45 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
	24/05/07 10:33:45 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, b2617105c628, 39665, None)
	24/05/07 10:33:45 INFO BlockManagerMasterEndpoint: Registering block manager b2617105c628:39665 with 93.3 MiB RAM, BlockManagerId(driver, b2617105c628, 39665, None)
	24/05/07 10:33:45 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, b2617105c628, 39665, None)
	24/05/07 10:33:45 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, b2617105c628, 39665, None)
[WI-0][TI-0] - [INFO] 2024-05-07 10:33:47.180 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8959537572254336 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:33:47.285 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:33:46 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
	24/05/07 10:33:46 INFO SharedState: Warehouse path is 'file:/tmp/dolphinscheduler/exec/process/default/13001194483488/13505298546272_21/1060/3956/spark-warehouse'.
[WI-0][TI-0] - [INFO] 2024-05-07 10:33:48.187 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7961165048543689 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:33:49.200 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8617021276595744 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:33:50.226 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.83 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:33:51.247 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7836879432624113 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:33:52.266 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8392857142857143 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:33:53.316 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:33:52 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
[WI-0][TI-0] - [INFO] 2024-05-07 10:33:54.298 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.724770642201835 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:33:54.319 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:33:53 INFO CodeGenerator: Code generated in 528.082889 ms
	24/05/07 10:33:54 INFO DAGScheduler: Registering RDD 2 (save at JdbcWriter.java:87) as input to shuffle 0
	24/05/07 10:33:54 INFO DAGScheduler: Got map stage job 0 (save at JdbcWriter.java:87) with 1 output partitions
	24/05/07 10:33:54 INFO DAGScheduler: Final stage: ShuffleMapStage 0 (save at JdbcWriter.java:87)
	24/05/07 10:33:54 INFO DAGScheduler: Parents of final stage: List()
	24/05/07 10:33:54 INFO DAGScheduler: Missing parents: List()
	24/05/07 10:33:54 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[2] at save at JdbcWriter.java:87), which has no missing parents
	24/05/07 10:33:54 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 34.8 KiB, free 93.3 MiB)
[WI-0][TI-0] - [INFO] 2024-05-07 10:33:55.323 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:33:54 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 16.4 KiB, free 93.3 MiB)
	24/05/07 10:33:54 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on b2617105c628:39665 (size: 16.4 KiB, free: 93.3 MiB)
	24/05/07 10:33:54 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1585
	24/05/07 10:33:54 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[2] at save at JdbcWriter.java:87) (first 15 tasks are for partitions Vector(0))
	24/05/07 10:33:54 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
	24/05/07 10:33:54 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (b2617105c628, executor driver, partition 0, PROCESS_LOCAL, 7878 bytes) 
	24/05/07 10:33:54 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
	24/05/07 10:33:55 INFO CodeGenerator: Code generated in 84.770723 ms
	24/05/07 10:33:55 INFO CodeGenerator: Code generated in 26.288598 ms
	24/05/07 10:33:55 INFO CodeGenerator: Code generated in 16.535111 ms
	24/05/07 10:33:55 INFO CodeGenerator: Code generated in 30.933279 ms
[WI-0][TI-0] - [INFO] 2024-05-07 10:33:55.349 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8545994065281899 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:33:56.336 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:33:55 INFO CodeGenerator: Code generated in 58.290763 ms
	24/05/07 10:33:55 INFO JDBCRDD: closed connection
	24/05/07 10:33:55 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 2534 bytes result sent to driver
	24/05/07 10:33:55 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1070 ms on b2617105c628 (executor driver) (1/1)
	24/05/07 10:33:55 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
	24/05/07 10:33:55 INFO DAGScheduler: ShuffleMapStage 0 (save at JdbcWriter.java:87) finished in 1.504 s
	24/05/07 10:33:55 INFO DAGScheduler: looking for newly runnable stages
	24/05/07 10:33:55 INFO DAGScheduler: running: Set()
	24/05/07 10:33:55 INFO DAGScheduler: waiting: Set()
	24/05/07 10:33:55 INFO DAGScheduler: failed: Set()
	24/05/07 10:33:55 INFO ShufflePartitionsUtil: For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
	24/05/07 10:33:55 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
	24/05/07 10:33:56 INFO CodeGenerator: Code generated in 57.085644 ms
	24/05/07 10:33:56 INFO DAGScheduler: Registering RDD 5 (save at JdbcWriter.java:87) as input to shuffle 1
	24/05/07 10:33:56 INFO DAGScheduler: Got map stage job 1 (save at JdbcWriter.java:87) with 1 output partitions
	24/05/07 10:33:56 INFO DAGScheduler: Final stage: ShuffleMapStage 2 (save at JdbcWriter.java:87)
	24/05/07 10:33:56 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
	24/05/07 10:33:56 INFO DAGScheduler: Missing parents: List()
	24/05/07 10:33:56 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[5] at save at JdbcWriter.java:87), which has no missing parents
	24/05/07 10:33:56 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 40.5 KiB, free 93.2 MiB)
	24/05/07 10:33:56 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 19.1 KiB, free 93.2 MiB)
	24/05/07 10:33:56 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on b2617105c628:39665 (size: 19.1 KiB, free: 93.3 MiB)
	24/05/07 10:33:56 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1585
	24/05/07 10:33:56 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[5] at save at JdbcWriter.java:87) (first 15 tasks are for partitions Vector(0))
	24/05/07 10:33:56 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
	24/05/07 10:33:56 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 1) (b2617105c628, executor driver, partition 0, NODE_LOCAL, 8032 bytes) 
	24/05/07 10:33:56 INFO Executor: Running task 0.0 in stage 2.0 (TID 1)
	24/05/07 10:33:56 INFO ShuffleBlockFetcherIterator: Getting 1 (2.9 KiB) non-empty blocks including 1 (2.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
	24/05/07 10:33:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 41 ms
	24/05/07 10:33:56 INFO CodeGenerator: Code generated in 70.463181 ms
[WI-0][TI-0] - [INFO] 2024-05-07 10:33:56.352 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9039548022598871 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:33:57.340 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:33:56 INFO Executor: Finished task 0.0 in stage 2.0 (TID 1). 5420 bytes result sent to driver
	24/05/07 10:33:56 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 1) in 229 ms on b2617105c628 (executor driver) (1/1)
	24/05/07 10:33:56 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
	24/05/07 10:33:56 INFO DAGScheduler: ShuffleMapStage 2 (save at JdbcWriter.java:87) finished in 0.268 s
	24/05/07 10:33:56 INFO DAGScheduler: looking for newly runnable stages
	24/05/07 10:33:56 INFO DAGScheduler: running: Set()
	24/05/07 10:33:56 INFO DAGScheduler: waiting: Set()
	24/05/07 10:33:56 INFO DAGScheduler: failed: Set()
	24/05/07 10:33:56 INFO CodeGenerator: Code generated in 31.939173 ms
	24/05/07 10:33:56 INFO SparkContext: Starting job: save at JdbcWriter.java:87
	24/05/07 10:33:56 INFO DAGScheduler: Got job 2 (save at JdbcWriter.java:87) with 1 output partitions
	24/05/07 10:33:56 INFO DAGScheduler: Final stage: ResultStage 5 (save at JdbcWriter.java:87)
	24/05/07 10:33:56 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
	24/05/07 10:33:56 INFO DAGScheduler: Missing parents: List()
	24/05/07 10:33:56 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[10] at save at JdbcWriter.java:87), which has no missing parents
	24/05/07 10:33:57 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 51.4 KiB, free 93.1 MiB)
	24/05/07 10:33:57 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 23.0 KiB, free 93.1 MiB)
	24/05/07 10:33:57 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on b2617105c628:39665 (size: 23.0 KiB, free: 93.2 MiB)
	24/05/07 10:33:57 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1585
	24/05/07 10:33:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[10] at save at JdbcWriter.java:87) (first 15 tasks are for partitions Vector(0))
	24/05/07 10:33:57 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
	24/05/07 10:33:57 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 2) (b2617105c628, executor driver, partition 0, NODE_LOCAL, 8043 bytes) 
	24/05/07 10:33:57 INFO Executor: Running task 0.0 in stage 5.0 (TID 2)
[WI-0][TI-0] - [INFO] 2024-05-07 10:33:57.363 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9502762430939227 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:33:58.341 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:33:57 INFO BlockManagerInfo: Removed broadcast_0_piece0 on b2617105c628:39665 in memory (size: 16.4 KiB, free: 93.3 MiB)
	24/05/07 10:33:57 INFO BlockManagerInfo: Removed broadcast_1_piece0 on b2617105c628:39665 in memory (size: 19.1 KiB, free: 93.3 MiB)
	24/05/07 10:33:57 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
	24/05/07 10:33:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
	24/05/07 10:33:57 INFO CodeGenerator: Code generated in 12.134104 ms
[WI-0][TI-0] - [INFO] 2024-05-07 10:33:58.365 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8760806916426513 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:33:59.366 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.837748344370861 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:34:00.344 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:34:00 INFO CodeGenerator: Code generated in 53.420749 ms
	24/05/07 10:34:00 INFO Executor: Finished task 0.0 in stage 5.0 (TID 2). 6711 bytes result sent to driver
	24/05/07 10:34:00 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 2) in 3168 ms on b2617105c628 (executor driver) (1/1)
	24/05/07 10:34:00 INFO DAGScheduler: ResultStage 5 (save at JdbcWriter.java:87) finished in 3.477 s
	24/05/07 10:34:00 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
	24/05/07 10:34:00 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
	24/05/07 10:34:00 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
	24/05/07 10:34:00 INFO DAGScheduler: Job 2 finished: save at JdbcWriter.java:87, took 3.572096 s
[WI-0][TI-0] - [INFO] 2024-05-07 10:34:00.369 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9411764705882353 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:34:01.346 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:34:00 INFO DAGScheduler: Registering RDD 13 (save at JdbcWriter.java:87) as input to shuffle 2
	24/05/07 10:34:00 INFO DAGScheduler: Got map stage job 3 (save at JdbcWriter.java:87) with 1 output partitions
	24/05/07 10:34:00 INFO DAGScheduler: Final stage: ShuffleMapStage 6 (save at JdbcWriter.java:87)
	24/05/07 10:34:00 INFO DAGScheduler: Parents of final stage: List()
	24/05/07 10:34:00 INFO DAGScheduler: Missing parents: List()
	24/05/07 10:34:00 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[13] at save at JdbcWriter.java:87), which has no missing parents
	24/05/07 10:34:00 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 34.8 KiB, free 93.2 MiB)
	24/05/07 10:34:00 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 16.5 KiB, free 93.2 MiB)
	24/05/07 10:34:00 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on b2617105c628:39665 (size: 16.5 KiB, free: 93.3 MiB)
	24/05/07 10:34:00 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1585
	24/05/07 10:34:00 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[13] at save at JdbcWriter.java:87) (first 15 tasks are for partitions Vector(0))
	24/05/07 10:34:00 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0
	24/05/07 10:34:00 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 3) (b2617105c628, executor driver, partition 0, PROCESS_LOCAL, 7878 bytes) 
	24/05/07 10:34:00 INFO Executor: Running task 0.0 in stage 6.0 (TID 3)
	24/05/07 10:34:00 INFO JDBCRDD: closed connection
	24/05/07 10:34:00 INFO Executor: Finished task 0.0 in stage 6.0 (TID 3). 2448 bytes result sent to driver
	24/05/07 10:34:00 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 3) in 188 ms on b2617105c628 (executor driver) (1/1)
	24/05/07 10:34:00 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
	24/05/07 10:34:00 INFO DAGScheduler: ShuffleMapStage 6 (save at JdbcWriter.java:87) finished in 0.211 s
	24/05/07 10:34:00 INFO DAGScheduler: looking for newly runnable stages
	24/05/07 10:34:00 INFO DAGScheduler: running: Set()
	24/05/07 10:34:00 INFO DAGScheduler: waiting: Set()
	24/05/07 10:34:00 INFO DAGScheduler: failed: Set()
	24/05/07 10:34:00 INFO ShufflePartitionsUtil: For shuffle(2), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
	24/05/07 10:34:01 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
	24/05/07 10:34:01 INFO DAGScheduler: Registering RDD 16 (save at JdbcWriter.java:87) as input to shuffle 3
	24/05/07 10:34:01 INFO DAGScheduler: Got map stage job 4 (save at JdbcWriter.java:87) with 1 output partitions
	24/05/07 10:34:01 INFO DAGScheduler: Final stage: ShuffleMapStage 8 (save at JdbcWriter.java:87)
	24/05/07 10:34:01 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
	24/05/07 10:34:01 INFO DAGScheduler: Missing parents: List()
	24/05/07 10:34:01 INFO DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[16] at save at JdbcWriter.java:87), which has no missing parents
	24/05/07 10:34:01 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 40.6 KiB, free 93.1 MiB)
	24/05/07 10:34:01 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 19.1 KiB, free 93.1 MiB)
	24/05/07 10:34:01 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on b2617105c628:39665 (size: 19.1 KiB, free: 93.2 MiB)
	24/05/07 10:34:01 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1585
	24/05/07 10:34:01 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[16] at save at JdbcWriter.java:87) (first 15 tasks are for partitions Vector(0))
	24/05/07 10:34:01 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0
	24/05/07 10:34:01 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 4) (b2617105c628, executor driver, partition 0, NODE_LOCAL, 8032 bytes) 
	24/05/07 10:34:01 INFO Executor: Running task 0.0 in stage 8.0 (TID 4)
	24/05/07 10:34:01 INFO ShuffleBlockFetcherIterator: Getting 1 (2.9 KiB) non-empty blocks including 1 (2.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
	24/05/07 10:34:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
	24/05/07 10:34:01 INFO Executor: Finished task 0.0 in stage 8.0 (TID 4). 5420 bytes result sent to driver
	24/05/07 10:34:01 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 4) in 47 ms on b2617105c628 (executor driver) (1/1)
	24/05/07 10:34:01 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
	24/05/07 10:34:01 INFO DAGScheduler: ShuffleMapStage 8 (save at JdbcWriter.java:87) finished in 0.077 s
	24/05/07 10:34:01 INFO DAGScheduler: looking for newly runnable stages
	24/05/07 10:34:01 INFO DAGScheduler: running: Set()
	24/05/07 10:34:01 INFO DAGScheduler: waiting: Set()
	24/05/07 10:34:01 INFO DAGScheduler: failed: Set()
	24/05/07 10:34:01 INFO CodeGenerator: Code generated in 11.677728 ms
	24/05/07 10:34:01 INFO SparkContext: Starting job: save at JdbcWriter.java:87
	24/05/07 10:34:01 INFO DAGScheduler: Got job 5 (save at JdbcWriter.java:87) with 1 output partitions
	24/05/07 10:34:01 INFO DAGScheduler: Final stage: ResultStage 11 (save at JdbcWriter.java:87)
	24/05/07 10:34:01 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)
	24/05/07 10:34:01 INFO DAGScheduler: Missing parents: List()
	24/05/07 10:34:01 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[21] at save at JdbcWriter.java:87), which has no missing parents
	24/05/07 10:34:01 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 49.2 KiB, free 93.1 MiB)
	24/05/07 10:34:01 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 22.7 KiB, free 93.0 MiB)
	24/05/07 10:34:01 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on b2617105c628:39665 (size: 22.7 KiB, free: 93.2 MiB)
	24/05/07 10:34:01 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1585
	24/05/07 10:34:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[21] at save at JdbcWriter.java:87) (first 15 tasks are for partitions Vector(0))
	24/05/07 10:34:01 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks resource profile 0
	24/05/07 10:34:01 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 5) (b2617105c628, executor driver, partition 0, NODE_LOCAL, 8043 bytes) 
	24/05/07 10:34:01 INFO Executor: Running task 0.0 in stage 11.0 (TID 5)
[WI-0][TI-0] - [INFO] 2024-05-07 10:34:01.375 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8583489380771755 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:34:02.350 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:34:01 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
	24/05/07 10:34:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
	24/05/07 10:34:01 INFO CodeGenerator: Code generated in 64.979428 ms
	24/05/07 10:34:01 INFO CodeGenerator: Code generated in 44.832028 ms
	24/05/07 10:34:01 INFO Executor: Finished task 0.0 in stage 11.0 (TID 5). 6625 bytes result sent to driver
	24/05/07 10:34:01 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 5) in 292 ms on b2617105c628 (executor driver) (1/1)
	24/05/07 10:34:01 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
	24/05/07 10:34:01 INFO DAGScheduler: ResultStage 11 (save at JdbcWriter.java:87) finished in 0.372 s
	24/05/07 10:34:01 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
	24/05/07 10:34:01 INFO TaskSchedulerImpl: Killing all running tasks in stage 11: Stage finished
	24/05/07 10:34:01 INFO DAGScheduler: Job 5 finished: save at JdbcWriter.java:87, took 0.391286 s
	24/05/07 10:34:01 WARN FileSystem: Failed to initialize fileystem hdfs://mycluster:8020/user/default/data_quality_error_data/0_1060_%5Bnull%20check%5D%20filtered%20data%20persistence: java.lang.IllegalArgumentException: java.net.UnknownHostException: mycluster
	Exception in thread "main" java.lang.IllegalArgumentException: java.net.UnknownHostException: mycluster
		at org.apache.hadoop.security.SecurityUtil.buildTokenService(SecurityUtil.java:466)
		at org.apache.hadoop.hdfs.NameNodeProxiesClient.createProxyWithClientProtocol(NameNodeProxiesClient.java:134)
		at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:374)
		at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:308)
		at org.apache.hadoop.hdfs.DistributedFileSystem.initDFSClient(DistributedFileSystem.java:202)
		at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:187)
		at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469)
		at org.apache.hadoop.fs.FileSystem.access$300(FileSystem.java:174)
		at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3574)
		at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3521)
		at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540)
		at org.apache.hadoop.fs.Path.getFileSystem(Path.java:365)
		at org.apache.spark.sql.execution.datasources.DataSource.planForWritingFileFormat(DataSource.scala:454)
		at org.apache.spark.sql.execution.datasources.DataSource.planForWriting(DataSource.scala:530)
		at org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)
		at org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)
		at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:240)
		at org.apache.spark.sql.DataFrameWriter.csv(DataFrameWriter.scala:850)
		at org.apache.dolphinscheduler.data.quality.flow.batch.writer.file.BaseFileWriter.outputImpl(BaseFileWriter.java:114)
		at org.apache.dolphinscheduler.data.quality.flow.batch.writer.file.HdfsFileWriter.write(HdfsFileWriter.java:40)
		at org.apache.dolphinscheduler.data.quality.execution.SparkBatchExecution.executeWriter(SparkBatchExecution.java:132)
		at org.apache.dolphinscheduler.data.quality.execution.SparkBatchExecution.execute(SparkBatchExecution.java:58)
		at org.apache.dolphinscheduler.data.quality.context.DataQualityContext.execute(DataQualityContext.java:62)
		at org.apache.dolphinscheduler.data.quality.DataQualityApplication.main(DataQualityApplication.java:78)
		at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
		at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
		at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
		at java.lang.reflect.Method.invoke(Method.java:498)
		at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
		at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:1029)
		at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:194)
		at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:217)
		at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:91)
		at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1120)
		at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1129)
		at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
	Caused by: java.net.UnknownHostException: mycluster
		... 36 more
	24/05/07 10:34:01 INFO SparkContext: Invoking stop() from shutdown hook
	24/05/07 10:34:01 INFO SparkContext: SparkContext is stopping with exitCode 0.
	24/05/07 10:34:01 INFO SparkUI: Stopped Spark web UI at http://b2617105c628:4040
	24/05/07 10:34:02 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
	24/05/07 10:34:02 INFO MemoryStore: MemoryStore cleared
	24/05/07 10:34:02 INFO BlockManager: BlockManager stopped
	24/05/07 10:34:02 INFO BlockManagerMaster: BlockManagerMaster stopped
	24/05/07 10:34:02 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
[WI-0][TI-0] - [INFO] 2024-05-07 10:34:02.400 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9091061290960839 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:34:03.358 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:34:02 INFO SparkContext: Successfully stopped SparkContext
	24/05/07 10:34:02 INFO ShutdownHookManager: Shutdown hook called
	24/05/07 10:34:02 INFO ShutdownHookManager: Deleting directory /tmp/spark-ae3e818f-b8a5-4f50-8fc3-02a51c775a77
	24/05/07 10:34:02 INFO ShutdownHookManager: Deleting directory /tmp/spark-36a10755-857a-4e6b-a97e-7dfcdd7492f5
[WI-1060][TI-3956] - [INFO] 2024-05-07 10:34:03.360 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13001194483488/13505298546272_21/1060/3956, processId:265 ,exitStatusCode:1 ,processWaitForStatus:true ,processExitValue:1
[WI-1060][TI-3956] - [INFO] 2024-05-07 10:34:03.360 +0800 o.a.d.p.t.a.u.LogUtils:[79] - Start finding appId in /opt/dolphinscheduler/logs/20240507/13505298546272/21/1060/3956.log, fetch way: log 
[WI-1060][TI-3956] - [INFO] 2024-05-07 10:34:03.366 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-1060][TI-3956] - [INFO] 2024-05-07 10:34:03.366 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-1060][TI-3956] - [INFO] 2024-05-07 10:34:03.366 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-1060][TI-3956] - [INFO] 2024-05-07 10:34:03.367 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-1060][TI-3956] - [INFO] 2024-05-07 10:34:03.390 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: FAILURE to master : 172.18.1.1:1234
[WI-1060][TI-3956] - [INFO] 2024-05-07 10:34:03.391 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-1060][TI-3956] - [INFO] 2024-05-07 10:34:03.391 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13001194483488/13505298546272_21/1060/3956
[WI-1060][TI-3956] - [INFO] 2024-05-07 10:34:03.392 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13001194483488/13505298546272_21/1060/3956
[WI-1060][TI-3956] - [INFO] 2024-05-07 10:34:03.392 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-0] - [INFO] 2024-05-07 10:34:07.423 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7122507122507122 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [WARN] 2024-05-07 10:34:09.741 +0800 o.a.d.e.b.s.JdkDynamicServerHandler:[147] - [id: 0x13abdb7d, L:/172.18.1.1:1234 - R:/172.18.0.14:57804] is not writable, over high water level : 65536
[WI-0][TI-0] - [WARN] 2024-05-07 10:34:09.761 +0800 o.a.d.e.b.s.JdkDynamicServerHandler:[154] - [id: 0x13abdb7d, L:/172.18.1.1:1234 - R:/172.18.0.14:57804] is writable, to low water : 32768
[WI-0][TI-0] - [INFO] 2024-05-07 10:35:29.763 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8236914600550965 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:35:30.791 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8194070080862534 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-3955] - [INFO] 2024-05-07 10:35:37.487 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=3955, processInstanceId=1059, status=6, startTime=1715049051676, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.15:5678, logPath=/opt/dolphinscheduler/logs/20240507/13505298546272/21/1059/3955.log, executePath=/tmp/dolphinscheduler/exec/process/default/13001194483488/13505298546272_21/1059/3955, endTime=1715049070330, processId=85, appIds=, varPool=[], eventCreateTime=0, eventSendTime=0)
[WI-0][TI-3955] - [INFO] 2024-05-07 10:35:37.498 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=3955, processInstanceId=1059, status=6, startTime=1715049051676, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.15:5678, logPath=/opt/dolphinscheduler/logs/20240507/13505298546272/21/1059/3955.log, executePath=/tmp/dolphinscheduler/exec/process/default/13001194483488/13505298546272_21/1059/3955, endTime=1715049070330, processId=85, appIds=, varPool=[], eventCreateTime=0, eventSendTime=1715049337487)
[WI-0][TI-3956] - [INFO] 2024-05-07 10:35:37.501 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=3956, processInstanceId=1060, status=6, startTime=1715049220207, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.15:5678, logPath=/opt/dolphinscheduler/logs/20240507/13505298546272/21/1060/3956.log, executePath=/tmp/dolphinscheduler/exec/process/default/13001194483488/13505298546272_21/1060/3956, endTime=1715049243367, processId=265, appIds=, varPool=[], eventCreateTime=0, eventSendTime=0)
[WI-0][TI-3956] - [INFO] 2024-05-07 10:35:37.505 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=3956, processInstanceId=1060, status=6, startTime=1715049220207, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.15:5678, logPath=/opt/dolphinscheduler/logs/20240507/13505298546272/21/1060/3956.log, executePath=/tmp/dolphinscheduler/exec/process/default/13001194483488/13505298546272_21/1060/3956, endTime=1715049243367, processId=265, appIds=, varPool=[], eventCreateTime=0, eventSendTime=1715049337487)
[WI-0][TI-0] - [WARN] 2024-05-07 10:38:57.079 +0800 o.s.c.k.c.p.AbstractKubernetesProfileEnvironmentPostProcessor:[258] - Not running inside kubernetes. Skipping 'kubernetes' profile activation.
[WI-0][TI-0] - [WARN] 2024-05-07 10:39:02.450 +0800 o.s.c.k.c.p.AbstractKubernetesProfileEnvironmentPostProcessor:[258] - Not running inside kubernetes. Skipping 'kubernetes' profile activation.
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:02.497 +0800 o.a.d.s.w.WorkerServer:[634] - No active profile set, falling back to 1 default profile: "default"
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:13.761 +0800 o.s.c.c.s.GenericScope:[283] - BeanFactory id=7e7bf7c6-2cb3-34d2-a0d5-a56161c67d0e
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:15.183 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'org.springframework.cloud.commons.config.CommonsConfigAutoConfiguration' of type [org.springframework.cloud.commons.config.CommonsConfigAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:15.268 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'org.springframework.cloud.client.loadbalancer.LoadBalancerDefaultMappingsProviderAutoConfiguration' of type [org.springframework.cloud.client.loadbalancer.LoadBalancerDefaultMappingsProviderAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:15.270 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'loadBalancerClientsDefaultsMappingsProvider' of type [org.springframework.cloud.client.loadbalancer.LoadBalancerDefaultMappingsProviderAutoConfiguration$$Lambda$392/302905744] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:15.295 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'defaultsBindHandlerAdvisor' of type [org.springframework.cloud.commons.config.DefaultsBindHandlerAdvisor] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:15.622 +0800 o.a.d.c.u.NetUtils:[312] - Get all NetworkInterfaces: [name:eth0 (eth0), name:lo (lo)]
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:15.716 +0800 o.a.d.s.w.c.WorkerConfig:[98] - 
****************************Worker Configuration**************************************
  listen-port -> 1234
  exec-threads -> 100
  max-heartbeat-interval -> PT10S
  host-weight -> 100
  tenantConfig -> TenantConfig(autoCreateTenantEnabled=true, distributedTenantEnabled=false, defaultTenantEnabled=false)
  server-load-protection -> WorkerServerLoadProtection(enabled=true, maxCpuUsagePercentageThresholds=0.7, maxJVMMemoryUsagePercentageThresholds=0.7, maxSystemMemoryUsagePercentageThresholds=0.7, maxDiskUsagePercentageThresholds=0.7)
  registry-disconnect-strategy -> ConnectStrategyProperties(strategy=WAITING, maxWaitingTime=PT1M40S)
  task-execute-threads-full-policy: REJECT
  address -> 172.18.1.1:1234
  registry-path: /nodes/worker/172.18.1.1:1234
****************************Worker Configuration**************************************
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:15.723 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'workerConfig' of type [org.apache.dolphinscheduler.server.worker.config.WorkerConfig$$EnhancerBySpringCGLIB$$da954724] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:16.469 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'io.kubernetes.client.spring.extended.manifests.config.KubernetesManifestsAutoConfiguration' of type [io.kubernetes.client.spring.extended.manifests.config.KubernetesManifestsAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:16.549 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'kubernetes.manifests-io.kubernetes.client.spring.extended.manifests.config.KubernetesManifestsProperties' of type [io.kubernetes.client.spring.extended.manifests.config.KubernetesManifestsProperties] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:16.636 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'io.kubernetes.client.spring.extended.controller.config.KubernetesInformerAutoConfiguration' of type [io.kubernetes.client.spring.extended.controller.config.KubernetesInformerAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:16.706 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'defaultApiClient' of type [io.kubernetes.client.openapi.ApiClient] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:17.368 +0800 o.e.j.u.log:[170] - Logging initialized @36942ms to org.eclipse.jetty.util.log.Slf4jLog
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:18.688 +0800 o.s.b.w.e.j.JettyServletWebServerFactory:[166] - Server initialized with port: 1235
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:18.701 +0800 o.e.j.s.Server:[375] - jetty-9.4.48.v20220622; built: 2022-06-21T20:42:25.880Z; git: 6b67c5719d1f4371b33655ff2d047d24e171e49a; jvm 1.8.0_402-b06
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:19.135 +0800 o.e.j.s.h.C.application:[2368] - Initializing Spring embedded WebApplicationContext
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:19.137 +0800 o.s.b.w.s.c.ServletWebServerApplicationContext:[292] - Root WebApplicationContext: initialization completed in 16505 ms
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:21.338 +0800 o.e.j.s.session:[334] - DefaultSessionIdManager workerName=node0
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:21.374 +0800 o.e.j.s.session:[339] - No SessionScavenger set, using defaults
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:21.431 +0800 o.e.j.s.session:[132] - node0 Scavenging every 600000ms
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:21.451 +0800 o.e.j.s.h.ContextHandler:[921] - Started o.s.b.w.e.j.JettyEmbeddedWebAppContext@52433946{application,/,[file:///tmp/jetty-docbase.1235.585122359700562180/],AVAILABLE}
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:21.458 +0800 o.e.j.s.Server:[415] - Started @41046ms
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:22.127 +0800 o.a.c.f.i.CuratorFrameworkImpl:[338] - Starting
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:22.221 +0800 o.a.z.ZooKeeper:[98] - Client environment:zookeeper.version=3.8.0-5a02a05eddb59aee6ac762f7ea82e92a68eb9c0f, built on 2022-02-25 08:49 UTC
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:22.222 +0800 o.a.z.ZooKeeper:[98] - Client environment:host.name=27ccc46d6f5e
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:22.222 +0800 o.a.z.ZooKeeper:[98] - Client environment:java.version=1.8.0_402
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:22.222 +0800 o.a.z.ZooKeeper:[98] - Client environment:java.vendor=Temurin
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:22.236 +0800 o.a.z.ZooKeeper:[98] - Client environment:java.home=/opt/java/openjdk
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:22.237 +0800 o.a.z.ZooKeeper:[98] - Client environment:java.class.path=/opt/dolphinscheduler/conf:/opt/dolphinscheduler/libs/kerb-client-1.0.1.jar:/opt/dolphinscheduler/libs/spring-cloud-starter-kubernetes-client-config-2.1.3.jar:/opt/dolphinscheduler/libs/oauth2-oidc-sdk-9.35.jar:/opt/dolphinscheduler/libs/jsqlparser-4.4.jar:/opt/dolphinscheduler/libs/reactive-streams-1.0.4.jar:/opt/dolphinscheduler/libs/kubernetes-model-extensions-5.10.2.jar:/opt/dolphinscheduler/libs/zookeeper-3.8.0.jar:/opt/dolphinscheduler/libs/kubernetes-model-apps-5.10.2.jar:/opt/dolphinscheduler/libs/grpc-api-1.41.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-pigeon-3.2.1.jar:/opt/dolphinscheduler/libs/client-java-api-13.0.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-obs-3.2.1.jar:/opt/dolphinscheduler/libs/spring-web-5.3.22.jar:/opt/dolphinscheduler/libs/aws-java-sdk-emr-1.12.300.jar:/opt/dolphinscheduler/libs/spring-context-5.3.22.jar:/opt/dolphinscheduler/libs/gapic-google-cloud-storage-v2-2.18.0-alpha.jar:/opt/dolphinscheduler/libs/spring-cloud-kubernetes-client-config-2.1.3.jar:/opt/dolphinscheduler/libs/jetty-io-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/annotations-13.0.jar:/opt/dolphinscheduler/libs/jpam-1.1.jar:/opt/dolphinscheduler/libs/joda-time-2.10.13.jar:/opt/dolphinscheduler/libs/spring-cloud-kubernetes-client-autoconfig-2.1.3.jar:/opt/dolphinscheduler/libs/kerb-identity-1.0.1.jar:/opt/dolphinscheduler/libs/vertica-jdbc-12.0.4-0.jar:/opt/dolphinscheduler/libs/grpc-googleapis-1.52.1.jar:/opt/dolphinscheduler/libs/aliyun-java-sdk-kms-2.11.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-dvc-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-hana-3.2.1.jar:/opt/dolphinscheduler/libs/kubernetes-httpclient-okhttp-6.0.0.jar:/opt/dolphinscheduler/libs/jline-2.12.jar:/opt/dolphinscheduler/libs/sshd-core-2.8.0.jar:/opt/dolphinscheduler/libs/jna-platform-5.10.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-sqlserver-3.2.1.jar:/opt/dolphinscheduler/libs/commons-beanutils-1.9.4.jar:/opt/dolphinscheduler/libs/grpc-services-1.41.0.jar:/opt/dolphinscheduler/libs/jmespath-java-1.12.300.jar:/opt/dolphinscheduler/libs/curator-client-5.3.0.jar:/opt/dolphinscheduler/libs/proto-google-common-protos-2.0.1.jar:/opt/dolphinscheduler/libs/mybatis-3.5.10.jar:/opt/dolphinscheduler/libs/jackson-annotations-2.13.4.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-all-3.2.1.jar:/opt/dolphinscheduler/libs/jakarta.xml.bind-api-2.3.3.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-jupyter-3.2.1.jar:/opt/dolphinscheduler/libs/mybatis-plus-extension-3.5.2.jar:/opt/dolphinscheduler/libs/j2objc-annotations-1.3.jar:/opt/dolphinscheduler/libs/Java-WebSocket-1.5.1.jar:/opt/dolphinscheduler/libs/azure-storage-common-12.20.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-sagemaker-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-databend-3.2.1.jar:/opt/dolphinscheduler/libs/google-auth-library-oauth2-http-1.15.0.jar:/opt/dolphinscheduler/libs/jetty-security-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-python-3.2.1.jar:/opt/dolphinscheduler/libs/snappy-java-1.1.10.1.jar:/opt/dolphinscheduler/libs/kubernetes-model-batch-5.10.2.jar:/opt/dolphinscheduler/libs/netty-transport-native-epoll-4.1.53.Final-linux-x86_64.jar:/opt/dolphinscheduler/libs/jackson-core-asl-1.9.13.jar:/opt/dolphinscheduler/libs/gson-fire-1.8.5.jar:/opt/dolphinscheduler/libs/clickhouse-jdbc-0.4.6.jar:/opt/dolphinscheduler/libs/grpc-netty-shaded-1.41.0.jar:/opt/dolphinscheduler/libs/caffeine-2.9.3.jar:/opt/dolphinscheduler/libs/aliyun-java-sdk-core-4.5.10.jar:/opt/dolphinscheduler/libs/jackson-module-jaxb-annotations-2.13.3.jar:/opt/dolphinscheduler/libs/jetty-http-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/jersey-servlet-1.19.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-dinky-3.2.1.jar:/opt/dolphinscheduler/libs/simpleclient_tracer_common-0.15.0.jar:/opt/dolphinscheduler/libs/netty-handler-4.1.53.Final.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-datafactory-3.2.1.jar:/opt/dolphinscheduler/libs/json-path-2.7.0.jar:/opt/dolphinscheduler/libs/mybatis-plus-annotation-3.5.2.jar:/opt/dolphinscheduler/libs/azure-resourcemanager-datafactory-1.0.0-beta.19.jar:/opt/dolphinscheduler/libs/commons-codec-1.11.jar:/opt/dolphinscheduler/libs/dolphinscheduler-extract-master-3.2.1.jar:/opt/dolphinscheduler/libs/spring-aop-5.3.22.jar:/opt/dolphinscheduler/libs/kubernetes-model-core-5.10.2.jar:/opt/dolphinscheduler/libs/kubernetes-model-networking-5.10.2.jar:/opt/dolphinscheduler/libs/kotlin-stdlib-jdk7-1.6.21.jar:/opt/dolphinscheduler/libs/kerby-xdr-1.0.1.jar:/opt/dolphinscheduler/libs/aliyun-java-sdk-ram-3.1.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-k8s-3.2.1.jar:/opt/dolphinscheduler/libs/guava-31.1-jre.jar:/opt/dolphinscheduler/libs/netty-codec-dns-4.1.53.Final.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-kubeflow-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-azure-sql-3.2.1.jar:/opt/dolphinscheduler/libs/HikariCP-4.0.3.jar:/opt/dolphinscheduler/libs/hive-metastore-2.3.9.jar:/opt/dolphinscheduler/libs/msal4j-1.13.3.jar:/opt/dolphinscheduler/libs/jackson-core-2.13.4.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-hive-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-mr-3.2.1.jar:/opt/dolphinscheduler/libs/kubernetes-model-node-5.10.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-common-3.2.1.jar:/opt/dolphinscheduler/libs/jose4j-0.7.8.jar:/opt/dolphinscheduler/libs/jul-to-slf4j-1.7.36.jar:/opt/dolphinscheduler/libs/azure-identity-1.7.1.jar:/opt/dolphinscheduler/libs/spring-boot-autoconfigure-2.7.3.jar:/opt/dolphinscheduler/libs/commons-math3-3.1.1.jar:/opt/dolphinscheduler/libs/jackson-jaxrs-json-provider-2.13.3.jar:/opt/dolphinscheduler/libs/perfmark-api-0.23.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-doris-3.2.1.jar:/opt/dolphinscheduler/libs/httpclient-4.5.13.jar:/opt/dolphinscheduler/libs/hive-service-2.3.9.jar:/opt/dolphinscheduler/libs/kerby-util-1.0.1.jar:/opt/dolphinscheduler/libs/commons-collections-3.2.2.jar:/opt/dolphinscheduler/libs/hadoop-yarn-client-3.2.4.jar:/opt/dolphinscheduler/libs/commons-text-1.8.jar:/opt/dolphinscheduler/libs/dolphinscheduler-worker-3.2.1.jar:/opt/dolphinscheduler/libs/hadoop-yarn-common-3.2.4.jar:/opt/dolphinscheduler/libs/zeppelin-client-0.10.1.jar:/opt/dolphinscheduler/libs/azure-core-management-1.10.1.jar:/opt/dolphinscheduler/libs/hadoop-mapreduce-client-jobclient-3.2.4.jar:/opt/dolphinscheduler/libs/jta-1.1.jar:/opt/dolphinscheduler/libs/annotations-4.1.1.4.jar:/opt/dolphinscheduler/libs/dolphinscheduler-extract-alert-3.2.1.jar:/opt/dolphinscheduler/libs/curator-framework-5.3.0.jar:/opt/dolphinscheduler/libs/hive-jdbc-2.3.9.jar:/opt/dolphinscheduler/libs/kyuubi-hive-jdbc-shaded-1.7.0.jar:/opt/dolphinscheduler/libs/client-java-proto-13.0.2.jar:/opt/dolphinscheduler/libs/checker-qual-3.19.0.jar:/opt/dolphinscheduler/libs/jetty-servlet-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/google-cloud-core-grpc-2.10.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-shell-3.2.1.jar:/opt/dolphinscheduler/libs/spring-security-rsa-1.0.10.RELEASE.jar:/opt/dolphinscheduler/libs/avro-1.7.7.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-postgresql-3.2.1.jar:/opt/dolphinscheduler/libs/netty-nio-client-2.17.282.jar:/opt/dolphinscheduler/libs/spring-webmvc-5.3.22.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-mysql-3.2.1.jar:/opt/dolphinscheduler/libs/opentracing-util-0.33.0.jar:/opt/dolphinscheduler/libs/auto-value-1.10.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-all-3.2.1.jar:/opt/dolphinscheduler/libs/jetcd-core-0.5.11.jar:/opt/dolphinscheduler/libs/grpc-context-1.41.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-datasync-3.2.1.jar:/opt/dolphinscheduler/libs/jackson-dataformat-cbor-2.13.3.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-gcs-3.2.1.jar:/opt/dolphinscheduler/libs/client-java-extended-13.0.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-redshift-3.2.1.jar:/opt/dolphinscheduler/libs/opencsv-2.3.jar:/opt/dolphinscheduler/libs/jcip-annotations-1.0-1.jar:/opt/dolphinscheduler/libs/accessors-smart-2.4.8.jar:/opt/dolphinscheduler/libs/hadoop-client-3.2.4.jar:/opt/dolphinscheduler/libs/commons-collections4-4.3.jar:/opt/dolphinscheduler/libs/metrics-core-4.2.11.jar:/opt/dolphinscheduler/libs/netty-resolver-4.1.53.Final.jar:/opt/dolphinscheduler/libs/parquet-hadoop-bundle-1.8.1.jar:/opt/dolphinscheduler/libs/bucket4j-core-6.2.0.jar:/opt/dolphinscheduler/libs/spring-cloud-starter-3.1.3.jar:/opt/dolphinscheduler/libs/mssql-jdbc-11.2.1.jre8.jar:/opt/dolphinscheduler/libs/netty-tcnative-boringssl-static-2.0.53.Final.jar:/opt/dolphinscheduler/libs/kubernetes-model-coordination-5.10.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-linkis-3.2.1.jar:/opt/dolphinscheduler/libs/commons-net-3.6.jar:/opt/dolphinscheduler/libs/netty-transport-native-kqueue-4.1.53.Final-osx-x86_64.jar:/opt/dolphinscheduler/libs/dolphinscheduler-meter-3.2.1.jar:/opt/dolphinscheduler/libs/kubernetes-client-api-6.0.0.jar:/opt/dolphinscheduler/libs/kubernetes-model-certificates-5.10.2.jar:/opt/dolphinscheduler/libs/opencensus-api-0.31.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-mlflow-3.2.1.jar:/opt/dolphinscheduler/libs/kotlin-stdlib-jdk8-1.6.21.jar:/opt/dolphinscheduler/libs/dolphinscheduler-registry-jdbc-3.2.1.jar:/opt/dolphinscheduler/libs/audience-annotations-0.12.0.jar:/opt/dolphinscheduler/libs/simpleclient_httpserver-0.15.0.jar:/opt/dolphinscheduler/libs/jetty-xml-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/kerby-asn1-1.0.1.jar:/opt/dolphinscheduler/libs/lang-tag-1.6.jar:/opt/dolphinscheduler/libs/api-common-2.6.0.jar:/opt/dolphinscheduler/libs/HdrHistogram-2.1.12.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-abs-3.2.1.jar:/opt/dolphinscheduler/libs/failsafe-2.4.4.jar:/opt/dolphinscheduler/libs/hbase-noop-htrace-4.1.1.jar:/opt/dolphinscheduler/libs/jamon-runtime-2.3.1.jar:/opt/dolphinscheduler/libs/jetty-util-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/threetenbp-1.6.5.jar:/opt/dolphinscheduler/libs/jakarta.activation-api-1.2.2.jar:/opt/dolphinscheduler/libs/kubernetes-model-common-5.10.2.jar:/opt/dolphinscheduler/libs/okhttp-4.9.3.jar:/opt/dolphinscheduler/libs/profiles-2.17.282.jar:/opt/dolphinscheduler/libs/hadoop-auth-3.2.4.jar:/opt/dolphinscheduler/libs/grpc-netty-1.41.0.jar:/opt/dolphinscheduler/libs/httpcore-nio-4.4.15.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-seatunnel-3.2.1.jar:/opt/dolphinscheduler/libs/aws-java-sdk-sagemaker-1.12.300.jar:/opt/dolphinscheduler/libs/oshi-core-6.1.1.jar:/opt/dolphinscheduler/libs/bonecp-0.8.0.RELEASE.jar:/opt/dolphinscheduler/libs/jackson-module-parameter-names-2.13.3.jar:/opt/dolphinscheduler/libs/bcutil-jdk15on-1.69.jar:/opt/dolphinscheduler/libs/aws-json-protocol-2.17.282.jar:/opt/dolphinscheduler/libs/dolphinscheduler-extract-base-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-all-3.2.1.jar:/opt/dolphinscheduler/libs/derby-10.14.2.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-snowflake-3.2.1.jar:/opt/dolphinscheduler/libs/netty-codec-http2-4.1.53.Final.jar:/opt/dolphinscheduler/libs/jetty-continuation-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/jackson-mapper-asl-1.9.13.jar:/opt/dolphinscheduler/libs/datanucleus-core-4.1.17.jar:/opt/dolphinscheduler/libs/netty-tcnative-boringssl-static-2.0.53.Final-osx-aarch_64.jar:/opt/dolphinscheduler/libs/failureaccess-1.0.1.jar:/opt/dolphinscheduler/libs/error_prone_annotations-2.5.1.jar:/opt/dolphinscheduler/libs/kerb-admin-1.0.1.jar:/opt/dolphinscheduler/libs/token-provider-1.0.1.jar:/opt/dolphinscheduler/libs/reactor-netty-core-1.0.22.jar:/opt/dolphinscheduler/libs/dolphinscheduler-registry-all-3.2.1.jar:/opt/dolphinscheduler/libs/jakarta.servlet-api-4.0.4.jar:/opt/dolphinscheduler/libs/http-client-spi-2.17.282.jar:/opt/dolphinscheduler/libs/regions-2.17.282.jar:/opt/dolphinscheduler/libs/logback-core-1.2.11.jar:/opt/dolphinscheduler/libs/json-1.8.jar:/opt/dolphinscheduler/libs/gax-grpc-2.23.0.jar:/opt/dolphinscheduler/libs/google-http-client-1.42.3.jar:/opt/dolphinscheduler/libs/hive-serde-2.3.9.jar:/opt/dolphinscheduler/libs/jettison-1.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-http-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-registry-zookeeper-3.2.1.jar:/opt/dolphinscheduler/libs/spring-security-crypto-5.7.3.jar:/opt/dolphinscheduler/libs/auth-2.17.282.jar:/opt/dolphinscheduler/libs/proto-google-cloud-storage-v2-2.18.0-alpha.jar:/opt/dolphinscheduler/libs/jetty-server-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/javax.annotation-api-1.3.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-starrocks-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-dataquality-3.2.1.jar:/opt/dolphinscheduler/libs/jcl-over-slf4j-1.7.36.jar:/opt/dolphinscheduler/libs/commons-lang3-3.12.0.jar:/opt/dolphinscheduler/libs/tomcat-embed-el-9.0.65.jar:/opt/dolphinscheduler/libs/opentracing-noop-0.33.0.jar:/opt/dolphinscheduler/libs/client-java-13.0.2.jar:/opt/dolphinscheduler/libs/spring-beans-5.3.22.jar:/opt/dolphinscheduler/libs/snakeyaml-1.33.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-ssh-3.2.1.jar:/opt/dolphinscheduler/libs/commons-pool-1.6.jar:/opt/dolphinscheduler/libs/javax.servlet-api-3.1.0.jar:/opt/dolphinscheduler/libs/hadoop-common-3.2.4.jar:/opt/dolphinscheduler/libs/kubernetes-model-apiextensions-5.10.2.jar:/opt/dolphinscheduler/libs/spring-boot-2.7.3.jar:/opt/dolphinscheduler/libs/bcprov-ext-jdk15on-1.69.jar:/opt/dolphinscheduler/libs/spring-boot-starter-2.7.3.jar:/opt/dolphinscheduler/libs/paranamer-2.3.jar:/opt/dolphinscheduler/libs/httpmime-4.5.13.jar:/opt/dolphinscheduler/libs/reactor-core-3.4.22.jar:/opt/dolphinscheduler/libs/azure-core-1.36.0.jar:/opt/dolphinscheduler/libs/bcpkix-jdk15on-1.69.jar:/opt/dolphinscheduler/libs/kubernetes-model-scheduling-5.10.2.jar:/opt/dolphinscheduler/libs/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/dolphinscheduler/libs/websocket-client-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/unirest-java-3.7.04-standalone.jar:/opt/dolphinscheduler/libs/hadoop-mapreduce-client-core-3.2.4.jar:/opt/dolphinscheduler/libs/google-auth-library-credentials-1.15.0.jar:/opt/dolphinscheduler/libs/azure-storage-internal-avro-12.6.0.jar:/opt/dolphinscheduler/libs/jackson-datatype-jdk8-2.13.3.jar:/opt/dolphinscheduler/libs/spring-expression-5.3.22.jar:/opt/dolphinscheduler/libs/aspectjweaver-1.9.7.jar:/opt/dolphinscheduler/libs/websocket-common-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/client-java-api-fluent-13.0.2.jar:/opt/dolphinscheduler/libs/mybatis-plus-3.5.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-athena-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-oss-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-openmldb-3.2.1.jar:/opt/dolphinscheduler/libs/curator-recipes-5.3.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-api-3.2.1.jar:/opt/dolphinscheduler/libs/netty-all-4.1.53.Final.jar:/opt/dolphinscheduler/libs/netty-resolver-dns-4.1.53.Final.jar:/opt/dolphinscheduler/libs/kubernetes-model-autoscaling-5.10.2.jar:/opt/dolphinscheduler/libs/kerb-util-1.0.1.jar:/opt/dolphinscheduler/libs/grpc-alts-1.41.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-presto-3.2.1.jar:/opt/dolphinscheduler/libs/kerb-simplekdc-1.0.1.jar:/opt/dolphinscheduler/libs/protobuf-java-util-3.17.2.jar:/opt/dolphinscheduler/libs/azure-core-http-netty-1.13.0.jar:/opt/dolphinscheduler/libs/transaction-api-1.1.jar:/opt/dolphinscheduler/libs/datanucleus-api-jdo-4.2.4.jar:/opt/dolphinscheduler/libs/zeppelin-common-0.10.1.jar:/opt/dolphinscheduler/libs/zt-zip-1.15.jar:/opt/dolphinscheduler/libs/animal-sniffer-annotations-1.19.jar:/opt/dolphinscheduler/libs/google-http-client-jackson2-1.42.3.jar:/opt/dolphinscheduler/libs/netty-buffer-4.1.53.Final.jar:/opt/dolphinscheduler/libs/jsr305-3.0.0.jar:/opt/dolphinscheduler/libs/netty-transport-classes-epoll-4.1.79.Final.jar:/opt/dolphinscheduler/libs/spring-boot-actuator-autoconfigure-2.7.3.jar:/opt/dolphinscheduler/libs/simpleclient-0.15.0.jar:/opt/dolphinscheduler/libs/aliyun-sdk-oss-3.15.1.jar:/opt/dolphinscheduler/libs/json-utils-2.17.282.jar:/opt/dolphinscheduler/libs/tephra-api-0.6.0.jar:/opt/dolphinscheduler/libs/spring-jdbc-5.3.22.jar:/opt/dolphinscheduler/libs/grpc-xds-1.41.0.jar:/opt/dolphinscheduler/libs/logback-classic-1.2.11.jar:/opt/dolphinscheduler/libs/google-cloud-storage-2.18.0.jar:/opt/dolphinscheduler/libs/micrometer-registry-prometheus-1.9.3.jar:/opt/dolphinscheduler/libs/grpc-core-1.41.0.jar:/opt/dolphinscheduler/libs/aws-java-sdk-kms-1.12.300.jar:/opt/dolphinscheduler/libs/kubernetes-model-rbac-5.10.2.jar:/opt/dolphinscheduler/libs/ini4j-0.5.4.jar:/opt/dolphinscheduler/libs/spring-boot-starter-web-2.7.3.jar:/opt/dolphinscheduler/libs/spring-cloud-commons-3.1.3.jar:/opt/dolphinscheduler/libs/netty-codec-http-4.1.53.Final.jar:/opt/dolphinscheduler/libs/jetty-client-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/jetcd-common-0.5.11.jar:/opt/dolphinscheduler/libs/metrics-spi-2.17.282.jar:/opt/dolphinscheduler/libs/utils-2.17.282.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-emr-3.2.1.jar:/opt/dolphinscheduler/libs/protocol-core-2.17.282.jar:/opt/dolphinscheduler/libs/micrometer-core-1.9.3.jar:/opt/dolphinscheduler/libs/netty-transport-native-unix-common-4.1.53.Final.jar:/opt/dolphinscheduler/libs/zjsonpatch-0.4.11.jar:/opt/dolphinscheduler/libs/annotations-2.17.282.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-sql-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-extract-common-3.2.1.jar:/opt/dolphinscheduler/libs/apache-client-2.17.282.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-oceanbase-3.2.1.jar:/opt/dolphinscheduler/libs/jdo-api-3.0.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-datax-3.2.1.jar:/opt/dolphinscheduler/libs/postgresql-42.4.1.jar:/opt/dolphinscheduler/libs/jetty-util-ajax-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/gax-2.23.0.jar:/opt/dolphinscheduler/libs/grpc-stub-1.41.0.jar:/opt/dolphinscheduler/libs/libfb303-0.9.3.jar:/opt/dolphinscheduler/libs/spring-core-5.3.22.jar:/opt/dolphinscheduler/libs/jaxb-api-2.3.1.jar:/opt/dolphinscheduler/libs/hive-service-rpc-2.3.9.jar:/opt/dolphinscheduler/libs/kubernetes-model-flowcontrol-5.10.2.jar:/opt/dolphinscheduler/libs/commons-logging-1.1.1.jar:/opt/dolphinscheduler/libs/mybatis-spring-2.0.7.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-oracle-3.2.1.jar:/opt/dolphinscheduler/libs/opencensus-proto-0.2.0.jar:/opt/dolphinscheduler/libs/grpc-protobuf-1.41.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-clickhouse-3.2.1.jar:/opt/dolphinscheduler/libs/spring-cloud-starter-bootstrap-3.1.3.jar:/opt/dolphinscheduler/libs/kubernetes-model-admissionregistration-5.10.2.jar:/opt/dolphinscheduler/libs/grpc-google-cloud-storage-v2-2.18.0-alpha.jar:/opt/dolphinscheduler/libs/esdk-obs-java-bundle-3.23.3.jar:/opt/dolphinscheduler/libs/dnsjava-2.1.7.jar:/opt/dolphinscheduler/libs/asm-9.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-spark-3.2.1.jar:/opt/dolphinscheduler/libs/netty-tcnative-boringssl-static-2.0.53.Final-linux-aarch_64.jar:/opt/dolphinscheduler/libs/re2j-1.6.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-vertica-3.2.1.jar:/opt/dolphinscheduler/libs/json-smart-2.4.8.jar:/opt/dolphinscheduler/libs/reactor-netty-http-1.0.22.jar:/opt/dolphinscheduler/libs/google-api-services-storage-v1-rev20220705-2.0.0.jar:/opt/dolphinscheduler/libs/kubernetes-client-6.0.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-kyuubi-3.2.1.jar:/opt/dolphinscheduler/libs/auto-value-annotations-1.10.1.jar:/opt/dolphinscheduler/libs/commons-cli-1.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-data-quality-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-chunjun-3.2.1.jar:/opt/dolphinscheduler/libs/kerb-server-1.0.1.jar:/opt/dolphinscheduler/libs/content-type-2.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-remoteshell-3.2.1.jar:/opt/dolphinscheduler/libs/opencensus-contrib-http-util-0.31.1.jar:/opt/dolphinscheduler/libs/druid-1.2.20.jar:/opt/dolphinscheduler/libs/javolution-5.5.1.jar:/opt/dolphinscheduler/libs/protobuf-java-3.17.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-db2-3.2.1.jar:/opt/dolphinscheduler/libs/aws-java-sdk-core-1.12.300.jar:/opt/dolphinscheduler/libs/spring-boot-starter-logging-2.7.3.jar:/opt/dolphinscheduler/libs/kerby-pkix-1.0.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-procedure-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-registry-etcd-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-sqoop-3.2.1.jar:/opt/dolphinscheduler/libs/zookeeper-jute-3.8.0.jar:/opt/dolphinscheduler/libs/netty-resolver-dns-native-macos-4.1.53.Final-osx-x86_64.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-sagemaker-3.2.1.jar:/opt/dolphinscheduler/libs/spring-boot-configuration-processor-2.6.1.jar:/opt/dolphinscheduler/libs/hive-common-2.3.9.jar:/opt/dolphinscheduler/libs/kerb-common-1.0.1.jar:/opt/dolphinscheduler/libs/stax-api-1.0.1.jar:/opt/dolphinscheduler/libs/kubernetes-model-storageclass-5.10.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-s3-3.2.1.jar:/opt/dolphinscheduler/libs/spring-boot-starter-jetty-2.7.3.jar:/opt/dolphinscheduler/libs/okio-2.8.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-dms-3.2.1.jar:/opt/dolphinscheduler/libs/simpleclient_common-0.15.0.jar:/opt/dolphinscheduler/libs/sdk-core-2.17.282.jar:/opt/dolphinscheduler/libs/javax.activation-api-1.2.0.jar:/opt/dolphinscheduler/libs/netty-handler-proxy-4.1.53.Final.jar:/opt/dolphinscheduler/libs/kerby-config-1.0.1.jar:/opt/dolphinscheduler/libs/netty-tcnative-classes-2.0.53.Final.jar:/opt/dolphinscheduler/libs/jackson-jaxrs-base-2.13.3.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-trino-3.2.1.jar:/opt/dolphinscheduler/libs/presto-jdbc-0.238.1.jar:/opt/dolphinscheduler/libs/websocket-api-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-flink-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-api-3.2.1.jar:/opt/dolphinscheduler/libs/kubernetes-model-metrics-5.10.2.jar:/opt/dolphinscheduler/libs/datasync-2.17.282.jar:/opt/dolphinscheduler/libs/hadoop-yarn-api-3.2.4.jar:/opt/dolphinscheduler/libs/google-http-client-apache-v2-1.42.3.jar:/opt/dolphinscheduler/libs/hadoop-annotations-3.2.4.jar:/opt/dolphinscheduler/libs/google-oauth-client-1.34.1.jar:/opt/dolphinscheduler/libs/sshd-common-2.8.0.jar:/opt/dolphinscheduler/libs/LatencyUtils-2.0.3.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-spark-3.2.1.jar:/opt/dolphinscheduler/libs/slf4j-api-1.7.36.jar:/opt/dolphinscheduler/libs/snowflake-jdbc-3.13.29.jar:/opt/dolphinscheduler/libs/jackson-datatype-jsr310-2.13.3.jar:/opt/dolphinscheduler/libs/trino-jdbc-402.jar:/opt/dolphinscheduler/libs/logging-interceptor-4.9.3.jar:/opt/dolphinscheduler/libs/simpleclient_tracer_otel_agent-0.15.0.jar:/opt/dolphinscheduler/libs/janino-3.0.16.jar:/opt/dolphinscheduler/libs/jackson-dataformat-yaml-2.13.3.jar:/opt/dolphinscheduler/libs/ion-java-1.0.2.jar:/opt/dolphinscheduler/libs/commons-dbcp-1.4.jar:/opt/dolphinscheduler/libs/jsp-api-2.1.jar:/opt/dolphinscheduler/libs/google-http-client-gson-1.42.3.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-hivecli-3.2.1.jar:/opt/dolphinscheduler/libs/spring-boot-actuator-2.7.3.jar:/opt/dolphinscheduler/libs/google-cloud-core-http-2.10.0.jar:/opt/dolphinscheduler/libs/DmJdbcDriver18-8.1.2.79.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-java-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-dameng-3.2.1.jar:/opt/dolphinscheduler/libs/sshd-sftp-2.8.0.jar:/opt/dolphinscheduler/libs/kerb-crypto-1.0.1.jar:/opt/dolphinscheduler/libs/conscrypt-openjdk-uber-2.5.2.jar:/opt/dolphinscheduler/libs/httpcore-4.4.15.jar:/opt/dolphinscheduler/libs/lz4-java-1.4.0.jar:/opt/dolphinscheduler/libs/guava-retrying-2.0.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-flink-stream-3.2.1.jar:/opt/dolphinscheduler/libs/spring-tx-5.3.22.jar:/opt/dolphinscheduler/libs/grpc-auth-1.41.0.jar:/opt/dolphinscheduler/libs/netty-tcnative-boringssl-static-2.0.53.Final-osx-x86_64.jar:/opt/dolphinscheduler/libs/databend-jdbc-0.0.7.jar:/opt/dolphinscheduler/libs/bcprov-jdk15on-1.69.jar:/opt/dolphinscheduler/libs/commons-lang-2.6.jar:/opt/dolphinscheduler/libs/kubernetes-model-policy-5.10.2.jar:/opt/dolphinscheduler/libs/commons-io-2.11.0.jar:/opt/dolphinscheduler/libs/grpc-grpclb-1.41.0.jar:/opt/dolphinscheduler/libs/netty-tcnative-boringssl-static-2.0.53.Final-linux-x86_64.jar:/opt/dolphinscheduler/libs/opentracing-api-0.33.0.jar:/opt/dolphinscheduler/libs/sshd-scp-2.8.0.jar:/opt/dolphinscheduler/libs/reload4j-1.2.18.3.jar:/opt/dolphinscheduler/libs/netty-tcnative-2.0.48.Final.jar:/opt/dolphinscheduler/libs/jdom2-2.0.6.1.jar:/opt/dolphinscheduler/libs/spring-boot-starter-json-2.7.3.jar:/opt/dolphinscheduler/libs/netty-transport-native-epoll-4.1.53.Final.jar:/opt/dolphinscheduler/libs/google-cloud-core-2.10.0.jar:/opt/dolphinscheduler/libs/javax.jdo-3.2.0-m3.jar:/opt/dolphinscheduler/libs/gax-httpjson-0.108.0.jar:/opt/dolphinscheduler/libs/mybatis-plus-core-3.5.2.jar:/opt/dolphinscheduler/libs/auto-service-annotations-1.0.1.jar:/opt/dolphinscheduler/libs/nimbus-jose-jwt-9.22.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-zeppelin-3.2.1.jar:/opt/dolphinscheduler/libs/commons-compress-1.21.jar:/opt/dolphinscheduler/libs/hadoop-hdfs-client-3.2.4.jar:/opt/dolphinscheduler/libs/msal4j-persistence-extension-1.1.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-pytorch-3.2.1.jar:/opt/dolphinscheduler/libs/netty-tcnative-boringssl-static-2.0.53.Final-windows-x86_64.jar:/opt/dolphinscheduler/libs/jetty-servlets-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/woodstox-core-6.4.0.jar:/opt/dolphinscheduler/libs/spring-cloud-kubernetes-commons-2.1.3.jar:/opt/dolphinscheduler/libs/grpc-protobuf-lite-1.41.0.jar:/opt/dolphinscheduler/libs/jetty-webapp-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/eventstream-1.0.1.jar:/opt/dolphinscheduler/libs/commons-compiler-3.1.7.jar:/opt/dolphinscheduler/libs/netty-transport-4.1.53.Final.jar:/opt/dolphinscheduler/libs/spring-cloud-context-3.1.3.jar:/opt/dolphinscheduler/libs/aws-java-sdk-dms-1.12.300.jar:/opt/dolphinscheduler/libs/hive-storage-api-2.4.0.jar:/opt/dolphinscheduler/libs/client-java-spring-integration-13.0.2.jar:/opt/dolphinscheduler/libs/spring-boot-starter-actuator-2.7.3.jar:/opt/dolphinscheduler/libs/third-party-jackson-core-2.17.282.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-hdfs-3.2.1.jar:/opt/dolphinscheduler/libs/netty-codec-4.1.53.Final.jar:/opt/dolphinscheduler/libs/google-http-client-appengine-1.42.3.jar:/opt/dolphinscheduler/libs/commons-configuration2-2.1.1.jar:/opt/dolphinscheduler/libs/datanucleus-rdbms-4.1.19.jar:/opt/dolphinscheduler/libs/swagger-annotations-1.6.2.jar:/opt/dolphinscheduler/libs/simpleclient_tracer_otel-0.15.0.jar:/opt/dolphinscheduler/libs/kotlin-stdlib-common-1.6.21.jar:/opt/dolphinscheduler/libs/aws-core-2.17.282.jar:/opt/dolphinscheduler/libs/kerb-core-1.0.1.jar:/opt/dolphinscheduler/libs/httpasyncclient-4.1.5.jar:/opt/dolphinscheduler/libs/dolphinscheduler-extract-worker-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-spi-3.2.1.jar:/opt/dolphinscheduler/libs/okhttp-2.7.5.jar:/opt/dolphinscheduler/libs/google-api-client-2.2.0.jar:/opt/dolphinscheduler/libs/kotlin-stdlib-1.6.21.jar:/opt/dolphinscheduler/libs/jakarta.websocket-api-1.1.2.jar:/opt/dolphinscheduler/libs/libthrift-0.9.3.jar:/opt/dolphinscheduler/libs/spring-boot-starter-aop-2.7.3.jar:/opt/dolphinscheduler/libs/netty-common-4.1.53.Final.jar:/opt/dolphinscheduler/libs/log4j-1.2-api-2.17.2.jar:/opt/dolphinscheduler/libs/jackson-databind-2.13.4.jar:/opt/dolphinscheduler/libs/jackson-dataformat-xml-2.13.3.jar:/opt/dolphinscheduler/libs/kubernetes-model-events-5.10.2.jar:/opt/dolphinscheduler/libs/gson-2.9.1.jar:/opt/dolphinscheduler/libs/proto-google-iam-v1-1.9.0.jar:/opt/dolphinscheduler/libs/netty-codec-socks-4.1.53.Final.jar:/opt/dolphinscheduler/libs/zjsonpatch-0.3.0.jar:/opt/dolphinscheduler/libs/hadoop-mapreduce-client-common-3.2.4.jar:/opt/dolphinscheduler/libs/dolphinscheduler-registry-api-3.2.1.jar:/opt/dolphinscheduler/libs/azure-storage-blob-12.21.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-zeppelin-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-api-3.2.1.jar:/opt/dolphinscheduler/libs/aws-java-sdk-s3-1.12.300.jar:/opt/dolphinscheduler/libs/stax2-api-4.2.1.jar:/opt/dolphinscheduler/libs/jakarta.annotation-api-1.3.5.jar:/opt/dolphinscheduler/libs/kubernetes-model-discovery-5.10.2.jar:/opt/dolphinscheduler/libs/jna-5.10.0.jar:/opt/dolphinscheduler/libs/spring-jcl-5.3.22.jar
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:22.237 +0800 o.a.z.ZooKeeper:[98] - Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:22.238 +0800 o.a.z.ZooKeeper:[98] - Client environment:java.io.tmpdir=/tmp
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:22.238 +0800 o.a.z.ZooKeeper:[98] - Client environment:java.compiler=<NA>
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:22.238 +0800 o.a.z.ZooKeeper:[98] - Client environment:os.name=Linux
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:22.238 +0800 o.a.z.ZooKeeper:[98] - Client environment:os.arch=amd64
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:22.239 +0800 o.a.z.ZooKeeper:[98] - Client environment:os.version=6.5.0-28-generic
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:22.239 +0800 o.a.z.ZooKeeper:[98] - Client environment:user.name=root
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:22.239 +0800 o.a.z.ZooKeeper:[98] - Client environment:user.home=/root
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:22.239 +0800 o.a.z.ZooKeeper:[98] - Client environment:user.dir=/opt/dolphinscheduler
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:22.239 +0800 o.a.z.ZooKeeper:[98] - Client environment:os.memory.free=3235MB
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:22.240 +0800 o.a.z.ZooKeeper:[98] - Client environment:os.memory.max=3840MB
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:22.249 +0800 o.a.z.ZooKeeper:[98] - Client environment:os.memory.total=3840MB
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:22.258 +0800 o.a.z.ZooKeeper:[637] - Initiating client connection, connectString=dolphinscheduler-zookeeper:2181 sessionTimeout=30000 watcher=org.apache.curator.ConnectionState@6996bbc4
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:22.288 +0800 o.a.z.c.X509Util:[77] - Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:22.318 +0800 o.a.z.ClientCnxnSocket:[239] - jute.maxbuffer value is 1048575 Bytes
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:22.489 +0800 o.a.z.ClientCnxn:[1732] - zookeeper.request.timeout value is 0. feature enabled=false
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:22.883 +0800 o.a.c.f.i.CuratorFrameworkImpl:[386] - Default schema
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:22.919 +0800 o.a.z.ClientCnxn:[1171] - Opening socket connection to server dolphinscheduler-zookeeper/172.18.0.3:2181.
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:23.065 +0800 o.a.z.ClientCnxn:[1173] - SASL config status: Will not attempt to authenticate using SASL (unknown error)
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:23.117 +0800 o.a.z.ClientCnxn:[1005] - Socket connection established, initiating session, client: /172.18.1.1:51332, server: dolphinscheduler-zookeeper/172.18.0.3:2181
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:23.219 +0800 o.a.z.ClientCnxn:[1444] - Session establishment complete on server dolphinscheduler-zookeeper/172.18.0.3:2181, session id = 0x100009fbdb50000, negotiated timeout = 30000
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:23.276 +0800 o.a.c.f.s.ConnectionStateManager:[252] - State change: CONNECTED
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:23.380 +0800 o.a.c.f.i.EnsembleTracker:[201] - New config event received: {}
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:23.567 +0800 o.a.c.f.i.EnsembleTracker:[201] - New config event received: {}
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:24.047 +0800 o.a.d.s.w.r.WorkerRpcServer:[41] - WorkerRpcServer starting...
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:24.995 +0800 o.a.d.e.b.NettyRemotingServer:[112] - WorkerRpcServer bind success at port: 1234
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:25.002 +0800 o.a.d.s.w.r.WorkerRpcServer:[43] - WorkerRpcServer started...
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:25.084 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: JAVA - JavaTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:25.150 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: JAVA - JavaTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:25.151 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: JUPYTER - JupyterTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:25.153 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: JUPYTER - JupyterTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:25.155 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: SPARK - SparkTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:25.158 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: SPARK - SparkTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:25.162 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: FLINK_STREAM - FlinkStreamTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:25.175 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: FLINK_STREAM - FlinkStreamTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:25.194 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: PYTHON - PythonTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:25.200 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: PYTHON - PythonTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:25.201 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: DATASYNC - DatasyncTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:25.202 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: DATASYNC - DatasyncTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:25.208 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: DATA_FACTORY - DatafactoryTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:25.209 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: DATA_FACTORY - DatafactoryTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:25.210 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: CHUNJUN - ChunJunTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:25.213 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: CHUNJUN - ChunJunTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:25.213 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: REMOTESHELL - RemoteShellTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:25.215 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: REMOTESHELL - RemoteShellTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:25.221 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: PIGEON - PigeonTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:25.226 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: PIGEON - PigeonTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:25.227 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: SHELL - ShellTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:25.230 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: SHELL - ShellTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:25.355 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: PROCEDURE - ProcedureTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:25.358 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: PROCEDURE - ProcedureTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:25.359 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: MR - MapReduceTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:25.374 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: MR - MapReduceTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:25.374 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: SQOOP - SqoopTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:25.385 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: SQOOP - SqoopTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:25.385 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: PYTORCH - PytorchTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:25.394 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: PYTORCH - PytorchTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:25.408 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: K8S - K8sTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:25.415 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: K8S - K8sTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:25.428 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: SEATUNNEL - SeatunnelTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:25.438 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: SEATUNNEL - SeatunnelTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:25.446 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: SAGEMAKER - SagemakerTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:25.448 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: SAGEMAKER - SagemakerTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:25.449 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: HTTP - HttpTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:25.460 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: HTTP - HttpTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:25.461 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: EMR - EmrTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:25.464 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: EMR - EmrTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:25.465 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: DMS - DmsTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:25.480 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: DMS - DmsTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:25.483 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: DATA_QUALITY - DataQualityTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:25.496 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: DATA_QUALITY - DataQualityTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:25.498 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: KUBEFLOW - KubeflowTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:25.515 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: KUBEFLOW - KubeflowTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:25.519 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: SQL - SqlTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:25.526 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: SQL - SqlTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:25.526 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: DVC - DvcTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:25.532 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: DVC - DvcTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:25.532 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: DATAX - DataxTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:25.536 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: DATAX - DataxTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:25.544 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: ZEPPELIN - ZeppelinTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:25.549 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: ZEPPELIN - ZeppelinTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:25.550 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: DINKY - DinkyTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:25.558 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: DINKY - DinkyTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:25.558 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: MLFLOW - MlflowTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:25.560 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: MLFLOW - MlflowTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:25.566 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: OPENMLDB - OpenmldbTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:25.568 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: OPENMLDB - OpenmldbTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:25.570 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: LINKIS - LinkisTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:25.574 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: LINKIS - LinkisTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:25.574 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: FLINK - FlinkTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:25.589 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: FLINK - FlinkTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:25.590 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: HIVECLI - HiveCliTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:25.594 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: HIVECLI - HiveCliTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:25.685 +0800 o.a.d.c.u.JSONUtils:[72] - init timezone: sun.util.calendar.ZoneInfo[id="Asia/Shanghai",offset=28800000,dstSavings=0,useDaylight=false,transitions=31,lastRule=null]
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:25.964 +0800 o.a.d.s.w.r.WorkerRegistryClient:[104] - Worker node: 172.18.1.1:1234 registry to ZK /nodes/worker/172.18.1.1:1234 successfully
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:26.991 +0800 o.a.d.c.m.BaseHeartBeatTask:[48] - Starting WorkerHeartBeatTask...
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:26.994 +0800 o.a.d.c.m.BaseHeartBeatTask:[50] - Started WorkerHeartBeatTask, heartBeatInterval: 10000...
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:26.995 +0800 o.a.d.s.w.r.WorkerRegistryClient:[114] - Worker node: 172.18.1.1:1234 registry finished
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:26.997 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.048165137614679 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:26.998 +0800 o.a.d.s.w.m.MessageRetryRunner:[69] - Message retry runner staring
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:27.158 +0800 o.a.d.s.w.m.MessageRetryRunner:[72] - Injected message sender: TaskInstanceExecutionFinishEventSender
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:27.159 +0800 o.a.d.s.w.m.MessageRetryRunner:[72] - Injected message sender: TaskInstanceExecutionInfoUpdateEventSender
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:27.216 +0800 o.a.d.s.w.m.MessageRetryRunner:[72] - Injected message sender: TaskInstanceExecutionRunningEventSender
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:27.217 +0800 o.a.d.s.w.m.MessageRetryRunner:[75] - Message retry runner started
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:28.046 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.2584745762711864 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:29.056 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.2371541501976284 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:30.068 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.413978494623656 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:31.996 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.2300884955752212 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:33.032 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.29136690647482 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:34.046 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.380952380952381 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:35.061 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.3529411764705883 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:36.245 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.1672473867595818 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:37.342 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.214046822742475 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:38.405 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.3937823834196892 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:39.560 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.1273584905660377 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:40.585 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.2266666666666666 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:41.600 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.1563981042654028 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:42.552 +0800 o.s.b.a.e.w.EndpointLinksResolver:[58] - Exposing 3 endpoint(s) beneath base path '/actuator'
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:42.608 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.253393665158371 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:42.971 +0800 o.e.j.s.h.C.application:[2368] - Initializing Spring DispatcherServlet 'dispatcherServlet'
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:42.972 +0800 o.s.w.s.DispatcherServlet:[525] - Initializing Servlet 'dispatcherServlet'
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:42.983 +0800 o.s.w.s.DispatcherServlet:[547] - Completed initialization in 10 ms
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:43.097 +0800 o.e.j.s.AbstractConnector:[333] - Started ServerConnector@acb5508{HTTP/1.1, (http/1.1)}{0.0.0.0:1235}
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:43.267 +0800 o.s.b.w.e.j.JettyWebServer:[172] - Jetty started on port(s) 1235 (http/1.1) with context path '/'
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:43.840 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.3560975609756096 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:43.847 +0800 o.a.d.s.w.WorkerServer:[61] - Started WorkerServer in 59.54 seconds (JVM running for 63.434)
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:44.845 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.4285714285714286 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:45.847 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9887218045112782 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:46.851 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.0067567567567568 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:47.926 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.0075757575757576 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:48.961 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.0052083333333335 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:50.045 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7577319587628866 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:51.055 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.0 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:52.087 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9999999999999999 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:53.090 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9946808510638299 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:54.094 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8966789667896679 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:55.097 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9591078066914499 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:56.100 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9171597633136095 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:57.117 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9897610921501707 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:58.119 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9775280898876404 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:39:59.145 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9386503067484662 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:40:00.173 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9321266968325792 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:40:02.191 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8059701492537313 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:40:03.290 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9416342412451362 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:40:04.301 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7144792876500193 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:40:12.454 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8657142857142858 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:40:17.495 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7766990291262136 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-3956] - [INFO] 2024-05-07 10:40:24.126 +0800 o.a.d.s.w.r.o.UpdateWorkflowHostOperationFunction:[49] - Received UpdateWorkflowHostRequest: UpdateWorkflowHostRequest(taskInstanceId=3956, workflowHost=172.18.0.14:5678)
[WI-0][TI-0] - [INFO] 2024-05-07 10:40:24.361 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=3957, taskName=[null check] filtered data persistence, firstSubmitTime=1715049624185, startTime=0, taskType=DATA_QUALITY, workflowInstanceHost=172.18.0.14:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13505298546272, processDefineVersion=21, appIds=null, processInstanceId=1060, scheduleTime=0, globalParams=null, executorId=1, cmdTypeIfComplement=2, tenantCode=default, processDefineId=0, projectId=0, projectCode=13001194483488, taskParams={"localParams":[],"resourceList":[],"ruleId":6,"ruleInputParameter":{"check_type":"0","comparison_type":1,"comparison_name":"0","failure_strategy":"0","operator":"0","src_connector_type":1,"src_datasource_id":6,"src_database":"persistence","src_field":"content","src_table":"filtered_data_persistence","threshold":"0"},"sparkParameters":{"deployMode":"local","driverCores":1,"driverMemory":"512M","executorCores":1,"executorMemory":"1G","numExecutors":1,"others":"--conf spark.driver.extraJavaOptions=\"-Divy.cache.dir=/tmp -Divy.home=/tmp\" \\\n--packages org.postgresql:postgresql:42.7.3","yarnQueue":""}}, environmentConfig=export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export PYSPARK_DRIVER_PYTHON=/bin/python3.11
export PYSPARK_PYTHON=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='[null check] filtered data persistence'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13001194483488'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='1060'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240507'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240506'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='3957'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='qualti_test'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13505264408800'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13505298546272'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240507104024'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=null, dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=org.apache.dolphinscheduler.plugin.task.api.DataQualityTaskExecutionContext@41f102d, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-1060][TI-3957] - [INFO] 2024-05-07 10:40:24.436 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: [null check] filtered data persistence to wait queue success
[WI-1060][TI-3957] - [INFO] 2024-05-07 10:40:24.451 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-1060][TI-3957] - [INFO] 2024-05-07 10:40:24.459 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-1060][TI-3957] - [INFO] 2024-05-07 10:40:24.463 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-1060][TI-3957] - [INFO] 2024-05-07 10:40:24.465 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-1060][TI-3957] - [INFO] 2024-05-07 10:40:24.466 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1715049624466
[WI-1060][TI-3957] - [INFO] 2024-05-07 10:40:24.469 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 1060_3957
[WI-1060][TI-3957] - [INFO] 2024-05-07 10:40:24.499 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 3957,
  "taskName" : "[null check] filtered data persistence",
  "firstSubmitTime" : 1715049624185,
  "startTime" : 1715049624466,
  "taskType" : "DATA_QUALITY",
  "workflowInstanceHost" : "172.18.0.14:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240507/13505298546272/21/1060/3957.log",
  "processId" : 0,
  "processDefineCode" : 13505298546272,
  "processDefineVersion" : 21,
  "processInstanceId" : 1060,
  "scheduleTime" : 0,
  "executorId" : 1,
  "cmdTypeIfComplement" : 2,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13001194483488,
  "taskParams" : "{\"localParams\":[],\"resourceList\":[],\"ruleId\":6,\"ruleInputParameter\":{\"check_type\":\"0\",\"comparison_type\":1,\"comparison_name\":\"0\",\"failure_strategy\":\"0\",\"operator\":\"0\",\"src_connector_type\":1,\"src_datasource_id\":6,\"src_database\":\"persistence\",\"src_field\":\"content\",\"src_table\":\"filtered_data_persistence\",\"threshold\":\"0\"},\"sparkParameters\":{\"deployMode\":\"local\",\"driverCores\":1,\"driverMemory\":\"512M\",\"executorCores\":1,\"executorMemory\":\"1G\",\"numExecutors\":1,\"others\":\"--conf spark.driver.extraJavaOptions=\\\"-Divy.cache.dir=/tmp -Divy.home=/tmp\\\" \\\\\\n--packages org.postgresql:postgresql:42.7.3\",\"yarnQueue\":\"\"}}",
  "environmentConfig" : "export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3\nexport JAVA_HOME=/opt/java/openjdk\nexport PYSPARK_DRIVER_PYTHON=/bin/python3.11\nexport PYSPARK_PYTHON=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "[null check] filtered data persistence"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13001194483488"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1060"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240507"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240506"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "3957"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "qualti_test"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13505264408800"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13505298546272"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240507104024"
    }
  },
  "taskAppId" : "1060_3957",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "dryRun" : 0,
  "paramsMap" : { },
  "dataQualityTaskExecutionContext" : {
    "ruleId" : 6,
    "ruleName" : "$t(uniqueness_check)",
    "ruleType" : 0,
    "ruleInputEntryList" : "[{\"id\":1,\"field\":\"src_connector_type\",\"type\":\"select\",\"title\":\"$t(src_connector_type)\",\"data\":\"\",\"options\":\"[{\\\"label\\\":\\\"HIVE\\\",\\\"value\\\":\\\"HIVE\\\"},{\\\"label\\\":\\\"JDBC\\\",\\\"value\\\":\\\"JDBC\\\"}]\",\"placeholder\":\"please select source connector type\",\"optionSourceType\":2,\"dataType\":2,\"inputType\":0,\"isShow\":true,\"canEdit\":true,\"isEmit\":true,\"isValidate\":false,\"valuesMap\":null,\"index\":1,\"createTime\":null,\"updateTime\":null},{\"id\":2,\"field\":\"src_datasource_id\",\"type\":\"select\",\"title\":\"$t(src_datasource_id)\",\"data\":\"\",\"options\":null,\"placeholder\":\"please select source datasource id\",\"optionSourceType\":1,\"dataType\":2,\"inputType\":0,\"isShow\":true,\"canEdit\":true,\"isEmit\":true,\"isValidate\":false,\"valuesMap\":null,\"index\":2,\"createTime\":null,\"updateTime\":null},{\"id\":30,\"field\":\"src_database\",\"type\":\"select\",\"title\":\"$t(src_database)\",\"data\":null,\"options\":null,\"placeholder\":\"Please select source database\",\"optionSourceType\":0,\"dataType\":0,\"inputType\":0,\"isShow\":true,\"canEdit\":true,\"isEmit\":true,\"isValidate\":true,\"valuesMap\":null,\"index\":2,\"createTime\":null,\"updateTime\":null},{\"id\":3,\"field\":\"src_table\",\"type\":\"select\",\"title\":\"$t(src_table)\",\"data\":null,\"options\":null,\"placeholder\":\"Please enter source table name\",\"optionSourceType\":0,\"dataType\":0,\"inputType\":0,\"isShow\":true,\"canEdit\":true,\"isEmit\":true,\"isValidate\":true,\"valuesMap\":null,\"index\":3,\"createTime\":null,\"updateTime\":null},{\"id\":4,\"field\":\"src_filter\",\"type\":\"input\",\"title\":\"$t(src_filter)\",\"data\":null,\"options\":null,\"placeholder\":\"Please enter filter expression\",\"optionSourceType\":0,\"dataType\":3,\"inputType\":0,\"isShow\":true,\"canEdit\":true,\"isEmit\":false,\"isValidate\":false,\"valuesMap\":null,\"index\":4,\"createTime\":null,\"updateTime\":null},{\"id\":5,\"field\":\"src_field\",\"type\":\"select\",\"title\":\"$t(src_field)\",\"data\":null,\"options\":null,\"placeholder\":\"Please enter column, only single column is supported\",\"optionSourceType\":0,\"dataType\":0,\"inputType\":0,\"isShow\":true,\"canEdit\":true,\"isEmit\":false,\"isValidate\":true,\"valuesMap\":null,\"index\":5,\"createTime\":null,\"updateTime\":null},{\"id\":6,\"field\":\"statistics_name\",\"type\":\"input\",\"title\":\"$t(statistics_name)\",\"data\":\"duplicate_count.duplicates\",\"options\":null,\"placeholder\":\"Please enter statistics name, the alias in statistics execute sql\",\"optionSourceType\":0,\"dataType\":0,\"inputType\":1,\"isShow\":false,\"canEdit\":false,\"isEmit\":false,\"isValidate\":true,\"valuesMap\":\"{\\\"statistics_name\\\":\\\"duplicate_count.duplicates\\\"}\",\"index\":6,\"createTime\":null,\"updateTime\":null},{\"id\":7,\"field\":\"check_type\",\"type\":\"select\",\"title\":\"$t(check_type)\",\"data\":\"0\",\"options\":\"[{\\\"label\\\":\\\"Expected - Actual\\\",\\\"value\\\":\\\"0\\\"},{\\\"label\\\":\\\"Actual - Expected\\\",\\\"value\\\":\\\"1\\\"},{\\\"label\\\":\\\"Actual / Expected\\\",\\\"value\\\":\\\"2\\\"},{\\\"label\\\":\\\"(Expected - Actual) / Expected\\\",\\\"value\\\":\\\"3\\\"}]\",\"placeholder\":\"please select check type\",\"optionSourceType\":0,\"dataType\":0,\"inputType\":3,\"isShow\":true,\"canEdit\":true,\"isEmit\":true,\"isValidate\":false,\"valuesMap\":null,\"index\":7,\"createTime\":null,\"updateTime\":null},{\"id\":8,\"field\":\"operator\",\"type\":\"select\",\"title\":\"$t(operator)\",\"data\":\"0\",\"options\":\"[{\\\"label\\\":\\\"=\\\",\\\"value\\\":\\\"0\\\"},{\\\"label\\\":\\\"<\\\",\\\"value\\\":\\\"1\\\"},{\\\"label\\\":\\\"<=\\\",\\\"value\\\":\\\"2\\\"},{\\\"label\\\":\\\">\\\",\\\"value\\\":\\\"3\\\"},{\\\"label\\\":\\\">=\\\",\\\"value\\\":\\\"4\\\"},{\\\"label\\\":\\\"!=\\\",\\\"value\\\":\\\"5\\\"}]\",\"placeholder\":\"please select operator\",\"optionSourceType\":0,\"dataType\":0,\"inputType\":3,\"isShow\":true,\"canEdit\":true,\"isEmit\":false,\"isValidate\":false,\"valuesMap\":null,\"index\":8,\"createTime\":null,\"updateTime\":null},{\"id\":9,\"field\":\"threshold\",\"type\":\"input\",\"title\":\"$t(threshold)\",\"data\":null,\"options\":null,\"placeholder\":\"Please enter threshold, number is needed\",\"optionSourceType\":0,\"dataType\":2,\"inputType\":3,\"isShow\":true,\"canEdit\":true,\"isEmit\":false,\"isValidate\":true,\"valuesMap\":null,\"index\":9,\"createTime\":null,\"updateTime\":null},{\"id\":10,\"field\":\"failure_strategy\",\"type\":\"select\",\"title\":\"$t(failure_strategy)\",\"data\":\"0\",\"options\":\"[{\\\"label\\\":\\\"Alert\\\",\\\"value\\\":\\\"0\\\"},{\\\"label\\\":\\\"Block\\\",\\\"value\\\":\\\"1\\\"}]\",\"placeholder\":\"please select failure strategy\",\"optionSourceType\":0,\"dataType\":0,\"inputType\":3,\"isShow\":true,\"canEdit\":true,\"isEmit\":false,\"isValidate\":false,\"valuesMap\":null,\"index\":10,\"createTime\":null,\"updateTime\":null},{\"id\":17,\"field\":\"comparison_name\",\"type\":\"input\",\"title\":\"$t(comparison_name)\",\"data\":null,\"options\":null,\"placeholder\":\"Please enter comparison name, the alias in comparison execute sql\",\"optionSourceType\":0,\"dataType\":0,\"inputType\":0,\"isShow\":false,\"canEdit\":false,\"isEmit\":false,\"isValidate\":true,\"valuesMap\":\"\",\"index\":11,\"createTime\":null,\"updateTime\":null},{\"id\":19,\"field\":\"comparison_type\",\"type\":\"select\",\"title\":\"$t(comparison_type)\",\"data\":\"\",\"options\":null,\"placeholder\":\"Please enter comparison title\",\"optionSourceType\":3,\"dataType\":0,\"inputType\":2,\"isShow\":true,\"canEdit\":false,\"isEmit\":true,\"isValidate\":false,\"valuesMap\":null,\"index\":12,\"createTime\":null,\"updateTime\":null}]",
    "executeSqlList" : "[{\"id\":6,\"index\":1,\"sql\":\"SELECT ${src_field} FROM ${src_table} group by ${src_field} having count(*) > 1\",\"tableAlias\":\"duplicate_items\",\"type\":0,\"createTime\":\"2021-03-03 11:31:24\",\"updateTime\":\"2021-03-03 11:31:24\",\"errorOutputSql\":true},{\"id\":7,\"index\":1,\"sql\":\"SELECT COUNT(*) AS duplicates FROM duplicate_items\",\"tableAlias\":\"duplicate_count\",\"type\":1,\"createTime\":\"2021-03-03 11:31:24\",\"updateTime\":\"2021-03-03 11:31:24\",\"errorOutputSql\":false}]",
    "comparisonNeedStatisticsValueTable" : false,
    "compareWithFixedValue" : true,
    "hdfsPath" : "hdfs://mycluster:8020/user/default/data_quality_error_data",
    "sourceConnectorType" : "JDBC",
    "sourceType" : 1,
    "sourceConnectionParams" : "{\"user\":\"root\",\"password\":\"root\",\"address\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432\",\"database\":\"persistence\",\"jdbcUrl\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432/persistence\",\"driverClassName\":\"org.postgresql.Driver\",\"validationQuery\":\"select version()\",\"other\":{\"password\":\"root\"}}",
    "targetConnectorType" : null,
    "targetType" : 0,
    "targetConnectionParams" : null,
    "writerConnectorType" : "JDBC",
    "writerType" : 1,
    "writerTable" : "t_ds_dq_execute_result",
    "writerConnectionParams" : "{\"user\":\"root\",\"password\":\"root\",\"address\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432\",\"database\":\"dolphinscheduler\",\"jdbcUrl\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432/dolphinscheduler\"}",
    "statisticsValueConnectorType" : "JDBC",
    "statisticsValueType" : 1,
    "statisticsValueTable" : "t_ds_dq_task_statistics_value",
    "statisticsValueWriterConnectionParams" : "{\"user\":\"root\",\"password\":\"root\",\"address\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432\",\"database\":\"dolphinscheduler\",\"jdbcUrl\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432/dolphinscheduler\"}"
  },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-1060][TI-3957] - [INFO] 2024-05-07 10:40:24.524 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-1060][TI-3957] - [INFO] 2024-05-07 10:40:24.525 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-1060][TI-3957] - [INFO] 2024-05-07 10:40:24.525 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-0][TI-0] - [INFO] 2024-05-07 10:40:24.537 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7884615384615384 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-1060][TI-3957] - [INFO] 2024-05-07 10:40:24.661 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-1060][TI-3957] - [INFO] 2024-05-07 10:40:24.684 +0800 o.a.d.c.u.OSUtils:[231] - create linux os user: default
[WI-1060][TI-3957] - [INFO] 2024-05-07 10:40:24.684 +0800 o.a.d.c.u.OSUtils:[233] - execute cmd: sudo useradd -g root
 default
[WI-1060][TI-3957] - [INFO] 2024-05-07 10:40:24.749 +0800 o.a.d.c.u.OSUtils:[190] - create user default success
[WI-1060][TI-3957] - [INFO] 2024-05-07 10:40:24.750 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-1060][TI-3957] - [INFO] 2024-05-07 10:40:24.755 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13001194483488/13505298546272_21/1060/3957 check successfully
[WI-1060][TI-3957] - [INFO] 2024-05-07 10:40:24.758 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.dq.DataQualityTaskChannel successfully
[WI-1060][TI-3957] - [INFO] 2024-05-07 10:40:24.769 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-1060][TI-3957] - [INFO] 2024-05-07 10:40:24.778 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-1060][TI-3957] - [INFO] 2024-05-07 10:40:24.781 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: DATA_QUALITY create successfully
[WI-1060][TI-3957] - [INFO] 2024-05-07 10:40:24.786 +0800 o.a.d.p.t.d.DataQualityTask:[89] - Initialize data quality task params {
  "localParams" : [ ],
  "varPool" : null,
  "ruleId" : 6,
  "ruleInputParameter" : {
    "check_type" : "0",
    "comparison_type" : "1",
    "comparison_name" : "0",
    "failure_strategy" : "0",
    "operator" : "0",
    "src_connector_type" : "1",
    "src_datasource_id" : "6",
    "src_database" : "persistence",
    "src_field" : "content",
    "src_table" : "filtered_data_persistence",
    "threshold" : "0"
  },
  "sparkParameters" : {
    "localParams" : null,
    "varPool" : null,
    "mainJar" : null,
    "mainClass" : null,
    "deployMode" : "local",
    "mainArgs" : null,
    "driverCores" : 1,
    "driverMemory" : "512M",
    "numExecutors" : 1,
    "executorCores" : 1,
    "executorMemory" : "1G",
    "appName" : null,
    "yarnQueue" : "",
    "others" : "--conf spark.driver.extraJavaOptions=\"-Divy.cache.dir=/tmp -Divy.home=/tmp\" \\\n--packages org.postgresql:postgresql:42.7.3",
    "programType" : null,
    "resourceList" : [ ]
  }
}
[WI-1060][TI-3957] - [INFO] 2024-05-07 10:40:24.818 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: HANA
[WI-1060][TI-3957] - [INFO] 2024-05-07 10:40:24.818 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: HANA
[WI-1060][TI-3957] - [INFO] 2024-05-07 10:40:24.820 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: SQLSERVER
[WI-1060][TI-3957] - [INFO] 2024-05-07 10:40:24.820 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: SQLSERVER
[WI-1060][TI-3957] - [INFO] 2024-05-07 10:40:24.821 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: SAGEMAKER
[WI-1060][TI-3957] - [INFO] 2024-05-07 10:40:24.822 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: SAGEMAKER
[WI-1060][TI-3957] - [INFO] 2024-05-07 10:40:24.823 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: DATABEND
[WI-1060][TI-3957] - [INFO] 2024-05-07 10:40:24.823 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: DATABEND
[WI-1060][TI-3957] - [INFO] 2024-05-07 10:40:24.862 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: AZURESQL
[WI-1060][TI-3957] - [INFO] 2024-05-07 10:40:24.863 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: AZURESQL
[WI-1060][TI-3957] - [INFO] 2024-05-07 10:40:24.866 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: HIVE
[WI-1060][TI-3957] - [INFO] 2024-05-07 10:40:24.866 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: HIVE
[WI-1060][TI-3957] - [INFO] 2024-05-07 10:40:24.871 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: DORIS
[WI-1060][TI-3957] - [INFO] 2024-05-07 10:40:24.871 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: DORIS
[WI-1060][TI-3957] - [INFO] 2024-05-07 10:40:24.873 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: POSTGRESQL
[WI-1060][TI-3957] - [INFO] 2024-05-07 10:40:24.873 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: POSTGRESQL
[WI-1060][TI-3957] - [INFO] 2024-05-07 10:40:24.876 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: MYSQL
[WI-1060][TI-3957] - [INFO] 2024-05-07 10:40:24.876 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: MYSQL
[WI-1060][TI-3957] - [INFO] 2024-05-07 10:40:24.878 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: REDSHIFT
[WI-1060][TI-3957] - [INFO] 2024-05-07 10:40:24.879 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: REDSHIFT
[WI-1060][TI-3957] - [INFO] 2024-05-07 10:40:24.881 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: SNOWFLAKE
[WI-1060][TI-3957] - [INFO] 2024-05-07 10:40:24.881 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: SNOWFLAKE
[WI-1060][TI-3957] - [INFO] 2024-05-07 10:40:24.884 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: STARROCKS
[WI-1060][TI-3957] - [INFO] 2024-05-07 10:40:24.884 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: STARROCKS
[WI-1060][TI-3957] - [INFO] 2024-05-07 10:40:24.886 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: SSH
[WI-1060][TI-3957] - [INFO] 2024-05-07 10:40:24.886 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: SSH
[WI-1060][TI-3957] - [INFO] 2024-05-07 10:40:24.889 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: ATHENA
[WI-1060][TI-3957] - [INFO] 2024-05-07 10:40:24.889 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: ATHENA
[WI-1060][TI-3957] - [INFO] 2024-05-07 10:40:24.891 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: PRESTO
[WI-1060][TI-3957] - [INFO] 2024-05-07 10:40:24.892 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: PRESTO
[WI-1060][TI-3957] - [INFO] 2024-05-07 10:40:24.894 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: OCEANBASE
[WI-1060][TI-3957] - [INFO] 2024-05-07 10:40:24.895 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: OCEANBASE
[WI-1060][TI-3957] - [INFO] 2024-05-07 10:40:24.928 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: ORACLE
[WI-1060][TI-3957] - [INFO] 2024-05-07 10:40:24.929 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: ORACLE
[WI-1060][TI-3957] - [INFO] 2024-05-07 10:40:24.934 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: CLICKHOUSE
[WI-1060][TI-3957] - [INFO] 2024-05-07 10:40:24.934 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: CLICKHOUSE
[WI-1060][TI-3957] - [INFO] 2024-05-07 10:40:24.938 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: VERTICA
[WI-1060][TI-3957] - [INFO] 2024-05-07 10:40:24.940 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: VERTICA
[WI-1060][TI-3957] - [INFO] 2024-05-07 10:40:24.944 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: KYUUBI
[WI-1060][TI-3957] - [INFO] 2024-05-07 10:40:24.945 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: KYUUBI
[WI-1060][TI-3957] - [INFO] 2024-05-07 10:40:24.950 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: DB2
[WI-1060][TI-3957] - [INFO] 2024-05-07 10:40:24.950 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: DB2
[WI-1060][TI-3957] - [INFO] 2024-05-07 10:40:24.955 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: TRINO
[WI-1060][TI-3957] - [INFO] 2024-05-07 10:40:24.956 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: TRINO
[WI-1060][TI-3957] - [INFO] 2024-05-07 10:40:24.960 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: SPARK
[WI-1060][TI-3957] - [INFO] 2024-05-07 10:40:24.960 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: SPARK
[WI-1060][TI-3957] - [INFO] 2024-05-07 10:40:24.963 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: DAMENG
[WI-1060][TI-3957] - [INFO] 2024-05-07 10:40:24.964 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: DAMENG
[WI-1060][TI-3957] - [INFO] 2024-05-07 10:40:24.967 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: ZEPPELIN
[WI-1060][TI-3957] - [INFO] 2024-05-07 10:40:24.967 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: ZEPPELIN
[WI-1060][TI-3957] - [INFO] 2024-05-07 10:40:24.989 +0800 o.a.d.p.t.d.DataQualityTask:[119] - data quality configuration: {
  "name" : "$t(uniqueness_check)",
  "env" : {
    "type" : "batch",
    "config" : null
  },
  "readers" : [ {
    "type" : "JDBC",
    "config" : {
      "database" : "persistence",
      "password" : "root",
      "driver" : "org.postgresql.Driver",
      "user" : "root",
      "output_table" : "persistence_filtered_data_persistence",
      "table" : "filtered_data_persistence",
      "url" : "jdbc:postgresql://dolphinscheduler-postgresql:5432/persistence?password=root"
    }
  } ],
  "transformers" : [ {
    "type" : "sql",
    "config" : {
      "index" : 1,
      "output_table" : "duplicate_items",
      "sql" : "SELECT content FROM persistence_filtered_data_persistence group by content having count(*) > 1"
    }
  }, {
    "type" : "sql",
    "config" : {
      "index" : 2,
      "output_table" : "duplicate_count",
      "sql" : "SELECT COUNT(*) AS duplicates FROM duplicate_items"
    }
  } ],
  "writers" : [ {
    "type" : "JDBC",
    "config" : {
      "database" : "dolphinscheduler",
      "password" : "root",
      "driver" : "org.postgresql.Driver",
      "user" : "root",
      "table" : "t_ds_dq_execute_result",
      "url" : "jdbc:postgresql://dolphinscheduler-postgresql:5432/dolphinscheduler",
      "sql" : "select 0 as rule_type,'$t(uniqueness_check)' as rule_name,0 as process_definition_id,1060 as process_instance_id,3957 as task_instance_id,duplicate_count.duplicates AS statistics_value,0 AS comparison_value,1 AS comparison_type,0 as check_type,0 as threshold,0 as operator,0 as failure_strategy,'hdfs://mycluster:8020/user/default/data_quality_error_data/0_1060_[null check] filtered data persistence' as error_output_path,'2024-05-07 10:40:24' as create_time,'2024-05-07 10:40:24' as update_time from duplicate_count "
    }
  }, {
    "type" : "JDBC",
    "config" : {
      "database" : "dolphinscheduler",
      "password" : "root",
      "driver" : "org.postgresql.Driver",
      "user" : "root",
      "table" : "t_ds_dq_task_statistics_value",
      "url" : "jdbc:postgresql://dolphinscheduler-postgresql:5432/dolphinscheduler",
      "sql" : "select 0 as process_definition_id,3957 as task_instance_id,6 as rule_id,'KA0AXXWVHWW+GZX4BPZXFGFZ0F0OYMUQ+BVYG4+ZIKG=' as unique_code,'duplicate_count.duplicates'AS statistics_name,duplicate_count.duplicates AS statistics_value,'2024-05-07 10:40:24' as data_time,'2024-05-07 10:40:24' as create_time,'2024-05-07 10:40:24' as update_time from duplicate_count"
    }
  }, {
    "type" : "hdfs_file",
    "config" : {
      "path" : "hdfs://mycluster:8020/user/default/data_quality_error_data/0_1060_[null check] filtered data persistence",
      "input_table" : "duplicate_items"
    }
  } ]
}
[WI-1060][TI-3957] - [INFO] 2024-05-07 10:40:24.995 +0800 o.a.d.p.d.a.u.CommonUtils:[136] - Trying to get data quality jar in path
[WI-1060][TI-3957] - [INFO] 2024-05-07 10:40:24.995 +0800 o.a.d.p.d.a.u.CommonUtils:[147] - data quality jar path is empty, will try to auto discover it from build-in rules.
[WI-1060][TI-3957] - [INFO] 2024-05-07 10:40:24.996 +0800 o.a.d.p.d.a.u.CommonUtils:[187] - Try to get data quality jar from path /opt/dolphinscheduler/conf/../libs
[WI-1060][TI-3957] - [INFO] 2024-05-07 10:40:24.998 +0800 o.a.d.p.d.a.u.CommonUtils:[182] - get default data quality jar name: /opt/dolphinscheduler/conf/../libs/dolphinscheduler-data-quality-3.2.1.jar
[WI-1060][TI-3957] - [INFO] 2024-05-07 10:40:24.998 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-1060][TI-3957] - [INFO] 2024-05-07 10:40:24.998 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: null successfully
[WI-1060][TI-3957] - [INFO] 2024-05-07 10:40:25.002 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-1060][TI-3957] - [INFO] 2024-05-07 10:40:25.002 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-1060][TI-3957] - [INFO] 2024-05-07 10:40:25.002 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-1060][TI-3957] - [INFO] 2024-05-07 10:40:25.010 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-1060][TI-3957] - [INFO] 2024-05-07 10:40:25.010 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-1060][TI-3957] - [INFO] 2024-05-07 10:40:25.010 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export PYSPARK_DRIVER_PYTHON=/bin/python3.11
export PYSPARK_PYTHON=/bin/python3.11
${SPARK_HOME}/bin/spark-submit --master local --driver-cores 1 --driver-memory 512M --num-executors 1 --executor-cores 1 --executor-memory 1G --conf spark.driver.extraJavaOptions="-Divy.cache.dir=/tmp -Divy.home=/tmp" \
--packages org.postgresql:postgresql:42.7.3 /opt/dolphinscheduler/conf/../libs/dolphinscheduler-data-quality-3.2.1.jar "{\"name\":\"$t(uniqueness_check)\",\"env\":{\"type\":\"batch\",\"config\":null},\"readers\":[{\"type\":\"JDBC\",\"config\":{\"database\":\"persistence\",\"password\":\"root\",\"driver\":\"org.postgresql.Driver\",\"user\":\"root\",\"output_table\":\"persistence_filtered_data_persistence\",\"table\":\"filtered_data_persistence\",\"url\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432/persistence?password=root\"} }],\"transformers\":[{\"type\":\"sql\",\"config\":{\"index\":1,\"output_table\":\"duplicate_items\",\"sql\":\"SELECT content FROM persistence_filtered_data_persistence group by content having count(*) > 1\"} },{\"type\":\"sql\",\"config\":{\"index\":2,\"output_table\":\"duplicate_count\",\"sql\":\"SELECT COUNT(*) AS duplicates FROM duplicate_items\"} }],\"writers\":[{\"type\":\"JDBC\",\"config\":{\"database\":\"dolphinscheduler\",\"password\":\"root\",\"driver\":\"org.postgresql.Driver\",\"user\":\"root\",\"table\":\"t_ds_dq_execute_result\",\"url\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432/dolphinscheduler\",\"sql\":\"select 0 as rule_type,'$t(uniqueness_check)' as rule_name,0 as process_definition_id,1060 as process_instance_id,3957 as task_instance_id,duplicate_count.duplicates AS statistics_value,0 AS comparison_value,1 AS comparison_type,0 as check_type,0 as threshold,0 as operator,0 as failure_strategy,'hdfs://mycluster:8020/user/default/data_quality_error_data/0_1060_[null check] filtered data persistence' as error_output_path,'2024-05-07 10:40:24' as create_time,'2024-05-07 10:40:24' as update_time from duplicate_count \"} },{\"type\":\"JDBC\",\"config\":{\"database\":\"dolphinscheduler\",\"password\":\"root\",\"driver\":\"org.postgresql.Driver\",\"user\":\"root\",\"table\":\"t_ds_dq_task_statistics_value\",\"url\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432/dolphinscheduler\",\"sql\":\"select 0 as process_definition_id,3957 as task_instance_id,6 as rule_id,'KA0AXXWVHWW+GZX4BPZXFGFZ0F0OYMUQ+BVYG4+ZIKG=' as unique_code,'duplicate_count.duplicates'AS statistics_name,duplicate_count.duplicates AS statistics_value,'2024-05-07 10:40:24' as data_time,'2024-05-07 10:40:24' as create_time,'2024-05-07 10:40:24' as update_time from duplicate_count\"} },{\"type\":\"hdfs_file\",\"config\":{\"path\":\"hdfs://mycluster:8020/user/default/data_quality_error_data/0_1060_[null check] filtered data persistence\",\"input_table\":\"duplicate_items\"} }]}"
[WI-1060][TI-3957] - [INFO] 2024-05-07 10:40:25.011 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-1060][TI-3957] - [INFO] 2024-05-07 10:40:25.013 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13001194483488/13505298546272_21/1060/3957/1060_3957.sh
[WI-1060][TI-3957] - [INFO] 2024-05-07 10:40:25.021 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 93
[WI-0][TI-3957] - [INFO] 2024-05-07 10:40:25.497 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=3957, success=true)
[WI-0][TI-0] - [INFO] 2024-05-07 10:40:25.560 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.716931216931217 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-3957] - [INFO] 2024-05-07 10:40:25.588 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=3957)
[WI-0][TI-0] - [INFO] 2024-05-07 10:40:26.024 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
[WI-0][TI-0] - [INFO] 2024-05-07 10:40:26.579 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7747747747747747 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:40:27.584 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7924528301886793 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:40:29.031 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	:: loading settings :: url = jar:file:/opt/spark-3.5.1-bin-hadoop3/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml
	Ivy Default Cache set to: /tmp
	The jars for the packages stored in: /tmp/jars
	org.postgresql#postgresql added as a dependency
	:: resolving dependencies :: org.apache.spark#spark-submit-parent-12ce2a5d-f6dc-4c79-81ee-a4f1f063ecf0;1.0
		confs: [default]
[WI-0][TI-0] - [INFO] 2024-05-07 10:40:30.032 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
		found org.postgresql#postgresql;42.7.3 in central
[WI-0][TI-0] - [INFO] 2024-05-07 10:40:31.033 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
		found org.checkerframework#checker-qual;3.42.0 in central
	downloading https://repo1.maven.org/maven2/org/postgresql/postgresql/42.7.3/postgresql-42.7.3.jar ...
[WI-0][TI-0] - [INFO] 2024-05-07 10:40:31.608 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8857142857142857 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:40:32.621 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9045092838196286 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:40:33.629 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8265582655826558 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:40:34.630 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.709141274238227 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:40:37.038 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
		[SUCCESSFUL ] org.postgresql#postgresql;42.7.3!postgresql.jar (6816ms)
[WI-0][TI-0] - [INFO] 2024-05-07 10:40:38.059 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	downloading https://repo1.maven.org/maven2/org/checkerframework/checker-qual/3.42.0/checker-qual-3.42.0.jar ...
[WI-0][TI-0] - [INFO] 2024-05-07 10:40:39.062 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
		[SUCCESSFUL ] org.checkerframework#checker-qual;3.42.0!checker-qual.jar (1967ms)
	:: resolution report :: resolve 1952ms :: artifacts dl 8792ms
		:: modules in use:
		org.checkerframework#checker-qual;3.42.0 from central in [default]
		org.postgresql#postgresql;42.7.3 from central in [default]
		---------------------------------------------------------------------
		|                  |            modules            ||   artifacts   |
		|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
		---------------------------------------------------------------------
		|      default     |   2   |   2   |   2   |   0   ||   2   |   2   |
		---------------------------------------------------------------------
	:: retrieving :: org.apache.spark#spark-submit-parent-12ce2a5d-f6dc-4c79-81ee-a4f1f063ecf0
		confs: [default]
		2 artifacts copied, 0 already retrieved (1289kB/8ms)
[WI-0][TI-0] - [INFO] 2024-05-07 10:40:40.064 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:40:39 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
	24/05/07 10:40:39 INFO SparkContext: Running Spark version 3.5.1
	24/05/07 10:40:39 INFO SparkContext: OS info Linux, 6.5.0-28-generic, amd64
	24/05/07 10:40:39 INFO SparkContext: Java version 1.8.0_402
	24/05/07 10:40:39 INFO ResourceUtils: ==============================================================
	24/05/07 10:40:39 INFO ResourceUtils: No custom resources configured for spark.driver.
	24/05/07 10:40:39 INFO ResourceUtils: ==============================================================
	24/05/07 10:40:39 INFO SparkContext: Submitted application: (uniqueness_check)
	24/05/07 10:40:39 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
	24/05/07 10:40:39 INFO ResourceProfile: Limiting resource is cpu
	24/05/07 10:40:39 INFO ResourceProfileManager: Added ResourceProfile id: 0
	24/05/07 10:40:40 INFO SecurityManager: Changing view acls to: default
	24/05/07 10:40:40 INFO SecurityManager: Changing modify acls to: default
	24/05/07 10:40:40 INFO SecurityManager: Changing view acls groups to: 
	24/05/07 10:40:40 INFO SecurityManager: Changing modify acls groups to: 
	24/05/07 10:40:40 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: default; groups with view permissions: EMPTY; users with modify permissions: default; groups with modify permissions: EMPTY
[WI-0][TI-0] - [INFO] 2024-05-07 10:40:41.067 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:40:40 INFO Utils: Successfully started service 'sparkDriver' on port 41023.
	24/05/07 10:40:40 INFO SparkEnv: Registering MapOutputTracker
	24/05/07 10:40:40 INFO SparkEnv: Registering BlockManagerMaster
	24/05/07 10:40:40 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
	24/05/07 10:40:40 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
	24/05/07 10:40:40 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
	24/05/07 10:40:40 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-5ac5647b-0bea-48f9-a828-bdaaf4b0a41e
	24/05/07 10:40:40 INFO MemoryStore: MemoryStore started with capacity 93.3 MiB
	24/05/07 10:40:40 INFO SparkEnv: Registering OutputCommitCoordinator
	24/05/07 10:40:40 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
	24/05/07 10:40:40 INFO Utils: Successfully started service 'SparkUI' on port 4040.
	24/05/07 10:40:40 INFO SparkContext: Added JAR file:///tmp/jars/org.postgresql_postgresql-42.7.3.jar at spark://27ccc46d6f5e:41023/jars/org.postgresql_postgresql-42.7.3.jar with timestamp 1715049639862
	24/05/07 10:40:40 INFO SparkContext: Added JAR file:///tmp/jars/org.checkerframework_checker-qual-3.42.0.jar at spark://27ccc46d6f5e:41023/jars/org.checkerframework_checker-qual-3.42.0.jar with timestamp 1715049639862
	24/05/07 10:40:40 INFO SparkContext: Added JAR file:/opt/dolphinscheduler/libs/dolphinscheduler-data-quality-3.2.1.jar at spark://27ccc46d6f5e:41023/jars/dolphinscheduler-data-quality-3.2.1.jar with timestamp 1715049639862
	24/05/07 10:40:40 INFO Executor: Starting executor ID driver on host 27ccc46d6f5e
	24/05/07 10:40:40 INFO Executor: OS info Linux, 6.5.0-28-generic, amd64
	24/05/07 10:40:40 INFO Executor: Java version 1.8.0_402
	24/05/07 10:40:40 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
	24/05/07 10:40:40 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@358ab600 for default.
	24/05/07 10:40:40 INFO Executor: Fetching spark://27ccc46d6f5e:41023/jars/org.checkerframework_checker-qual-3.42.0.jar with timestamp 1715049639862
	24/05/07 10:40:40 INFO TransportClientFactory: Successfully created connection to 27ccc46d6f5e/172.18.1.1:41023 after 41 ms (0 ms spent in bootstraps)
	24/05/07 10:40:40 INFO Utils: Fetching spark://27ccc46d6f5e:41023/jars/org.checkerframework_checker-qual-3.42.0.jar to /tmp/spark-6c2eea89-5784-47f3-8127-e41c6cf0be9a/userFiles-b54dfc55-3667-442b-96ed-79209e083458/fetchFileTemp6723324581467545183.tmp
	24/05/07 10:40:41 INFO Executor: Adding file:/tmp/spark-6c2eea89-5784-47f3-8127-e41c6cf0be9a/userFiles-b54dfc55-3667-442b-96ed-79209e083458/org.checkerframework_checker-qual-3.42.0.jar to class loader default
	24/05/07 10:40:41 INFO Executor: Fetching spark://27ccc46d6f5e:41023/jars/dolphinscheduler-data-quality-3.2.1.jar with timestamp 1715049639862
	24/05/07 10:40:41 INFO Utils: Fetching spark://27ccc46d6f5e:41023/jars/dolphinscheduler-data-quality-3.2.1.jar to /tmp/spark-6c2eea89-5784-47f3-8127-e41c6cf0be9a/userFiles-b54dfc55-3667-442b-96ed-79209e083458/fetchFileTemp1509613850018495373.tmp
	24/05/07 10:40:41 INFO Executor: Adding file:/tmp/spark-6c2eea89-5784-47f3-8127-e41c6cf0be9a/userFiles-b54dfc55-3667-442b-96ed-79209e083458/dolphinscheduler-data-quality-3.2.1.jar to class loader default
	24/05/07 10:40:41 INFO Executor: Fetching spark://27ccc46d6f5e:41023/jars/org.postgresql_postgresql-42.7.3.jar with timestamp 1715049639862
[WI-0][TI-0] - [INFO] 2024-05-07 10:40:42.069 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:40:41 INFO Utils: Fetching spark://27ccc46d6f5e:41023/jars/org.postgresql_postgresql-42.7.3.jar to /tmp/spark-6c2eea89-5784-47f3-8127-e41c6cf0be9a/userFiles-b54dfc55-3667-442b-96ed-79209e083458/fetchFileTemp10179718841733301.tmp
	24/05/07 10:40:41 INFO Executor: Adding file:/tmp/spark-6c2eea89-5784-47f3-8127-e41c6cf0be9a/userFiles-b54dfc55-3667-442b-96ed-79209e083458/org.postgresql_postgresql-42.7.3.jar to class loader default
	24/05/07 10:40:41 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42757.
	24/05/07 10:40:41 INFO NettyBlockTransferService: Server created on 27ccc46d6f5e:42757
	24/05/07 10:40:41 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
	24/05/07 10:40:41 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 27ccc46d6f5e, 42757, None)
	24/05/07 10:40:41 INFO BlockManagerMasterEndpoint: Registering block manager 27ccc46d6f5e:42757 with 93.3 MiB RAM, BlockManagerId(driver, 27ccc46d6f5e, 42757, None)
	24/05/07 10:40:41 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 27ccc46d6f5e, 42757, None)
	24/05/07 10:40:41 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 27ccc46d6f5e, 42757, None)
	24/05/07 10:40:41 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
	24/05/07 10:40:41 INFO SharedState: Warehouse path is 'file:/tmp/dolphinscheduler/exec/process/default/13001194483488/13505298546272_21/1060/3957/spark-warehouse'.
[WI-0][TI-0] - [INFO] 2024-05-07 10:40:46.194 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:40:46 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
[WI-0][TI-0] - [INFO] 2024-05-07 10:40:47.195 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:40:46 INFO CodeGenerator: Code generated in 379.339448 ms
[WI-0][TI-0] - [INFO] 2024-05-07 10:40:48.201 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:40:47 INFO DAGScheduler: Registering RDD 2 (save at JdbcWriter.java:87) as input to shuffle 0
	24/05/07 10:40:47 INFO DAGScheduler: Got map stage job 0 (save at JdbcWriter.java:87) with 1 output partitions
	24/05/07 10:40:47 INFO DAGScheduler: Final stage: ShuffleMapStage 0 (save at JdbcWriter.java:87)
	24/05/07 10:40:47 INFO DAGScheduler: Parents of final stage: List()
	24/05/07 10:40:47 INFO DAGScheduler: Missing parents: List()
	24/05/07 10:40:47 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[2] at save at JdbcWriter.java:87), which has no missing parents
	24/05/07 10:40:47 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 34.8 KiB, free 93.3 MiB)
	24/05/07 10:40:47 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 16.4 KiB, free 93.2 MiB)
	24/05/07 10:40:47 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 27ccc46d6f5e:42757 (size: 16.4 KiB, free: 93.3 MiB)
	24/05/07 10:40:47 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1585
	24/05/07 10:40:47 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[2] at save at JdbcWriter.java:87) (first 15 tasks are for partitions Vector(0))
	24/05/07 10:40:47 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
	24/05/07 10:40:47 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (27ccc46d6f5e, executor driver, partition 0, PROCESS_LOCAL, 7878 bytes) 
	24/05/07 10:40:47 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
	24/05/07 10:40:48 INFO CodeGenerator: Code generated in 81.681548 ms
	24/05/07 10:40:48 INFO CodeGenerator: Code generated in 16.433592 ms
	24/05/07 10:40:48 INFO CodeGenerator: Code generated in 8.077083 ms
	24/05/07 10:40:48 INFO CodeGenerator: Code generated in 11.685382 ms
	24/05/07 10:40:48 INFO CodeGenerator: Code generated in 6.423588 ms
	24/05/07 10:40:48 INFO JDBCRDD: closed connection
[WI-0][TI-0] - [INFO] 2024-05-07 10:40:48.746 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7808219178082192 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:40:49.203 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:40:48 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 2491 bytes result sent to driver
	24/05/07 10:40:48 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 752 ms on 27ccc46d6f5e (executor driver) (1/1)
	24/05/07 10:40:48 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
	24/05/07 10:40:48 INFO DAGScheduler: ShuffleMapStage 0 (save at JdbcWriter.java:87) finished in 1.071 s
	24/05/07 10:40:48 INFO DAGScheduler: looking for newly runnable stages
	24/05/07 10:40:48 INFO DAGScheduler: running: Set()
	24/05/07 10:40:48 INFO DAGScheduler: waiting: Set()
	24/05/07 10:40:48 INFO DAGScheduler: failed: Set()
	24/05/07 10:40:48 INFO ShufflePartitionsUtil: For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
	24/05/07 10:40:48 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
	24/05/07 10:40:48 INFO CodeGenerator: Code generated in 37.367916 ms
	24/05/07 10:40:48 INFO DAGScheduler: Registering RDD 5 (save at JdbcWriter.java:87) as input to shuffle 1
	24/05/07 10:40:48 INFO DAGScheduler: Got map stage job 1 (save at JdbcWriter.java:87) with 1 output partitions
	24/05/07 10:40:48 INFO DAGScheduler: Final stage: ShuffleMapStage 2 (save at JdbcWriter.java:87)
	24/05/07 10:40:48 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
	24/05/07 10:40:48 INFO DAGScheduler: Missing parents: List()
	24/05/07 10:40:48 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[5] at save at JdbcWriter.java:87), which has no missing parents
	24/05/07 10:40:48 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 40.5 KiB, free 93.2 MiB)
	24/05/07 10:40:48 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 19.1 KiB, free 93.2 MiB)
	24/05/07 10:40:48 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 27ccc46d6f5e:42757 (size: 19.1 KiB, free: 93.3 MiB)
	24/05/07 10:40:48 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1585
	24/05/07 10:40:48 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[5] at save at JdbcWriter.java:87) (first 15 tasks are for partitions Vector(0))
	24/05/07 10:40:48 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
	24/05/07 10:40:48 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 1) (27ccc46d6f5e, executor driver, partition 0, NODE_LOCAL, 8032 bytes) 
	24/05/07 10:40:48 INFO Executor: Running task 0.0 in stage 2.0 (TID 1)
	24/05/07 10:40:48 INFO ShuffleBlockFetcherIterator: Getting 1 (2.9 KiB) non-empty blocks including 1 (2.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
	24/05/07 10:40:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 22 ms
	24/05/07 10:40:48 INFO CodeGenerator: Code generated in 41.20961 ms
	24/05/07 10:40:48 INFO Executor: Finished task 0.0 in stage 2.0 (TID 1). 5463 bytes result sent to driver
	24/05/07 10:40:48 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 27ccc46d6f5e:42757 in memory (size: 16.4 KiB, free: 93.3 MiB)
	24/05/07 10:40:48 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 1) in 170 ms on 27ccc46d6f5e (executor driver) (1/1)
	24/05/07 10:40:48 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
	24/05/07 10:40:48 INFO DAGScheduler: ShuffleMapStage 2 (save at JdbcWriter.java:87) finished in 0.196 s
	24/05/07 10:40:48 INFO DAGScheduler: looking for newly runnable stages
	24/05/07 10:40:48 INFO DAGScheduler: running: Set()
	24/05/07 10:40:48 INFO DAGScheduler: waiting: Set()
	24/05/07 10:40:48 INFO DAGScheduler: failed: Set()
	24/05/07 10:40:48 INFO CodeGenerator: Code generated in 24.67396 ms
	24/05/07 10:40:48 INFO SparkContext: Starting job: save at JdbcWriter.java:87
	24/05/07 10:40:48 INFO DAGScheduler: Got job 2 (save at JdbcWriter.java:87) with 1 output partitions
	24/05/07 10:40:48 INFO DAGScheduler: Final stage: ResultStage 5 (save at JdbcWriter.java:87)
	24/05/07 10:40:48 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
	24/05/07 10:40:48 INFO DAGScheduler: Missing parents: List()
	24/05/07 10:40:49 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[10] at save at JdbcWriter.java:87), which has no missing parents
	24/05/07 10:40:49 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 51.4 KiB, free 93.2 MiB)
	24/05/07 10:40:49 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 23.1 KiB, free 93.2 MiB)
	24/05/07 10:40:49 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 27ccc46d6f5e:42757 (size: 23.1 KiB, free: 93.3 MiB)
	24/05/07 10:40:49 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1585
	24/05/07 10:40:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[10] at save at JdbcWriter.java:87) (first 15 tasks are for partitions Vector(0))
	24/05/07 10:40:49 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
	24/05/07 10:40:49 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 2) (27ccc46d6f5e, executor driver, partition 0, NODE_LOCAL, 8043 bytes) 
	24/05/07 10:40:49 INFO Executor: Running task 0.0 in stage 5.0 (TID 2)
[WI-0][TI-0] - [INFO] 2024-05-07 10:40:50.206 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:40:49 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
	24/05/07 10:40:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
	24/05/07 10:40:49 INFO CodeGenerator: Code generated in 10.466982 ms
	24/05/07 10:40:49 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 27ccc46d6f5e:42757 in memory (size: 19.1 KiB, free: 93.3 MiB)
[WI-0][TI-0] - [INFO] 2024-05-07 10:40:51.209 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:40:50 INFO CodeGenerator: Code generated in 15.60294 ms
	24/05/07 10:40:50 INFO Executor: Finished task 0.0 in stage 5.0 (TID 2). 6668 bytes result sent to driver
	24/05/07 10:40:50 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 2) in 1507 ms on 27ccc46d6f5e (executor driver) (1/1)
	24/05/07 10:40:50 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
	24/05/07 10:40:50 INFO DAGScheduler: ResultStage 5 (save at JdbcWriter.java:87) finished in 1.581 s
	24/05/07 10:40:50 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
	24/05/07 10:40:50 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
	24/05/07 10:40:50 INFO DAGScheduler: Job 2 finished: save at JdbcWriter.java:87, took 1.610983 s
	24/05/07 10:40:50 INFO DAGScheduler: Registering RDD 13 (save at JdbcWriter.java:87) as input to shuffle 2
	24/05/07 10:40:50 INFO DAGScheduler: Got map stage job 3 (save at JdbcWriter.java:87) with 1 output partitions
	24/05/07 10:40:50 INFO DAGScheduler: Final stage: ShuffleMapStage 6 (save at JdbcWriter.java:87)
	24/05/07 10:40:50 INFO DAGScheduler: Parents of final stage: List()
	24/05/07 10:40:50 INFO DAGScheduler: Missing parents: List()
	24/05/07 10:40:50 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[13] at save at JdbcWriter.java:87), which has no missing parents
	24/05/07 10:40:50 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 34.8 KiB, free 93.2 MiB)
	24/05/07 10:40:50 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 16.5 KiB, free 93.2 MiB)
	24/05/07 10:40:50 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 27ccc46d6f5e:42757 (size: 16.5 KiB, free: 93.3 MiB)
	24/05/07 10:40:50 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1585
	24/05/07 10:40:50 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[13] at save at JdbcWriter.java:87) (first 15 tasks are for partitions Vector(0))
	24/05/07 10:40:50 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0
	24/05/07 10:40:50 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 3) (27ccc46d6f5e, executor driver, partition 0, PROCESS_LOCAL, 7878 bytes) 
	24/05/07 10:40:50 INFO Executor: Running task 0.0 in stage 6.0 (TID 3)
	24/05/07 10:40:50 INFO JDBCRDD: closed connection
	24/05/07 10:40:50 INFO Executor: Finished task 0.0 in stage 6.0 (TID 3). 2448 bytes result sent to driver
	24/05/07 10:40:50 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 3) in 105 ms on 27ccc46d6f5e (executor driver) (1/1)
	24/05/07 10:40:50 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
	24/05/07 10:40:50 INFO DAGScheduler: ShuffleMapStage 6 (save at JdbcWriter.java:87) finished in 0.122 s
	24/05/07 10:40:50 INFO DAGScheduler: looking for newly runnable stages
	24/05/07 10:40:50 INFO DAGScheduler: running: Set()
	24/05/07 10:40:50 INFO DAGScheduler: waiting: Set()
	24/05/07 10:40:50 INFO DAGScheduler: failed: Set()
	24/05/07 10:40:50 INFO ShufflePartitionsUtil: For shuffle(2), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
	24/05/07 10:40:50 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
	24/05/07 10:40:51 INFO DAGScheduler: Registering RDD 16 (save at JdbcWriter.java:87) as input to shuffle 3
	24/05/07 10:40:51 INFO DAGScheduler: Got map stage job 4 (save at JdbcWriter.java:87) with 1 output partitions
	24/05/07 10:40:51 INFO DAGScheduler: Final stage: ShuffleMapStage 8 (save at JdbcWriter.java:87)
	24/05/07 10:40:51 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
	24/05/07 10:40:51 INFO DAGScheduler: Missing parents: List()
	24/05/07 10:40:51 INFO DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[16] at save at JdbcWriter.java:87), which has no missing parents
	24/05/07 10:40:51 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 40.6 KiB, free 93.1 MiB)
	24/05/07 10:40:51 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 19.1 KiB, free 93.1 MiB)
	24/05/07 10:40:51 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 27ccc46d6f5e:42757 (size: 19.1 KiB, free: 93.2 MiB)
	24/05/07 10:40:51 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1585
	24/05/07 10:40:51 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[16] at save at JdbcWriter.java:87) (first 15 tasks are for partitions Vector(0))
	24/05/07 10:40:51 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0
	24/05/07 10:40:51 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 4) (27ccc46d6f5e, executor driver, partition 0, NODE_LOCAL, 8032 bytes) 
	24/05/07 10:40:51 INFO Executor: Running task 0.0 in stage 8.0 (TID 4)
	24/05/07 10:40:51 INFO ShuffleBlockFetcherIterator: Getting 1 (2.9 KiB) non-empty blocks including 1 (2.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
	24/05/07 10:40:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
	24/05/07 10:40:51 INFO Executor: Finished task 0.0 in stage 8.0 (TID 4). 5420 bytes result sent to driver
	24/05/07 10:40:51 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 4) in 23 ms on 27ccc46d6f5e (executor driver) (1/1)
	24/05/07 10:40:51 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
	24/05/07 10:40:51 INFO DAGScheduler: ShuffleMapStage 8 (save at JdbcWriter.java:87) finished in 0.035 s
	24/05/07 10:40:51 INFO DAGScheduler: looking for newly runnable stages
	24/05/07 10:40:51 INFO DAGScheduler: running: Set()
	24/05/07 10:40:51 INFO DAGScheduler: waiting: Set()
	24/05/07 10:40:51 INFO DAGScheduler: failed: Set()
	24/05/07 10:40:51 INFO CodeGenerator: Code generated in 9.825507 ms
	24/05/07 10:40:51 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 27ccc46d6f5e:42757 in memory (size: 19.1 KiB, free: 93.3 MiB)
	24/05/07 10:40:51 INFO SparkContext: Starting job: save at JdbcWriter.java:87
	24/05/07 10:40:51 INFO DAGScheduler: Got job 5 (save at JdbcWriter.java:87) with 1 output partitions
	24/05/07 10:40:51 INFO DAGScheduler: Final stage: ResultStage 11 (save at JdbcWriter.java:87)
	24/05/07 10:40:51 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)
	24/05/07 10:40:51 INFO DAGScheduler: Missing parents: List()
	24/05/07 10:40:51 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[21] at save at JdbcWriter.java:87), which has no missing parents
	24/05/07 10:40:51 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 27ccc46d6f5e:42757 in memory (size: 16.5 KiB, free: 93.3 MiB)
	24/05/07 10:40:51 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 49.2 KiB, free 93.2 MiB)
	24/05/07 10:40:51 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 22.7 KiB, free 93.2 MiB)
	24/05/07 10:40:51 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 27ccc46d6f5e:42757 (size: 22.7 KiB, free: 93.3 MiB)
[WI-0][TI-0] - [INFO] 2024-05-07 10:40:52.211 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:40:51 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 5) (27ccc46d6f5e, executor driver, partition 0, NODE_LOCAL, 8043 bytes) 
	24/05/07 10:40:51 INFO Executor: Running task 0.0 in stage 11.0 (TID 5)
	24/05/07 10:40:51 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 27ccc46d6f5e:42757 in memory (size: 23.1 KiB, free: 93.3 MiB)
	24/05/07 10:40:51 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
	24/05/07 10:40:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
	24/05/07 10:40:51 INFO CodeGenerator: Code generated in 27.497311 ms
	24/05/07 10:40:51 INFO CodeGenerator: Code generated in 13.856379 ms
	24/05/07 10:40:51 INFO Executor: Finished task 0.0 in stage 11.0 (TID 5). 6625 bytes result sent to driver
	24/05/07 10:40:51 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 5) in 105 ms on 27ccc46d6f5e (executor driver) (1/1)
	24/05/07 10:40:51 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
	24/05/07 10:40:51 INFO DAGScheduler: ResultStage 11 (save at JdbcWriter.java:87) finished in 0.170 s
	24/05/07 10:40:51 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
	24/05/07 10:40:51 INFO TaskSchedulerImpl: Killing all running tasks in stage 11: Stage finished
	24/05/07 10:40:51 INFO DAGScheduler: Job 5 finished: save at JdbcWriter.java:87, took 0.189680 s
	24/05/07 10:40:51 WARN FileSystem: Failed to initialize fileystem hdfs://mycluster:8020/user/default/data_quality_error_data/0_1060_%5Bnull%20check%5D%20filtered%20data%20persistence: java.lang.IllegalArgumentException: java.net.UnknownHostException: mycluster
	Exception in thread "main" java.lang.IllegalArgumentException: java.net.UnknownHostException: mycluster
		at org.apache.hadoop.security.SecurityUtil.buildTokenService(SecurityUtil.java:466)
		at org.apache.hadoop.hdfs.NameNodeProxiesClient.createProxyWithClientProtocol(NameNodeProxiesClient.java:134)
		at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:374)
		at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:308)
		at org.apache.hadoop.hdfs.DistributedFileSystem.initDFSClient(DistributedFileSystem.java:202)
		at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:187)
		at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469)
		at org.apache.hadoop.fs.FileSystem.access$300(FileSystem.java:174)
		at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3574)
		at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3521)
		at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540)
		at org.apache.hadoop.fs.Path.getFileSystem(Path.java:365)
		at org.apache.spark.sql.execution.datasources.DataSource.planForWritingFileFormat(DataSource.scala:454)
		at org.apache.spark.sql.execution.datasources.DataSource.planForWriting(DataSource.scala:530)
		at org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)
		at org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)
		at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:240)
		at org.apache.spark.sql.DataFrameWriter.csv(DataFrameWriter.scala:850)
		at org.apache.dolphinscheduler.data.quality.flow.batch.writer.file.BaseFileWriter.outputImpl(BaseFileWriter.java:114)
		at org.apache.dolphinscheduler.data.quality.flow.batch.writer.file.HdfsFileWriter.write(HdfsFileWriter.java:40)
		at org.apache.dolphinscheduler.data.quality.execution.SparkBatchExecution.executeWriter(SparkBatchExecution.java:132)
		at org.apache.dolphinscheduler.data.quality.execution.SparkBatchExecution.execute(SparkBatchExecution.java:58)
		at org.apache.dolphinscheduler.data.quality.context.DataQualityContext.execute(DataQualityContext.java:62)
		at org.apache.dolphinscheduler.data.quality.DataQualityApplication.main(DataQualityApplication.java:78)
		at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
		at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
		at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
		at java.lang.reflect.Method.invoke(Method.java:498)
		at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
		at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:1029)
		at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:194)
		at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:217)
		at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:91)
		at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1120)
		at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1129)
		at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
	Caused by: java.net.UnknownHostException: mycluster
		... 36 more
	24/05/07 10:40:51 INFO SparkContext: Invoking stop() from shutdown hook
	24/05/07 10:40:51 INFO SparkContext: SparkContext is stopping with exitCode 0.
	24/05/07 10:40:51 INFO SparkUI: Stopped Spark web UI at http://27ccc46d6f5e:4040
	24/05/07 10:40:51 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
	24/05/07 10:40:51 INFO MemoryStore: MemoryStore cleared
	24/05/07 10:40:51 INFO BlockManager: BlockManager stopped
	24/05/07 10:40:51 INFO BlockManagerMaster: BlockManagerMaster stopped
	24/05/07 10:40:51 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
	24/05/07 10:40:51 INFO SparkContext: Successfully stopped SparkContext
	24/05/07 10:40:51 INFO ShutdownHookManager: Shutdown hook called
	24/05/07 10:40:51 INFO ShutdownHookManager: Deleting directory /tmp/spark-31f090e1-cacb-488e-9e6e-76e351a16ec9
	24/05/07 10:40:51 INFO ShutdownHookManager: Deleting directory /tmp/spark-6c2eea89-5784-47f3-8127-e41c6cf0be9a
[WI-1060][TI-3957] - [INFO] 2024-05-07 10:40:52.217 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13001194483488/13505298546272_21/1060/3957, processId:93 ,exitStatusCode:1 ,processWaitForStatus:true ,processExitValue:1
[WI-1060][TI-3957] - [INFO] 2024-05-07 10:40:52.218 +0800 o.a.d.p.t.a.u.LogUtils:[79] - Start finding appId in /opt/dolphinscheduler/logs/20240507/13505298546272/21/1060/3957.log, fetch way: log 
[WI-1060][TI-3957] - [INFO] 2024-05-07 10:40:52.221 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-1060][TI-3957] - [INFO] 2024-05-07 10:40:52.223 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-1060][TI-3957] - [INFO] 2024-05-07 10:40:52.224 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-1060][TI-3957] - [INFO] 2024-05-07 10:40:52.226 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-1060][TI-3957] - [INFO] 2024-05-07 10:40:52.246 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: FAILURE to master : 172.18.1.1:1234
[WI-1060][TI-3957] - [INFO] 2024-05-07 10:40:52.246 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-1060][TI-3957] - [INFO] 2024-05-07 10:40:52.247 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13001194483488/13505298546272_21/1060/3957
[WI-1060][TI-3957] - [INFO] 2024-05-07 10:40:52.276 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13001194483488/13505298546272_21/1060/3957
[WI-1060][TI-3957] - [INFO] 2024-05-07 10:40:52.280 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-0] - [WARN] 2024-05-07 10:44:44.617 +0800 o.s.c.k.c.p.AbstractKubernetesProfileEnvironmentPostProcessor:[258] - Not running inside kubernetes. Skipping 'kubernetes' profile activation.
[WI-0][TI-0] - [WARN] 2024-05-07 10:44:50.760 +0800 o.s.c.k.c.p.AbstractKubernetesProfileEnvironmentPostProcessor:[258] - Not running inside kubernetes. Skipping 'kubernetes' profile activation.
[WI-0][TI-0] - [INFO] 2024-05-07 10:44:50.822 +0800 o.a.d.s.w.WorkerServer:[634] - No active profile set, falling back to 1 default profile: "default"
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:00.813 +0800 o.s.c.c.s.GenericScope:[283] - BeanFactory id=7e7bf7c6-2cb3-34d2-a0d5-a56161c67d0e
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:04.177 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'org.springframework.cloud.commons.config.CommonsConfigAutoConfiguration' of type [org.springframework.cloud.commons.config.CommonsConfigAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:04.294 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'org.springframework.cloud.client.loadbalancer.LoadBalancerDefaultMappingsProviderAutoConfiguration' of type [org.springframework.cloud.client.loadbalancer.LoadBalancerDefaultMappingsProviderAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:04.370 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'loadBalancerClientsDefaultsMappingsProvider' of type [org.springframework.cloud.client.loadbalancer.LoadBalancerDefaultMappingsProviderAutoConfiguration$$Lambda$392/302905744] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:04.392 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'defaultsBindHandlerAdvisor' of type [org.springframework.cloud.commons.config.DefaultsBindHandlerAdvisor] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:04.630 +0800 o.a.d.c.u.NetUtils:[312] - Get all NetworkInterfaces: [name:eth0 (eth0), name:lo (lo)]
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:04.815 +0800 o.a.d.s.w.c.WorkerConfig:[98] - 
****************************Worker Configuration**************************************
  listen-port -> 1234
  exec-threads -> 100
  max-heartbeat-interval -> PT10S
  host-weight -> 100
  tenantConfig -> TenantConfig(autoCreateTenantEnabled=true, distributedTenantEnabled=false, defaultTenantEnabled=false)
  server-load-protection -> WorkerServerLoadProtection(enabled=true, maxCpuUsagePercentageThresholds=0.7, maxJVMMemoryUsagePercentageThresholds=0.7, maxSystemMemoryUsagePercentageThresholds=0.7, maxDiskUsagePercentageThresholds=0.7)
  registry-disconnect-strategy -> ConnectStrategyProperties(strategy=WAITING, maxWaitingTime=PT1M40S)
  task-execute-threads-full-policy: REJECT
  address -> 172.18.1.1:1234
  registry-path: /nodes/worker/172.18.1.1:1234
****************************Worker Configuration**************************************
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:04.831 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'workerConfig' of type [org.apache.dolphinscheduler.server.worker.config.WorkerConfig$$EnhancerBySpringCGLIB$$da954724] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:05.478 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'io.kubernetes.client.spring.extended.manifests.config.KubernetesManifestsAutoConfiguration' of type [io.kubernetes.client.spring.extended.manifests.config.KubernetesManifestsAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:05.577 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'kubernetes.manifests-io.kubernetes.client.spring.extended.manifests.config.KubernetesManifestsProperties' of type [io.kubernetes.client.spring.extended.manifests.config.KubernetesManifestsProperties] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:05.592 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'io.kubernetes.client.spring.extended.controller.config.KubernetesInformerAutoConfiguration' of type [io.kubernetes.client.spring.extended.controller.config.KubernetesInformerAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:05.700 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'defaultApiClient' of type [io.kubernetes.client.openapi.ApiClient] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:07.289 +0800 o.e.j.u.log:[170] - Logging initialized @42634ms to org.eclipse.jetty.util.log.Slf4jLog
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:09.723 +0800 o.s.b.w.e.j.JettyServletWebServerFactory:[166] - Server initialized with port: 1235
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:09.847 +0800 o.e.j.s.Server:[375] - jetty-9.4.48.v20220622; built: 2022-06-21T20:42:25.880Z; git: 6b67c5719d1f4371b33655ff2d047d24e171e49a; jvm 1.8.0_402-b06
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:10.835 +0800 o.e.j.s.h.C.application:[2368] - Initializing Spring embedded WebApplicationContext
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:10.844 +0800 o.s.b.w.s.c.ServletWebServerApplicationContext:[292] - Root WebApplicationContext: initialization completed in 19875 ms
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:13.221 +0800 o.e.j.s.session:[334] - DefaultSessionIdManager workerName=node0
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:13.285 +0800 o.e.j.s.session:[339] - No SessionScavenger set, using defaults
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:13.319 +0800 o.e.j.s.session:[132] - node0 Scavenging every 660000ms
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:13.514 +0800 o.e.j.s.h.ContextHandler:[921] - Started o.s.b.w.e.j.JettyEmbeddedWebAppContext@52433946{application,/,[file:///tmp/jetty-docbase.1235.7346182365335270189/],AVAILABLE}
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:13.515 +0800 o.e.j.s.Server:[415] - Started @48861ms
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:14.426 +0800 o.a.c.f.i.CuratorFrameworkImpl:[338] - Starting
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:14.541 +0800 o.a.z.ZooKeeper:[98] - Client environment:zookeeper.version=3.8.0-5a02a05eddb59aee6ac762f7ea82e92a68eb9c0f, built on 2022-02-25 08:49 UTC
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:14.542 +0800 o.a.z.ZooKeeper:[98] - Client environment:host.name=d8bddb7812a3
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:14.542 +0800 o.a.z.ZooKeeper:[98] - Client environment:java.version=1.8.0_402
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:14.542 +0800 o.a.z.ZooKeeper:[98] - Client environment:java.vendor=Temurin
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:14.542 +0800 o.a.z.ZooKeeper:[98] - Client environment:java.home=/opt/java/openjdk
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:14.542 +0800 o.a.z.ZooKeeper:[98] - Client environment:java.class.path=/opt/dolphinscheduler/conf:/opt/dolphinscheduler/libs/kerb-client-1.0.1.jar:/opt/dolphinscheduler/libs/spring-cloud-starter-kubernetes-client-config-2.1.3.jar:/opt/dolphinscheduler/libs/oauth2-oidc-sdk-9.35.jar:/opt/dolphinscheduler/libs/jsqlparser-4.4.jar:/opt/dolphinscheduler/libs/reactive-streams-1.0.4.jar:/opt/dolphinscheduler/libs/kubernetes-model-extensions-5.10.2.jar:/opt/dolphinscheduler/libs/zookeeper-3.8.0.jar:/opt/dolphinscheduler/libs/kubernetes-model-apps-5.10.2.jar:/opt/dolphinscheduler/libs/grpc-api-1.41.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-pigeon-3.2.1.jar:/opt/dolphinscheduler/libs/client-java-api-13.0.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-obs-3.2.1.jar:/opt/dolphinscheduler/libs/spring-web-5.3.22.jar:/opt/dolphinscheduler/libs/aws-java-sdk-emr-1.12.300.jar:/opt/dolphinscheduler/libs/spring-context-5.3.22.jar:/opt/dolphinscheduler/libs/gapic-google-cloud-storage-v2-2.18.0-alpha.jar:/opt/dolphinscheduler/libs/spring-cloud-kubernetes-client-config-2.1.3.jar:/opt/dolphinscheduler/libs/jetty-io-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/annotations-13.0.jar:/opt/dolphinscheduler/libs/jpam-1.1.jar:/opt/dolphinscheduler/libs/joda-time-2.10.13.jar:/opt/dolphinscheduler/libs/spring-cloud-kubernetes-client-autoconfig-2.1.3.jar:/opt/dolphinscheduler/libs/kerb-identity-1.0.1.jar:/opt/dolphinscheduler/libs/vertica-jdbc-12.0.4-0.jar:/opt/dolphinscheduler/libs/grpc-googleapis-1.52.1.jar:/opt/dolphinscheduler/libs/aliyun-java-sdk-kms-2.11.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-dvc-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-hana-3.2.1.jar:/opt/dolphinscheduler/libs/kubernetes-httpclient-okhttp-6.0.0.jar:/opt/dolphinscheduler/libs/jline-2.12.jar:/opt/dolphinscheduler/libs/sshd-core-2.8.0.jar:/opt/dolphinscheduler/libs/jna-platform-5.10.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-sqlserver-3.2.1.jar:/opt/dolphinscheduler/libs/commons-beanutils-1.9.4.jar:/opt/dolphinscheduler/libs/grpc-services-1.41.0.jar:/opt/dolphinscheduler/libs/jmespath-java-1.12.300.jar:/opt/dolphinscheduler/libs/curator-client-5.3.0.jar:/opt/dolphinscheduler/libs/proto-google-common-protos-2.0.1.jar:/opt/dolphinscheduler/libs/mybatis-3.5.10.jar:/opt/dolphinscheduler/libs/jackson-annotations-2.13.4.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-all-3.2.1.jar:/opt/dolphinscheduler/libs/jakarta.xml.bind-api-2.3.3.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-jupyter-3.2.1.jar:/opt/dolphinscheduler/libs/mybatis-plus-extension-3.5.2.jar:/opt/dolphinscheduler/libs/j2objc-annotations-1.3.jar:/opt/dolphinscheduler/libs/Java-WebSocket-1.5.1.jar:/opt/dolphinscheduler/libs/azure-storage-common-12.20.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-sagemaker-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-databend-3.2.1.jar:/opt/dolphinscheduler/libs/google-auth-library-oauth2-http-1.15.0.jar:/opt/dolphinscheduler/libs/jetty-security-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-python-3.2.1.jar:/opt/dolphinscheduler/libs/snappy-java-1.1.10.1.jar:/opt/dolphinscheduler/libs/kubernetes-model-batch-5.10.2.jar:/opt/dolphinscheduler/libs/netty-transport-native-epoll-4.1.53.Final-linux-x86_64.jar:/opt/dolphinscheduler/libs/jackson-core-asl-1.9.13.jar:/opt/dolphinscheduler/libs/gson-fire-1.8.5.jar:/opt/dolphinscheduler/libs/clickhouse-jdbc-0.4.6.jar:/opt/dolphinscheduler/libs/grpc-netty-shaded-1.41.0.jar:/opt/dolphinscheduler/libs/caffeine-2.9.3.jar:/opt/dolphinscheduler/libs/aliyun-java-sdk-core-4.5.10.jar:/opt/dolphinscheduler/libs/jackson-module-jaxb-annotations-2.13.3.jar:/opt/dolphinscheduler/libs/jetty-http-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/jersey-servlet-1.19.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-dinky-3.2.1.jar:/opt/dolphinscheduler/libs/simpleclient_tracer_common-0.15.0.jar:/opt/dolphinscheduler/libs/netty-handler-4.1.53.Final.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-datafactory-3.2.1.jar:/opt/dolphinscheduler/libs/json-path-2.7.0.jar:/opt/dolphinscheduler/libs/mybatis-plus-annotation-3.5.2.jar:/opt/dolphinscheduler/libs/azure-resourcemanager-datafactory-1.0.0-beta.19.jar:/opt/dolphinscheduler/libs/commons-codec-1.11.jar:/opt/dolphinscheduler/libs/dolphinscheduler-extract-master-3.2.1.jar:/opt/dolphinscheduler/libs/spring-aop-5.3.22.jar:/opt/dolphinscheduler/libs/kubernetes-model-core-5.10.2.jar:/opt/dolphinscheduler/libs/kubernetes-model-networking-5.10.2.jar:/opt/dolphinscheduler/libs/kotlin-stdlib-jdk7-1.6.21.jar:/opt/dolphinscheduler/libs/kerby-xdr-1.0.1.jar:/opt/dolphinscheduler/libs/aliyun-java-sdk-ram-3.1.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-k8s-3.2.1.jar:/opt/dolphinscheduler/libs/guava-31.1-jre.jar:/opt/dolphinscheduler/libs/netty-codec-dns-4.1.53.Final.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-kubeflow-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-azure-sql-3.2.1.jar:/opt/dolphinscheduler/libs/HikariCP-4.0.3.jar:/opt/dolphinscheduler/libs/hive-metastore-2.3.9.jar:/opt/dolphinscheduler/libs/msal4j-1.13.3.jar:/opt/dolphinscheduler/libs/jackson-core-2.13.4.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-hive-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-mr-3.2.1.jar:/opt/dolphinscheduler/libs/kubernetes-model-node-5.10.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-common-3.2.1.jar:/opt/dolphinscheduler/libs/jose4j-0.7.8.jar:/opt/dolphinscheduler/libs/jul-to-slf4j-1.7.36.jar:/opt/dolphinscheduler/libs/azure-identity-1.7.1.jar:/opt/dolphinscheduler/libs/spring-boot-autoconfigure-2.7.3.jar:/opt/dolphinscheduler/libs/commons-math3-3.1.1.jar:/opt/dolphinscheduler/libs/jackson-jaxrs-json-provider-2.13.3.jar:/opt/dolphinscheduler/libs/perfmark-api-0.23.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-doris-3.2.1.jar:/opt/dolphinscheduler/libs/httpclient-4.5.13.jar:/opt/dolphinscheduler/libs/hive-service-2.3.9.jar:/opt/dolphinscheduler/libs/kerby-util-1.0.1.jar:/opt/dolphinscheduler/libs/commons-collections-3.2.2.jar:/opt/dolphinscheduler/libs/hadoop-yarn-client-3.2.4.jar:/opt/dolphinscheduler/libs/commons-text-1.8.jar:/opt/dolphinscheduler/libs/dolphinscheduler-worker-3.2.1.jar:/opt/dolphinscheduler/libs/hadoop-yarn-common-3.2.4.jar:/opt/dolphinscheduler/libs/zeppelin-client-0.10.1.jar:/opt/dolphinscheduler/libs/azure-core-management-1.10.1.jar:/opt/dolphinscheduler/libs/hadoop-mapreduce-client-jobclient-3.2.4.jar:/opt/dolphinscheduler/libs/jta-1.1.jar:/opt/dolphinscheduler/libs/annotations-4.1.1.4.jar:/opt/dolphinscheduler/libs/dolphinscheduler-extract-alert-3.2.1.jar:/opt/dolphinscheduler/libs/curator-framework-5.3.0.jar:/opt/dolphinscheduler/libs/hive-jdbc-2.3.9.jar:/opt/dolphinscheduler/libs/kyuubi-hive-jdbc-shaded-1.7.0.jar:/opt/dolphinscheduler/libs/client-java-proto-13.0.2.jar:/opt/dolphinscheduler/libs/checker-qual-3.19.0.jar:/opt/dolphinscheduler/libs/jetty-servlet-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/google-cloud-core-grpc-2.10.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-shell-3.2.1.jar:/opt/dolphinscheduler/libs/spring-security-rsa-1.0.10.RELEASE.jar:/opt/dolphinscheduler/libs/avro-1.7.7.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-postgresql-3.2.1.jar:/opt/dolphinscheduler/libs/netty-nio-client-2.17.282.jar:/opt/dolphinscheduler/libs/spring-webmvc-5.3.22.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-mysql-3.2.1.jar:/opt/dolphinscheduler/libs/opentracing-util-0.33.0.jar:/opt/dolphinscheduler/libs/auto-value-1.10.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-all-3.2.1.jar:/opt/dolphinscheduler/libs/jetcd-core-0.5.11.jar:/opt/dolphinscheduler/libs/grpc-context-1.41.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-datasync-3.2.1.jar:/opt/dolphinscheduler/libs/jackson-dataformat-cbor-2.13.3.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-gcs-3.2.1.jar:/opt/dolphinscheduler/libs/client-java-extended-13.0.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-redshift-3.2.1.jar:/opt/dolphinscheduler/libs/opencsv-2.3.jar:/opt/dolphinscheduler/libs/jcip-annotations-1.0-1.jar:/opt/dolphinscheduler/libs/accessors-smart-2.4.8.jar:/opt/dolphinscheduler/libs/hadoop-client-3.2.4.jar:/opt/dolphinscheduler/libs/commons-collections4-4.3.jar:/opt/dolphinscheduler/libs/metrics-core-4.2.11.jar:/opt/dolphinscheduler/libs/netty-resolver-4.1.53.Final.jar:/opt/dolphinscheduler/libs/parquet-hadoop-bundle-1.8.1.jar:/opt/dolphinscheduler/libs/bucket4j-core-6.2.0.jar:/opt/dolphinscheduler/libs/spring-cloud-starter-3.1.3.jar:/opt/dolphinscheduler/libs/mssql-jdbc-11.2.1.jre8.jar:/opt/dolphinscheduler/libs/netty-tcnative-boringssl-static-2.0.53.Final.jar:/opt/dolphinscheduler/libs/kubernetes-model-coordination-5.10.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-linkis-3.2.1.jar:/opt/dolphinscheduler/libs/commons-net-3.6.jar:/opt/dolphinscheduler/libs/netty-transport-native-kqueue-4.1.53.Final-osx-x86_64.jar:/opt/dolphinscheduler/libs/dolphinscheduler-meter-3.2.1.jar:/opt/dolphinscheduler/libs/kubernetes-client-api-6.0.0.jar:/opt/dolphinscheduler/libs/kubernetes-model-certificates-5.10.2.jar:/opt/dolphinscheduler/libs/opencensus-api-0.31.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-mlflow-3.2.1.jar:/opt/dolphinscheduler/libs/kotlin-stdlib-jdk8-1.6.21.jar:/opt/dolphinscheduler/libs/dolphinscheduler-registry-jdbc-3.2.1.jar:/opt/dolphinscheduler/libs/audience-annotations-0.12.0.jar:/opt/dolphinscheduler/libs/simpleclient_httpserver-0.15.0.jar:/opt/dolphinscheduler/libs/jetty-xml-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/kerby-asn1-1.0.1.jar:/opt/dolphinscheduler/libs/lang-tag-1.6.jar:/opt/dolphinscheduler/libs/api-common-2.6.0.jar:/opt/dolphinscheduler/libs/HdrHistogram-2.1.12.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-abs-3.2.1.jar:/opt/dolphinscheduler/libs/failsafe-2.4.4.jar:/opt/dolphinscheduler/libs/hbase-noop-htrace-4.1.1.jar:/opt/dolphinscheduler/libs/jamon-runtime-2.3.1.jar:/opt/dolphinscheduler/libs/jetty-util-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/threetenbp-1.6.5.jar:/opt/dolphinscheduler/libs/jakarta.activation-api-1.2.2.jar:/opt/dolphinscheduler/libs/kubernetes-model-common-5.10.2.jar:/opt/dolphinscheduler/libs/okhttp-4.9.3.jar:/opt/dolphinscheduler/libs/profiles-2.17.282.jar:/opt/dolphinscheduler/libs/hadoop-auth-3.2.4.jar:/opt/dolphinscheduler/libs/grpc-netty-1.41.0.jar:/opt/dolphinscheduler/libs/httpcore-nio-4.4.15.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-seatunnel-3.2.1.jar:/opt/dolphinscheduler/libs/aws-java-sdk-sagemaker-1.12.300.jar:/opt/dolphinscheduler/libs/oshi-core-6.1.1.jar:/opt/dolphinscheduler/libs/bonecp-0.8.0.RELEASE.jar:/opt/dolphinscheduler/libs/jackson-module-parameter-names-2.13.3.jar:/opt/dolphinscheduler/libs/bcutil-jdk15on-1.69.jar:/opt/dolphinscheduler/libs/aws-json-protocol-2.17.282.jar:/opt/dolphinscheduler/libs/dolphinscheduler-extract-base-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-all-3.2.1.jar:/opt/dolphinscheduler/libs/derby-10.14.2.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-snowflake-3.2.1.jar:/opt/dolphinscheduler/libs/netty-codec-http2-4.1.53.Final.jar:/opt/dolphinscheduler/libs/jetty-continuation-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/jackson-mapper-asl-1.9.13.jar:/opt/dolphinscheduler/libs/datanucleus-core-4.1.17.jar:/opt/dolphinscheduler/libs/netty-tcnative-boringssl-static-2.0.53.Final-osx-aarch_64.jar:/opt/dolphinscheduler/libs/failureaccess-1.0.1.jar:/opt/dolphinscheduler/libs/error_prone_annotations-2.5.1.jar:/opt/dolphinscheduler/libs/kerb-admin-1.0.1.jar:/opt/dolphinscheduler/libs/token-provider-1.0.1.jar:/opt/dolphinscheduler/libs/reactor-netty-core-1.0.22.jar:/opt/dolphinscheduler/libs/dolphinscheduler-registry-all-3.2.1.jar:/opt/dolphinscheduler/libs/jakarta.servlet-api-4.0.4.jar:/opt/dolphinscheduler/libs/http-client-spi-2.17.282.jar:/opt/dolphinscheduler/libs/regions-2.17.282.jar:/opt/dolphinscheduler/libs/logback-core-1.2.11.jar:/opt/dolphinscheduler/libs/json-1.8.jar:/opt/dolphinscheduler/libs/gax-grpc-2.23.0.jar:/opt/dolphinscheduler/libs/google-http-client-1.42.3.jar:/opt/dolphinscheduler/libs/hive-serde-2.3.9.jar:/opt/dolphinscheduler/libs/jettison-1.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-http-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-registry-zookeeper-3.2.1.jar:/opt/dolphinscheduler/libs/spring-security-crypto-5.7.3.jar:/opt/dolphinscheduler/libs/auth-2.17.282.jar:/opt/dolphinscheduler/libs/proto-google-cloud-storage-v2-2.18.0-alpha.jar:/opt/dolphinscheduler/libs/jetty-server-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/javax.annotation-api-1.3.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-starrocks-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-dataquality-3.2.1.jar:/opt/dolphinscheduler/libs/jcl-over-slf4j-1.7.36.jar:/opt/dolphinscheduler/libs/commons-lang3-3.12.0.jar:/opt/dolphinscheduler/libs/tomcat-embed-el-9.0.65.jar:/opt/dolphinscheduler/libs/opentracing-noop-0.33.0.jar:/opt/dolphinscheduler/libs/client-java-13.0.2.jar:/opt/dolphinscheduler/libs/spring-beans-5.3.22.jar:/opt/dolphinscheduler/libs/snakeyaml-1.33.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-ssh-3.2.1.jar:/opt/dolphinscheduler/libs/commons-pool-1.6.jar:/opt/dolphinscheduler/libs/javax.servlet-api-3.1.0.jar:/opt/dolphinscheduler/libs/hadoop-common-3.2.4.jar:/opt/dolphinscheduler/libs/kubernetes-model-apiextensions-5.10.2.jar:/opt/dolphinscheduler/libs/spring-boot-2.7.3.jar:/opt/dolphinscheduler/libs/bcprov-ext-jdk15on-1.69.jar:/opt/dolphinscheduler/libs/spring-boot-starter-2.7.3.jar:/opt/dolphinscheduler/libs/paranamer-2.3.jar:/opt/dolphinscheduler/libs/httpmime-4.5.13.jar:/opt/dolphinscheduler/libs/reactor-core-3.4.22.jar:/opt/dolphinscheduler/libs/azure-core-1.36.0.jar:/opt/dolphinscheduler/libs/bcpkix-jdk15on-1.69.jar:/opt/dolphinscheduler/libs/kubernetes-model-scheduling-5.10.2.jar:/opt/dolphinscheduler/libs/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/dolphinscheduler/libs/websocket-client-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/unirest-java-3.7.04-standalone.jar:/opt/dolphinscheduler/libs/hadoop-mapreduce-client-core-3.2.4.jar:/opt/dolphinscheduler/libs/google-auth-library-credentials-1.15.0.jar:/opt/dolphinscheduler/libs/azure-storage-internal-avro-12.6.0.jar:/opt/dolphinscheduler/libs/jackson-datatype-jdk8-2.13.3.jar:/opt/dolphinscheduler/libs/spring-expression-5.3.22.jar:/opt/dolphinscheduler/libs/aspectjweaver-1.9.7.jar:/opt/dolphinscheduler/libs/websocket-common-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/client-java-api-fluent-13.0.2.jar:/opt/dolphinscheduler/libs/mybatis-plus-3.5.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-athena-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-oss-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-openmldb-3.2.1.jar:/opt/dolphinscheduler/libs/curator-recipes-5.3.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-api-3.2.1.jar:/opt/dolphinscheduler/libs/netty-all-4.1.53.Final.jar:/opt/dolphinscheduler/libs/netty-resolver-dns-4.1.53.Final.jar:/opt/dolphinscheduler/libs/kubernetes-model-autoscaling-5.10.2.jar:/opt/dolphinscheduler/libs/kerb-util-1.0.1.jar:/opt/dolphinscheduler/libs/grpc-alts-1.41.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-presto-3.2.1.jar:/opt/dolphinscheduler/libs/kerb-simplekdc-1.0.1.jar:/opt/dolphinscheduler/libs/protobuf-java-util-3.17.2.jar:/opt/dolphinscheduler/libs/azure-core-http-netty-1.13.0.jar:/opt/dolphinscheduler/libs/transaction-api-1.1.jar:/opt/dolphinscheduler/libs/datanucleus-api-jdo-4.2.4.jar:/opt/dolphinscheduler/libs/zeppelin-common-0.10.1.jar:/opt/dolphinscheduler/libs/zt-zip-1.15.jar:/opt/dolphinscheduler/libs/animal-sniffer-annotations-1.19.jar:/opt/dolphinscheduler/libs/google-http-client-jackson2-1.42.3.jar:/opt/dolphinscheduler/libs/netty-buffer-4.1.53.Final.jar:/opt/dolphinscheduler/libs/jsr305-3.0.0.jar:/opt/dolphinscheduler/libs/netty-transport-classes-epoll-4.1.79.Final.jar:/opt/dolphinscheduler/libs/spring-boot-actuator-autoconfigure-2.7.3.jar:/opt/dolphinscheduler/libs/simpleclient-0.15.0.jar:/opt/dolphinscheduler/libs/aliyun-sdk-oss-3.15.1.jar:/opt/dolphinscheduler/libs/json-utils-2.17.282.jar:/opt/dolphinscheduler/libs/tephra-api-0.6.0.jar:/opt/dolphinscheduler/libs/spring-jdbc-5.3.22.jar:/opt/dolphinscheduler/libs/grpc-xds-1.41.0.jar:/opt/dolphinscheduler/libs/logback-classic-1.2.11.jar:/opt/dolphinscheduler/libs/google-cloud-storage-2.18.0.jar:/opt/dolphinscheduler/libs/micrometer-registry-prometheus-1.9.3.jar:/opt/dolphinscheduler/libs/grpc-core-1.41.0.jar:/opt/dolphinscheduler/libs/aws-java-sdk-kms-1.12.300.jar:/opt/dolphinscheduler/libs/kubernetes-model-rbac-5.10.2.jar:/opt/dolphinscheduler/libs/ini4j-0.5.4.jar:/opt/dolphinscheduler/libs/spring-boot-starter-web-2.7.3.jar:/opt/dolphinscheduler/libs/spring-cloud-commons-3.1.3.jar:/opt/dolphinscheduler/libs/netty-codec-http-4.1.53.Final.jar:/opt/dolphinscheduler/libs/jetty-client-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/jetcd-common-0.5.11.jar:/opt/dolphinscheduler/libs/metrics-spi-2.17.282.jar:/opt/dolphinscheduler/libs/utils-2.17.282.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-emr-3.2.1.jar:/opt/dolphinscheduler/libs/protocol-core-2.17.282.jar:/opt/dolphinscheduler/libs/micrometer-core-1.9.3.jar:/opt/dolphinscheduler/libs/netty-transport-native-unix-common-4.1.53.Final.jar:/opt/dolphinscheduler/libs/zjsonpatch-0.4.11.jar:/opt/dolphinscheduler/libs/annotations-2.17.282.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-sql-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-extract-common-3.2.1.jar:/opt/dolphinscheduler/libs/apache-client-2.17.282.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-oceanbase-3.2.1.jar:/opt/dolphinscheduler/libs/jdo-api-3.0.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-datax-3.2.1.jar:/opt/dolphinscheduler/libs/postgresql-42.4.1.jar:/opt/dolphinscheduler/libs/jetty-util-ajax-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/gax-2.23.0.jar:/opt/dolphinscheduler/libs/grpc-stub-1.41.0.jar:/opt/dolphinscheduler/libs/libfb303-0.9.3.jar:/opt/dolphinscheduler/libs/spring-core-5.3.22.jar:/opt/dolphinscheduler/libs/jaxb-api-2.3.1.jar:/opt/dolphinscheduler/libs/hive-service-rpc-2.3.9.jar:/opt/dolphinscheduler/libs/kubernetes-model-flowcontrol-5.10.2.jar:/opt/dolphinscheduler/libs/commons-logging-1.1.1.jar:/opt/dolphinscheduler/libs/mybatis-spring-2.0.7.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-oracle-3.2.1.jar:/opt/dolphinscheduler/libs/opencensus-proto-0.2.0.jar:/opt/dolphinscheduler/libs/grpc-protobuf-1.41.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-clickhouse-3.2.1.jar:/opt/dolphinscheduler/libs/spring-cloud-starter-bootstrap-3.1.3.jar:/opt/dolphinscheduler/libs/kubernetes-model-admissionregistration-5.10.2.jar:/opt/dolphinscheduler/libs/grpc-google-cloud-storage-v2-2.18.0-alpha.jar:/opt/dolphinscheduler/libs/esdk-obs-java-bundle-3.23.3.jar:/opt/dolphinscheduler/libs/dnsjava-2.1.7.jar:/opt/dolphinscheduler/libs/asm-9.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-spark-3.2.1.jar:/opt/dolphinscheduler/libs/netty-tcnative-boringssl-static-2.0.53.Final-linux-aarch_64.jar:/opt/dolphinscheduler/libs/re2j-1.6.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-vertica-3.2.1.jar:/opt/dolphinscheduler/libs/json-smart-2.4.8.jar:/opt/dolphinscheduler/libs/reactor-netty-http-1.0.22.jar:/opt/dolphinscheduler/libs/google-api-services-storage-v1-rev20220705-2.0.0.jar:/opt/dolphinscheduler/libs/kubernetes-client-6.0.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-kyuubi-3.2.1.jar:/opt/dolphinscheduler/libs/auto-value-annotations-1.10.1.jar:/opt/dolphinscheduler/libs/commons-cli-1.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-data-quality-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-chunjun-3.2.1.jar:/opt/dolphinscheduler/libs/kerb-server-1.0.1.jar:/opt/dolphinscheduler/libs/content-type-2.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-remoteshell-3.2.1.jar:/opt/dolphinscheduler/libs/opencensus-contrib-http-util-0.31.1.jar:/opt/dolphinscheduler/libs/druid-1.2.20.jar:/opt/dolphinscheduler/libs/javolution-5.5.1.jar:/opt/dolphinscheduler/libs/protobuf-java-3.17.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-db2-3.2.1.jar:/opt/dolphinscheduler/libs/aws-java-sdk-core-1.12.300.jar:/opt/dolphinscheduler/libs/spring-boot-starter-logging-2.7.3.jar:/opt/dolphinscheduler/libs/kerby-pkix-1.0.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-procedure-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-registry-etcd-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-sqoop-3.2.1.jar:/opt/dolphinscheduler/libs/zookeeper-jute-3.8.0.jar:/opt/dolphinscheduler/libs/netty-resolver-dns-native-macos-4.1.53.Final-osx-x86_64.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-sagemaker-3.2.1.jar:/opt/dolphinscheduler/libs/spring-boot-configuration-processor-2.6.1.jar:/opt/dolphinscheduler/libs/hive-common-2.3.9.jar:/opt/dolphinscheduler/libs/kerb-common-1.0.1.jar:/opt/dolphinscheduler/libs/stax-api-1.0.1.jar:/opt/dolphinscheduler/libs/kubernetes-model-storageclass-5.10.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-s3-3.2.1.jar:/opt/dolphinscheduler/libs/spring-boot-starter-jetty-2.7.3.jar:/opt/dolphinscheduler/libs/okio-2.8.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-dms-3.2.1.jar:/opt/dolphinscheduler/libs/simpleclient_common-0.15.0.jar:/opt/dolphinscheduler/libs/sdk-core-2.17.282.jar:/opt/dolphinscheduler/libs/javax.activation-api-1.2.0.jar:/opt/dolphinscheduler/libs/netty-handler-proxy-4.1.53.Final.jar:/opt/dolphinscheduler/libs/kerby-config-1.0.1.jar:/opt/dolphinscheduler/libs/netty-tcnative-classes-2.0.53.Final.jar:/opt/dolphinscheduler/libs/jackson-jaxrs-base-2.13.3.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-trino-3.2.1.jar:/opt/dolphinscheduler/libs/presto-jdbc-0.238.1.jar:/opt/dolphinscheduler/libs/websocket-api-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-flink-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-api-3.2.1.jar:/opt/dolphinscheduler/libs/kubernetes-model-metrics-5.10.2.jar:/opt/dolphinscheduler/libs/datasync-2.17.282.jar:/opt/dolphinscheduler/libs/hadoop-yarn-api-3.2.4.jar:/opt/dolphinscheduler/libs/google-http-client-apache-v2-1.42.3.jar:/opt/dolphinscheduler/libs/hadoop-annotations-3.2.4.jar:/opt/dolphinscheduler/libs/google-oauth-client-1.34.1.jar:/opt/dolphinscheduler/libs/sshd-common-2.8.0.jar:/opt/dolphinscheduler/libs/LatencyUtils-2.0.3.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-spark-3.2.1.jar:/opt/dolphinscheduler/libs/slf4j-api-1.7.36.jar:/opt/dolphinscheduler/libs/snowflake-jdbc-3.13.29.jar:/opt/dolphinscheduler/libs/jackson-datatype-jsr310-2.13.3.jar:/opt/dolphinscheduler/libs/trino-jdbc-402.jar:/opt/dolphinscheduler/libs/logging-interceptor-4.9.3.jar:/opt/dolphinscheduler/libs/simpleclient_tracer_otel_agent-0.15.0.jar:/opt/dolphinscheduler/libs/janino-3.0.16.jar:/opt/dolphinscheduler/libs/jackson-dataformat-yaml-2.13.3.jar:/opt/dolphinscheduler/libs/ion-java-1.0.2.jar:/opt/dolphinscheduler/libs/commons-dbcp-1.4.jar:/opt/dolphinscheduler/libs/jsp-api-2.1.jar:/opt/dolphinscheduler/libs/google-http-client-gson-1.42.3.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-hivecli-3.2.1.jar:/opt/dolphinscheduler/libs/spring-boot-actuator-2.7.3.jar:/opt/dolphinscheduler/libs/google-cloud-core-http-2.10.0.jar:/opt/dolphinscheduler/libs/DmJdbcDriver18-8.1.2.79.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-java-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-dameng-3.2.1.jar:/opt/dolphinscheduler/libs/sshd-sftp-2.8.0.jar:/opt/dolphinscheduler/libs/kerb-crypto-1.0.1.jar:/opt/dolphinscheduler/libs/conscrypt-openjdk-uber-2.5.2.jar:/opt/dolphinscheduler/libs/httpcore-4.4.15.jar:/opt/dolphinscheduler/libs/lz4-java-1.4.0.jar:/opt/dolphinscheduler/libs/guava-retrying-2.0.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-flink-stream-3.2.1.jar:/opt/dolphinscheduler/libs/spring-tx-5.3.22.jar:/opt/dolphinscheduler/libs/grpc-auth-1.41.0.jar:/opt/dolphinscheduler/libs/netty-tcnative-boringssl-static-2.0.53.Final-osx-x86_64.jar:/opt/dolphinscheduler/libs/databend-jdbc-0.0.7.jar:/opt/dolphinscheduler/libs/bcprov-jdk15on-1.69.jar:/opt/dolphinscheduler/libs/commons-lang-2.6.jar:/opt/dolphinscheduler/libs/kubernetes-model-policy-5.10.2.jar:/opt/dolphinscheduler/libs/commons-io-2.11.0.jar:/opt/dolphinscheduler/libs/grpc-grpclb-1.41.0.jar:/opt/dolphinscheduler/libs/netty-tcnative-boringssl-static-2.0.53.Final-linux-x86_64.jar:/opt/dolphinscheduler/libs/opentracing-api-0.33.0.jar:/opt/dolphinscheduler/libs/sshd-scp-2.8.0.jar:/opt/dolphinscheduler/libs/reload4j-1.2.18.3.jar:/opt/dolphinscheduler/libs/netty-tcnative-2.0.48.Final.jar:/opt/dolphinscheduler/libs/jdom2-2.0.6.1.jar:/opt/dolphinscheduler/libs/spring-boot-starter-json-2.7.3.jar:/opt/dolphinscheduler/libs/netty-transport-native-epoll-4.1.53.Final.jar:/opt/dolphinscheduler/libs/google-cloud-core-2.10.0.jar:/opt/dolphinscheduler/libs/javax.jdo-3.2.0-m3.jar:/opt/dolphinscheduler/libs/gax-httpjson-0.108.0.jar:/opt/dolphinscheduler/libs/mybatis-plus-core-3.5.2.jar:/opt/dolphinscheduler/libs/auto-service-annotations-1.0.1.jar:/opt/dolphinscheduler/libs/nimbus-jose-jwt-9.22.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-zeppelin-3.2.1.jar:/opt/dolphinscheduler/libs/commons-compress-1.21.jar:/opt/dolphinscheduler/libs/hadoop-hdfs-client-3.2.4.jar:/opt/dolphinscheduler/libs/msal4j-persistence-extension-1.1.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-pytorch-3.2.1.jar:/opt/dolphinscheduler/libs/netty-tcnative-boringssl-static-2.0.53.Final-windows-x86_64.jar:/opt/dolphinscheduler/libs/jetty-servlets-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/woodstox-core-6.4.0.jar:/opt/dolphinscheduler/libs/spring-cloud-kubernetes-commons-2.1.3.jar:/opt/dolphinscheduler/libs/grpc-protobuf-lite-1.41.0.jar:/opt/dolphinscheduler/libs/jetty-webapp-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/eventstream-1.0.1.jar:/opt/dolphinscheduler/libs/commons-compiler-3.1.7.jar:/opt/dolphinscheduler/libs/netty-transport-4.1.53.Final.jar:/opt/dolphinscheduler/libs/spring-cloud-context-3.1.3.jar:/opt/dolphinscheduler/libs/aws-java-sdk-dms-1.12.300.jar:/opt/dolphinscheduler/libs/hive-storage-api-2.4.0.jar:/opt/dolphinscheduler/libs/client-java-spring-integration-13.0.2.jar:/opt/dolphinscheduler/libs/spring-boot-starter-actuator-2.7.3.jar:/opt/dolphinscheduler/libs/third-party-jackson-core-2.17.282.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-hdfs-3.2.1.jar:/opt/dolphinscheduler/libs/netty-codec-4.1.53.Final.jar:/opt/dolphinscheduler/libs/google-http-client-appengine-1.42.3.jar:/opt/dolphinscheduler/libs/commons-configuration2-2.1.1.jar:/opt/dolphinscheduler/libs/datanucleus-rdbms-4.1.19.jar:/opt/dolphinscheduler/libs/swagger-annotations-1.6.2.jar:/opt/dolphinscheduler/libs/simpleclient_tracer_otel-0.15.0.jar:/opt/dolphinscheduler/libs/kotlin-stdlib-common-1.6.21.jar:/opt/dolphinscheduler/libs/aws-core-2.17.282.jar:/opt/dolphinscheduler/libs/kerb-core-1.0.1.jar:/opt/dolphinscheduler/libs/httpasyncclient-4.1.5.jar:/opt/dolphinscheduler/libs/dolphinscheduler-extract-worker-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-spi-3.2.1.jar:/opt/dolphinscheduler/libs/okhttp-2.7.5.jar:/opt/dolphinscheduler/libs/google-api-client-2.2.0.jar:/opt/dolphinscheduler/libs/kotlin-stdlib-1.6.21.jar:/opt/dolphinscheduler/libs/jakarta.websocket-api-1.1.2.jar:/opt/dolphinscheduler/libs/libthrift-0.9.3.jar:/opt/dolphinscheduler/libs/spring-boot-starter-aop-2.7.3.jar:/opt/dolphinscheduler/libs/netty-common-4.1.53.Final.jar:/opt/dolphinscheduler/libs/log4j-1.2-api-2.17.2.jar:/opt/dolphinscheduler/libs/jackson-databind-2.13.4.jar:/opt/dolphinscheduler/libs/jackson-dataformat-xml-2.13.3.jar:/opt/dolphinscheduler/libs/kubernetes-model-events-5.10.2.jar:/opt/dolphinscheduler/libs/gson-2.9.1.jar:/opt/dolphinscheduler/libs/proto-google-iam-v1-1.9.0.jar:/opt/dolphinscheduler/libs/netty-codec-socks-4.1.53.Final.jar:/opt/dolphinscheduler/libs/zjsonpatch-0.3.0.jar:/opt/dolphinscheduler/libs/hadoop-mapreduce-client-common-3.2.4.jar:/opt/dolphinscheduler/libs/dolphinscheduler-registry-api-3.2.1.jar:/opt/dolphinscheduler/libs/azure-storage-blob-12.21.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-zeppelin-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-api-3.2.1.jar:/opt/dolphinscheduler/libs/aws-java-sdk-s3-1.12.300.jar:/opt/dolphinscheduler/libs/stax2-api-4.2.1.jar:/opt/dolphinscheduler/libs/jakarta.annotation-api-1.3.5.jar:/opt/dolphinscheduler/libs/kubernetes-model-discovery-5.10.2.jar:/opt/dolphinscheduler/libs/jna-5.10.0.jar:/opt/dolphinscheduler/libs/spring-jcl-5.3.22.jar
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:14.543 +0800 o.a.z.ZooKeeper:[98] - Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:14.543 +0800 o.a.z.ZooKeeper:[98] - Client environment:java.io.tmpdir=/tmp
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:14.543 +0800 o.a.z.ZooKeeper:[98] - Client environment:java.compiler=<NA>
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:14.543 +0800 o.a.z.ZooKeeper:[98] - Client environment:os.name=Linux
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:14.543 +0800 o.a.z.ZooKeeper:[98] - Client environment:os.arch=amd64
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:14.543 +0800 o.a.z.ZooKeeper:[98] - Client environment:os.version=6.5.0-28-generic
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:14.543 +0800 o.a.z.ZooKeeper:[98] - Client environment:user.name=root
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:14.544 +0800 o.a.z.ZooKeeper:[98] - Client environment:user.home=/root
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:14.544 +0800 o.a.z.ZooKeeper:[98] - Client environment:user.dir=/opt/dolphinscheduler
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:14.690 +0800 o.a.z.ZooKeeper:[98] - Client environment:os.memory.free=3211MB
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:14.692 +0800 o.a.z.ZooKeeper:[98] - Client environment:os.memory.max=3840MB
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:14.692 +0800 o.a.z.ZooKeeper:[98] - Client environment:os.memory.total=3840MB
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:14.695 +0800 o.a.z.ZooKeeper:[637] - Initiating client connection, connectString=dolphinscheduler-zookeeper:2181 sessionTimeout=30000 watcher=org.apache.curator.ConnectionState@6996bbc4
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:14.711 +0800 o.a.z.c.X509Util:[77] - Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:14.793 +0800 o.a.z.ClientCnxnSocket:[239] - jute.maxbuffer value is 1048575 Bytes
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:15.059 +0800 o.a.z.ClientCnxn:[1732] - zookeeper.request.timeout value is 0. feature enabled=false
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:15.236 +0800 o.a.z.ClientCnxn:[1171] - Opening socket connection to server dolphinscheduler-zookeeper/172.18.0.4:2181.
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:15.283 +0800 o.a.z.ClientCnxn:[1173] - SASL config status: Will not attempt to authenticate using SASL (unknown error)
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:15.292 +0800 o.a.z.ClientCnxn:[1005] - Socket connection established, initiating session, client: /172.18.1.1:37676, server: dolphinscheduler-zookeeper/172.18.0.4:2181
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:15.333 +0800 o.a.c.f.i.CuratorFrameworkImpl:[386] - Default schema
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:15.344 +0800 o.a.z.ClientCnxn:[1444] - Session establishment complete on server dolphinscheduler-zookeeper/172.18.0.4:2181, session id = 0x10000a4f7700001, negotiated timeout = 30000
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:15.382 +0800 o.a.c.f.s.ConnectionStateManager:[252] - State change: CONNECTED
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:15.590 +0800 o.a.c.f.i.EnsembleTracker:[201] - New config event received: {}
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:15.615 +0800 o.a.c.f.i.EnsembleTracker:[201] - New config event received: {}
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:16.612 +0800 o.a.d.s.w.r.WorkerRpcServer:[41] - WorkerRpcServer starting...
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:17.101 +0800 o.a.d.e.b.NettyRemotingServer:[112] - WorkerRpcServer bind success at port: 1234
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:17.102 +0800 o.a.d.s.w.r.WorkerRpcServer:[43] - WorkerRpcServer started...
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:17.132 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: JAVA - JavaTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:17.222 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: JAVA - JavaTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:17.228 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: JUPYTER - JupyterTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:17.246 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: JUPYTER - JupyterTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:17.262 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: SPARK - SparkTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:17.272 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: SPARK - SparkTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:17.288 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: FLINK_STREAM - FlinkStreamTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:17.302 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: FLINK_STREAM - FlinkStreamTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:17.305 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: PYTHON - PythonTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:17.310 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: PYTHON - PythonTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:17.326 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: DATASYNC - DatasyncTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:17.332 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: DATASYNC - DatasyncTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:17.334 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: DATA_FACTORY - DatafactoryTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:17.340 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: DATA_FACTORY - DatafactoryTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:17.341 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: CHUNJUN - ChunJunTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:17.348 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: CHUNJUN - ChunJunTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:17.349 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: REMOTESHELL - RemoteShellTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:17.364 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: REMOTESHELL - RemoteShellTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:17.366 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: PIGEON - PigeonTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:17.369 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: PIGEON - PigeonTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:17.388 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: SHELL - ShellTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:17.390 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: SHELL - ShellTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:17.391 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: PROCEDURE - ProcedureTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:17.393 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: PROCEDURE - ProcedureTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:17.393 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: MR - MapReduceTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:17.405 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: MR - MapReduceTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:17.406 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: SQOOP - SqoopTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:17.411 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: SQOOP - SqoopTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:17.416 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: PYTORCH - PytorchTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:17.418 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: PYTORCH - PytorchTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:17.431 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: K8S - K8sTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:17.438 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: K8S - K8sTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:17.439 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: SEATUNNEL - SeatunnelTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:17.446 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: SEATUNNEL - SeatunnelTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:17.447 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: SAGEMAKER - SagemakerTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:17.450 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: SAGEMAKER - SagemakerTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:17.474 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: HTTP - HttpTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:17.480 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: HTTP - HttpTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:17.482 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: EMR - EmrTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:17.487 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: EMR - EmrTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:17.495 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: DMS - DmsTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:17.512 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: DMS - DmsTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:17.514 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: DATA_QUALITY - DataQualityTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:17.518 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: DATA_QUALITY - DataQualityTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:17.523 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: KUBEFLOW - KubeflowTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:17.525 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: KUBEFLOW - KubeflowTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:17.531 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: SQL - SqlTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:17.536 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: SQL - SqlTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:17.542 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: DVC - DvcTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:17.550 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: DVC - DvcTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:17.560 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: DATAX - DataxTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:17.583 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: DATAX - DataxTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:17.593 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: ZEPPELIN - ZeppelinTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:17.603 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: ZEPPELIN - ZeppelinTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:17.605 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: DINKY - DinkyTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:17.608 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: DINKY - DinkyTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:17.611 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: MLFLOW - MlflowTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:17.621 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: MLFLOW - MlflowTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:17.623 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: OPENMLDB - OpenmldbTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:17.629 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: OPENMLDB - OpenmldbTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:17.639 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: LINKIS - LinkisTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:17.642 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: LINKIS - LinkisTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:17.649 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: FLINK - FlinkTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:17.661 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: FLINK - FlinkTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:17.665 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: HIVECLI - HiveCliTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:17.667 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: HIVECLI - HiveCliTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:17.872 +0800 o.a.d.c.u.JSONUtils:[72] - init timezone: sun.util.calendar.ZoneInfo[id="Asia/Shanghai",offset=28800000,dstSavings=0,useDaylight=false,transitions=31,lastRule=null]
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:18.196 +0800 o.a.d.s.w.r.WorkerRegistryClient:[104] - Worker node: 172.18.1.1:1234 registry to ZK /nodes/worker/172.18.1.1:1234 successfully
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:19.455 +0800 o.a.d.c.m.BaseHeartBeatTask:[48] - Starting WorkerHeartBeatTask...
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:19.464 +0800 o.a.d.c.m.BaseHeartBeatTask:[50] - Started WorkerHeartBeatTask, heartBeatInterval: 10000...
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:19.465 +0800 o.a.d.s.w.r.WorkerRegistryClient:[114] - Worker node: 172.18.1.1:1234 registry finished
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:19.501 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.3149847094801221 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:19.504 +0800 o.a.d.s.w.m.MessageRetryRunner:[69] - Message retry runner staring
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:20.005 +0800 o.a.d.s.w.m.MessageRetryRunner:[72] - Injected message sender: TaskInstanceExecutionFinishEventSender
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:20.020 +0800 o.a.d.s.w.m.MessageRetryRunner:[72] - Injected message sender: TaskInstanceExecutionInfoUpdateEventSender
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:20.021 +0800 o.a.d.s.w.m.MessageRetryRunner:[72] - Injected message sender: TaskInstanceExecutionRunningEventSender
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:20.023 +0800 o.a.d.s.w.m.MessageRetryRunner:[75] - Message retry runner started
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:21.287 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.2676579925650557 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:22.294 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.2629482071713147 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:23.398 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.3571428571428572 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:24.423 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.2231404958677685 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:25.452 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.194267515923567 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:27.892 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.1430678466076696 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:29.571 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.3968871595330739 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:30.595 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.2117117117117118 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:31.733 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.1506376948512045 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:32.747 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.7803030303030303 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:34.135 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.3985507246376812 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:35.160 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.8472222222222223 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:36.517 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.5339805825242718 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:37.794 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.544 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:37.331 +0800 o.s.b.a.e.w.EndpointLinksResolver:[58] - Exposing 3 endpoint(s) beneath base path '/actuator'
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:38.757 +0800 o.e.j.s.h.C.application:[2368] - Initializing Spring DispatcherServlet 'dispatcherServlet'
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:38.762 +0800 o.s.w.s.DispatcherServlet:[525] - Initializing Servlet 'dispatcherServlet'
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:38.778 +0800 o.s.w.s.DispatcherServlet:[547] - Completed initialization in 15 ms
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:38.811 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.308641975308642 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:38.974 +0800 o.e.j.s.AbstractConnector:[333] - Started ServerConnector@acb5508{HTTP/1.1, (http/1.1)}{0.0.0.0:1235}
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:38.977 +0800 o.s.b.w.e.j.JettyWebServer:[172] - Jetty started on port(s) 1235 (http/1.1) with context path '/'
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:39.186 +0800 o.a.d.s.w.WorkerServer:[61] - Started WorkerServer in 68.303 seconds (JVM running for 74.532)
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:39.861 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.2352941176470589 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:40.879 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.0 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:41.902 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9777777777777777 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:42.905 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.98046875 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:43.910 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9469026548672567 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:47.162 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9419354838709677 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:48.192 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.0 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:49.874 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7198275862068965 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:50.936 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9801587301587301 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:51.937 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.940711462450593 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:52.946 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7964285714285715 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:55.082 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8387096774193548 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:56.131 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8272251308900523 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:45:57.157 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.088495575221239 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-3957] - [INFO] 2024-05-07 10:46:11.790 +0800 o.a.d.s.w.r.o.UpdateWorkflowHostOperationFunction:[49] - Received UpdateWorkflowHostRequest: UpdateWorkflowHostRequest(taskInstanceId=3957, workflowHost=172.18.0.17:5678)
[WI-0][TI-0] - [INFO] 2024-05-07 10:46:12.012 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=3958, taskName=[null check] filtered data persistence, firstSubmitTime=1715049971862, startTime=0, taskType=DATA_QUALITY, workflowInstanceHost=172.18.0.17:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13505298546272, processDefineVersion=21, appIds=null, processInstanceId=1060, scheduleTime=0, globalParams=null, executorId=1, cmdTypeIfComplement=2, tenantCode=default, processDefineId=0, projectId=0, projectCode=13001194483488, taskParams={"localParams":[],"resourceList":[],"ruleId":6,"ruleInputParameter":{"check_type":"0","comparison_type":1,"comparison_name":"0","failure_strategy":"0","operator":"0","src_connector_type":1,"src_datasource_id":6,"src_database":"persistence","src_field":"content","src_table":"filtered_data_persistence","threshold":"0"},"sparkParameters":{"deployMode":"local","driverCores":1,"driverMemory":"512M","executorCores":1,"executorMemory":"1G","numExecutors":1,"others":"--conf spark.driver.extraJavaOptions=\"-Divy.cache.dir=/tmp -Divy.home=/tmp\" \\\n--packages org.postgresql:postgresql:42.7.3","yarnQueue":""}}, environmentConfig=export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export PYSPARK_DRIVER_PYTHON=/bin/python3.11
export PYSPARK_PYTHON=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='[null check] filtered data persistence'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13001194483488'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='1060'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240507'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240506'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='3958'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='qualti_test'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13505264408800'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13505298546272'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240507104611'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=null, dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=org.apache.dolphinscheduler.plugin.task.api.DataQualityTaskExecutionContext@161d9a32, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-1060][TI-3958] - [INFO] 2024-05-07 10:46:12.060 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: [null check] filtered data persistence to wait queue success
[WI-1060][TI-3958] - [INFO] 2024-05-07 10:46:12.069 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-1060][TI-3958] - [INFO] 2024-05-07 10:46:12.077 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-1060][TI-3958] - [INFO] 2024-05-07 10:46:12.079 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-1060][TI-3958] - [INFO] 2024-05-07 10:46:12.079 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-1060][TI-3958] - [INFO] 2024-05-07 10:46:12.080 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1715049972080
[WI-1060][TI-3958] - [INFO] 2024-05-07 10:46:12.081 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 1060_3958
[WI-1060][TI-3958] - [INFO] 2024-05-07 10:46:12.091 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 3958,
  "taskName" : "[null check] filtered data persistence",
  "firstSubmitTime" : 1715049971862,
  "startTime" : 1715049972080,
  "taskType" : "DATA_QUALITY",
  "workflowInstanceHost" : "172.18.0.17:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240507/13505298546272/21/1060/3958.log",
  "processId" : 0,
  "processDefineCode" : 13505298546272,
  "processDefineVersion" : 21,
  "processInstanceId" : 1060,
  "scheduleTime" : 0,
  "executorId" : 1,
  "cmdTypeIfComplement" : 2,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13001194483488,
  "taskParams" : "{\"localParams\":[],\"resourceList\":[],\"ruleId\":6,\"ruleInputParameter\":{\"check_type\":\"0\",\"comparison_type\":1,\"comparison_name\":\"0\",\"failure_strategy\":\"0\",\"operator\":\"0\",\"src_connector_type\":1,\"src_datasource_id\":6,\"src_database\":\"persistence\",\"src_field\":\"content\",\"src_table\":\"filtered_data_persistence\",\"threshold\":\"0\"},\"sparkParameters\":{\"deployMode\":\"local\",\"driverCores\":1,\"driverMemory\":\"512M\",\"executorCores\":1,\"executorMemory\":\"1G\",\"numExecutors\":1,\"others\":\"--conf spark.driver.extraJavaOptions=\\\"-Divy.cache.dir=/tmp -Divy.home=/tmp\\\" \\\\\\n--packages org.postgresql:postgresql:42.7.3\",\"yarnQueue\":\"\"}}",
  "environmentConfig" : "export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3\nexport JAVA_HOME=/opt/java/openjdk\nexport PYSPARK_DRIVER_PYTHON=/bin/python3.11\nexport PYSPARK_PYTHON=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "[null check] filtered data persistence"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13001194483488"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1060"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240507"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240506"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "3958"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "qualti_test"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13505264408800"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13505298546272"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240507104611"
    }
  },
  "taskAppId" : "1060_3958",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "dryRun" : 0,
  "paramsMap" : { },
  "dataQualityTaskExecutionContext" : {
    "ruleId" : 6,
    "ruleName" : "$t(uniqueness_check)",
    "ruleType" : 0,
    "ruleInputEntryList" : "[{\"id\":1,\"field\":\"src_connector_type\",\"type\":\"select\",\"title\":\"$t(src_connector_type)\",\"data\":\"\",\"options\":\"[{\\\"label\\\":\\\"HIVE\\\",\\\"value\\\":\\\"HIVE\\\"},{\\\"label\\\":\\\"JDBC\\\",\\\"value\\\":\\\"JDBC\\\"}]\",\"placeholder\":\"please select source connector type\",\"optionSourceType\":2,\"dataType\":2,\"inputType\":0,\"isShow\":true,\"canEdit\":true,\"isEmit\":true,\"isValidate\":false,\"valuesMap\":null,\"index\":1,\"createTime\":null,\"updateTime\":null},{\"id\":2,\"field\":\"src_datasource_id\",\"type\":\"select\",\"title\":\"$t(src_datasource_id)\",\"data\":\"\",\"options\":null,\"placeholder\":\"please select source datasource id\",\"optionSourceType\":1,\"dataType\":2,\"inputType\":0,\"isShow\":true,\"canEdit\":true,\"isEmit\":true,\"isValidate\":false,\"valuesMap\":null,\"index\":2,\"createTime\":null,\"updateTime\":null},{\"id\":30,\"field\":\"src_database\",\"type\":\"select\",\"title\":\"$t(src_database)\",\"data\":null,\"options\":null,\"placeholder\":\"Please select source database\",\"optionSourceType\":0,\"dataType\":0,\"inputType\":0,\"isShow\":true,\"canEdit\":true,\"isEmit\":true,\"isValidate\":true,\"valuesMap\":null,\"index\":2,\"createTime\":null,\"updateTime\":null},{\"id\":3,\"field\":\"src_table\",\"type\":\"select\",\"title\":\"$t(src_table)\",\"data\":null,\"options\":null,\"placeholder\":\"Please enter source table name\",\"optionSourceType\":0,\"dataType\":0,\"inputType\":0,\"isShow\":true,\"canEdit\":true,\"isEmit\":true,\"isValidate\":true,\"valuesMap\":null,\"index\":3,\"createTime\":null,\"updateTime\":null},{\"id\":4,\"field\":\"src_filter\",\"type\":\"input\",\"title\":\"$t(src_filter)\",\"data\":null,\"options\":null,\"placeholder\":\"Please enter filter expression\",\"optionSourceType\":0,\"dataType\":3,\"inputType\":0,\"isShow\":true,\"canEdit\":true,\"isEmit\":false,\"isValidate\":false,\"valuesMap\":null,\"index\":4,\"createTime\":null,\"updateTime\":null},{\"id\":5,\"field\":\"src_field\",\"type\":\"select\",\"title\":\"$t(src_field)\",\"data\":null,\"options\":null,\"placeholder\":\"Please enter column, only single column is supported\",\"optionSourceType\":0,\"dataType\":0,\"inputType\":0,\"isShow\":true,\"canEdit\":true,\"isEmit\":false,\"isValidate\":true,\"valuesMap\":null,\"index\":5,\"createTime\":null,\"updateTime\":null},{\"id\":6,\"field\":\"statistics_name\",\"type\":\"input\",\"title\":\"$t(statistics_name)\",\"data\":\"duplicate_count.duplicates\",\"options\":null,\"placeholder\":\"Please enter statistics name, the alias in statistics execute sql\",\"optionSourceType\":0,\"dataType\":0,\"inputType\":1,\"isShow\":false,\"canEdit\":false,\"isEmit\":false,\"isValidate\":true,\"valuesMap\":\"{\\\"statistics_name\\\":\\\"duplicate_count.duplicates\\\"}\",\"index\":6,\"createTime\":null,\"updateTime\":null},{\"id\":7,\"field\":\"check_type\",\"type\":\"select\",\"title\":\"$t(check_type)\",\"data\":\"0\",\"options\":\"[{\\\"label\\\":\\\"Expected - Actual\\\",\\\"value\\\":\\\"0\\\"},{\\\"label\\\":\\\"Actual - Expected\\\",\\\"value\\\":\\\"1\\\"},{\\\"label\\\":\\\"Actual / Expected\\\",\\\"value\\\":\\\"2\\\"},{\\\"label\\\":\\\"(Expected - Actual) / Expected\\\",\\\"value\\\":\\\"3\\\"}]\",\"placeholder\":\"please select check type\",\"optionSourceType\":0,\"dataType\":0,\"inputType\":3,\"isShow\":true,\"canEdit\":true,\"isEmit\":true,\"isValidate\":false,\"valuesMap\":null,\"index\":7,\"createTime\":null,\"updateTime\":null},{\"id\":8,\"field\":\"operator\",\"type\":\"select\",\"title\":\"$t(operator)\",\"data\":\"0\",\"options\":\"[{\\\"label\\\":\\\"=\\\",\\\"value\\\":\\\"0\\\"},{\\\"label\\\":\\\"<\\\",\\\"value\\\":\\\"1\\\"},{\\\"label\\\":\\\"<=\\\",\\\"value\\\":\\\"2\\\"},{\\\"label\\\":\\\">\\\",\\\"value\\\":\\\"3\\\"},{\\\"label\\\":\\\">=\\\",\\\"value\\\":\\\"4\\\"},{\\\"label\\\":\\\"!=\\\",\\\"value\\\":\\\"5\\\"}]\",\"placeholder\":\"please select operator\",\"optionSourceType\":0,\"dataType\":0,\"inputType\":3,\"isShow\":true,\"canEdit\":true,\"isEmit\":false,\"isValidate\":false,\"valuesMap\":null,\"index\":8,\"createTime\":null,\"updateTime\":null},{\"id\":9,\"field\":\"threshold\",\"type\":\"input\",\"title\":\"$t(threshold)\",\"data\":null,\"options\":null,\"placeholder\":\"Please enter threshold, number is needed\",\"optionSourceType\":0,\"dataType\":2,\"inputType\":3,\"isShow\":true,\"canEdit\":true,\"isEmit\":false,\"isValidate\":true,\"valuesMap\":null,\"index\":9,\"createTime\":null,\"updateTime\":null},{\"id\":10,\"field\":\"failure_strategy\",\"type\":\"select\",\"title\":\"$t(failure_strategy)\",\"data\":\"0\",\"options\":\"[{\\\"label\\\":\\\"Alert\\\",\\\"value\\\":\\\"0\\\"},{\\\"label\\\":\\\"Block\\\",\\\"value\\\":\\\"1\\\"}]\",\"placeholder\":\"please select failure strategy\",\"optionSourceType\":0,\"dataType\":0,\"inputType\":3,\"isShow\":true,\"canEdit\":true,\"isEmit\":false,\"isValidate\":false,\"valuesMap\":null,\"index\":10,\"createTime\":null,\"updateTime\":null},{\"id\":17,\"field\":\"comparison_name\",\"type\":\"input\",\"title\":\"$t(comparison_name)\",\"data\":null,\"options\":null,\"placeholder\":\"Please enter comparison name, the alias in comparison execute sql\",\"optionSourceType\":0,\"dataType\":0,\"inputType\":0,\"isShow\":false,\"canEdit\":false,\"isEmit\":false,\"isValidate\":true,\"valuesMap\":\"\",\"index\":11,\"createTime\":null,\"updateTime\":null},{\"id\":19,\"field\":\"comparison_type\",\"type\":\"select\",\"title\":\"$t(comparison_type)\",\"data\":\"\",\"options\":null,\"placeholder\":\"Please enter comparison title\",\"optionSourceType\":3,\"dataType\":0,\"inputType\":2,\"isShow\":true,\"canEdit\":false,\"isEmit\":true,\"isValidate\":false,\"valuesMap\":null,\"index\":12,\"createTime\":null,\"updateTime\":null}]",
    "executeSqlList" : "[{\"id\":6,\"index\":1,\"sql\":\"SELECT ${src_field} FROM ${src_table} group by ${src_field} having count(*) > 1\",\"tableAlias\":\"duplicate_items\",\"type\":0,\"createTime\":\"2021-03-03 11:31:24\",\"updateTime\":\"2021-03-03 11:31:24\",\"errorOutputSql\":true},{\"id\":7,\"index\":1,\"sql\":\"SELECT COUNT(*) AS duplicates FROM duplicate_items\",\"tableAlias\":\"duplicate_count\",\"type\":1,\"createTime\":\"2021-03-03 11:31:24\",\"updateTime\":\"2021-03-03 11:31:24\",\"errorOutputSql\":false}]",
    "comparisonNeedStatisticsValueTable" : false,
    "compareWithFixedValue" : true,
    "hdfsPath" : "hdfs://mycluster:8020/user/default/data_quality_error_data",
    "sourceConnectorType" : "JDBC",
    "sourceType" : 1,
    "sourceConnectionParams" : "{\"user\":\"root\",\"password\":\"root\",\"address\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432\",\"database\":\"persistence\",\"jdbcUrl\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432/persistence\",\"driverClassName\":\"org.postgresql.Driver\",\"validationQuery\":\"select version()\",\"other\":{\"password\":\"root\"}}",
    "targetConnectorType" : null,
    "targetType" : 0,
    "targetConnectionParams" : null,
    "writerConnectorType" : "JDBC",
    "writerType" : 1,
    "writerTable" : "t_ds_dq_execute_result",
    "writerConnectionParams" : "{\"user\":\"root\",\"password\":\"root\",\"address\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432\",\"database\":\"dolphinscheduler\",\"jdbcUrl\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432/dolphinscheduler\"}",
    "statisticsValueConnectorType" : "JDBC",
    "statisticsValueType" : 1,
    "statisticsValueTable" : "t_ds_dq_task_statistics_value",
    "statisticsValueWriterConnectionParams" : "{\"user\":\"root\",\"password\":\"root\",\"address\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432\",\"database\":\"dolphinscheduler\",\"jdbcUrl\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432/dolphinscheduler\"}"
  },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-1060][TI-3958] - [INFO] 2024-05-07 10:46:12.097 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-1060][TI-3958] - [INFO] 2024-05-07 10:46:12.099 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-1060][TI-3958] - [INFO] 2024-05-07 10:46:12.100 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-0][TI-0] - [INFO] 2024-05-07 10:46:12.230 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8602739726027397 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-1060][TI-3958] - [INFO] 2024-05-07 10:46:12.267 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-1060][TI-3958] - [INFO] 2024-05-07 10:46:12.326 +0800 o.a.d.c.u.OSUtils:[231] - create linux os user: default
[WI-1060][TI-3958] - [INFO] 2024-05-07 10:46:12.327 +0800 o.a.d.c.u.OSUtils:[233] - execute cmd: sudo useradd -g root
 default
[WI-1060][TI-3958] - [INFO] 2024-05-07 10:46:12.473 +0800 o.a.d.c.u.OSUtils:[190] - create user default success
[WI-1060][TI-3958] - [INFO] 2024-05-07 10:46:12.475 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-1060][TI-3958] - [INFO] 2024-05-07 10:46:12.484 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13001194483488/13505298546272_21/1060/3958 check successfully
[WI-1060][TI-3958] - [INFO] 2024-05-07 10:46:12.489 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.dq.DataQualityTaskChannel successfully
[WI-1060][TI-3958] - [INFO] 2024-05-07 10:46:12.523 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-1060][TI-3958] - [INFO] 2024-05-07 10:46:12.541 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-1060][TI-3958] - [INFO] 2024-05-07 10:46:12.553 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: DATA_QUALITY create successfully
[WI-1060][TI-3958] - [INFO] 2024-05-07 10:46:12.558 +0800 o.a.d.p.t.d.DataQualityTask:[89] - Initialize data quality task params {
  "localParams" : [ ],
  "varPool" : null,
  "ruleId" : 6,
  "ruleInputParameter" : {
    "check_type" : "0",
    "comparison_type" : "1",
    "comparison_name" : "0",
    "failure_strategy" : "0",
    "operator" : "0",
    "src_connector_type" : "1",
    "src_datasource_id" : "6",
    "src_database" : "persistence",
    "src_field" : "content",
    "src_table" : "filtered_data_persistence",
    "threshold" : "0"
  },
  "sparkParameters" : {
    "localParams" : null,
    "varPool" : null,
    "mainJar" : null,
    "mainClass" : null,
    "deployMode" : "local",
    "mainArgs" : null,
    "driverCores" : 1,
    "driverMemory" : "512M",
    "numExecutors" : 1,
    "executorCores" : 1,
    "executorMemory" : "1G",
    "appName" : null,
    "yarnQueue" : "",
    "others" : "--conf spark.driver.extraJavaOptions=\"-Divy.cache.dir=/tmp -Divy.home=/tmp\" \\\n--packages org.postgresql:postgresql:42.7.3",
    "programType" : null,
    "resourceList" : [ ]
  }
}
[WI-1060][TI-3958] - [INFO] 2024-05-07 10:46:12.648 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: HANA
[WI-1060][TI-3958] - [INFO] 2024-05-07 10:46:12.650 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: HANA
[WI-1060][TI-3958] - [INFO] 2024-05-07 10:46:12.653 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: SQLSERVER
[WI-1060][TI-3958] - [INFO] 2024-05-07 10:46:12.654 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: SQLSERVER
[WI-1060][TI-3958] - [INFO] 2024-05-07 10:46:12.658 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: SAGEMAKER
[WI-1060][TI-3958] - [INFO] 2024-05-07 10:46:12.659 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: SAGEMAKER
[WI-1060][TI-3958] - [INFO] 2024-05-07 10:46:12.662 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: DATABEND
[WI-1060][TI-3958] - [INFO] 2024-05-07 10:46:12.662 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: DATABEND
[WI-1060][TI-3958] - [INFO] 2024-05-07 10:46:12.868 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: AZURESQL
[WI-1060][TI-3958] - [INFO] 2024-05-07 10:46:12.871 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: AZURESQL
[WI-1060][TI-3958] - [INFO] 2024-05-07 10:46:12.877 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: HIVE
[WI-1060][TI-3958] - [INFO] 2024-05-07 10:46:12.877 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: HIVE
[WI-1060][TI-3958] - [INFO] 2024-05-07 10:46:12.880 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: DORIS
[WI-1060][TI-3958] - [INFO] 2024-05-07 10:46:12.880 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: DORIS
[WI-1060][TI-3958] - [INFO] 2024-05-07 10:46:12.884 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: POSTGRESQL
[WI-1060][TI-3958] - [INFO] 2024-05-07 10:46:12.884 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: POSTGRESQL
[WI-1060][TI-3958] - [INFO] 2024-05-07 10:46:12.887 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: MYSQL
[WI-1060][TI-3958] - [INFO] 2024-05-07 10:46:12.887 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: MYSQL
[WI-1060][TI-3958] - [INFO] 2024-05-07 10:46:12.891 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: REDSHIFT
[WI-1060][TI-3958] - [INFO] 2024-05-07 10:46:12.892 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: REDSHIFT
[WI-1060][TI-3958] - [INFO] 2024-05-07 10:46:12.894 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: SNOWFLAKE
[WI-1060][TI-3958] - [INFO] 2024-05-07 10:46:12.897 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: SNOWFLAKE
[WI-1060][TI-3958] - [INFO] 2024-05-07 10:46:12.901 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: STARROCKS
[WI-1060][TI-3958] - [INFO] 2024-05-07 10:46:12.902 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: STARROCKS
[WI-1060][TI-3958] - [INFO] 2024-05-07 10:46:12.903 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: SSH
[WI-1060][TI-3958] - [INFO] 2024-05-07 10:46:12.904 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: SSH
[WI-1060][TI-3958] - [INFO] 2024-05-07 10:46:12.907 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: ATHENA
[WI-1060][TI-3958] - [INFO] 2024-05-07 10:46:12.909 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: ATHENA
[WI-1060][TI-3958] - [INFO] 2024-05-07 10:46:12.912 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: PRESTO
[WI-1060][TI-3958] - [INFO] 2024-05-07 10:46:12.912 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: PRESTO
[WI-1060][TI-3958] - [INFO] 2024-05-07 10:46:12.914 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: OCEANBASE
[WI-1060][TI-3958] - [INFO] 2024-05-07 10:46:12.915 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: OCEANBASE
[WI-1060][TI-3958] - [INFO] 2024-05-07 10:46:12.929 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: ORACLE
[WI-1060][TI-3958] - [INFO] 2024-05-07 10:46:12.930 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: ORACLE
[WI-1060][TI-3958] - [INFO] 2024-05-07 10:46:12.933 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: CLICKHOUSE
[WI-1060][TI-3958] - [INFO] 2024-05-07 10:46:12.934 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: CLICKHOUSE
[WI-1060][TI-3958] - [INFO] 2024-05-07 10:46:12.938 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: VERTICA
[WI-1060][TI-3958] - [INFO] 2024-05-07 10:46:12.938 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: VERTICA
[WI-1060][TI-3958] - [INFO] 2024-05-07 10:46:12.942 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: KYUUBI
[WI-1060][TI-3958] - [INFO] 2024-05-07 10:46:12.943 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: KYUUBI
[WI-1060][TI-3958] - [INFO] 2024-05-07 10:46:12.947 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: DB2
[WI-1060][TI-3958] - [INFO] 2024-05-07 10:46:12.947 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: DB2
[WI-1060][TI-3958] - [INFO] 2024-05-07 10:46:12.951 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: TRINO
[WI-1060][TI-3958] - [INFO] 2024-05-07 10:46:12.951 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: TRINO
[WI-1060][TI-3958] - [INFO] 2024-05-07 10:46:12.954 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: SPARK
[WI-1060][TI-3958] - [INFO] 2024-05-07 10:46:12.954 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: SPARK
[WI-1060][TI-3958] - [INFO] 2024-05-07 10:46:12.957 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: DAMENG
[WI-1060][TI-3958] - [INFO] 2024-05-07 10:46:12.958 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: DAMENG
[WI-1060][TI-3958] - [INFO] 2024-05-07 10:46:12.960 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: ZEPPELIN
[WI-1060][TI-3958] - [INFO] 2024-05-07 10:46:12.961 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: ZEPPELIN
[WI-1060][TI-3958] - [INFO] 2024-05-07 10:46:12.977 +0800 o.a.d.p.t.d.DataQualityTask:[119] - data quality configuration: {
  "name" : "$t(uniqueness_check)",
  "env" : {
    "type" : "batch",
    "config" : null
  },
  "readers" : [ {
    "type" : "JDBC",
    "config" : {
      "database" : "persistence",
      "password" : "root",
      "driver" : "org.postgresql.Driver",
      "user" : "root",
      "output_table" : "persistence_filtered_data_persistence",
      "table" : "filtered_data_persistence",
      "url" : "jdbc:postgresql://dolphinscheduler-postgresql:5432/persistence?password=root"
    }
  } ],
  "transformers" : [ {
    "type" : "sql",
    "config" : {
      "index" : 1,
      "output_table" : "duplicate_items",
      "sql" : "SELECT content FROM persistence_filtered_data_persistence group by content having count(*) > 1"
    }
  }, {
    "type" : "sql",
    "config" : {
      "index" : 2,
      "output_table" : "duplicate_count",
      "sql" : "SELECT COUNT(*) AS duplicates FROM duplicate_items"
    }
  } ],
  "writers" : [ {
    "type" : "JDBC",
    "config" : {
      "database" : "dolphinscheduler",
      "password" : "root",
      "driver" : "org.postgresql.Driver",
      "user" : "root",
      "table" : "t_ds_dq_execute_result",
      "url" : "jdbc:postgresql://dolphinscheduler-postgresql:5432/dolphinscheduler",
      "sql" : "select 0 as rule_type,'$t(uniqueness_check)' as rule_name,0 as process_definition_id,1060 as process_instance_id,3958 as task_instance_id,duplicate_count.duplicates AS statistics_value,0 AS comparison_value,1 AS comparison_type,0 as check_type,0 as threshold,0 as operator,0 as failure_strategy,'hdfs://mycluster:8020/user/default/data_quality_error_data/0_1060_[null check] filtered data persistence' as error_output_path,'2024-05-07 10:46:12' as create_time,'2024-05-07 10:46:12' as update_time from duplicate_count "
    }
  }, {
    "type" : "JDBC",
    "config" : {
      "database" : "dolphinscheduler",
      "password" : "root",
      "driver" : "org.postgresql.Driver",
      "user" : "root",
      "table" : "t_ds_dq_task_statistics_value",
      "url" : "jdbc:postgresql://dolphinscheduler-postgresql:5432/dolphinscheduler",
      "sql" : "select 0 as process_definition_id,3958 as task_instance_id,6 as rule_id,'KA0AXXWVHWW+GZX4BPZXFGFZ0F0OYMUQ+BVYG4+ZIKG=' as unique_code,'duplicate_count.duplicates'AS statistics_name,duplicate_count.duplicates AS statistics_value,'2024-05-07 10:46:12' as data_time,'2024-05-07 10:46:12' as create_time,'2024-05-07 10:46:12' as update_time from duplicate_count"
    }
  }, {
    "type" : "hdfs_file",
    "config" : {
      "path" : "hdfs://mycluster:8020/user/default/data_quality_error_data/0_1060_[null check] filtered data persistence",
      "input_table" : "duplicate_items"
    }
  } ]
}
[WI-1060][TI-3958] - [INFO] 2024-05-07 10:46:12.983 +0800 o.a.d.p.d.a.u.CommonUtils:[136] - Trying to get data quality jar in path
[WI-1060][TI-3958] - [INFO] 2024-05-07 10:46:12.984 +0800 o.a.d.p.d.a.u.CommonUtils:[147] - data quality jar path is empty, will try to auto discover it from build-in rules.
[WI-1060][TI-3958] - [INFO] 2024-05-07 10:46:12.984 +0800 o.a.d.p.d.a.u.CommonUtils:[187] - Try to get data quality jar from path /opt/dolphinscheduler/conf/../libs
[WI-1060][TI-3958] - [INFO] 2024-05-07 10:46:12.986 +0800 o.a.d.p.d.a.u.CommonUtils:[182] - get default data quality jar name: /opt/dolphinscheduler/conf/../libs/dolphinscheduler-data-quality-3.2.1.jar
[WI-1060][TI-3958] - [INFO] 2024-05-07 10:46:12.986 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-1060][TI-3958] - [INFO] 2024-05-07 10:46:12.986 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: null successfully
[WI-1060][TI-3958] - [INFO] 2024-05-07 10:46:12.988 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-1060][TI-3958] - [INFO] 2024-05-07 10:46:12.988 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-1060][TI-3958] - [INFO] 2024-05-07 10:46:12.989 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-1060][TI-3958] - [INFO] 2024-05-07 10:46:12.995 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-1060][TI-3958] - [INFO] 2024-05-07 10:46:12.995 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-1060][TI-3958] - [INFO] 2024-05-07 10:46:12.995 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export PYSPARK_DRIVER_PYTHON=/bin/python3.11
export PYSPARK_PYTHON=/bin/python3.11
${SPARK_HOME}/bin/spark-submit --master local --driver-cores 1 --driver-memory 512M --num-executors 1 --executor-cores 1 --executor-memory 1G --conf spark.driver.extraJavaOptions="-Divy.cache.dir=/tmp -Divy.home=/tmp" \
--packages org.postgresql:postgresql:42.7.3 /opt/dolphinscheduler/conf/../libs/dolphinscheduler-data-quality-3.2.1.jar "{\"name\":\"$t(uniqueness_check)\",\"env\":{\"type\":\"batch\",\"config\":null},\"readers\":[{\"type\":\"JDBC\",\"config\":{\"database\":\"persistence\",\"password\":\"root\",\"driver\":\"org.postgresql.Driver\",\"user\":\"root\",\"output_table\":\"persistence_filtered_data_persistence\",\"table\":\"filtered_data_persistence\",\"url\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432/persistence?password=root\"} }],\"transformers\":[{\"type\":\"sql\",\"config\":{\"index\":1,\"output_table\":\"duplicate_items\",\"sql\":\"SELECT content FROM persistence_filtered_data_persistence group by content having count(*) > 1\"} },{\"type\":\"sql\",\"config\":{\"index\":2,\"output_table\":\"duplicate_count\",\"sql\":\"SELECT COUNT(*) AS duplicates FROM duplicate_items\"} }],\"writers\":[{\"type\":\"JDBC\",\"config\":{\"database\":\"dolphinscheduler\",\"password\":\"root\",\"driver\":\"org.postgresql.Driver\",\"user\":\"root\",\"table\":\"t_ds_dq_execute_result\",\"url\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432/dolphinscheduler\",\"sql\":\"select 0 as rule_type,'$t(uniqueness_check)' as rule_name,0 as process_definition_id,1060 as process_instance_id,3958 as task_instance_id,duplicate_count.duplicates AS statistics_value,0 AS comparison_value,1 AS comparison_type,0 as check_type,0 as threshold,0 as operator,0 as failure_strategy,'hdfs://mycluster:8020/user/default/data_quality_error_data/0_1060_[null check] filtered data persistence' as error_output_path,'2024-05-07 10:46:12' as create_time,'2024-05-07 10:46:12' as update_time from duplicate_count \"} },{\"type\":\"JDBC\",\"config\":{\"database\":\"dolphinscheduler\",\"password\":\"root\",\"driver\":\"org.postgresql.Driver\",\"user\":\"root\",\"table\":\"t_ds_dq_task_statistics_value\",\"url\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432/dolphinscheduler\",\"sql\":\"select 0 as process_definition_id,3958 as task_instance_id,6 as rule_id,'KA0AXXWVHWW+GZX4BPZXFGFZ0F0OYMUQ+BVYG4+ZIKG=' as unique_code,'duplicate_count.duplicates'AS statistics_name,duplicate_count.duplicates AS statistics_value,'2024-05-07 10:46:12' as data_time,'2024-05-07 10:46:12' as create_time,'2024-05-07 10:46:12' as update_time from duplicate_count\"} },{\"type\":\"hdfs_file\",\"config\":{\"path\":\"hdfs://mycluster:8020/user/default/data_quality_error_data/0_1060_[null check] filtered data persistence\",\"input_table\":\"duplicate_items\"} }]}"
[WI-1060][TI-3958] - [INFO] 2024-05-07 10:46:12.996 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-1060][TI-3958] - [INFO] 2024-05-07 10:46:12.998 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13001194483488/13505298546272_21/1060/3958/1060_3958.sh
[WI-1060][TI-3958] - [INFO] 2024-05-07 10:46:13.014 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 92
[WI-0][TI-3958] - [INFO] 2024-05-07 10:46:13.221 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=3958, success=true)
[WI-0][TI-0] - [INFO] 2024-05-07 10:46:13.247 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.194915254237288 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-3958] - [INFO] 2024-05-07 10:46:13.278 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=3958)
[WI-0][TI-0] - [INFO] 2024-05-07 10:46:14.016 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
[WI-0][TI-0] - [INFO] 2024-05-07 10:46:16.019 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	:: loading settings :: url = jar:file:/opt/spark-3.5.1-bin-hadoop3/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml
	Ivy Default Cache set to: /tmp
	The jars for the packages stored in: /tmp/jars
	org.postgresql#postgresql added as a dependency
	:: resolving dependencies :: org.apache.spark#spark-submit-parent-8cdf5544-3e5b-4f4f-9a9c-e5867a9d72ae;1.0
		confs: [default]
[WI-0][TI-0] - [INFO] 2024-05-07 10:46:17.020 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
		found org.postgresql#postgresql;42.7.3 in central
		found org.checkerframework#checker-qual;3.42.0 in central
[WI-0][TI-0] - [INFO] 2024-05-07 10:46:18.021 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	downloading https://repo1.maven.org/maven2/org/postgresql/postgresql/42.7.3/postgresql-42.7.3.jar ...
[WI-0][TI-0] - [INFO] 2024-05-07 10:46:19.025 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
		[SUCCESSFUL ] org.postgresql#postgresql;42.7.3!postgresql.jar (1271ms)
	downloading https://repo1.maven.org/maven2/org/checkerframework/checker-qual/3.42.0/checker-qual-3.42.0.jar ...
		[SUCCESSFUL ] org.checkerframework#checker-qual;3.42.0!checker-qual.jar (381ms)
	:: resolution report :: resolve 1747ms :: artifacts dl 1657ms
		:: modules in use:
		org.checkerframework#checker-qual;3.42.0 from central in [default]
		org.postgresql#postgresql;42.7.3 from central in [default]
		---------------------------------------------------------------------
		|                  |            modules            ||   artifacts   |
		|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
		---------------------------------------------------------------------
		|      default     |   2   |   2   |   2   |   0   ||   2   |   2   |
		---------------------------------------------------------------------
	:: retrieving :: org.apache.spark#spark-submit-parent-8cdf5544-3e5b-4f4f-9a9c-e5867a9d72ae
		confs: [default]
		2 artifacts copied, 0 already retrieved (1289kB/18ms)
	24/05/07 10:46:18 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[WI-0][TI-0] - [INFO] 2024-05-07 10:46:20.026 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:46:19 INFO SparkContext: Running Spark version 3.5.1
	24/05/07 10:46:19 INFO SparkContext: OS info Linux, 6.5.0-28-generic, amd64
	24/05/07 10:46:19 INFO SparkContext: Java version 1.8.0_402
	24/05/07 10:46:19 INFO ResourceUtils: ==============================================================
	24/05/07 10:46:19 INFO ResourceUtils: No custom resources configured for spark.driver.
	24/05/07 10:46:19 INFO ResourceUtils: ==============================================================
	24/05/07 10:46:19 INFO SparkContext: Submitted application: (uniqueness_check)
	24/05/07 10:46:19 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
	24/05/07 10:46:19 INFO ResourceProfile: Limiting resource is cpu
	24/05/07 10:46:19 INFO ResourceProfileManager: Added ResourceProfile id: 0
	24/05/07 10:46:19 INFO SecurityManager: Changing view acls to: default
	24/05/07 10:46:19 INFO SecurityManager: Changing modify acls to: default
	24/05/07 10:46:19 INFO SecurityManager: Changing view acls groups to: 
	24/05/07 10:46:19 INFO SecurityManager: Changing modify acls groups to: 
	24/05/07 10:46:19 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: default; groups with view permissions: EMPTY; users with modify permissions: default; groups with modify permissions: EMPTY
	24/05/07 10:46:19 INFO Utils: Successfully started service 'sparkDriver' on port 42075.
	24/05/07 10:46:19 INFO SparkEnv: Registering MapOutputTracker
	24/05/07 10:46:19 INFO SparkEnv: Registering BlockManagerMaster
	24/05/07 10:46:19 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
	24/05/07 10:46:19 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
	24/05/07 10:46:19 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
	24/05/07 10:46:19 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-7aca28b7-6497-4553-b2cb-7cabd9511981
	24/05/07 10:46:20 INFO MemoryStore: MemoryStore started with capacity 93.3 MiB
[WI-0][TI-0] - [INFO] 2024-05-07 10:46:21.032 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:46:20 INFO SparkEnv: Registering OutputCommitCoordinator
	24/05/07 10:46:20 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
	24/05/07 10:46:20 INFO Utils: Successfully started service 'SparkUI' on port 4040.
	24/05/07 10:46:20 INFO SparkContext: Added JAR file:///tmp/jars/org.postgresql_postgresql-42.7.3.jar at spark://d8bddb7812a3:42075/jars/org.postgresql_postgresql-42.7.3.jar with timestamp 1715049979430
	24/05/07 10:46:20 INFO SparkContext: Added JAR file:///tmp/jars/org.checkerframework_checker-qual-3.42.0.jar at spark://d8bddb7812a3:42075/jars/org.checkerframework_checker-qual-3.42.0.jar with timestamp 1715049979430
	24/05/07 10:46:20 INFO SparkContext: Added JAR file:/opt/dolphinscheduler/libs/dolphinscheduler-data-quality-3.2.1.jar at spark://d8bddb7812a3:42075/jars/dolphinscheduler-data-quality-3.2.1.jar with timestamp 1715049979430
	24/05/07 10:46:20 INFO Executor: Starting executor ID driver on host d8bddb7812a3
	24/05/07 10:46:20 INFO Executor: OS info Linux, 6.5.0-28-generic, amd64
	24/05/07 10:46:20 INFO Executor: Java version 1.8.0_402
	24/05/07 10:46:20 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
	24/05/07 10:46:20 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@358ab600 for default.
	24/05/07 10:46:20 INFO Executor: Fetching spark://d8bddb7812a3:42075/jars/dolphinscheduler-data-quality-3.2.1.jar with timestamp 1715049979430
	24/05/07 10:46:20 INFO TransportClientFactory: Successfully created connection to d8bddb7812a3/172.18.1.1:42075 after 28 ms (0 ms spent in bootstraps)
	24/05/07 10:46:20 INFO Utils: Fetching spark://d8bddb7812a3:42075/jars/dolphinscheduler-data-quality-3.2.1.jar to /tmp/spark-18b13db1-bc7e-4249-ad44-a31f53af9ee2/userFiles-ba6e4c36-88ad-4d37-8cb9-55ca5762ef0a/fetchFileTemp7709473590274589959.tmp
	24/05/07 10:46:20 INFO Executor: Adding file:/tmp/spark-18b13db1-bc7e-4249-ad44-a31f53af9ee2/userFiles-ba6e4c36-88ad-4d37-8cb9-55ca5762ef0a/dolphinscheduler-data-quality-3.2.1.jar to class loader default
	24/05/07 10:46:20 INFO Executor: Fetching spark://d8bddb7812a3:42075/jars/org.postgresql_postgresql-42.7.3.jar with timestamp 1715049979430
	24/05/07 10:46:20 INFO Utils: Fetching spark://d8bddb7812a3:42075/jars/org.postgresql_postgresql-42.7.3.jar to /tmp/spark-18b13db1-bc7e-4249-ad44-a31f53af9ee2/userFiles-ba6e4c36-88ad-4d37-8cb9-55ca5762ef0a/fetchFileTemp3132925248542063873.tmp
	24/05/07 10:46:20 INFO Executor: Adding file:/tmp/spark-18b13db1-bc7e-4249-ad44-a31f53af9ee2/userFiles-ba6e4c36-88ad-4d37-8cb9-55ca5762ef0a/org.postgresql_postgresql-42.7.3.jar to class loader default
	24/05/07 10:46:20 INFO Executor: Fetching spark://d8bddb7812a3:42075/jars/org.checkerframework_checker-qual-3.42.0.jar with timestamp 1715049979430
	24/05/07 10:46:20 INFO Utils: Fetching spark://d8bddb7812a3:42075/jars/org.checkerframework_checker-qual-3.42.0.jar to /tmp/spark-18b13db1-bc7e-4249-ad44-a31f53af9ee2/userFiles-ba6e4c36-88ad-4d37-8cb9-55ca5762ef0a/fetchFileTemp4297137173646353481.tmp
	24/05/07 10:46:20 INFO Executor: Adding file:/tmp/spark-18b13db1-bc7e-4249-ad44-a31f53af9ee2/userFiles-ba6e4c36-88ad-4d37-8cb9-55ca5762ef0a/org.checkerframework_checker-qual-3.42.0.jar to class loader default
	24/05/07 10:46:20 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41689.
	24/05/07 10:46:20 INFO NettyBlockTransferService: Server created on d8bddb7812a3:41689
	24/05/07 10:46:20 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
	24/05/07 10:46:20 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, d8bddb7812a3, 41689, None)
	24/05/07 10:46:20 INFO BlockManagerMasterEndpoint: Registering block manager d8bddb7812a3:41689 with 93.3 MiB RAM, BlockManagerId(driver, d8bddb7812a3, 41689, None)
	24/05/07 10:46:20 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, d8bddb7812a3, 41689, None)
	24/05/07 10:46:20 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, d8bddb7812a3, 41689, None)
	24/05/07 10:46:20 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
	24/05/07 10:46:20 INFO SharedState: Warehouse path is 'file:/tmp/dolphinscheduler/exec/process/default/13001194483488/13505298546272_21/1060/3958/spark-warehouse'.
[WI-0][TI-0] - [INFO] 2024-05-07 10:46:23.298 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7147766323024054 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:46:25.073 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:46:24 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
[WI-0][TI-0] - [INFO] 2024-05-07 10:46:26.073 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:46:25 INFO CodeGenerator: Code generated in 333.221411 ms
	24/05/07 10:46:25 INFO DAGScheduler: Registering RDD 2 (save at JdbcWriter.java:87) as input to shuffle 0
	24/05/07 10:46:26 INFO DAGScheduler: Got map stage job 0 (save at JdbcWriter.java:87) with 1 output partitions
	24/05/07 10:46:26 INFO DAGScheduler: Final stage: ShuffleMapStage 0 (save at JdbcWriter.java:87)
	24/05/07 10:46:26 INFO DAGScheduler: Parents of final stage: List()
	24/05/07 10:46:26 INFO DAGScheduler: Missing parents: List()
	24/05/07 10:46:26 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[2] at save at JdbcWriter.java:87), which has no missing parents
[WI-0][TI-0] - [INFO] 2024-05-07 10:46:27.082 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:46:26 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 34.8 KiB, free 93.3 MiB)
	24/05/07 10:46:26 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 16.5 KiB, free 93.2 MiB)
	24/05/07 10:46:26 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on d8bddb7812a3:41689 (size: 16.5 KiB, free: 93.3 MiB)
	24/05/07 10:46:26 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1585
	24/05/07 10:46:26 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[2] at save at JdbcWriter.java:87) (first 15 tasks are for partitions Vector(0))
	24/05/07 10:46:26 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
	24/05/07 10:46:26 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (d8bddb7812a3, executor driver, partition 0, PROCESS_LOCAL, 7878 bytes) 
	24/05/07 10:46:26 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
	24/05/07 10:46:26 INFO CodeGenerator: Code generated in 39.880073 ms
	24/05/07 10:46:26 INFO CodeGenerator: Code generated in 13.178248 ms
	24/05/07 10:46:26 INFO CodeGenerator: Code generated in 7.571025 ms
	24/05/07 10:46:26 INFO CodeGenerator: Code generated in 8.661048 ms
	24/05/07 10:46:26 INFO CodeGenerator: Code generated in 5.866207 ms
	24/05/07 10:46:26 INFO JDBCRDD: closed connection
	24/05/07 10:46:26 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 2491 bytes result sent to driver
	24/05/07 10:46:26 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 459 ms on d8bddb7812a3 (executor driver) (1/1)
	24/05/07 10:46:26 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
	24/05/07 10:46:26 INFO DAGScheduler: ShuffleMapStage 0 (save at JdbcWriter.java:87) finished in 0.624 s
	24/05/07 10:46:26 INFO DAGScheduler: looking for newly runnable stages
	24/05/07 10:46:26 INFO DAGScheduler: running: Set()
	24/05/07 10:46:26 INFO DAGScheduler: waiting: Set()
	24/05/07 10:46:26 INFO DAGScheduler: failed: Set()
	24/05/07 10:46:26 INFO ShufflePartitionsUtil: For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
	24/05/07 10:46:26 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
	24/05/07 10:46:26 INFO CodeGenerator: Code generated in 13.243253 ms
	24/05/07 10:46:26 INFO DAGScheduler: Registering RDD 5 (save at JdbcWriter.java:87) as input to shuffle 1
	24/05/07 10:46:26 INFO DAGScheduler: Got map stage job 1 (save at JdbcWriter.java:87) with 1 output partitions
	24/05/07 10:46:26 INFO DAGScheduler: Final stage: ShuffleMapStage 2 (save at JdbcWriter.java:87)
	24/05/07 10:46:26 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
	24/05/07 10:46:26 INFO DAGScheduler: Missing parents: List()
	24/05/07 10:46:26 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[5] at save at JdbcWriter.java:87), which has no missing parents
	24/05/07 10:46:26 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 40.5 KiB, free 93.2 MiB)
	24/05/07 10:46:26 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 19.1 KiB, free 93.2 MiB)
	24/05/07 10:46:26 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on d8bddb7812a3:41689 (size: 19.1 KiB, free: 93.3 MiB)
	24/05/07 10:46:26 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1585
	24/05/07 10:46:26 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[5] at save at JdbcWriter.java:87) (first 15 tasks are for partitions Vector(0))
	24/05/07 10:46:26 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
	24/05/07 10:46:26 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 1) (d8bddb7812a3, executor driver, partition 0, NODE_LOCAL, 8032 bytes) 
	24/05/07 10:46:26 INFO Executor: Running task 0.0 in stage 2.0 (TID 1)
	24/05/07 10:46:26 INFO ShuffleBlockFetcherIterator: Getting 1 (2.9 KiB) non-empty blocks including 1 (2.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
	24/05/07 10:46:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 17 ms
	24/05/07 10:46:26 INFO CodeGenerator: Code generated in 19.729596 ms
	24/05/07 10:46:27 INFO BlockManagerInfo: Removed broadcast_0_piece0 on d8bddb7812a3:41689 in memory (size: 16.5 KiB, free: 93.3 MiB)
	24/05/07 10:46:27 INFO Executor: Finished task 0.0 in stage 2.0 (TID 1). 5463 bytes result sent to driver
	24/05/07 10:46:27 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 1) in 183 ms on d8bddb7812a3 (executor driver) (1/1)
	24/05/07 10:46:27 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
	24/05/07 10:46:27 INFO DAGScheduler: ShuffleMapStage 2 (save at JdbcWriter.java:87) finished in 0.204 s
	24/05/07 10:46:27 INFO DAGScheduler: looking for newly runnable stages
	24/05/07 10:46:27 INFO DAGScheduler: running: Set()
	24/05/07 10:46:27 INFO DAGScheduler: waiting: Set()
	24/05/07 10:46:27 INFO DAGScheduler: failed: Set()
[WI-0][TI-0] - [INFO] 2024-05-07 10:46:27.385 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7278911564625851 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:46:28.084 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:46:27 INFO CodeGenerator: Code generated in 79.684931 ms
	24/05/07 10:46:27 INFO SparkContext: Starting job: save at JdbcWriter.java:87
	24/05/07 10:46:27 INFO DAGScheduler: Got job 2 (save at JdbcWriter.java:87) with 1 output partitions
	24/05/07 10:46:27 INFO DAGScheduler: Final stage: ResultStage 5 (save at JdbcWriter.java:87)
	24/05/07 10:46:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
	24/05/07 10:46:27 INFO DAGScheduler: Missing parents: List()
	24/05/07 10:46:27 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[10] at save at JdbcWriter.java:87), which has no missing parents
	24/05/07 10:46:27 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 51.4 KiB, free 93.2 MiB)
	24/05/07 10:46:27 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 23.1 KiB, free 93.2 MiB)
	24/05/07 10:46:27 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on d8bddb7812a3:41689 (size: 23.1 KiB, free: 93.3 MiB)
	24/05/07 10:46:27 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1585
	24/05/07 10:46:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[10] at save at JdbcWriter.java:87) (first 15 tasks are for partitions Vector(0))
	24/05/07 10:46:27 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
	24/05/07 10:46:27 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 2) (d8bddb7812a3, executor driver, partition 0, NODE_LOCAL, 8043 bytes) 
	24/05/07 10:46:27 INFO Executor: Running task 0.0 in stage 5.0 (TID 2)
	24/05/07 10:46:27 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
	24/05/07 10:46:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
	24/05/07 10:46:27 INFO CodeGenerator: Code generated in 57.834289 ms
[WI-0][TI-0] - [INFO] 2024-05-07 10:46:28.444 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7186544342507646 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:46:29.088 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:46:28 INFO BlockManagerInfo: Removed broadcast_1_piece0 on d8bddb7812a3:41689 in memory (size: 19.1 KiB, free: 93.3 MiB)
[WI-0][TI-0] - [INFO] 2024-05-07 10:46:30.090 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:46:29 INFO CodeGenerator: Code generated in 14.612424 ms
	24/05/07 10:46:29 INFO Executor: Finished task 0.0 in stage 5.0 (TID 2). 6711 bytes result sent to driver
	24/05/07 10:46:29 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 2) in 2175 ms on d8bddb7812a3 (executor driver) (1/1)
	24/05/07 10:46:29 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
	24/05/07 10:46:29 INFO DAGScheduler: ResultStage 5 (save at JdbcWriter.java:87) finished in 2.328 s
	24/05/07 10:46:29 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
	24/05/07 10:46:29 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
	24/05/07 10:46:29 INFO DAGScheduler: Job 2 finished: save at JdbcWriter.java:87, took 2.363865 s
	24/05/07 10:46:29 INFO DAGScheduler: Registering RDD 13 (save at JdbcWriter.java:87) as input to shuffle 2
	24/05/07 10:46:29 INFO DAGScheduler: Got map stage job 3 (save at JdbcWriter.java:87) with 1 output partitions
	24/05/07 10:46:29 INFO DAGScheduler: Final stage: ShuffleMapStage 6 (save at JdbcWriter.java:87)
	24/05/07 10:46:29 INFO DAGScheduler: Parents of final stage: List()
	24/05/07 10:46:29 INFO DAGScheduler: Missing parents: List()
	24/05/07 10:46:29 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[13] at save at JdbcWriter.java:87), which has no missing parents
	24/05/07 10:46:29 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 34.8 KiB, free 93.2 MiB)
	24/05/07 10:46:29 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 16.5 KiB, free 93.2 MiB)
	24/05/07 10:46:29 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on d8bddb7812a3:41689 (size: 16.5 KiB, free: 93.3 MiB)
	24/05/07 10:46:29 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1585
	24/05/07 10:46:29 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[13] at save at JdbcWriter.java:87) (first 15 tasks are for partitions Vector(0))
	24/05/07 10:46:29 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0
	24/05/07 10:46:29 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 3) (d8bddb7812a3, executor driver, partition 0, PROCESS_LOCAL, 7878 bytes) 
	24/05/07 10:46:29 INFO Executor: Running task 0.0 in stage 6.0 (TID 3)
	24/05/07 10:46:30 INFO JDBCRDD: closed connection
	24/05/07 10:46:30 INFO Executor: Finished task 0.0 in stage 6.0 (TID 3). 2448 bytes result sent to driver
	24/05/07 10:46:30 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 3) in 60 ms on d8bddb7812a3 (executor driver) (1/1)
	24/05/07 10:46:30 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
	24/05/07 10:46:30 INFO DAGScheduler: ShuffleMapStage 6 (save at JdbcWriter.java:87) finished in 0.069 s
	24/05/07 10:46:30 INFO DAGScheduler: looking for newly runnable stages
	24/05/07 10:46:30 INFO DAGScheduler: running: Set()
	24/05/07 10:46:30 INFO DAGScheduler: waiting: Set()
	24/05/07 10:46:30 INFO DAGScheduler: failed: Set()
	24/05/07 10:46:30 INFO ShufflePartitionsUtil: For shuffle(2), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
	24/05/07 10:46:30 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
	24/05/07 10:46:30 INFO DAGScheduler: Registering RDD 16 (save at JdbcWriter.java:87) as input to shuffle 3
	24/05/07 10:46:30 INFO DAGScheduler: Got map stage job 4 (save at JdbcWriter.java:87) with 1 output partitions
	24/05/07 10:46:30 INFO DAGScheduler: Final stage: ShuffleMapStage 8 (save at JdbcWriter.java:87)
	24/05/07 10:46:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
[WI-0][TI-0] - [INFO] 2024-05-07 10:46:30.497 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7956403269754767 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:46:31.092 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:46:30 INFO DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[16] at save at JdbcWriter.java:87), which has no missing parents
	24/05/07 10:46:30 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 40.6 KiB, free 93.1 MiB)
	24/05/07 10:46:30 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 19.1 KiB, free 93.1 MiB)
	24/05/07 10:46:30 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on d8bddb7812a3:41689 (size: 19.1 KiB, free: 93.2 MiB)
	24/05/07 10:46:30 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1585
	24/05/07 10:46:30 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[16] at save at JdbcWriter.java:87) (first 15 tasks are for partitions Vector(0))
	24/05/07 10:46:30 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0
	24/05/07 10:46:30 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 4) (d8bddb7812a3, executor driver, partition 0, NODE_LOCAL, 8032 bytes) 
	24/05/07 10:46:30 INFO Executor: Running task 0.0 in stage 8.0 (TID 4)
	24/05/07 10:46:30 INFO ShuffleBlockFetcherIterator: Getting 1 (2.9 KiB) non-empty blocks including 1 (2.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
	24/05/07 10:46:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
	24/05/07 10:46:30 INFO Executor: Finished task 0.0 in stage 8.0 (TID 4). 5420 bytes result sent to driver
	24/05/07 10:46:30 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 4) in 41 ms on d8bddb7812a3 (executor driver) (1/1)
	24/05/07 10:46:30 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
	24/05/07 10:46:30 INFO DAGScheduler: ShuffleMapStage 8 (save at JdbcWriter.java:87) finished in 0.057 s
	24/05/07 10:46:30 INFO DAGScheduler: looking for newly runnable stages
	24/05/07 10:46:30 INFO DAGScheduler: running: Set()
	24/05/07 10:46:30 INFO DAGScheduler: waiting: Set()
	24/05/07 10:46:30 INFO DAGScheduler: failed: Set()
	24/05/07 10:46:30 INFO CodeGenerator: Code generated in 86.040516 ms
	24/05/07 10:46:30 INFO SparkContext: Starting job: save at JdbcWriter.java:87
	24/05/07 10:46:30 INFO DAGScheduler: Got job 5 (save at JdbcWriter.java:87) with 1 output partitions
	24/05/07 10:46:30 INFO DAGScheduler: Final stage: ResultStage 11 (save at JdbcWriter.java:87)
	24/05/07 10:46:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)
	24/05/07 10:46:30 INFO BlockManagerInfo: Removed broadcast_3_piece0 on d8bddb7812a3:41689 in memory (size: 16.5 KiB, free: 93.3 MiB)
	24/05/07 10:46:30 INFO DAGScheduler: Missing parents: List()
	24/05/07 10:46:30 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[21] at save at JdbcWriter.java:87), which has no missing parents
	24/05/07 10:46:30 INFO BlockManagerInfo: Removed broadcast_2_piece0 on d8bddb7812a3:41689 in memory (size: 23.1 KiB, free: 93.3 MiB)
	24/05/07 10:46:30 INFO BlockManagerInfo: Removed broadcast_4_piece0 on d8bddb7812a3:41689 in memory (size: 19.1 KiB, free: 93.3 MiB)
	24/05/07 10:46:30 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 49.2 KiB, free 93.2 MiB)
	24/05/07 10:46:30 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 22.7 KiB, free 93.2 MiB)
	24/05/07 10:46:30 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on d8bddb7812a3:41689 (size: 22.7 KiB, free: 93.3 MiB)
	24/05/07 10:46:30 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1585
	24/05/07 10:46:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[21] at save at JdbcWriter.java:87) (first 15 tasks are for partitions Vector(0))
	24/05/07 10:46:30 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks resource profile 0
	24/05/07 10:46:30 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 5) (d8bddb7812a3, executor driver, partition 0, NODE_LOCAL, 8043 bytes) 
	24/05/07 10:46:30 INFO Executor: Running task 0.0 in stage 11.0 (TID 5)
	24/05/07 10:46:30 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
	24/05/07 10:46:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
	24/05/07 10:46:30 INFO CodeGenerator: Code generated in 12.403724 ms
	24/05/07 10:46:30 INFO CodeGenerator: Code generated in 22.400926 ms
	24/05/07 10:46:30 INFO Executor: Finished task 0.0 in stage 11.0 (TID 5). 6625 bytes result sent to driver
	24/05/07 10:46:30 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 5) in 149 ms on d8bddb7812a3 (executor driver) (1/1)
	24/05/07 10:46:30 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
	24/05/07 10:46:30 INFO DAGScheduler: ResultStage 11 (save at JdbcWriter.java:87) finished in 0.306 s
	24/05/07 10:46:30 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
	24/05/07 10:46:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 11: Stage finished
	24/05/07 10:46:30 INFO DAGScheduler: Job 5 finished: save at JdbcWriter.java:87, took 0.345823 s
	24/05/07 10:46:30 WARN FileSystem: Failed to initialize fileystem hdfs://mycluster:8020/user/default/data_quality_error_data/0_1060_%5Bnull%20check%5D%20filtered%20data%20persistence: java.lang.IllegalArgumentException: java.net.UnknownHostException: mycluster
	Exception in thread "main" java.lang.IllegalArgumentException: java.net.UnknownHostException: mycluster
		at org.apache.hadoop.security.SecurityUtil.buildTokenService(SecurityUtil.java:466)
		at org.apache.hadoop.hdfs.NameNodeProxiesClient.createProxyWithClientProtocol(NameNodeProxiesClient.java:134)
		at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:374)
		at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:308)
		at org.apache.hadoop.hdfs.DistributedFileSystem.initDFSClient(DistributedFileSystem.java:202)
		at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:187)
		at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469)
		at org.apache.hadoop.fs.FileSystem.access$300(FileSystem.java:174)
		at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3574)
		at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3521)
		at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540)
		at org.apache.hadoop.fs.Path.getFileSystem(Path.java:365)
		at org.apache.spark.sql.execution.datasources.DataSource.planForWritingFileFormat(DataSource.scala:454)
		at org.apache.spark.sql.execution.datasources.DataSource.planForWriting(DataSource.scala:530)
		at org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)
		at org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)
		at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:240)
		at org.apache.spark.sql.DataFrameWriter.csv(DataFrameWriter.scala:850)
		at org.apache.dolphinscheduler.data.quality.flow.batch.writer.file.BaseFileWriter.outputImpl(BaseFileWriter.java:114)
		at org.apache.dolphinscheduler.data.quality.flow.batch.writer.file.HdfsFileWriter.write(HdfsFileWriter.java:40)
		at org.apache.dolphinscheduler.data.quality.execution.SparkBatchExecution.executeWriter(SparkBatchExecution.java:132)
		at org.apache.dolphinscheduler.data.quality.execution.SparkBatchExecution.execute(SparkBatchExecution.java:58)
		at org.apache.dolphinscheduler.data.quality.context.DataQualityContext.execute(DataQualityContext.java:62)
		at org.apache.dolphinscheduler.data.quality.DataQualityApplication.main(DataQualityApplication.java:78)
		at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
		at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
		at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
		at java.lang.reflect.Method.invoke(Method.java:498)
		at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
		at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:1029)
		at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:194)
		at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:217)
		at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:91)
		at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1120)
		at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1129)
		at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
	Caused by: java.net.UnknownHostException: mycluster
		... 36 more
	24/05/07 10:46:30 INFO SparkContext: Invoking stop() from shutdown hook
	24/05/07 10:46:30 INFO SparkContext: SparkContext is stopping with exitCode 0.
	24/05/07 10:46:30 INFO SparkUI: Stopped Spark web UI at http://d8bddb7812a3:4040
	24/05/07 10:46:31 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
[WI-0][TI-0] - [INFO] 2024-05-07 10:46:32.103 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:46:31 INFO MemoryStore: MemoryStore cleared
	24/05/07 10:46:31 INFO BlockManager: BlockManager stopped
	24/05/07 10:46:31 INFO BlockManagerMaster: BlockManagerMaster stopped
	24/05/07 10:46:31 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
	24/05/07 10:46:31 INFO SparkContext: Successfully stopped SparkContext
	24/05/07 10:46:31 INFO ShutdownHookManager: Shutdown hook called
	24/05/07 10:46:31 INFO ShutdownHookManager: Deleting directory /tmp/spark-a9230bde-c09d-45cb-a123-a7fb1f6540de
	24/05/07 10:46:31 INFO ShutdownHookManager: Deleting directory /tmp/spark-18b13db1-bc7e-4249-ad44-a31f53af9ee2
[WI-1060][TI-3958] - [INFO] 2024-05-07 10:46:32.111 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13001194483488/13505298546272_21/1060/3958, processId:92 ,exitStatusCode:1 ,processWaitForStatus:true ,processExitValue:1
[WI-1060][TI-3958] - [INFO] 2024-05-07 10:46:32.115 +0800 o.a.d.p.t.a.u.LogUtils:[79] - Start finding appId in /opt/dolphinscheduler/logs/20240507/13505298546272/21/1060/3958.log, fetch way: log 
[WI-1060][TI-3958] - [INFO] 2024-05-07 10:46:32.120 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-1060][TI-3958] - [INFO] 2024-05-07 10:46:32.120 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-1060][TI-3958] - [INFO] 2024-05-07 10:46:32.121 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-1060][TI-3958] - [INFO] 2024-05-07 10:46:32.125 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-1060][TI-3958] - [INFO] 2024-05-07 10:46:32.216 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: FAILURE to master : 172.18.1.1:1234
[WI-1060][TI-3958] - [INFO] 2024-05-07 10:46:32.217 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-1060][TI-3958] - [INFO] 2024-05-07 10:46:32.217 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13001194483488/13505298546272_21/1060/3958
[WI-1060][TI-3958] - [INFO] 2024-05-07 10:46:32.295 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13001194483488/13505298546272_21/1060/3958
[WI-1060][TI-3958] - [INFO] 2024-05-07 10:46:32.301 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-0] - [INFO] 2024-05-07 10:46:32.556 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7492625368731564 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:46:37.645 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8126801152737753 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:46:38.657 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7171428571428572 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:46:39.663 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8571428571428572 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:46:40.683 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8226744186046512 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:46:41.684 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.910919540229885 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:46:42.687 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8603351955307263 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:46:43.689 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7870992408105304 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:46:44.691 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7893258426966292 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:46:45.696 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9333333333333333 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:46:46.698 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7439024390243902 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:46:50.733 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8452380952380951 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:46:51.758 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7857142857142857 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:46:52.768 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7055393586005831 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:46:53.964 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=3959, taskName=[null check] filtered data persistence, firstSubmitTime=1715050013888, startTime=0, taskType=DATA_QUALITY, workflowInstanceHost=172.18.0.17:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13505298546272, processDefineVersion=21, appIds=null, processInstanceId=1061, scheduleTime=0, globalParams=null, executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13001194483488, taskParams={"localParams":[],"resourceList":[],"ruleId":6,"ruleInputParameter":{"check_type":"0","comparison_type":1,"comparison_name":"0","failure_strategy":"0","operator":"0","src_connector_type":1,"src_datasource_id":6,"src_database":"persistence","src_field":"content","src_table":"filtered_data_persistence","threshold":"0"},"sparkParameters":{"deployMode":"local","driverCores":1,"driverMemory":"512M","executorCores":1,"executorMemory":"1G","numExecutors":1,"others":"--conf spark.driver.extraJavaOptions=\"-Divy.cache.dir=/tmp -Divy.home=/tmp\" \\\n--packages org.postgresql:postgresql:42.7.3","yarnQueue":""}}, environmentConfig=export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export PYSPARK_DRIVER_PYTHON=/bin/python3.11
export PYSPARK_PYTHON=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='[null check] filtered data persistence'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13001194483488'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='1061'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240507'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240506'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='3959'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='qualti_test'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13505264408800'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13505298546272'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240507104653'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=null, dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=org.apache.dolphinscheduler.plugin.task.api.DataQualityTaskExecutionContext@223e3a7d, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-1061][TI-3959] - [INFO] 2024-05-07 10:46:53.977 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: [null check] filtered data persistence to wait queue success
[WI-1061][TI-3959] - [INFO] 2024-05-07 10:46:53.977 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-1061][TI-3959] - [INFO] 2024-05-07 10:46:53.982 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-1061][TI-3959] - [INFO] 2024-05-07 10:46:53.982 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-1061][TI-3959] - [INFO] 2024-05-07 10:46:53.982 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-1061][TI-3959] - [INFO] 2024-05-07 10:46:53.983 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1715050013982
[WI-1061][TI-3959] - [INFO] 2024-05-07 10:46:53.983 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 1061_3959
[WI-1061][TI-3959] - [INFO] 2024-05-07 10:46:53.986 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 3959,
  "taskName" : "[null check] filtered data persistence",
  "firstSubmitTime" : 1715050013888,
  "startTime" : 1715050013982,
  "taskType" : "DATA_QUALITY",
  "workflowInstanceHost" : "172.18.0.17:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240507/13505298546272/21/1061/3959.log",
  "processId" : 0,
  "processDefineCode" : 13505298546272,
  "processDefineVersion" : 21,
  "processInstanceId" : 1061,
  "scheduleTime" : 0,
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13001194483488,
  "taskParams" : "{\"localParams\":[],\"resourceList\":[],\"ruleId\":6,\"ruleInputParameter\":{\"check_type\":\"0\",\"comparison_type\":1,\"comparison_name\":\"0\",\"failure_strategy\":\"0\",\"operator\":\"0\",\"src_connector_type\":1,\"src_datasource_id\":6,\"src_database\":\"persistence\",\"src_field\":\"content\",\"src_table\":\"filtered_data_persistence\",\"threshold\":\"0\"},\"sparkParameters\":{\"deployMode\":\"local\",\"driverCores\":1,\"driverMemory\":\"512M\",\"executorCores\":1,\"executorMemory\":\"1G\",\"numExecutors\":1,\"others\":\"--conf spark.driver.extraJavaOptions=\\\"-Divy.cache.dir=/tmp -Divy.home=/tmp\\\" \\\\\\n--packages org.postgresql:postgresql:42.7.3\",\"yarnQueue\":\"\"}}",
  "environmentConfig" : "export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3\nexport JAVA_HOME=/opt/java/openjdk\nexport PYSPARK_DRIVER_PYTHON=/bin/python3.11\nexport PYSPARK_PYTHON=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "[null check] filtered data persistence"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13001194483488"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1061"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240507"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240506"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "3959"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "qualti_test"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13505264408800"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13505298546272"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240507104653"
    }
  },
  "taskAppId" : "1061_3959",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "dryRun" : 0,
  "paramsMap" : { },
  "dataQualityTaskExecutionContext" : {
    "ruleId" : 6,
    "ruleName" : "$t(uniqueness_check)",
    "ruleType" : 0,
    "ruleInputEntryList" : "[{\"id\":1,\"field\":\"src_connector_type\",\"type\":\"select\",\"title\":\"$t(src_connector_type)\",\"data\":\"\",\"options\":\"[{\\\"label\\\":\\\"HIVE\\\",\\\"value\\\":\\\"HIVE\\\"},{\\\"label\\\":\\\"JDBC\\\",\\\"value\\\":\\\"JDBC\\\"}]\",\"placeholder\":\"please select source connector type\",\"optionSourceType\":2,\"dataType\":2,\"inputType\":0,\"isShow\":true,\"canEdit\":true,\"isEmit\":true,\"isValidate\":false,\"valuesMap\":null,\"index\":1,\"createTime\":null,\"updateTime\":null},{\"id\":2,\"field\":\"src_datasource_id\",\"type\":\"select\",\"title\":\"$t(src_datasource_id)\",\"data\":\"\",\"options\":null,\"placeholder\":\"please select source datasource id\",\"optionSourceType\":1,\"dataType\":2,\"inputType\":0,\"isShow\":true,\"canEdit\":true,\"isEmit\":true,\"isValidate\":false,\"valuesMap\":null,\"index\":2,\"createTime\":null,\"updateTime\":null},{\"id\":30,\"field\":\"src_database\",\"type\":\"select\",\"title\":\"$t(src_database)\",\"data\":null,\"options\":null,\"placeholder\":\"Please select source database\",\"optionSourceType\":0,\"dataType\":0,\"inputType\":0,\"isShow\":true,\"canEdit\":true,\"isEmit\":true,\"isValidate\":true,\"valuesMap\":null,\"index\":2,\"createTime\":null,\"updateTime\":null},{\"id\":3,\"field\":\"src_table\",\"type\":\"select\",\"title\":\"$t(src_table)\",\"data\":null,\"options\":null,\"placeholder\":\"Please enter source table name\",\"optionSourceType\":0,\"dataType\":0,\"inputType\":0,\"isShow\":true,\"canEdit\":true,\"isEmit\":true,\"isValidate\":true,\"valuesMap\":null,\"index\":3,\"createTime\":null,\"updateTime\":null},{\"id\":4,\"field\":\"src_filter\",\"type\":\"input\",\"title\":\"$t(src_filter)\",\"data\":null,\"options\":null,\"placeholder\":\"Please enter filter expression\",\"optionSourceType\":0,\"dataType\":3,\"inputType\":0,\"isShow\":true,\"canEdit\":true,\"isEmit\":false,\"isValidate\":false,\"valuesMap\":null,\"index\":4,\"createTime\":null,\"updateTime\":null},{\"id\":5,\"field\":\"src_field\",\"type\":\"select\",\"title\":\"$t(src_field)\",\"data\":null,\"options\":null,\"placeholder\":\"Please enter column, only single column is supported\",\"optionSourceType\":0,\"dataType\":0,\"inputType\":0,\"isShow\":true,\"canEdit\":true,\"isEmit\":false,\"isValidate\":true,\"valuesMap\":null,\"index\":5,\"createTime\":null,\"updateTime\":null},{\"id\":6,\"field\":\"statistics_name\",\"type\":\"input\",\"title\":\"$t(statistics_name)\",\"data\":\"duplicate_count.duplicates\",\"options\":null,\"placeholder\":\"Please enter statistics name, the alias in statistics execute sql\",\"optionSourceType\":0,\"dataType\":0,\"inputType\":1,\"isShow\":false,\"canEdit\":false,\"isEmit\":false,\"isValidate\":true,\"valuesMap\":\"{\\\"statistics_name\\\":\\\"duplicate_count.duplicates\\\"}\",\"index\":6,\"createTime\":null,\"updateTime\":null},{\"id\":7,\"field\":\"check_type\",\"type\":\"select\",\"title\":\"$t(check_type)\",\"data\":\"0\",\"options\":\"[{\\\"label\\\":\\\"Expected - Actual\\\",\\\"value\\\":\\\"0\\\"},{\\\"label\\\":\\\"Actual - Expected\\\",\\\"value\\\":\\\"1\\\"},{\\\"label\\\":\\\"Actual / Expected\\\",\\\"value\\\":\\\"2\\\"},{\\\"label\\\":\\\"(Expected - Actual) / Expected\\\",\\\"value\\\":\\\"3\\\"}]\",\"placeholder\":\"please select check type\",\"optionSourceType\":0,\"dataType\":0,\"inputType\":3,\"isShow\":true,\"canEdit\":true,\"isEmit\":true,\"isValidate\":false,\"valuesMap\":null,\"index\":7,\"createTime\":null,\"updateTime\":null},{\"id\":8,\"field\":\"operator\",\"type\":\"select\",\"title\":\"$t(operator)\",\"data\":\"0\",\"options\":\"[{\\\"label\\\":\\\"=\\\",\\\"value\\\":\\\"0\\\"},{\\\"label\\\":\\\"<\\\",\\\"value\\\":\\\"1\\\"},{\\\"label\\\":\\\"<=\\\",\\\"value\\\":\\\"2\\\"},{\\\"label\\\":\\\">\\\",\\\"value\\\":\\\"3\\\"},{\\\"label\\\":\\\">=\\\",\\\"value\\\":\\\"4\\\"},{\\\"label\\\":\\\"!=\\\",\\\"value\\\":\\\"5\\\"}]\",\"placeholder\":\"please select operator\",\"optionSourceType\":0,\"dataType\":0,\"inputType\":3,\"isShow\":true,\"canEdit\":true,\"isEmit\":false,\"isValidate\":false,\"valuesMap\":null,\"index\":8,\"createTime\":null,\"updateTime\":null},{\"id\":9,\"field\":\"threshold\",\"type\":\"input\",\"title\":\"$t(threshold)\",\"data\":null,\"options\":null,\"placeholder\":\"Please enter threshold, number is needed\",\"optionSourceType\":0,\"dataType\":2,\"inputType\":3,\"isShow\":true,\"canEdit\":true,\"isEmit\":false,\"isValidate\":true,\"valuesMap\":null,\"index\":9,\"createTime\":null,\"updateTime\":null},{\"id\":10,\"field\":\"failure_strategy\",\"type\":\"select\",\"title\":\"$t(failure_strategy)\",\"data\":\"0\",\"options\":\"[{\\\"label\\\":\\\"Alert\\\",\\\"value\\\":\\\"0\\\"},{\\\"label\\\":\\\"Block\\\",\\\"value\\\":\\\"1\\\"}]\",\"placeholder\":\"please select failure strategy\",\"optionSourceType\":0,\"dataType\":0,\"inputType\":3,\"isShow\":true,\"canEdit\":true,\"isEmit\":false,\"isValidate\":false,\"valuesMap\":null,\"index\":10,\"createTime\":null,\"updateTime\":null},{\"id\":17,\"field\":\"comparison_name\",\"type\":\"input\",\"title\":\"$t(comparison_name)\",\"data\":null,\"options\":null,\"placeholder\":\"Please enter comparison name, the alias in comparison execute sql\",\"optionSourceType\":0,\"dataType\":0,\"inputType\":0,\"isShow\":false,\"canEdit\":false,\"isEmit\":false,\"isValidate\":true,\"valuesMap\":\"\",\"index\":11,\"createTime\":null,\"updateTime\":null},{\"id\":19,\"field\":\"comparison_type\",\"type\":\"select\",\"title\":\"$t(comparison_type)\",\"data\":\"\",\"options\":null,\"placeholder\":\"Please enter comparison title\",\"optionSourceType\":3,\"dataType\":0,\"inputType\":2,\"isShow\":true,\"canEdit\":false,\"isEmit\":true,\"isValidate\":false,\"valuesMap\":null,\"index\":12,\"createTime\":null,\"updateTime\":null}]",
    "executeSqlList" : "[{\"id\":6,\"index\":1,\"sql\":\"SELECT ${src_field} FROM ${src_table} group by ${src_field} having count(*) > 1\",\"tableAlias\":\"duplicate_items\",\"type\":0,\"createTime\":\"2021-03-03 11:31:24\",\"updateTime\":\"2021-03-03 11:31:24\",\"errorOutputSql\":true},{\"id\":7,\"index\":1,\"sql\":\"SELECT COUNT(*) AS duplicates FROM duplicate_items\",\"tableAlias\":\"duplicate_count\",\"type\":1,\"createTime\":\"2021-03-03 11:31:24\",\"updateTime\":\"2021-03-03 11:31:24\",\"errorOutputSql\":false}]",
    "comparisonNeedStatisticsValueTable" : false,
    "compareWithFixedValue" : true,
    "hdfsPath" : "hdfs://mycluster:8020/user/default/data_quality_error_data",
    "sourceConnectorType" : "JDBC",
    "sourceType" : 1,
    "sourceConnectionParams" : "{\"user\":\"root\",\"password\":\"root\",\"address\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432\",\"database\":\"persistence\",\"jdbcUrl\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432/persistence\",\"driverClassName\":\"org.postgresql.Driver\",\"validationQuery\":\"select version()\",\"other\":{\"password\":\"root\"}}",
    "targetConnectorType" : null,
    "targetType" : 0,
    "targetConnectionParams" : null,
    "writerConnectorType" : "JDBC",
    "writerType" : 1,
    "writerTable" : "t_ds_dq_execute_result",
    "writerConnectionParams" : "{\"user\":\"root\",\"password\":\"root\",\"address\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432\",\"database\":\"dolphinscheduler\",\"jdbcUrl\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432/dolphinscheduler\"}",
    "statisticsValueConnectorType" : "JDBC",
    "statisticsValueType" : 1,
    "statisticsValueTable" : "t_ds_dq_task_statistics_value",
    "statisticsValueWriterConnectionParams" : "{\"user\":\"root\",\"password\":\"root\",\"address\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432\",\"database\":\"dolphinscheduler\",\"jdbcUrl\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432/dolphinscheduler\"}"
  },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-1061][TI-3959] - [INFO] 2024-05-07 10:46:53.995 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-1061][TI-3959] - [INFO] 2024-05-07 10:46:53.995 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-1061][TI-3959] - [INFO] 2024-05-07 10:46:53.996 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-1061][TI-3959] - [INFO] 2024-05-07 10:46:54.011 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-1061][TI-3959] - [INFO] 2024-05-07 10:46:54.013 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-1061][TI-3959] - [INFO] 2024-05-07 10:46:54.015 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13001194483488/13505298546272_21/1061/3959 check successfully
[WI-1061][TI-3959] - [INFO] 2024-05-07 10:46:54.017 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.dq.DataQualityTaskChannel successfully
[WI-1061][TI-3959] - [INFO] 2024-05-07 10:46:54.018 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-1061][TI-3959] - [INFO] 2024-05-07 10:46:54.019 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-1061][TI-3959] - [INFO] 2024-05-07 10:46:54.019 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: DATA_QUALITY create successfully
[WI-1061][TI-3959] - [INFO] 2024-05-07 10:46:54.020 +0800 o.a.d.p.t.d.DataQualityTask:[89] - Initialize data quality task params {
  "localParams" : [ ],
  "varPool" : null,
  "ruleId" : 6,
  "ruleInputParameter" : {
    "check_type" : "0",
    "comparison_type" : "1",
    "comparison_name" : "0",
    "failure_strategy" : "0",
    "operator" : "0",
    "src_connector_type" : "1",
    "src_datasource_id" : "6",
    "src_database" : "persistence",
    "src_field" : "content",
    "src_table" : "filtered_data_persistence",
    "threshold" : "0"
  },
  "sparkParameters" : {
    "localParams" : null,
    "varPool" : null,
    "mainJar" : null,
    "mainClass" : null,
    "deployMode" : "local",
    "mainArgs" : null,
    "driverCores" : 1,
    "driverMemory" : "512M",
    "numExecutors" : 1,
    "executorCores" : 1,
    "executorMemory" : "1G",
    "appName" : null,
    "yarnQueue" : "",
    "others" : "--conf spark.driver.extraJavaOptions=\"-Divy.cache.dir=/tmp -Divy.home=/tmp\" \\\n--packages org.postgresql:postgresql:42.7.3",
    "programType" : null,
    "resourceList" : [ ]
  }
}
[WI-1061][TI-3959] - [INFO] 2024-05-07 10:46:54.042 +0800 o.a.d.p.t.d.DataQualityTask:[119] - data quality configuration: {
  "name" : "$t(uniqueness_check)",
  "env" : {
    "type" : "batch",
    "config" : null
  },
  "readers" : [ {
    "type" : "JDBC",
    "config" : {
      "database" : "persistence",
      "password" : "root",
      "driver" : "org.postgresql.Driver",
      "user" : "root",
      "output_table" : "persistence_filtered_data_persistence",
      "table" : "filtered_data_persistence",
      "url" : "jdbc:postgresql://dolphinscheduler-postgresql:5432/persistence?password=root"
    }
  } ],
  "transformers" : [ {
    "type" : "sql",
    "config" : {
      "index" : 1,
      "output_table" : "duplicate_items",
      "sql" : "SELECT content FROM persistence_filtered_data_persistence group by content having count(*) > 1"
    }
  }, {
    "type" : "sql",
    "config" : {
      "index" : 2,
      "output_table" : "duplicate_count",
      "sql" : "SELECT COUNT(*) AS duplicates FROM duplicate_items"
    }
  } ],
  "writers" : [ {
    "type" : "JDBC",
    "config" : {
      "database" : "dolphinscheduler",
      "password" : "root",
      "driver" : "org.postgresql.Driver",
      "user" : "root",
      "table" : "t_ds_dq_execute_result",
      "url" : "jdbc:postgresql://dolphinscheduler-postgresql:5432/dolphinscheduler",
      "sql" : "select 0 as rule_type,'$t(uniqueness_check)' as rule_name,0 as process_definition_id,1061 as process_instance_id,3959 as task_instance_id,duplicate_count.duplicates AS statistics_value,0 AS comparison_value,1 AS comparison_type,0 as check_type,0 as threshold,0 as operator,0 as failure_strategy,'hdfs://mycluster:8020/user/default/data_quality_error_data/0_1061_[null check] filtered data persistence' as error_output_path,'2024-05-07 10:46:54' as create_time,'2024-05-07 10:46:54' as update_time from duplicate_count "
    }
  }, {
    "type" : "JDBC",
    "config" : {
      "database" : "dolphinscheduler",
      "password" : "root",
      "driver" : "org.postgresql.Driver",
      "user" : "root",
      "table" : "t_ds_dq_task_statistics_value",
      "url" : "jdbc:postgresql://dolphinscheduler-postgresql:5432/dolphinscheduler",
      "sql" : "select 0 as process_definition_id,3959 as task_instance_id,6 as rule_id,'KA0AXXWVHWW+GZX4BPZXFGFZ0F0OYMUQ+BVYG4+ZIKG=' as unique_code,'duplicate_count.duplicates'AS statistics_name,duplicate_count.duplicates AS statistics_value,'2024-05-07 10:46:54' as data_time,'2024-05-07 10:46:54' as create_time,'2024-05-07 10:46:54' as update_time from duplicate_count"
    }
  }, {
    "type" : "hdfs_file",
    "config" : {
      "path" : "hdfs://mycluster:8020/user/default/data_quality_error_data/0_1061_[null check] filtered data persistence",
      "input_table" : "duplicate_items"
    }
  } ]
}
[WI-1061][TI-3959] - [INFO] 2024-05-07 10:46:54.043 +0800 o.a.d.p.d.a.u.CommonUtils:[136] - Trying to get data quality jar in path
[WI-1061][TI-3959] - [INFO] 2024-05-07 10:46:54.044 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-1061][TI-3959] - [INFO] 2024-05-07 10:46:54.044 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: null successfully
[WI-1061][TI-3959] - [INFO] 2024-05-07 10:46:54.044 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-1061][TI-3959] - [INFO] 2024-05-07 10:46:54.044 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-1061][TI-3959] - [INFO] 2024-05-07 10:46:54.044 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-1061][TI-3959] - [INFO] 2024-05-07 10:46:54.045 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-1061][TI-3959] - [INFO] 2024-05-07 10:46:54.045 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-1061][TI-3959] - [INFO] 2024-05-07 10:46:54.045 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export PYSPARK_DRIVER_PYTHON=/bin/python3.11
export PYSPARK_PYTHON=/bin/python3.11
${SPARK_HOME}/bin/spark-submit --master local --driver-cores 1 --driver-memory 512M --num-executors 1 --executor-cores 1 --executor-memory 1G --conf spark.driver.extraJavaOptions="-Divy.cache.dir=/tmp -Divy.home=/tmp" \
--packages org.postgresql:postgresql:42.7.3 /opt/dolphinscheduler/conf/../libs/dolphinscheduler-data-quality-3.2.1.jar "{\"name\":\"$t(uniqueness_check)\",\"env\":{\"type\":\"batch\",\"config\":null},\"readers\":[{\"type\":\"JDBC\",\"config\":{\"database\":\"persistence\",\"password\":\"root\",\"driver\":\"org.postgresql.Driver\",\"user\":\"root\",\"output_table\":\"persistence_filtered_data_persistence\",\"table\":\"filtered_data_persistence\",\"url\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432/persistence?password=root\"} }],\"transformers\":[{\"type\":\"sql\",\"config\":{\"index\":1,\"output_table\":\"duplicate_items\",\"sql\":\"SELECT content FROM persistence_filtered_data_persistence group by content having count(*) > 1\"} },{\"type\":\"sql\",\"config\":{\"index\":2,\"output_table\":\"duplicate_count\",\"sql\":\"SELECT COUNT(*) AS duplicates FROM duplicate_items\"} }],\"writers\":[{\"type\":\"JDBC\",\"config\":{\"database\":\"dolphinscheduler\",\"password\":\"root\",\"driver\":\"org.postgresql.Driver\",\"user\":\"root\",\"table\":\"t_ds_dq_execute_result\",\"url\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432/dolphinscheduler\",\"sql\":\"select 0 as rule_type,'$t(uniqueness_check)' as rule_name,0 as process_definition_id,1061 as process_instance_id,3959 as task_instance_id,duplicate_count.duplicates AS statistics_value,0 AS comparison_value,1 AS comparison_type,0 as check_type,0 as threshold,0 as operator,0 as failure_strategy,'hdfs://mycluster:8020/user/default/data_quality_error_data/0_1061_[null check] filtered data persistence' as error_output_path,'2024-05-07 10:46:54' as create_time,'2024-05-07 10:46:54' as update_time from duplicate_count \"} },{\"type\":\"JDBC\",\"config\":{\"database\":\"dolphinscheduler\",\"password\":\"root\",\"driver\":\"org.postgresql.Driver\",\"user\":\"root\",\"table\":\"t_ds_dq_task_statistics_value\",\"url\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432/dolphinscheduler\",\"sql\":\"select 0 as process_definition_id,3959 as task_instance_id,6 as rule_id,'KA0AXXWVHWW+GZX4BPZXFGFZ0F0OYMUQ+BVYG4+ZIKG=' as unique_code,'duplicate_count.duplicates'AS statistics_name,duplicate_count.duplicates AS statistics_value,'2024-05-07 10:46:54' as data_time,'2024-05-07 10:46:54' as create_time,'2024-05-07 10:46:54' as update_time from duplicate_count\"} },{\"type\":\"hdfs_file\",\"config\":{\"path\":\"hdfs://mycluster:8020/user/default/data_quality_error_data/0_1061_[null check] filtered data persistence\",\"input_table\":\"duplicate_items\"} }]}"
[WI-1061][TI-3959] - [INFO] 2024-05-07 10:46:54.045 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-1061][TI-3959] - [INFO] 2024-05-07 10:46:54.045 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13001194483488/13505298546272_21/1061/3959/1061_3959.sh
[WI-1061][TI-3959] - [INFO] 2024-05-07 10:46:54.057 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 244
[WI-0][TI-3959] - [INFO] 2024-05-07 10:46:54.401 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=3959, success=true)
[WI-0][TI-3959] - [INFO] 2024-05-07 10:46:54.436 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=3959)
[WI-0][TI-0] - [INFO] 2024-05-07 10:46:54.798 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8425655976676384 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:46:55.059 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
[WI-0][TI-0] - [INFO] 2024-05-07 10:46:55.881 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8675496688741722 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:46:56.885 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8080495356037152 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:46:57.893 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8204419889502763 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:46:58.379 +0800 o.a.d.s.w.r.o.TaskInstanceKillOperationFunction:[55] - Receive TaskInstanceKillRequest: TaskInstanceKillRequest(taskInstanceId=3958)
[WI-0][TI-3958] - [ERROR] 2024-05-07 10:46:58.381 +0800 o.a.d.s.w.r.o.TaskInstanceKillOperationFunction:[62] - Cannot find WorkerTaskExecutor for taskInstance: 3958
[WI-0][TI-0] - [INFO] 2024-05-07 10:46:58.910 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8999540863177227 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:46:59.062 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	:: loading settings :: url = jar:file:/opt/spark-3.5.1-bin-hadoop3/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml
	Ivy Default Cache set to: /tmp
	The jars for the packages stored in: /tmp/jars
	org.postgresql#postgresql added as a dependency
	:: resolving dependencies :: org.apache.spark#spark-submit-parent-cc35e82b-9488-4fbc-9830-b301167c541b;1.0
		confs: [default]
		found org.postgresql#postgresql;42.7.3 in central
		found org.checkerframework#checker-qual;3.42.0 in central
	:: resolution report :: resolve 355ms :: artifacts dl 5ms
		:: modules in use:
		org.checkerframework#checker-qual;3.42.0 from central in [default]
		org.postgresql#postgresql;42.7.3 from central in [default]
		---------------------------------------------------------------------
		|                  |            modules            ||   artifacts   |
		|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
		---------------------------------------------------------------------
		|      default     |   2   |   0   |   0   |   0   ||   2   |   0   |
		---------------------------------------------------------------------
	:: retrieving :: org.apache.spark#spark-submit-parent-cc35e82b-9488-4fbc-9830-b301167c541b
		confs: [default]
		0 artifacts copied, 2 already retrieved (0kB/25ms)
[WI-0][TI-0] - [INFO] 2024-05-07 10:46:59.960 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8969045741324921 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:47:00.074 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:46:59 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[WI-0][TI-0] - [INFO] 2024-05-07 10:47:00.965 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.951219512195122 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:47:01.078 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:47:00 INFO SparkContext: Running Spark version 3.5.1
	24/05/07 10:47:00 INFO SparkContext: OS info Linux, 6.5.0-28-generic, amd64
	24/05/07 10:47:00 INFO SparkContext: Java version 1.8.0_402
	24/05/07 10:47:00 INFO ResourceUtils: ==============================================================
	24/05/07 10:47:00 INFO ResourceUtils: No custom resources configured for spark.driver.
	24/05/07 10:47:00 INFO ResourceUtils: ==============================================================
	24/05/07 10:47:00 INFO SparkContext: Submitted application: (uniqueness_check)
	24/05/07 10:47:00 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
	24/05/07 10:47:00 INFO ResourceProfile: Limiting resource is cpu
	24/05/07 10:47:00 INFO ResourceProfileManager: Added ResourceProfile id: 0
	24/05/07 10:47:01 INFO SecurityManager: Changing view acls to: default
	24/05/07 10:47:01 INFO SecurityManager: Changing modify acls to: default
	24/05/07 10:47:01 INFO SecurityManager: Changing view acls groups to: 
	24/05/07 10:47:01 INFO SecurityManager: Changing modify acls groups to: 
	24/05/07 10:47:01 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: default; groups with view permissions: EMPTY; users with modify permissions: default; groups with modify permissions: EMPTY
[WI-0][TI-0] - [INFO] 2024-05-07 10:47:01.967 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9050445103857566 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:47:02.088 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:47:01 INFO Utils: Successfully started service 'sparkDriver' on port 39263.
	24/05/07 10:47:01 INFO SparkEnv: Registering MapOutputTracker
	24/05/07 10:47:01 INFO SparkEnv: Registering BlockManagerMaster
	24/05/07 10:47:01 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
	24/05/07 10:47:01 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
	24/05/07 10:47:01 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
	24/05/07 10:47:01 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-7e34501a-c4fc-4633-a2a0-3822f2747810
	24/05/07 10:47:02 INFO MemoryStore: MemoryStore started with capacity 93.3 MiB
[WI-0][TI-0] - [INFO] 2024-05-07 10:47:02.972 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.891025641025641 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:47:03.097 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:47:02 INFO SparkEnv: Registering OutputCommitCoordinator
	24/05/07 10:47:02 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
	24/05/07 10:47:02 INFO Utils: Successfully started service 'SparkUI' on port 4040.
	24/05/07 10:47:02 INFO SparkContext: Added JAR file:///tmp/jars/org.postgresql_postgresql-42.7.3.jar at spark://d8bddb7812a3:39263/jars/org.postgresql_postgresql-42.7.3.jar with timestamp 1715050020566
	24/05/07 10:47:02 INFO SparkContext: Added JAR file:///tmp/jars/org.checkerframework_checker-qual-3.42.0.jar at spark://d8bddb7812a3:39263/jars/org.checkerframework_checker-qual-3.42.0.jar with timestamp 1715050020566
	24/05/07 10:47:02 INFO SparkContext: Added JAR file:/opt/dolphinscheduler/libs/dolphinscheduler-data-quality-3.2.1.jar at spark://d8bddb7812a3:39263/jars/dolphinscheduler-data-quality-3.2.1.jar with timestamp 1715050020566
	24/05/07 10:47:03 INFO Executor: Starting executor ID driver on host d8bddb7812a3
	24/05/07 10:47:03 INFO Executor: OS info Linux, 6.5.0-28-generic, amd64
	24/05/07 10:47:03 INFO Executor: Java version 1.8.0_402
[WI-0][TI-0] - [INFO] 2024-05-07 10:47:03.977 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8579881656804734 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:47:04.100 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:47:03 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
	24/05/07 10:47:03 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@73844119 for default.
	24/05/07 10:47:03 INFO Executor: Fetching spark://d8bddb7812a3:39263/jars/org.checkerframework_checker-qual-3.42.0.jar with timestamp 1715050020566
	24/05/07 10:47:03 INFO TransportClientFactory: Successfully created connection to d8bddb7812a3/172.18.1.1:39263 after 88 ms (0 ms spent in bootstraps)
	24/05/07 10:47:03 INFO Utils: Fetching spark://d8bddb7812a3:39263/jars/org.checkerframework_checker-qual-3.42.0.jar to /tmp/spark-fb9401cd-c2d4-4db5-a667-ed1c4fa02eef/userFiles-974217be-e7e2-4ec5-a3c0-f8cac717b89c/fetchFileTemp281398111584704451.tmp
	24/05/07 10:47:03 INFO Executor: Adding file:/tmp/spark-fb9401cd-c2d4-4db5-a667-ed1c4fa02eef/userFiles-974217be-e7e2-4ec5-a3c0-f8cac717b89c/org.checkerframework_checker-qual-3.42.0.jar to class loader default
	24/05/07 10:47:03 INFO Executor: Fetching spark://d8bddb7812a3:39263/jars/org.postgresql_postgresql-42.7.3.jar with timestamp 1715050020566
	24/05/07 10:47:03 INFO Utils: Fetching spark://d8bddb7812a3:39263/jars/org.postgresql_postgresql-42.7.3.jar to /tmp/spark-fb9401cd-c2d4-4db5-a667-ed1c4fa02eef/userFiles-974217be-e7e2-4ec5-a3c0-f8cac717b89c/fetchFileTemp8575824696609552106.tmp
	24/05/07 10:47:03 INFO Executor: Adding file:/tmp/spark-fb9401cd-c2d4-4db5-a667-ed1c4fa02eef/userFiles-974217be-e7e2-4ec5-a3c0-f8cac717b89c/org.postgresql_postgresql-42.7.3.jar to class loader default
	24/05/07 10:47:03 INFO Executor: Fetching spark://d8bddb7812a3:39263/jars/dolphinscheduler-data-quality-3.2.1.jar with timestamp 1715050020566
	24/05/07 10:47:03 INFO Utils: Fetching spark://d8bddb7812a3:39263/jars/dolphinscheduler-data-quality-3.2.1.jar to /tmp/spark-fb9401cd-c2d4-4db5-a667-ed1c4fa02eef/userFiles-974217be-e7e2-4ec5-a3c0-f8cac717b89c/fetchFileTemp5259642791284430822.tmp
	24/05/07 10:47:03 INFO Executor: Adding file:/tmp/spark-fb9401cd-c2d4-4db5-a667-ed1c4fa02eef/userFiles-974217be-e7e2-4ec5-a3c0-f8cac717b89c/dolphinscheduler-data-quality-3.2.1.jar to class loader default
	24/05/07 10:47:03 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33419.
	24/05/07 10:47:03 INFO NettyBlockTransferService: Server created on d8bddb7812a3:33419
	24/05/07 10:47:03 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
	24/05/07 10:47:03 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, d8bddb7812a3, 33419, None)
	24/05/07 10:47:03 INFO BlockManagerMasterEndpoint: Registering block manager d8bddb7812a3:33419 with 93.3 MiB RAM, BlockManagerId(driver, d8bddb7812a3, 33419, None)
	24/05/07 10:47:03 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, d8bddb7812a3, 33419, None)
	24/05/07 10:47:03 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, d8bddb7812a3, 33419, None)
[WI-0][TI-0] - [INFO] 2024-05-07 10:47:04.982 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9002849002849002 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:47:05.101 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:47:04 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
	24/05/07 10:47:04 INFO SharedState: Warehouse path is 'file:/tmp/dolphinscheduler/exec/process/default/13001194483488/13505298546272_21/1061/3959/spark-warehouse'.
[WI-0][TI-0] - [INFO] 2024-05-07 10:47:06.023 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8648648648648648 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:47:07.037 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8956521739130433 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:47:08.050 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8876080691642652 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:47:09.057 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8362068965517242 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:47:10.062 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9388888888888889 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:47:11.088 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8088235294117647 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:47:12.095 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7672131147540984 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:47:13.097 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8163934426229509 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:47:13.131 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:47:12 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
[WI-0][TI-0] - [INFO] 2024-05-07 10:47:14.099 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7768240343347639 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:47:14.137 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:47:13 INFO CodeGenerator: Code generated in 553.953432 ms
	24/05/07 10:47:13 INFO DAGScheduler: Registering RDD 2 (save at JdbcWriter.java:87) as input to shuffle 0
	24/05/07 10:47:13 INFO DAGScheduler: Got map stage job 0 (save at JdbcWriter.java:87) with 1 output partitions
	24/05/07 10:47:13 INFO DAGScheduler: Final stage: ShuffleMapStage 0 (save at JdbcWriter.java:87)
	24/05/07 10:47:13 INFO DAGScheduler: Parents of final stage: List()
	24/05/07 10:47:13 INFO DAGScheduler: Missing parents: List()
	24/05/07 10:47:13 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[2] at save at JdbcWriter.java:87), which has no missing parents
	24/05/07 10:47:14 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 34.8 KiB, free 93.3 MiB)
[WI-0][TI-0] - [INFO] 2024-05-07 10:47:15.156 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:47:14 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 16.4 KiB, free 93.3 MiB)
	24/05/07 10:47:14 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on d8bddb7812a3:33419 (size: 16.4 KiB, free: 93.3 MiB)
	24/05/07 10:47:14 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1585
	24/05/07 10:47:14 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[2] at save at JdbcWriter.java:87) (first 15 tasks are for partitions Vector(0))
	24/05/07 10:47:14 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
	24/05/07 10:47:14 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (d8bddb7812a3, executor driver, partition 0, PROCESS_LOCAL, 7878 bytes) 
	24/05/07 10:47:14 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
[WI-0][TI-0] - [INFO] 2024-05-07 10:47:16.121 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8138801261829652 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:47:16.159 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:47:15 INFO CodeGenerator: Code generated in 89.744475 ms
	24/05/07 10:47:15 INFO CodeGenerator: Code generated in 31.58592 ms
	24/05/07 10:47:15 INFO CodeGenerator: Code generated in 11.784004 ms
	24/05/07 10:47:15 INFO CodeGenerator: Code generated in 9.019916 ms
	24/05/07 10:47:15 INFO CodeGenerator: Code generated in 11.203452 ms
	24/05/07 10:47:15 INFO JDBCRDD: closed connection
	24/05/07 10:47:15 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 2534 bytes result sent to driver
	24/05/07 10:47:15 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1334 ms on d8bddb7812a3 (executor driver) (1/1)
	24/05/07 10:47:15 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
	24/05/07 10:47:15 INFO DAGScheduler: ShuffleMapStage 0 (save at JdbcWriter.java:87) finished in 1.601 s
	24/05/07 10:47:15 INFO DAGScheduler: looking for newly runnable stages
	24/05/07 10:47:15 INFO DAGScheduler: running: Set()
	24/05/07 10:47:15 INFO DAGScheduler: waiting: Set()
	24/05/07 10:47:15 INFO DAGScheduler: failed: Set()
	24/05/07 10:47:15 INFO ShufflePartitionsUtil: For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
	24/05/07 10:47:15 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
	24/05/07 10:47:15 INFO CodeGenerator: Code generated in 48.76683 ms
	24/05/07 10:47:16 INFO DAGScheduler: Registering RDD 5 (save at JdbcWriter.java:87) as input to shuffle 1
	24/05/07 10:47:16 INFO DAGScheduler: Got map stage job 1 (save at JdbcWriter.java:87) with 1 output partitions
	24/05/07 10:47:16 INFO DAGScheduler: Final stage: ShuffleMapStage 2 (save at JdbcWriter.java:87)
	24/05/07 10:47:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
	24/05/07 10:47:16 INFO DAGScheduler: Missing parents: List()
	24/05/07 10:47:16 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[5] at save at JdbcWriter.java:87), which has no missing parents
	24/05/07 10:47:16 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 40.5 KiB, free 93.2 MiB)
	24/05/07 10:47:16 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 19.1 KiB, free 93.2 MiB)
	24/05/07 10:47:16 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on d8bddb7812a3:33419 (size: 19.1 KiB, free: 93.3 MiB)
	24/05/07 10:47:16 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1585
	24/05/07 10:47:16 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[5] at save at JdbcWriter.java:87) (first 15 tasks are for partitions Vector(0))
	24/05/07 10:47:16 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
	24/05/07 10:47:16 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 1) (d8bddb7812a3, executor driver, partition 0, NODE_LOCAL, 8032 bytes) 
	24/05/07 10:47:16 INFO Executor: Running task 0.0 in stage 2.0 (TID 1)
[WI-0][TI-0] - [INFO] 2024-05-07 10:47:17.148 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.838006230529595 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:47:17.165 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:47:16 INFO ShuffleBlockFetcherIterator: Getting 1 (2.9 KiB) non-empty blocks including 1 (2.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
	24/05/07 10:47:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 22 ms
	24/05/07 10:47:16 INFO CodeGenerator: Code generated in 21.857185 ms
	24/05/07 10:47:16 INFO Executor: Finished task 0.0 in stage 2.0 (TID 1). 5420 bytes result sent to driver
	24/05/07 10:47:16 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 1) in 160 ms on d8bddb7812a3 (executor driver) (1/1)
	24/05/07 10:47:16 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
	24/05/07 10:47:16 INFO DAGScheduler: ShuffleMapStage 2 (save at JdbcWriter.java:87) finished in 0.205 s
	24/05/07 10:47:16 INFO DAGScheduler: looking for newly runnable stages
	24/05/07 10:47:16 INFO DAGScheduler: running: Set()
	24/05/07 10:47:16 INFO DAGScheduler: waiting: Set()
	24/05/07 10:47:16 INFO DAGScheduler: failed: Set()
	24/05/07 10:47:16 INFO CodeGenerator: Code generated in 22.706007 ms
	24/05/07 10:47:16 INFO SparkContext: Starting job: save at JdbcWriter.java:87
	24/05/07 10:47:16 INFO DAGScheduler: Got job 2 (save at JdbcWriter.java:87) with 1 output partitions
	24/05/07 10:47:16 INFO DAGScheduler: Final stage: ResultStage 5 (save at JdbcWriter.java:87)
	24/05/07 10:47:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
	24/05/07 10:47:16 INFO DAGScheduler: Missing parents: List()
	24/05/07 10:47:16 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[10] at save at JdbcWriter.java:87), which has no missing parents
	24/05/07 10:47:16 INFO BlockManagerInfo: Removed broadcast_1_piece0 on d8bddb7812a3:33419 in memory (size: 19.1 KiB, free: 93.3 MiB)
	24/05/07 10:47:17 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 51.4 KiB, free 93.2 MiB)
	24/05/07 10:47:17 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 23.1 KiB, free 93.2 MiB)
	24/05/07 10:47:17 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on d8bddb7812a3:33419 (size: 23.1 KiB, free: 93.3 MiB)
	24/05/07 10:47:17 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1585
	24/05/07 10:47:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[10] at save at JdbcWriter.java:87) (first 15 tasks are for partitions Vector(0))
	24/05/07 10:47:17 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
	24/05/07 10:47:17 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 2) (d8bddb7812a3, executor driver, partition 0, NODE_LOCAL, 8043 bytes) 
	24/05/07 10:47:17 INFO Executor: Running task 0.0 in stage 5.0 (TID 2)
[WI-0][TI-0] - [INFO] 2024-05-07 10:47:18.157 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7532051282051283 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:47:18.169 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:47:17 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
	24/05/07 10:47:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
	24/05/07 10:47:17 INFO CodeGenerator: Code generated in 16.492976 ms
[WI-0][TI-0] - [INFO] 2024-05-07 10:47:19.162 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8200692041522492 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:47:20.164 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8158730158730159 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:47:20.177 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:47:19 INFO CodeGenerator: Code generated in 126.375769 ms
	24/05/07 10:47:19 INFO Executor: Finished task 0.0 in stage 5.0 (TID 2). 6711 bytes result sent to driver
	24/05/07 10:47:19 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 2) in 2654 ms on d8bddb7812a3 (executor driver) (1/1)
	24/05/07 10:47:19 INFO DAGScheduler: ResultStage 5 (save at JdbcWriter.java:87) finished in 2.985 s
	24/05/07 10:47:19 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
	24/05/07 10:47:19 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
	24/05/07 10:47:19 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
	24/05/07 10:47:19 INFO DAGScheduler: Job 2 finished: save at JdbcWriter.java:87, took 3.212287 s
	24/05/07 10:47:20 INFO DAGScheduler: Registering RDD 13 (save at JdbcWriter.java:87) as input to shuffle 2
	24/05/07 10:47:20 INFO DAGScheduler: Got map stage job 3 (save at JdbcWriter.java:87) with 1 output partitions
	24/05/07 10:47:20 INFO DAGScheduler: Final stage: ShuffleMapStage 6 (save at JdbcWriter.java:87)
	24/05/07 10:47:20 INFO DAGScheduler: Parents of final stage: List()
	24/05/07 10:47:20 INFO DAGScheduler: Missing parents: List()
	24/05/07 10:47:20 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[13] at save at JdbcWriter.java:87), which has no missing parents
[WI-0][TI-0] - [INFO] 2024-05-07 10:47:21.166 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7961783439490446 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:47:21.179 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:47:20 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 34.8 KiB, free 93.1 MiB)
	24/05/07 10:47:20 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 16.5 KiB, free 93.1 MiB)
	24/05/07 10:47:20 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on d8bddb7812a3:33419 (size: 16.5 KiB, free: 93.2 MiB)
	24/05/07 10:47:20 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1585
	24/05/07 10:47:20 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[13] at save at JdbcWriter.java:87) (first 15 tasks are for partitions Vector(0))
	24/05/07 10:47:20 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0
	24/05/07 10:47:20 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 3) (d8bddb7812a3, executor driver, partition 0, PROCESS_LOCAL, 7878 bytes) 
	24/05/07 10:47:20 INFO Executor: Running task 0.0 in stage 6.0 (TID 3)
	24/05/07 10:47:20 INFO JDBCRDD: closed connection
	24/05/07 10:47:20 INFO Executor: Finished task 0.0 in stage 6.0 (TID 3). 2448 bytes result sent to driver
	24/05/07 10:47:20 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 3) in 66 ms on d8bddb7812a3 (executor driver) (1/1)
	24/05/07 10:47:20 INFO DAGScheduler: ShuffleMapStage 6 (save at JdbcWriter.java:87) finished in 0.081 s
	24/05/07 10:47:20 INFO DAGScheduler: looking for newly runnable stages
	24/05/07 10:47:20 INFO DAGScheduler: running: Set()
	24/05/07 10:47:20 INFO DAGScheduler: waiting: Set()
	24/05/07 10:47:20 INFO DAGScheduler: failed: Set()
	24/05/07 10:47:20 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
	24/05/07 10:47:20 INFO ShufflePartitionsUtil: For shuffle(2), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
	24/05/07 10:47:20 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
	24/05/07 10:47:20 INFO DAGScheduler: Registering RDD 16 (save at JdbcWriter.java:87) as input to shuffle 3
	24/05/07 10:47:20 INFO DAGScheduler: Got map stage job 4 (save at JdbcWriter.java:87) with 1 output partitions
	24/05/07 10:47:20 INFO DAGScheduler: Final stage: ShuffleMapStage 8 (save at JdbcWriter.java:87)
	24/05/07 10:47:20 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
	24/05/07 10:47:20 INFO DAGScheduler: Missing parents: List()
	24/05/07 10:47:20 INFO DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[16] at save at JdbcWriter.java:87), which has no missing parents
	24/05/07 10:47:20 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 40.6 KiB, free 93.1 MiB)
	24/05/07 10:47:20 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 19.1 KiB, free 93.1 MiB)
	24/05/07 10:47:20 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on d8bddb7812a3:33419 (size: 19.1 KiB, free: 93.2 MiB)
	24/05/07 10:47:20 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1585
	24/05/07 10:47:20 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[16] at save at JdbcWriter.java:87) (first 15 tasks are for partitions Vector(0))
	24/05/07 10:47:20 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0
	24/05/07 10:47:20 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 4) (d8bddb7812a3, executor driver, partition 0, NODE_LOCAL, 8032 bytes) 
	24/05/07 10:47:20 INFO Executor: Running task 0.0 in stage 8.0 (TID 4)
	24/05/07 10:47:20 INFO ShuffleBlockFetcherIterator: Getting 1 (2.9 KiB) non-empty blocks including 1 (2.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
	24/05/07 10:47:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
	24/05/07 10:47:20 INFO Executor: Finished task 0.0 in stage 8.0 (TID 4). 5420 bytes result sent to driver
	24/05/07 10:47:20 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 4) in 28 ms on d8bddb7812a3 (executor driver) (1/1)
	24/05/07 10:47:20 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
	24/05/07 10:47:20 INFO DAGScheduler: ShuffleMapStage 8 (save at JdbcWriter.java:87) finished in 0.051 s
	24/05/07 10:47:20 INFO DAGScheduler: looking for newly runnable stages
	24/05/07 10:47:20 INFO DAGScheduler: running: Set()
	24/05/07 10:47:20 INFO DAGScheduler: waiting: Set()
	24/05/07 10:47:20 INFO DAGScheduler: failed: Set()
	24/05/07 10:47:20 INFO CodeGenerator: Code generated in 9.095679 ms
	24/05/07 10:47:20 INFO SparkContext: Starting job: save at JdbcWriter.java:87
	24/05/07 10:47:20 INFO DAGScheduler: Got job 5 (save at JdbcWriter.java:87) with 1 output partitions
	24/05/07 10:47:20 INFO DAGScheduler: Final stage: ResultStage 11 (save at JdbcWriter.java:87)
	24/05/07 10:47:20 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)
	24/05/07 10:47:20 INFO DAGScheduler: Missing parents: List()
	24/05/07 10:47:20 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[21] at save at JdbcWriter.java:87), which has no missing parents
	24/05/07 10:47:20 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 49.2 KiB, free 93.0 MiB)
	24/05/07 10:47:20 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 22.7 KiB, free 93.0 MiB)
	24/05/07 10:47:20 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on d8bddb7812a3:33419 (size: 22.7 KiB, free: 93.2 MiB)
	24/05/07 10:47:20 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1585
	24/05/07 10:47:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[21] at save at JdbcWriter.java:87) (first 15 tasks are for partitions Vector(0))
	24/05/07 10:47:20 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks resource profile 0
	24/05/07 10:47:20 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 5) (d8bddb7812a3, executor driver, partition 0, NODE_LOCAL, 8043 bytes) 
	24/05/07 10:47:20 INFO Executor: Running task 0.0 in stage 11.0 (TID 5)
	24/05/07 10:47:20 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
	24/05/07 10:47:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 34 ms
	24/05/07 10:47:20 INFO CodeGenerator: Code generated in 39.42395 ms
	24/05/07 10:47:20 INFO CodeGenerator: Code generated in 36.720394 ms
	24/05/07 10:47:20 INFO Executor: Finished task 0.0 in stage 11.0 (TID 5). 6625 bytes result sent to driver
	24/05/07 10:47:20 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 5) in 239 ms on d8bddb7812a3 (executor driver) (1/1)
	24/05/07 10:47:20 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
	24/05/07 10:47:20 INFO DAGScheduler: ResultStage 11 (save at JdbcWriter.java:87) finished in 0.396 s
	24/05/07 10:47:20 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
	24/05/07 10:47:20 INFO TaskSchedulerImpl: Killing all running tasks in stage 11: Stage finished
	24/05/07 10:47:20 INFO DAGScheduler: Job 5 finished: save at JdbcWriter.java:87, took 0.424285 s
	24/05/07 10:47:21 WARN FileSystem: Failed to initialize fileystem hdfs://mycluster:8020/user/default/data_quality_error_data/0_1061_%5Bnull%20check%5D%20filtered%20data%20persistence: java.lang.IllegalArgumentException: java.net.UnknownHostException: mycluster
	Exception in thread "main" java.lang.IllegalArgumentException: java.net.UnknownHostException: mycluster
		at org.apache.hadoop.security.SecurityUtil.buildTokenService(SecurityUtil.java:466)
		at org.apache.hadoop.hdfs.NameNodeProxiesClient.createProxyWithClientProtocol(NameNodeProxiesClient.java:134)
		at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:374)
		at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:308)
		at org.apache.hadoop.hdfs.DistributedFileSystem.initDFSClient(DistributedFileSystem.java:202)
		at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:187)
		at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469)
		at org.apache.hadoop.fs.FileSystem.access$300(FileSystem.java:174)
		at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3574)
		at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3521)
		at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540)
		at org.apache.hadoop.fs.Path.getFileSystem(Path.java:365)
		at org.apache.spark.sql.execution.datasources.DataSource.planForWritingFileFormat(DataSource.scala:454)
		at org.apache.spark.sql.execution.datasources.DataSource.planForWriting(DataSource.scala:530)
		at org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)
		at org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)
		at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:240)
		at org.apache.spark.sql.DataFrameWriter.csv(DataFrameWriter.scala:850)
		at org.apache.dolphinscheduler.data.quality.flow.batch.writer.file.BaseFileWriter.outputImpl(BaseFileWriter.java:114)
		at org.apache.dolphinscheduler.data.quality.flow.batch.writer.file.HdfsFileWriter.write(HdfsFileWriter.java:40)
		at org.apache.dolphinscheduler.data.quality.execution.SparkBatchExecution.executeWriter(SparkBatchExecution.java:132)
		at org.apache.dolphinscheduler.data.quality.execution.SparkBatchExecution.execute(SparkBatchExecution.java:58)
		at org.apache.dolphinscheduler.data.quality.context.DataQualityContext.execute(DataQualityContext.java:62)
		at org.apache.dolphinscheduler.data.quality.DataQualityApplication.main(DataQualityApplication.java:78)
		at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
		at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
		at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
		at java.lang.reflect.Method.invoke(Method.java:498)
		at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
		at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:1029)
		at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:194)
		at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:217)
		at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:91)
		at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1120)
		at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1129)
		at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
	Caused by: java.net.UnknownHostException: mycluster
		... 36 more
	24/05/07 10:47:21 INFO SparkContext: Invoking stop() from shutdown hook
	24/05/07 10:47:21 INFO SparkContext: SparkContext is stopping with exitCode 0.
	24/05/07 10:47:21 INFO SparkUI: Stopped Spark web UI at http://d8bddb7812a3:4040
[WI-0][TI-0] - [INFO] 2024-05-07 10:47:22.186 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:47:21 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
	24/05/07 10:47:21 INFO MemoryStore: MemoryStore cleared
	24/05/07 10:47:21 INFO BlockManager: BlockManager stopped
	24/05/07 10:47:21 INFO BlockManagerMaster: BlockManagerMaster stopped
	24/05/07 10:47:21 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
	24/05/07 10:47:21 INFO SparkContext: Successfully stopped SparkContext
	24/05/07 10:47:21 INFO ShutdownHookManager: Shutdown hook called
	24/05/07 10:47:21 INFO ShutdownHookManager: Deleting directory /tmp/spark-fb9401cd-c2d4-4db5-a667-ed1c4fa02eef
	24/05/07 10:47:21 INFO ShutdownHookManager: Deleting directory /tmp/spark-ecd43559-e245-4bd2-829c-19fe0088f4d6
[WI-1061][TI-3959] - [INFO] 2024-05-07 10:47:22.187 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13001194483488/13505298546272_21/1061/3959, processId:244 ,exitStatusCode:1 ,processWaitForStatus:true ,processExitValue:1
[WI-1061][TI-3959] - [INFO] 2024-05-07 10:47:22.187 +0800 o.a.d.p.t.a.u.LogUtils:[79] - Start finding appId in /opt/dolphinscheduler/logs/20240507/13505298546272/21/1061/3959.log, fetch way: log 
[WI-1061][TI-3959] - [INFO] 2024-05-07 10:47:22.189 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-1061][TI-3959] - [INFO] 2024-05-07 10:47:22.189 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-1061][TI-3959] - [INFO] 2024-05-07 10:47:22.189 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-1061][TI-3959] - [INFO] 2024-05-07 10:47:22.192 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-1061][TI-3959] - [INFO] 2024-05-07 10:47:22.206 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: FAILURE to master : 172.18.1.1:1234
[WI-1061][TI-3959] - [INFO] 2024-05-07 10:47:22.207 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-1061][TI-3959] - [INFO] 2024-05-07 10:47:22.210 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13001194483488/13505298546272_21/1061/3959
[WI-1061][TI-3959] - [INFO] 2024-05-07 10:47:22.211 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13001194483488/13505298546272_21/1061/3959
[WI-1061][TI-3959] - [INFO] 2024-05-07 10:47:22.213 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-0] - [WARN] 2024-05-07 10:47:27.278 +0800 o.a.d.e.b.s.JdkDynamicServerHandler:[147] - [id: 0xef6e8442, L:/172.18.1.1:1234 - R:/172.18.0.15:47910] is not writable, over high water level : 65536
[WI-0][TI-0] - [WARN] 2024-05-07 10:47:27.300 +0800 o.a.d.e.b.s.JdkDynamicServerHandler:[154] - [id: 0xef6e8442, L:/172.18.1.1:1234 - R:/172.18.0.15:47910] is writable, to low water : 32768
[WI-0][TI-0] - [INFO] 2024-05-07 10:47:28.234 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7565982404692082 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [WARN] 2024-05-07 10:50:13.696 +0800 o.s.c.k.c.p.AbstractKubernetesProfileEnvironmentPostProcessor:[258] - Not running inside kubernetes. Skipping 'kubernetes' profile activation.
[WI-0][TI-0] - [WARN] 2024-05-07 10:50:17.367 +0800 o.s.c.k.c.p.AbstractKubernetesProfileEnvironmentPostProcessor:[258] - Not running inside kubernetes. Skipping 'kubernetes' profile activation.
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:17.368 +0800 o.a.d.s.w.WorkerServer:[634] - No active profile set, falling back to 1 default profile: "default"
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:27.353 +0800 o.s.c.c.s.GenericScope:[283] - BeanFactory id=7e7bf7c6-2cb3-34d2-a0d5-a56161c67d0e
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:28.754 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'org.springframework.cloud.commons.config.CommonsConfigAutoConfiguration' of type [org.springframework.cloud.commons.config.CommonsConfigAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:28.759 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'org.springframework.cloud.client.loadbalancer.LoadBalancerDefaultMappingsProviderAutoConfiguration' of type [org.springframework.cloud.client.loadbalancer.LoadBalancerDefaultMappingsProviderAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:28.763 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'loadBalancerClientsDefaultsMappingsProvider' of type [org.springframework.cloud.client.loadbalancer.LoadBalancerDefaultMappingsProviderAutoConfiguration$$Lambda$392/302905744] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:28.775 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'defaultsBindHandlerAdvisor' of type [org.springframework.cloud.commons.config.DefaultsBindHandlerAdvisor] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:28.820 +0800 o.a.d.c.u.NetUtils:[312] - Get all NetworkInterfaces: [name:eth0 (eth0), name:lo (lo)]
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:28.950 +0800 o.a.d.s.w.c.WorkerConfig:[98] - 
****************************Worker Configuration**************************************
  listen-port -> 1234
  exec-threads -> 100
  max-heartbeat-interval -> PT10S
  host-weight -> 100
  tenantConfig -> TenantConfig(autoCreateTenantEnabled=true, distributedTenantEnabled=false, defaultTenantEnabled=false)
  server-load-protection -> WorkerServerLoadProtection(enabled=true, maxCpuUsagePercentageThresholds=0.7, maxJVMMemoryUsagePercentageThresholds=0.7, maxSystemMemoryUsagePercentageThresholds=0.7, maxDiskUsagePercentageThresholds=0.7)
  registry-disconnect-strategy -> ConnectStrategyProperties(strategy=WAITING, maxWaitingTime=PT1M40S)
  task-execute-threads-full-policy: REJECT
  address -> 172.18.1.1:1234
  registry-path: /nodes/worker/172.18.1.1:1234
****************************Worker Configuration**************************************
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:29.037 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'workerConfig' of type [org.apache.dolphinscheduler.server.worker.config.WorkerConfig$$EnhancerBySpringCGLIB$$da954724] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:30.008 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'io.kubernetes.client.spring.extended.manifests.config.KubernetesManifestsAutoConfiguration' of type [io.kubernetes.client.spring.extended.manifests.config.KubernetesManifestsAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:30.083 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'kubernetes.manifests-io.kubernetes.client.spring.extended.manifests.config.KubernetesManifestsProperties' of type [io.kubernetes.client.spring.extended.manifests.config.KubernetesManifestsProperties] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:30.119 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'io.kubernetes.client.spring.extended.controller.config.KubernetesInformerAutoConfiguration' of type [io.kubernetes.client.spring.extended.controller.config.KubernetesInformerAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:30.211 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'defaultApiClient' of type [io.kubernetes.client.openapi.ApiClient] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:30.915 +0800 o.e.j.u.log:[170] - Logging initialized @34045ms to org.eclipse.jetty.util.log.Slf4jLog
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:33.436 +0800 o.s.b.w.e.j.JettyServletWebServerFactory:[166] - Server initialized with port: 1235
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:33.449 +0800 o.e.j.s.Server:[375] - jetty-9.4.48.v20220622; built: 2022-06-21T20:42:25.880Z; git: 6b67c5719d1f4371b33655ff2d047d24e171e49a; jvm 1.8.0_402-b06
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:33.500 +0800 o.e.j.s.h.C.application:[2368] - Initializing Spring embedded WebApplicationContext
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:33.506 +0800 o.s.b.w.s.c.ServletWebServerApplicationContext:[292] - Root WebApplicationContext: initialization completed in 16090 ms
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:37.235 +0800 o.e.j.s.session:[334] - DefaultSessionIdManager workerName=node0
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:37.236 +0800 o.e.j.s.session:[339] - No SessionScavenger set, using defaults
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:37.242 +0800 o.e.j.s.session:[132] - node0 Scavenging every 660000ms
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:37.293 +0800 o.e.j.s.h.ContextHandler:[921] - Started o.s.b.w.e.j.JettyEmbeddedWebAppContext@52433946{application,/,[file:///tmp/jetty-docbase.1235.8667384526402754729/],AVAILABLE}
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:37.294 +0800 o.e.j.s.Server:[415] - Started @40424ms
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:37.618 +0800 o.a.c.f.i.CuratorFrameworkImpl:[338] - Starting
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:37.711 +0800 o.a.z.ZooKeeper:[98] - Client environment:zookeeper.version=3.8.0-5a02a05eddb59aee6ac762f7ea82e92a68eb9c0f, built on 2022-02-25 08:49 UTC
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:37.758 +0800 o.a.z.ZooKeeper:[98] - Client environment:host.name=56042a532902
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:37.776 +0800 o.a.z.ZooKeeper:[98] - Client environment:java.version=1.8.0_402
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:37.783 +0800 o.a.z.ZooKeeper:[98] - Client environment:java.vendor=Temurin
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:37.783 +0800 o.a.z.ZooKeeper:[98] - Client environment:java.home=/opt/java/openjdk
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:38.020 +0800 o.a.z.ZooKeeper:[98] - Client environment:java.class.path=/opt/dolphinscheduler/conf:/opt/dolphinscheduler/libs/kerb-client-1.0.1.jar:/opt/dolphinscheduler/libs/spring-cloud-starter-kubernetes-client-config-2.1.3.jar:/opt/dolphinscheduler/libs/oauth2-oidc-sdk-9.35.jar:/opt/dolphinscheduler/libs/jsqlparser-4.4.jar:/opt/dolphinscheduler/libs/reactive-streams-1.0.4.jar:/opt/dolphinscheduler/libs/kubernetes-model-extensions-5.10.2.jar:/opt/dolphinscheduler/libs/zookeeper-3.8.0.jar:/opt/dolphinscheduler/libs/kubernetes-model-apps-5.10.2.jar:/opt/dolphinscheduler/libs/grpc-api-1.41.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-pigeon-3.2.1.jar:/opt/dolphinscheduler/libs/client-java-api-13.0.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-obs-3.2.1.jar:/opt/dolphinscheduler/libs/spring-web-5.3.22.jar:/opt/dolphinscheduler/libs/aws-java-sdk-emr-1.12.300.jar:/opt/dolphinscheduler/libs/spring-context-5.3.22.jar:/opt/dolphinscheduler/libs/gapic-google-cloud-storage-v2-2.18.0-alpha.jar:/opt/dolphinscheduler/libs/spring-cloud-kubernetes-client-config-2.1.3.jar:/opt/dolphinscheduler/libs/jetty-io-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/annotations-13.0.jar:/opt/dolphinscheduler/libs/jpam-1.1.jar:/opt/dolphinscheduler/libs/joda-time-2.10.13.jar:/opt/dolphinscheduler/libs/spring-cloud-kubernetes-client-autoconfig-2.1.3.jar:/opt/dolphinscheduler/libs/kerb-identity-1.0.1.jar:/opt/dolphinscheduler/libs/vertica-jdbc-12.0.4-0.jar:/opt/dolphinscheduler/libs/grpc-googleapis-1.52.1.jar:/opt/dolphinscheduler/libs/aliyun-java-sdk-kms-2.11.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-dvc-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-hana-3.2.1.jar:/opt/dolphinscheduler/libs/kubernetes-httpclient-okhttp-6.0.0.jar:/opt/dolphinscheduler/libs/jline-2.12.jar:/opt/dolphinscheduler/libs/sshd-core-2.8.0.jar:/opt/dolphinscheduler/libs/jna-platform-5.10.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-sqlserver-3.2.1.jar:/opt/dolphinscheduler/libs/commons-beanutils-1.9.4.jar:/opt/dolphinscheduler/libs/grpc-services-1.41.0.jar:/opt/dolphinscheduler/libs/jmespath-java-1.12.300.jar:/opt/dolphinscheduler/libs/curator-client-5.3.0.jar:/opt/dolphinscheduler/libs/proto-google-common-protos-2.0.1.jar:/opt/dolphinscheduler/libs/mybatis-3.5.10.jar:/opt/dolphinscheduler/libs/jackson-annotations-2.13.4.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-all-3.2.1.jar:/opt/dolphinscheduler/libs/jakarta.xml.bind-api-2.3.3.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-jupyter-3.2.1.jar:/opt/dolphinscheduler/libs/mybatis-plus-extension-3.5.2.jar:/opt/dolphinscheduler/libs/j2objc-annotations-1.3.jar:/opt/dolphinscheduler/libs/Java-WebSocket-1.5.1.jar:/opt/dolphinscheduler/libs/azure-storage-common-12.20.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-sagemaker-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-databend-3.2.1.jar:/opt/dolphinscheduler/libs/google-auth-library-oauth2-http-1.15.0.jar:/opt/dolphinscheduler/libs/jetty-security-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-python-3.2.1.jar:/opt/dolphinscheduler/libs/snappy-java-1.1.10.1.jar:/opt/dolphinscheduler/libs/kubernetes-model-batch-5.10.2.jar:/opt/dolphinscheduler/libs/netty-transport-native-epoll-4.1.53.Final-linux-x86_64.jar:/opt/dolphinscheduler/libs/jackson-core-asl-1.9.13.jar:/opt/dolphinscheduler/libs/gson-fire-1.8.5.jar:/opt/dolphinscheduler/libs/clickhouse-jdbc-0.4.6.jar:/opt/dolphinscheduler/libs/grpc-netty-shaded-1.41.0.jar:/opt/dolphinscheduler/libs/caffeine-2.9.3.jar:/opt/dolphinscheduler/libs/aliyun-java-sdk-core-4.5.10.jar:/opt/dolphinscheduler/libs/jackson-module-jaxb-annotations-2.13.3.jar:/opt/dolphinscheduler/libs/jetty-http-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/jersey-servlet-1.19.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-dinky-3.2.1.jar:/opt/dolphinscheduler/libs/simpleclient_tracer_common-0.15.0.jar:/opt/dolphinscheduler/libs/netty-handler-4.1.53.Final.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-datafactory-3.2.1.jar:/opt/dolphinscheduler/libs/json-path-2.7.0.jar:/opt/dolphinscheduler/libs/mybatis-plus-annotation-3.5.2.jar:/opt/dolphinscheduler/libs/azure-resourcemanager-datafactory-1.0.0-beta.19.jar:/opt/dolphinscheduler/libs/commons-codec-1.11.jar:/opt/dolphinscheduler/libs/dolphinscheduler-extract-master-3.2.1.jar:/opt/dolphinscheduler/libs/spring-aop-5.3.22.jar:/opt/dolphinscheduler/libs/kubernetes-model-core-5.10.2.jar:/opt/dolphinscheduler/libs/kubernetes-model-networking-5.10.2.jar:/opt/dolphinscheduler/libs/kotlin-stdlib-jdk7-1.6.21.jar:/opt/dolphinscheduler/libs/kerby-xdr-1.0.1.jar:/opt/dolphinscheduler/libs/aliyun-java-sdk-ram-3.1.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-k8s-3.2.1.jar:/opt/dolphinscheduler/libs/guava-31.1-jre.jar:/opt/dolphinscheduler/libs/netty-codec-dns-4.1.53.Final.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-kubeflow-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-azure-sql-3.2.1.jar:/opt/dolphinscheduler/libs/HikariCP-4.0.3.jar:/opt/dolphinscheduler/libs/hive-metastore-2.3.9.jar:/opt/dolphinscheduler/libs/msal4j-1.13.3.jar:/opt/dolphinscheduler/libs/jackson-core-2.13.4.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-hive-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-mr-3.2.1.jar:/opt/dolphinscheduler/libs/kubernetes-model-node-5.10.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-common-3.2.1.jar:/opt/dolphinscheduler/libs/jose4j-0.7.8.jar:/opt/dolphinscheduler/libs/jul-to-slf4j-1.7.36.jar:/opt/dolphinscheduler/libs/azure-identity-1.7.1.jar:/opt/dolphinscheduler/libs/spring-boot-autoconfigure-2.7.3.jar:/opt/dolphinscheduler/libs/commons-math3-3.1.1.jar:/opt/dolphinscheduler/libs/jackson-jaxrs-json-provider-2.13.3.jar:/opt/dolphinscheduler/libs/perfmark-api-0.23.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-doris-3.2.1.jar:/opt/dolphinscheduler/libs/httpclient-4.5.13.jar:/opt/dolphinscheduler/libs/hive-service-2.3.9.jar:/opt/dolphinscheduler/libs/kerby-util-1.0.1.jar:/opt/dolphinscheduler/libs/commons-collections-3.2.2.jar:/opt/dolphinscheduler/libs/hadoop-yarn-client-3.2.4.jar:/opt/dolphinscheduler/libs/commons-text-1.8.jar:/opt/dolphinscheduler/libs/dolphinscheduler-worker-3.2.1.jar:/opt/dolphinscheduler/libs/hadoop-yarn-common-3.2.4.jar:/opt/dolphinscheduler/libs/zeppelin-client-0.10.1.jar:/opt/dolphinscheduler/libs/azure-core-management-1.10.1.jar:/opt/dolphinscheduler/libs/hadoop-mapreduce-client-jobclient-3.2.4.jar:/opt/dolphinscheduler/libs/jta-1.1.jar:/opt/dolphinscheduler/libs/annotations-4.1.1.4.jar:/opt/dolphinscheduler/libs/dolphinscheduler-extract-alert-3.2.1.jar:/opt/dolphinscheduler/libs/curator-framework-5.3.0.jar:/opt/dolphinscheduler/libs/hive-jdbc-2.3.9.jar:/opt/dolphinscheduler/libs/kyuubi-hive-jdbc-shaded-1.7.0.jar:/opt/dolphinscheduler/libs/client-java-proto-13.0.2.jar:/opt/dolphinscheduler/libs/checker-qual-3.19.0.jar:/opt/dolphinscheduler/libs/jetty-servlet-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/google-cloud-core-grpc-2.10.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-shell-3.2.1.jar:/opt/dolphinscheduler/libs/spring-security-rsa-1.0.10.RELEASE.jar:/opt/dolphinscheduler/libs/avro-1.7.7.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-postgresql-3.2.1.jar:/opt/dolphinscheduler/libs/netty-nio-client-2.17.282.jar:/opt/dolphinscheduler/libs/spring-webmvc-5.3.22.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-mysql-3.2.1.jar:/opt/dolphinscheduler/libs/opentracing-util-0.33.0.jar:/opt/dolphinscheduler/libs/auto-value-1.10.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-all-3.2.1.jar:/opt/dolphinscheduler/libs/jetcd-core-0.5.11.jar:/opt/dolphinscheduler/libs/grpc-context-1.41.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-datasync-3.2.1.jar:/opt/dolphinscheduler/libs/jackson-dataformat-cbor-2.13.3.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-gcs-3.2.1.jar:/opt/dolphinscheduler/libs/client-java-extended-13.0.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-redshift-3.2.1.jar:/opt/dolphinscheduler/libs/opencsv-2.3.jar:/opt/dolphinscheduler/libs/jcip-annotations-1.0-1.jar:/opt/dolphinscheduler/libs/accessors-smart-2.4.8.jar:/opt/dolphinscheduler/libs/hadoop-client-3.2.4.jar:/opt/dolphinscheduler/libs/commons-collections4-4.3.jar:/opt/dolphinscheduler/libs/metrics-core-4.2.11.jar:/opt/dolphinscheduler/libs/netty-resolver-4.1.53.Final.jar:/opt/dolphinscheduler/libs/parquet-hadoop-bundle-1.8.1.jar:/opt/dolphinscheduler/libs/bucket4j-core-6.2.0.jar:/opt/dolphinscheduler/libs/spring-cloud-starter-3.1.3.jar:/opt/dolphinscheduler/libs/mssql-jdbc-11.2.1.jre8.jar:/opt/dolphinscheduler/libs/netty-tcnative-boringssl-static-2.0.53.Final.jar:/opt/dolphinscheduler/libs/kubernetes-model-coordination-5.10.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-linkis-3.2.1.jar:/opt/dolphinscheduler/libs/commons-net-3.6.jar:/opt/dolphinscheduler/libs/netty-transport-native-kqueue-4.1.53.Final-osx-x86_64.jar:/opt/dolphinscheduler/libs/dolphinscheduler-meter-3.2.1.jar:/opt/dolphinscheduler/libs/kubernetes-client-api-6.0.0.jar:/opt/dolphinscheduler/libs/kubernetes-model-certificates-5.10.2.jar:/opt/dolphinscheduler/libs/opencensus-api-0.31.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-mlflow-3.2.1.jar:/opt/dolphinscheduler/libs/kotlin-stdlib-jdk8-1.6.21.jar:/opt/dolphinscheduler/libs/dolphinscheduler-registry-jdbc-3.2.1.jar:/opt/dolphinscheduler/libs/audience-annotations-0.12.0.jar:/opt/dolphinscheduler/libs/simpleclient_httpserver-0.15.0.jar:/opt/dolphinscheduler/libs/jetty-xml-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/kerby-asn1-1.0.1.jar:/opt/dolphinscheduler/libs/lang-tag-1.6.jar:/opt/dolphinscheduler/libs/api-common-2.6.0.jar:/opt/dolphinscheduler/libs/HdrHistogram-2.1.12.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-abs-3.2.1.jar:/opt/dolphinscheduler/libs/failsafe-2.4.4.jar:/opt/dolphinscheduler/libs/hbase-noop-htrace-4.1.1.jar:/opt/dolphinscheduler/libs/jamon-runtime-2.3.1.jar:/opt/dolphinscheduler/libs/jetty-util-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/threetenbp-1.6.5.jar:/opt/dolphinscheduler/libs/jakarta.activation-api-1.2.2.jar:/opt/dolphinscheduler/libs/kubernetes-model-common-5.10.2.jar:/opt/dolphinscheduler/libs/okhttp-4.9.3.jar:/opt/dolphinscheduler/libs/profiles-2.17.282.jar:/opt/dolphinscheduler/libs/hadoop-auth-3.2.4.jar:/opt/dolphinscheduler/libs/grpc-netty-1.41.0.jar:/opt/dolphinscheduler/libs/httpcore-nio-4.4.15.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-seatunnel-3.2.1.jar:/opt/dolphinscheduler/libs/aws-java-sdk-sagemaker-1.12.300.jar:/opt/dolphinscheduler/libs/oshi-core-6.1.1.jar:/opt/dolphinscheduler/libs/bonecp-0.8.0.RELEASE.jar:/opt/dolphinscheduler/libs/jackson-module-parameter-names-2.13.3.jar:/opt/dolphinscheduler/libs/bcutil-jdk15on-1.69.jar:/opt/dolphinscheduler/libs/aws-json-protocol-2.17.282.jar:/opt/dolphinscheduler/libs/dolphinscheduler-extract-base-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-all-3.2.1.jar:/opt/dolphinscheduler/libs/derby-10.14.2.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-snowflake-3.2.1.jar:/opt/dolphinscheduler/libs/netty-codec-http2-4.1.53.Final.jar:/opt/dolphinscheduler/libs/jetty-continuation-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/jackson-mapper-asl-1.9.13.jar:/opt/dolphinscheduler/libs/datanucleus-core-4.1.17.jar:/opt/dolphinscheduler/libs/netty-tcnative-boringssl-static-2.0.53.Final-osx-aarch_64.jar:/opt/dolphinscheduler/libs/failureaccess-1.0.1.jar:/opt/dolphinscheduler/libs/error_prone_annotations-2.5.1.jar:/opt/dolphinscheduler/libs/kerb-admin-1.0.1.jar:/opt/dolphinscheduler/libs/token-provider-1.0.1.jar:/opt/dolphinscheduler/libs/reactor-netty-core-1.0.22.jar:/opt/dolphinscheduler/libs/dolphinscheduler-registry-all-3.2.1.jar:/opt/dolphinscheduler/libs/jakarta.servlet-api-4.0.4.jar:/opt/dolphinscheduler/libs/http-client-spi-2.17.282.jar:/opt/dolphinscheduler/libs/regions-2.17.282.jar:/opt/dolphinscheduler/libs/logback-core-1.2.11.jar:/opt/dolphinscheduler/libs/json-1.8.jar:/opt/dolphinscheduler/libs/gax-grpc-2.23.0.jar:/opt/dolphinscheduler/libs/google-http-client-1.42.3.jar:/opt/dolphinscheduler/libs/hive-serde-2.3.9.jar:/opt/dolphinscheduler/libs/jettison-1.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-http-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-registry-zookeeper-3.2.1.jar:/opt/dolphinscheduler/libs/spring-security-crypto-5.7.3.jar:/opt/dolphinscheduler/libs/auth-2.17.282.jar:/opt/dolphinscheduler/libs/proto-google-cloud-storage-v2-2.18.0-alpha.jar:/opt/dolphinscheduler/libs/jetty-server-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/javax.annotation-api-1.3.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-starrocks-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-dataquality-3.2.1.jar:/opt/dolphinscheduler/libs/jcl-over-slf4j-1.7.36.jar:/opt/dolphinscheduler/libs/commons-lang3-3.12.0.jar:/opt/dolphinscheduler/libs/tomcat-embed-el-9.0.65.jar:/opt/dolphinscheduler/libs/opentracing-noop-0.33.0.jar:/opt/dolphinscheduler/libs/client-java-13.0.2.jar:/opt/dolphinscheduler/libs/spring-beans-5.3.22.jar:/opt/dolphinscheduler/libs/snakeyaml-1.33.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-ssh-3.2.1.jar:/opt/dolphinscheduler/libs/commons-pool-1.6.jar:/opt/dolphinscheduler/libs/javax.servlet-api-3.1.0.jar:/opt/dolphinscheduler/libs/hadoop-common-3.2.4.jar:/opt/dolphinscheduler/libs/kubernetes-model-apiextensions-5.10.2.jar:/opt/dolphinscheduler/libs/spring-boot-2.7.3.jar:/opt/dolphinscheduler/libs/bcprov-ext-jdk15on-1.69.jar:/opt/dolphinscheduler/libs/spring-boot-starter-2.7.3.jar:/opt/dolphinscheduler/libs/paranamer-2.3.jar:/opt/dolphinscheduler/libs/httpmime-4.5.13.jar:/opt/dolphinscheduler/libs/reactor-core-3.4.22.jar:/opt/dolphinscheduler/libs/azure-core-1.36.0.jar:/opt/dolphinscheduler/libs/bcpkix-jdk15on-1.69.jar:/opt/dolphinscheduler/libs/kubernetes-model-scheduling-5.10.2.jar:/opt/dolphinscheduler/libs/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/dolphinscheduler/libs/websocket-client-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/unirest-java-3.7.04-standalone.jar:/opt/dolphinscheduler/libs/hadoop-mapreduce-client-core-3.2.4.jar:/opt/dolphinscheduler/libs/google-auth-library-credentials-1.15.0.jar:/opt/dolphinscheduler/libs/azure-storage-internal-avro-12.6.0.jar:/opt/dolphinscheduler/libs/jackson-datatype-jdk8-2.13.3.jar:/opt/dolphinscheduler/libs/spring-expression-5.3.22.jar:/opt/dolphinscheduler/libs/aspectjweaver-1.9.7.jar:/opt/dolphinscheduler/libs/websocket-common-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/client-java-api-fluent-13.0.2.jar:/opt/dolphinscheduler/libs/mybatis-plus-3.5.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-athena-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-oss-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-openmldb-3.2.1.jar:/opt/dolphinscheduler/libs/curator-recipes-5.3.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-api-3.2.1.jar:/opt/dolphinscheduler/libs/netty-all-4.1.53.Final.jar:/opt/dolphinscheduler/libs/netty-resolver-dns-4.1.53.Final.jar:/opt/dolphinscheduler/libs/kubernetes-model-autoscaling-5.10.2.jar:/opt/dolphinscheduler/libs/kerb-util-1.0.1.jar:/opt/dolphinscheduler/libs/grpc-alts-1.41.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-presto-3.2.1.jar:/opt/dolphinscheduler/libs/kerb-simplekdc-1.0.1.jar:/opt/dolphinscheduler/libs/protobuf-java-util-3.17.2.jar:/opt/dolphinscheduler/libs/azure-core-http-netty-1.13.0.jar:/opt/dolphinscheduler/libs/transaction-api-1.1.jar:/opt/dolphinscheduler/libs/datanucleus-api-jdo-4.2.4.jar:/opt/dolphinscheduler/libs/zeppelin-common-0.10.1.jar:/opt/dolphinscheduler/libs/zt-zip-1.15.jar:/opt/dolphinscheduler/libs/animal-sniffer-annotations-1.19.jar:/opt/dolphinscheduler/libs/google-http-client-jackson2-1.42.3.jar:/opt/dolphinscheduler/libs/netty-buffer-4.1.53.Final.jar:/opt/dolphinscheduler/libs/jsr305-3.0.0.jar:/opt/dolphinscheduler/libs/netty-transport-classes-epoll-4.1.79.Final.jar:/opt/dolphinscheduler/libs/spring-boot-actuator-autoconfigure-2.7.3.jar:/opt/dolphinscheduler/libs/simpleclient-0.15.0.jar:/opt/dolphinscheduler/libs/aliyun-sdk-oss-3.15.1.jar:/opt/dolphinscheduler/libs/json-utils-2.17.282.jar:/opt/dolphinscheduler/libs/tephra-api-0.6.0.jar:/opt/dolphinscheduler/libs/spring-jdbc-5.3.22.jar:/opt/dolphinscheduler/libs/grpc-xds-1.41.0.jar:/opt/dolphinscheduler/libs/logback-classic-1.2.11.jar:/opt/dolphinscheduler/libs/google-cloud-storage-2.18.0.jar:/opt/dolphinscheduler/libs/micrometer-registry-prometheus-1.9.3.jar:/opt/dolphinscheduler/libs/grpc-core-1.41.0.jar:/opt/dolphinscheduler/libs/aws-java-sdk-kms-1.12.300.jar:/opt/dolphinscheduler/libs/kubernetes-model-rbac-5.10.2.jar:/opt/dolphinscheduler/libs/ini4j-0.5.4.jar:/opt/dolphinscheduler/libs/spring-boot-starter-web-2.7.3.jar:/opt/dolphinscheduler/libs/spring-cloud-commons-3.1.3.jar:/opt/dolphinscheduler/libs/netty-codec-http-4.1.53.Final.jar:/opt/dolphinscheduler/libs/jetty-client-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/jetcd-common-0.5.11.jar:/opt/dolphinscheduler/libs/metrics-spi-2.17.282.jar:/opt/dolphinscheduler/libs/utils-2.17.282.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-emr-3.2.1.jar:/opt/dolphinscheduler/libs/protocol-core-2.17.282.jar:/opt/dolphinscheduler/libs/micrometer-core-1.9.3.jar:/opt/dolphinscheduler/libs/netty-transport-native-unix-common-4.1.53.Final.jar:/opt/dolphinscheduler/libs/zjsonpatch-0.4.11.jar:/opt/dolphinscheduler/libs/annotations-2.17.282.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-sql-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-extract-common-3.2.1.jar:/opt/dolphinscheduler/libs/apache-client-2.17.282.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-oceanbase-3.2.1.jar:/opt/dolphinscheduler/libs/jdo-api-3.0.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-datax-3.2.1.jar:/opt/dolphinscheduler/libs/postgresql-42.4.1.jar:/opt/dolphinscheduler/libs/jetty-util-ajax-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/gax-2.23.0.jar:/opt/dolphinscheduler/libs/grpc-stub-1.41.0.jar:/opt/dolphinscheduler/libs/libfb303-0.9.3.jar:/opt/dolphinscheduler/libs/spring-core-5.3.22.jar:/opt/dolphinscheduler/libs/jaxb-api-2.3.1.jar:/opt/dolphinscheduler/libs/hive-service-rpc-2.3.9.jar:/opt/dolphinscheduler/libs/kubernetes-model-flowcontrol-5.10.2.jar:/opt/dolphinscheduler/libs/commons-logging-1.1.1.jar:/opt/dolphinscheduler/libs/mybatis-spring-2.0.7.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-oracle-3.2.1.jar:/opt/dolphinscheduler/libs/opencensus-proto-0.2.0.jar:/opt/dolphinscheduler/libs/grpc-protobuf-1.41.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-clickhouse-3.2.1.jar:/opt/dolphinscheduler/libs/spring-cloud-starter-bootstrap-3.1.3.jar:/opt/dolphinscheduler/libs/kubernetes-model-admissionregistration-5.10.2.jar:/opt/dolphinscheduler/libs/grpc-google-cloud-storage-v2-2.18.0-alpha.jar:/opt/dolphinscheduler/libs/esdk-obs-java-bundle-3.23.3.jar:/opt/dolphinscheduler/libs/dnsjava-2.1.7.jar:/opt/dolphinscheduler/libs/asm-9.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-spark-3.2.1.jar:/opt/dolphinscheduler/libs/netty-tcnative-boringssl-static-2.0.53.Final-linux-aarch_64.jar:/opt/dolphinscheduler/libs/re2j-1.6.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-vertica-3.2.1.jar:/opt/dolphinscheduler/libs/json-smart-2.4.8.jar:/opt/dolphinscheduler/libs/reactor-netty-http-1.0.22.jar:/opt/dolphinscheduler/libs/google-api-services-storage-v1-rev20220705-2.0.0.jar:/opt/dolphinscheduler/libs/kubernetes-client-6.0.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-kyuubi-3.2.1.jar:/opt/dolphinscheduler/libs/auto-value-annotations-1.10.1.jar:/opt/dolphinscheduler/libs/commons-cli-1.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-data-quality-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-chunjun-3.2.1.jar:/opt/dolphinscheduler/libs/kerb-server-1.0.1.jar:/opt/dolphinscheduler/libs/content-type-2.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-remoteshell-3.2.1.jar:/opt/dolphinscheduler/libs/opencensus-contrib-http-util-0.31.1.jar:/opt/dolphinscheduler/libs/druid-1.2.20.jar:/opt/dolphinscheduler/libs/javolution-5.5.1.jar:/opt/dolphinscheduler/libs/protobuf-java-3.17.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-db2-3.2.1.jar:/opt/dolphinscheduler/libs/aws-java-sdk-core-1.12.300.jar:/opt/dolphinscheduler/libs/spring-boot-starter-logging-2.7.3.jar:/opt/dolphinscheduler/libs/kerby-pkix-1.0.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-procedure-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-registry-etcd-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-sqoop-3.2.1.jar:/opt/dolphinscheduler/libs/zookeeper-jute-3.8.0.jar:/opt/dolphinscheduler/libs/netty-resolver-dns-native-macos-4.1.53.Final-osx-x86_64.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-sagemaker-3.2.1.jar:/opt/dolphinscheduler/libs/spring-boot-configuration-processor-2.6.1.jar:/opt/dolphinscheduler/libs/hive-common-2.3.9.jar:/opt/dolphinscheduler/libs/kerb-common-1.0.1.jar:/opt/dolphinscheduler/libs/stax-api-1.0.1.jar:/opt/dolphinscheduler/libs/kubernetes-model-storageclass-5.10.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-s3-3.2.1.jar:/opt/dolphinscheduler/libs/spring-boot-starter-jetty-2.7.3.jar:/opt/dolphinscheduler/libs/okio-2.8.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-dms-3.2.1.jar:/opt/dolphinscheduler/libs/simpleclient_common-0.15.0.jar:/opt/dolphinscheduler/libs/sdk-core-2.17.282.jar:/opt/dolphinscheduler/libs/javax.activation-api-1.2.0.jar:/opt/dolphinscheduler/libs/netty-handler-proxy-4.1.53.Final.jar:/opt/dolphinscheduler/libs/kerby-config-1.0.1.jar:/opt/dolphinscheduler/libs/netty-tcnative-classes-2.0.53.Final.jar:/opt/dolphinscheduler/libs/jackson-jaxrs-base-2.13.3.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-trino-3.2.1.jar:/opt/dolphinscheduler/libs/presto-jdbc-0.238.1.jar:/opt/dolphinscheduler/libs/websocket-api-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-flink-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-api-3.2.1.jar:/opt/dolphinscheduler/libs/kubernetes-model-metrics-5.10.2.jar:/opt/dolphinscheduler/libs/datasync-2.17.282.jar:/opt/dolphinscheduler/libs/hadoop-yarn-api-3.2.4.jar:/opt/dolphinscheduler/libs/google-http-client-apache-v2-1.42.3.jar:/opt/dolphinscheduler/libs/hadoop-annotations-3.2.4.jar:/opt/dolphinscheduler/libs/google-oauth-client-1.34.1.jar:/opt/dolphinscheduler/libs/sshd-common-2.8.0.jar:/opt/dolphinscheduler/libs/LatencyUtils-2.0.3.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-spark-3.2.1.jar:/opt/dolphinscheduler/libs/slf4j-api-1.7.36.jar:/opt/dolphinscheduler/libs/snowflake-jdbc-3.13.29.jar:/opt/dolphinscheduler/libs/jackson-datatype-jsr310-2.13.3.jar:/opt/dolphinscheduler/libs/trino-jdbc-402.jar:/opt/dolphinscheduler/libs/logging-interceptor-4.9.3.jar:/opt/dolphinscheduler/libs/simpleclient_tracer_otel_agent-0.15.0.jar:/opt/dolphinscheduler/libs/janino-3.0.16.jar:/opt/dolphinscheduler/libs/jackson-dataformat-yaml-2.13.3.jar:/opt/dolphinscheduler/libs/ion-java-1.0.2.jar:/opt/dolphinscheduler/libs/commons-dbcp-1.4.jar:/opt/dolphinscheduler/libs/jsp-api-2.1.jar:/opt/dolphinscheduler/libs/google-http-client-gson-1.42.3.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-hivecli-3.2.1.jar:/opt/dolphinscheduler/libs/spring-boot-actuator-2.7.3.jar:/opt/dolphinscheduler/libs/google-cloud-core-http-2.10.0.jar:/opt/dolphinscheduler/libs/DmJdbcDriver18-8.1.2.79.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-java-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-dameng-3.2.1.jar:/opt/dolphinscheduler/libs/sshd-sftp-2.8.0.jar:/opt/dolphinscheduler/libs/kerb-crypto-1.0.1.jar:/opt/dolphinscheduler/libs/conscrypt-openjdk-uber-2.5.2.jar:/opt/dolphinscheduler/libs/httpcore-4.4.15.jar:/opt/dolphinscheduler/libs/lz4-java-1.4.0.jar:/opt/dolphinscheduler/libs/guava-retrying-2.0.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-flink-stream-3.2.1.jar:/opt/dolphinscheduler/libs/spring-tx-5.3.22.jar:/opt/dolphinscheduler/libs/grpc-auth-1.41.0.jar:/opt/dolphinscheduler/libs/netty-tcnative-boringssl-static-2.0.53.Final-osx-x86_64.jar:/opt/dolphinscheduler/libs/databend-jdbc-0.0.7.jar:/opt/dolphinscheduler/libs/bcprov-jdk15on-1.69.jar:/opt/dolphinscheduler/libs/commons-lang-2.6.jar:/opt/dolphinscheduler/libs/kubernetes-model-policy-5.10.2.jar:/opt/dolphinscheduler/libs/commons-io-2.11.0.jar:/opt/dolphinscheduler/libs/grpc-grpclb-1.41.0.jar:/opt/dolphinscheduler/libs/netty-tcnative-boringssl-static-2.0.53.Final-linux-x86_64.jar:/opt/dolphinscheduler/libs/opentracing-api-0.33.0.jar:/opt/dolphinscheduler/libs/sshd-scp-2.8.0.jar:/opt/dolphinscheduler/libs/reload4j-1.2.18.3.jar:/opt/dolphinscheduler/libs/netty-tcnative-2.0.48.Final.jar:/opt/dolphinscheduler/libs/jdom2-2.0.6.1.jar:/opt/dolphinscheduler/libs/spring-boot-starter-json-2.7.3.jar:/opt/dolphinscheduler/libs/netty-transport-native-epoll-4.1.53.Final.jar:/opt/dolphinscheduler/libs/google-cloud-core-2.10.0.jar:/opt/dolphinscheduler/libs/javax.jdo-3.2.0-m3.jar:/opt/dolphinscheduler/libs/gax-httpjson-0.108.0.jar:/opt/dolphinscheduler/libs/mybatis-plus-core-3.5.2.jar:/opt/dolphinscheduler/libs/auto-service-annotations-1.0.1.jar:/opt/dolphinscheduler/libs/nimbus-jose-jwt-9.22.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-zeppelin-3.2.1.jar:/opt/dolphinscheduler/libs/commons-compress-1.21.jar:/opt/dolphinscheduler/libs/hadoop-hdfs-client-3.2.4.jar:/opt/dolphinscheduler/libs/msal4j-persistence-extension-1.1.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-pytorch-3.2.1.jar:/opt/dolphinscheduler/libs/netty-tcnative-boringssl-static-2.0.53.Final-windows-x86_64.jar:/opt/dolphinscheduler/libs/jetty-servlets-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/woodstox-core-6.4.0.jar:/opt/dolphinscheduler/libs/spring-cloud-kubernetes-commons-2.1.3.jar:/opt/dolphinscheduler/libs/grpc-protobuf-lite-1.41.0.jar:/opt/dolphinscheduler/libs/jetty-webapp-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/eventstream-1.0.1.jar:/opt/dolphinscheduler/libs/commons-compiler-3.1.7.jar:/opt/dolphinscheduler/libs/netty-transport-4.1.53.Final.jar:/opt/dolphinscheduler/libs/spring-cloud-context-3.1.3.jar:/opt/dolphinscheduler/libs/aws-java-sdk-dms-1.12.300.jar:/opt/dolphinscheduler/libs/hive-storage-api-2.4.0.jar:/opt/dolphinscheduler/libs/client-java-spring-integration-13.0.2.jar:/opt/dolphinscheduler/libs/spring-boot-starter-actuator-2.7.3.jar:/opt/dolphinscheduler/libs/third-party-jackson-core-2.17.282.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-hdfs-3.2.1.jar:/opt/dolphinscheduler/libs/netty-codec-4.1.53.Final.jar:/opt/dolphinscheduler/libs/google-http-client-appengine-1.42.3.jar:/opt/dolphinscheduler/libs/commons-configuration2-2.1.1.jar:/opt/dolphinscheduler/libs/datanucleus-rdbms-4.1.19.jar:/opt/dolphinscheduler/libs/swagger-annotations-1.6.2.jar:/opt/dolphinscheduler/libs/simpleclient_tracer_otel-0.15.0.jar:/opt/dolphinscheduler/libs/kotlin-stdlib-common-1.6.21.jar:/opt/dolphinscheduler/libs/aws-core-2.17.282.jar:/opt/dolphinscheduler/libs/kerb-core-1.0.1.jar:/opt/dolphinscheduler/libs/httpasyncclient-4.1.5.jar:/opt/dolphinscheduler/libs/dolphinscheduler-extract-worker-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-spi-3.2.1.jar:/opt/dolphinscheduler/libs/okhttp-2.7.5.jar:/opt/dolphinscheduler/libs/google-api-client-2.2.0.jar:/opt/dolphinscheduler/libs/kotlin-stdlib-1.6.21.jar:/opt/dolphinscheduler/libs/jakarta.websocket-api-1.1.2.jar:/opt/dolphinscheduler/libs/libthrift-0.9.3.jar:/opt/dolphinscheduler/libs/spring-boot-starter-aop-2.7.3.jar:/opt/dolphinscheduler/libs/netty-common-4.1.53.Final.jar:/opt/dolphinscheduler/libs/log4j-1.2-api-2.17.2.jar:/opt/dolphinscheduler/libs/jackson-databind-2.13.4.jar:/opt/dolphinscheduler/libs/jackson-dataformat-xml-2.13.3.jar:/opt/dolphinscheduler/libs/kubernetes-model-events-5.10.2.jar:/opt/dolphinscheduler/libs/gson-2.9.1.jar:/opt/dolphinscheduler/libs/proto-google-iam-v1-1.9.0.jar:/opt/dolphinscheduler/libs/netty-codec-socks-4.1.53.Final.jar:/opt/dolphinscheduler/libs/zjsonpatch-0.3.0.jar:/opt/dolphinscheduler/libs/hadoop-mapreduce-client-common-3.2.4.jar:/opt/dolphinscheduler/libs/dolphinscheduler-registry-api-3.2.1.jar:/opt/dolphinscheduler/libs/azure-storage-blob-12.21.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-zeppelin-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-api-3.2.1.jar:/opt/dolphinscheduler/libs/aws-java-sdk-s3-1.12.300.jar:/opt/dolphinscheduler/libs/stax2-api-4.2.1.jar:/opt/dolphinscheduler/libs/jakarta.annotation-api-1.3.5.jar:/opt/dolphinscheduler/libs/kubernetes-model-discovery-5.10.2.jar:/opt/dolphinscheduler/libs/jna-5.10.0.jar:/opt/dolphinscheduler/libs/spring-jcl-5.3.22.jar
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:38.163 +0800 o.a.z.ZooKeeper:[98] - Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:38.165 +0800 o.a.z.ZooKeeper:[98] - Client environment:java.io.tmpdir=/tmp
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:38.169 +0800 o.a.z.ZooKeeper:[98] - Client environment:java.compiler=<NA>
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:38.169 +0800 o.a.z.ZooKeeper:[98] - Client environment:os.name=Linux
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:38.170 +0800 o.a.z.ZooKeeper:[98] - Client environment:os.arch=amd64
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:38.171 +0800 o.a.z.ZooKeeper:[98] - Client environment:os.version=6.5.0-28-generic
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:38.171 +0800 o.a.z.ZooKeeper:[98] - Client environment:user.name=root
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:38.172 +0800 o.a.z.ZooKeeper:[98] - Client environment:user.home=/root
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:38.174 +0800 o.a.z.ZooKeeper:[98] - Client environment:user.dir=/opt/dolphinscheduler
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:38.175 +0800 o.a.z.ZooKeeper:[98] - Client environment:os.memory.free=3217MB
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:38.177 +0800 o.a.z.ZooKeeper:[98] - Client environment:os.memory.max=3840MB
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:38.184 +0800 o.a.z.ZooKeeper:[98] - Client environment:os.memory.total=3840MB
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:38.192 +0800 o.a.z.ZooKeeper:[637] - Initiating client connection, connectString=dolphinscheduler-zookeeper:2181 sessionTimeout=30000 watcher=org.apache.curator.ConnectionState@6996bbc4
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:38.223 +0800 o.a.z.c.X509Util:[77] - Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:38.251 +0800 o.a.z.ClientCnxnSocket:[239] - jute.maxbuffer value is 1048575 Bytes
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:38.350 +0800 o.a.z.ClientCnxn:[1732] - zookeeper.request.timeout value is 0. feature enabled=false
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:38.474 +0800 o.a.c.f.i.CuratorFrameworkImpl:[386] - Default schema
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:38.495 +0800 o.a.z.ClientCnxn:[1171] - Opening socket connection to server dolphinscheduler-zookeeper/172.18.0.4:2181.
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:38.497 +0800 o.a.z.ClientCnxn:[1173] - SASL config status: Will not attempt to authenticate using SASL (unknown error)
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:38.519 +0800 o.a.z.ClientCnxn:[1005] - Socket connection established, initiating session, client: /172.18.1.1:33654, server: dolphinscheduler-zookeeper/172.18.0.4:2181
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:38.619 +0800 o.a.z.ClientCnxn:[1444] - Session establishment complete on server dolphinscheduler-zookeeper/172.18.0.4:2181, session id = 0x10000aa0a590001, negotiated timeout = 30000
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:38.666 +0800 o.a.c.f.s.ConnectionStateManager:[252] - State change: CONNECTED
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:39.184 +0800 o.a.c.f.i.EnsembleTracker:[201] - New config event received: {}
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:39.200 +0800 o.a.c.f.i.EnsembleTracker:[201] - New config event received: {}
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:39.604 +0800 o.a.d.s.w.r.WorkerRpcServer:[41] - WorkerRpcServer starting...
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:40.001 +0800 o.a.d.e.b.NettyRemotingServer:[112] - WorkerRpcServer bind success at port: 1234
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:40.001 +0800 o.a.d.s.w.r.WorkerRpcServer:[43] - WorkerRpcServer started...
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:40.176 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: JAVA - JavaTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:40.359 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: JAVA - JavaTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:40.360 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: JUPYTER - JupyterTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:40.398 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: JUPYTER - JupyterTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:40.398 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: SPARK - SparkTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:40.401 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: SPARK - SparkTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:40.401 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: FLINK_STREAM - FlinkStreamTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:40.404 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: FLINK_STREAM - FlinkStreamTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:40.404 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: PYTHON - PythonTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:40.405 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: PYTHON - PythonTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:40.406 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: DATASYNC - DatasyncTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:40.407 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: DATASYNC - DatasyncTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:40.407 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: DATA_FACTORY - DatafactoryTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:40.415 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: DATA_FACTORY - DatafactoryTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:40.416 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: CHUNJUN - ChunJunTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:40.418 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: CHUNJUN - ChunJunTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:40.418 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: REMOTESHELL - RemoteShellTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:40.420 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: REMOTESHELL - RemoteShellTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:40.420 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: PIGEON - PigeonTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:40.439 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: PIGEON - PigeonTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:40.439 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: SHELL - ShellTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:40.441 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: SHELL - ShellTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:40.441 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: PROCEDURE - ProcedureTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:40.443 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: PROCEDURE - ProcedureTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:40.443 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: MR - MapReduceTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:40.453 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: MR - MapReduceTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:40.454 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: SQOOP - SqoopTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:40.456 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: SQOOP - SqoopTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:40.456 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: PYTORCH - PytorchTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:40.457 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: PYTORCH - PytorchTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:40.458 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: K8S - K8sTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:40.459 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: K8S - K8sTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:40.459 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: SEATUNNEL - SeatunnelTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:40.548 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: SEATUNNEL - SeatunnelTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:40.549 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: SAGEMAKER - SagemakerTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:40.551 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: SAGEMAKER - SagemakerTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:40.551 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: HTTP - HttpTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:40.553 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: HTTP - HttpTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:40.554 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: EMR - EmrTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:40.942 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: EMR - EmrTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:40.942 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: DMS - DmsTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:40.954 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: DMS - DmsTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:40.954 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: DATA_QUALITY - DataQualityTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:40.965 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: DATA_QUALITY - DataQualityTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:40.965 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: KUBEFLOW - KubeflowTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:40.980 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: KUBEFLOW - KubeflowTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:40.981 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: SQL - SqlTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:41.042 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: SQL - SqlTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:41.042 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: DVC - DvcTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:41.053 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: DVC - DvcTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:41.054 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: DATAX - DataxTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:41.068 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: DATAX - DataxTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:41.069 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: ZEPPELIN - ZeppelinTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:41.072 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: ZEPPELIN - ZeppelinTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:41.072 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: DINKY - DinkyTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:41.078 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: DINKY - DinkyTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:41.079 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: MLFLOW - MlflowTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:41.081 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: MLFLOW - MlflowTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:41.081 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: OPENMLDB - OpenmldbTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:41.091 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: OPENMLDB - OpenmldbTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:41.091 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: LINKIS - LinkisTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:41.093 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: LINKIS - LinkisTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:41.093 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: FLINK - FlinkTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:41.094 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: FLINK - FlinkTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:41.094 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: HIVECLI - HiveCliTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:41.096 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: HIVECLI - HiveCliTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:41.249 +0800 o.a.d.c.u.JSONUtils:[72] - init timezone: sun.util.calendar.ZoneInfo[id="Asia/Shanghai",offset=28800000,dstSavings=0,useDaylight=false,transitions=31,lastRule=null]
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:41.443 +0800 o.a.d.s.w.r.WorkerRegistryClient:[104] - Worker node: 172.18.1.1:1234 registry to ZK /nodes/worker/172.18.1.1:1234 successfully
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:42.534 +0800 o.a.d.c.m.BaseHeartBeatTask:[48] - Starting WorkerHeartBeatTask...
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:42.540 +0800 o.a.d.c.m.BaseHeartBeatTask:[50] - Started WorkerHeartBeatTask, heartBeatInterval: 10000...
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:42.541 +0800 o.a.d.s.w.r.WorkerRegistryClient:[114] - Worker node: 172.18.1.1:1234 registry finished
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:42.542 +0800 o.a.d.s.w.m.MessageRetryRunner:[69] - Message retry runner staring
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:42.562 +0800 o.a.d.s.w.m.MessageRetryRunner:[72] - Injected message sender: TaskInstanceExecutionFinishEventSender
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:42.562 +0800 o.a.d.s.w.m.MessageRetryRunner:[72] - Injected message sender: TaskInstanceExecutionInfoUpdateEventSender
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:42.563 +0800 o.a.d.s.w.m.MessageRetryRunner:[72] - Injected message sender: TaskInstanceExecutionRunningEventSender
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:42.713 +0800 o.a.d.s.w.m.MessageRetryRunner:[75] - Message retry runner started
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:42.753 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.0853242320819112 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:43.843 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.6549295774647887 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:44.891 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.2289733392252173 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:46.290 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.0982776089159068 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:47.298 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.2637362637362637 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:48.318 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 2.0 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:49.320 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.5052631578947366 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:50.529 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.4178082191780823 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:51.533 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.7054263565891472 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:52.534 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.5036496350364965 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:53.670 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.8666666666666667 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:54.784 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.56 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:55.045 +0800 o.s.b.a.e.w.EndpointLinksResolver:[58] - Exposing 3 endpoint(s) beneath base path '/actuator'
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:55.616 +0800 o.e.j.s.h.C.application:[2368] - Initializing Spring DispatcherServlet 'dispatcherServlet'
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:55.625 +0800 o.s.w.s.DispatcherServlet:[525] - Initializing Servlet 'dispatcherServlet'
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:55.628 +0800 o.s.w.s.DispatcherServlet:[547] - Completed initialization in 3 ms
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:55.694 +0800 o.e.j.s.AbstractConnector:[333] - Started ServerConnector@acb5508{HTTP/1.1, (http/1.1)}{0.0.0.0:1235}
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:55.764 +0800 o.s.b.w.e.j.JettyWebServer:[172] - Jetty started on port(s) 1235 (http/1.1) with context path '/'
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:55.790 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.3336236617673745 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:56.044 +0800 o.a.d.s.w.WorkerServer:[61] - Started WorkerServer in 52.248 seconds (JVM running for 59.175)
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:56.800 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.5286624203821657 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:57.802 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.97008547008547 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:58.805 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.0698529411764706 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:50:59.823 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7966101694915254 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:51:01.017 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9241071428571428 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:51:02.164 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.845679012345679 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:51:03.168 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9357142857142857 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:51:04.306 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8957055214723926 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:51:05.322 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8504672897196262 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:51:06.440 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8756756756756756 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:51:07.452 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7243243243243244 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:51:08.459 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9411764705882353 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:51:09.462 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.91015625 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:51:10.498 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8543689320388349 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:51:11.506 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.825531914893617 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:51:12.519 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9945054945054945 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:51:13.521 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9481132075471699 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:51:14.575 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9370860927152318 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:51:16.687 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8247863247863247 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:51:17.710 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.885608856088561 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:51:20.773 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8141592920353983 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:51:21.789 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7927170868347339 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:51:22.796 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8567073170731707 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:51:23.817 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.776255707762557 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:51:24.823 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8157894736842105 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:51:25.832 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7999999999999999 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:51:26.842 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8691860465116279 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:51:27.844 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9269662921348314 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:51:28.854 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8254847645429362 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:51:29.859 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8925619834710745 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:51:30.862 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8130311614730878 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:51:31.898 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8337801608579088 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:51:32.900 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9175824175824177 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-3959] - [INFO] 2024-05-07 10:51:43.935 +0800 o.a.d.s.w.r.o.UpdateWorkflowHostOperationFunction:[49] - Received UpdateWorkflowHostRequest: UpdateWorkflowHostRequest(taskInstanceId=3959, workflowHost=172.18.0.14:5678)
[WI-0][TI-0] - [INFO] 2024-05-07 10:51:44.307 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=3991, taskName=[null check] filtered data persistence, firstSubmitTime=1715050304042, startTime=0, taskType=DATA_QUALITY, workflowInstanceHost=172.18.0.14:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13505298546272, processDefineVersion=21, appIds=null, processInstanceId=1061, scheduleTime=0, globalParams=null, executorId=1, cmdTypeIfComplement=2, tenantCode=default, processDefineId=0, projectId=0, projectCode=13001194483488, taskParams={"localParams":[],"resourceList":[],"ruleId":6,"ruleInputParameter":{"check_type":"0","comparison_type":1,"comparison_name":"0","failure_strategy":"0","operator":"0","src_connector_type":1,"src_datasource_id":6,"src_database":"persistence","src_field":"content","src_table":"filtered_data_persistence","threshold":"0"},"sparkParameters":{"deployMode":"local","driverCores":1,"driverMemory":"512M","executorCores":1,"executorMemory":"1G","numExecutors":1,"others":"--conf spark.driver.extraJavaOptions=\"-Divy.cache.dir=/tmp -Divy.home=/tmp\" \\\n--packages org.postgresql:postgresql:42.7.3","yarnQueue":""}}, environmentConfig=export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export PYSPARK_DRIVER_PYTHON=/bin/python3.11
export PYSPARK_PYTHON=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='[null check] filtered data persistence'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13001194483488'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='1061'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240507'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240506'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='3991'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='qualti_test'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13505264408800'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13505298546272'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240507105144'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=null, dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=org.apache.dolphinscheduler.plugin.task.api.DataQualityTaskExecutionContext@70d38ffd, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-0][TI-0] - [INFO] 2024-05-07 10:51:44.340 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8575418994413408 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-1061][TI-3991] - [INFO] 2024-05-07 10:51:44.402 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: [null check] filtered data persistence to wait queue success
[WI-1061][TI-3991] - [INFO] 2024-05-07 10:51:44.417 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-1061][TI-3991] - [INFO] 2024-05-07 10:51:44.429 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-1061][TI-3991] - [INFO] 2024-05-07 10:51:44.435 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-1061][TI-3991] - [INFO] 2024-05-07 10:51:44.436 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-1061][TI-3991] - [INFO] 2024-05-07 10:51:44.436 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1715050304436
[WI-1061][TI-3991] - [INFO] 2024-05-07 10:51:44.437 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 1061_3991
[WI-1061][TI-3991] - [INFO] 2024-05-07 10:51:44.458 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 3991,
  "taskName" : "[null check] filtered data persistence",
  "firstSubmitTime" : 1715050304042,
  "startTime" : 1715050304436,
  "taskType" : "DATA_QUALITY",
  "workflowInstanceHost" : "172.18.0.14:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240507/13505298546272/21/1061/3991.log",
  "processId" : 0,
  "processDefineCode" : 13505298546272,
  "processDefineVersion" : 21,
  "processInstanceId" : 1061,
  "scheduleTime" : 0,
  "executorId" : 1,
  "cmdTypeIfComplement" : 2,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13001194483488,
  "taskParams" : "{\"localParams\":[],\"resourceList\":[],\"ruleId\":6,\"ruleInputParameter\":{\"check_type\":\"0\",\"comparison_type\":1,\"comparison_name\":\"0\",\"failure_strategy\":\"0\",\"operator\":\"0\",\"src_connector_type\":1,\"src_datasource_id\":6,\"src_database\":\"persistence\",\"src_field\":\"content\",\"src_table\":\"filtered_data_persistence\",\"threshold\":\"0\"},\"sparkParameters\":{\"deployMode\":\"local\",\"driverCores\":1,\"driverMemory\":\"512M\",\"executorCores\":1,\"executorMemory\":\"1G\",\"numExecutors\":1,\"others\":\"--conf spark.driver.extraJavaOptions=\\\"-Divy.cache.dir=/tmp -Divy.home=/tmp\\\" \\\\\\n--packages org.postgresql:postgresql:42.7.3\",\"yarnQueue\":\"\"}}",
  "environmentConfig" : "export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3\nexport JAVA_HOME=/opt/java/openjdk\nexport PYSPARK_DRIVER_PYTHON=/bin/python3.11\nexport PYSPARK_PYTHON=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "[null check] filtered data persistence"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13001194483488"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1061"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240507"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240506"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "3991"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "qualti_test"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13505264408800"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13505298546272"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240507105144"
    }
  },
  "taskAppId" : "1061_3991",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "dryRun" : 0,
  "paramsMap" : { },
  "dataQualityTaskExecutionContext" : {
    "ruleId" : 6,
    "ruleName" : "$t(uniqueness_check)",
    "ruleType" : 0,
    "ruleInputEntryList" : "[{\"id\":1,\"field\":\"src_connector_type\",\"type\":\"select\",\"title\":\"$t(src_connector_type)\",\"data\":\"\",\"options\":\"[{\\\"label\\\":\\\"HIVE\\\",\\\"value\\\":\\\"HIVE\\\"},{\\\"label\\\":\\\"JDBC\\\",\\\"value\\\":\\\"JDBC\\\"}]\",\"placeholder\":\"please select source connector type\",\"optionSourceType\":2,\"dataType\":2,\"inputType\":0,\"isShow\":true,\"canEdit\":true,\"isEmit\":true,\"isValidate\":false,\"valuesMap\":null,\"index\":1,\"createTime\":null,\"updateTime\":null},{\"id\":2,\"field\":\"src_datasource_id\",\"type\":\"select\",\"title\":\"$t(src_datasource_id)\",\"data\":\"\",\"options\":null,\"placeholder\":\"please select source datasource id\",\"optionSourceType\":1,\"dataType\":2,\"inputType\":0,\"isShow\":true,\"canEdit\":true,\"isEmit\":true,\"isValidate\":false,\"valuesMap\":null,\"index\":2,\"createTime\":null,\"updateTime\":null},{\"id\":30,\"field\":\"src_database\",\"type\":\"select\",\"title\":\"$t(src_database)\",\"data\":null,\"options\":null,\"placeholder\":\"Please select source database\",\"optionSourceType\":0,\"dataType\":0,\"inputType\":0,\"isShow\":true,\"canEdit\":true,\"isEmit\":true,\"isValidate\":true,\"valuesMap\":null,\"index\":2,\"createTime\":null,\"updateTime\":null},{\"id\":3,\"field\":\"src_table\",\"type\":\"select\",\"title\":\"$t(src_table)\",\"data\":null,\"options\":null,\"placeholder\":\"Please enter source table name\",\"optionSourceType\":0,\"dataType\":0,\"inputType\":0,\"isShow\":true,\"canEdit\":true,\"isEmit\":true,\"isValidate\":true,\"valuesMap\":null,\"index\":3,\"createTime\":null,\"updateTime\":null},{\"id\":4,\"field\":\"src_filter\",\"type\":\"input\",\"title\":\"$t(src_filter)\",\"data\":null,\"options\":null,\"placeholder\":\"Please enter filter expression\",\"optionSourceType\":0,\"dataType\":3,\"inputType\":0,\"isShow\":true,\"canEdit\":true,\"isEmit\":false,\"isValidate\":false,\"valuesMap\":null,\"index\":4,\"createTime\":null,\"updateTime\":null},{\"id\":5,\"field\":\"src_field\",\"type\":\"select\",\"title\":\"$t(src_field)\",\"data\":null,\"options\":null,\"placeholder\":\"Please enter column, only single column is supported\",\"optionSourceType\":0,\"dataType\":0,\"inputType\":0,\"isShow\":true,\"canEdit\":true,\"isEmit\":false,\"isValidate\":true,\"valuesMap\":null,\"index\":5,\"createTime\":null,\"updateTime\":null},{\"id\":6,\"field\":\"statistics_name\",\"type\":\"input\",\"title\":\"$t(statistics_name)\",\"data\":\"duplicate_count.duplicates\",\"options\":null,\"placeholder\":\"Please enter statistics name, the alias in statistics execute sql\",\"optionSourceType\":0,\"dataType\":0,\"inputType\":1,\"isShow\":false,\"canEdit\":false,\"isEmit\":false,\"isValidate\":true,\"valuesMap\":\"{\\\"statistics_name\\\":\\\"duplicate_count.duplicates\\\"}\",\"index\":6,\"createTime\":null,\"updateTime\":null},{\"id\":7,\"field\":\"check_type\",\"type\":\"select\",\"title\":\"$t(check_type)\",\"data\":\"0\",\"options\":\"[{\\\"label\\\":\\\"Expected - Actual\\\",\\\"value\\\":\\\"0\\\"},{\\\"label\\\":\\\"Actual - Expected\\\",\\\"value\\\":\\\"1\\\"},{\\\"label\\\":\\\"Actual / Expected\\\",\\\"value\\\":\\\"2\\\"},{\\\"label\\\":\\\"(Expected - Actual) / Expected\\\",\\\"value\\\":\\\"3\\\"}]\",\"placeholder\":\"please select check type\",\"optionSourceType\":0,\"dataType\":0,\"inputType\":3,\"isShow\":true,\"canEdit\":true,\"isEmit\":true,\"isValidate\":false,\"valuesMap\":null,\"index\":7,\"createTime\":null,\"updateTime\":null},{\"id\":8,\"field\":\"operator\",\"type\":\"select\",\"title\":\"$t(operator)\",\"data\":\"0\",\"options\":\"[{\\\"label\\\":\\\"=\\\",\\\"value\\\":\\\"0\\\"},{\\\"label\\\":\\\"<\\\",\\\"value\\\":\\\"1\\\"},{\\\"label\\\":\\\"<=\\\",\\\"value\\\":\\\"2\\\"},{\\\"label\\\":\\\">\\\",\\\"value\\\":\\\"3\\\"},{\\\"label\\\":\\\">=\\\",\\\"value\\\":\\\"4\\\"},{\\\"label\\\":\\\"!=\\\",\\\"value\\\":\\\"5\\\"}]\",\"placeholder\":\"please select operator\",\"optionSourceType\":0,\"dataType\":0,\"inputType\":3,\"isShow\":true,\"canEdit\":true,\"isEmit\":false,\"isValidate\":false,\"valuesMap\":null,\"index\":8,\"createTime\":null,\"updateTime\":null},{\"id\":9,\"field\":\"threshold\",\"type\":\"input\",\"title\":\"$t(threshold)\",\"data\":null,\"options\":null,\"placeholder\":\"Please enter threshold, number is needed\",\"optionSourceType\":0,\"dataType\":2,\"inputType\":3,\"isShow\":true,\"canEdit\":true,\"isEmit\":false,\"isValidate\":true,\"valuesMap\":null,\"index\":9,\"createTime\":null,\"updateTime\":null},{\"id\":10,\"field\":\"failure_strategy\",\"type\":\"select\",\"title\":\"$t(failure_strategy)\",\"data\":\"0\",\"options\":\"[{\\\"label\\\":\\\"Alert\\\",\\\"value\\\":\\\"0\\\"},{\\\"label\\\":\\\"Block\\\",\\\"value\\\":\\\"1\\\"}]\",\"placeholder\":\"please select failure strategy\",\"optionSourceType\":0,\"dataType\":0,\"inputType\":3,\"isShow\":true,\"canEdit\":true,\"isEmit\":false,\"isValidate\":false,\"valuesMap\":null,\"index\":10,\"createTime\":null,\"updateTime\":null},{\"id\":17,\"field\":\"comparison_name\",\"type\":\"input\",\"title\":\"$t(comparison_name)\",\"data\":null,\"options\":null,\"placeholder\":\"Please enter comparison name, the alias in comparison execute sql\",\"optionSourceType\":0,\"dataType\":0,\"inputType\":0,\"isShow\":false,\"canEdit\":false,\"isEmit\":false,\"isValidate\":true,\"valuesMap\":\"\",\"index\":11,\"createTime\":null,\"updateTime\":null},{\"id\":19,\"field\":\"comparison_type\",\"type\":\"select\",\"title\":\"$t(comparison_type)\",\"data\":\"\",\"options\":null,\"placeholder\":\"Please enter comparison title\",\"optionSourceType\":3,\"dataType\":0,\"inputType\":2,\"isShow\":true,\"canEdit\":false,\"isEmit\":true,\"isValidate\":false,\"valuesMap\":null,\"index\":12,\"createTime\":null,\"updateTime\":null}]",
    "executeSqlList" : "[{\"id\":6,\"index\":1,\"sql\":\"SELECT ${src_field} FROM ${src_table} group by ${src_field} having count(*) > 1\",\"tableAlias\":\"duplicate_items\",\"type\":0,\"createTime\":\"2021-03-03 11:31:24\",\"updateTime\":\"2021-03-03 11:31:24\",\"errorOutputSql\":true},{\"id\":7,\"index\":1,\"sql\":\"SELECT COUNT(*) AS duplicates FROM duplicate_items\",\"tableAlias\":\"duplicate_count\",\"type\":1,\"createTime\":\"2021-03-03 11:31:24\",\"updateTime\":\"2021-03-03 11:31:24\",\"errorOutputSql\":false}]",
    "comparisonNeedStatisticsValueTable" : false,
    "compareWithFixedValue" : true,
    "hdfsPath" : "hdfs://mycluster:8020/user/default/data_quality_error_data",
    "sourceConnectorType" : "JDBC",
    "sourceType" : 1,
    "sourceConnectionParams" : "{\"user\":\"root\",\"password\":\"root\",\"address\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432\",\"database\":\"persistence\",\"jdbcUrl\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432/persistence\",\"driverClassName\":\"org.postgresql.Driver\",\"validationQuery\":\"select version()\",\"other\":{\"password\":\"root\"}}",
    "targetConnectorType" : null,
    "targetType" : 0,
    "targetConnectionParams" : null,
    "writerConnectorType" : "JDBC",
    "writerType" : 1,
    "writerTable" : "t_ds_dq_execute_result",
    "writerConnectionParams" : "{\"user\":\"root\",\"password\":\"root\",\"address\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432\",\"database\":\"dolphinscheduler\",\"jdbcUrl\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432/dolphinscheduler\"}",
    "statisticsValueConnectorType" : "JDBC",
    "statisticsValueType" : 1,
    "statisticsValueTable" : "t_ds_dq_task_statistics_value",
    "statisticsValueWriterConnectionParams" : "{\"user\":\"root\",\"password\":\"root\",\"address\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432\",\"database\":\"dolphinscheduler\",\"jdbcUrl\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432/dolphinscheduler\"}"
  },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-1061][TI-3991] - [INFO] 2024-05-07 10:51:44.461 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-1061][TI-3991] - [INFO] 2024-05-07 10:51:44.461 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-1061][TI-3991] - [INFO] 2024-05-07 10:51:44.462 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-1061][TI-3991] - [INFO] 2024-05-07 10:51:44.603 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-1061][TI-3991] - [INFO] 2024-05-07 10:51:44.646 +0800 o.a.d.c.u.OSUtils:[231] - create linux os user: default
[WI-1061][TI-3991] - [INFO] 2024-05-07 10:51:44.648 +0800 o.a.d.c.u.OSUtils:[233] - execute cmd: sudo useradd -g root
 default
[WI-1061][TI-3991] - [INFO] 2024-05-07 10:51:44.851 +0800 o.a.d.c.u.OSUtils:[190] - create user default success
[WI-1061][TI-3991] - [INFO] 2024-05-07 10:51:44.852 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-1061][TI-3991] - [INFO] 2024-05-07 10:51:44.866 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13001194483488/13505298546272_21/1061/3991 check successfully
[WI-1061][TI-3991] - [INFO] 2024-05-07 10:51:44.867 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.dq.DataQualityTaskChannel successfully
[WI-1061][TI-3991] - [INFO] 2024-05-07 10:51:44.907 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-1061][TI-3991] - [INFO] 2024-05-07 10:51:44.917 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-1061][TI-3991] - [INFO] 2024-05-07 10:51:44.923 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: DATA_QUALITY create successfully
[WI-1061][TI-3991] - [INFO] 2024-05-07 10:51:44.931 +0800 o.a.d.p.t.d.DataQualityTask:[89] - Initialize data quality task params {
  "localParams" : [ ],
  "varPool" : null,
  "ruleId" : 6,
  "ruleInputParameter" : {
    "check_type" : "0",
    "comparison_type" : "1",
    "comparison_name" : "0",
    "failure_strategy" : "0",
    "operator" : "0",
    "src_connector_type" : "1",
    "src_datasource_id" : "6",
    "src_database" : "persistence",
    "src_field" : "content",
    "src_table" : "filtered_data_persistence",
    "threshold" : "0"
  },
  "sparkParameters" : {
    "localParams" : null,
    "varPool" : null,
    "mainJar" : null,
    "mainClass" : null,
    "deployMode" : "local",
    "mainArgs" : null,
    "driverCores" : 1,
    "driverMemory" : "512M",
    "numExecutors" : 1,
    "executorCores" : 1,
    "executorMemory" : "1G",
    "appName" : null,
    "yarnQueue" : "",
    "others" : "--conf spark.driver.extraJavaOptions=\"-Divy.cache.dir=/tmp -Divy.home=/tmp\" \\\n--packages org.postgresql:postgresql:42.7.3",
    "programType" : null,
    "resourceList" : [ ]
  }
}
[WI-1061][TI-3991] - [INFO] 2024-05-07 10:51:45.012 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: HANA
[WI-1061][TI-3991] - [INFO] 2024-05-07 10:51:45.013 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: HANA
[WI-1061][TI-3991] - [INFO] 2024-05-07 10:51:45.017 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: SQLSERVER
[WI-1061][TI-3991] - [INFO] 2024-05-07 10:51:45.019 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: SQLSERVER
[WI-1061][TI-3991] - [INFO] 2024-05-07 10:51:45.024 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: SAGEMAKER
[WI-1061][TI-3991] - [INFO] 2024-05-07 10:51:45.026 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: SAGEMAKER
[WI-1061][TI-3991] - [INFO] 2024-05-07 10:51:45.031 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: DATABEND
[WI-1061][TI-3991] - [INFO] 2024-05-07 10:51:45.032 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: DATABEND
[WI-1061][TI-3991] - [INFO] 2024-05-07 10:51:45.112 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: AZURESQL
[WI-1061][TI-3991] - [INFO] 2024-05-07 10:51:45.124 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: AZURESQL
[WI-1061][TI-3991] - [INFO] 2024-05-07 10:51:45.132 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: HIVE
[WI-1061][TI-3991] - [INFO] 2024-05-07 10:51:45.132 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: HIVE
[WI-1061][TI-3991] - [INFO] 2024-05-07 10:51:45.133 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: DORIS
[WI-1061][TI-3991] - [INFO] 2024-05-07 10:51:45.134 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: DORIS
[WI-1061][TI-3991] - [INFO] 2024-05-07 10:51:45.148 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: POSTGRESQL
[WI-1061][TI-3991] - [INFO] 2024-05-07 10:51:45.150 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: POSTGRESQL
[WI-1061][TI-3991] - [INFO] 2024-05-07 10:51:45.155 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: MYSQL
[WI-1061][TI-3991] - [INFO] 2024-05-07 10:51:45.158 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: MYSQL
[WI-1061][TI-3991] - [INFO] 2024-05-07 10:51:45.161 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: REDSHIFT
[WI-1061][TI-3991] - [INFO] 2024-05-07 10:51:45.162 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: REDSHIFT
[WI-1061][TI-3991] - [INFO] 2024-05-07 10:51:45.167 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: SNOWFLAKE
[WI-1061][TI-3991] - [INFO] 2024-05-07 10:51:45.168 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: SNOWFLAKE
[WI-1061][TI-3991] - [INFO] 2024-05-07 10:51:45.171 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: STARROCKS
[WI-1061][TI-3991] - [INFO] 2024-05-07 10:51:45.173 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: STARROCKS
[WI-1061][TI-3991] - [INFO] 2024-05-07 10:51:45.177 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: SSH
[WI-1061][TI-3991] - [INFO] 2024-05-07 10:51:45.182 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: SSH
[WI-1061][TI-3991] - [INFO] 2024-05-07 10:51:45.191 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: ATHENA
[WI-1061][TI-3991] - [INFO] 2024-05-07 10:51:45.192 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: ATHENA
[WI-1061][TI-3991] - [INFO] 2024-05-07 10:51:45.196 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: PRESTO
[WI-1061][TI-3991] - [INFO] 2024-05-07 10:51:45.199 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: PRESTO
[WI-1061][TI-3991] - [INFO] 2024-05-07 10:51:45.209 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: OCEANBASE
[WI-1061][TI-3991] - [INFO] 2024-05-07 10:51:45.212 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: OCEANBASE
[WI-1061][TI-3991] - [INFO] 2024-05-07 10:51:45.225 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: ORACLE
[WI-1061][TI-3991] - [INFO] 2024-05-07 10:51:45.226 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: ORACLE
[WI-1061][TI-3991] - [INFO] 2024-05-07 10:51:45.228 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: CLICKHOUSE
[WI-1061][TI-3991] - [INFO] 2024-05-07 10:51:45.231 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: CLICKHOUSE
[WI-1061][TI-3991] - [INFO] 2024-05-07 10:51:45.246 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: VERTICA
[WI-1061][TI-3991] - [INFO] 2024-05-07 10:51:45.247 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: VERTICA
[WI-1061][TI-3991] - [INFO] 2024-05-07 10:51:45.251 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: KYUUBI
[WI-1061][TI-3991] - [INFO] 2024-05-07 10:51:45.257 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: KYUUBI
[WI-1061][TI-3991] - [INFO] 2024-05-07 10:51:45.260 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: DB2
[WI-1061][TI-3991] - [INFO] 2024-05-07 10:51:45.262 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: DB2
[WI-1061][TI-3991] - [INFO] 2024-05-07 10:51:45.265 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: TRINO
[WI-1061][TI-3991] - [INFO] 2024-05-07 10:51:45.265 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: TRINO
[WI-1061][TI-3991] - [INFO] 2024-05-07 10:51:45.270 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: SPARK
[WI-1061][TI-3991] - [INFO] 2024-05-07 10:51:45.270 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: SPARK
[WI-1061][TI-3991] - [INFO] 2024-05-07 10:51:45.275 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: DAMENG
[WI-1061][TI-3991] - [INFO] 2024-05-07 10:51:45.276 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: DAMENG
[WI-1061][TI-3991] - [INFO] 2024-05-07 10:51:45.283 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[45] - start register processor: ZEPPELIN
[WI-1061][TI-3991] - [INFO] 2024-05-07 10:51:45.283 +0800 o.a.d.p.d.a.p.DataSourceProcessorManager:[51] - done register processor: ZEPPELIN
[WI-1061][TI-3991] - [INFO] 2024-05-07 10:51:45.303 +0800 o.a.d.p.t.d.DataQualityTask:[119] - data quality configuration: {
  "name" : "$t(uniqueness_check)",
  "env" : {
    "type" : "batch",
    "config" : null
  },
  "readers" : [ {
    "type" : "JDBC",
    "config" : {
      "database" : "persistence",
      "password" : "root",
      "driver" : "org.postgresql.Driver",
      "user" : "root",
      "output_table" : "persistence_filtered_data_persistence",
      "table" : "filtered_data_persistence",
      "url" : "jdbc:postgresql://dolphinscheduler-postgresql:5432/persistence?password=root"
    }
  } ],
  "transformers" : [ {
    "type" : "sql",
    "config" : {
      "index" : 1,
      "output_table" : "duplicate_items",
      "sql" : "SELECT content FROM persistence_filtered_data_persistence group by content having count(*) > 1"
    }
  }, {
    "type" : "sql",
    "config" : {
      "index" : 2,
      "output_table" : "duplicate_count",
      "sql" : "SELECT COUNT(*) AS duplicates FROM duplicate_items"
    }
  } ],
  "writers" : [ {
    "type" : "JDBC",
    "config" : {
      "database" : "dolphinscheduler",
      "password" : "root",
      "driver" : "org.postgresql.Driver",
      "user" : "root",
      "table" : "t_ds_dq_execute_result",
      "url" : "jdbc:postgresql://dolphinscheduler-postgresql:5432/dolphinscheduler",
      "sql" : "select 0 as rule_type,'$t(uniqueness_check)' as rule_name,0 as process_definition_id,1061 as process_instance_id,3991 as task_instance_id,duplicate_count.duplicates AS statistics_value,0 AS comparison_value,1 AS comparison_type,0 as check_type,0 as threshold,0 as operator,0 as failure_strategy,'hdfs://mycluster:8020/user/default/data_quality_error_data/0_1061_[null check] filtered data persistence' as error_output_path,'2024-05-07 10:51:44' as create_time,'2024-05-07 10:51:44' as update_time from duplicate_count "
    }
  }, {
    "type" : "JDBC",
    "config" : {
      "database" : "dolphinscheduler",
      "password" : "root",
      "driver" : "org.postgresql.Driver",
      "user" : "root",
      "table" : "t_ds_dq_task_statistics_value",
      "url" : "jdbc:postgresql://dolphinscheduler-postgresql:5432/dolphinscheduler",
      "sql" : "select 0 as process_definition_id,3991 as task_instance_id,6 as rule_id,'KA0AXXWVHWW+GZX4BPZXFGFZ0F0OYMUQ+BVYG4+ZIKG=' as unique_code,'duplicate_count.duplicates'AS statistics_name,duplicate_count.duplicates AS statistics_value,'2024-05-07 10:51:44' as data_time,'2024-05-07 10:51:44' as create_time,'2024-05-07 10:51:44' as update_time from duplicate_count"
    }
  }, {
    "type" : "hdfs_file",
    "config" : {
      "path" : "hdfs://mycluster:8020/user/default/data_quality_error_data/0_1061_[null check] filtered data persistence",
      "input_table" : "duplicate_items"
    }
  } ]
}
[WI-1061][TI-3991] - [INFO] 2024-05-07 10:51:45.329 +0800 o.a.d.p.d.a.u.CommonUtils:[136] - Trying to get data quality jar in path
[WI-1061][TI-3991] - [INFO] 2024-05-07 10:51:45.330 +0800 o.a.d.p.d.a.u.CommonUtils:[147] - data quality jar path is empty, will try to auto discover it from build-in rules.
[WI-1061][TI-3991] - [INFO] 2024-05-07 10:51:45.333 +0800 o.a.d.p.d.a.u.CommonUtils:[187] - Try to get data quality jar from path /opt/dolphinscheduler/conf/../libs
[WI-1061][TI-3991] - [INFO] 2024-05-07 10:51:45.337 +0800 o.a.d.p.d.a.u.CommonUtils:[182] - get default data quality jar name: /opt/dolphinscheduler/conf/../libs/dolphinscheduler-data-quality-3.2.1.jar
[WI-1061][TI-3991] - [INFO] 2024-05-07 10:51:45.339 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-1061][TI-3991] - [INFO] 2024-05-07 10:51:45.340 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: null successfully
[WI-1061][TI-3991] - [INFO] 2024-05-07 10:51:45.373 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-1061][TI-3991] - [INFO] 2024-05-07 10:51:45.374 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-1061][TI-3991] - [INFO] 2024-05-07 10:51:45.374 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-0][TI-0] - [INFO] 2024-05-07 10:51:45.381 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.1297709923664123 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-1061][TI-3991] - [INFO] 2024-05-07 10:51:45.405 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-1061][TI-3991] - [INFO] 2024-05-07 10:51:45.406 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-1061][TI-3991] - [INFO] 2024-05-07 10:51:45.406 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export PYSPARK_DRIVER_PYTHON=/bin/python3.11
export PYSPARK_PYTHON=/bin/python3.11
${SPARK_HOME}/bin/spark-submit --master local --driver-cores 1 --driver-memory 512M --num-executors 1 --executor-cores 1 --executor-memory 1G --conf spark.driver.extraJavaOptions="-Divy.cache.dir=/tmp -Divy.home=/tmp" \
--packages org.postgresql:postgresql:42.7.3 /opt/dolphinscheduler/conf/../libs/dolphinscheduler-data-quality-3.2.1.jar "{\"name\":\"$t(uniqueness_check)\",\"env\":{\"type\":\"batch\",\"config\":null},\"readers\":[{\"type\":\"JDBC\",\"config\":{\"database\":\"persistence\",\"password\":\"root\",\"driver\":\"org.postgresql.Driver\",\"user\":\"root\",\"output_table\":\"persistence_filtered_data_persistence\",\"table\":\"filtered_data_persistence\",\"url\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432/persistence?password=root\"} }],\"transformers\":[{\"type\":\"sql\",\"config\":{\"index\":1,\"output_table\":\"duplicate_items\",\"sql\":\"SELECT content FROM persistence_filtered_data_persistence group by content having count(*) > 1\"} },{\"type\":\"sql\",\"config\":{\"index\":2,\"output_table\":\"duplicate_count\",\"sql\":\"SELECT COUNT(*) AS duplicates FROM duplicate_items\"} }],\"writers\":[{\"type\":\"JDBC\",\"config\":{\"database\":\"dolphinscheduler\",\"password\":\"root\",\"driver\":\"org.postgresql.Driver\",\"user\":\"root\",\"table\":\"t_ds_dq_execute_result\",\"url\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432/dolphinscheduler\",\"sql\":\"select 0 as rule_type,'$t(uniqueness_check)' as rule_name,0 as process_definition_id,1061 as process_instance_id,3991 as task_instance_id,duplicate_count.duplicates AS statistics_value,0 AS comparison_value,1 AS comparison_type,0 as check_type,0 as threshold,0 as operator,0 as failure_strategy,'hdfs://mycluster:8020/user/default/data_quality_error_data/0_1061_[null check] filtered data persistence' as error_output_path,'2024-05-07 10:51:44' as create_time,'2024-05-07 10:51:44' as update_time from duplicate_count \"} },{\"type\":\"JDBC\",\"config\":{\"database\":\"dolphinscheduler\",\"password\":\"root\",\"driver\":\"org.postgresql.Driver\",\"user\":\"root\",\"table\":\"t_ds_dq_task_statistics_value\",\"url\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432/dolphinscheduler\",\"sql\":\"select 0 as process_definition_id,3991 as task_instance_id,6 as rule_id,'KA0AXXWVHWW+GZX4BPZXFGFZ0F0OYMUQ+BVYG4+ZIKG=' as unique_code,'duplicate_count.duplicates'AS statistics_name,duplicate_count.duplicates AS statistics_value,'2024-05-07 10:51:44' as data_time,'2024-05-07 10:51:44' as create_time,'2024-05-07 10:51:44' as update_time from duplicate_count\"} },{\"type\":\"hdfs_file\",\"config\":{\"path\":\"hdfs://mycluster:8020/user/default/data_quality_error_data/0_1061_[null check] filtered data persistence\",\"input_table\":\"duplicate_items\"} }]}"
[WI-1061][TI-3991] - [INFO] 2024-05-07 10:51:45.406 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-1061][TI-3991] - [INFO] 2024-05-07 10:51:45.419 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13001194483488/13505298546272_21/1061/3991/1061_3991.sh
[WI-1061][TI-3991] - [INFO] 2024-05-07 10:51:45.434 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 92
[WI-0][TI-3991] - [INFO] 2024-05-07 10:51:45.441 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=3991, success=true)
[WI-0][TI-3991] - [INFO] 2024-05-07 10:51:46.366 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=3991)
[WI-0][TI-0] - [INFO] 2024-05-07 10:51:46.383 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8438438438438438 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:51:46.463 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
[WI-0][TI-0] - [INFO] 2024-05-07 10:51:47.385 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7237237237237237 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:51:48.395 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8583815028901735 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:51:48.466 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	:: loading settings :: url = jar:file:/opt/spark-3.5.1-bin-hadoop3/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml
[WI-0][TI-0] - [INFO] 2024-05-07 10:51:49.398 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8299120234604105 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:51:49.469 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	Ivy Default Cache set to: /tmp
	The jars for the packages stored in: /tmp/jars
	org.postgresql#postgresql added as a dependency
	:: resolving dependencies :: org.apache.spark#spark-submit-parent-0b920a18-38dc-4fb1-9fa9-d11731028ae1;1.0
		confs: [default]
[WI-0][TI-0] - [INFO] 2024-05-07 10:51:50.472 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
		found org.postgresql#postgresql;42.7.3 in central
		found org.checkerframework#checker-qual;3.42.0 in central
[WI-0][TI-0] - [INFO] 2024-05-07 10:51:50.712 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=3992, taskName=[null check] filtered data persistence, firstSubmitTime=1715050310658, startTime=0, taskType=DATA_QUALITY, workflowInstanceHost=172.18.0.14:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13505298546272, processDefineVersion=21, appIds=null, processInstanceId=1094, scheduleTime=0, globalParams=null, executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13001194483488, taskParams={"localParams":[],"resourceList":[],"ruleId":6,"ruleInputParameter":{"check_type":"0","comparison_type":1,"comparison_name":"0","failure_strategy":"0","operator":"0","src_connector_type":1,"src_datasource_id":6,"src_database":"persistence","src_field":"content","src_table":"filtered_data_persistence","threshold":"0"},"sparkParameters":{"deployMode":"local","driverCores":1,"driverMemory":"512M","executorCores":1,"executorMemory":"1G","numExecutors":1,"others":"--conf spark.driver.extraJavaOptions=\"-Divy.cache.dir=/tmp -Divy.home=/tmp\" \\\n--packages org.postgresql:postgresql:42.7.3","yarnQueue":""}}, environmentConfig=export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export PYSPARK_DRIVER_PYTHON=/bin/python3.11
export PYSPARK_PYTHON=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='[null check] filtered data persistence'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13001194483488'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='1094'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240507'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240506'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='3992'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='qualti_test'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13505264408800'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13505298546272'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240507105150'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=null, dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=org.apache.dolphinscheduler.plugin.task.api.DataQualityTaskExecutionContext@17405282, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-1094][TI-3992] - [INFO] 2024-05-07 10:51:50.718 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: [null check] filtered data persistence to wait queue success
[WI-1094][TI-3992] - [INFO] 2024-05-07 10:51:50.718 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-1094][TI-3992] - [INFO] 2024-05-07 10:51:50.721 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-1094][TI-3992] - [INFO] 2024-05-07 10:51:50.721 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-1094][TI-3992] - [INFO] 2024-05-07 10:51:50.721 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-1094][TI-3992] - [INFO] 2024-05-07 10:51:50.721 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1715050310721
[WI-1094][TI-3992] - [INFO] 2024-05-07 10:51:50.721 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 1094_3992
[WI-1094][TI-3992] - [INFO] 2024-05-07 10:51:50.730 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 3992,
  "taskName" : "[null check] filtered data persistence",
  "firstSubmitTime" : 1715050310658,
  "startTime" : 1715050310721,
  "taskType" : "DATA_QUALITY",
  "workflowInstanceHost" : "172.18.0.14:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240507/13505298546272/21/1094/3992.log",
  "processId" : 0,
  "processDefineCode" : 13505298546272,
  "processDefineVersion" : 21,
  "processInstanceId" : 1094,
  "scheduleTime" : 0,
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13001194483488,
  "taskParams" : "{\"localParams\":[],\"resourceList\":[],\"ruleId\":6,\"ruleInputParameter\":{\"check_type\":\"0\",\"comparison_type\":1,\"comparison_name\":\"0\",\"failure_strategy\":\"0\",\"operator\":\"0\",\"src_connector_type\":1,\"src_datasource_id\":6,\"src_database\":\"persistence\",\"src_field\":\"content\",\"src_table\":\"filtered_data_persistence\",\"threshold\":\"0\"},\"sparkParameters\":{\"deployMode\":\"local\",\"driverCores\":1,\"driverMemory\":\"512M\",\"executorCores\":1,\"executorMemory\":\"1G\",\"numExecutors\":1,\"others\":\"--conf spark.driver.extraJavaOptions=\\\"-Divy.cache.dir=/tmp -Divy.home=/tmp\\\" \\\\\\n--packages org.postgresql:postgresql:42.7.3\",\"yarnQueue\":\"\"}}",
  "environmentConfig" : "export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3\nexport JAVA_HOME=/opt/java/openjdk\nexport PYSPARK_DRIVER_PYTHON=/bin/python3.11\nexport PYSPARK_PYTHON=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "[null check] filtered data persistence"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13001194483488"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1094"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240507"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240506"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "3992"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "qualti_test"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13505264408800"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13505298546272"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240507105150"
    }
  },
  "taskAppId" : "1094_3992",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "dryRun" : 0,
  "paramsMap" : { },
  "dataQualityTaskExecutionContext" : {
    "ruleId" : 6,
    "ruleName" : "$t(uniqueness_check)",
    "ruleType" : 0,
    "ruleInputEntryList" : "[{\"id\":1,\"field\":\"src_connector_type\",\"type\":\"select\",\"title\":\"$t(src_connector_type)\",\"data\":\"\",\"options\":\"[{\\\"label\\\":\\\"HIVE\\\",\\\"value\\\":\\\"HIVE\\\"},{\\\"label\\\":\\\"JDBC\\\",\\\"value\\\":\\\"JDBC\\\"}]\",\"placeholder\":\"please select source connector type\",\"optionSourceType\":2,\"dataType\":2,\"inputType\":0,\"isShow\":true,\"canEdit\":true,\"isEmit\":true,\"isValidate\":false,\"valuesMap\":null,\"index\":1,\"createTime\":null,\"updateTime\":null},{\"id\":2,\"field\":\"src_datasource_id\",\"type\":\"select\",\"title\":\"$t(src_datasource_id)\",\"data\":\"\",\"options\":null,\"placeholder\":\"please select source datasource id\",\"optionSourceType\":1,\"dataType\":2,\"inputType\":0,\"isShow\":true,\"canEdit\":true,\"isEmit\":true,\"isValidate\":false,\"valuesMap\":null,\"index\":2,\"createTime\":null,\"updateTime\":null},{\"id\":30,\"field\":\"src_database\",\"type\":\"select\",\"title\":\"$t(src_database)\",\"data\":null,\"options\":null,\"placeholder\":\"Please select source database\",\"optionSourceType\":0,\"dataType\":0,\"inputType\":0,\"isShow\":true,\"canEdit\":true,\"isEmit\":true,\"isValidate\":true,\"valuesMap\":null,\"index\":2,\"createTime\":null,\"updateTime\":null},{\"id\":3,\"field\":\"src_table\",\"type\":\"select\",\"title\":\"$t(src_table)\",\"data\":null,\"options\":null,\"placeholder\":\"Please enter source table name\",\"optionSourceType\":0,\"dataType\":0,\"inputType\":0,\"isShow\":true,\"canEdit\":true,\"isEmit\":true,\"isValidate\":true,\"valuesMap\":null,\"index\":3,\"createTime\":null,\"updateTime\":null},{\"id\":4,\"field\":\"src_filter\",\"type\":\"input\",\"title\":\"$t(src_filter)\",\"data\":null,\"options\":null,\"placeholder\":\"Please enter filter expression\",\"optionSourceType\":0,\"dataType\":3,\"inputType\":0,\"isShow\":true,\"canEdit\":true,\"isEmit\":false,\"isValidate\":false,\"valuesMap\":null,\"index\":4,\"createTime\":null,\"updateTime\":null},{\"id\":5,\"field\":\"src_field\",\"type\":\"select\",\"title\":\"$t(src_field)\",\"data\":null,\"options\":null,\"placeholder\":\"Please enter column, only single column is supported\",\"optionSourceType\":0,\"dataType\":0,\"inputType\":0,\"isShow\":true,\"canEdit\":true,\"isEmit\":false,\"isValidate\":true,\"valuesMap\":null,\"index\":5,\"createTime\":null,\"updateTime\":null},{\"id\":6,\"field\":\"statistics_name\",\"type\":\"input\",\"title\":\"$t(statistics_name)\",\"data\":\"duplicate_count.duplicates\",\"options\":null,\"placeholder\":\"Please enter statistics name, the alias in statistics execute sql\",\"optionSourceType\":0,\"dataType\":0,\"inputType\":1,\"isShow\":false,\"canEdit\":false,\"isEmit\":false,\"isValidate\":true,\"valuesMap\":\"{\\\"statistics_name\\\":\\\"duplicate_count.duplicates\\\"}\",\"index\":6,\"createTime\":null,\"updateTime\":null},{\"id\":7,\"field\":\"check_type\",\"type\":\"select\",\"title\":\"$t(check_type)\",\"data\":\"0\",\"options\":\"[{\\\"label\\\":\\\"Expected - Actual\\\",\\\"value\\\":\\\"0\\\"},{\\\"label\\\":\\\"Actual - Expected\\\",\\\"value\\\":\\\"1\\\"},{\\\"label\\\":\\\"Actual / Expected\\\",\\\"value\\\":\\\"2\\\"},{\\\"label\\\":\\\"(Expected - Actual) / Expected\\\",\\\"value\\\":\\\"3\\\"}]\",\"placeholder\":\"please select check type\",\"optionSourceType\":0,\"dataType\":0,\"inputType\":3,\"isShow\":true,\"canEdit\":true,\"isEmit\":true,\"isValidate\":false,\"valuesMap\":null,\"index\":7,\"createTime\":null,\"updateTime\":null},{\"id\":8,\"field\":\"operator\",\"type\":\"select\",\"title\":\"$t(operator)\",\"data\":\"0\",\"options\":\"[{\\\"label\\\":\\\"=\\\",\\\"value\\\":\\\"0\\\"},{\\\"label\\\":\\\"<\\\",\\\"value\\\":\\\"1\\\"},{\\\"label\\\":\\\"<=\\\",\\\"value\\\":\\\"2\\\"},{\\\"label\\\":\\\">\\\",\\\"value\\\":\\\"3\\\"},{\\\"label\\\":\\\">=\\\",\\\"value\\\":\\\"4\\\"},{\\\"label\\\":\\\"!=\\\",\\\"value\\\":\\\"5\\\"}]\",\"placeholder\":\"please select operator\",\"optionSourceType\":0,\"dataType\":0,\"inputType\":3,\"isShow\":true,\"canEdit\":true,\"isEmit\":false,\"isValidate\":false,\"valuesMap\":null,\"index\":8,\"createTime\":null,\"updateTime\":null},{\"id\":9,\"field\":\"threshold\",\"type\":\"input\",\"title\":\"$t(threshold)\",\"data\":null,\"options\":null,\"placeholder\":\"Please enter threshold, number is needed\",\"optionSourceType\":0,\"dataType\":2,\"inputType\":3,\"isShow\":true,\"canEdit\":true,\"isEmit\":false,\"isValidate\":true,\"valuesMap\":null,\"index\":9,\"createTime\":null,\"updateTime\":null},{\"id\":10,\"field\":\"failure_strategy\",\"type\":\"select\",\"title\":\"$t(failure_strategy)\",\"data\":\"0\",\"options\":\"[{\\\"label\\\":\\\"Alert\\\",\\\"value\\\":\\\"0\\\"},{\\\"label\\\":\\\"Block\\\",\\\"value\\\":\\\"1\\\"}]\",\"placeholder\":\"please select failure strategy\",\"optionSourceType\":0,\"dataType\":0,\"inputType\":3,\"isShow\":true,\"canEdit\":true,\"isEmit\":false,\"isValidate\":false,\"valuesMap\":null,\"index\":10,\"createTime\":null,\"updateTime\":null},{\"id\":17,\"field\":\"comparison_name\",\"type\":\"input\",\"title\":\"$t(comparison_name)\",\"data\":null,\"options\":null,\"placeholder\":\"Please enter comparison name, the alias in comparison execute sql\",\"optionSourceType\":0,\"dataType\":0,\"inputType\":0,\"isShow\":false,\"canEdit\":false,\"isEmit\":false,\"isValidate\":true,\"valuesMap\":\"\",\"index\":11,\"createTime\":null,\"updateTime\":null},{\"id\":19,\"field\":\"comparison_type\",\"type\":\"select\",\"title\":\"$t(comparison_type)\",\"data\":\"\",\"options\":null,\"placeholder\":\"Please enter comparison title\",\"optionSourceType\":3,\"dataType\":0,\"inputType\":2,\"isShow\":true,\"canEdit\":false,\"isEmit\":true,\"isValidate\":false,\"valuesMap\":null,\"index\":12,\"createTime\":null,\"updateTime\":null}]",
    "executeSqlList" : "[{\"id\":6,\"index\":1,\"sql\":\"SELECT ${src_field} FROM ${src_table} group by ${src_field} having count(*) > 1\",\"tableAlias\":\"duplicate_items\",\"type\":0,\"createTime\":\"2021-03-03 11:31:24\",\"updateTime\":\"2021-03-03 11:31:24\",\"errorOutputSql\":true},{\"id\":7,\"index\":1,\"sql\":\"SELECT COUNT(*) AS duplicates FROM duplicate_items\",\"tableAlias\":\"duplicate_count\",\"type\":1,\"createTime\":\"2021-03-03 11:31:24\",\"updateTime\":\"2021-03-03 11:31:24\",\"errorOutputSql\":false}]",
    "comparisonNeedStatisticsValueTable" : false,
    "compareWithFixedValue" : true,
    "hdfsPath" : "hdfs://mycluster:8020/user/default/data_quality_error_data",
    "sourceConnectorType" : "JDBC",
    "sourceType" : 1,
    "sourceConnectionParams" : "{\"user\":\"root\",\"password\":\"root\",\"address\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432\",\"database\":\"persistence\",\"jdbcUrl\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432/persistence\",\"driverClassName\":\"org.postgresql.Driver\",\"validationQuery\":\"select version()\",\"other\":{\"password\":\"root\"}}",
    "targetConnectorType" : null,
    "targetType" : 0,
    "targetConnectionParams" : null,
    "writerConnectorType" : "JDBC",
    "writerType" : 1,
    "writerTable" : "t_ds_dq_execute_result",
    "writerConnectionParams" : "{\"user\":\"root\",\"password\":\"root\",\"address\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432\",\"database\":\"dolphinscheduler\",\"jdbcUrl\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432/dolphinscheduler\"}",
    "statisticsValueConnectorType" : "JDBC",
    "statisticsValueType" : 1,
    "statisticsValueTable" : "t_ds_dq_task_statistics_value",
    "statisticsValueWriterConnectionParams" : "{\"user\":\"root\",\"password\":\"root\",\"address\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432\",\"database\":\"dolphinscheduler\",\"jdbcUrl\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432/dolphinscheduler\"}"
  },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-1094][TI-3992] - [INFO] 2024-05-07 10:51:50.732 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-1094][TI-3992] - [INFO] 2024-05-07 10:51:50.732 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-1094][TI-3992] - [INFO] 2024-05-07 10:51:50.732 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-1094][TI-3992] - [INFO] 2024-05-07 10:51:50.744 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-1094][TI-3992] - [INFO] 2024-05-07 10:51:50.745 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-1094][TI-3992] - [INFO] 2024-05-07 10:51:50.747 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13001194483488/13505298546272_21/1094/3992 check successfully
[WI-1094][TI-3992] - [INFO] 2024-05-07 10:51:50.747 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.dq.DataQualityTaskChannel successfully
[WI-1094][TI-3992] - [INFO] 2024-05-07 10:51:50.749 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-1094][TI-3992] - [INFO] 2024-05-07 10:51:50.750 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-1094][TI-3992] - [INFO] 2024-05-07 10:51:50.751 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: DATA_QUALITY create successfully
[WI-1094][TI-3992] - [INFO] 2024-05-07 10:51:50.752 +0800 o.a.d.p.t.d.DataQualityTask:[89] - Initialize data quality task params {
  "localParams" : [ ],
  "varPool" : null,
  "ruleId" : 6,
  "ruleInputParameter" : {
    "check_type" : "0",
    "comparison_type" : "1",
    "comparison_name" : "0",
    "failure_strategy" : "0",
    "operator" : "0",
    "src_connector_type" : "1",
    "src_datasource_id" : "6",
    "src_database" : "persistence",
    "src_field" : "content",
    "src_table" : "filtered_data_persistence",
    "threshold" : "0"
  },
  "sparkParameters" : {
    "localParams" : null,
    "varPool" : null,
    "mainJar" : null,
    "mainClass" : null,
    "deployMode" : "local",
    "mainArgs" : null,
    "driverCores" : 1,
    "driverMemory" : "512M",
    "numExecutors" : 1,
    "executorCores" : 1,
    "executorMemory" : "1G",
    "appName" : null,
    "yarnQueue" : "",
    "others" : "--conf spark.driver.extraJavaOptions=\"-Divy.cache.dir=/tmp -Divy.home=/tmp\" \\\n--packages org.postgresql:postgresql:42.7.3",
    "programType" : null,
    "resourceList" : [ ]
  }
}
[WI-1094][TI-3992] - [INFO] 2024-05-07 10:51:50.766 +0800 o.a.d.p.t.d.DataQualityTask:[119] - data quality configuration: {
  "name" : "$t(uniqueness_check)",
  "env" : {
    "type" : "batch",
    "config" : null
  },
  "readers" : [ {
    "type" : "JDBC",
    "config" : {
      "database" : "persistence",
      "password" : "root",
      "driver" : "org.postgresql.Driver",
      "user" : "root",
      "output_table" : "persistence_filtered_data_persistence",
      "table" : "filtered_data_persistence",
      "url" : "jdbc:postgresql://dolphinscheduler-postgresql:5432/persistence?password=root"
    }
  } ],
  "transformers" : [ {
    "type" : "sql",
    "config" : {
      "index" : 1,
      "output_table" : "duplicate_items",
      "sql" : "SELECT content FROM persistence_filtered_data_persistence group by content having count(*) > 1"
    }
  }, {
    "type" : "sql",
    "config" : {
      "index" : 2,
      "output_table" : "duplicate_count",
      "sql" : "SELECT COUNT(*) AS duplicates FROM duplicate_items"
    }
  } ],
  "writers" : [ {
    "type" : "JDBC",
    "config" : {
      "database" : "dolphinscheduler",
      "password" : "root",
      "driver" : "org.postgresql.Driver",
      "user" : "root",
      "table" : "t_ds_dq_execute_result",
      "url" : "jdbc:postgresql://dolphinscheduler-postgresql:5432/dolphinscheduler",
      "sql" : "select 0 as rule_type,'$t(uniqueness_check)' as rule_name,0 as process_definition_id,1094 as process_instance_id,3992 as task_instance_id,duplicate_count.duplicates AS statistics_value,0 AS comparison_value,1 AS comparison_type,0 as check_type,0 as threshold,0 as operator,0 as failure_strategy,'hdfs://mycluster:8020/user/default/data_quality_error_data/0_1094_[null check] filtered data persistence' as error_output_path,'2024-05-07 10:51:50' as create_time,'2024-05-07 10:51:50' as update_time from duplicate_count "
    }
  }, {
    "type" : "JDBC",
    "config" : {
      "database" : "dolphinscheduler",
      "password" : "root",
      "driver" : "org.postgresql.Driver",
      "user" : "root",
      "table" : "t_ds_dq_task_statistics_value",
      "url" : "jdbc:postgresql://dolphinscheduler-postgresql:5432/dolphinscheduler",
      "sql" : "select 0 as process_definition_id,3992 as task_instance_id,6 as rule_id,'KA0AXXWVHWW+GZX4BPZXFGFZ0F0OYMUQ+BVYG4+ZIKG=' as unique_code,'duplicate_count.duplicates'AS statistics_name,duplicate_count.duplicates AS statistics_value,'2024-05-07 10:51:50' as data_time,'2024-05-07 10:51:50' as create_time,'2024-05-07 10:51:50' as update_time from duplicate_count"
    }
  }, {
    "type" : "hdfs_file",
    "config" : {
      "path" : "hdfs://mycluster:8020/user/default/data_quality_error_data/0_1094_[null check] filtered data persistence",
      "input_table" : "duplicate_items"
    }
  } ]
}
[WI-1094][TI-3992] - [INFO] 2024-05-07 10:51:50.767 +0800 o.a.d.p.d.a.u.CommonUtils:[136] - Trying to get data quality jar in path
[WI-1094][TI-3992] - [INFO] 2024-05-07 10:51:50.768 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-1094][TI-3992] - [INFO] 2024-05-07 10:51:50.769 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: null successfully
[WI-1094][TI-3992] - [INFO] 2024-05-07 10:51:50.769 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-1094][TI-3992] - [INFO] 2024-05-07 10:51:50.769 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-1094][TI-3992] - [INFO] 2024-05-07 10:51:50.770 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-1094][TI-3992] - [INFO] 2024-05-07 10:51:50.771 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-1094][TI-3992] - [INFO] 2024-05-07 10:51:50.771 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-1094][TI-3992] - [INFO] 2024-05-07 10:51:50.771 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export PYSPARK_DRIVER_PYTHON=/bin/python3.11
export PYSPARK_PYTHON=/bin/python3.11
${SPARK_HOME}/bin/spark-submit --master local --driver-cores 1 --driver-memory 512M --num-executors 1 --executor-cores 1 --executor-memory 1G --conf spark.driver.extraJavaOptions="-Divy.cache.dir=/tmp -Divy.home=/tmp" \
--packages org.postgresql:postgresql:42.7.3 /opt/dolphinscheduler/conf/../libs/dolphinscheduler-data-quality-3.2.1.jar "{\"name\":\"$t(uniqueness_check)\",\"env\":{\"type\":\"batch\",\"config\":null},\"readers\":[{\"type\":\"JDBC\",\"config\":{\"database\":\"persistence\",\"password\":\"root\",\"driver\":\"org.postgresql.Driver\",\"user\":\"root\",\"output_table\":\"persistence_filtered_data_persistence\",\"table\":\"filtered_data_persistence\",\"url\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432/persistence?password=root\"} }],\"transformers\":[{\"type\":\"sql\",\"config\":{\"index\":1,\"output_table\":\"duplicate_items\",\"sql\":\"SELECT content FROM persistence_filtered_data_persistence group by content having count(*) > 1\"} },{\"type\":\"sql\",\"config\":{\"index\":2,\"output_table\":\"duplicate_count\",\"sql\":\"SELECT COUNT(*) AS duplicates FROM duplicate_items\"} }],\"writers\":[{\"type\":\"JDBC\",\"config\":{\"database\":\"dolphinscheduler\",\"password\":\"root\",\"driver\":\"org.postgresql.Driver\",\"user\":\"root\",\"table\":\"t_ds_dq_execute_result\",\"url\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432/dolphinscheduler\",\"sql\":\"select 0 as rule_type,'$t(uniqueness_check)' as rule_name,0 as process_definition_id,1094 as process_instance_id,3992 as task_instance_id,duplicate_count.duplicates AS statistics_value,0 AS comparison_value,1 AS comparison_type,0 as check_type,0 as threshold,0 as operator,0 as failure_strategy,'hdfs://mycluster:8020/user/default/data_quality_error_data/0_1094_[null check] filtered data persistence' as error_output_path,'2024-05-07 10:51:50' as create_time,'2024-05-07 10:51:50' as update_time from duplicate_count \"} },{\"type\":\"JDBC\",\"config\":{\"database\":\"dolphinscheduler\",\"password\":\"root\",\"driver\":\"org.postgresql.Driver\",\"user\":\"root\",\"table\":\"t_ds_dq_task_statistics_value\",\"url\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432/dolphinscheduler\",\"sql\":\"select 0 as process_definition_id,3992 as task_instance_id,6 as rule_id,'KA0AXXWVHWW+GZX4BPZXFGFZ0F0OYMUQ+BVYG4+ZIKG=' as unique_code,'duplicate_count.duplicates'AS statistics_name,duplicate_count.duplicates AS statistics_value,'2024-05-07 10:51:50' as data_time,'2024-05-07 10:51:50' as create_time,'2024-05-07 10:51:50' as update_time from duplicate_count\"} },{\"type\":\"hdfs_file\",\"config\":{\"path\":\"hdfs://mycluster:8020/user/default/data_quality_error_data/0_1094_[null check] filtered data persistence\",\"input_table\":\"duplicate_items\"} }]}"
[WI-1094][TI-3992] - [INFO] 2024-05-07 10:51:50.772 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-1094][TI-3992] - [INFO] 2024-05-07 10:51:50.772 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13001194483488/13505298546272_21/1094/3992/1094_3992.sh
[WI-1094][TI-3992] - [INFO] 2024-05-07 10:51:50.776 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 139
[WI-0][TI-0] - [INFO] 2024-05-07 10:51:51.451 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7597911227154047 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-3992] - [INFO] 2024-05-07 10:51:51.474 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=3992, success=true)
[WI-0][TI-0] - [INFO] 2024-05-07 10:51:51.478 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	downloading https://repo1.maven.org/maven2/org/postgresql/postgresql/42.7.3/postgresql-42.7.3.jar ...
[WI-0][TI-3992] - [INFO] 2024-05-07 10:51:51.519 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=3992)
[WI-0][TI-0] - [INFO] 2024-05-07 10:51:51.778 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
[WI-0][TI-0] - [INFO] 2024-05-07 10:51:52.480 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
		[SUCCESSFUL ] org.postgresql#postgresql;42.7.3!postgresql.jar (1331ms)
	downloading https://repo1.maven.org/maven2/org/checkerframework/checker-qual/3.42.0/checker-qual-3.42.0.jar ...
		[SUCCESSFUL ] org.checkerframework#checker-qual;3.42.0!checker-qual.jar (424ms)
	:: resolution report :: resolve 1976ms :: artifacts dl 1782ms
		:: modules in use:
		org.checkerframework#checker-qual;3.42.0 from central in [default]
		org.postgresql#postgresql;42.7.3 from central in [default]
		---------------------------------------------------------------------
		|                  |            modules            ||   artifacts   |
		|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
		---------------------------------------------------------------------
		|      default     |   2   |   2   |   2   |   0   ||   2   |   2   |
		---------------------------------------------------------------------
	:: retrieving :: org.apache.spark#spark-submit-parent-0b920a18-38dc-4fb1-9fa9-d11731028ae1
		confs: [default]
		2 artifacts copied, 0 already retrieved (1289kB/28ms)
[WI-0][TI-0] - [INFO] 2024-05-07 10:51:52.537 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9410112359550562 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:51:53.489 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:51:53 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[WI-0][TI-0] - [INFO] 2024-05-07 10:51:53.541 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9560117302052786 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:51:54.547 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9122257053291536 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:51:55.543 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:51:54 INFO SparkContext: Running Spark version 3.5.1
	24/05/07 10:51:54 INFO SparkContext: OS info Linux, 6.5.0-28-generic, amd64
	24/05/07 10:51:54 INFO SparkContext: Java version 1.8.0_402
	24/05/07 10:51:54 INFO ResourceUtils: ==============================================================
	24/05/07 10:51:54 INFO ResourceUtils: No custom resources configured for spark.driver.
	24/05/07 10:51:54 INFO ResourceUtils: ==============================================================
	24/05/07 10:51:54 INFO SparkContext: Submitted application: (uniqueness_check)
	24/05/07 10:51:54 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
	24/05/07 10:51:54 INFO ResourceProfile: Limiting resource is cpu
	24/05/07 10:51:54 INFO ResourceProfileManager: Added ResourceProfile id: 0
	24/05/07 10:51:54 INFO SecurityManager: Changing view acls to: default
	24/05/07 10:51:54 INFO SecurityManager: Changing modify acls to: default
	24/05/07 10:51:54 INFO SecurityManager: Changing view acls groups to: 
	24/05/07 10:51:54 INFO SecurityManager: Changing modify acls groups to: 
	24/05/07 10:51:54 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: default; groups with view permissions: EMPTY; users with modify permissions: default; groups with modify permissions: EMPTY
[WI-0][TI-0] - [INFO] 2024-05-07 10:51:55.565 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9136904761904762 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:51:55.873 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	:: loading settings :: url = jar:file:/opt/spark-3.5.1-bin-hadoop3/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml
	Ivy Default Cache set to: /tmp
	The jars for the packages stored in: /tmp/jars
	org.postgresql#postgresql added as a dependency
	:: resolving dependencies :: org.apache.spark#spark-submit-parent-711ee08a-d4f6-4905-86cd-63f5ca27980c;1.0
		confs: [default]
[WI-0][TI-0] - [INFO] 2024-05-07 10:51:56.545 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:51:55 INFO Utils: Successfully started service 'sparkDriver' on port 35027.
	24/05/07 10:51:56 INFO SparkEnv: Registering MapOutputTracker
	24/05/07 10:51:56 INFO SparkEnv: Registering BlockManagerMaster
	24/05/07 10:51:56 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
	24/05/07 10:51:56 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
	24/05/07 10:51:56 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
	24/05/07 10:51:56 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-7e02fb52-f038-462b-905f-f1be352a1d4e
	24/05/07 10:51:56 INFO MemoryStore: MemoryStore started with capacity 93.3 MiB
[WI-0][TI-0] - [INFO] 2024-05-07 10:51:56.581 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8857142857142857 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:51:56.877 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
		found org.postgresql#postgresql;42.7.3 in central
		found org.checkerframework#checker-qual;3.42.0 in central
	:: resolution report :: resolve 413ms :: artifacts dl 29ms
		:: modules in use:
		org.checkerframework#checker-qual;3.42.0 from central in [default]
		org.postgresql#postgresql;42.7.3 from central in [default]
		---------------------------------------------------------------------
		|                  |            modules            ||   artifacts   |
		|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
		---------------------------------------------------------------------
		|      default     |   2   |   0   |   0   |   0   ||   2   |   0   |
		---------------------------------------------------------------------
	:: retrieving :: org.apache.spark#spark-submit-parent-711ee08a-d4f6-4905-86cd-63f5ca27980c
		confs: [default]
		0 artifacts copied, 2 already retrieved (0kB/8ms)
	24/05/07 10:51:56 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[WI-0][TI-0] - [INFO] 2024-05-07 10:51:57.558 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:51:56 INFO SparkEnv: Registering OutputCommitCoordinator
	24/05/07 10:51:56 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
	24/05/07 10:51:57 INFO Utils: Successfully started service 'SparkUI' on port 4040.
	24/05/07 10:51:57 INFO SparkContext: Added JAR file:///tmp/jars/org.postgresql_postgresql-42.7.3.jar at spark://56042a532902:35027/jars/org.postgresql_postgresql-42.7.3.jar with timestamp 1715050314480
	24/05/07 10:51:57 INFO SparkContext: Added JAR file:///tmp/jars/org.checkerframework_checker-qual-3.42.0.jar at spark://56042a532902:35027/jars/org.checkerframework_checker-qual-3.42.0.jar with timestamp 1715050314480
	24/05/07 10:51:57 INFO SparkContext: Added JAR file:/opt/dolphinscheduler/libs/dolphinscheduler-data-quality-3.2.1.jar at spark://56042a532902:35027/jars/dolphinscheduler-data-quality-3.2.1.jar with timestamp 1715050314480
[WI-0][TI-0] - [INFO] 2024-05-07 10:51:57.587 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9266666666666666 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:51:58.559 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:51:57 INFO Executor: Starting executor ID driver on host 56042a532902
	24/05/07 10:51:57 INFO Executor: OS info Linux, 6.5.0-28-generic, amd64
	24/05/07 10:51:57 INFO Executor: Java version 1.8.0_402
	24/05/07 10:51:57 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
	24/05/07 10:51:57 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@33956d1a for default.
	24/05/07 10:51:57 INFO Executor: Fetching spark://56042a532902:35027/jars/org.postgresql_postgresql-42.7.3.jar with timestamp 1715050314480
	24/05/07 10:51:58 INFO TransportClientFactory: Successfully created connection to 56042a532902/172.18.1.1:35027 after 236 ms (0 ms spent in bootstraps)
	24/05/07 10:51:58 INFO Utils: Fetching spark://56042a532902:35027/jars/org.postgresql_postgresql-42.7.3.jar to /tmp/spark-7cb29114-5e3c-4d08-b803-0e8455771639/userFiles-78de8830-93b6-4142-a4a1-ef10ddd0ceea/fetchFileTemp6492543576534540086.tmp
	24/05/07 10:51:58 INFO Executor: Adding file:/tmp/spark-7cb29114-5e3c-4d08-b803-0e8455771639/userFiles-78de8830-93b6-4142-a4a1-ef10ddd0ceea/org.postgresql_postgresql-42.7.3.jar to class loader default
	24/05/07 10:51:58 INFO Executor: Fetching spark://56042a532902:35027/jars/org.checkerframework_checker-qual-3.42.0.jar with timestamp 1715050314480
	24/05/07 10:51:58 INFO Utils: Fetching spark://56042a532902:35027/jars/org.checkerframework_checker-qual-3.42.0.jar to /tmp/spark-7cb29114-5e3c-4d08-b803-0e8455771639/userFiles-78de8830-93b6-4142-a4a1-ef10ddd0ceea/fetchFileTemp5884759776946420626.tmp
[WI-0][TI-0] - [INFO] 2024-05-07 10:51:58.600 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.920863309352518 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:51:58.907 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:51:58 INFO SparkContext: Running Spark version 3.5.1
	24/05/07 10:51:58 INFO SparkContext: OS info Linux, 6.5.0-28-generic, amd64
	24/05/07 10:51:58 INFO SparkContext: Java version 1.8.0_402
	24/05/07 10:51:58 INFO ResourceUtils: ==============================================================
	24/05/07 10:51:58 INFO ResourceUtils: No custom resources configured for spark.driver.
	24/05/07 10:51:58 INFO ResourceUtils: ==============================================================
	24/05/07 10:51:58 INFO SparkContext: Submitted application: (uniqueness_check)
	24/05/07 10:51:58 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
	24/05/07 10:51:58 INFO ResourceProfile: Limiting resource is cpu
	24/05/07 10:51:58 INFO ResourceProfileManager: Added ResourceProfile id: 0
	24/05/07 10:51:58 INFO SecurityManager: Changing view acls to: default
	24/05/07 10:51:58 INFO SecurityManager: Changing modify acls to: default
	24/05/07 10:51:58 INFO SecurityManager: Changing view acls groups to: 
	24/05/07 10:51:58 INFO SecurityManager: Changing modify acls groups to: 
	24/05/07 10:51:58 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: default; groups with view permissions: EMPTY; users with modify permissions: default; groups with modify permissions: EMPTY
[WI-0][TI-0] - [INFO] 2024-05-07 10:51:59.569 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:51:58 INFO Utils: Fetching spark://56042a532902:35027/jars/dolphinscheduler-data-quality-3.2.1.jar to /tmp/spark-7cb29114-5e3c-4d08-b803-0e8455771639/userFiles-78de8830-93b6-4142-a4a1-ef10ddd0ceea/fetchFileTemp1478902421825940652.tmp
	24/05/07 10:51:58 INFO Executor: Adding file:/tmp/spark-7cb29114-5e3c-4d08-b803-0e8455771639/userFiles-78de8830-93b6-4142-a4a1-ef10ddd0ceea/dolphinscheduler-data-quality-3.2.1.jar to class loader default
	24/05/07 10:51:58 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44473.
	24/05/07 10:51:58 INFO NettyBlockTransferService: Server created on 56042a532902:44473
	24/05/07 10:51:58 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
	24/05/07 10:51:58 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 56042a532902, 44473, None)
	24/05/07 10:51:58 INFO BlockManagerMasterEndpoint: Registering block manager 56042a532902:44473 with 93.3 MiB RAM, BlockManagerId(driver, 56042a532902, 44473, None)
	24/05/07 10:51:58 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 56042a532902, 44473, None)
	24/05/07 10:51:58 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 56042a532902, 44473, None)
[WI-0][TI-0] - [INFO] 2024-05-07 10:51:59.614 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9931506849315068 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:51:59.910 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:51:59 INFO Utils: Successfully started service 'sparkDriver' on port 45851.
	24/05/07 10:51:59 INFO SparkEnv: Registering MapOutputTracker
[WI-0][TI-0] - [INFO] 2024-05-07 10:52:00.571 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:51:59 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
	24/05/07 10:51:59 INFO SharedState: Warehouse path is 'file:/tmp/dolphinscheduler/exec/process/default/13001194483488/13505298546272_21/1061/3991/spark-warehouse'.
[WI-0][TI-0] - [INFO] 2024-05-07 10:52:00.631 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9536784741144414 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:52:00.946 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:51:59 INFO SparkEnv: Registering BlockManagerMaster
	24/05/07 10:51:59 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
	24/05/07 10:51:59 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
	24/05/07 10:51:59 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
	24/05/07 10:52:00 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-5ecd01c3-5468-4981-8b7c-dbf98e1b1d2a
	24/05/07 10:52:00 INFO MemoryStore: MemoryStore started with capacity 93.3 MiB
	24/05/07 10:52:00 INFO SparkEnv: Registering OutputCommitCoordinator
	24/05/07 10:52:00 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
	24/05/07 10:52:00 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
	24/05/07 10:52:00 INFO Utils: Successfully started service 'SparkUI' on port 4041.
[WI-0][TI-0] - [INFO] 2024-05-07 10:52:01.634 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9530791788856304 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:52:01.960 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:52:01 INFO SparkContext: Added JAR file:///tmp/jars/org.postgresql_postgresql-42.7.3.jar at spark://56042a532902:45851/jars/org.postgresql_postgresql-42.7.3.jar with timestamp 1715050318167
	24/05/07 10:52:01 INFO SparkContext: Added JAR file:///tmp/jars/org.checkerframework_checker-qual-3.42.0.jar at spark://56042a532902:45851/jars/org.checkerframework_checker-qual-3.42.0.jar with timestamp 1715050318167
	24/05/07 10:52:01 INFO SparkContext: Added JAR file:/opt/dolphinscheduler/libs/dolphinscheduler-data-quality-3.2.1.jar at spark://56042a532902:45851/jars/dolphinscheduler-data-quality-3.2.1.jar with timestamp 1715050318167
	24/05/07 10:52:01 INFO Executor: Starting executor ID driver on host 56042a532902
	24/05/07 10:52:01 INFO Executor: OS info Linux, 6.5.0-28-generic, amd64
	24/05/07 10:52:01 INFO Executor: Java version 1.8.0_402
	24/05/07 10:52:01 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
	24/05/07 10:52:01 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@7fb29ca9 for default.
	24/05/07 10:52:01 INFO Executor: Fetching spark://56042a532902:45851/jars/org.checkerframework_checker-qual-3.42.0.jar with timestamp 1715050318167
	24/05/07 10:52:01 INFO TransportClientFactory: Successfully created connection to 56042a532902/172.18.1.1:45851 after 220 ms (0 ms spent in bootstraps)
[WI-0][TI-0] - [INFO] 2024-05-07 10:52:02.692 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9337016574585636 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:52:02.961 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:52:02 INFO Utils: Fetching spark://56042a532902:45851/jars/org.checkerframework_checker-qual-3.42.0.jar to /tmp/spark-76c6e52f-ce23-40cf-aaf0-b9d7a97be03e/userFiles-ab84ecad-0cc9-4302-81a8-24508be32cda/fetchFileTemp1223624975529645963.tmp
	24/05/07 10:52:02 INFO Executor: Adding file:/tmp/spark-76c6e52f-ce23-40cf-aaf0-b9d7a97be03e/userFiles-ab84ecad-0cc9-4302-81a8-24508be32cda/org.checkerframework_checker-qual-3.42.0.jar to class loader default
	24/05/07 10:52:02 INFO Executor: Fetching spark://56042a532902:45851/jars/dolphinscheduler-data-quality-3.2.1.jar with timestamp 1715050318167
	24/05/07 10:52:02 INFO Utils: Fetching spark://56042a532902:45851/jars/dolphinscheduler-data-quality-3.2.1.jar to /tmp/spark-76c6e52f-ce23-40cf-aaf0-b9d7a97be03e/userFiles-ab84ecad-0cc9-4302-81a8-24508be32cda/fetchFileTemp2124795664325613162.tmp
	24/05/07 10:52:02 INFO Executor: Adding file:/tmp/spark-76c6e52f-ce23-40cf-aaf0-b9d7a97be03e/userFiles-ab84ecad-0cc9-4302-81a8-24508be32cda/dolphinscheduler-data-quality-3.2.1.jar to class loader default
	24/05/07 10:52:02 INFO Executor: Fetching spark://56042a532902:45851/jars/org.postgresql_postgresql-42.7.3.jar with timestamp 1715050318167
	24/05/07 10:52:02 INFO Utils: Fetching spark://56042a532902:45851/jars/org.postgresql_postgresql-42.7.3.jar to /tmp/spark-76c6e52f-ce23-40cf-aaf0-b9d7a97be03e/userFiles-ab84ecad-0cc9-4302-81a8-24508be32cda/fetchFileTemp1031073007342077428.tmp
	24/05/07 10:52:02 INFO Executor: Adding file:/tmp/spark-76c6e52f-ce23-40cf-aaf0-b9d7a97be03e/userFiles-ab84ecad-0cc9-4302-81a8-24508be32cda/org.postgresql_postgresql-42.7.3.jar to class loader default
	24/05/07 10:52:02 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45489.
	24/05/07 10:52:02 INFO NettyBlockTransferService: Server created on 56042a532902:45489
	24/05/07 10:52:02 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
	24/05/07 10:52:02 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 56042a532902, 45489, None)
	24/05/07 10:52:02 INFO BlockManagerMasterEndpoint: Registering block manager 56042a532902:45489 with 93.3 MiB RAM, BlockManagerId(driver, 56042a532902, 45489, None)
	24/05/07 10:52:02 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 56042a532902, 45489, None)
	24/05/07 10:52:02 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 56042a532902, 45489, None)
[WI-0][TI-0] - [INFO] 2024-05-07 10:52:03.695 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9321533923303834 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:52:03.963 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:52:03 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
	24/05/07 10:52:03 INFO SharedState: Warehouse path is 'file:/tmp/dolphinscheduler/exec/process/default/13001194483488/13505298546272_21/1094/3992/spark-warehouse'.
[WI-0][TI-0] - [INFO] 2024-05-07 10:52:04.709 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9276729559748428 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:52:05.713 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9064327485380117 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:52:06.730 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8922413793103449 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:52:07.735 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.886986301369863 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:52:08.761 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9342929292929293 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:52:09.793 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9838919145370758 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:52:10.640 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:52:10 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
[WI-0][TI-0] - [INFO] 2024-05-07 10:52:10.798 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9107142857142857 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:52:11.807 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9680511182108626 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:52:12.935 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9503105590062112 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:52:13.645 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:52:13 INFO CodeGenerator: Code generated in 906.578445 ms
[WI-0][TI-0] - [INFO] 2024-05-07 10:52:13.938 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9400749063670413 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:52:14.677 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:52:14 INFO DAGScheduler: Registering RDD 2 (save at JdbcWriter.java:87) as input to shuffle 0
	24/05/07 10:52:14 INFO DAGScheduler: Got map stage job 0 (save at JdbcWriter.java:87) with 1 output partitions
	24/05/07 10:52:14 INFO DAGScheduler: Final stage: ShuffleMapStage 0 (save at JdbcWriter.java:87)
	24/05/07 10:52:14 INFO DAGScheduler: Parents of final stage: List()
	24/05/07 10:52:14 INFO DAGScheduler: Missing parents: List()
	24/05/07 10:52:14 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[2] at save at JdbcWriter.java:87), which has no missing parents
[WI-0][TI-0] - [INFO] 2024-05-07 10:52:14.958 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9611307420494699 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:52:15.685 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:52:14 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 34.8 KiB, free 93.3 MiB)
	24/05/07 10:52:15 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 16.4 KiB, free 93.2 MiB)
	24/05/07 10:52:15 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 56042a532902:44473 (size: 16.4 KiB, free: 93.3 MiB)
	24/05/07 10:52:15 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1585
	24/05/07 10:52:15 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[2] at save at JdbcWriter.java:87) (first 15 tasks are for partitions Vector(0))
	24/05/07 10:52:15 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
	24/05/07 10:52:15 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (56042a532902, executor driver, partition 0, PROCESS_LOCAL, 7878 bytes) 
	24/05/07 10:52:15 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
[WI-0][TI-0] - [INFO] 2024-05-07 10:52:15.978 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9249999999999999 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:52:16.153 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:52:15 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
[WI-0][TI-0] - [INFO] 2024-05-07 10:52:16.688 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:52:16 INFO CodeGenerator: Code generated in 85.788943 ms
	24/05/07 10:52:16 INFO CodeGenerator: Code generated in 12.536012 ms
	24/05/07 10:52:16 INFO CodeGenerator: Code generated in 5.633002 ms
[WI-0][TI-0] - [INFO] 2024-05-07 10:52:17.017 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9679715302491103 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:52:17.692 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:52:16 INFO CodeGenerator: Code generated in 17.104237 ms
	24/05/07 10:52:16 INFO CodeGenerator: Code generated in 19.397807 ms
	24/05/07 10:52:17 INFO JDBCRDD: closed connection
	24/05/07 10:52:17 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 2491 bytes result sent to driver
	24/05/07 10:52:17 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 2398 ms on 56042a532902 (executor driver) (1/1)
	24/05/07 10:52:17 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
[WI-0][TI-0] - [INFO] 2024-05-07 10:52:18.021 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9136212624584719 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:52:18.696 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:52:17 INFO DAGScheduler: ShuffleMapStage 0 (save at JdbcWriter.java:87) finished in 3.109 s
	24/05/07 10:52:17 INFO DAGScheduler: looking for newly runnable stages
	24/05/07 10:52:17 INFO DAGScheduler: running: Set()
	24/05/07 10:52:17 INFO DAGScheduler: waiting: Set()
	24/05/07 10:52:17 INFO DAGScheduler: failed: Set()
	24/05/07 10:52:18 INFO ShufflePartitionsUtil: For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
	24/05/07 10:52:18 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
	24/05/07 10:52:18 INFO CodeGenerator: Code generated in 24.532835 ms
[WI-0][TI-0] - [INFO] 2024-05-07 10:52:19.041 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9581993569131833 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:52:19.174 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:52:18 INFO CodeGenerator: Code generated in 1846.36218 ms
[WI-0][TI-0] - [INFO] 2024-05-07 10:52:19.724 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:52:18 INFO DAGScheduler: Registering RDD 5 (save at JdbcWriter.java:87) as input to shuffle 1
	24/05/07 10:52:18 INFO DAGScheduler: Got map stage job 1 (save at JdbcWriter.java:87) with 1 output partitions
	24/05/07 10:52:18 INFO DAGScheduler: Final stage: ShuffleMapStage 2 (save at JdbcWriter.java:87)
	24/05/07 10:52:18 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
	24/05/07 10:52:18 INFO DAGScheduler: Missing parents: List()
	24/05/07 10:52:18 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[5] at save at JdbcWriter.java:87), which has no missing parents
	24/05/07 10:52:18 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 40.5 KiB, free 93.2 MiB)
	24/05/07 10:52:18 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 19.1 KiB, free 93.2 MiB)
	24/05/07 10:52:18 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 56042a532902:44473 (size: 19.1 KiB, free: 93.3 MiB)
	24/05/07 10:52:18 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 56042a532902:44473 in memory (size: 16.4 KiB, free: 93.3 MiB)
	24/05/07 10:52:18 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1585
	24/05/07 10:52:18 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[5] at save at JdbcWriter.java:87) (first 15 tasks are for partitions Vector(0))
	24/05/07 10:52:18 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
	24/05/07 10:52:18 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 1) (56042a532902, executor driver, partition 0, NODE_LOCAL, 8032 bytes) 
	24/05/07 10:52:18 INFO Executor: Running task 0.0 in stage 2.0 (TID 1)
	24/05/07 10:52:19 INFO ShuffleBlockFetcherIterator: Getting 1 (2.9 KiB) non-empty blocks including 1 (2.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
	24/05/07 10:52:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 66 ms
	24/05/07 10:52:19 INFO CodeGenerator: Code generated in 221.407799 ms
	24/05/07 10:52:19 INFO Executor: Finished task 0.0 in stage 2.0 (TID 1). 5420 bytes result sent to driver
	24/05/07 10:52:19 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 1) in 648 ms on 56042a532902 (executor driver) (1/1)
	24/05/07 10:52:19 INFO DAGScheduler: ShuffleMapStage 2 (save at JdbcWriter.java:87) finished in 0.693 s
	24/05/07 10:52:19 INFO DAGScheduler: looking for newly runnable stages
	24/05/07 10:52:19 INFO DAGScheduler: running: Set()
	24/05/07 10:52:19 INFO DAGScheduler: waiting: Set()
	24/05/07 10:52:19 INFO DAGScheduler: failed: Set()
	24/05/07 10:52:19 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
	24/05/07 10:52:19 INFO CodeGenerator: Code generated in 24.418577 ms
[WI-0][TI-0] - [INFO] 2024-05-07 10:52:20.053 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.96875 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:52:20.176 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:52:19 INFO DAGScheduler: Registering RDD 2 (save at JdbcWriter.java:87) as input to shuffle 0
	24/05/07 10:52:19 INFO DAGScheduler: Got map stage job 0 (save at JdbcWriter.java:87) with 1 output partitions
	24/05/07 10:52:19 INFO DAGScheduler: Final stage: ShuffleMapStage 0 (save at JdbcWriter.java:87)
	24/05/07 10:52:19 INFO DAGScheduler: Parents of final stage: List()
	24/05/07 10:52:19 INFO DAGScheduler: Missing parents: List()
	24/05/07 10:52:19 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[2] at save at JdbcWriter.java:87), which has no missing parents
[WI-0][TI-0] - [INFO] 2024-05-07 10:52:20.734 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:52:19 INFO SparkContext: Starting job: save at JdbcWriter.java:87
	24/05/07 10:52:19 INFO DAGScheduler: Got job 2 (save at JdbcWriter.java:87) with 1 output partitions
	24/05/07 10:52:19 INFO DAGScheduler: Final stage: ResultStage 5 (save at JdbcWriter.java:87)
	24/05/07 10:52:19 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
	24/05/07 10:52:20 INFO DAGScheduler: Missing parents: List()
	24/05/07 10:52:20 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[10] at save at JdbcWriter.java:87), which has no missing parents
	24/05/07 10:52:20 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 51.4 KiB, free 93.2 MiB)
	24/05/07 10:52:20 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 23.1 KiB, free 93.2 MiB)
	24/05/07 10:52:20 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 56042a532902:44473 (size: 23.1 KiB, free: 93.3 MiB)
	24/05/07 10:52:20 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1585
	24/05/07 10:52:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[10] at save at JdbcWriter.java:87) (first 15 tasks are for partitions Vector(0))
	24/05/07 10:52:20 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
	24/05/07 10:52:20 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 2) (56042a532902, executor driver, partition 0, NODE_LOCAL, 8043 bytes) 
	24/05/07 10:52:20 INFO Executor: Running task 0.0 in stage 5.0 (TID 2)
[WI-0][TI-0] - [INFO] 2024-05-07 10:52:21.062 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9779874213836478 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:52:21.180 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:52:20 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 34.8 KiB, free 93.3 MiB)
	24/05/07 10:52:20 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 16.4 KiB, free 93.3 MiB)
	24/05/07 10:52:20 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 56042a532902:45489 (size: 16.4 KiB, free: 93.3 MiB)
	24/05/07 10:52:20 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1585
	24/05/07 10:52:20 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[2] at save at JdbcWriter.java:87) (first 15 tasks are for partitions Vector(0))
	24/05/07 10:52:20 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
	24/05/07 10:52:20 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (56042a532902, executor driver, partition 0, PROCESS_LOCAL, 7878 bytes) 
	24/05/07 10:52:21 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
[WI-0][TI-0] - [INFO] 2024-05-07 10:52:21.735 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:52:21 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
	24/05/07 10:52:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
	24/05/07 10:52:21 INFO CodeGenerator: Code generated in 16.127584 ms
[WI-0][TI-0] - [INFO] 2024-05-07 10:52:22.064 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9685714285714286 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:52:22.754 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:52:22 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 56042a532902:44473 in memory (size: 19.1 KiB, free: 93.3 MiB)
[WI-0][TI-0] - [INFO] 2024-05-07 10:52:23.108 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9371584699453552 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:52:23.191 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:52:22 INFO CodeGenerator: Code generated in 273.469831 ms
	24/05/07 10:52:22 INFO CodeGenerator: Code generated in 39.693745 ms
	24/05/07 10:52:22 INFO CodeGenerator: Code generated in 41.51652 ms
	24/05/07 10:52:22 INFO CodeGenerator: Code generated in 9.048699 ms
	24/05/07 10:52:22 INFO CodeGenerator: Code generated in 8.033383 ms
	24/05/07 10:52:22 INFO JDBCRDD: closed connection
[WI-0][TI-0] - [INFO] 2024-05-07 10:52:23.201 +0800 o.a.d.s.w.r.o.TaskInstanceKillOperationFunction:[55] - Receive TaskInstanceKillRequest: TaskInstanceKillRequest(taskInstanceId=3991)
[WI-0][TI-3991] - [INFO] 2024-05-07 10:52:23.352 +0800 o.a.d.s.w.r.o.TaskInstanceKillOperationFunction:[134] - process id:92, cmd:sudo -u default kill -9 92 96 99 102 120 121 122 123 124 125 126 127 128 129 130 131 132 133 184 186 187 188 189 190 191 192 193 194 195 196 197 198 202 203 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 230 231 232 233 234 235 252 290 298 300 301 302 303 304 305 306 307 308 310 311 312 313 314
[WI-0][TI-3991] - [ERROR] 2024-05-07 10:52:23.494 +0800 o.a.d.s.w.r.o.TaskInstanceKillOperationFunction:[139] - kill task error
org.apache.dolphinscheduler.common.shell.AbstractShell$ExitCodeException: kill: (92): Operation not permitted
kill: (132): No such process
kill: (186): No such process
kill: (190): No such process
kill: (193): No such process
kill: (198): No such process
kill: (202): No such process
kill: (212): No such process
kill: (213): No such process
kill: (214): No such process
kill: (219): No such process
kill: (223): No such process
kill: (232): No such process
kill: (233): No such process
kill: (234): No such process
kill: (252): No such process
kill: (290): No such process
kill: (303): No such process
kill: (311): No such process
kill: (312): No such process
kill: (314): No such process

	at org.apache.dolphinscheduler.common.shell.AbstractShell.runCommand(AbstractShell.java:205)
	at org.apache.dolphinscheduler.common.shell.AbstractShell.run(AbstractShell.java:118)
	at org.apache.dolphinscheduler.common.shell.ShellExecutor.execute(ShellExecutor.java:125)
	at org.apache.dolphinscheduler.common.shell.ShellExecutor.execCommand(ShellExecutor.java:103)
	at org.apache.dolphinscheduler.common.shell.ShellExecutor.execCommand(ShellExecutor.java:86)
	at org.apache.dolphinscheduler.common.utils.OSUtils.exeShell(OSUtils.java:345)
	at org.apache.dolphinscheduler.common.utils.OSUtils.exeCmd(OSUtils.java:334)
	at org.apache.dolphinscheduler.server.worker.runner.operator.TaskInstanceKillOperationFunction.killProcess(TaskInstanceKillOperationFunction.java:135)
	at org.apache.dolphinscheduler.server.worker.runner.operator.TaskInstanceKillOperationFunction.doKill(TaskInstanceKillOperationFunction.java:96)
	at org.apache.dolphinscheduler.server.worker.runner.operator.TaskInstanceKillOperationFunction.operate(TaskInstanceKillOperationFunction.java:69)
	at org.apache.dolphinscheduler.server.worker.rpc.TaskInstanceOperatorImpl.killTask(TaskInstanceOperatorImpl.java:49)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.dolphinscheduler.extract.base.server.ServerMethodInvokerImpl.invoke(ServerMethodInvokerImpl.java:41)
	at org.apache.dolphinscheduler.extract.base.server.JdkDynamicServerHandler.lambda$processReceived$0(JdkDynamicServerHandler.java:108)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
[WI-0][TI-3991] - [INFO] 2024-05-07 10:52:23.494 +0800 o.a.d.p.t.a.u.ProcessUtils:[182] - Get appIds from worker 172.18.1.1:1234, taskLogPath: /opt/dolphinscheduler/logs/20240507/13505298546272/21/1061/3991.log
[WI-0][TI-3991] - [INFO] 2024-05-07 10:52:23.496 +0800 o.a.d.p.t.a.u.LogUtils:[79] - Start finding appId in /opt/dolphinscheduler/logs/20240507/13505298546272/21/1061/3991.log, fetch way: log 
[WI-0][TI-3991] - [INFO] 2024-05-07 10:52:23.512 +0800 o.a.d.p.t.a.u.ProcessUtils:[188] - The appId is empty
[WI-0][TI-3991] - [INFO] 2024-05-07 10:52:23.513 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[220] - Begin to kill process process, pid is : 92
[WI-0][TI-3991] - [INFO] 2024-05-07 10:52:23.599 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[225] - Success kill task: 1061_3991, pid: 92
[WI-0][TI-3991] - [INFO] 2024-05-07 10:52:23.600 +0800 o.a.d.s.w.r.o.TaskInstanceKillOperationFunction:[119] - kill task by cancelApplication, taskInstanceId: 3991
[WI-1061][TI-3991] - [INFO] 2024-05-07 10:52:23.758 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has killed. execute path:/tmp/dolphinscheduler/exec/process/default/13001194483488/13505298546272_21/1061/3991, processId:92 ,exitStatusCode:137 ,processWaitForStatus:true ,processExitValue:137
[WI-1061][TI-3991] - [INFO] 2024-05-07 10:52:23.762 +0800 o.a.d.p.t.a.u.LogUtils:[79] - Start finding appId in /opt/dolphinscheduler/logs/20240507/13505298546272/21/1061/3991.log, fetch way: log 
[WI-1061][TI-3991] - [INFO] 2024-05-07 10:52:23.786 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-1061][TI-3991] - [INFO] 2024-05-07 10:52:23.791 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-1061][TI-3991] - [INFO] 2024-05-07 10:52:23.791 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-1061][TI-3991] - [INFO] 2024-05-07 10:52:23.794 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-1061][TI-3991] - [INFO] 2024-05-07 10:52:23.880 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: KILL to master : 172.18.1.1:1234
[WI-1061][TI-3991] - [INFO] 2024-05-07 10:52:23.882 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-1061][TI-3991] - [INFO] 2024-05-07 10:52:23.882 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13001194483488/13505298546272_21/1061/3991
[WI-1061][TI-3991] - [INFO] 2024-05-07 10:52:24.113 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13001194483488/13505298546272_21/1061/3991
[WI-1061][TI-3991] - [INFO] 2024-05-07 10:52:24.118 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-0] - [INFO] 2024-05-07 10:52:24.125 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.0546105175811638 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:52:24.209 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:52:23 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 2534 bytes result sent to driver
	24/05/07 10:52:23 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 2368 ms on 56042a532902 (executor driver) (1/1)
	24/05/07 10:52:23 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
	24/05/07 10:52:23 INFO DAGScheduler: ShuffleMapStage 0 (save at JdbcWriter.java:87) finished in 3.452 s
	24/05/07 10:52:23 INFO DAGScheduler: looking for newly runnable stages
	24/05/07 10:52:23 INFO DAGScheduler: running: Set()
	24/05/07 10:52:23 INFO DAGScheduler: waiting: Set()
	24/05/07 10:52:23 INFO DAGScheduler: failed: Set()
	24/05/07 10:52:23 INFO ShufflePartitionsUtil: For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
	24/05/07 10:52:24 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[WI-0][TI-3991] - [INFO] 2024-05-07 10:52:24.661 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=3991, success=true)
[WI-0][TI-0] - [INFO] 2024-05-07 10:52:25.127 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.926982117423643 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:52:25.211 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:52:24 INFO CodeGenerator: Code generated in 84.560187 ms
	24/05/07 10:52:24 INFO DAGScheduler: Registering RDD 5 (save at JdbcWriter.java:87) as input to shuffle 1
	24/05/07 10:52:24 INFO DAGScheduler: Got map stage job 1 (save at JdbcWriter.java:87) with 1 output partitions
	24/05/07 10:52:24 INFO DAGScheduler: Final stage: ShuffleMapStage 2 (save at JdbcWriter.java:87)
	24/05/07 10:52:24 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
	24/05/07 10:52:24 INFO DAGScheduler: Missing parents: List()
	24/05/07 10:52:24 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[5] at save at JdbcWriter.java:87), which has no missing parents
	24/05/07 10:52:24 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 40.5 KiB, free 93.2 MiB)
	24/05/07 10:52:24 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 19.1 KiB, free 93.2 MiB)
	24/05/07 10:52:24 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 56042a532902:45489 (size: 19.1 KiB, free: 93.3 MiB)
	24/05/07 10:52:24 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1585
	24/05/07 10:52:24 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[5] at save at JdbcWriter.java:87) (first 15 tasks are for partitions Vector(0))
	24/05/07 10:52:24 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
	24/05/07 10:52:24 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 1) (56042a532902, executor driver, partition 0, NODE_LOCAL, 8032 bytes) 
	24/05/07 10:52:24 INFO Executor: Running task 0.0 in stage 2.0 (TID 1)
	24/05/07 10:52:24 INFO ShuffleBlockFetcherIterator: Getting 1 (2.9 KiB) non-empty blocks including 1 (2.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
	24/05/07 10:52:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 23 ms
	24/05/07 10:52:24 INFO CodeGenerator: Code generated in 19.70079 ms
	24/05/07 10:52:24 INFO Executor: Finished task 0.0 in stage 2.0 (TID 1). 5420 bytes result sent to driver
	24/05/07 10:52:24 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 1) in 192 ms on 56042a532902 (executor driver) (1/1)
	24/05/07 10:52:24 INFO DAGScheduler: ShuffleMapStage 2 (save at JdbcWriter.java:87) finished in 0.304 s
	24/05/07 10:52:24 INFO DAGScheduler: looking for newly runnable stages
	24/05/07 10:52:24 INFO DAGScheduler: running: Set()
	24/05/07 10:52:24 INFO DAGScheduler: waiting: Set()
	24/05/07 10:52:24 INFO DAGScheduler: failed: Set()
	24/05/07 10:52:24 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
	24/05/07 10:52:25 INFO CodeGenerator: Code generated in 70.391183 ms
[WI-0][TI-0] - [INFO] 2024-05-07 10:52:26.134 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8668555240793202 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:52:26.214 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:52:25 INFO SparkContext: Starting job: save at JdbcWriter.java:87
	24/05/07 10:52:25 INFO DAGScheduler: Got job 2 (save at JdbcWriter.java:87) with 1 output partitions
	24/05/07 10:52:25 INFO DAGScheduler: Final stage: ResultStage 5 (save at JdbcWriter.java:87)
	24/05/07 10:52:25 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
	24/05/07 10:52:25 INFO DAGScheduler: Missing parents: List()
	24/05/07 10:52:25 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[10] at save at JdbcWriter.java:87), which has no missing parents
	24/05/07 10:52:25 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 56042a532902:45489 in memory (size: 19.1 KiB, free: 93.3 MiB)
	24/05/07 10:52:25 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 56042a532902:45489 in memory (size: 16.4 KiB, free: 93.3 MiB)
	24/05/07 10:52:25 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 51.4 KiB, free 93.2 MiB)
	24/05/07 10:52:25 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 23.0 KiB, free 93.2 MiB)
	24/05/07 10:52:25 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 56042a532902:45489 (size: 23.0 KiB, free: 93.3 MiB)
	24/05/07 10:52:25 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1585
	24/05/07 10:52:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[10] at save at JdbcWriter.java:87) (first 15 tasks are for partitions Vector(0))
	24/05/07 10:52:25 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
	24/05/07 10:52:25 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 2) (56042a532902, executor driver, partition 0, NODE_LOCAL, 8043 bytes) 
	24/05/07 10:52:25 INFO Executor: Running task 0.0 in stage 5.0 (TID 2)
[WI-0][TI-0] - [INFO] 2024-05-07 10:52:27.169 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8332465955416776 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:52:27.229 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:52:26 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
	24/05/07 10:52:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
	24/05/07 10:52:26 INFO CodeGenerator: Code generated in 21.844961 ms
[WI-0][TI-0] - [INFO] 2024-05-07 10:52:28.230 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9171195652173914 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:52:29.232 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:52:28 INFO CodeGenerator: Code generated in 24.126259 ms
	24/05/07 10:52:28 INFO Executor: Finished task 0.0 in stage 5.0 (TID 2). 6711 bytes result sent to driver
	24/05/07 10:52:28 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 2) in 3173 ms on 56042a532902 (executor driver) (1/1)
	24/05/07 10:52:28 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
	24/05/07 10:52:28 INFO DAGScheduler: ResultStage 5 (save at JdbcWriter.java:87) finished in 3.449 s
	24/05/07 10:52:28 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
	24/05/07 10:52:28 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
	24/05/07 10:52:28 INFO DAGScheduler: Job 2 finished: save at JdbcWriter.java:87, took 3.563375 s
[WI-0][TI-0] - [INFO] 2024-05-07 10:52:29.253 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9135135135135135 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:52:30.245 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:52:30 INFO DAGScheduler: Registering RDD 13 (save at JdbcWriter.java:87) as input to shuffle 2
	24/05/07 10:52:30 INFO DAGScheduler: Got map stage job 3 (save at JdbcWriter.java:87) with 1 output partitions
	24/05/07 10:52:30 INFO DAGScheduler: Final stage: ShuffleMapStage 6 (save at JdbcWriter.java:87)
	24/05/07 10:52:30 INFO DAGScheduler: Parents of final stage: List()
	24/05/07 10:52:30 INFO DAGScheduler: Missing parents: List()
	24/05/07 10:52:30 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[13] at save at JdbcWriter.java:87), which has no missing parents
	24/05/07 10:52:30 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 34.8 KiB, free 93.2 MiB)
	24/05/07 10:52:30 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 16.5 KiB, free 93.2 MiB)
[WI-0][TI-0] - [INFO] 2024-05-07 10:52:30.275 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9810725552050473 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:52:31.247 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:52:30 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 56042a532902:45489 (size: 16.5 KiB, free: 93.3 MiB)
	24/05/07 10:52:30 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1585
	24/05/07 10:52:30 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[13] at save at JdbcWriter.java:87) (first 15 tasks are for partitions Vector(0))
	24/05/07 10:52:30 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0
	24/05/07 10:52:30 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 3) (56042a532902, executor driver, partition 0, PROCESS_LOCAL, 7878 bytes) 
	24/05/07 10:52:30 INFO Executor: Running task 0.0 in stage 6.0 (TID 3)
	24/05/07 10:52:30 INFO JDBCRDD: closed connection
	24/05/07 10:52:30 INFO Executor: Finished task 0.0 in stage 6.0 (TID 3). 2491 bytes result sent to driver
	24/05/07 10:52:30 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 3) in 384 ms on 56042a532902 (executor driver) (1/1)
	24/05/07 10:52:30 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
	24/05/07 10:52:30 INFO DAGScheduler: ShuffleMapStage 6 (save at JdbcWriter.java:87) finished in 0.483 s
	24/05/07 10:52:30 INFO DAGScheduler: looking for newly runnable stages
	24/05/07 10:52:30 INFO DAGScheduler: running: Set()
	24/05/07 10:52:30 INFO DAGScheduler: waiting: Set()
	24/05/07 10:52:30 INFO DAGScheduler: failed: Set()
	24/05/07 10:52:30 INFO ShufflePartitionsUtil: For shuffle(2), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
	24/05/07 10:52:30 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
	24/05/07 10:52:30 INFO DAGScheduler: Registering RDD 16 (save at JdbcWriter.java:87) as input to shuffle 3
	24/05/07 10:52:30 INFO DAGScheduler: Got map stage job 4 (save at JdbcWriter.java:87) with 1 output partitions
	24/05/07 10:52:30 INFO DAGScheduler: Final stage: ShuffleMapStage 8 (save at JdbcWriter.java:87)
	24/05/07 10:52:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
	24/05/07 10:52:30 INFO DAGScheduler: Missing parents: List()
	24/05/07 10:52:30 INFO DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[16] at save at JdbcWriter.java:87), which has no missing parents
	24/05/07 10:52:30 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 40.6 KiB, free 93.1 MiB)
	24/05/07 10:52:31 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 19.1 KiB, free 93.1 MiB)
	24/05/07 10:52:31 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 56042a532902:45489 (size: 19.1 KiB, free: 93.2 MiB)
	24/05/07 10:52:31 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1585
	24/05/07 10:52:31 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[16] at save at JdbcWriter.java:87) (first 15 tasks are for partitions Vector(0))
	24/05/07 10:52:31 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0
	24/05/07 10:52:31 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 4) (56042a532902, executor driver, partition 0, NODE_LOCAL, 8032 bytes) 
	24/05/07 10:52:31 INFO Executor: Running task 0.0 in stage 8.0 (TID 4)
	24/05/07 10:52:31 INFO ShuffleBlockFetcherIterator: Getting 1 (2.9 KiB) non-empty blocks including 1 (2.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
	24/05/07 10:52:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
	24/05/07 10:52:31 INFO Executor: Finished task 0.0 in stage 8.0 (TID 4). 5420 bytes result sent to driver
	24/05/07 10:52:31 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 4) in 72 ms on 56042a532902 (executor driver) (1/1)
	24/05/07 10:52:31 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
	24/05/07 10:52:31 INFO DAGScheduler: ShuffleMapStage 8 (save at JdbcWriter.java:87) finished in 0.133 s
	24/05/07 10:52:31 INFO DAGScheduler: looking for newly runnable stages
	24/05/07 10:52:31 INFO DAGScheduler: running: Set()
	24/05/07 10:52:31 INFO DAGScheduler: waiting: Set()
	24/05/07 10:52:31 INFO DAGScheduler: failed: Set()
	24/05/07 10:52:31 INFO CodeGenerator: Code generated in 10.906953 ms
	24/05/07 10:52:31 INFO SparkContext: Starting job: save at JdbcWriter.java:87
[WI-0][TI-0] - [INFO] 2024-05-07 10:52:31.278 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8966666666666666 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:52:32.257 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:52:31 INFO DAGScheduler: Got job 5 (save at JdbcWriter.java:87) with 1 output partitions
	24/05/07 10:52:31 INFO DAGScheduler: Final stage: ResultStage 11 (save at JdbcWriter.java:87)
	24/05/07 10:52:31 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)
	24/05/07 10:52:31 INFO DAGScheduler: Missing parents: List()
	24/05/07 10:52:31 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[21] at save at JdbcWriter.java:87), which has no missing parents
	24/05/07 10:52:31 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 49.2 KiB, free 93.1 MiB)
	24/05/07 10:52:31 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 22.7 KiB, free 93.0 MiB)
	24/05/07 10:52:31 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 56042a532902:45489 (size: 22.7 KiB, free: 93.2 MiB)
	24/05/07 10:52:31 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1585
	24/05/07 10:52:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[21] at save at JdbcWriter.java:87) (first 15 tasks are for partitions Vector(0))
	24/05/07 10:52:31 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks resource profile 0
	24/05/07 10:52:31 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 5) (56042a532902, executor driver, partition 0, NODE_LOCAL, 8043 bytes) 
	24/05/07 10:52:31 INFO Executor: Running task 0.0 in stage 11.0 (TID 5)
	24/05/07 10:52:31 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
	24/05/07 10:52:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
	24/05/07 10:52:31 INFO CodeGenerator: Code generated in 52.561678 ms
	24/05/07 10:52:31 INFO CodeGenerator: Code generated in 42.140351 ms
	24/05/07 10:52:31 INFO Executor: Finished task 0.0 in stage 11.0 (TID 5). 6625 bytes result sent to driver
	24/05/07 10:52:31 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 5) in 324 ms on 56042a532902 (executor driver) (1/1)
	24/05/07 10:52:31 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
	24/05/07 10:52:31 INFO DAGScheduler: ResultStage 11 (save at JdbcWriter.java:87) finished in 0.398 s
	24/05/07 10:52:31 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
	24/05/07 10:52:31 INFO TaskSchedulerImpl: Killing all running tasks in stage 11: Stage finished
	24/05/07 10:52:31 INFO DAGScheduler: Job 5 finished: save at JdbcWriter.java:87, took 0.503720 s
[WI-0][TI-0] - [INFO] 2024-05-07 10:52:32.303 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8684040032052921 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:52:33.266 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:52:32 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 56042a532902:45489 in memory (size: 16.5 KiB, free: 93.2 MiB)
	24/05/07 10:52:33 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 56042a532902:45489 in memory (size: 22.7 KiB, free: 93.3 MiB)
	24/05/07 10:52:33 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 56042a532902:45489 in memory (size: 23.0 KiB, free: 93.3 MiB)
	24/05/07 10:52:33 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 56042a532902:45489 in memory (size: 19.1 KiB, free: 93.3 MiB)
[WI-0][TI-0] - [INFO] 2024-05-07 10:52:33.418 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9208722480490291 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:52:35.459 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9676549865229112 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:52:36.278 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:52:35 INFO DAGScheduler: Registering RDD 24 (csv at BaseFileWriter.java:114) as input to shuffle 4
	24/05/07 10:52:35 INFO DAGScheduler: Got map stage job 6 (csv at BaseFileWriter.java:114) with 1 output partitions
	24/05/07 10:52:35 INFO DAGScheduler: Final stage: ShuffleMapStage 12 (csv at BaseFileWriter.java:114)
	24/05/07 10:52:35 INFO DAGScheduler: Parents of final stage: List()
	24/05/07 10:52:35 INFO DAGScheduler: Missing parents: List()
	24/05/07 10:52:35 INFO DAGScheduler: Submitting ShuffleMapStage 12 (MapPartitionsRDD[24] at csv at BaseFileWriter.java:114), which has no missing parents
	24/05/07 10:52:36 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 34.8 KiB, free 93.3 MiB)
	24/05/07 10:52:36 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 16.5 KiB, free 93.2 MiB)
	24/05/07 10:52:36 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 56042a532902:45489 (size: 16.5 KiB, free: 93.3 MiB)
	24/05/07 10:52:36 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1585
	24/05/07 10:52:36 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[24] at csv at BaseFileWriter.java:114) (first 15 tasks are for partitions Vector(0))
	24/05/07 10:52:36 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks resource profile 0
	24/05/07 10:52:36 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 6) (56042a532902, executor driver, partition 0, PROCESS_LOCAL, 7878 bytes) 
	24/05/07 10:52:36 INFO Executor: Running task 0.0 in stage 12.0 (TID 6)
	24/05/07 10:52:36 INFO JDBCRDD: closed connection
	24/05/07 10:52:36 INFO Executor: Finished task 0.0 in stage 12.0 (TID 6). 2448 bytes result sent to driver
	24/05/07 10:52:36 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 6) in 142 ms on 56042a532902 (executor driver) (1/1)
	24/05/07 10:52:36 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
	24/05/07 10:52:36 INFO DAGScheduler: ShuffleMapStage 12 (csv at BaseFileWriter.java:114) finished in 0.205 s
	24/05/07 10:52:36 INFO DAGScheduler: looking for newly runnable stages
	24/05/07 10:52:36 INFO DAGScheduler: running: Set()
	24/05/07 10:52:36 INFO DAGScheduler: waiting: Set()
	24/05/07 10:52:36 INFO DAGScheduler: failed: Set()
	24/05/07 10:52:36 INFO ShufflePartitionsUtil: For shuffle(4), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[WI-0][TI-0] - [INFO] 2024-05-07 10:52:36.537 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9472140762463344 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:52:37.281 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:52:36 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
	24/05/07 10:52:36 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
	24/05/07 10:52:36 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
	Exception in thread "main" org.apache.hadoop.security.AccessControlException: Permission denied: user=default, access=WRITE, inode="/":hadoop:supergroup:drwxr-xr-x
		at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:506)
		at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:346)
		at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermissionWithContext(FSPermissionChecker.java:370)
		at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:240)
		at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1943)
		at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1927)
		at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1886)
		at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:60)
		at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3441)
		at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:1167)
		at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:742)
		at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
		at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
		at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
		at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
		at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)
		at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1094)
		at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1017)
		at java.security.AccessController.doPrivileged(Native Method)
		at javax.security.auth.Subject.doAs(Subject.java:422)
		at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
		at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3048)
	
		at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
		at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
		at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
		at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
		at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:121)
		at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:88)
		at org.apache.hadoop.hdfs.DFSClient.primitiveMkdir(DFSClient.java:2509)
		at org.apache.hadoop.hdfs.DFSClient.mkdirs(DFSClient.java:2483)
		at org.apache.hadoop.hdfs.DistributedFileSystem$27.doCall(DistributedFileSystem.java:1485)
		at org.apache.hadoop.hdfs.DistributedFileSystem$27.doCall(DistributedFileSystem.java:1482)
		at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
		at org.apache.hadoop.hdfs.DistributedFileSystem.mkdirsInternal(DistributedFileSystem.java:1499)
		at org.apache.hadoop.hdfs.DistributedFileSystem.mkdirs(DistributedFileSystem.java:1474)
		at org.apache.hadoop.fs.FileSystem.mkdirs(FileSystem.java:2388)
		at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.setupJob(FileOutputCommitter.java:356)
		at org.apache.spark.internal.io.HadoopMapReduceCommitProtocol.setupJob(HadoopMapReduceCommitProtocol.scala:188)
		at org.apache.spark.sql.execution.datasources.FileFormatWriter$.writeAndCommit(FileFormatWriter.scala:269)
		at org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeWrite(FileFormatWriter.scala:304)
		at org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:190)
		at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:190)
		at org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:113)
		at org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:111)
		at org.apache.spark.sql.execution.command.DataWritingCommandExec.executeCollect(commands.scala:125)
		at org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.$anonfun$executeCollect$1(AdaptiveSparkPlanExec.scala:390)
		at org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.withFinalPlanUpdate(AdaptiveSparkPlanExec.scala:418)
		at org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.executeCollect(AdaptiveSparkPlanExec.scala:390)
		at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)
		at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)
		at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)
		at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)
		at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
		at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)
		at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)
		at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)
		at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)
		at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
		at org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)
		at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)
		at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)
		at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)
		at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)
		at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)
		at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)
		at org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)
		at org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)
		at org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)
		at org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)
		at org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)
		at org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)
		at org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)
		at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:240)
		at org.apache.spark.sql.DataFrameWriter.csv(DataFrameWriter.scala:850)
		at org.apache.dolphinscheduler.data.quality.flow.batch.writer.file.BaseFileWriter.outputImpl(BaseFileWriter.java:114)
		at org.apache.dolphinscheduler.data.quality.flow.batch.writer.file.HdfsFileWriter.write(HdfsFileWriter.java:40)
		at org.apache.dolphinscheduler.data.quality.execution.SparkBatchExecution.executeWriter(SparkBatchExecution.java:132)
		at org.apache.dolphinscheduler.data.quality.execution.SparkBatchExecution.execute(SparkBatchExecution.java:58)
		at org.apache.dolphinscheduler.data.quality.context.DataQualityContext.execute(DataQualityContext.java:62)
		at org.apache.dolphinscheduler.data.quality.DataQualityApplication.main(DataQualityApplication.java:78)
		at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
		at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
		at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
		at java.lang.reflect.Method.invoke(Method.java:498)
		at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
		at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:1029)
		at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:194)
		at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:217)
		at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:91)
		at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1120)
		at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1129)
		at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
	Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.AccessControlException): Permission denied: user=default, access=WRITE, inode="/":hadoop:supergroup:drwxr-xr-x
		at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:506)
		at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:346)
		at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermissionWithContext(FSPermissionChecker.java:370)
		at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:240)
		at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1943)
		at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1927)
		at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1886)
		at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:60)
		at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3441)
		at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:1167)
		at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:742)
		at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
		at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
		at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
		at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
		at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)
		at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1094)
		at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1017)
		at java.security.AccessController.doPrivileged(Native Method)
		at javax.security.auth.Subject.doAs(Subject.java:422)
		at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
		at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3048)
	
		at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1612)
		at org.apache.hadoop.ipc.Client.call(Client.java:1558)
		at org.apache.hadoop.ipc.Client.call(Client.java:1455)
		at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
		at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
		at com.sun.proxy.$Proxy40.mkdirs(Unknown Source)
		at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.mkdirs(ClientNamenodeProtocolTranslatorPB.java:674)
		at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
		at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
		at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
		at java.lang.reflect.Method.invoke(Method.java:498)
		at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
		at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
		at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
		at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
		at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
		at com.sun.proxy.$Proxy41.mkdirs(Unknown Source)
		at org.apache.hadoop.hdfs.DFSClient.primitiveMkdir(DFSClient.java:2507)
		... 63 more
	24/05/07 10:52:37 INFO SparkContext: Invoking stop() from shutdown hook
	24/05/07 10:52:37 INFO SparkContext: SparkContext is stopping with exitCode 0.
	24/05/07 10:52:37 INFO SparkUI: Stopped Spark web UI at http://56042a532902:4041
	24/05/07 10:52:37 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
	24/05/07 10:52:37 INFO MemoryStore: MemoryStore cleared
	24/05/07 10:52:37 INFO BlockManager: BlockManager stopped
	24/05/07 10:52:37 INFO BlockManagerMaster: BlockManagerMaster stopped
	24/05/07 10:52:37 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
[WI-0][TI-0] - [INFO] 2024-05-07 10:52:37.544 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7168674698795181 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:52:38.296 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/05/07 10:52:37 INFO ShutdownHookManager: Deleting directory /tmp/spark-76c6e52f-ce23-40cf-aaf0-b9d7a97be03e
[WI-1094][TI-3992] - [INFO] 2024-05-07 10:52:38.297 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13001194483488/13505298546272_21/1094/3992, processId:139 ,exitStatusCode:1 ,processWaitForStatus:true ,processExitValue:1
[WI-1094][TI-3992] - [INFO] 2024-05-07 10:52:38.298 +0800 o.a.d.p.t.a.u.LogUtils:[79] - Start finding appId in /opt/dolphinscheduler/logs/20240507/13505298546272/21/1094/3992.log, fetch way: log 
[WI-1094][TI-3992] - [INFO] 2024-05-07 10:52:38.298 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-1094][TI-3992] - [INFO] 2024-05-07 10:52:38.299 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-1094][TI-3992] - [INFO] 2024-05-07 10:52:38.299 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-1094][TI-3992] - [INFO] 2024-05-07 10:52:38.299 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-1094][TI-3992] - [INFO] 2024-05-07 10:52:38.320 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: FAILURE to master : 172.18.1.1:1234
[WI-1094][TI-3992] - [INFO] 2024-05-07 10:52:38.321 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-1094][TI-3992] - [INFO] 2024-05-07 10:52:38.321 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13001194483488/13505298546272_21/1094/3992
[WI-1094][TI-3992] - [INFO] 2024-05-07 10:52:38.321 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13001194483488/13505298546272_21/1094/3992
[WI-1094][TI-3992] - [INFO] 2024-05-07 10:52:38.321 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-0] - [WARN] 2024-05-07 10:52:38.295 +0800 o.a.d.e.b.s.JdkDynamicServerHandler:[147] - [id: 0xbb85b4f4, L:/172.18.1.1:1234 - R:/172.18.0.15:52678] is not writable, over high water level : 65536
[WI-0][TI-0] - [WARN] 2024-05-07 10:52:38.326 +0800 o.a.d.e.b.s.JdkDynamicServerHandler:[154] - [id: 0xbb85b4f4, L:/172.18.1.1:1234 - R:/172.18.0.15:52678] is writable, to low water : 32768
[WI-0][TI-0] - [INFO] 2024-05-07 10:52:38.547 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7762039660056658 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-07 10:52:39.558 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.706081081081081 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-3992] - [INFO] 2024-05-07 10:55:42.734 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=3992, processInstanceId=1094, status=6, startTime=1715050310721, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.14:5678, logPath=/opt/dolphinscheduler/logs/20240507/13505298546272/21/1094/3992.log, executePath=/tmp/dolphinscheduler/exec/process/default/13001194483488/13505298546272_21/1094/3992, endTime=1715050358299, processId=139, appIds=, varPool=[], eventCreateTime=0, eventSendTime=0)
[WI-0][TI-3992] - [INFO] 2024-05-07 10:55:42.738 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=3992, processInstanceId=1094, status=6, startTime=1715050310721, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.14:5678, logPath=/opt/dolphinscheduler/logs/20240507/13505298546272/21/1094/3992.log, executePath=/tmp/dolphinscheduler/exec/process/default/13001194483488/13505298546272_21/1094/3992, endTime=1715050358299, processId=139, appIds=, varPool=[], eventCreateTime=0, eventSendTime=1715050542734)
