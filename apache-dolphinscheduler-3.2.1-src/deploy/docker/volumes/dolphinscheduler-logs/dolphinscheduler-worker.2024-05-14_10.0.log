[WI-0][TI-0] - [WARN] 2024-05-14 10:14:34.272 +0800 o.s.c.k.c.p.AbstractKubernetesProfileEnvironmentPostProcessor:[258] - Not running inside kubernetes. Skipping 'kubernetes' profile activation.
[WI-0][TI-0] - [WARN] 2024-05-14 10:14:42.858 +0800 o.s.c.k.c.p.AbstractKubernetesProfileEnvironmentPostProcessor:[258] - Not running inside kubernetes. Skipping 'kubernetes' profile activation.
[WI-0][TI-0] - [INFO] 2024-05-14 10:14:42.898 +0800 o.a.d.s.w.WorkerServer:[634] - No active profile set, falling back to 1 default profile: "default"
[WI-0][TI-0] - [INFO] 2024-05-14 10:14:55.643 +0800 o.s.c.c.s.GenericScope:[283] - BeanFactory id=7e7bf7c6-2cb3-34d2-a0d5-a56161c67d0e
[WI-0][TI-0] - [INFO] 2024-05-14 10:14:58.287 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'org.springframework.cloud.commons.config.CommonsConfigAutoConfiguration' of type [org.springframework.cloud.commons.config.CommonsConfigAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-05-14 10:14:58.350 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'org.springframework.cloud.client.loadbalancer.LoadBalancerDefaultMappingsProviderAutoConfiguration' of type [org.springframework.cloud.client.loadbalancer.LoadBalancerDefaultMappingsProviderAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-05-14 10:14:58.354 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'loadBalancerClientsDefaultsMappingsProvider' of type [org.springframework.cloud.client.loadbalancer.LoadBalancerDefaultMappingsProviderAutoConfiguration$$Lambda$392/189820624] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-05-14 10:14:58.361 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'defaultsBindHandlerAdvisor' of type [org.springframework.cloud.commons.config.DefaultsBindHandlerAdvisor] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-05-14 10:14:58.418 +0800 o.a.d.c.u.NetUtils:[312] - Get all NetworkInterfaces: [name:eth0 (eth0), name:lo (lo)]
[WI-0][TI-0] - [INFO] 2024-05-14 10:14:58.715 +0800 o.a.d.s.w.c.WorkerConfig:[98] - 
****************************Worker Configuration**************************************
  listen-port -> 1234
  exec-threads -> 100
  max-heartbeat-interval -> PT10S
  host-weight -> 100
  tenantConfig -> TenantConfig(autoCreateTenantEnabled=true, distributedTenantEnabled=false, defaultTenantEnabled=false)
  server-load-protection -> WorkerServerLoadProtection(enabled=true, maxCpuUsagePercentageThresholds=0.7, maxJVMMemoryUsagePercentageThresholds=0.7, maxSystemMemoryUsagePercentageThresholds=0.7, maxDiskUsagePercentageThresholds=0.7)
  registry-disconnect-strategy -> ConnectStrategyProperties(strategy=WAITING, maxWaitingTime=PT1M40S)
  task-execute-threads-full-policy: REJECT
  address -> 172.18.1.1:1234
  registry-path: /nodes/worker/172.18.1.1:1234
****************************Worker Configuration**************************************
[WI-0][TI-0] - [INFO] 2024-05-14 10:14:58.716 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'workerConfig' of type [org.apache.dolphinscheduler.server.worker.config.WorkerConfig$$EnhancerBySpringCGLIB$$153d90bb] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-05-14 10:14:59.995 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'io.kubernetes.client.spring.extended.manifests.config.KubernetesManifestsAutoConfiguration' of type [io.kubernetes.client.spring.extended.manifests.config.KubernetesManifestsAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:00.151 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'kubernetes.manifests-io.kubernetes.client.spring.extended.manifests.config.KubernetesManifestsProperties' of type [io.kubernetes.client.spring.extended.manifests.config.KubernetesManifestsProperties] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:00.193 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'io.kubernetes.client.spring.extended.controller.config.KubernetesInformerAutoConfiguration' of type [io.kubernetes.client.spring.extended.controller.config.KubernetesInformerAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:00.243 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'defaultApiClient' of type [io.kubernetes.client.openapi.ApiClient] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:00.752 +0800 o.e.j.u.log:[170] - Logging initialized @48943ms to org.eclipse.jetty.util.log.Slf4jLog
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:03.212 +0800 o.s.b.w.e.j.JettyServletWebServerFactory:[166] - Server initialized with port: 1235
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:03.220 +0800 o.e.j.s.Server:[375] - jetty-9.4.48.v20220622; built: 2022-06-21T20:42:25.880Z; git: 6b67c5719d1f4371b33655ff2d047d24e171e49a; jvm 1.8.0_402-b06
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:04.076 +0800 o.e.j.s.h.C.application:[2368] - Initializing Spring embedded WebApplicationContext
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:04.077 +0800 o.s.b.w.s.c.ServletWebServerApplicationContext:[292] - Root WebApplicationContext: initialization completed in 20744 ms
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:06.783 +0800 o.e.j.s.session:[334] - DefaultSessionIdManager workerName=node0
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:06.783 +0800 o.e.j.s.session:[339] - No SessionScavenger set, using defaults
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:06.810 +0800 o.e.j.s.session:[132] - node0 Scavenging every 600000ms
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:07.021 +0800 o.e.j.s.h.ContextHandler:[921] - Started o.s.b.w.e.j.JettyEmbeddedWebAppContext@5403431a{application,/,[file:///tmp/jetty-docbase.1235.3744286809364796034/],AVAILABLE}
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:07.039 +0800 o.e.j.s.Server:[415] - Started @55230ms
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:08.809 +0800 o.a.c.f.i.CuratorFrameworkImpl:[338] - Starting
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:08.837 +0800 o.a.z.ZooKeeper:[98] - Client environment:zookeeper.version=3.8.0-5a02a05eddb59aee6ac762f7ea82e92a68eb9c0f, built on 2022-02-25 08:49 UTC
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:08.838 +0800 o.a.z.ZooKeeper:[98] - Client environment:host.name=5a08c1b1b869
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:08.838 +0800 o.a.z.ZooKeeper:[98] - Client environment:java.version=1.8.0_402
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:08.838 +0800 o.a.z.ZooKeeper:[98] - Client environment:java.vendor=Temurin
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:08.839 +0800 o.a.z.ZooKeeper:[98] - Client environment:java.home=/opt/java/openjdk
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:08.839 +0800 o.a.z.ZooKeeper:[98] - Client environment:java.class.path=/opt/dolphinscheduler/conf:/opt/dolphinscheduler/libs/kerb-client-1.0.1.jar:/opt/dolphinscheduler/libs/spring-cloud-starter-kubernetes-client-config-2.1.3.jar:/opt/dolphinscheduler/libs/oauth2-oidc-sdk-9.35.jar:/opt/dolphinscheduler/libs/jsqlparser-4.4.jar:/opt/dolphinscheduler/libs/reactive-streams-1.0.4.jar:/opt/dolphinscheduler/libs/kubernetes-model-extensions-5.10.2.jar:/opt/dolphinscheduler/libs/zookeeper-3.8.0.jar:/opt/dolphinscheduler/libs/kubernetes-model-apps-5.10.2.jar:/opt/dolphinscheduler/libs/grpc-api-1.41.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-pigeon-3.2.1.jar:/opt/dolphinscheduler/libs/client-java-api-13.0.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-obs-3.2.1.jar:/opt/dolphinscheduler/libs/spring-web-5.3.22.jar:/opt/dolphinscheduler/libs/aws-java-sdk-emr-1.12.300.jar:/opt/dolphinscheduler/libs/spring-context-5.3.22.jar:/opt/dolphinscheduler/libs/gapic-google-cloud-storage-v2-2.18.0-alpha.jar:/opt/dolphinscheduler/libs/spring-cloud-kubernetes-client-config-2.1.3.jar:/opt/dolphinscheduler/libs/jetty-io-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/annotations-13.0.jar:/opt/dolphinscheduler/libs/jpam-1.1.jar:/opt/dolphinscheduler/libs/joda-time-2.10.13.jar:/opt/dolphinscheduler/libs/spring-cloud-kubernetes-client-autoconfig-2.1.3.jar:/opt/dolphinscheduler/libs/kerb-identity-1.0.1.jar:/opt/dolphinscheduler/libs/vertica-jdbc-12.0.4-0.jar:/opt/dolphinscheduler/libs/grpc-googleapis-1.52.1.jar:/opt/dolphinscheduler/libs/aliyun-java-sdk-kms-2.11.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-dvc-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-hana-3.2.1.jar:/opt/dolphinscheduler/libs/kubernetes-httpclient-okhttp-6.0.0.jar:/opt/dolphinscheduler/libs/jline-2.12.jar:/opt/dolphinscheduler/libs/sshd-core-2.8.0.jar:/opt/dolphinscheduler/libs/jna-platform-5.10.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-sqlserver-3.2.1.jar:/opt/dolphinscheduler/libs/commons-beanutils-1.9.4.jar:/opt/dolphinscheduler/libs/grpc-services-1.41.0.jar:/opt/dolphinscheduler/libs/jmespath-java-1.12.300.jar:/opt/dolphinscheduler/libs/curator-client-5.3.0.jar:/opt/dolphinscheduler/libs/proto-google-common-protos-2.0.1.jar:/opt/dolphinscheduler/libs/mybatis-3.5.10.jar:/opt/dolphinscheduler/libs/jackson-annotations-2.13.4.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-all-3.2.1.jar:/opt/dolphinscheduler/libs/jakarta.xml.bind-api-2.3.3.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-jupyter-3.2.1.jar:/opt/dolphinscheduler/libs/mybatis-plus-extension-3.5.2.jar:/opt/dolphinscheduler/libs/j2objc-annotations-1.3.jar:/opt/dolphinscheduler/libs/Java-WebSocket-1.5.1.jar:/opt/dolphinscheduler/libs/azure-storage-common-12.20.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-sagemaker-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-databend-3.2.1.jar:/opt/dolphinscheduler/libs/google-auth-library-oauth2-http-1.15.0.jar:/opt/dolphinscheduler/libs/jetty-security-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-python-3.2.1.jar:/opt/dolphinscheduler/libs/snappy-java-1.1.10.1.jar:/opt/dolphinscheduler/libs/kubernetes-model-batch-5.10.2.jar:/opt/dolphinscheduler/libs/netty-transport-native-epoll-4.1.53.Final-linux-x86_64.jar:/opt/dolphinscheduler/libs/jackson-core-asl-1.9.13.jar:/opt/dolphinscheduler/libs/gson-fire-1.8.5.jar:/opt/dolphinscheduler/libs/clickhouse-jdbc-0.4.6.jar:/opt/dolphinscheduler/libs/grpc-netty-shaded-1.41.0.jar:/opt/dolphinscheduler/libs/caffeine-2.9.3.jar:/opt/dolphinscheduler/libs/aliyun-java-sdk-core-4.5.10.jar:/opt/dolphinscheduler/libs/jackson-module-jaxb-annotations-2.13.3.jar:/opt/dolphinscheduler/libs/jetty-http-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/jersey-servlet-1.19.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-dinky-3.2.1.jar:/opt/dolphinscheduler/libs/simpleclient_tracer_common-0.15.0.jar:/opt/dolphinscheduler/libs/netty-handler-4.1.53.Final.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-datafactory-3.2.1.jar:/opt/dolphinscheduler/libs/json-path-2.7.0.jar:/opt/dolphinscheduler/libs/mybatis-plus-annotation-3.5.2.jar:/opt/dolphinscheduler/libs/azure-resourcemanager-datafactory-1.0.0-beta.19.jar:/opt/dolphinscheduler/libs/commons-codec-1.11.jar:/opt/dolphinscheduler/libs/dolphinscheduler-extract-master-3.2.1.jar:/opt/dolphinscheduler/libs/spring-aop-5.3.22.jar:/opt/dolphinscheduler/libs/kubernetes-model-core-5.10.2.jar:/opt/dolphinscheduler/libs/kubernetes-model-networking-5.10.2.jar:/opt/dolphinscheduler/libs/kotlin-stdlib-jdk7-1.6.21.jar:/opt/dolphinscheduler/libs/kerby-xdr-1.0.1.jar:/opt/dolphinscheduler/libs/aliyun-java-sdk-ram-3.1.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-k8s-3.2.1.jar:/opt/dolphinscheduler/libs/guava-31.1-jre.jar:/opt/dolphinscheduler/libs/netty-codec-dns-4.1.53.Final.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-kubeflow-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-azure-sql-3.2.1.jar:/opt/dolphinscheduler/libs/HikariCP-4.0.3.jar:/opt/dolphinscheduler/libs/hive-metastore-2.3.9.jar:/opt/dolphinscheduler/libs/msal4j-1.13.3.jar:/opt/dolphinscheduler/libs/jackson-core-2.13.4.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-hive-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-mr-3.2.1.jar:/opt/dolphinscheduler/libs/kubernetes-model-node-5.10.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-common-3.2.1.jar:/opt/dolphinscheduler/libs/jose4j-0.7.8.jar:/opt/dolphinscheduler/libs/jul-to-slf4j-1.7.36.jar:/opt/dolphinscheduler/libs/azure-identity-1.7.1.jar:/opt/dolphinscheduler/libs/spring-boot-autoconfigure-2.7.3.jar:/opt/dolphinscheduler/libs/commons-math3-3.1.1.jar:/opt/dolphinscheduler/libs/jackson-jaxrs-json-provider-2.13.3.jar:/opt/dolphinscheduler/libs/perfmark-api-0.23.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-doris-3.2.1.jar:/opt/dolphinscheduler/libs/httpclient-4.5.13.jar:/opt/dolphinscheduler/libs/hive-service-2.3.9.jar:/opt/dolphinscheduler/libs/kerby-util-1.0.1.jar:/opt/dolphinscheduler/libs/commons-collections-3.2.2.jar:/opt/dolphinscheduler/libs/hadoop-yarn-client-3.2.4.jar:/opt/dolphinscheduler/libs/commons-text-1.8.jar:/opt/dolphinscheduler/libs/dolphinscheduler-worker-3.2.1.jar:/opt/dolphinscheduler/libs/hadoop-yarn-common-3.2.4.jar:/opt/dolphinscheduler/libs/zeppelin-client-0.10.1.jar:/opt/dolphinscheduler/libs/azure-core-management-1.10.1.jar:/opt/dolphinscheduler/libs/hadoop-mapreduce-client-jobclient-3.2.4.jar:/opt/dolphinscheduler/libs/jta-1.1.jar:/opt/dolphinscheduler/libs/annotations-4.1.1.4.jar:/opt/dolphinscheduler/libs/dolphinscheduler-extract-alert-3.2.1.jar:/opt/dolphinscheduler/libs/curator-framework-5.3.0.jar:/opt/dolphinscheduler/libs/hive-jdbc-2.3.9.jar:/opt/dolphinscheduler/libs/kyuubi-hive-jdbc-shaded-1.7.0.jar:/opt/dolphinscheduler/libs/client-java-proto-13.0.2.jar:/opt/dolphinscheduler/libs/checker-qual-3.19.0.jar:/opt/dolphinscheduler/libs/jetty-servlet-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/google-cloud-core-grpc-2.10.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-shell-3.2.1.jar:/opt/dolphinscheduler/libs/spring-security-rsa-1.0.10.RELEASE.jar:/opt/dolphinscheduler/libs/avro-1.7.7.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-postgresql-3.2.1.jar:/opt/dolphinscheduler/libs/netty-nio-client-2.17.282.jar:/opt/dolphinscheduler/libs/spring-webmvc-5.3.22.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-mysql-3.2.1.jar:/opt/dolphinscheduler/libs/opentracing-util-0.33.0.jar:/opt/dolphinscheduler/libs/auto-value-1.10.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-all-3.2.1.jar:/opt/dolphinscheduler/libs/jetcd-core-0.5.11.jar:/opt/dolphinscheduler/libs/grpc-context-1.41.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-datasync-3.2.1.jar:/opt/dolphinscheduler/libs/jackson-dataformat-cbor-2.13.3.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-gcs-3.2.1.jar:/opt/dolphinscheduler/libs/client-java-extended-13.0.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-redshift-3.2.1.jar:/opt/dolphinscheduler/libs/opencsv-2.3.jar:/opt/dolphinscheduler/libs/jcip-annotations-1.0-1.jar:/opt/dolphinscheduler/libs/accessors-smart-2.4.8.jar:/opt/dolphinscheduler/libs/hadoop-client-3.2.4.jar:/opt/dolphinscheduler/libs/commons-collections4-4.3.jar:/opt/dolphinscheduler/libs/metrics-core-4.2.11.jar:/opt/dolphinscheduler/libs/netty-resolver-4.1.53.Final.jar:/opt/dolphinscheduler/libs/parquet-hadoop-bundle-1.8.1.jar:/opt/dolphinscheduler/libs/bucket4j-core-6.2.0.jar:/opt/dolphinscheduler/libs/spring-cloud-starter-3.1.3.jar:/opt/dolphinscheduler/libs/mssql-jdbc-11.2.1.jre8.jar:/opt/dolphinscheduler/libs/netty-tcnative-boringssl-static-2.0.53.Final.jar:/opt/dolphinscheduler/libs/kubernetes-model-coordination-5.10.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-linkis-3.2.1.jar:/opt/dolphinscheduler/libs/commons-net-3.6.jar:/opt/dolphinscheduler/libs/netty-transport-native-kqueue-4.1.53.Final-osx-x86_64.jar:/opt/dolphinscheduler/libs/dolphinscheduler-meter-3.2.1.jar:/opt/dolphinscheduler/libs/kubernetes-client-api-6.0.0.jar:/opt/dolphinscheduler/libs/kubernetes-model-certificates-5.10.2.jar:/opt/dolphinscheduler/libs/opencensus-api-0.31.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-mlflow-3.2.1.jar:/opt/dolphinscheduler/libs/kotlin-stdlib-jdk8-1.6.21.jar:/opt/dolphinscheduler/libs/dolphinscheduler-registry-jdbc-3.2.1.jar:/opt/dolphinscheduler/libs/audience-annotations-0.12.0.jar:/opt/dolphinscheduler/libs/simpleclient_httpserver-0.15.0.jar:/opt/dolphinscheduler/libs/jetty-xml-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/kerby-asn1-1.0.1.jar:/opt/dolphinscheduler/libs/lang-tag-1.6.jar:/opt/dolphinscheduler/libs/api-common-2.6.0.jar:/opt/dolphinscheduler/libs/HdrHistogram-2.1.12.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-abs-3.2.1.jar:/opt/dolphinscheduler/libs/failsafe-2.4.4.jar:/opt/dolphinscheduler/libs/hbase-noop-htrace-4.1.1.jar:/opt/dolphinscheduler/libs/jamon-runtime-2.3.1.jar:/opt/dolphinscheduler/libs/jetty-util-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/threetenbp-1.6.5.jar:/opt/dolphinscheduler/libs/jakarta.activation-api-1.2.2.jar:/opt/dolphinscheduler/libs/kubernetes-model-common-5.10.2.jar:/opt/dolphinscheduler/libs/okhttp-4.9.3.jar:/opt/dolphinscheduler/libs/profiles-2.17.282.jar:/opt/dolphinscheduler/libs/hadoop-auth-3.2.4.jar:/opt/dolphinscheduler/libs/grpc-netty-1.41.0.jar:/opt/dolphinscheduler/libs/httpcore-nio-4.4.15.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-seatunnel-3.2.1.jar:/opt/dolphinscheduler/libs/aws-java-sdk-sagemaker-1.12.300.jar:/opt/dolphinscheduler/libs/oshi-core-6.1.1.jar:/opt/dolphinscheduler/libs/bonecp-0.8.0.RELEASE.jar:/opt/dolphinscheduler/libs/jackson-module-parameter-names-2.13.3.jar:/opt/dolphinscheduler/libs/bcutil-jdk15on-1.69.jar:/opt/dolphinscheduler/libs/aws-json-protocol-2.17.282.jar:/opt/dolphinscheduler/libs/dolphinscheduler-extract-base-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-all-3.2.1.jar:/opt/dolphinscheduler/libs/derby-10.14.2.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-snowflake-3.2.1.jar:/opt/dolphinscheduler/libs/netty-codec-http2-4.1.53.Final.jar:/opt/dolphinscheduler/libs/jetty-continuation-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/jackson-mapper-asl-1.9.13.jar:/opt/dolphinscheduler/libs/datanucleus-core-4.1.17.jar:/opt/dolphinscheduler/libs/netty-tcnative-boringssl-static-2.0.53.Final-osx-aarch_64.jar:/opt/dolphinscheduler/libs/failureaccess-1.0.1.jar:/opt/dolphinscheduler/libs/error_prone_annotations-2.5.1.jar:/opt/dolphinscheduler/libs/kerb-admin-1.0.1.jar:/opt/dolphinscheduler/libs/token-provider-1.0.1.jar:/opt/dolphinscheduler/libs/reactor-netty-core-1.0.22.jar:/opt/dolphinscheduler/libs/dolphinscheduler-registry-all-3.2.1.jar:/opt/dolphinscheduler/libs/jakarta.servlet-api-4.0.4.jar:/opt/dolphinscheduler/libs/http-client-spi-2.17.282.jar:/opt/dolphinscheduler/libs/regions-2.17.282.jar:/opt/dolphinscheduler/libs/logback-core-1.2.11.jar:/opt/dolphinscheduler/libs/json-1.8.jar:/opt/dolphinscheduler/libs/gax-grpc-2.23.0.jar:/opt/dolphinscheduler/libs/google-http-client-1.42.3.jar:/opt/dolphinscheduler/libs/hive-serde-2.3.9.jar:/opt/dolphinscheduler/libs/jettison-1.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-http-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-registry-zookeeper-3.2.1.jar:/opt/dolphinscheduler/libs/spring-security-crypto-5.7.3.jar:/opt/dolphinscheduler/libs/auth-2.17.282.jar:/opt/dolphinscheduler/libs/proto-google-cloud-storage-v2-2.18.0-alpha.jar:/opt/dolphinscheduler/libs/jetty-server-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/javax.annotation-api-1.3.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-starrocks-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-dataquality-3.2.1.jar:/opt/dolphinscheduler/libs/jcl-over-slf4j-1.7.36.jar:/opt/dolphinscheduler/libs/commons-lang3-3.12.0.jar:/opt/dolphinscheduler/libs/tomcat-embed-el-9.0.65.jar:/opt/dolphinscheduler/libs/opentracing-noop-0.33.0.jar:/opt/dolphinscheduler/libs/client-java-13.0.2.jar:/opt/dolphinscheduler/libs/spring-beans-5.3.22.jar:/opt/dolphinscheduler/libs/snakeyaml-1.33.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-ssh-3.2.1.jar:/opt/dolphinscheduler/libs/commons-pool-1.6.jar:/opt/dolphinscheduler/libs/javax.servlet-api-3.1.0.jar:/opt/dolphinscheduler/libs/hadoop-common-3.2.4.jar:/opt/dolphinscheduler/libs/kubernetes-model-apiextensions-5.10.2.jar:/opt/dolphinscheduler/libs/spring-boot-2.7.3.jar:/opt/dolphinscheduler/libs/bcprov-ext-jdk15on-1.69.jar:/opt/dolphinscheduler/libs/spring-boot-starter-2.7.3.jar:/opt/dolphinscheduler/libs/paranamer-2.3.jar:/opt/dolphinscheduler/libs/httpmime-4.5.13.jar:/opt/dolphinscheduler/libs/reactor-core-3.4.22.jar:/opt/dolphinscheduler/libs/azure-core-1.36.0.jar:/opt/dolphinscheduler/libs/bcpkix-jdk15on-1.69.jar:/opt/dolphinscheduler/libs/kubernetes-model-scheduling-5.10.2.jar:/opt/dolphinscheduler/libs/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/dolphinscheduler/libs/websocket-client-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/unirest-java-3.7.04-standalone.jar:/opt/dolphinscheduler/libs/hadoop-mapreduce-client-core-3.2.4.jar:/opt/dolphinscheduler/libs/google-auth-library-credentials-1.15.0.jar:/opt/dolphinscheduler/libs/azure-storage-internal-avro-12.6.0.jar:/opt/dolphinscheduler/libs/jackson-datatype-jdk8-2.13.3.jar:/opt/dolphinscheduler/libs/spring-expression-5.3.22.jar:/opt/dolphinscheduler/libs/aspectjweaver-1.9.7.jar:/opt/dolphinscheduler/libs/websocket-common-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/client-java-api-fluent-13.0.2.jar:/opt/dolphinscheduler/libs/mybatis-plus-3.5.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-athena-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-oss-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-openmldb-3.2.1.jar:/opt/dolphinscheduler/libs/curator-recipes-5.3.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-api-3.2.1.jar:/opt/dolphinscheduler/libs/netty-all-4.1.53.Final.jar:/opt/dolphinscheduler/libs/netty-resolver-dns-4.1.53.Final.jar:/opt/dolphinscheduler/libs/kubernetes-model-autoscaling-5.10.2.jar:/opt/dolphinscheduler/libs/kerb-util-1.0.1.jar:/opt/dolphinscheduler/libs/grpc-alts-1.41.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-presto-3.2.1.jar:/opt/dolphinscheduler/libs/kerb-simplekdc-1.0.1.jar:/opt/dolphinscheduler/libs/protobuf-java-util-3.17.2.jar:/opt/dolphinscheduler/libs/azure-core-http-netty-1.13.0.jar:/opt/dolphinscheduler/libs/transaction-api-1.1.jar:/opt/dolphinscheduler/libs/datanucleus-api-jdo-4.2.4.jar:/opt/dolphinscheduler/libs/zeppelin-common-0.10.1.jar:/opt/dolphinscheduler/libs/zt-zip-1.15.jar:/opt/dolphinscheduler/libs/animal-sniffer-annotations-1.19.jar:/opt/dolphinscheduler/libs/google-http-client-jackson2-1.42.3.jar:/opt/dolphinscheduler/libs/netty-buffer-4.1.53.Final.jar:/opt/dolphinscheduler/libs/jsr305-3.0.0.jar:/opt/dolphinscheduler/libs/netty-transport-classes-epoll-4.1.79.Final.jar:/opt/dolphinscheduler/libs/spring-boot-actuator-autoconfigure-2.7.3.jar:/opt/dolphinscheduler/libs/simpleclient-0.15.0.jar:/opt/dolphinscheduler/libs/aliyun-sdk-oss-3.15.1.jar:/opt/dolphinscheduler/libs/json-utils-2.17.282.jar:/opt/dolphinscheduler/libs/tephra-api-0.6.0.jar:/opt/dolphinscheduler/libs/spring-jdbc-5.3.22.jar:/opt/dolphinscheduler/libs/grpc-xds-1.41.0.jar:/opt/dolphinscheduler/libs/logback-classic-1.2.11.jar:/opt/dolphinscheduler/libs/google-cloud-storage-2.18.0.jar:/opt/dolphinscheduler/libs/micrometer-registry-prometheus-1.9.3.jar:/opt/dolphinscheduler/libs/grpc-core-1.41.0.jar:/opt/dolphinscheduler/libs/aws-java-sdk-kms-1.12.300.jar:/opt/dolphinscheduler/libs/kubernetes-model-rbac-5.10.2.jar:/opt/dolphinscheduler/libs/ini4j-0.5.4.jar:/opt/dolphinscheduler/libs/spring-boot-starter-web-2.7.3.jar:/opt/dolphinscheduler/libs/spring-cloud-commons-3.1.3.jar:/opt/dolphinscheduler/libs/netty-codec-http-4.1.53.Final.jar:/opt/dolphinscheduler/libs/jetty-client-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/jetcd-common-0.5.11.jar:/opt/dolphinscheduler/libs/metrics-spi-2.17.282.jar:/opt/dolphinscheduler/libs/utils-2.17.282.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-emr-3.2.1.jar:/opt/dolphinscheduler/libs/protocol-core-2.17.282.jar:/opt/dolphinscheduler/libs/micrometer-core-1.9.3.jar:/opt/dolphinscheduler/libs/netty-transport-native-unix-common-4.1.53.Final.jar:/opt/dolphinscheduler/libs/zjsonpatch-0.4.11.jar:/opt/dolphinscheduler/libs/annotations-2.17.282.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-sql-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-extract-common-3.2.1.jar:/opt/dolphinscheduler/libs/apache-client-2.17.282.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-oceanbase-3.2.1.jar:/opt/dolphinscheduler/libs/jdo-api-3.0.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-datax-3.2.1.jar:/opt/dolphinscheduler/libs/postgresql-42.4.1.jar:/opt/dolphinscheduler/libs/jetty-util-ajax-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/gax-2.23.0.jar:/opt/dolphinscheduler/libs/grpc-stub-1.41.0.jar:/opt/dolphinscheduler/libs/libfb303-0.9.3.jar:/opt/dolphinscheduler/libs/spring-core-5.3.22.jar:/opt/dolphinscheduler/libs/jaxb-api-2.3.1.jar:/opt/dolphinscheduler/libs/hive-service-rpc-2.3.9.jar:/opt/dolphinscheduler/libs/kubernetes-model-flowcontrol-5.10.2.jar:/opt/dolphinscheduler/libs/commons-logging-1.1.1.jar:/opt/dolphinscheduler/libs/mybatis-spring-2.0.7.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-oracle-3.2.1.jar:/opt/dolphinscheduler/libs/opencensus-proto-0.2.0.jar:/opt/dolphinscheduler/libs/grpc-protobuf-1.41.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-clickhouse-3.2.1.jar:/opt/dolphinscheduler/libs/spring-cloud-starter-bootstrap-3.1.3.jar:/opt/dolphinscheduler/libs/kubernetes-model-admissionregistration-5.10.2.jar:/opt/dolphinscheduler/libs/grpc-google-cloud-storage-v2-2.18.0-alpha.jar:/opt/dolphinscheduler/libs/esdk-obs-java-bundle-3.23.3.jar:/opt/dolphinscheduler/libs/dnsjava-2.1.7.jar:/opt/dolphinscheduler/libs/asm-9.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-spark-3.2.1.jar:/opt/dolphinscheduler/libs/netty-tcnative-boringssl-static-2.0.53.Final-linux-aarch_64.jar:/opt/dolphinscheduler/libs/re2j-1.6.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-vertica-3.2.1.jar:/opt/dolphinscheduler/libs/json-smart-2.4.8.jar:/opt/dolphinscheduler/libs/reactor-netty-http-1.0.22.jar:/opt/dolphinscheduler/libs/google-api-services-storage-v1-rev20220705-2.0.0.jar:/opt/dolphinscheduler/libs/kubernetes-client-6.0.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-kyuubi-3.2.1.jar:/opt/dolphinscheduler/libs/auto-value-annotations-1.10.1.jar:/opt/dolphinscheduler/libs/commons-cli-1.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-data-quality-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-chunjun-3.2.1.jar:/opt/dolphinscheduler/libs/kerb-server-1.0.1.jar:/opt/dolphinscheduler/libs/content-type-2.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-remoteshell-3.2.1.jar:/opt/dolphinscheduler/libs/opencensus-contrib-http-util-0.31.1.jar:/opt/dolphinscheduler/libs/druid-1.2.20.jar:/opt/dolphinscheduler/libs/javolution-5.5.1.jar:/opt/dolphinscheduler/libs/protobuf-java-3.17.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-db2-3.2.1.jar:/opt/dolphinscheduler/libs/aws-java-sdk-core-1.12.300.jar:/opt/dolphinscheduler/libs/spring-boot-starter-logging-2.7.3.jar:/opt/dolphinscheduler/libs/kerby-pkix-1.0.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-procedure-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-registry-etcd-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-sqoop-3.2.1.jar:/opt/dolphinscheduler/libs/zookeeper-jute-3.8.0.jar:/opt/dolphinscheduler/libs/netty-resolver-dns-native-macos-4.1.53.Final-osx-x86_64.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-sagemaker-3.2.1.jar:/opt/dolphinscheduler/libs/spring-boot-configuration-processor-2.6.1.jar:/opt/dolphinscheduler/libs/hive-common-2.3.9.jar:/opt/dolphinscheduler/libs/kerb-common-1.0.1.jar:/opt/dolphinscheduler/libs/stax-api-1.0.1.jar:/opt/dolphinscheduler/libs/kubernetes-model-storageclass-5.10.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-s3-3.2.1.jar:/opt/dolphinscheduler/libs/spring-boot-starter-jetty-2.7.3.jar:/opt/dolphinscheduler/libs/okio-2.8.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-dms-3.2.1.jar:/opt/dolphinscheduler/libs/simpleclient_common-0.15.0.jar:/opt/dolphinscheduler/libs/sdk-core-2.17.282.jar:/opt/dolphinscheduler/libs/javax.activation-api-1.2.0.jar:/opt/dolphinscheduler/libs/netty-handler-proxy-4.1.53.Final.jar:/opt/dolphinscheduler/libs/kerby-config-1.0.1.jar:/opt/dolphinscheduler/libs/netty-tcnative-classes-2.0.53.Final.jar:/opt/dolphinscheduler/libs/jackson-jaxrs-base-2.13.3.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-trino-3.2.1.jar:/opt/dolphinscheduler/libs/presto-jdbc-0.238.1.jar:/opt/dolphinscheduler/libs/websocket-api-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-flink-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-api-3.2.1.jar:/opt/dolphinscheduler/libs/kubernetes-model-metrics-5.10.2.jar:/opt/dolphinscheduler/libs/datasync-2.17.282.jar:/opt/dolphinscheduler/libs/hadoop-yarn-api-3.2.4.jar:/opt/dolphinscheduler/libs/google-http-client-apache-v2-1.42.3.jar:/opt/dolphinscheduler/libs/hadoop-annotations-3.2.4.jar:/opt/dolphinscheduler/libs/google-oauth-client-1.34.1.jar:/opt/dolphinscheduler/libs/sshd-common-2.8.0.jar:/opt/dolphinscheduler/libs/LatencyUtils-2.0.3.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-spark-3.2.1.jar:/opt/dolphinscheduler/libs/slf4j-api-1.7.36.jar:/opt/dolphinscheduler/libs/snowflake-jdbc-3.13.29.jar:/opt/dolphinscheduler/libs/jackson-datatype-jsr310-2.13.3.jar:/opt/dolphinscheduler/libs/trino-jdbc-402.jar:/opt/dolphinscheduler/libs/logging-interceptor-4.9.3.jar:/opt/dolphinscheduler/libs/simpleclient_tracer_otel_agent-0.15.0.jar:/opt/dolphinscheduler/libs/janino-3.0.16.jar:/opt/dolphinscheduler/libs/jackson-dataformat-yaml-2.13.3.jar:/opt/dolphinscheduler/libs/ion-java-1.0.2.jar:/opt/dolphinscheduler/libs/commons-dbcp-1.4.jar:/opt/dolphinscheduler/libs/jsp-api-2.1.jar:/opt/dolphinscheduler/libs/google-http-client-gson-1.42.3.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-hivecli-3.2.1.jar:/opt/dolphinscheduler/libs/spring-boot-actuator-2.7.3.jar:/opt/dolphinscheduler/libs/google-cloud-core-http-2.10.0.jar:/opt/dolphinscheduler/libs/DmJdbcDriver18-8.1.2.79.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-java-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-dameng-3.2.1.jar:/opt/dolphinscheduler/libs/sshd-sftp-2.8.0.jar:/opt/dolphinscheduler/libs/kerb-crypto-1.0.1.jar:/opt/dolphinscheduler/libs/conscrypt-openjdk-uber-2.5.2.jar:/opt/dolphinscheduler/libs/httpcore-4.4.15.jar:/opt/dolphinscheduler/libs/lz4-java-1.4.0.jar:/opt/dolphinscheduler/libs/guava-retrying-2.0.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-flink-stream-3.2.1.jar:/opt/dolphinscheduler/libs/spring-tx-5.3.22.jar:/opt/dolphinscheduler/libs/grpc-auth-1.41.0.jar:/opt/dolphinscheduler/libs/netty-tcnative-boringssl-static-2.0.53.Final-osx-x86_64.jar:/opt/dolphinscheduler/libs/databend-jdbc-0.0.7.jar:/opt/dolphinscheduler/libs/bcprov-jdk15on-1.69.jar:/opt/dolphinscheduler/libs/commons-lang-2.6.jar:/opt/dolphinscheduler/libs/kubernetes-model-policy-5.10.2.jar:/opt/dolphinscheduler/libs/commons-io-2.11.0.jar:/opt/dolphinscheduler/libs/grpc-grpclb-1.41.0.jar:/opt/dolphinscheduler/libs/netty-tcnative-boringssl-static-2.0.53.Final-linux-x86_64.jar:/opt/dolphinscheduler/libs/opentracing-api-0.33.0.jar:/opt/dolphinscheduler/libs/sshd-scp-2.8.0.jar:/opt/dolphinscheduler/libs/reload4j-1.2.18.3.jar:/opt/dolphinscheduler/libs/netty-tcnative-2.0.48.Final.jar:/opt/dolphinscheduler/libs/jdom2-2.0.6.1.jar:/opt/dolphinscheduler/libs/spring-boot-starter-json-2.7.3.jar:/opt/dolphinscheduler/libs/netty-transport-native-epoll-4.1.53.Final.jar:/opt/dolphinscheduler/libs/google-cloud-core-2.10.0.jar:/opt/dolphinscheduler/libs/javax.jdo-3.2.0-m3.jar:/opt/dolphinscheduler/libs/gax-httpjson-0.108.0.jar:/opt/dolphinscheduler/libs/mybatis-plus-core-3.5.2.jar:/opt/dolphinscheduler/libs/auto-service-annotations-1.0.1.jar:/opt/dolphinscheduler/libs/nimbus-jose-jwt-9.22.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-zeppelin-3.2.1.jar:/opt/dolphinscheduler/libs/commons-compress-1.21.jar:/opt/dolphinscheduler/libs/hadoop-hdfs-client-3.2.4.jar:/opt/dolphinscheduler/libs/msal4j-persistence-extension-1.1.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-pytorch-3.2.1.jar:/opt/dolphinscheduler/libs/netty-tcnative-boringssl-static-2.0.53.Final-windows-x86_64.jar:/opt/dolphinscheduler/libs/jetty-servlets-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/woodstox-core-6.4.0.jar:/opt/dolphinscheduler/libs/spring-cloud-kubernetes-commons-2.1.3.jar:/opt/dolphinscheduler/libs/grpc-protobuf-lite-1.41.0.jar:/opt/dolphinscheduler/libs/jetty-webapp-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/eventstream-1.0.1.jar:/opt/dolphinscheduler/libs/commons-compiler-3.1.7.jar:/opt/dolphinscheduler/libs/netty-transport-4.1.53.Final.jar:/opt/dolphinscheduler/libs/spring-cloud-context-3.1.3.jar:/opt/dolphinscheduler/libs/aws-java-sdk-dms-1.12.300.jar:/opt/dolphinscheduler/libs/hive-storage-api-2.4.0.jar:/opt/dolphinscheduler/libs/client-java-spring-integration-13.0.2.jar:/opt/dolphinscheduler/libs/spring-boot-starter-actuator-2.7.3.jar:/opt/dolphinscheduler/libs/third-party-jackson-core-2.17.282.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-hdfs-3.2.1.jar:/opt/dolphinscheduler/libs/netty-codec-4.1.53.Final.jar:/opt/dolphinscheduler/libs/google-http-client-appengine-1.42.3.jar:/opt/dolphinscheduler/libs/commons-configuration2-2.1.1.jar:/opt/dolphinscheduler/libs/datanucleus-rdbms-4.1.19.jar:/opt/dolphinscheduler/libs/swagger-annotations-1.6.2.jar:/opt/dolphinscheduler/libs/simpleclient_tracer_otel-0.15.0.jar:/opt/dolphinscheduler/libs/kotlin-stdlib-common-1.6.21.jar:/opt/dolphinscheduler/libs/aws-core-2.17.282.jar:/opt/dolphinscheduler/libs/kerb-core-1.0.1.jar:/opt/dolphinscheduler/libs/httpasyncclient-4.1.5.jar:/opt/dolphinscheduler/libs/dolphinscheduler-extract-worker-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-spi-3.2.1.jar:/opt/dolphinscheduler/libs/okhttp-2.7.5.jar:/opt/dolphinscheduler/libs/google-api-client-2.2.0.jar:/opt/dolphinscheduler/libs/kotlin-stdlib-1.6.21.jar:/opt/dolphinscheduler/libs/jakarta.websocket-api-1.1.2.jar:/opt/dolphinscheduler/libs/libthrift-0.9.3.jar:/opt/dolphinscheduler/libs/spring-boot-starter-aop-2.7.3.jar:/opt/dolphinscheduler/libs/netty-common-4.1.53.Final.jar:/opt/dolphinscheduler/libs/log4j-1.2-api-2.17.2.jar:/opt/dolphinscheduler/libs/jackson-databind-2.13.4.jar:/opt/dolphinscheduler/libs/jackson-dataformat-xml-2.13.3.jar:/opt/dolphinscheduler/libs/kubernetes-model-events-5.10.2.jar:/opt/dolphinscheduler/libs/gson-2.9.1.jar:/opt/dolphinscheduler/libs/proto-google-iam-v1-1.9.0.jar:/opt/dolphinscheduler/libs/netty-codec-socks-4.1.53.Final.jar:/opt/dolphinscheduler/libs/zjsonpatch-0.3.0.jar:/opt/dolphinscheduler/libs/hadoop-mapreduce-client-common-3.2.4.jar:/opt/dolphinscheduler/libs/dolphinscheduler-registry-api-3.2.1.jar:/opt/dolphinscheduler/libs/azure-storage-blob-12.21.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-zeppelin-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-api-3.2.1.jar:/opt/dolphinscheduler/libs/aws-java-sdk-s3-1.12.300.jar:/opt/dolphinscheduler/libs/stax2-api-4.2.1.jar:/opt/dolphinscheduler/libs/jakarta.annotation-api-1.3.5.jar:/opt/dolphinscheduler/libs/kubernetes-model-discovery-5.10.2.jar:/opt/dolphinscheduler/libs/jna-5.10.0.jar:/opt/dolphinscheduler/libs/spring-jcl-5.3.22.jar
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:08.839 +0800 o.a.z.ZooKeeper:[98] - Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:08.843 +0800 o.a.z.ZooKeeper:[98] - Client environment:java.io.tmpdir=/tmp
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:08.848 +0800 o.a.z.ZooKeeper:[98] - Client environment:java.compiler=<NA>
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:08.853 +0800 o.a.z.ZooKeeper:[98] - Client environment:os.name=Linux
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:08.860 +0800 o.a.z.ZooKeeper:[98] - Client environment:os.arch=amd64
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:08.861 +0800 o.a.z.ZooKeeper:[98] - Client environment:os.version=6.5.0-28-generic
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:08.861 +0800 o.a.z.ZooKeeper:[98] - Client environment:user.name=root
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:08.861 +0800 o.a.z.ZooKeeper:[98] - Client environment:user.home=/root
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:08.861 +0800 o.a.z.ZooKeeper:[98] - Client environment:user.dir=/opt/dolphinscheduler
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:08.867 +0800 o.a.z.ZooKeeper:[98] - Client environment:os.memory.free=3191MB
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:08.867 +0800 o.a.z.ZooKeeper:[98] - Client environment:os.memory.max=3840MB
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:08.867 +0800 o.a.z.ZooKeeper:[98] - Client environment:os.memory.total=3840MB
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:08.898 +0800 o.a.z.ZooKeeper:[637] - Initiating client connection, connectString=dolphinscheduler-zookeeper:2181 sessionTimeout=30000 watcher=org.apache.curator.ConnectionState@1de08775
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:09.032 +0800 o.a.z.c.X509Util:[77] - Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:09.042 +0800 o.a.z.ClientCnxnSocket:[239] - jute.maxbuffer value is 1048575 Bytes
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:09.074 +0800 o.a.z.ClientCnxn:[1732] - zookeeper.request.timeout value is 0. feature enabled=false
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:09.165 +0800 o.a.z.ClientCnxn:[1171] - Opening socket connection to server dolphinscheduler-zookeeper/172.18.0.5:2181.
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:09.228 +0800 o.a.z.ClientCnxn:[1173] - SASL config status: Will not attempt to authenticate using SASL (unknown error)
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:09.208 +0800 o.a.c.f.i.CuratorFrameworkImpl:[386] - Default schema
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:09.241 +0800 o.a.z.ClientCnxn:[1005] - Socket connection established, initiating session, client: /172.18.1.1:42322, server: dolphinscheduler-zookeeper/172.18.0.5:2181
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:09.542 +0800 o.a.z.ClientCnxn:[1444] - Session establishment complete on server dolphinscheduler-zookeeper/172.18.0.5:2181, session id = 0x1000009ecbd0002, negotiated timeout = 30000
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:09.557 +0800 o.a.c.f.s.ConnectionStateManager:[252] - State change: CONNECTED
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:09.972 +0800 o.a.c.f.i.EnsembleTracker:[201] - New config event received: {}
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:10.105 +0800 o.a.c.f.i.EnsembleTracker:[201] - New config event received: {}
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:10.394 +0800 o.a.d.s.w.r.WorkerRpcServer:[41] - WorkerRpcServer starting...
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:10.998 +0800 o.a.d.e.b.NettyRemotingServer:[112] - WorkerRpcServer bind success at port: 1234
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:10.999 +0800 o.a.d.s.w.r.WorkerRpcServer:[43] - WorkerRpcServer started...
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:11.029 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: JAVA - JavaTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:11.112 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: JAVA - JavaTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:11.113 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: JUPYTER - JupyterTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:11.116 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: JUPYTER - JupyterTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:11.116 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: SPARK - SparkTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:11.120 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: SPARK - SparkTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:11.124 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: FLINK_STREAM - FlinkStreamTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:11.129 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: FLINK_STREAM - FlinkStreamTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:11.130 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: PYTHON - PythonTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:11.131 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: PYTHON - PythonTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:11.132 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: DATASYNC - DatasyncTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:11.134 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: DATASYNC - DatasyncTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:11.154 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: DATA_FACTORY - DatafactoryTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:11.156 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: DATA_FACTORY - DatafactoryTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:11.157 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: CHUNJUN - ChunJunTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:11.159 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: CHUNJUN - ChunJunTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:11.160 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: REMOTESHELL - RemoteShellTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:11.162 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: REMOTESHELL - RemoteShellTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:11.163 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: PIGEON - PigeonTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:11.164 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: PIGEON - PigeonTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:11.164 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: SHELL - ShellTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:11.168 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: SHELL - ShellTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:11.169 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: PROCEDURE - ProcedureTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:11.171 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: PROCEDURE - ProcedureTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:11.172 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: MR - MapReduceTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:11.174 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: MR - MapReduceTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:11.175 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: SQOOP - SqoopTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:11.227 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: SQOOP - SqoopTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:11.228 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: PYTORCH - PytorchTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:11.235 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: PYTORCH - PytorchTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:11.236 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: K8S - K8sTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:11.237 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: K8S - K8sTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:11.238 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: SEATUNNEL - SeatunnelTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:11.241 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: SEATUNNEL - SeatunnelTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:11.241 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: SAGEMAKER - SagemakerTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:11.243 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: SAGEMAKER - SagemakerTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:11.244 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: HTTP - HttpTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:11.246 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: HTTP - HttpTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:11.246 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: EMR - EmrTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:11.249 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: EMR - EmrTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:11.250 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: DMS - DmsTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:11.256 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: DMS - DmsTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:11.256 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: DATA_QUALITY - DataQualityTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:11.258 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: DATA_QUALITY - DataQualityTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:11.258 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: KUBEFLOW - KubeflowTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:11.260 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: KUBEFLOW - KubeflowTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:11.263 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: SQL - SqlTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:11.265 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: SQL - SqlTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:11.279 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: DVC - DvcTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:11.281 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: DVC - DvcTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:11.282 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: DATAX - DataxTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:11.284 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: DATAX - DataxTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:11.285 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: ZEPPELIN - ZeppelinTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:11.287 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: ZEPPELIN - ZeppelinTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:11.288 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: DINKY - DinkyTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:11.289 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: DINKY - DinkyTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:11.290 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: MLFLOW - MlflowTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:11.292 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: MLFLOW - MlflowTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:11.292 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: OPENMLDB - OpenmldbTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:11.293 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: OPENMLDB - OpenmldbTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:11.294 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: LINKIS - LinkisTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:11.298 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: LINKIS - LinkisTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:11.299 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: FLINK - FlinkTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:11.327 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: FLINK - FlinkTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:11.328 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: HIVECLI - HiveCliTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:11.331 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: HIVECLI - HiveCliTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:11.653 +0800 o.a.d.c.u.JSONUtils:[72] - init timezone: sun.util.calendar.ZoneInfo[id="Asia/Shanghai",offset=28800000,dstSavings=0,useDaylight=false,transitions=31,lastRule=null]
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:12.049 +0800 o.a.d.s.w.r.WorkerRegistryClient:[104] - Worker node: 172.18.1.1:1234 registry to ZK /nodes/worker/172.18.1.1:1234 successfully
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:13.112 +0800 o.a.d.c.m.BaseHeartBeatTask:[48] - Starting WorkerHeartBeatTask...
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:13.113 +0800 o.a.d.c.m.BaseHeartBeatTask:[50] - Started WorkerHeartBeatTask, heartBeatInterval: 10000...
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:13.113 +0800 o.a.d.s.w.r.WorkerRegistryClient:[114] - Worker node: 172.18.1.1:1234 registry finished
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:13.115 +0800 o.a.d.s.w.m.MessageRetryRunner:[69] - Message retry runner staring
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:13.118 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.0526315789473684 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:13.197 +0800 o.a.d.s.w.m.MessageRetryRunner:[72] - Injected message sender: TaskInstanceExecutionFinishEventSender
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:13.244 +0800 o.a.d.s.w.m.MessageRetryRunner:[72] - Injected message sender: TaskInstanceExecutionInfoUpdateEventSender
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:13.244 +0800 o.a.d.s.w.m.MessageRetryRunner:[72] - Injected message sender: TaskInstanceExecutionRunningEventSender
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:13.244 +0800 o.a.d.s.w.m.MessageRetryRunner:[75] - Message retry runner started
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:14.141 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.2831050228310503 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:15.175 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.4455445544554455 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:16.183 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.392156862745098 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:18.144 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.3850574712643677 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:19.147 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.5714285714285714 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:20.156 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.6753246753246753 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:21.415 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.9915254237288136 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:22.518 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 2.0 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:23.721 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.8157894736842106 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:24.592 +0800 o.s.b.a.e.w.EndpointLinksResolver:[58] - Exposing 3 endpoint(s) beneath base path '/actuator'
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:24.897 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.6793478260869565 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:25.045 +0800 o.e.j.s.h.C.application:[2368] - Initializing Spring DispatcherServlet 'dispatcherServlet'
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:25.049 +0800 o.s.w.s.DispatcherServlet:[525] - Initializing Servlet 'dispatcherServlet'
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:25.052 +0800 o.s.w.s.DispatcherServlet:[547] - Completed initialization in 2 ms
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:25.435 +0800 o.e.j.s.AbstractConnector:[333] - Started ServerConnector@1f45db49{HTTP/1.1, (http/1.1)}{0.0.0.0:1235}
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:25.438 +0800 o.s.b.w.e.j.JettyWebServer:[172] - Jetty started on port(s) 1235 (http/1.1) with context path '/'
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:25.522 +0800 o.a.d.s.w.WorkerServer:[61] - Started WorkerServer in 65.072 seconds (JVM running for 73.713)
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:25.899 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.2999999999999998 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:27.147 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7898550724637681 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:28.149 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.746177370030581 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:30.172 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8745098039215686 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:31.194 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8603351955307263 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:32.231 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7588495575221239 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:33.234 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7761755134103916 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:34.250 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8387096774193549 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:39.430 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.751131221719457 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:40.445 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7439024390243903 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 10:15:44.474 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.764367816091954 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 10:18:22.511 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8072625698324023 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 10:18:23.520 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8236914600550964 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 10:18:48.659 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7577464788732394 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 10:18:49.699 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9199999999999999 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 10:18:50.704 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8802228412256267 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 10:18:51.707 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7569060773480663 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 10:19:57.161 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7158469945355191 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 10:19:58.217 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8979057591623036 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 10:20:02.242 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8854489164086687 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 10:20:05.267 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7138810198300283 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 10:20:09.331 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8205128205128204 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 10:20:58.889 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7192982456140351 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 10:20:59.949 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7050938337801609 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 10:21:04.002 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7750759878419453 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 10:21:05.143 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8190954773869347 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 10:21:10.184 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.75 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 10:21:12.270 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.782991202346041 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 10:21:14.343 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7073863636363636 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 10:21:15.372 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7914285714285714 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 10:21:16.374 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8686567164179105 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 10:21:17.376 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7685459940652819 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 10:21:20.403 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8333333333333334 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 10:21:22.449 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7204610951008645 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 10:21:25.581 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7915492957746479 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 10:21:28.640 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7291666666666667 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 10:21:29.664 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8465909090909092 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 10:21:30.669 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9204545454545454 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 10:21:31.674 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8057324840764332 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 10:21:39.777 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7806267806267805 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 10:21:40.808 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7903682719546743 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 10:23:03.210 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7953216374269005 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 10:31:49.841 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8104395604395604 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 10:31:50.870 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7478510028653296 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 10:32:20.021 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7319884726224785 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 10:45:16.702 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=4013, taskName=Extract Reddit Data, firstSubmitTime=1715654716219, startTime=0, taskType=PYTHON, workflowInstanceHost=172.18.0.16:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13045665829504, processDefineVersion=20, appIds=null, processInstanceId=1112, scheduleTime=0, globalParams=[{"prop":"subreddit","direct":"IN","type":"VARCHAR","value":"singapore"},{"prop":"limit","direct":"IN","type":"VARCHAR","value":"3"}], executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[],"rawScript":"import praw\nimport json\n\nclass RedditPostDataExtractor:\n    def __init__(self):\n        self.data = []\n\n    def extract_data(self, hot_posts):\n        if hot_posts:\n            for post in hot_posts:\n                post.comments.replace_more(limit=None)\n                # initialise a dictionary to contain the data of the post\n                post_data = {}\n\n                # get the relevant post's data and store it inside post_data\n\n                # get the poster's name\n                if post.author is not None:\n                    post_data['author'] = post.author.name\n                else:\n                    post_data['author'] = '[deleted]' # if the user was deleted, post.author will return None. This line will catch that scenario and instead provide the value 'deleted'\n\n                # get the unix time in which the post was created\n                post_data['unix_time'] = post.created_utc\n                post_data['permalink'] = post.permalink\n                post_data['score'] = post.score\n                post_data['post_title'] = post.title\n                post_data['body'] = post.selftext\n\n                # get the unique name of the post (name refers to the id of the post prefixed with t3_)\n                # t3 represents that it is a post\n                post_data['name'] = post.name\n\n                # store the posts data in the dictionary where the name is used as the key\n                self.data.append(post_data)\n\n                # extract the comments from the post\n                comments = post.comments.list()\n\n                # extract the data in the comments and store them inside the dictionary\n                self.extract_comments_data(comments)\n        \n        return self.data\n\n    def extract_comments_data(self, comments):\n        if comments:\n            for comment in comments:\n                # initialise a dictionary to contain the data of the comment\n                comment_data = {}\n\n\n                # get the relevant post's data and store it inside post_data\n\n                # get the commenter name\n                if comment.author is not None:\n                    comment_data['author'] = comment.author.name\n                else:\n                    comment_data['author'] = '[deleted]' # if the user was deleted, comment.author will return None, this line will catch that scenario and instead provide the value 'deleted'\n\n                # get the unix time in which the comment was created\n                comment_data['unix_time'] = comment.created_utc\n                comment_data['permalink'] = comment.permalink\n                comment_data['score'] = comment.score\n                comment_data['post_title'] = comment.submission.title\n                comment_data['body'] = comment.body\n\n                # get the unique name of the comment (name refers to the id of the post prefixed with t1_)\n                # t1 represents that it is a post\n                comment_data['name'] = comment.name\n\n                # store the comment's data in the dictionary where the name is used as the key\n                self.data.append(comment_data)\n\n                # extract the comment's replies from the post\n                # replies = comment.replies\n\n                # extract the data in the comments and store them inside the dictionary\n                # self.extract_comments_data(replies)\n        \n        return\n    \ndef get_hot_posts(reddit_instance, subreddit_name, limit):\n    # Define the subreddit\n    subreddit = reddit_instance.subreddit(subreddit_name)\n\n    # Get hot posts from the subreddit\n    hot_posts = subreddit.hot(limit=limit)\n\n    # Filter out posts that are not pinned\n    filtered_posts = [post for post in hot_posts if not post.stickied]\n    return filtered_posts\n\n\n# initialize Reddit instance\nreddit = praw.Reddit(client_id='hM2BAD8XKakgkVdR2V2S-Q',\n                     client_secret='dWBfOf7Ed2WxqVavqQIcZ6V72QyBLg',\n                     user_agent='Prawlingv1')\n\n\n# choose the subreddit to extract data from\nsubreddit = \"${subreddit}\"\nlimit = ${limit}\n\n# get hot posts from the subreddit\nhot_posts = get_hot_posts(reddit, subreddit, limit)\n\n# initialise a reddit data extractor object\ndata_extractor = RedditPostDataExtractor()\n\n# extract data from the hot posts from r/singapore\ndata = data_extractor.extract_data(hot_posts)\n\nwith open(\"/local_storage/reddit/in/${system.workflow.instance.id}-${system.datetime}.json\", \"w\") as fp:\n    json.dump(data, fp, indent=4)","resourceList":[]}, environmentConfig=export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={GNEWS_HOME=Property{prop='GNEWS_HOME', direct=IN, type=VARCHAR, value='/local_storage/google_news'}, system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='Extract Reddit Data'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240514'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='4013'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13045662268160'}, subreddit=Property{prop='subreddit', direct=IN, type=VARCHAR, value='singapore'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240514104516'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='1112'}, limit=Property{prop='limit', direct=IN, type=VARCHAR, value='3'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240513'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='extract_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13045665829504'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=null, dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-1112][TI-4013] - [INFO] 2024-05-14 10:45:16.775 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: Extract Reddit Data to wait queue success
[WI-1112][TI-4013] - [INFO] 2024-05-14 10:45:16.823 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-1112][TI-4013] - [INFO] 2024-05-14 10:45:16.844 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-1112][TI-4013] - [INFO] 2024-05-14 10:45:16.844 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-1112][TI-4013] - [INFO] 2024-05-14 10:45:16.844 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-1112][TI-4013] - [INFO] 2024-05-14 10:45:16.844 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1715654716844
[WI-1112][TI-4013] - [INFO] 2024-05-14 10:45:16.852 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 1112_4013
[WI-1112][TI-4013] - [INFO] 2024-05-14 10:45:16.865 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 4013,
  "taskName" : "Extract Reddit Data",
  "firstSubmitTime" : 1715654716219,
  "startTime" : 1715654716844,
  "taskType" : "PYTHON",
  "workflowInstanceHost" : "172.18.0.16:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240514/13045665829504/20/1112/4013.log",
  "processId" : 0,
  "processDefineCode" : 13045665829504,
  "processDefineVersion" : 20,
  "processInstanceId" : 1112,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"subreddit\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"singapore\"},{\"prop\":\"limit\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"3\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[],\"rawScript\":\"import praw\\nimport json\\n\\nclass RedditPostDataExtractor:\\n    def __init__(self):\\n        self.data = []\\n\\n    def extract_data(self, hot_posts):\\n        if hot_posts:\\n            for post in hot_posts:\\n                post.comments.replace_more(limit=None)\\n                # initialise a dictionary to contain the data of the post\\n                post_data = {}\\n\\n                # get the relevant post's data and store it inside post_data\\n\\n                # get the poster's name\\n                if post.author is not None:\\n                    post_data['author'] = post.author.name\\n                else:\\n                    post_data['author'] = '[deleted]' # if the user was deleted, post.author will return None. This line will catch that scenario and instead provide the value 'deleted'\\n\\n                # get the unix time in which the post was created\\n                post_data['unix_time'] = post.created_utc\\n                post_data['permalink'] = post.permalink\\n                post_data['score'] = post.score\\n                post_data['post_title'] = post.title\\n                post_data['body'] = post.selftext\\n\\n                # get the unique name of the post (name refers to the id of the post prefixed with t3_)\\n                # t3 represents that it is a post\\n                post_data['name'] = post.name\\n\\n                # store the posts data in the dictionary where the name is used as the key\\n                self.data.append(post_data)\\n\\n                # extract the comments from the post\\n                comments = post.comments.list()\\n\\n                # extract the data in the comments and store them inside the dictionary\\n                self.extract_comments_data(comments)\\n        \\n        return self.data\\n\\n    def extract_comments_data(self, comments):\\n        if comments:\\n            for comment in comments:\\n                # initialise a dictionary to contain the data of the comment\\n                comment_data = {}\\n\\n\\n                # get the relevant post's data and store it inside post_data\\n\\n                # get the commenter name\\n                if comment.author is not None:\\n                    comment_data['author'] = comment.author.name\\n                else:\\n                    comment_data['author'] = '[deleted]' # if the user was deleted, comment.author will return None, this line will catch that scenario and instead provide the value 'deleted'\\n\\n                # get the unix time in which the comment was created\\n                comment_data['unix_time'] = comment.created_utc\\n                comment_data['permalink'] = comment.permalink\\n                comment_data['score'] = comment.score\\n                comment_data['post_title'] = comment.submission.title\\n                comment_data['body'] = comment.body\\n\\n                # get the unique name of the comment (name refers to the id of the post prefixed with t1_)\\n                # t1 represents that it is a post\\n                comment_data['name'] = comment.name\\n\\n                # store the comment's data in the dictionary where the name is used as the key\\n                self.data.append(comment_data)\\n\\n                # extract the comment's replies from the post\\n                # replies = comment.replies\\n\\n                # extract the data in the comments and store them inside the dictionary\\n                # self.extract_comments_data(replies)\\n        \\n        return\\n    \\ndef get_hot_posts(reddit_instance, subreddit_name, limit):\\n    # Define the subreddit\\n    subreddit = reddit_instance.subreddit(subreddit_name)\\n\\n    # Get hot posts from the subreddit\\n    hot_posts = subreddit.hot(limit=limit)\\n\\n    # Filter out posts that are not pinned\\n    filtered_posts = [post for post in hot_posts if not post.stickied]\\n    return filtered_posts\\n\\n\\n# initialize Reddit instance\\nreddit = praw.Reddit(client_id='hM2BAD8XKakgkVdR2V2S-Q',\\n                     client_secret='dWBfOf7Ed2WxqVavqQIcZ6V72QyBLg',\\n                     user_agent='Prawlingv1')\\n\\n\\n# choose the subreddit to extract data from\\nsubreddit = \\\"${subreddit}\\\"\\nlimit = ${limit}\\n\\n# get hot posts from the subreddit\\nhot_posts = get_hot_posts(reddit, subreddit, limit)\\n\\n# initialise a reddit data extractor object\\ndata_extractor = RedditPostDataExtractor()\\n\\n# extract data from the hot posts from r/singapore\\ndata = data_extractor.extract_data(hot_posts)\\n\\nwith open(\\\"/local_storage/reddit/in/${system.workflow.instance.id}-${system.datetime}.json\\\", \\\"w\\\") as fp:\\n    json.dump(data, fp, indent=4)\",\"resourceList\":[]}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "GNEWS_HOME" : {
      "prop" : "GNEWS_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/google_news"
    },
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "Extract Reddit Data"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240514"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "4013"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13045662268160"
    },
    "subreddit" : {
      "prop" : "subreddit",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "singapore"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240514104516"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1112"
    },
    "limit" : {
      "prop" : "limit",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "3"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240513"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "extract_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13045665829504"
    }
  },
  "taskAppId" : "1112_4013",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-1112][TI-4013] - [INFO] 2024-05-14 10:45:16.867 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-1112][TI-4013] - [INFO] 2024-05-14 10:45:16.868 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-1112][TI-4013] - [INFO] 2024-05-14 10:45:16.868 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-1112][TI-4013] - [INFO] 2024-05-14 10:45:17.039 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-1112][TI-4013] - [INFO] 2024-05-14 10:45:17.090 +0800 o.a.d.c.u.OSUtils:[231] - create linux os user: default
[WI-1112][TI-4013] - [INFO] 2024-05-14 10:45:17.091 +0800 o.a.d.c.u.OSUtils:[233] - execute cmd: sudo useradd -g root
 default
[WI-0][TI-0] - [INFO] 2024-05-14 10:45:17.126 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8777777777777778 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-1112][TI-4013] - [INFO] 2024-05-14 10:45:17.343 +0800 o.a.d.c.u.OSUtils:[190] - create user default success
[WI-1112][TI-4013] - [INFO] 2024-05-14 10:45:17.345 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-1112][TI-4013] - [INFO] 2024-05-14 10:45:17.352 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13045665829504_20/1112/4013 check successfully
[WI-1112][TI-4013] - [INFO] 2024-05-14 10:45:17.354 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.python.PythonTaskChannel successfully
[WI-1112][TI-4013] - [INFO] 2024-05-14 10:45:17.368 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-1112][TI-4013] - [INFO] 2024-05-14 10:45:17.382 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-1112][TI-4013] - [INFO] 2024-05-14 10:45:17.385 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: PYTHON create successfully
[WI-1112][TI-4013] - [INFO] 2024-05-14 10:45:17.403 +0800 o.a.d.p.t.p.PythonTask:[75] - Initialize python task params {
  "localParams" : [ ],
  "varPool" : null,
  "rawScript" : "import praw\nimport json\n\nclass RedditPostDataExtractor:\n    def __init__(self):\n        self.data = []\n\n    def extract_data(self, hot_posts):\n        if hot_posts:\n            for post in hot_posts:\n                post.comments.replace_more(limit=None)\n                # initialise a dictionary to contain the data of the post\n                post_data = {}\n\n                # get the relevant post's data and store it inside post_data\n\n                # get the poster's name\n                if post.author is not None:\n                    post_data['author'] = post.author.name\n                else:\n                    post_data['author'] = '[deleted]' # if the user was deleted, post.author will return None. This line will catch that scenario and instead provide the value 'deleted'\n\n                # get the unix time in which the post was created\n                post_data['unix_time'] = post.created_utc\n                post_data['permalink'] = post.permalink\n                post_data['score'] = post.score\n                post_data['post_title'] = post.title\n                post_data['body'] = post.selftext\n\n                # get the unique name of the post (name refers to the id of the post prefixed with t3_)\n                # t3 represents that it is a post\n                post_data['name'] = post.name\n\n                # store the posts data in the dictionary where the name is used as the key\n                self.data.append(post_data)\n\n                # extract the comments from the post\n                comments = post.comments.list()\n\n                # extract the data in the comments and store them inside the dictionary\n                self.extract_comments_data(comments)\n        \n        return self.data\n\n    def extract_comments_data(self, comments):\n        if comments:\n            for comment in comments:\n                # initialise a dictionary to contain the data of the comment\n                comment_data = {}\n\n\n                # get the relevant post's data and store it inside post_data\n\n                # get the commenter name\n                if comment.author is not None:\n                    comment_data['author'] = comment.author.name\n                else:\n                    comment_data['author'] = '[deleted]' # if the user was deleted, comment.author will return None, this line will catch that scenario and instead provide the value 'deleted'\n\n                # get the unix time in which the comment was created\n                comment_data['unix_time'] = comment.created_utc\n                comment_data['permalink'] = comment.permalink\n                comment_data['score'] = comment.score\n                comment_data['post_title'] = comment.submission.title\n                comment_data['body'] = comment.body\n\n                # get the unique name of the comment (name refers to the id of the post prefixed with t1_)\n                # t1 represents that it is a post\n                comment_data['name'] = comment.name\n\n                # store the comment's data in the dictionary where the name is used as the key\n                self.data.append(comment_data)\n\n                # extract the comment's replies from the post\n                # replies = comment.replies\n\n                # extract the data in the comments and store them inside the dictionary\n                # self.extract_comments_data(replies)\n        \n        return\n    \ndef get_hot_posts(reddit_instance, subreddit_name, limit):\n    # Define the subreddit\n    subreddit = reddit_instance.subreddit(subreddit_name)\n\n    # Get hot posts from the subreddit\n    hot_posts = subreddit.hot(limit=limit)\n\n    # Filter out posts that are not pinned\n    filtered_posts = [post for post in hot_posts if not post.stickied]\n    return filtered_posts\n\n\n# initialize Reddit instance\nreddit = praw.Reddit(client_id='hM2BAD8XKakgkVdR2V2S-Q',\n                     client_secret='dWBfOf7Ed2WxqVavqQIcZ6V72QyBLg',\n                     user_agent='Prawlingv1')\n\n\n# choose the subreddit to extract data from\nsubreddit = \"${subreddit}\"\nlimit = ${limit}\n\n# get hot posts from the subreddit\nhot_posts = get_hot_posts(reddit, subreddit, limit)\n\n# initialise a reddit data extractor object\ndata_extractor = RedditPostDataExtractor()\n\n# extract data from the hot posts from r/singapore\ndata = data_extractor.extract_data(hot_posts)\n\nwith open(\"/local_storage/reddit/in/${system.workflow.instance.id}-${system.datetime}.json\", \"w\") as fp:\n    json.dump(data, fp, indent=4)",
  "resourceList" : [ ]
}
[WI-1112][TI-4013] - [INFO] 2024-05-14 10:45:17.404 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-1112][TI-4013] - [INFO] 2024-05-14 10:45:17.404 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: null successfully
[WI-1112][TI-4013] - [INFO] 2024-05-14 10:45:17.410 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-1112][TI-4013] - [INFO] 2024-05-14 10:45:17.411 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-1112][TI-4013] - [INFO] 2024-05-14 10:45:17.411 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-1112][TI-4013] - [INFO] 2024-05-14 10:45:17.412 +0800 o.a.d.p.t.p.PythonTask:[165] - raw python script : import praw
import json

class RedditPostDataExtractor:
    def __init__(self):
        self.data = []

    def extract_data(self, hot_posts):
        if hot_posts:
            for post in hot_posts:
                post.comments.replace_more(limit=None)
                # initialise a dictionary to contain the data of the post
                post_data = {}

                # get the relevant post's data and store it inside post_data

                # get the poster's name
                if post.author is not None:
                    post_data['author'] = post.author.name
                else:
                    post_data['author'] = '[deleted]' # if the user was deleted, post.author will return None. This line will catch that scenario and instead provide the value 'deleted'

                # get the unix time in which the post was created
                post_data['unix_time'] = post.created_utc
                post_data['permalink'] = post.permalink
                post_data['score'] = post.score
                post_data['post_title'] = post.title
                post_data['body'] = post.selftext

                # get the unique name of the post (name refers to the id of the post prefixed with t3_)
                # t3 represents that it is a post
                post_data['name'] = post.name

                # store the posts data in the dictionary where the name is used as the key
                self.data.append(post_data)

                # extract the comments from the post
                comments = post.comments.list()

                # extract the data in the comments and store them inside the dictionary
                self.extract_comments_data(comments)
        
        return self.data

    def extract_comments_data(self, comments):
        if comments:
            for comment in comments:
                # initialise a dictionary to contain the data of the comment
                comment_data = {}


                # get the relevant post's data and store it inside post_data

                # get the commenter name
                if comment.author is not None:
                    comment_data['author'] = comment.author.name
                else:
                    comment_data['author'] = '[deleted]' # if the user was deleted, comment.author will return None, this line will catch that scenario and instead provide the value 'deleted'

                # get the unix time in which the comment was created
                comment_data['unix_time'] = comment.created_utc
                comment_data['permalink'] = comment.permalink
                comment_data['score'] = comment.score
                comment_data['post_title'] = comment.submission.title
                comment_data['body'] = comment.body

                # get the unique name of the comment (name refers to the id of the post prefixed with t1_)
                # t1 represents that it is a post
                comment_data['name'] = comment.name

                # store the comment's data in the dictionary where the name is used as the key
                self.data.append(comment_data)

                # extract the comment's replies from the post
                # replies = comment.replies

                # extract the data in the comments and store them inside the dictionary
                # self.extract_comments_data(replies)
        
        return
    
def get_hot_posts(reddit_instance, subreddit_name, limit):
    # Define the subreddit
    subreddit = reddit_instance.subreddit(subreddit_name)

    # Get hot posts from the subreddit
    hot_posts = subreddit.hot(limit=limit)

    # Filter out posts that are not pinned
    filtered_posts = [post for post in hot_posts if not post.stickied]
    return filtered_posts


# initialize Reddit instance
reddit = praw.Reddit(client_id='hM2BAD8XKakgkVdR2V2S-Q',
                     client_secret='dWBfOf7Ed2WxqVavqQIcZ6V72QyBLg',
                     user_agent='Prawlingv1')


# choose the subreddit to extract data from
subreddit = "${subreddit}"
limit = ${limit}

# get hot posts from the subreddit
hot_posts = get_hot_posts(reddit, subreddit, limit)

# initialise a reddit data extractor object
data_extractor = RedditPostDataExtractor()

# extract data from the hot posts from r/singapore
data = data_extractor.extract_data(hot_posts)

with open("/local_storage/reddit/in/${system.workflow.instance.id}-${system.datetime}.json", "w") as fp:
    json.dump(data, fp, indent=4)
[WI-1112][TI-4013] - [INFO] 2024-05-14 10:45:17.419 +0800 o.a.d.p.t.p.PythonTask:[131] - tenantCode :default, task dir:/tmp/dolphinscheduler/exec/process/default/13010050770016/13045665829504_20/1112/4013
[WI-1112][TI-4013] - [INFO] 2024-05-14 10:45:17.421 +0800 o.a.d.p.t.p.PythonTask:[134] - generate python script file:/tmp/dolphinscheduler/exec/process/default/13010050770016/13045665829504_20/1112/4013/py_1112_4013.py
[WI-1112][TI-4013] - [INFO] 2024-05-14 10:45:17.421 +0800 o.a.d.p.t.p.PythonTask:[141] - #-*- encoding=utf8 -*-

import praw
import json

class RedditPostDataExtractor:
    def __init__(self):
        self.data = []

    def extract_data(self, hot_posts):
        if hot_posts:
            for post in hot_posts:
                post.comments.replace_more(limit=None)
                # initialise a dictionary to contain the data of the post
                post_data = {}

                # get the relevant post's data and store it inside post_data

                # get the poster's name
                if post.author is not None:
                    post_data['author'] = post.author.name
                else:
                    post_data['author'] = '[deleted]' # if the user was deleted, post.author will return None. This line will catch that scenario and instead provide the value 'deleted'

                # get the unix time in which the post was created
                post_data['unix_time'] = post.created_utc
                post_data['permalink'] = post.permalink
                post_data['score'] = post.score
                post_data['post_title'] = post.title
                post_data['body'] = post.selftext

                # get the unique name of the post (name refers to the id of the post prefixed with t3_)
                # t3 represents that it is a post
                post_data['name'] = post.name

                # store the posts data in the dictionary where the name is used as the key
                self.data.append(post_data)

                # extract the comments from the post
                comments = post.comments.list()

                # extract the data in the comments and store them inside the dictionary
                self.extract_comments_data(comments)
        
        return self.data

    def extract_comments_data(self, comments):
        if comments:
            for comment in comments:
                # initialise a dictionary to contain the data of the comment
                comment_data = {}


                # get the relevant post's data and store it inside post_data

                # get the commenter name
                if comment.author is not None:
                    comment_data['author'] = comment.author.name
                else:
                    comment_data['author'] = '[deleted]' # if the user was deleted, comment.author will return None, this line will catch that scenario and instead provide the value 'deleted'

                # get the unix time in which the comment was created
                comment_data['unix_time'] = comment.created_utc
                comment_data['permalink'] = comment.permalink
                comment_data['score'] = comment.score
                comment_data['post_title'] = comment.submission.title
                comment_data['body'] = comment.body

                # get the unique name of the comment (name refers to the id of the post prefixed with t1_)
                # t1 represents that it is a post
                comment_data['name'] = comment.name

                # store the comment's data in the dictionary where the name is used as the key
                self.data.append(comment_data)

                # extract the comment's replies from the post
                # replies = comment.replies

                # extract the data in the comments and store them inside the dictionary
                # self.extract_comments_data(replies)
        
        return
    
def get_hot_posts(reddit_instance, subreddit_name, limit):
    # Define the subreddit
    subreddit = reddit_instance.subreddit(subreddit_name)

    # Get hot posts from the subreddit
    hot_posts = subreddit.hot(limit=limit)

    # Filter out posts that are not pinned
    filtered_posts = [post for post in hot_posts if not post.stickied]
    return filtered_posts


# initialize Reddit instance
reddit = praw.Reddit(client_id='hM2BAD8XKakgkVdR2V2S-Q',
                     client_secret='dWBfOf7Ed2WxqVavqQIcZ6V72QyBLg',
                     user_agent='Prawlingv1')


# choose the subreddit to extract data from
subreddit = "singapore"
limit = 3

# get hot posts from the subreddit
hot_posts = get_hot_posts(reddit, subreddit, limit)

# initialise a reddit data extractor object
data_extractor = RedditPostDataExtractor()

# extract data from the hot posts from r/singapore
data = data_extractor.extract_data(hot_posts)

with open("/local_storage/reddit/in/1112-20240514104516.json", "w") as fp:
    json.dump(data, fp, indent=4)
[WI-1112][TI-4013] - [INFO] 2024-05-14 10:45:17.448 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-1112][TI-4013] - [INFO] 2024-05-14 10:45:17.448 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-1112][TI-4013] - [INFO] 2024-05-14 10:45:17.449 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export PYTHON_LAUNCHER=/bin/python3.11
${PYTHON_LAUNCHER} /tmp/dolphinscheduler/exec/process/default/13010050770016/13045665829504_20/1112/4013/py_1112_4013.py
[WI-1112][TI-4013] - [INFO] 2024-05-14 10:45:17.449 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-1112][TI-4013] - [INFO] 2024-05-14 10:45:17.450 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13045665829504_20/1112/4013/1112_4013.sh
[WI-1112][TI-4013] - [INFO] 2024-05-14 10:45:17.470 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 447
[WI-0][TI-4013] - [INFO] 2024-05-14 10:45:17.502 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=4013, success=true)
[WI-0][TI-4013] - [INFO] 2024-05-14 10:45:17.519 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=4013)
[WI-0][TI-0] - [INFO] 2024-05-14 10:45:18.161 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8537234042553191 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 10:45:18.477 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
[WI-0][TI-0] - [INFO] 2024-05-14 10:45:19.171 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.778688524590164 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-1112][TI-4013] - [INFO] 2024-05-14 10:45:21.481 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13045665829504_20/1112/4013, processId:447 ,exitStatusCode:0 ,processWaitForStatus:true ,processExitValue:0
[WI-1112][TI-4013] - [INFO] 2024-05-14 10:45:21.483 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-1112][TI-4013] - [INFO] 2024-05-14 10:45:21.483 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-1112][TI-4013] - [INFO] 2024-05-14 10:45:21.484 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-1112][TI-4013] - [INFO] 2024-05-14 10:45:21.485 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-1112][TI-4013] - [INFO] 2024-05-14 10:45:21.503 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: SUCCESS to master : 172.18.1.1:1234
[WI-1112][TI-4013] - [INFO] 2024-05-14 10:45:21.504 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-1112][TI-4013] - [INFO] 2024-05-14 10:45:21.505 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13045665829504_20/1112/4013
[WI-1112][TI-4013] - [INFO] 2024-05-14 10:45:21.528 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13045665829504_20/1112/4013
[WI-1112][TI-4013] - [INFO] 2024-05-14 10:45:21.532 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-4013] - [INFO] 2024-05-14 10:45:22.466 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=4013, success=true)
[WI-0][TI-0] - [INFO] 2024-05-14 10:45:30.209 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7114285714285714 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 10:45:31.223 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7787273984784112 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 10:45:44.517 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7208672086720866 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 10:51:04.620 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7960893854748603 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 10:52:56.822 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7219101123595505 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 10:52:57.852 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.726775956284153 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 10:53:13.909 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.773224043715847 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 10:53:14.923 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7586206896551725 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 10:55:53.737 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7289719626168224 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 10:56:01.790 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.771186440677966 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 10:56:53.994 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7115384615384616 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-05-14 10:57:03.025 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7118055555555556 is over then the MaxCpuUsagePercentageThresholds 0.7
