[WI-0][TI-0] - [INFO] 2024-04-22 18:04:07.655 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7215909090909091 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-22 18:04:08.682 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7175141242937852 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-22 18:04:39.859 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=950, taskName=search for intake JSON files, firstSubmitTime=1713780279843, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.11:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=66, appIds=null, processInstanceId=407, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"processing"}], executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":""},{"prop":"raw_file","direct":"OUT","type":"VARCHAR","value":""}],"rawScript":"# find 1 raw file in the folder\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\nraw_file=null\n\n# check if raw_file_dir is empty, then set raw_file_dir and raw_file to empty strings\nif [ -z \"$raw_file_dir\" ]; then\n    raw_file_dir=null\nelse\n    raw_file=$(basename \"$raw_file_dir\")\nfi\n\necho \"#{setValue(raw_file_dir=${raw_file_dir})}\"\necho \"#{setValue(raw_file=${raw_file})}\"","resourceList":[]}, environmentConfig=export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='search for intake JSON files'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240422'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='950'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13340113777664'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240422180439'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='processing'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='407'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240421'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=null, dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-407][TI-950] - [INFO] 2024-04-22 18:04:39.862 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: search for intake JSON files to wait queue success
[WI-407][TI-950] - [INFO] 2024-04-22 18:04:39.862 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-407][TI-950] - [INFO] 2024-04-22 18:04:39.865 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-407][TI-950] - [INFO] 2024-04-22 18:04:39.865 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-407][TI-950] - [INFO] 2024-04-22 18:04:39.865 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-407][TI-950] - [INFO] 2024-04-22 18:04:39.865 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713780279865
[WI-407][TI-950] - [INFO] 2024-04-22 18:04:39.865 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 407_950
[WI-407][TI-950] - [INFO] 2024-04-22 18:04:39.865 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 950,
  "taskName" : "search for intake JSON files",
  "firstSubmitTime" : 1713780279843,
  "startTime" : 1713780279865,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.11:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240422/13201021801792/66/407/950.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 66,
  "processInstanceId" : 407,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"processing\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[{\"prop\":\"raw_file_dir\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"\"},{\"prop\":\"raw_file\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"\"}],\"rawScript\":\"# find 1 raw file in the folder\\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\\nraw_file=null\\n\\n# check if raw_file_dir is empty, then set raw_file_dir and raw_file to empty strings\\nif [ -z \\\"$raw_file_dir\\\" ]; then\\n    raw_file_dir=null\\nelse\\n    raw_file=$(basename \\\"$raw_file_dir\\\")\\nfi\\n\\necho \\\"#{setValue(raw_file_dir=${raw_file_dir})}\\\"\\necho \\\"#{setValue(raw_file=${raw_file})}\\\"\",\"resourceList\":[]}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "search for intake JSON files"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240422"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "950"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13340113777664"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240422180439"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "processing"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "407"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240421"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "407_950",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-407][TI-950] - [INFO] 2024-04-22 18:04:39.866 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-407][TI-950] - [INFO] 2024-04-22 18:04:39.872 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-407][TI-950] - [INFO] 2024-04-22 18:04:39.872 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-407][TI-950] - [INFO] 2024-04-22 18:04:39.891 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-407][TI-950] - [INFO] 2024-04-22 18:04:39.892 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-407][TI-950] - [INFO] 2024-04-22 18:04:39.893 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_66/407/950 check successfully
[WI-407][TI-950] - [INFO] 2024-04-22 18:04:39.893 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-407][TI-950] - [INFO] 2024-04-22 18:04:39.893 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-407][TI-950] - [INFO] 2024-04-22 18:04:39.893 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-407][TI-950] - [INFO] 2024-04-22 18:04:39.893 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-407][TI-950] - [INFO] 2024-04-22 18:04:39.893 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ {
    "prop" : "raw_file_dir",
    "direct" : "OUT",
    "type" : "VARCHAR",
    "value" : ""
  }, {
    "prop" : "raw_file",
    "direct" : "OUT",
    "type" : "VARCHAR",
    "value" : ""
  } ],
  "varPool" : null,
  "rawScript" : "# find 1 raw file in the folder\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\nraw_file=null\n\n# check if raw_file_dir is empty, then set raw_file_dir and raw_file to empty strings\nif [ -z \"$raw_file_dir\" ]; then\n    raw_file_dir=null\nelse\n    raw_file=$(basename \"$raw_file_dir\")\nfi\n\necho \"#{setValue(raw_file_dir=${raw_file_dir})}\"\necho \"#{setValue(raw_file=${raw_file})}\"",
  "resourceList" : [ ]
}
[WI-407][TI-950] - [INFO] 2024-04-22 18:04:39.894 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-407][TI-950] - [INFO] 2024-04-22 18:04:39.894 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: null successfully
[WI-407][TI-950] - [INFO] 2024-04-22 18:04:39.894 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-407][TI-950] - [INFO] 2024-04-22 18:04:39.894 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-407][TI-950] - [INFO] 2024-04-22 18:04:39.894 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-407][TI-950] - [INFO] 2024-04-22 18:04:39.894 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-407][TI-950] - [INFO] 2024-04-22 18:04:39.894 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-407][TI-950] - [INFO] 2024-04-22 18:04:39.895 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export PYTHON_LAUNCHER=/bin/python3.11
# find 1 raw file in the folder
raw_file_dir=$(find /local_storage/reddit/processing -type f -name '*.json'| head -n 1)
raw_file=null

# check if raw_file_dir is empty, then set raw_file_dir and raw_file to empty strings
if [ -z "$raw_file_dir" ]; then
    raw_file_dir=null
else
    raw_file=$(basename "$raw_file_dir")
fi

echo "#{setValue(raw_file_dir=${raw_file_dir})}"
echo "#{setValue(raw_file=${raw_file})}"
[WI-407][TI-950] - [INFO] 2024-04-22 18:04:39.895 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-407][TI-950] - [INFO] 2024-04-22 18:04:39.895 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_66/407/950/407_950.sh
[WI-407][TI-950] - [INFO] 2024-04-22 18:04:39.904 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 9126
[WI-0][TI-950] - [INFO] 2024-04-22 18:04:40.481 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=950, success=true)
[WI-0][TI-950] - [INFO] 2024-04-22 18:04:40.487 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=950)
[WI-0][TI-0] - [INFO] 2024-04-22 18:04:40.905 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
	#{setValue(raw_file_dir=/local_storage/reddit/processing/386-20240422.json)}
	#{setValue(raw_file=386-20240422.json)}
[WI-407][TI-950] - [INFO] 2024-04-22 18:04:40.925 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_66/407/950, processId:9126 ,exitStatusCode:0 ,processWaitForStatus:true ,processExitValue:0
[WI-407][TI-950] - [INFO] 2024-04-22 18:04:40.926 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-407][TI-950] - [INFO] 2024-04-22 18:04:40.926 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-407][TI-950] - [INFO] 2024-04-22 18:04:40.926 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-407][TI-950] - [INFO] 2024-04-22 18:04:40.926 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-407][TI-950] - [INFO] 2024-04-22 18:04:40.930 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: SUCCESS to master : 172.18.1.1:1234
[WI-407][TI-950] - [INFO] 2024-04-22 18:04:40.930 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-407][TI-950] - [INFO] 2024-04-22 18:04:40.930 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_66/407/950
[WI-407][TI-950] - [INFO] 2024-04-22 18:04:40.932 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_66/407/950
[WI-407][TI-950] - [INFO] 2024-04-22 18:04:40.932 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-950] - [INFO] 2024-04-22 18:04:41.487 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=950, success=true)
[WI-0][TI-0] - [INFO] 2024-04-22 18:04:42.576 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=952, taskName=move to processing, firstSubmitTime=1713780282570, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.11:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=66, appIds=null, processInstanceId=407, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"processing"}], executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[],"rawScript":"# move file to the reddit processing folder\n# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error\nif [\"${folder}\"!=\"processing\"]; then\n    mv ${raw_file_dir} ${REDDIT_HOME}/processing\nelse\n    echo JSON is already in processing\nfi","resourceList":[]}, environmentConfig=export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='move to processing'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240422'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='952'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13340390094208'}, raw_file=Property{prop='raw_file', direct=IN, type=VARCHAR, value='386-20240422.json'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240422180442'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='processing'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='407'}, raw_file_dir=Property{prop='raw_file_dir', direct=IN, type=VARCHAR, value='/local_storage/reddit/processing/386-20240422.json'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240421'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"},{"prop":"raw_file","direct":"IN","type":"VARCHAR","value":"386-20240422.json"}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-407][TI-952] - [INFO] 2024-04-22 18:04:42.577 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: move to processing to wait queue success
[WI-407][TI-952] - [INFO] 2024-04-22 18:04:42.578 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-407][TI-952] - [INFO] 2024-04-22 18:04:42.579 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-407][TI-952] - [INFO] 2024-04-22 18:04:42.579 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-407][TI-952] - [INFO] 2024-04-22 18:04:42.579 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-407][TI-952] - [INFO] 2024-04-22 18:04:42.579 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713780282579
[WI-407][TI-952] - [INFO] 2024-04-22 18:04:42.580 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 407_952
[WI-407][TI-952] - [INFO] 2024-04-22 18:04:42.580 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 952,
  "taskName" : "move to processing",
  "firstSubmitTime" : 1713780282570,
  "startTime" : 1713780282579,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.11:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240422/13201021801792/66/407/952.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 66,
  "processInstanceId" : 407,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"processing\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[],\"rawScript\":\"# move file to the reddit processing folder\\n# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error\\nif [\\\"${folder}\\\"!=\\\"processing\\\"]; then\\n    mv ${raw_file_dir} ${REDDIT_HOME}/processing\\nelse\\n    echo JSON is already in processing\\nfi\",\"resourceList\":[]}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "move to processing"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240422"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "952"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13340390094208"
    },
    "raw_file" : {
      "prop" : "raw_file",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "386-20240422.json"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240422180442"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "processing"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "407"
    },
    "raw_file_dir" : {
      "prop" : "raw_file_dir",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit/processing/386-20240422.json"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240421"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "407_952",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"raw_file_dir\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"/local_storage/reddit/processing/386-20240422.json\"},{\"prop\":\"raw_file\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"386-20240422.json\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-407][TI-952] - [INFO] 2024-04-22 18:04:42.581 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-407][TI-952] - [INFO] 2024-04-22 18:04:42.581 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-407][TI-952] - [INFO] 2024-04-22 18:04:42.581 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-407][TI-952] - [INFO] 2024-04-22 18:04:42.590 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-407][TI-952] - [INFO] 2024-04-22 18:04:42.590 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-407][TI-952] - [INFO] 2024-04-22 18:04:42.592 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_66/407/952 check successfully
[WI-407][TI-952] - [INFO] 2024-04-22 18:04:42.592 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-407][TI-952] - [INFO] 2024-04-22 18:04:42.593 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-407][TI-952] - [INFO] 2024-04-22 18:04:42.594 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-407][TI-952] - [INFO] 2024-04-22 18:04:42.594 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-407][TI-952] - [INFO] 2024-04-22 18:04:42.594 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ ],
  "varPool" : null,
  "rawScript" : "# move file to the reddit processing folder\n# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error\nif [\"${folder}\"!=\"processing\"]; then\n    mv ${raw_file_dir} ${REDDIT_HOME}/processing\nelse\n    echo JSON is already in processing\nfi",
  "resourceList" : [ ]
}
[WI-407][TI-952] - [INFO] 2024-04-22 18:04:42.594 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-407][TI-952] - [INFO] 2024-04-22 18:04:42.594 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"},{"prop":"raw_file","direct":"IN","type":"VARCHAR","value":"386-20240422.json"}] successfully
[WI-407][TI-952] - [INFO] 2024-04-22 18:04:42.595 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-407][TI-952] - [INFO] 2024-04-22 18:04:42.595 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-407][TI-952] - [INFO] 2024-04-22 18:04:42.595 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-407][TI-952] - [INFO] 2024-04-22 18:04:42.596 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-407][TI-952] - [INFO] 2024-04-22 18:04:42.597 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-407][TI-952] - [INFO] 2024-04-22 18:04:42.597 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export PYTHON_LAUNCHER=/bin/python3.11
# move file to the reddit processing folder
# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error
if ["processing"!="processing"]; then
    mv /local_storage/reddit/processing/386-20240422.json /local_storage/reddit/processing
else
    echo JSON is already in processing
fi
[WI-407][TI-952] - [INFO] 2024-04-22 18:04:42.597 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-407][TI-952] - [INFO] 2024-04-22 18:04:42.597 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_66/407/952/407_952.sh
[WI-407][TI-952] - [INFO] 2024-04-22 18:04:42.621 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 9141
[WI-0][TI-0] - [INFO] 2024-04-22 18:04:42.622 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
[WI-0][TI-952] - [INFO] 2024-04-22 18:04:43.499 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=952, success=true)
[WI-0][TI-952] - [INFO] 2024-04-22 18:04:43.505 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=952)
[WI-0][TI-0] - [INFO] 2024-04-22 18:04:43.633 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_66/407/952/407_952.sh: line 7: [processing!=processing]: command not found
	JSON is already in processing
[WI-407][TI-952] - [INFO] 2024-04-22 18:04:43.634 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_66/407/952, processId:9141 ,exitStatusCode:0 ,processWaitForStatus:true ,processExitValue:0
[WI-407][TI-952] - [INFO] 2024-04-22 18:04:43.635 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-407][TI-952] - [INFO] 2024-04-22 18:04:43.636 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-407][TI-952] - [INFO] 2024-04-22 18:04:43.637 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-407][TI-952] - [INFO] 2024-04-22 18:04:43.637 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-407][TI-952] - [INFO] 2024-04-22 18:04:43.642 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: SUCCESS to master : 172.18.1.1:1234
[WI-407][TI-952] - [INFO] 2024-04-22 18:04:43.643 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-407][TI-952] - [INFO] 2024-04-22 18:04:43.643 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_66/407/952
[WI-407][TI-952] - [INFO] 2024-04-22 18:04:43.645 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_66/407/952
[WI-407][TI-952] - [INFO] 2024-04-22 18:04:43.645 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-952] - [INFO] 2024-04-22 18:04:44.498 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=952, success=true)
[WI-0][TI-0] - [INFO] 2024-04-22 18:04:44.530 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=953, taskName=spark preprocessing, firstSubmitTime=1713780284524, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.11:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=66, appIds=null, processInstanceId=407, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"processing"}], executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[],"rawScript":"$SPARK_HOME/bin/spark-submit \\\n    --master spark://spark-master:7077 \\\n    --conf spark.driver.cores=1 \\\n    --conf spark.driver.memory=512M \\\n    --conf spark.executor.instances=2 \\\n    --conf spark.executor.cores=2 \\\n    --conf spark.executor.memory=1G \\\n    --files ${raw_file_dir}#raw_data.json \\\n    --name reddit_preprocessing spark_reddit_preprocessing.py\n","resourceList":[{"id":null,"resourceName":"file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py","res":null}]}, environmentConfig=export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export HADOOP_CONF_DIR=/opt/hadoop-3.4.0/etc/hadoop
export PYSPARK_DRIVER_PYTHON=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='spark preprocessing'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240422'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='953'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13210058002752'}, raw_file=Property{prop='raw_file', direct=IN, type=VARCHAR, value='386-20240422.json'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240422180444'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='processing'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='407'}, raw_file_dir=Property{prop='raw_file_dir', direct=IN, type=VARCHAR, value='/local_storage/reddit/processing/386-20240422.json'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240421'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"},{"prop":"raw_file","direct":"IN","type":"VARCHAR","value":"386-20240422.json"}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-407][TI-953] - [INFO] 2024-04-22 18:04:44.532 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: spark preprocessing to wait queue success
[WI-407][TI-953] - [INFO] 2024-04-22 18:04:44.532 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-407][TI-953] - [INFO] 2024-04-22 18:04:44.533 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-407][TI-953] - [INFO] 2024-04-22 18:04:44.533 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-407][TI-953] - [INFO] 2024-04-22 18:04:44.533 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-407][TI-953] - [INFO] 2024-04-22 18:04:44.534 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713780284534
[WI-407][TI-953] - [INFO] 2024-04-22 18:04:44.534 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 407_953
[WI-407][TI-953] - [INFO] 2024-04-22 18:04:44.534 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 953,
  "taskName" : "spark preprocessing",
  "firstSubmitTime" : 1713780284524,
  "startTime" : 1713780284534,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.11:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240422/13201021801792/66/407/953.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 66,
  "processInstanceId" : 407,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"processing\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[],\"rawScript\":\"$SPARK_HOME/bin/spark-submit \\\\\\n    --master spark://spark-master:7077 \\\\\\n    --conf spark.driver.cores=1 \\\\\\n    --conf spark.driver.memory=512M \\\\\\n    --conf spark.executor.instances=2 \\\\\\n    --conf spark.executor.cores=2 \\\\\\n    --conf spark.executor.memory=1G \\\\\\n    --files ${raw_file_dir}#raw_data.json \\\\\\n    --name reddit_preprocessing spark_reddit_preprocessing.py\\n\",\"resourceList\":[{\"id\":null,\"resourceName\":\"file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py\",\"res\":null}]}",
  "environmentConfig" : "export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3\nexport JAVA_HOME=/opt/java/openjdk\nexport HADOOP_CONF_DIR=/opt/hadoop-3.4.0/etc/hadoop\nexport PYSPARK_DRIVER_PYTHON=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "spark preprocessing"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240422"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "953"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13210058002752"
    },
    "raw_file" : {
      "prop" : "raw_file",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "386-20240422.json"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240422180444"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "processing"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "407"
    },
    "raw_file_dir" : {
      "prop" : "raw_file_dir",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit/processing/386-20240422.json"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240421"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "407_953",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"raw_file_dir\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"/local_storage/reddit/processing/386-20240422.json\"},{\"prop\":\"raw_file\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"386-20240422.json\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-407][TI-953] - [INFO] 2024-04-22 18:04:44.535 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-407][TI-953] - [INFO] 2024-04-22 18:04:44.535 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-407][TI-953] - [INFO] 2024-04-22 18:04:44.535 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-407][TI-953] - [INFO] 2024-04-22 18:04:44.541 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-407][TI-953] - [INFO] 2024-04-22 18:04:44.542 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-407][TI-953] - [INFO] 2024-04-22 18:04:44.543 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_66/407/953 check successfully
[WI-407][TI-953] - [INFO] 2024-04-22 18:04:44.543 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-407][TI-953] - [INFO] 2024-04-22 18:04:44.546 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py=ResourceContext.ResourceItem(resourceAbsolutePathInStorage=file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py, resourceRelativePath=spark_reddit_preprocessing.py, resourceAbsolutePathInLocal=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_66/407/953/spark_reddit_preprocessing.py)})
[WI-407][TI-953] - [INFO] 2024-04-22 18:04:44.547 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-407][TI-953] - [INFO] 2024-04-22 18:04:44.547 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-407][TI-953] - [INFO] 2024-04-22 18:04:44.561 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ ],
  "varPool" : null,
  "rawScript" : "$SPARK_HOME/bin/spark-submit \\\n    --master spark://spark-master:7077 \\\n    --conf spark.driver.cores=1 \\\n    --conf spark.driver.memory=512M \\\n    --conf spark.executor.instances=2 \\\n    --conf spark.executor.cores=2 \\\n    --conf spark.executor.memory=1G \\\n    --files ${raw_file_dir}#raw_data.json \\\n    --name reddit_preprocessing spark_reddit_preprocessing.py\n",
  "resourceList" : [ {
    "id" : null,
    "resourceName" : "file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py",
    "res" : null
  } ]
}
[WI-407][TI-953] - [INFO] 2024-04-22 18:04:44.561 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-407][TI-953] - [INFO] 2024-04-22 18:04:44.562 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"},{"prop":"raw_file","direct":"IN","type":"VARCHAR","value":"386-20240422.json"}] successfully
[WI-407][TI-953] - [INFO] 2024-04-22 18:04:44.563 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-407][TI-953] - [INFO] 2024-04-22 18:04:44.563 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-407][TI-953] - [INFO] 2024-04-22 18:04:44.563 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-407][TI-953] - [INFO] 2024-04-22 18:04:44.564 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-407][TI-953] - [INFO] 2024-04-22 18:04:44.565 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-407][TI-953] - [INFO] 2024-04-22 18:04:44.565 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export HADOOP_CONF_DIR=/opt/hadoop-3.4.0/etc/hadoop
export PYSPARK_DRIVER_PYTHON=/bin/python3.11
$SPARK_HOME/bin/spark-submit \
    --master spark://spark-master:7077 \
    --conf spark.driver.cores=1 \
    --conf spark.driver.memory=512M \
    --conf spark.executor.instances=2 \
    --conf spark.executor.cores=2 \
    --conf spark.executor.memory=1G \
    --files /local_storage/reddit/processing/386-20240422.json#raw_data.json \
    --name reddit_preprocessing spark_reddit_preprocessing.py

[WI-407][TI-953] - [INFO] 2024-04-22 18:04:44.566 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-407][TI-953] - [INFO] 2024-04-22 18:04:44.566 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_66/407/953/407_953.sh
[WI-407][TI-953] - [INFO] 2024-04-22 18:04:44.570 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 9152
[WI-0][TI-953] - [INFO] 2024-04-22 18:04:45.504 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=953, success=true)
[WI-0][TI-953] - [INFO] 2024-04-22 18:04:45.512 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=953)
[WI-0][TI-0] - [INFO] 2024-04-22 18:04:45.571 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
[WI-0][TI-0] - [INFO] 2024-04-22 18:04:47.601 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/22 18:04:46 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[WI-0][TI-0] - [INFO] 2024-04-22 18:04:47.821 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8267045454545454 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-22 18:04:48.605 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/22 18:04:47 INFO SparkContext: Running Spark version 3.5.1
	24/04/22 18:04:47 INFO SparkContext: OS info Linux, 6.5.0-28-generic, amd64
	24/04/22 18:04:47 INFO SparkContext: Java version 1.8.0_402
	24/04/22 18:04:47 INFO ResourceUtils: ==============================================================
	24/04/22 18:04:47 INFO ResourceUtils: No custom resources configured for spark.driver.
	24/04/22 18:04:47 INFO ResourceUtils: ==============================================================
	24/04/22 18:04:47 INFO SparkContext: Submitted application: reddit_preprocessing
	24/04/22 18:04:47 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 2, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
	24/04/22 18:04:48 INFO ResourceProfile: Limiting resource is cpus at 2 tasks per executor
	24/04/22 18:04:48 INFO ResourceProfileManager: Added ResourceProfile id: 0
	24/04/22 18:04:48 INFO SecurityManager: Changing view acls to: default
	24/04/22 18:04:48 INFO SecurityManager: Changing modify acls to: default
	24/04/22 18:04:48 INFO SecurityManager: Changing view acls groups to: 
	24/04/22 18:04:48 INFO SecurityManager: Changing modify acls groups to: 
	24/04/22 18:04:48 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: default; groups with view permissions: EMPTY; users with modify permissions: default; groups with modify permissions: EMPTY
	24/04/22 18:04:48 INFO Utils: Successfully started service 'sparkDriver' on port 35381.
[WI-0][TI-0] - [INFO] 2024-04-22 18:04:48.840 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.815261044176707 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-22 18:04:49.608 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/22 18:04:48 INFO SparkEnv: Registering MapOutputTracker
	24/04/22 18:04:48 INFO SparkEnv: Registering BlockManagerMaster
	24/04/22 18:04:48 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
	24/04/22 18:04:48 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
	24/04/22 18:04:48 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
	24/04/22 18:04:48 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-5e09449c-fd5f-47f7-ac20-2d4ad38c0220
	24/04/22 18:04:49 INFO MemoryStore: MemoryStore started with capacity 93.3 MiB
	24/04/22 18:04:49 INFO SparkEnv: Registering OutputCommitCoordinator
	24/04/22 18:04:49 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
	24/04/22 18:04:49 INFO Utils: Successfully started service 'SparkUI' on port 4040.
	24/04/22 18:04:49 INFO SparkContext: Added file file:///local_storage/reddit/processing/386-20240422.json#raw_data.json at spark://868412aff9d6:35381/files/386-20240422.json with timestamp 1713780287860
	24/04/22 18:04:49 ERROR SparkContext: Error initializing SparkContext.
	java.lang.IllegalArgumentException: URI has a fragment component
		at java.io.File.<init>(File.java:427)
		at org.apache.spark.util.Utils$.doFetchFile(Utils.scala:724)
		at org.apache.spark.util.Utils$.fetchFile(Utils.scala:467)
		at org.apache.spark.SparkContext.addFile(SparkContext.scala:1795)
		at org.apache.spark.SparkContext.$anonfun$new$16(SparkContext.scala:533)
		at org.apache.spark.SparkContext.$anonfun$new$16$adapted(SparkContext.scala:533)
		at scala.collection.immutable.List.foreach(List.scala:431)
		at org.apache.spark.SparkContext.<init>(SparkContext.scala:533)
		at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)
		at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
		at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
		at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
		at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
		at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)
		at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
		at py4j.Gateway.invoke(Gateway.java:238)
		at py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)
		at py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)
		at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
		at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
		at java.lang.Thread.run(Thread.java:750)
	24/04/22 18:04:49 INFO SparkContext: SparkContext is stopping with exitCode 0.
	24/04/22 18:04:49 INFO SparkUI: Stopped Spark web UI at http://868412aff9d6:4040
[WI-0][TI-0] - [INFO] 2024-04-22 18:04:49.877 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8269708974293014 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-22 18:04:50.615 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/22 18:04:49 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
	24/04/22 18:04:49 INFO MemoryStore: MemoryStore cleared
	24/04/22 18:04:49 INFO BlockManager: BlockManager stopped
	24/04/22 18:04:49 INFO BlockManagerMaster: BlockManagerMaster stopped
	24/04/22 18:04:49 WARN MetricsSystem: Stopping a MetricsSystem that is not running
	24/04/22 18:04:49 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
	24/04/22 18:04:49 INFO SparkContext: Successfully stopped SparkContext
	Traceback (most recent call last):
	  File "/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_66/407/953/spark_reddit_preprocessing.py", line 23, in <module>
	    sc = pyspark.SparkContext(appName="reddit_preprocessing")
	         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
	  File "/opt/spark-3.5.1-bin-hadoop3/python/lib/pyspark.zip/pyspark/context.py", line 203, in __init__
	  File "/opt/spark-3.5.1-bin-hadoop3/python/lib/pyspark.zip/pyspark/context.py", line 296, in _do_init
	  File "/opt/spark-3.5.1-bin-hadoop3/python/lib/pyspark.zip/pyspark/context.py", line 421, in _initialize_context
	  File "/opt/spark-3.5.1-bin-hadoop3/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1587, in __call__
	  File "/opt/spark-3.5.1-bin-hadoop3/python/lib/py4j-0.10.9.7-src.zip/py4j/protocol.py", line 326, in get_return_value
	py4j.protocol.Py4JJavaError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext.
	: java.lang.IllegalArgumentException: URI has a fragment component
		at java.io.File.<init>(File.java:427)
		at org.apache.spark.util.Utils$.doFetchFile(Utils.scala:724)
		at org.apache.spark.util.Utils$.fetchFile(Utils.scala:467)
		at org.apache.spark.SparkContext.addFile(SparkContext.scala:1795)
		at org.apache.spark.SparkContext.$anonfun$new$16(SparkContext.scala:533)
		at org.apache.spark.SparkContext.$anonfun$new$16$adapted(SparkContext.scala:533)
		at scala.collection.immutable.List.foreach(List.scala:431)
		at org.apache.spark.SparkContext.<init>(SparkContext.scala:533)
		at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)
		at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
		at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
		at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
		at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
		at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)
		at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
		at py4j.Gateway.invoke(Gateway.java:238)
		at py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)
		at py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)
		at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
		at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
		at java.lang.Thread.run(Thread.java:750)
	
	24/04/22 18:04:49 INFO ShutdownHookManager: Shutdown hook called
	24/04/22 18:04:49 INFO ShutdownHookManager: Deleting directory /tmp/spark-e2a5c551-bea3-47b0-a2c5-36df6a42bb42
	24/04/22 18:04:49 INFO ShutdownHookManager: Deleting directory /tmp/spark-137ce9ff-a259-46fc-ba9c-e68749b54f1f
[WI-407][TI-953] - [INFO] 2024-04-22 18:04:50.617 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_66/407/953, processId:9152 ,exitStatusCode:1 ,processWaitForStatus:true ,processExitValue:1
[WI-407][TI-953] - [INFO] 2024-04-22 18:04:50.619 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-407][TI-953] - [INFO] 2024-04-22 18:04:50.620 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-407][TI-953] - [INFO] 2024-04-22 18:04:50.620 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-407][TI-953] - [INFO] 2024-04-22 18:04:50.620 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-407][TI-953] - [INFO] 2024-04-22 18:04:50.623 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: FAILURE to master : 172.18.1.1:1234
[WI-407][TI-953] - [INFO] 2024-04-22 18:04:50.624 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-407][TI-953] - [INFO] 2024-04-22 18:04:50.625 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_66/407/953
[WI-407][TI-953] - [INFO] 2024-04-22 18:04:50.625 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_66/407/953
[WI-407][TI-953] - [INFO] 2024-04-22 18:04:50.626 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-953] - [INFO] 2024-04-22 18:04:51.524 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=953, success=true)
[WI-0][TI-0] - [INFO] 2024-04-22 18:05:00.921 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8204419889502762 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-22 18:06:42.513 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7331378299120235 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-22 18:06:50.416 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=954, taskName=search for intake JSON files, firstSubmitTime=1713780410410, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.11:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=67, appIds=null, processInstanceId=408, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"processing"}], executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":""},{"prop":"raw_file","direct":"OUT","type":"VARCHAR","value":""}],"rawScript":"# find 1 raw file in the folder\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\nraw_file=null\n\n# check if raw_file_dir is empty, then set raw_file_dir and raw_file to empty strings\nif [ -z \"$raw_file_dir\" ]; then\n    raw_file_dir=null\nelse\n    raw_file=$(basename \"$raw_file_dir\")\nfi\n\necho \"#{setValue(raw_file_dir=${raw_file_dir})}\"\necho \"#{setValue(raw_file=${raw_file})}\"","resourceList":[]}, environmentConfig=export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='search for intake JSON files'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240422'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='954'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13340113777664'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240422180650'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='processing'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='408'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240421'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=null, dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-408][TI-954] - [INFO] 2024-04-22 18:06:50.418 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: search for intake JSON files to wait queue success
[WI-408][TI-954] - [INFO] 2024-04-22 18:06:50.418 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-408][TI-954] - [INFO] 2024-04-22 18:06:50.425 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-408][TI-954] - [INFO] 2024-04-22 18:06:50.425 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-408][TI-954] - [INFO] 2024-04-22 18:06:50.425 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-408][TI-954] - [INFO] 2024-04-22 18:06:50.425 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713780410425
[WI-408][TI-954] - [INFO] 2024-04-22 18:06:50.425 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 408_954
[WI-408][TI-954] - [INFO] 2024-04-22 18:06:50.426 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 954,
  "taskName" : "search for intake JSON files",
  "firstSubmitTime" : 1713780410410,
  "startTime" : 1713780410425,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.11:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240422/13201021801792/67/408/954.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 67,
  "processInstanceId" : 408,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"processing\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[{\"prop\":\"raw_file_dir\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"\"},{\"prop\":\"raw_file\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"\"}],\"rawScript\":\"# find 1 raw file in the folder\\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\\nraw_file=null\\n\\n# check if raw_file_dir is empty, then set raw_file_dir and raw_file to empty strings\\nif [ -z \\\"$raw_file_dir\\\" ]; then\\n    raw_file_dir=null\\nelse\\n    raw_file=$(basename \\\"$raw_file_dir\\\")\\nfi\\n\\necho \\\"#{setValue(raw_file_dir=${raw_file_dir})}\\\"\\necho \\\"#{setValue(raw_file=${raw_file})}\\\"\",\"resourceList\":[]}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "search for intake JSON files"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240422"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "954"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13340113777664"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240422180650"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "processing"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "408"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240421"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "408_954",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-408][TI-954] - [INFO] 2024-04-22 18:06:50.426 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-408][TI-954] - [INFO] 2024-04-22 18:06:50.426 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-408][TI-954] - [INFO] 2024-04-22 18:06:50.426 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-408][TI-954] - [INFO] 2024-04-22 18:06:50.430 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-408][TI-954] - [INFO] 2024-04-22 18:06:50.431 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-408][TI-954] - [INFO] 2024-04-22 18:06:50.432 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_67/408/954 check successfully
[WI-408][TI-954] - [INFO] 2024-04-22 18:06:50.432 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-408][TI-954] - [INFO] 2024-04-22 18:06:50.439 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-408][TI-954] - [INFO] 2024-04-22 18:06:50.442 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-408][TI-954] - [INFO] 2024-04-22 18:06:50.442 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-408][TI-954] - [INFO] 2024-04-22 18:06:50.442 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ {
    "prop" : "raw_file_dir",
    "direct" : "OUT",
    "type" : "VARCHAR",
    "value" : ""
  }, {
    "prop" : "raw_file",
    "direct" : "OUT",
    "type" : "VARCHAR",
    "value" : ""
  } ],
  "varPool" : null,
  "rawScript" : "# find 1 raw file in the folder\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\nraw_file=null\n\n# check if raw_file_dir is empty, then set raw_file_dir and raw_file to empty strings\nif [ -z \"$raw_file_dir\" ]; then\n    raw_file_dir=null\nelse\n    raw_file=$(basename \"$raw_file_dir\")\nfi\n\necho \"#{setValue(raw_file_dir=${raw_file_dir})}\"\necho \"#{setValue(raw_file=${raw_file})}\"",
  "resourceList" : [ ]
}
[WI-408][TI-954] - [INFO] 2024-04-22 18:06:50.442 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-408][TI-954] - [INFO] 2024-04-22 18:06:50.442 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: null successfully
[WI-408][TI-954] - [INFO] 2024-04-22 18:06:50.444 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-408][TI-954] - [INFO] 2024-04-22 18:06:50.446 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-408][TI-954] - [INFO] 2024-04-22 18:06:50.447 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-408][TI-954] - [INFO] 2024-04-22 18:06:50.447 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-408][TI-954] - [INFO] 2024-04-22 18:06:50.447 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-408][TI-954] - [INFO] 2024-04-22 18:06:50.447 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export PYTHON_LAUNCHER=/bin/python3.11
# find 1 raw file in the folder
raw_file_dir=$(find /local_storage/reddit/processing -type f -name '*.json'| head -n 1)
raw_file=null

# check if raw_file_dir is empty, then set raw_file_dir and raw_file to empty strings
if [ -z "$raw_file_dir" ]; then
    raw_file_dir=null
else
    raw_file=$(basename "$raw_file_dir")
fi

echo "#{setValue(raw_file_dir=${raw_file_dir})}"
echo "#{setValue(raw_file=${raw_file})}"
[WI-408][TI-954] - [INFO] 2024-04-22 18:06:50.447 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-408][TI-954] - [INFO] 2024-04-22 18:06:50.447 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_67/408/954/408_954.sh
[WI-408][TI-954] - [INFO] 2024-04-22 18:06:50.465 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 9270
[WI-0][TI-954] - [INFO] 2024-04-22 18:06:50.954 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=954, success=true)
[WI-0][TI-954] - [INFO] 2024-04-22 18:06:50.964 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=954)
[WI-0][TI-0] - [INFO] 2024-04-22 18:06:51.466 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
	#{setValue(raw_file_dir=/local_storage/reddit/processing/386-20240422.json)}
	#{setValue(raw_file=386-20240422.json)}
[WI-408][TI-954] - [INFO] 2024-04-22 18:06:51.469 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_67/408/954, processId:9270 ,exitStatusCode:0 ,processWaitForStatus:true ,processExitValue:0
[WI-408][TI-954] - [INFO] 2024-04-22 18:06:51.470 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-408][TI-954] - [INFO] 2024-04-22 18:06:51.470 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-408][TI-954] - [INFO] 2024-04-22 18:06:51.470 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-408][TI-954] - [INFO] 2024-04-22 18:06:51.470 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-408][TI-954] - [INFO] 2024-04-22 18:06:51.473 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: SUCCESS to master : 172.18.1.1:1234
[WI-408][TI-954] - [INFO] 2024-04-22 18:06:51.474 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-408][TI-954] - [INFO] 2024-04-22 18:06:51.474 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_67/408/954
[WI-408][TI-954] - [INFO] 2024-04-22 18:06:51.474 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_67/408/954
[WI-408][TI-954] - [INFO] 2024-04-22 18:06:51.474 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-954] - [INFO] 2024-04-22 18:06:51.946 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=954, success=true)
[WI-0][TI-0] - [INFO] 2024-04-22 18:06:53.142 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=956, taskName=move to processing, firstSubmitTime=1713780413110, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.11:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=67, appIds=null, processInstanceId=408, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"processing"}], executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[],"rawScript":"# move file to the reddit processing folder\n# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error\nif [\"${folder}\"!=\"processing\"]; then\n    mv ${raw_file_dir} ${REDDIT_HOME}/processing\nelse\n    echo JSON is already in processing\nfi","resourceList":[]}, environmentConfig=export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='move to processing'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240422'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='956'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13340390094208'}, raw_file=Property{prop='raw_file', direct=IN, type=VARCHAR, value='386-20240422.json'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240422180653'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='processing'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='408'}, raw_file_dir=Property{prop='raw_file_dir', direct=IN, type=VARCHAR, value='/local_storage/reddit/processing/386-20240422.json'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240421'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"},{"prop":"raw_file","direct":"IN","type":"VARCHAR","value":"386-20240422.json"}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-408][TI-956] - [INFO] 2024-04-22 18:06:53.156 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: move to processing to wait queue success
[WI-408][TI-956] - [INFO] 2024-04-22 18:06:53.160 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-408][TI-956] - [INFO] 2024-04-22 18:06:53.203 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-408][TI-956] - [INFO] 2024-04-22 18:06:53.203 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-408][TI-956] - [INFO] 2024-04-22 18:06:53.203 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-408][TI-956] - [INFO] 2024-04-22 18:06:53.204 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713780413203
[WI-408][TI-956] - [INFO] 2024-04-22 18:06:53.204 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 408_956
[WI-408][TI-956] - [INFO] 2024-04-22 18:06:53.204 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 956,
  "taskName" : "move to processing",
  "firstSubmitTime" : 1713780413110,
  "startTime" : 1713780413203,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.11:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240422/13201021801792/67/408/956.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 67,
  "processInstanceId" : 408,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"processing\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[],\"rawScript\":\"# move file to the reddit processing folder\\n# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error\\nif [\\\"${folder}\\\"!=\\\"processing\\\"]; then\\n    mv ${raw_file_dir} ${REDDIT_HOME}/processing\\nelse\\n    echo JSON is already in processing\\nfi\",\"resourceList\":[]}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "move to processing"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240422"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "956"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13340390094208"
    },
    "raw_file" : {
      "prop" : "raw_file",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "386-20240422.json"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240422180653"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "processing"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "408"
    },
    "raw_file_dir" : {
      "prop" : "raw_file_dir",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit/processing/386-20240422.json"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240421"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "408_956",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"raw_file_dir\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"/local_storage/reddit/processing/386-20240422.json\"},{\"prop\":\"raw_file\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"386-20240422.json\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-408][TI-956] - [INFO] 2024-04-22 18:06:53.204 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-408][TI-956] - [INFO] 2024-04-22 18:06:53.204 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-408][TI-956] - [INFO] 2024-04-22 18:06:53.204 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-408][TI-956] - [INFO] 2024-04-22 18:06:53.220 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-408][TI-956] - [INFO] 2024-04-22 18:06:53.221 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-408][TI-956] - [INFO] 2024-04-22 18:06:53.222 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_67/408/956 check successfully
[WI-408][TI-956] - [INFO] 2024-04-22 18:06:53.222 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-408][TI-956] - [INFO] 2024-04-22 18:06:53.222 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-408][TI-956] - [INFO] 2024-04-22 18:06:53.222 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-408][TI-956] - [INFO] 2024-04-22 18:06:53.222 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-408][TI-956] - [INFO] 2024-04-22 18:06:53.222 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ ],
  "varPool" : null,
  "rawScript" : "# move file to the reddit processing folder\n# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error\nif [\"${folder}\"!=\"processing\"]; then\n    mv ${raw_file_dir} ${REDDIT_HOME}/processing\nelse\n    echo JSON is already in processing\nfi",
  "resourceList" : [ ]
}
[WI-408][TI-956] - [INFO] 2024-04-22 18:06:53.222 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-408][TI-956] - [INFO] 2024-04-22 18:06:53.222 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"},{"prop":"raw_file","direct":"IN","type":"VARCHAR","value":"386-20240422.json"}] successfully
[WI-408][TI-956] - [INFO] 2024-04-22 18:06:53.222 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-408][TI-956] - [INFO] 2024-04-22 18:06:53.222 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-408][TI-956] - [INFO] 2024-04-22 18:06:53.222 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-408][TI-956] - [INFO] 2024-04-22 18:06:53.223 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-408][TI-956] - [INFO] 2024-04-22 18:06:53.223 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-408][TI-956] - [INFO] 2024-04-22 18:06:53.223 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export PYTHON_LAUNCHER=/bin/python3.11
# move file to the reddit processing folder
# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error
if ["processing"!="processing"]; then
    mv /local_storage/reddit/processing/386-20240422.json /local_storage/reddit/processing
else
    echo JSON is already in processing
fi
[WI-408][TI-956] - [INFO] 2024-04-22 18:06:53.223 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-408][TI-956] - [INFO] 2024-04-22 18:06:53.223 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_67/408/956/408_956.sh
[WI-408][TI-956] - [INFO] 2024-04-22 18:06:53.257 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 9285
[WI-0][TI-956] - [INFO] 2024-04-22 18:06:53.960 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=956, success=true)
[WI-0][TI-956] - [INFO] 2024-04-22 18:06:53.965 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=956)
[WI-0][TI-0] - [INFO] 2024-04-22 18:06:54.260 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
	/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_67/408/956/408_956.sh: line 7: [processing!=processing]: command not found
	JSON is already in processing
[WI-408][TI-956] - [INFO] 2024-04-22 18:06:54.262 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_67/408/956, processId:9285 ,exitStatusCode:0 ,processWaitForStatus:true ,processExitValue:0
[WI-408][TI-956] - [INFO] 2024-04-22 18:06:54.263 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-408][TI-956] - [INFO] 2024-04-22 18:06:54.263 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-408][TI-956] - [INFO] 2024-04-22 18:06:54.263 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-408][TI-956] - [INFO] 2024-04-22 18:06:54.264 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-408][TI-956] - [INFO] 2024-04-22 18:06:54.267 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: SUCCESS to master : 172.18.1.1:1234
[WI-408][TI-956] - [INFO] 2024-04-22 18:06:54.267 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-408][TI-956] - [INFO] 2024-04-22 18:06:54.267 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_67/408/956
[WI-408][TI-956] - [INFO] 2024-04-22 18:06:54.267 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_67/408/956
[WI-408][TI-956] - [INFO] 2024-04-22 18:06:54.268 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-956] - [INFO] 2024-04-22 18:06:54.958 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=956, success=true)
[WI-0][TI-0] - [INFO] 2024-04-22 18:06:54.980 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=957, taskName=spark preprocessing, firstSubmitTime=1713780414974, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.11:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=67, appIds=null, processInstanceId=408, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"processing"}], executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[],"rawScript":"$SPARK_HOME/bin/spark-submit \\\n    --master spark://spark-master:7077 \\\n    --conf spark.driver.cores=1 \\\n    --conf spark.driver.memory=512M \\\n    --conf spark.executor.instances=2 \\\n    --conf spark.executor.cores=2 \\\n    --conf spark.executor.memory=1G \\\n    --files ${raw_file_dir} \\\n    --name reddit_preprocessing spark_reddit_preprocessing.py\n","resourceList":[{"id":null,"resourceName":"file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py","res":null}]}, environmentConfig=export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export HADOOP_CONF_DIR=/opt/hadoop-3.4.0/etc/hadoop
export PYSPARK_DRIVER_PYTHON=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='spark preprocessing'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240422'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='957'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13210058002752'}, raw_file=Property{prop='raw_file', direct=IN, type=VARCHAR, value='386-20240422.json'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240422180654'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='processing'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='408'}, raw_file_dir=Property{prop='raw_file_dir', direct=IN, type=VARCHAR, value='/local_storage/reddit/processing/386-20240422.json'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240421'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"},{"prop":"raw_file","direct":"IN","type":"VARCHAR","value":"386-20240422.json"}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-408][TI-957] - [INFO] 2024-04-22 18:06:54.981 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: spark preprocessing to wait queue success
[WI-408][TI-957] - [INFO] 2024-04-22 18:06:54.982 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-408][TI-957] - [INFO] 2024-04-22 18:06:54.983 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-408][TI-957] - [INFO] 2024-04-22 18:06:54.983 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-408][TI-957] - [INFO] 2024-04-22 18:06:54.983 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-408][TI-957] - [INFO] 2024-04-22 18:06:54.983 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713780414983
[WI-408][TI-957] - [INFO] 2024-04-22 18:06:54.983 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 408_957
[WI-408][TI-957] - [INFO] 2024-04-22 18:06:54.984 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 957,
  "taskName" : "spark preprocessing",
  "firstSubmitTime" : 1713780414974,
  "startTime" : 1713780414983,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.11:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240422/13201021801792/67/408/957.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 67,
  "processInstanceId" : 408,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"processing\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[],\"rawScript\":\"$SPARK_HOME/bin/spark-submit \\\\\\n    --master spark://spark-master:7077 \\\\\\n    --conf spark.driver.cores=1 \\\\\\n    --conf spark.driver.memory=512M \\\\\\n    --conf spark.executor.instances=2 \\\\\\n    --conf spark.executor.cores=2 \\\\\\n    --conf spark.executor.memory=1G \\\\\\n    --files ${raw_file_dir} \\\\\\n    --name reddit_preprocessing spark_reddit_preprocessing.py\\n\",\"resourceList\":[{\"id\":null,\"resourceName\":\"file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py\",\"res\":null}]}",
  "environmentConfig" : "export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3\nexport JAVA_HOME=/opt/java/openjdk\nexport HADOOP_CONF_DIR=/opt/hadoop-3.4.0/etc/hadoop\nexport PYSPARK_DRIVER_PYTHON=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "spark preprocessing"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240422"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "957"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13210058002752"
    },
    "raw_file" : {
      "prop" : "raw_file",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "386-20240422.json"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240422180654"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "processing"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "408"
    },
    "raw_file_dir" : {
      "prop" : "raw_file_dir",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit/processing/386-20240422.json"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240421"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "408_957",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"raw_file_dir\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"/local_storage/reddit/processing/386-20240422.json\"},{\"prop\":\"raw_file\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"386-20240422.json\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-408][TI-957] - [INFO] 2024-04-22 18:06:54.984 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-408][TI-957] - [INFO] 2024-04-22 18:06:54.984 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-408][TI-957] - [INFO] 2024-04-22 18:06:54.985 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-408][TI-957] - [INFO] 2024-04-22 18:06:54.987 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-408][TI-957] - [INFO] 2024-04-22 18:06:54.987 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-408][TI-957] - [INFO] 2024-04-22 18:06:54.988 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_67/408/957 check successfully
[WI-408][TI-957] - [INFO] 2024-04-22 18:06:54.988 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-408][TI-957] - [INFO] 2024-04-22 18:06:54.990 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py=ResourceContext.ResourceItem(resourceAbsolutePathInStorage=file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py, resourceRelativePath=spark_reddit_preprocessing.py, resourceAbsolutePathInLocal=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_67/408/957/spark_reddit_preprocessing.py)})
[WI-408][TI-957] - [INFO] 2024-04-22 18:06:54.990 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-408][TI-957] - [INFO] 2024-04-22 18:06:54.990 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-408][TI-957] - [INFO] 2024-04-22 18:06:54.990 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ ],
  "varPool" : null,
  "rawScript" : "$SPARK_HOME/bin/spark-submit \\\n    --master spark://spark-master:7077 \\\n    --conf spark.driver.cores=1 \\\n    --conf spark.driver.memory=512M \\\n    --conf spark.executor.instances=2 \\\n    --conf spark.executor.cores=2 \\\n    --conf spark.executor.memory=1G \\\n    --files ${raw_file_dir} \\\n    --name reddit_preprocessing spark_reddit_preprocessing.py\n",
  "resourceList" : [ {
    "id" : null,
    "resourceName" : "file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py",
    "res" : null
  } ]
}
[WI-408][TI-957] - [INFO] 2024-04-22 18:06:54.990 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-408][TI-957] - [INFO] 2024-04-22 18:06:54.991 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"},{"prop":"raw_file","direct":"IN","type":"VARCHAR","value":"386-20240422.json"}] successfully
[WI-408][TI-957] - [INFO] 2024-04-22 18:06:54.991 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-408][TI-957] - [INFO] 2024-04-22 18:06:54.991 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-408][TI-957] - [INFO] 2024-04-22 18:06:54.991 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-408][TI-957] - [INFO] 2024-04-22 18:06:54.991 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-408][TI-957] - [INFO] 2024-04-22 18:06:54.991 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-408][TI-957] - [INFO] 2024-04-22 18:06:54.991 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export HADOOP_CONF_DIR=/opt/hadoop-3.4.0/etc/hadoop
export PYSPARK_DRIVER_PYTHON=/bin/python3.11
$SPARK_HOME/bin/spark-submit \
    --master spark://spark-master:7077 \
    --conf spark.driver.cores=1 \
    --conf spark.driver.memory=512M \
    --conf spark.executor.instances=2 \
    --conf spark.executor.cores=2 \
    --conf spark.executor.memory=1G \
    --files /local_storage/reddit/processing/386-20240422.json \
    --name reddit_preprocessing spark_reddit_preprocessing.py

[WI-408][TI-957] - [INFO] 2024-04-22 18:06:54.991 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-408][TI-957] - [INFO] 2024-04-22 18:06:54.991 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_67/408/957/408_957.sh
[WI-408][TI-957] - [INFO] 2024-04-22 18:06:54.994 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 9296
[WI-0][TI-957] - [INFO] 2024-04-22 18:06:55.968 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=957, success=true)
[WI-0][TI-957] - [INFO] 2024-04-22 18:06:55.975 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=957)
[WI-0][TI-0] - [INFO] 2024-04-22 18:06:55.996 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
[WI-0][TI-0] - [INFO] 2024-04-22 18:06:56.999 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/22 18:06:56 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[WI-0][TI-0] - [INFO] 2024-04-22 18:06:58.011 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/22 18:06:57 INFO SparkContext: Running Spark version 3.5.1
	24/04/22 18:06:57 INFO SparkContext: OS info Linux, 6.5.0-28-generic, amd64
	24/04/22 18:06:57 INFO SparkContext: Java version 1.8.0_402
	24/04/22 18:06:57 INFO ResourceUtils: ==============================================================
	24/04/22 18:06:57 INFO ResourceUtils: No custom resources configured for spark.driver.
	24/04/22 18:06:57 INFO ResourceUtils: ==============================================================
	24/04/22 18:06:57 INFO SparkContext: Submitted application: reddit_preprocessing
	24/04/22 18:06:57 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 2, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
	24/04/22 18:06:57 INFO ResourceProfile: Limiting resource is cpus at 2 tasks per executor
	24/04/22 18:06:57 INFO ResourceProfileManager: Added ResourceProfile id: 0
	24/04/22 18:06:57 INFO SecurityManager: Changing view acls to: default
	24/04/22 18:06:57 INFO SecurityManager: Changing modify acls to: default
	24/04/22 18:06:57 INFO SecurityManager: Changing view acls groups to: 
	24/04/22 18:06:57 INFO SecurityManager: Changing modify acls groups to: 
	24/04/22 18:06:57 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: default; groups with view permissions: EMPTY; users with modify permissions: default; groups with modify permissions: EMPTY
[WI-0][TI-0] - [INFO] 2024-04-22 18:06:59.015 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/22 18:06:58 INFO Utils: Successfully started service 'sparkDriver' on port 39267.
	24/04/22 18:06:58 INFO SparkEnv: Registering MapOutputTracker
	24/04/22 18:06:58 INFO SparkEnv: Registering BlockManagerMaster
	24/04/22 18:06:58 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
	24/04/22 18:06:58 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
	24/04/22 18:06:58 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
	24/04/22 18:06:58 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-b61c375a-60e9-456b-b983-e9a663f538c7
	24/04/22 18:06:58 INFO MemoryStore: MemoryStore started with capacity 93.3 MiB
	24/04/22 18:06:58 INFO SparkEnv: Registering OutputCommitCoordinator
	24/04/22 18:06:58 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
	24/04/22 18:06:58 INFO Utils: Successfully started service 'SparkUI' on port 4040.
	24/04/22 18:06:58 INFO SparkContext: Added file file:///local_storage/reddit/processing/386-20240422.json at spark://868412aff9d6:39267/files/386-20240422.json with timestamp 1713780417667
	24/04/22 18:06:58 INFO Utils: Copying /local_storage/reddit/processing/386-20240422.json to /tmp/spark-84babb0f-43f0-4ddf-be96-8e414e59dc2a/userFiles-f47661c6-f9dc-4199-aa39-f891579d57fa/386-20240422.json
	24/04/22 18:06:58 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
	24/04/22 18:06:58 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.3:7077 after 37 ms (0 ms spent in bootstraps)
[WI-0][TI-0] - [INFO] 2024-04-22 18:07:00.019 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/22 18:06:59 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20240422100659-0000
	24/04/22 18:06:59 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40331.
	24/04/22 18:06:59 INFO NettyBlockTransferService: Server created on 868412aff9d6:40331
	24/04/22 18:06:59 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
	24/04/22 18:06:59 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 868412aff9d6, 40331, None)
	24/04/22 18:06:59 INFO BlockManagerMasterEndpoint: Registering block manager 868412aff9d6:40331 with 93.3 MiB RAM, BlockManagerId(driver, 868412aff9d6, 40331, None)
	24/04/22 18:06:59 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20240422100659-0000/0 on worker-20240422004037-172.18.0.6-34601 (172.18.0.6:34601) with 2 core(s)
	24/04/22 18:06:59 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 868412aff9d6, 40331, None)
	24/04/22 18:06:59 INFO StandaloneSchedulerBackend: Granted executor ID app-20240422100659-0000/0 on hostPort 172.18.0.6:34601 with 2 core(s), 1024.0 MiB RAM
	24/04/22 18:06:59 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 868412aff9d6, 40331, None)
	24/04/22 18:06:59 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20240422100659-0000/0 is now RUNNING
	24/04/22 18:06:59 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
[WI-0][TI-0] - [INFO] 2024-04-22 18:07:00.594 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.804953560371517 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-22 18:07:01.020 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	Traceback (most recent call last):
	  File "/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_67/408/957/spark_reddit_preprocessing.py", line 41, in <module>
	    raw_df = sc.wholeTextFiles(reddit_data).map(lambda x:ast.literal_eval(x[1]))\
	                               ^^^^^^^^^^^
	NameError: name 'reddit_data' is not defined
	24/04/22 18:07:00 INFO SparkContext: Invoking stop() from shutdown hook
	24/04/22 18:07:00 INFO SparkContext: SparkContext is stopping with exitCode 0.
	24/04/22 18:07:00 INFO SparkUI: Stopped Spark web UI at http://868412aff9d6:4040
	24/04/22 18:07:00 INFO StandaloneSchedulerBackend: Shutting down all executors
	24/04/22 18:07:00 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Asking each executor to shut down
	24/04/22 18:07:00 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
	24/04/22 18:07:00 INFO MemoryStore: MemoryStore cleared
	24/04/22 18:07:00 INFO BlockManager: BlockManager stopped
	24/04/22 18:07:00 INFO BlockManagerMaster: BlockManagerMaster stopped
	24/04/22 18:07:00 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
	24/04/22 18:07:00 INFO SparkContext: Successfully stopped SparkContext
	24/04/22 18:07:00 INFO ShutdownHookManager: Shutdown hook called
	24/04/22 18:07:00 INFO ShutdownHookManager: Deleting directory /tmp/spark-331848fb-9ac8-4627-abfd-3c952e33505d
	24/04/22 18:07:00 INFO ShutdownHookManager: Deleting directory /tmp/spark-84babb0f-43f0-4ddf-be96-8e414e59dc2a/pyspark-7d380315-9671-45b1-a138-f7ada7dfdd37
	24/04/22 18:07:00 INFO ShutdownHookManager: Deleting directory /tmp/spark-84babb0f-43f0-4ddf-be96-8e414e59dc2a
[WI-408][TI-957] - [INFO] 2024-04-22 18:07:01.021 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_67/408/957, processId:9296 ,exitStatusCode:1 ,processWaitForStatus:true ,processExitValue:1
[WI-408][TI-957] - [INFO] 2024-04-22 18:07:01.022 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-408][TI-957] - [INFO] 2024-04-22 18:07:01.022 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-408][TI-957] - [INFO] 2024-04-22 18:07:01.022 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-408][TI-957] - [INFO] 2024-04-22 18:07:01.022 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-408][TI-957] - [INFO] 2024-04-22 18:07:01.025 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: FAILURE to master : 172.18.1.1:1234
[WI-408][TI-957] - [INFO] 2024-04-22 18:07:01.025 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-408][TI-957] - [INFO] 2024-04-22 18:07:01.025 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_67/408/957
[WI-408][TI-957] - [INFO] 2024-04-22 18:07:01.026 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_67/408/957
[WI-408][TI-957] - [INFO] 2024-04-22 18:07:01.026 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-957] - [INFO] 2024-04-22 18:07:02.009 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=957, success=true)
[WI-0][TI-0] - [INFO] 2024-04-22 18:08:54.340 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7285714285714286 is over then the MaxCpuUsagePercentageThresholds 0.7
