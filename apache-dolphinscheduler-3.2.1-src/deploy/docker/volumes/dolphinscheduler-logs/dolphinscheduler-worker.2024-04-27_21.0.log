[WI-0][TI-0] - [WARN] 2024-04-27 21:05:35.675 +0800 o.s.c.k.c.p.AbstractKubernetesProfileEnvironmentPostProcessor:[258] - Not running inside kubernetes. Skipping 'kubernetes' profile activation.
[WI-0][TI-0] - [WARN] 2024-04-27 21:05:51.800 +0800 o.s.c.k.c.p.AbstractKubernetesProfileEnvironmentPostProcessor:[258] - Not running inside kubernetes. Skipping 'kubernetes' profile activation.
[WI-0][TI-0] - [INFO] 2024-04-27 21:05:51.821 +0800 o.a.d.s.w.WorkerServer:[634] - No active profile set, falling back to 1 default profile: "default"
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:17.660 +0800 o.s.c.c.s.GenericScope:[283] - BeanFactory id=7e7bf7c6-2cb3-34d2-a0d5-a56161c67d0e
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:24.241 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'org.springframework.cloud.commons.config.CommonsConfigAutoConfiguration' of type [org.springframework.cloud.commons.config.CommonsConfigAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:24.247 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'org.springframework.cloud.client.loadbalancer.LoadBalancerDefaultMappingsProviderAutoConfiguration' of type [org.springframework.cloud.client.loadbalancer.LoadBalancerDefaultMappingsProviderAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:24.251 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'loadBalancerClientsDefaultsMappingsProvider' of type [org.springframework.cloud.client.loadbalancer.LoadBalancerDefaultMappingsProviderAutoConfiguration$$Lambda$392/189820624] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:24.263 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'defaultsBindHandlerAdvisor' of type [org.springframework.cloud.commons.config.DefaultsBindHandlerAdvisor] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:24.676 +0800 o.a.d.c.u.NetUtils:[312] - Get all NetworkInterfaces: [name:eth0 (eth0), name:lo (lo)]
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:24.996 +0800 o.a.d.s.w.c.WorkerConfig:[98] - 
****************************Worker Configuration**************************************
  listen-port -> 1234
  exec-threads -> 100
  max-heartbeat-interval -> PT10S
  host-weight -> 100
  tenantConfig -> TenantConfig(autoCreateTenantEnabled=true, distributedTenantEnabled=false, defaultTenantEnabled=false)
  server-load-protection -> WorkerServerLoadProtection(enabled=true, maxCpuUsagePercentageThresholds=0.7, maxJVMMemoryUsagePercentageThresholds=0.7, maxSystemMemoryUsagePercentageThresholds=0.7, maxDiskUsagePercentageThresholds=0.7)
  registry-disconnect-strategy -> ConnectStrategyProperties(strategy=WAITING, maxWaitingTime=PT1M40S)
  task-execute-threads-full-policy: REJECT
  address -> 172.18.1.1:1234
  registry-path: /nodes/worker/172.18.1.1:1234
****************************Worker Configuration**************************************
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:24.997 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'workerConfig' of type [org.apache.dolphinscheduler.server.worker.config.WorkerConfig$$EnhancerBySpringCGLIB$$153d90bb] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:26.238 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'io.kubernetes.client.spring.extended.manifests.config.KubernetesManifestsAutoConfiguration' of type [io.kubernetes.client.spring.extended.manifests.config.KubernetesManifestsAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:26.592 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'kubernetes.manifests-io.kubernetes.client.spring.extended.manifests.config.KubernetesManifestsProperties' of type [io.kubernetes.client.spring.extended.manifests.config.KubernetesManifestsProperties] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:26.717 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'io.kubernetes.client.spring.extended.controller.config.KubernetesInformerAutoConfiguration' of type [io.kubernetes.client.spring.extended.controller.config.KubernetesInformerAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:27.079 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'defaultApiClient' of type [io.kubernetes.client.openapi.ApiClient] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:29.127 +0800 o.e.j.u.log:[170] - Logging initialized @77286ms to org.eclipse.jetty.util.log.Slf4jLog
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:32.508 +0800 o.s.b.w.e.j.JettyServletWebServerFactory:[166] - Server initialized with port: 1235
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:32.566 +0800 o.e.j.s.Server:[375] - jetty-9.4.48.v20220622; built: 2022-06-21T20:42:25.880Z; git: 6b67c5719d1f4371b33655ff2d047d24e171e49a; jvm 1.8.0_402-b06
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:33.509 +0800 o.e.j.s.h.C.application:[2368] - Initializing Spring embedded WebApplicationContext
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:33.514 +0800 o.s.b.w.s.c.ServletWebServerApplicationContext:[292] - Root WebApplicationContext: initialization completed in 40760 ms
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:37.345 +0800 o.e.j.s.session:[334] - DefaultSessionIdManager workerName=node0
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:37.346 +0800 o.e.j.s.session:[339] - No SessionScavenger set, using defaults
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:37.378 +0800 o.e.j.s.session:[132] - node0 Scavenging every 660000ms
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:37.507 +0800 o.e.j.s.h.ContextHandler:[921] - Started o.s.b.w.e.j.JettyEmbeddedWebAppContext@3d798e76{application,/,[file:///tmp/jetty-docbase.1235.1396825295386242763/],AVAILABLE}
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:37.508 +0800 o.e.j.s.Server:[415] - Started @85686ms
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:39.504 +0800 o.a.c.f.i.CuratorFrameworkImpl:[338] - Starting
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:39.674 +0800 o.a.z.ZooKeeper:[98] - Client environment:zookeeper.version=3.8.0-5a02a05eddb59aee6ac762f7ea82e92a68eb9c0f, built on 2022-02-25 08:49 UTC
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:39.675 +0800 o.a.z.ZooKeeper:[98] - Client environment:host.name=e47c6ed01c88
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:39.677 +0800 o.a.z.ZooKeeper:[98] - Client environment:java.version=1.8.0_402
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:39.678 +0800 o.a.z.ZooKeeper:[98] - Client environment:java.vendor=Temurin
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:39.679 +0800 o.a.z.ZooKeeper:[98] - Client environment:java.home=/opt/java/openjdk
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:39.705 +0800 o.a.z.ZooKeeper:[98] - Client environment:java.class.path=/opt/dolphinscheduler/conf:/opt/dolphinscheduler/libs/kerb-client-1.0.1.jar:/opt/dolphinscheduler/libs/spring-cloud-starter-kubernetes-client-config-2.1.3.jar:/opt/dolphinscheduler/libs/oauth2-oidc-sdk-9.35.jar:/opt/dolphinscheduler/libs/jsqlparser-4.4.jar:/opt/dolphinscheduler/libs/reactive-streams-1.0.4.jar:/opt/dolphinscheduler/libs/kubernetes-model-extensions-5.10.2.jar:/opt/dolphinscheduler/libs/zookeeper-3.8.0.jar:/opt/dolphinscheduler/libs/kubernetes-model-apps-5.10.2.jar:/opt/dolphinscheduler/libs/grpc-api-1.41.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-pigeon-3.2.1.jar:/opt/dolphinscheduler/libs/client-java-api-13.0.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-obs-3.2.1.jar:/opt/dolphinscheduler/libs/spring-web-5.3.22.jar:/opt/dolphinscheduler/libs/aws-java-sdk-emr-1.12.300.jar:/opt/dolphinscheduler/libs/spring-context-5.3.22.jar:/opt/dolphinscheduler/libs/gapic-google-cloud-storage-v2-2.18.0-alpha.jar:/opt/dolphinscheduler/libs/spring-cloud-kubernetes-client-config-2.1.3.jar:/opt/dolphinscheduler/libs/jetty-io-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/annotations-13.0.jar:/opt/dolphinscheduler/libs/jpam-1.1.jar:/opt/dolphinscheduler/libs/joda-time-2.10.13.jar:/opt/dolphinscheduler/libs/spring-cloud-kubernetes-client-autoconfig-2.1.3.jar:/opt/dolphinscheduler/libs/kerb-identity-1.0.1.jar:/opt/dolphinscheduler/libs/vertica-jdbc-12.0.4-0.jar:/opt/dolphinscheduler/libs/grpc-googleapis-1.52.1.jar:/opt/dolphinscheduler/libs/aliyun-java-sdk-kms-2.11.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-dvc-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-hana-3.2.1.jar:/opt/dolphinscheduler/libs/kubernetes-httpclient-okhttp-6.0.0.jar:/opt/dolphinscheduler/libs/jline-2.12.jar:/opt/dolphinscheduler/libs/sshd-core-2.8.0.jar:/opt/dolphinscheduler/libs/jna-platform-5.10.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-sqlserver-3.2.1.jar:/opt/dolphinscheduler/libs/commons-beanutils-1.9.4.jar:/opt/dolphinscheduler/libs/grpc-services-1.41.0.jar:/opt/dolphinscheduler/libs/jmespath-java-1.12.300.jar:/opt/dolphinscheduler/libs/curator-client-5.3.0.jar:/opt/dolphinscheduler/libs/proto-google-common-protos-2.0.1.jar:/opt/dolphinscheduler/libs/mybatis-3.5.10.jar:/opt/dolphinscheduler/libs/jackson-annotations-2.13.4.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-all-3.2.1.jar:/opt/dolphinscheduler/libs/jakarta.xml.bind-api-2.3.3.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-jupyter-3.2.1.jar:/opt/dolphinscheduler/libs/mybatis-plus-extension-3.5.2.jar:/opt/dolphinscheduler/libs/j2objc-annotations-1.3.jar:/opt/dolphinscheduler/libs/Java-WebSocket-1.5.1.jar:/opt/dolphinscheduler/libs/azure-storage-common-12.20.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-sagemaker-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-databend-3.2.1.jar:/opt/dolphinscheduler/libs/google-auth-library-oauth2-http-1.15.0.jar:/opt/dolphinscheduler/libs/jetty-security-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-python-3.2.1.jar:/opt/dolphinscheduler/libs/snappy-java-1.1.10.1.jar:/opt/dolphinscheduler/libs/kubernetes-model-batch-5.10.2.jar:/opt/dolphinscheduler/libs/netty-transport-native-epoll-4.1.53.Final-linux-x86_64.jar:/opt/dolphinscheduler/libs/jackson-core-asl-1.9.13.jar:/opt/dolphinscheduler/libs/gson-fire-1.8.5.jar:/opt/dolphinscheduler/libs/clickhouse-jdbc-0.4.6.jar:/opt/dolphinscheduler/libs/grpc-netty-shaded-1.41.0.jar:/opt/dolphinscheduler/libs/caffeine-2.9.3.jar:/opt/dolphinscheduler/libs/aliyun-java-sdk-core-4.5.10.jar:/opt/dolphinscheduler/libs/jackson-module-jaxb-annotations-2.13.3.jar:/opt/dolphinscheduler/libs/jetty-http-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/jersey-servlet-1.19.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-dinky-3.2.1.jar:/opt/dolphinscheduler/libs/simpleclient_tracer_common-0.15.0.jar:/opt/dolphinscheduler/libs/netty-handler-4.1.53.Final.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-datafactory-3.2.1.jar:/opt/dolphinscheduler/libs/json-path-2.7.0.jar:/opt/dolphinscheduler/libs/mybatis-plus-annotation-3.5.2.jar:/opt/dolphinscheduler/libs/azure-resourcemanager-datafactory-1.0.0-beta.19.jar:/opt/dolphinscheduler/libs/commons-codec-1.11.jar:/opt/dolphinscheduler/libs/dolphinscheduler-extract-master-3.2.1.jar:/opt/dolphinscheduler/libs/spring-aop-5.3.22.jar:/opt/dolphinscheduler/libs/kubernetes-model-core-5.10.2.jar:/opt/dolphinscheduler/libs/kubernetes-model-networking-5.10.2.jar:/opt/dolphinscheduler/libs/kotlin-stdlib-jdk7-1.6.21.jar:/opt/dolphinscheduler/libs/kerby-xdr-1.0.1.jar:/opt/dolphinscheduler/libs/aliyun-java-sdk-ram-3.1.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-k8s-3.2.1.jar:/opt/dolphinscheduler/libs/guava-31.1-jre.jar:/opt/dolphinscheduler/libs/netty-codec-dns-4.1.53.Final.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-kubeflow-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-azure-sql-3.2.1.jar:/opt/dolphinscheduler/libs/HikariCP-4.0.3.jar:/opt/dolphinscheduler/libs/hive-metastore-2.3.9.jar:/opt/dolphinscheduler/libs/msal4j-1.13.3.jar:/opt/dolphinscheduler/libs/jackson-core-2.13.4.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-hive-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-mr-3.2.1.jar:/opt/dolphinscheduler/libs/kubernetes-model-node-5.10.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-common-3.2.1.jar:/opt/dolphinscheduler/libs/jose4j-0.7.8.jar:/opt/dolphinscheduler/libs/jul-to-slf4j-1.7.36.jar:/opt/dolphinscheduler/libs/azure-identity-1.7.1.jar:/opt/dolphinscheduler/libs/spring-boot-autoconfigure-2.7.3.jar:/opt/dolphinscheduler/libs/commons-math3-3.1.1.jar:/opt/dolphinscheduler/libs/jackson-jaxrs-json-provider-2.13.3.jar:/opt/dolphinscheduler/libs/perfmark-api-0.23.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-doris-3.2.1.jar:/opt/dolphinscheduler/libs/httpclient-4.5.13.jar:/opt/dolphinscheduler/libs/hive-service-2.3.9.jar:/opt/dolphinscheduler/libs/kerby-util-1.0.1.jar:/opt/dolphinscheduler/libs/commons-collections-3.2.2.jar:/opt/dolphinscheduler/libs/hadoop-yarn-client-3.2.4.jar:/opt/dolphinscheduler/libs/commons-text-1.8.jar:/opt/dolphinscheduler/libs/dolphinscheduler-worker-3.2.1.jar:/opt/dolphinscheduler/libs/hadoop-yarn-common-3.2.4.jar:/opt/dolphinscheduler/libs/zeppelin-client-0.10.1.jar:/opt/dolphinscheduler/libs/azure-core-management-1.10.1.jar:/opt/dolphinscheduler/libs/hadoop-mapreduce-client-jobclient-3.2.4.jar:/opt/dolphinscheduler/libs/jta-1.1.jar:/opt/dolphinscheduler/libs/annotations-4.1.1.4.jar:/opt/dolphinscheduler/libs/dolphinscheduler-extract-alert-3.2.1.jar:/opt/dolphinscheduler/libs/curator-framework-5.3.0.jar:/opt/dolphinscheduler/libs/hive-jdbc-2.3.9.jar:/opt/dolphinscheduler/libs/kyuubi-hive-jdbc-shaded-1.7.0.jar:/opt/dolphinscheduler/libs/client-java-proto-13.0.2.jar:/opt/dolphinscheduler/libs/checker-qual-3.19.0.jar:/opt/dolphinscheduler/libs/jetty-servlet-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/google-cloud-core-grpc-2.10.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-shell-3.2.1.jar:/opt/dolphinscheduler/libs/spring-security-rsa-1.0.10.RELEASE.jar:/opt/dolphinscheduler/libs/avro-1.7.7.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-postgresql-3.2.1.jar:/opt/dolphinscheduler/libs/netty-nio-client-2.17.282.jar:/opt/dolphinscheduler/libs/spring-webmvc-5.3.22.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-mysql-3.2.1.jar:/opt/dolphinscheduler/libs/opentracing-util-0.33.0.jar:/opt/dolphinscheduler/libs/auto-value-1.10.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-all-3.2.1.jar:/opt/dolphinscheduler/libs/jetcd-core-0.5.11.jar:/opt/dolphinscheduler/libs/grpc-context-1.41.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-datasync-3.2.1.jar:/opt/dolphinscheduler/libs/jackson-dataformat-cbor-2.13.3.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-gcs-3.2.1.jar:/opt/dolphinscheduler/libs/client-java-extended-13.0.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-redshift-3.2.1.jar:/opt/dolphinscheduler/libs/opencsv-2.3.jar:/opt/dolphinscheduler/libs/jcip-annotations-1.0-1.jar:/opt/dolphinscheduler/libs/accessors-smart-2.4.8.jar:/opt/dolphinscheduler/libs/hadoop-client-3.2.4.jar:/opt/dolphinscheduler/libs/commons-collections4-4.3.jar:/opt/dolphinscheduler/libs/metrics-core-4.2.11.jar:/opt/dolphinscheduler/libs/netty-resolver-4.1.53.Final.jar:/opt/dolphinscheduler/libs/parquet-hadoop-bundle-1.8.1.jar:/opt/dolphinscheduler/libs/bucket4j-core-6.2.0.jar:/opt/dolphinscheduler/libs/spring-cloud-starter-3.1.3.jar:/opt/dolphinscheduler/libs/mssql-jdbc-11.2.1.jre8.jar:/opt/dolphinscheduler/libs/netty-tcnative-boringssl-static-2.0.53.Final.jar:/opt/dolphinscheduler/libs/kubernetes-model-coordination-5.10.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-linkis-3.2.1.jar:/opt/dolphinscheduler/libs/commons-net-3.6.jar:/opt/dolphinscheduler/libs/netty-transport-native-kqueue-4.1.53.Final-osx-x86_64.jar:/opt/dolphinscheduler/libs/dolphinscheduler-meter-3.2.1.jar:/opt/dolphinscheduler/libs/kubernetes-client-api-6.0.0.jar:/opt/dolphinscheduler/libs/kubernetes-model-certificates-5.10.2.jar:/opt/dolphinscheduler/libs/opencensus-api-0.31.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-mlflow-3.2.1.jar:/opt/dolphinscheduler/libs/kotlin-stdlib-jdk8-1.6.21.jar:/opt/dolphinscheduler/libs/dolphinscheduler-registry-jdbc-3.2.1.jar:/opt/dolphinscheduler/libs/audience-annotations-0.12.0.jar:/opt/dolphinscheduler/libs/simpleclient_httpserver-0.15.0.jar:/opt/dolphinscheduler/libs/jetty-xml-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/kerby-asn1-1.0.1.jar:/opt/dolphinscheduler/libs/lang-tag-1.6.jar:/opt/dolphinscheduler/libs/api-common-2.6.0.jar:/opt/dolphinscheduler/libs/HdrHistogram-2.1.12.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-abs-3.2.1.jar:/opt/dolphinscheduler/libs/failsafe-2.4.4.jar:/opt/dolphinscheduler/libs/hbase-noop-htrace-4.1.1.jar:/opt/dolphinscheduler/libs/jamon-runtime-2.3.1.jar:/opt/dolphinscheduler/libs/jetty-util-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/threetenbp-1.6.5.jar:/opt/dolphinscheduler/libs/jakarta.activation-api-1.2.2.jar:/opt/dolphinscheduler/libs/kubernetes-model-common-5.10.2.jar:/opt/dolphinscheduler/libs/okhttp-4.9.3.jar:/opt/dolphinscheduler/libs/profiles-2.17.282.jar:/opt/dolphinscheduler/libs/hadoop-auth-3.2.4.jar:/opt/dolphinscheduler/libs/grpc-netty-1.41.0.jar:/opt/dolphinscheduler/libs/httpcore-nio-4.4.15.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-seatunnel-3.2.1.jar:/opt/dolphinscheduler/libs/aws-java-sdk-sagemaker-1.12.300.jar:/opt/dolphinscheduler/libs/oshi-core-6.1.1.jar:/opt/dolphinscheduler/libs/bonecp-0.8.0.RELEASE.jar:/opt/dolphinscheduler/libs/jackson-module-parameter-names-2.13.3.jar:/opt/dolphinscheduler/libs/bcutil-jdk15on-1.69.jar:/opt/dolphinscheduler/libs/aws-json-protocol-2.17.282.jar:/opt/dolphinscheduler/libs/dolphinscheduler-extract-base-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-all-3.2.1.jar:/opt/dolphinscheduler/libs/derby-10.14.2.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-snowflake-3.2.1.jar:/opt/dolphinscheduler/libs/netty-codec-http2-4.1.53.Final.jar:/opt/dolphinscheduler/libs/jetty-continuation-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/jackson-mapper-asl-1.9.13.jar:/opt/dolphinscheduler/libs/datanucleus-core-4.1.17.jar:/opt/dolphinscheduler/libs/netty-tcnative-boringssl-static-2.0.53.Final-osx-aarch_64.jar:/opt/dolphinscheduler/libs/failureaccess-1.0.1.jar:/opt/dolphinscheduler/libs/error_prone_annotations-2.5.1.jar:/opt/dolphinscheduler/libs/kerb-admin-1.0.1.jar:/opt/dolphinscheduler/libs/token-provider-1.0.1.jar:/opt/dolphinscheduler/libs/reactor-netty-core-1.0.22.jar:/opt/dolphinscheduler/libs/dolphinscheduler-registry-all-3.2.1.jar:/opt/dolphinscheduler/libs/jakarta.servlet-api-4.0.4.jar:/opt/dolphinscheduler/libs/http-client-spi-2.17.282.jar:/opt/dolphinscheduler/libs/regions-2.17.282.jar:/opt/dolphinscheduler/libs/logback-core-1.2.11.jar:/opt/dolphinscheduler/libs/json-1.8.jar:/opt/dolphinscheduler/libs/gax-grpc-2.23.0.jar:/opt/dolphinscheduler/libs/google-http-client-1.42.3.jar:/opt/dolphinscheduler/libs/hive-serde-2.3.9.jar:/opt/dolphinscheduler/libs/jettison-1.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-http-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-registry-zookeeper-3.2.1.jar:/opt/dolphinscheduler/libs/spring-security-crypto-5.7.3.jar:/opt/dolphinscheduler/libs/auth-2.17.282.jar:/opt/dolphinscheduler/libs/proto-google-cloud-storage-v2-2.18.0-alpha.jar:/opt/dolphinscheduler/libs/jetty-server-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/javax.annotation-api-1.3.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-starrocks-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-dataquality-3.2.1.jar:/opt/dolphinscheduler/libs/jcl-over-slf4j-1.7.36.jar:/opt/dolphinscheduler/libs/commons-lang3-3.12.0.jar:/opt/dolphinscheduler/libs/tomcat-embed-el-9.0.65.jar:/opt/dolphinscheduler/libs/opentracing-noop-0.33.0.jar:/opt/dolphinscheduler/libs/client-java-13.0.2.jar:/opt/dolphinscheduler/libs/spring-beans-5.3.22.jar:/opt/dolphinscheduler/libs/snakeyaml-1.33.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-ssh-3.2.1.jar:/opt/dolphinscheduler/libs/commons-pool-1.6.jar:/opt/dolphinscheduler/libs/javax.servlet-api-3.1.0.jar:/opt/dolphinscheduler/libs/hadoop-common-3.2.4.jar:/opt/dolphinscheduler/libs/kubernetes-model-apiextensions-5.10.2.jar:/opt/dolphinscheduler/libs/spring-boot-2.7.3.jar:/opt/dolphinscheduler/libs/bcprov-ext-jdk15on-1.69.jar:/opt/dolphinscheduler/libs/spring-boot-starter-2.7.3.jar:/opt/dolphinscheduler/libs/paranamer-2.3.jar:/opt/dolphinscheduler/libs/httpmime-4.5.13.jar:/opt/dolphinscheduler/libs/reactor-core-3.4.22.jar:/opt/dolphinscheduler/libs/azure-core-1.36.0.jar:/opt/dolphinscheduler/libs/bcpkix-jdk15on-1.69.jar:/opt/dolphinscheduler/libs/kubernetes-model-scheduling-5.10.2.jar:/opt/dolphinscheduler/libs/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/dolphinscheduler/libs/websocket-client-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/unirest-java-3.7.04-standalone.jar:/opt/dolphinscheduler/libs/hadoop-mapreduce-client-core-3.2.4.jar:/opt/dolphinscheduler/libs/google-auth-library-credentials-1.15.0.jar:/opt/dolphinscheduler/libs/azure-storage-internal-avro-12.6.0.jar:/opt/dolphinscheduler/libs/jackson-datatype-jdk8-2.13.3.jar:/opt/dolphinscheduler/libs/spring-expression-5.3.22.jar:/opt/dolphinscheduler/libs/aspectjweaver-1.9.7.jar:/opt/dolphinscheduler/libs/websocket-common-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/client-java-api-fluent-13.0.2.jar:/opt/dolphinscheduler/libs/mybatis-plus-3.5.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-athena-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-oss-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-openmldb-3.2.1.jar:/opt/dolphinscheduler/libs/curator-recipes-5.3.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-api-3.2.1.jar:/opt/dolphinscheduler/libs/netty-all-4.1.53.Final.jar:/opt/dolphinscheduler/libs/netty-resolver-dns-4.1.53.Final.jar:/opt/dolphinscheduler/libs/kubernetes-model-autoscaling-5.10.2.jar:/opt/dolphinscheduler/libs/kerb-util-1.0.1.jar:/opt/dolphinscheduler/libs/grpc-alts-1.41.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-presto-3.2.1.jar:/opt/dolphinscheduler/libs/kerb-simplekdc-1.0.1.jar:/opt/dolphinscheduler/libs/protobuf-java-util-3.17.2.jar:/opt/dolphinscheduler/libs/azure-core-http-netty-1.13.0.jar:/opt/dolphinscheduler/libs/transaction-api-1.1.jar:/opt/dolphinscheduler/libs/datanucleus-api-jdo-4.2.4.jar:/opt/dolphinscheduler/libs/zeppelin-common-0.10.1.jar:/opt/dolphinscheduler/libs/zt-zip-1.15.jar:/opt/dolphinscheduler/libs/animal-sniffer-annotations-1.19.jar:/opt/dolphinscheduler/libs/google-http-client-jackson2-1.42.3.jar:/opt/dolphinscheduler/libs/netty-buffer-4.1.53.Final.jar:/opt/dolphinscheduler/libs/jsr305-3.0.0.jar:/opt/dolphinscheduler/libs/netty-transport-classes-epoll-4.1.79.Final.jar:/opt/dolphinscheduler/libs/spring-boot-actuator-autoconfigure-2.7.3.jar:/opt/dolphinscheduler/libs/simpleclient-0.15.0.jar:/opt/dolphinscheduler/libs/aliyun-sdk-oss-3.15.1.jar:/opt/dolphinscheduler/libs/json-utils-2.17.282.jar:/opt/dolphinscheduler/libs/tephra-api-0.6.0.jar:/opt/dolphinscheduler/libs/spring-jdbc-5.3.22.jar:/opt/dolphinscheduler/libs/grpc-xds-1.41.0.jar:/opt/dolphinscheduler/libs/logback-classic-1.2.11.jar:/opt/dolphinscheduler/libs/google-cloud-storage-2.18.0.jar:/opt/dolphinscheduler/libs/micrometer-registry-prometheus-1.9.3.jar:/opt/dolphinscheduler/libs/grpc-core-1.41.0.jar:/opt/dolphinscheduler/libs/aws-java-sdk-kms-1.12.300.jar:/opt/dolphinscheduler/libs/kubernetes-model-rbac-5.10.2.jar:/opt/dolphinscheduler/libs/ini4j-0.5.4.jar:/opt/dolphinscheduler/libs/spring-boot-starter-web-2.7.3.jar:/opt/dolphinscheduler/libs/spring-cloud-commons-3.1.3.jar:/opt/dolphinscheduler/libs/netty-codec-http-4.1.53.Final.jar:/opt/dolphinscheduler/libs/jetty-client-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/jetcd-common-0.5.11.jar:/opt/dolphinscheduler/libs/metrics-spi-2.17.282.jar:/opt/dolphinscheduler/libs/utils-2.17.282.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-emr-3.2.1.jar:/opt/dolphinscheduler/libs/protocol-core-2.17.282.jar:/opt/dolphinscheduler/libs/micrometer-core-1.9.3.jar:/opt/dolphinscheduler/libs/netty-transport-native-unix-common-4.1.53.Final.jar:/opt/dolphinscheduler/libs/zjsonpatch-0.4.11.jar:/opt/dolphinscheduler/libs/annotations-2.17.282.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-sql-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-extract-common-3.2.1.jar:/opt/dolphinscheduler/libs/apache-client-2.17.282.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-oceanbase-3.2.1.jar:/opt/dolphinscheduler/libs/jdo-api-3.0.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-datax-3.2.1.jar:/opt/dolphinscheduler/libs/postgresql-42.4.1.jar:/opt/dolphinscheduler/libs/jetty-util-ajax-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/gax-2.23.0.jar:/opt/dolphinscheduler/libs/grpc-stub-1.41.0.jar:/opt/dolphinscheduler/libs/libfb303-0.9.3.jar:/opt/dolphinscheduler/libs/spring-core-5.3.22.jar:/opt/dolphinscheduler/libs/jaxb-api-2.3.1.jar:/opt/dolphinscheduler/libs/hive-service-rpc-2.3.9.jar:/opt/dolphinscheduler/libs/kubernetes-model-flowcontrol-5.10.2.jar:/opt/dolphinscheduler/libs/commons-logging-1.1.1.jar:/opt/dolphinscheduler/libs/mybatis-spring-2.0.7.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-oracle-3.2.1.jar:/opt/dolphinscheduler/libs/opencensus-proto-0.2.0.jar:/opt/dolphinscheduler/libs/grpc-protobuf-1.41.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-clickhouse-3.2.1.jar:/opt/dolphinscheduler/libs/spring-cloud-starter-bootstrap-3.1.3.jar:/opt/dolphinscheduler/libs/kubernetes-model-admissionregistration-5.10.2.jar:/opt/dolphinscheduler/libs/grpc-google-cloud-storage-v2-2.18.0-alpha.jar:/opt/dolphinscheduler/libs/esdk-obs-java-bundle-3.23.3.jar:/opt/dolphinscheduler/libs/dnsjava-2.1.7.jar:/opt/dolphinscheduler/libs/asm-9.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-spark-3.2.1.jar:/opt/dolphinscheduler/libs/netty-tcnative-boringssl-static-2.0.53.Final-linux-aarch_64.jar:/opt/dolphinscheduler/libs/re2j-1.6.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-vertica-3.2.1.jar:/opt/dolphinscheduler/libs/json-smart-2.4.8.jar:/opt/dolphinscheduler/libs/reactor-netty-http-1.0.22.jar:/opt/dolphinscheduler/libs/google-api-services-storage-v1-rev20220705-2.0.0.jar:/opt/dolphinscheduler/libs/kubernetes-client-6.0.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-kyuubi-3.2.1.jar:/opt/dolphinscheduler/libs/auto-value-annotations-1.10.1.jar:/opt/dolphinscheduler/libs/commons-cli-1.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-data-quality-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-chunjun-3.2.1.jar:/opt/dolphinscheduler/libs/kerb-server-1.0.1.jar:/opt/dolphinscheduler/libs/content-type-2.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-remoteshell-3.2.1.jar:/opt/dolphinscheduler/libs/opencensus-contrib-http-util-0.31.1.jar:/opt/dolphinscheduler/libs/druid-1.2.20.jar:/opt/dolphinscheduler/libs/javolution-5.5.1.jar:/opt/dolphinscheduler/libs/protobuf-java-3.17.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-db2-3.2.1.jar:/opt/dolphinscheduler/libs/aws-java-sdk-core-1.12.300.jar:/opt/dolphinscheduler/libs/spring-boot-starter-logging-2.7.3.jar:/opt/dolphinscheduler/libs/kerby-pkix-1.0.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-procedure-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-registry-etcd-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-sqoop-3.2.1.jar:/opt/dolphinscheduler/libs/zookeeper-jute-3.8.0.jar:/opt/dolphinscheduler/libs/netty-resolver-dns-native-macos-4.1.53.Final-osx-x86_64.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-sagemaker-3.2.1.jar:/opt/dolphinscheduler/libs/spring-boot-configuration-processor-2.6.1.jar:/opt/dolphinscheduler/libs/hive-common-2.3.9.jar:/opt/dolphinscheduler/libs/kerb-common-1.0.1.jar:/opt/dolphinscheduler/libs/stax-api-1.0.1.jar:/opt/dolphinscheduler/libs/kubernetes-model-storageclass-5.10.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-s3-3.2.1.jar:/opt/dolphinscheduler/libs/spring-boot-starter-jetty-2.7.3.jar:/opt/dolphinscheduler/libs/okio-2.8.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-dms-3.2.1.jar:/opt/dolphinscheduler/libs/simpleclient_common-0.15.0.jar:/opt/dolphinscheduler/libs/sdk-core-2.17.282.jar:/opt/dolphinscheduler/libs/javax.activation-api-1.2.0.jar:/opt/dolphinscheduler/libs/netty-handler-proxy-4.1.53.Final.jar:/opt/dolphinscheduler/libs/kerby-config-1.0.1.jar:/opt/dolphinscheduler/libs/netty-tcnative-classes-2.0.53.Final.jar:/opt/dolphinscheduler/libs/jackson-jaxrs-base-2.13.3.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-trino-3.2.1.jar:/opt/dolphinscheduler/libs/presto-jdbc-0.238.1.jar:/opt/dolphinscheduler/libs/websocket-api-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-flink-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-api-3.2.1.jar:/opt/dolphinscheduler/libs/kubernetes-model-metrics-5.10.2.jar:/opt/dolphinscheduler/libs/datasync-2.17.282.jar:/opt/dolphinscheduler/libs/hadoop-yarn-api-3.2.4.jar:/opt/dolphinscheduler/libs/google-http-client-apache-v2-1.42.3.jar:/opt/dolphinscheduler/libs/hadoop-annotations-3.2.4.jar:/opt/dolphinscheduler/libs/google-oauth-client-1.34.1.jar:/opt/dolphinscheduler/libs/sshd-common-2.8.0.jar:/opt/dolphinscheduler/libs/LatencyUtils-2.0.3.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-spark-3.2.1.jar:/opt/dolphinscheduler/libs/slf4j-api-1.7.36.jar:/opt/dolphinscheduler/libs/snowflake-jdbc-3.13.29.jar:/opt/dolphinscheduler/libs/jackson-datatype-jsr310-2.13.3.jar:/opt/dolphinscheduler/libs/trino-jdbc-402.jar:/opt/dolphinscheduler/libs/logging-interceptor-4.9.3.jar:/opt/dolphinscheduler/libs/simpleclient_tracer_otel_agent-0.15.0.jar:/opt/dolphinscheduler/libs/janino-3.0.16.jar:/opt/dolphinscheduler/libs/jackson-dataformat-yaml-2.13.3.jar:/opt/dolphinscheduler/libs/ion-java-1.0.2.jar:/opt/dolphinscheduler/libs/commons-dbcp-1.4.jar:/opt/dolphinscheduler/libs/jsp-api-2.1.jar:/opt/dolphinscheduler/libs/google-http-client-gson-1.42.3.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-hivecli-3.2.1.jar:/opt/dolphinscheduler/libs/spring-boot-actuator-2.7.3.jar:/opt/dolphinscheduler/libs/google-cloud-core-http-2.10.0.jar:/opt/dolphinscheduler/libs/DmJdbcDriver18-8.1.2.79.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-java-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-dameng-3.2.1.jar:/opt/dolphinscheduler/libs/sshd-sftp-2.8.0.jar:/opt/dolphinscheduler/libs/kerb-crypto-1.0.1.jar:/opt/dolphinscheduler/libs/conscrypt-openjdk-uber-2.5.2.jar:/opt/dolphinscheduler/libs/httpcore-4.4.15.jar:/opt/dolphinscheduler/libs/lz4-java-1.4.0.jar:/opt/dolphinscheduler/libs/guava-retrying-2.0.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-flink-stream-3.2.1.jar:/opt/dolphinscheduler/libs/spring-tx-5.3.22.jar:/opt/dolphinscheduler/libs/grpc-auth-1.41.0.jar:/opt/dolphinscheduler/libs/netty-tcnative-boringssl-static-2.0.53.Final-osx-x86_64.jar:/opt/dolphinscheduler/libs/databend-jdbc-0.0.7.jar:/opt/dolphinscheduler/libs/bcprov-jdk15on-1.69.jar:/opt/dolphinscheduler/libs/commons-lang-2.6.jar:/opt/dolphinscheduler/libs/kubernetes-model-policy-5.10.2.jar:/opt/dolphinscheduler/libs/commons-io-2.11.0.jar:/opt/dolphinscheduler/libs/grpc-grpclb-1.41.0.jar:/opt/dolphinscheduler/libs/netty-tcnative-boringssl-static-2.0.53.Final-linux-x86_64.jar:/opt/dolphinscheduler/libs/opentracing-api-0.33.0.jar:/opt/dolphinscheduler/libs/sshd-scp-2.8.0.jar:/opt/dolphinscheduler/libs/reload4j-1.2.18.3.jar:/opt/dolphinscheduler/libs/netty-tcnative-2.0.48.Final.jar:/opt/dolphinscheduler/libs/jdom2-2.0.6.1.jar:/opt/dolphinscheduler/libs/spring-boot-starter-json-2.7.3.jar:/opt/dolphinscheduler/libs/netty-transport-native-epoll-4.1.53.Final.jar:/opt/dolphinscheduler/libs/google-cloud-core-2.10.0.jar:/opt/dolphinscheduler/libs/javax.jdo-3.2.0-m3.jar:/opt/dolphinscheduler/libs/gax-httpjson-0.108.0.jar:/opt/dolphinscheduler/libs/mybatis-plus-core-3.5.2.jar:/opt/dolphinscheduler/libs/auto-service-annotations-1.0.1.jar:/opt/dolphinscheduler/libs/nimbus-jose-jwt-9.22.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-zeppelin-3.2.1.jar:/opt/dolphinscheduler/libs/commons-compress-1.21.jar:/opt/dolphinscheduler/libs/hadoop-hdfs-client-3.2.4.jar:/opt/dolphinscheduler/libs/msal4j-persistence-extension-1.1.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-pytorch-3.2.1.jar:/opt/dolphinscheduler/libs/netty-tcnative-boringssl-static-2.0.53.Final-windows-x86_64.jar:/opt/dolphinscheduler/libs/jetty-servlets-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/woodstox-core-6.4.0.jar:/opt/dolphinscheduler/libs/spring-cloud-kubernetes-commons-2.1.3.jar:/opt/dolphinscheduler/libs/grpc-protobuf-lite-1.41.0.jar:/opt/dolphinscheduler/libs/jetty-webapp-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/eventstream-1.0.1.jar:/opt/dolphinscheduler/libs/commons-compiler-3.1.7.jar:/opt/dolphinscheduler/libs/netty-transport-4.1.53.Final.jar:/opt/dolphinscheduler/libs/spring-cloud-context-3.1.3.jar:/opt/dolphinscheduler/libs/aws-java-sdk-dms-1.12.300.jar:/opt/dolphinscheduler/libs/hive-storage-api-2.4.0.jar:/opt/dolphinscheduler/libs/client-java-spring-integration-13.0.2.jar:/opt/dolphinscheduler/libs/spring-boot-starter-actuator-2.7.3.jar:/opt/dolphinscheduler/libs/third-party-jackson-core-2.17.282.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-hdfs-3.2.1.jar:/opt/dolphinscheduler/libs/netty-codec-4.1.53.Final.jar:/opt/dolphinscheduler/libs/google-http-client-appengine-1.42.3.jar:/opt/dolphinscheduler/libs/commons-configuration2-2.1.1.jar:/opt/dolphinscheduler/libs/datanucleus-rdbms-4.1.19.jar:/opt/dolphinscheduler/libs/swagger-annotations-1.6.2.jar:/opt/dolphinscheduler/libs/simpleclient_tracer_otel-0.15.0.jar:/opt/dolphinscheduler/libs/kotlin-stdlib-common-1.6.21.jar:/opt/dolphinscheduler/libs/aws-core-2.17.282.jar:/opt/dolphinscheduler/libs/kerb-core-1.0.1.jar:/opt/dolphinscheduler/libs/httpasyncclient-4.1.5.jar:/opt/dolphinscheduler/libs/dolphinscheduler-extract-worker-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-spi-3.2.1.jar:/opt/dolphinscheduler/libs/okhttp-2.7.5.jar:/opt/dolphinscheduler/libs/google-api-client-2.2.0.jar:/opt/dolphinscheduler/libs/kotlin-stdlib-1.6.21.jar:/opt/dolphinscheduler/libs/jakarta.websocket-api-1.1.2.jar:/opt/dolphinscheduler/libs/libthrift-0.9.3.jar:/opt/dolphinscheduler/libs/spring-boot-starter-aop-2.7.3.jar:/opt/dolphinscheduler/libs/netty-common-4.1.53.Final.jar:/opt/dolphinscheduler/libs/log4j-1.2-api-2.17.2.jar:/opt/dolphinscheduler/libs/jackson-databind-2.13.4.jar:/opt/dolphinscheduler/libs/jackson-dataformat-xml-2.13.3.jar:/opt/dolphinscheduler/libs/kubernetes-model-events-5.10.2.jar:/opt/dolphinscheduler/libs/gson-2.9.1.jar:/opt/dolphinscheduler/libs/proto-google-iam-v1-1.9.0.jar:/opt/dolphinscheduler/libs/netty-codec-socks-4.1.53.Final.jar:/opt/dolphinscheduler/libs/zjsonpatch-0.3.0.jar:/opt/dolphinscheduler/libs/hadoop-mapreduce-client-common-3.2.4.jar:/opt/dolphinscheduler/libs/dolphinscheduler-registry-api-3.2.1.jar:/opt/dolphinscheduler/libs/azure-storage-blob-12.21.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-zeppelin-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-api-3.2.1.jar:/opt/dolphinscheduler/libs/aws-java-sdk-s3-1.12.300.jar:/opt/dolphinscheduler/libs/stax2-api-4.2.1.jar:/opt/dolphinscheduler/libs/jakarta.annotation-api-1.3.5.jar:/opt/dolphinscheduler/libs/kubernetes-model-discovery-5.10.2.jar:/opt/dolphinscheduler/libs/jna-5.10.0.jar:/opt/dolphinscheduler/libs/spring-jcl-5.3.22.jar
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:39.706 +0800 o.a.z.ZooKeeper:[98] - Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:39.707 +0800 o.a.z.ZooKeeper:[98] - Client environment:java.io.tmpdir=/tmp
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:39.707 +0800 o.a.z.ZooKeeper:[98] - Client environment:java.compiler=<NA>
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:39.707 +0800 o.a.z.ZooKeeper:[98] - Client environment:os.name=Linux
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:39.707 +0800 o.a.z.ZooKeeper:[98] - Client environment:os.arch=amd64
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:39.708 +0800 o.a.z.ZooKeeper:[98] - Client environment:os.version=6.5.0-28-generic
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:39.709 +0800 o.a.z.ZooKeeper:[98] - Client environment:user.name=root
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:39.710 +0800 o.a.z.ZooKeeper:[98] - Client environment:user.home=/root
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:39.711 +0800 o.a.z.ZooKeeper:[98] - Client environment:user.dir=/opt/dolphinscheduler
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:39.713 +0800 o.a.z.ZooKeeper:[98] - Client environment:os.memory.free=3196MB
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:39.715 +0800 o.a.z.ZooKeeper:[98] - Client environment:os.memory.max=3840MB
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:39.729 +0800 o.a.z.ZooKeeper:[98] - Client environment:os.memory.total=3840MB
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:39.764 +0800 o.a.z.ZooKeeper:[637] - Initiating client connection, connectString=dolphinscheduler-zookeeper:2181 sessionTimeout=30000 watcher=org.apache.curator.ConnectionState@21a5b599
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:39.819 +0800 o.a.z.c.X509Util:[77] - Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:39.864 +0800 o.a.z.ClientCnxnSocket:[239] - jute.maxbuffer value is 1048575 Bytes
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:39.940 +0800 o.a.z.ClientCnxn:[1732] - zookeeper.request.timeout value is 0. feature enabled=false
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:40.088 +0800 o.a.c.f.i.CuratorFrameworkImpl:[386] - Default schema
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:40.084 +0800 o.a.z.ClientCnxn:[1171] - Opening socket connection to server dolphinscheduler-zookeeper/172.18.0.3:2181.
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:40.128 +0800 o.a.z.ClientCnxn:[1173] - SASL config status: Will not attempt to authenticate using SASL (unknown error)
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:40.281 +0800 o.a.z.ClientCnxn:[1005] - Socket connection established, initiating session, client: /172.18.1.1:52532, server: dolphinscheduler-zookeeper/172.18.0.3:2181
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:40.496 +0800 o.a.z.ClientCnxn:[1444] - Session establishment complete on server dolphinscheduler-zookeeper/172.18.0.3:2181, session id = 0x100000679d10001, negotiated timeout = 30000
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:40.616 +0800 o.a.c.f.s.ConnectionStateManager:[252] - State change: CONNECTED
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:40.846 +0800 o.a.c.f.i.EnsembleTracker:[201] - New config event received: {}
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:40.858 +0800 o.a.c.f.i.EnsembleTracker:[201] - New config event received: {}
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:42.650 +0800 o.a.d.s.w.r.WorkerRpcServer:[41] - WorkerRpcServer starting...
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:44.859 +0800 o.a.d.e.b.NettyRemotingServer:[112] - WorkerRpcServer bind success at port: 1234
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:44.859 +0800 o.a.d.s.w.r.WorkerRpcServer:[43] - WorkerRpcServer started...
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:45.248 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: JAVA - JavaTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:45.303 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: JAVA - JavaTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:45.304 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: JUPYTER - JupyterTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:45.308 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: JUPYTER - JupyterTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:45.309 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: SPARK - SparkTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:45.314 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: SPARK - SparkTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:45.314 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: FLINK_STREAM - FlinkStreamTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:45.319 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: FLINK_STREAM - FlinkStreamTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:45.320 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: PYTHON - PythonTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:45.321 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: PYTHON - PythonTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:45.321 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: DATASYNC - DatasyncTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:45.322 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: DATASYNC - DatasyncTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:45.323 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: DATA_FACTORY - DatafactoryTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:45.324 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: DATA_FACTORY - DatafactoryTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:45.324 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: CHUNJUN - ChunJunTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:45.326 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: CHUNJUN - ChunJunTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:45.327 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: REMOTESHELL - RemoteShellTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:45.329 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: REMOTESHELL - RemoteShellTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:45.329 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: PIGEON - PigeonTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:45.331 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: PIGEON - PigeonTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:45.331 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: SHELL - ShellTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:45.332 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: SHELL - ShellTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:45.333 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: PROCEDURE - ProcedureTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:45.335 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: PROCEDURE - ProcedureTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:45.335 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: MR - MapReduceTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:45.336 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: MR - MapReduceTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:45.336 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: SQOOP - SqoopTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:45.338 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: SQOOP - SqoopTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:45.339 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: PYTORCH - PytorchTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:45.342 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: PYTORCH - PytorchTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:45.342 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: K8S - K8sTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:45.344 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: K8S - K8sTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:45.345 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: SEATUNNEL - SeatunnelTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:45.348 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: SEATUNNEL - SeatunnelTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:45.348 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: SAGEMAKER - SagemakerTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:45.351 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: SAGEMAKER - SagemakerTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:45.351 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: HTTP - HttpTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:45.354 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: HTTP - HttpTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:45.360 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: EMR - EmrTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:45.364 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: EMR - EmrTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:45.365 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: DMS - DmsTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:45.368 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: DMS - DmsTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:45.368 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: DATA_QUALITY - DataQualityTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:45.371 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: DATA_QUALITY - DataQualityTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:45.372 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: KUBEFLOW - KubeflowTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:45.374 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: KUBEFLOW - KubeflowTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:45.379 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: SQL - SqlTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:45.384 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: SQL - SqlTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:45.386 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: DVC - DvcTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:45.390 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: DVC - DvcTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:45.391 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: DATAX - DataxTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:45.396 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: DATAX - DataxTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:45.398 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: ZEPPELIN - ZeppelinTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:45.402 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: ZEPPELIN - ZeppelinTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:45.403 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: DINKY - DinkyTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:45.421 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: DINKY - DinkyTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:45.423 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: MLFLOW - MlflowTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:45.443 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: MLFLOW - MlflowTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:45.452 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: OPENMLDB - OpenmldbTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:45.456 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: OPENMLDB - OpenmldbTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:45.460 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: LINKIS - LinkisTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:45.463 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: LINKIS - LinkisTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:45.464 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: FLINK - FlinkTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:45.466 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: FLINK - FlinkTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:45.468 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: HIVECLI - HiveCliTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:45.519 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: HIVECLI - HiveCliTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:45.973 +0800 o.a.d.c.u.JSONUtils:[72] - init timezone: sun.util.calendar.ZoneInfo[id="Asia/Shanghai",offset=28800000,dstSavings=0,useDaylight=false,transitions=31,lastRule=null]
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:46.453 +0800 o.a.d.s.w.r.WorkerRegistryClient:[104] - Worker node: 172.18.1.1:1234 registry to ZK /nodes/worker/172.18.1.1:1234 successfully
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:47.581 +0800 o.a.d.c.m.BaseHeartBeatTask:[48] - Starting WorkerHeartBeatTask...
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:47.582 +0800 o.a.d.c.m.BaseHeartBeatTask:[50] - Started WorkerHeartBeatTask, heartBeatInterval: 10000...
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:47.583 +0800 o.a.d.s.w.r.WorkerRegistryClient:[114] - Worker node: 172.18.1.1:1234 registry finished
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:47.586 +0800 o.a.d.s.w.m.MessageRetryRunner:[69] - Message retry runner staring
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:47.587 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.1526639344262295 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:47.844 +0800 o.a.d.s.w.m.MessageRetryRunner:[72] - Injected message sender: TaskInstanceExecutionFinishEventSender
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:47.844 +0800 o.a.d.s.w.m.MessageRetryRunner:[72] - Injected message sender: TaskInstanceExecutionInfoUpdateEventSender
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:47.855 +0800 o.a.d.s.w.m.MessageRetryRunner:[72] - Injected message sender: TaskInstanceExecutionRunningEventSender
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:47.868 +0800 o.a.d.s.w.m.MessageRetryRunner:[75] - Message retry runner started
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:49.011 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.4910714285714284 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:50.473 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.4427083333333335 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:51.477 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.1807692307692308 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:52.680 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.1769547325102883 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:53.699 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.3840579710144927 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:56.066 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.7357142857142858 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:57.283 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.6271186440677967 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:58.292 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.6363636363636365 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:06:59.951 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.7525773195876289 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:07:01.301 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.6094420600858368 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:07:02.403 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.2156862745098038 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:07:03.458 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.4187192118226601 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:07:04.836 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.9934640522875817 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:07:05.853 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.350785340314136 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:07:06.894 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.7483870967741935 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:07:07.897 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.6164383561643834 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:07:08.309 +0800 o.s.b.a.e.w.EndpointLinksResolver:[58] - Exposing 3 endpoint(s) beneath base path '/actuator'
[WI-0][TI-0] - [INFO] 2024-04-27 21:07:08.827 +0800 o.e.j.s.h.C.application:[2368] - Initializing Spring DispatcherServlet 'dispatcherServlet'
[WI-0][TI-0] - [INFO] 2024-04-27 21:07:08.827 +0800 o.s.w.s.DispatcherServlet:[525] - Initializing Servlet 'dispatcherServlet'
[WI-0][TI-0] - [INFO] 2024-04-27 21:07:08.852 +0800 o.s.w.s.DispatcherServlet:[547] - Completed initialization in 7 ms
[WI-0][TI-0] - [INFO] 2024-04-27 21:07:08.909 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.372093023255814 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:07:09.047 +0800 o.e.j.s.AbstractConnector:[333] - Started ServerConnector@e972ee1{HTTP/1.1, (http/1.1)}{0.0.0.0:1235}
[WI-0][TI-0] - [INFO] 2024-04-27 21:07:09.049 +0800 o.s.b.w.e.j.JettyWebServer:[172] - Jetty started on port(s) 1235 (http/1.1) with context path '/'
[WI-0][TI-0] - [INFO] 2024-04-27 21:07:09.177 +0800 o.a.d.s.w.WorkerServer:[61] - Started WorkerServer in 106.894 seconds (JVM running for 117.355)
[WI-0][TI-0] - [INFO] 2024-04-27 21:07:10.216 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.3216374269005848 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:07:11.485 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9810126582278481 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:07:12.488 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8630136986301371 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:07:13.501 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8888888888888888 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:07:14.517 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7327586206896551 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:07:16.801 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9226519337016574 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:07:17.826 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9692307692307691 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:07:18.845 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.3045267489711934 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:07:19.856 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9305555555555555 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:07:21.115 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8195876288659794 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:07:22.245 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9386724386724387 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:07:23.262 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.754424778761062 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:07:25.433 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8394324932859507 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:07:27.513 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9811320754716981 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:07:28.674 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9459459459459459 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:07:29.711 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9032258064516129 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:07:30.726 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8900456621004565 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:07:32.828 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8016528925619835 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:07:33.904 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9133333333333334 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:07:34.906 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8389261744966443 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:07:37.408 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8421052631578947 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:07:38.498 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9016393442622951 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:07:41.138 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.0083333333333333 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:07:42.340 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8538011695906432 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:07:44.523 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7621621621621621 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:08:21.920 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8389057750759878 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:08:22.943 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9478527607361963 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:08:23.960 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9864864864864865 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:08:24.972 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9621644198640397 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:08:26.002 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9906253605630553 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:08:27.005 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9540229885057472 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:08:29.038 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7005347593582888 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:08:30.064 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8905325443786982 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:08:31.066 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9387096774193548 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:08:34.093 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9632768361581922 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:08:35.201 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8801089918256131 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:08:36.208 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9212121212121213 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:08:37.266 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9470752089136492 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:08:38.290 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7507598784194528 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:08:52.358 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7923976608187134 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:09:02.529 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8299711815561961 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:09:03.650 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8463611859838275 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:09:04.660 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.801186943620178 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:09:05.664 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8805881307746979 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:09:06.667 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8576158940397351 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:09:07.672 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7837078651685393 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:09:29.962 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8694362017804155 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:09:33.049 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7701149425287357 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:09:35.122 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9348534201954397 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:09:41.282 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7492447129909365 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:12:21.430 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9088235294117646 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:12:23.540 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8704225352112676 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:12:24.584 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8168604651162792 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:12:26.604 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8941979522184301 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:14:22.250 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.823529411764706 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:14:25.358 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7288629737609329 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:14:26.398 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7976539589442815 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:14:27.400 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7507418397626112 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:14:30.438 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8106508875739645 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:14:31.555 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8140161725067385 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:14:32.564 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7492626618753814 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:14:53.667 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7270029673590503 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:14:55.777 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7572254335260116 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:14:58.830 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.880281690140845 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:14:59.849 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8444444444444444 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:15:00.853 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7682926829268293 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:15:08.973 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7699115044247787 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:15:09.993 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7558823529411764 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:15:11.009 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7492354740061162 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:15:12.011 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8567073170731708 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:15:14.070 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8076923076923077 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:15:31.292 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7485207100591716 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:15:32.340 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.07909604519774 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:15:37.381 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8405797101449275 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:15:38.407 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8909090909090909 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:15:38.720 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1869, taskName=keyword filtering, firstSubmitTime=1714223737285, startTime=0, taskType=PYTHON, workflowInstanceHost=172.18.0.9:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13377949373536, processDefineVersion=17, appIds=null, processInstanceId=684, scheduleTime=0, globalParams=[{"prop":"keywords","direct":"IN","type":"VARCHAR","value":"\"singapore\", \"lol\""}], executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[],"rawScript":"from pyspark.sql import SparkSession\nfrom pyspark.sql.functions import col, from_json\nfrom pyspark.sql.types import StringType, StructType, StructField, IntegerType\nimport os\n\n# Initialize Spark session in local mode\nimport findspark\nfindspark.init()\n\n# Set the environment variable\nos.environ[\"HADOOP_HOME\"] = r\"C:\\Users\\Intern-9CT2\\Downloads\\winutils-master\\winutils-master\\hadoop-3.3.5\"\n\nspark = SparkSession.builder \\\n    .master(\"local\") \\\n    .appName(\"Reddit Keyword Filtering\") \\\n    .config(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1\") \\\n    .config(\"spark.sql.streaming.checkpointLocation\", r\"C:\\CSIT_WORK\\tmp\") \\\n    .getOrCreate()\n\n# define the schema for the JSON data\nschema = StructType([\n    StructField(\"user\", StringType(), nullable=True),\n    StructField(\"content\", StringType(), nullable=True),\n    StructField(\"url\", StringType(), nullable=True),\n    StructField(\"context\", StringType(), nullable=True),\n    StructField(\"score\", IntegerType(), nullable=True),\n    StructField(\"subreddit\", StringType(), nullable=True),\n    StructField(\"type\", StringType(), nullable=True),\n    StructField(\"id\", StringType(), nullable=True),\n    StructField(\"datetime\", StringType(), nullable=True)  # Assuming the datetime is string type, you can change it to TimestampType if needed\n])\n\n# define the parameters for the input and output kafka broker and topic\nkafka_broker = \"kafka:9092\"\ninput_kafka_topic = \"reddit_post_preprocessed\"\noutput_kafka_topic = \"reddit_post_filtered\"\n\n# Subscribe to the input topic\ndf = spark \\\n    .readStream \\\n    .format(\"kafka\") \\\n    .option(\"kafka.bootstrap.servers\", kafka_broker) \\\n    .option(\"subscribe\", input_kafka_topic) \\\n    .load()\n\n# parse the JSON data in the 'value' column using the defined schema then create a dataframe containing the reddit data\ndf = df.select(col(\"value\").cast(\"string\")) \\\n    .withColumn(\"value\", from_json(\"value\", schema)) \\\n\nparsed_df = df \\\n    .select(\"value.*\")\n\n# filter rows containing specific keywords\nkeywords = ['singapore', 'sg']\n\n# initialize the filter condition with False\nfilter_condition = col(\"content\").contains(keywords[0])\n\n# loop through the rest of the keywords and update the filter condition\nfor keyword in keywords[1:]:\n    filter_condition = filter_condition | col(\"content\").contains(keyword)\n\n# apply the filter condition to the DataFrame\nfiltered_df = parsed_df.filter(filter_condition)\n\n# stream the data to kafka\nkafka_write = filtered_df \\\n    .selectExpr(\"'' AS key\", \"to_json(struct(*)) AS value\") \\\n    .writeStream \\\n    .format(\"kafka\") \\\n    .option(\"kafka.bootstrap.servers\", kafka_broker) \\\n    .option(\"topic\", output_kafka_topic) \\\n    .start()\n\n# Wait for the termination of the query\nkafka_write.awaitTermination()\n","resourceList":[]}, environmentConfig=export HADOOP_HOME=/opt/hadoop-3.4.0
export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export PYSPARK_DRIVER_PYTHON=/bin/python3.11
export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='keyword filtering'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, keywords=Property{prop='keywords', direct=IN, type=VARCHAR, value='"singapore", "lol"'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240427'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1869'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13377752024032'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240427211537'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='684'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240426'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='filter_data'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13377949373536'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=null, dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-684][TI-1869] - [INFO] 2024-04-27 21:15:38.787 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: keyword filtering to wait queue success
[WI-684][TI-1869] - [INFO] 2024-04-27 21:15:38.890 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-684][TI-1869] - [INFO] 2024-04-27 21:15:38.904 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-684][TI-1869] - [INFO] 2024-04-27 21:15:38.905 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-684][TI-1869] - [INFO] 2024-04-27 21:15:38.917 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-684][TI-1869] - [INFO] 2024-04-27 21:15:38.918 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1714223738918
[WI-684][TI-1869] - [INFO] 2024-04-27 21:15:38.919 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 684_1869
[WI-684][TI-1869] - [INFO] 2024-04-27 21:15:38.972 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1869,
  "taskName" : "keyword filtering",
  "firstSubmitTime" : 1714223737285,
  "startTime" : 1714223738918,
  "taskType" : "PYTHON",
  "workflowInstanceHost" : "172.18.0.9:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240427/13377949373536/17/684/1869.log",
  "processId" : 0,
  "processDefineCode" : 13377949373536,
  "processDefineVersion" : 17,
  "processInstanceId" : 684,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"keywords\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"\\\"singapore\\\", \\\"lol\\\"\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[],\"rawScript\":\"from pyspark.sql import SparkSession\\nfrom pyspark.sql.functions import col, from_json\\nfrom pyspark.sql.types import StringType, StructType, StructField, IntegerType\\nimport os\\n\\n# Initialize Spark session in local mode\\nimport findspark\\nfindspark.init()\\n\\n# Set the environment variable\\nos.environ[\\\"HADOOP_HOME\\\"] = r\\\"C:\\\\Users\\\\Intern-9CT2\\\\Downloads\\\\winutils-master\\\\winutils-master\\\\hadoop-3.3.5\\\"\\n\\nspark = SparkSession.builder \\\\\\n    .master(\\\"local\\\") \\\\\\n    .appName(\\\"Reddit Keyword Filtering\\\") \\\\\\n    .config(\\\"spark.jars.packages\\\", \\\"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1\\\") \\\\\\n    .config(\\\"spark.sql.streaming.checkpointLocation\\\", r\\\"C:\\\\CSIT_WORK\\\\tmp\\\") \\\\\\n    .getOrCreate()\\n\\n# define the schema for the JSON data\\nschema = StructType([\\n    StructField(\\\"user\\\", StringType(), nullable=True),\\n    StructField(\\\"content\\\", StringType(), nullable=True),\\n    StructField(\\\"url\\\", StringType(), nullable=True),\\n    StructField(\\\"context\\\", StringType(), nullable=True),\\n    StructField(\\\"score\\\", IntegerType(), nullable=True),\\n    StructField(\\\"subreddit\\\", StringType(), nullable=True),\\n    StructField(\\\"type\\\", StringType(), nullable=True),\\n    StructField(\\\"id\\\", StringType(), nullable=True),\\n    StructField(\\\"datetime\\\", StringType(), nullable=True)  # Assuming the datetime is string type, you can change it to TimestampType if needed\\n])\\n\\n# define the parameters for the input and output kafka broker and topic\\nkafka_broker = \\\"kafka:9092\\\"\\ninput_kafka_topic = \\\"reddit_post_preprocessed\\\"\\noutput_kafka_topic = \\\"reddit_post_filtered\\\"\\n\\n# Subscribe to the input topic\\ndf = spark \\\\\\n    .readStream \\\\\\n    .format(\\\"kafka\\\") \\\\\\n    .option(\\\"kafka.bootstrap.servers\\\", kafka_broker) \\\\\\n    .option(\\\"subscribe\\\", input_kafka_topic) \\\\\\n    .load()\\n\\n# parse the JSON data in the 'value' column using the defined schema then create a dataframe containing the reddit data\\ndf = df.select(col(\\\"value\\\").cast(\\\"string\\\")) \\\\\\n    .withColumn(\\\"value\\\", from_json(\\\"value\\\", schema)) \\\\\\n\\nparsed_df = df \\\\\\n    .select(\\\"value.*\\\")\\n\\n# filter rows containing specific keywords\\nkeywords = ['singapore', 'sg']\\n\\n# initialize the filter condition with False\\nfilter_condition = col(\\\"content\\\").contains(keywords[0])\\n\\n# loop through the rest of the keywords and update the filter condition\\nfor keyword in keywords[1:]:\\n    filter_condition = filter_condition | col(\\\"content\\\").contains(keyword)\\n\\n# apply the filter condition to the DataFrame\\nfiltered_df = parsed_df.filter(filter_condition)\\n\\n# stream the data to kafka\\nkafka_write = filtered_df \\\\\\n    .selectExpr(\\\"'' AS key\\\", \\\"to_json(struct(*)) AS value\\\") \\\\\\n    .writeStream \\\\\\n    .format(\\\"kafka\\\") \\\\\\n    .option(\\\"kafka.bootstrap.servers\\\", kafka_broker) \\\\\\n    .option(\\\"topic\\\", output_kafka_topic) \\\\\\n    .start()\\n\\n# Wait for the termination of the query\\nkafka_write.awaitTermination()\\n\",\"resourceList\":[]}",
  "environmentConfig" : "export HADOOP_HOME=/opt/hadoop-3.4.0\nexport SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3\nexport JAVA_HOME=/opt/java/openjdk\nexport PYSPARK_DRIVER_PYTHON=/bin/python3.11\nexport PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "keyword filtering"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "keywords" : {
      "prop" : "keywords",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "\"singapore\", \"lol\""
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240427"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1869"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13377752024032"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240427211537"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "684"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240426"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "filter_data"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13377949373536"
    }
  },
  "taskAppId" : "684_1869",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-684][TI-1869] - [INFO] 2024-04-27 21:15:38.992 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-684][TI-1869] - [INFO] 2024-04-27 21:15:38.992 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-684][TI-1869] - [INFO] 2024-04-27 21:15:38.993 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-0][TI-0] - [INFO] 2024-04-27 21:15:39.414 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.159375 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-684][TI-1869] - [INFO] 2024-04-27 21:15:39.596 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-684][TI-1869] - [INFO] 2024-04-27 21:15:39.784 +0800 o.a.d.c.u.OSUtils:[231] - create linux os user: default
[WI-684][TI-1869] - [INFO] 2024-04-27 21:15:39.788 +0800 o.a.d.c.u.OSUtils:[233] - execute cmd: sudo useradd -g root
 default
[WI-0][TI-1869] - [INFO] 2024-04-27 21:15:40.061 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1869, success=true)
[WI-0][TI-0] - [INFO] 2024-04-27 21:15:40.437 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9265175718849841 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-684][TI-1869] - [INFO] 2024-04-27 21:15:40.519 +0800 o.a.d.c.u.OSUtils:[190] - create user default success
[WI-684][TI-1869] - [INFO] 2024-04-27 21:15:40.523 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-684][TI-1869] - [INFO] 2024-04-27 21:15:40.552 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13377949373536_17/684/1869 check successfully
[WI-684][TI-1869] - [INFO] 2024-04-27 21:15:40.556 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.python.PythonTaskChannel successfully
[WI-684][TI-1869] - [INFO] 2024-04-27 21:15:40.567 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-684][TI-1869] - [INFO] 2024-04-27 21:15:40.608 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-684][TI-1869] - [INFO] 2024-04-27 21:15:40.615 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: PYTHON create successfully
[WI-684][TI-1869] - [INFO] 2024-04-27 21:15:40.623 +0800 o.a.d.p.t.p.PythonTask:[75] - Initialize python task params {
  "localParams" : [ ],
  "varPool" : null,
  "rawScript" : "from pyspark.sql import SparkSession\nfrom pyspark.sql.functions import col, from_json\nfrom pyspark.sql.types import StringType, StructType, StructField, IntegerType\nimport os\n\n# Initialize Spark session in local mode\nimport findspark\nfindspark.init()\n\n# Set the environment variable\nos.environ[\"HADOOP_HOME\"] = r\"C:\\Users\\Intern-9CT2\\Downloads\\winutils-master\\winutils-master\\hadoop-3.3.5\"\n\nspark = SparkSession.builder \\\n    .master(\"local\") \\\n    .appName(\"Reddit Keyword Filtering\") \\\n    .config(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1\") \\\n    .config(\"spark.sql.streaming.checkpointLocation\", r\"C:\\CSIT_WORK\\tmp\") \\\n    .getOrCreate()\n\n# define the schema for the JSON data\nschema = StructType([\n    StructField(\"user\", StringType(), nullable=True),\n    StructField(\"content\", StringType(), nullable=True),\n    StructField(\"url\", StringType(), nullable=True),\n    StructField(\"context\", StringType(), nullable=True),\n    StructField(\"score\", IntegerType(), nullable=True),\n    StructField(\"subreddit\", StringType(), nullable=True),\n    StructField(\"type\", StringType(), nullable=True),\n    StructField(\"id\", StringType(), nullable=True),\n    StructField(\"datetime\", StringType(), nullable=True)  # Assuming the datetime is string type, you can change it to TimestampType if needed\n])\n\n# define the parameters for the input and output kafka broker and topic\nkafka_broker = \"kafka:9092\"\ninput_kafka_topic = \"reddit_post_preprocessed\"\noutput_kafka_topic = \"reddit_post_filtered\"\n\n# Subscribe to the input topic\ndf = spark \\\n    .readStream \\\n    .format(\"kafka\") \\\n    .option(\"kafka.bootstrap.servers\", kafka_broker) \\\n    .option(\"subscribe\", input_kafka_topic) \\\n    .load()\n\n# parse the JSON data in the 'value' column using the defined schema then create a dataframe containing the reddit data\ndf = df.select(col(\"value\").cast(\"string\")) \\\n    .withColumn(\"value\", from_json(\"value\", schema)) \\\n\nparsed_df = df \\\n    .select(\"value.*\")\n\n# filter rows containing specific keywords\nkeywords = ['singapore', 'sg']\n\n# initialize the filter condition with False\nfilter_condition = col(\"content\").contains(keywords[0])\n\n# loop through the rest of the keywords and update the filter condition\nfor keyword in keywords[1:]:\n    filter_condition = filter_condition | col(\"content\").contains(keyword)\n\n# apply the filter condition to the DataFrame\nfiltered_df = parsed_df.filter(filter_condition)\n\n# stream the data to kafka\nkafka_write = filtered_df \\\n    .selectExpr(\"'' AS key\", \"to_json(struct(*)) AS value\") \\\n    .writeStream \\\n    .format(\"kafka\") \\\n    .option(\"kafka.bootstrap.servers\", kafka_broker) \\\n    .option(\"topic\", output_kafka_topic) \\\n    .start()\n\n# Wait for the termination of the query\nkafka_write.awaitTermination()\n",
  "resourceList" : [ ]
}
[WI-684][TI-1869] - [INFO] 2024-04-27 21:15:40.626 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-684][TI-1869] - [INFO] 2024-04-27 21:15:40.626 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: null successfully
[WI-684][TI-1869] - [INFO] 2024-04-27 21:15:40.633 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-684][TI-1869] - [INFO] 2024-04-27 21:15:40.634 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-684][TI-1869] - [INFO] 2024-04-27 21:15:40.635 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-684][TI-1869] - [INFO] 2024-04-27 21:15:40.636 +0800 o.a.d.p.t.p.PythonTask:[165] - raw python script : from pyspark.sql import SparkSession
from pyspark.sql.functions import col, from_json
from pyspark.sql.types import StringType, StructType, StructField, IntegerType
import os

# Initialize Spark session in local mode
import findspark
findspark.init()

# Set the environment variable
os.environ["HADOOP_HOME"] = r"C:\Users\Intern-9CT2\Downloads\winutils-master\winutils-master\hadoop-3.3.5"

spark = SparkSession.builder \
    .master("local") \
    .appName("Reddit Keyword Filtering") \
    .config("spark.jars.packages", "org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1") \
    .config("spark.sql.streaming.checkpointLocation", r"C:\CSIT_WORK\tmp") \
    .getOrCreate()

# define the schema for the JSON data
schema = StructType([
    StructField("user", StringType(), nullable=True),
    StructField("content", StringType(), nullable=True),
    StructField("url", StringType(), nullable=True),
    StructField("context", StringType(), nullable=True),
    StructField("score", IntegerType(), nullable=True),
    StructField("subreddit", StringType(), nullable=True),
    StructField("type", StringType(), nullable=True),
    StructField("id", StringType(), nullable=True),
    StructField("datetime", StringType(), nullable=True)  # Assuming the datetime is string type, you can change it to TimestampType if needed
])

# define the parameters for the input and output kafka broker and topic
kafka_broker = "kafka:9092"
input_kafka_topic = "reddit_post_preprocessed"
output_kafka_topic = "reddit_post_filtered"

# Subscribe to the input topic
df = spark \
    .readStream \
    .format("kafka") \
    .option("kafka.bootstrap.servers", kafka_broker) \
    .option("subscribe", input_kafka_topic) \
    .load()

# parse the JSON data in the 'value' column using the defined schema then create a dataframe containing the reddit data
df = df.select(col("value").cast("string")) \
    .withColumn("value", from_json("value", schema)) \

parsed_df = df \
    .select("value.*")

# filter rows containing specific keywords
keywords = ['singapore', 'sg']

# initialize the filter condition with False
filter_condition = col("content").contains(keywords[0])

# loop through the rest of the keywords and update the filter condition
for keyword in keywords[1:]:
    filter_condition = filter_condition | col("content").contains(keyword)

# apply the filter condition to the DataFrame
filtered_df = parsed_df.filter(filter_condition)

# stream the data to kafka
kafka_write = filtered_df \
    .selectExpr("'' AS key", "to_json(struct(*)) AS value") \
    .writeStream \
    .format("kafka") \
    .option("kafka.bootstrap.servers", kafka_broker) \
    .option("topic", output_kafka_topic) \
    .start()

# Wait for the termination of the query
kafka_write.awaitTermination()

[WI-684][TI-1869] - [INFO] 2024-04-27 21:15:40.664 +0800 o.a.d.p.t.p.PythonTask:[131] - tenantCode :default, task dir:/tmp/dolphinscheduler/exec/process/default/13010050770016/13377949373536_17/684/1869
[WI-684][TI-1869] - [INFO] 2024-04-27 21:15:40.665 +0800 o.a.d.p.t.p.PythonTask:[134] - generate python script file:/tmp/dolphinscheduler/exec/process/default/13010050770016/13377949373536_17/684/1869/py_684_1869.py
[WI-684][TI-1869] - [INFO] 2024-04-27 21:15:40.665 +0800 o.a.d.p.t.p.PythonTask:[141] - #-*- encoding=utf8 -*-

from pyspark.sql import SparkSession
from pyspark.sql.functions import col, from_json
from pyspark.sql.types import StringType, StructType, StructField, IntegerType
import os

# Initialize Spark session in local mode
import findspark
findspark.init()

# Set the environment variable
os.environ["HADOOP_HOME"] = r"C:\Users\Intern-9CT2\Downloads\winutils-master\winutils-master\hadoop-3.3.5"

spark = SparkSession.builder \
    .master("local") \
    .appName("Reddit Keyword Filtering") \
    .config("spark.jars.packages", "org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1") \
    .config("spark.sql.streaming.checkpointLocation", r"C:\CSIT_WORK\tmp") \
    .getOrCreate()

# define the schema for the JSON data
schema = StructType([
    StructField("user", StringType(), nullable=True),
    StructField("content", StringType(), nullable=True),
    StructField("url", StringType(), nullable=True),
    StructField("context", StringType(), nullable=True),
    StructField("score", IntegerType(), nullable=True),
    StructField("subreddit", StringType(), nullable=True),
    StructField("type", StringType(), nullable=True),
    StructField("id", StringType(), nullable=True),
    StructField("datetime", StringType(), nullable=True)  # Assuming the datetime is string type, you can change it to TimestampType if needed
])

# define the parameters for the input and output kafka broker and topic
kafka_broker = "kafka:9092"
input_kafka_topic = "reddit_post_preprocessed"
output_kafka_topic = "reddit_post_filtered"

# Subscribe to the input topic
df = spark \
    .readStream \
    .format("kafka") \
    .option("kafka.bootstrap.servers", kafka_broker) \
    .option("subscribe", input_kafka_topic) \
    .load()

# parse the JSON data in the 'value' column using the defined schema then create a dataframe containing the reddit data
df = df.select(col("value").cast("string")) \
    .withColumn("value", from_json("value", schema)) \

parsed_df = df \
    .select("value.*")

# filter rows containing specific keywords
keywords = ['singapore', 'sg']

# initialize the filter condition with False
filter_condition = col("content").contains(keywords[0])

# loop through the rest of the keywords and update the filter condition
for keyword in keywords[1:]:
    filter_condition = filter_condition | col("content").contains(keyword)

# apply the filter condition to the DataFrame
filtered_df = parsed_df.filter(filter_condition)

# stream the data to kafka
kafka_write = filtered_df \
    .selectExpr("'' AS key", "to_json(struct(*)) AS value") \
    .writeStream \
    .format("kafka") \
    .option("kafka.bootstrap.servers", kafka_broker) \
    .option("topic", output_kafka_topic) \
    .start()

# Wait for the termination of the query
kafka_write.awaitTermination()

[WI-684][TI-1869] - [INFO] 2024-04-27 21:15:40.763 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-684][TI-1869] - [INFO] 2024-04-27 21:15:40.764 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-684][TI-1869] - [INFO] 2024-04-27 21:15:40.765 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export HADOOP_HOME=/opt/hadoop-3.4.0
export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export PYSPARK_DRIVER_PYTHON=/bin/python3.11
export PYTHON_LAUNCHER=/bin/python3.11
${PYTHON_LAUNCHER} /tmp/dolphinscheduler/exec/process/default/13010050770016/13377949373536_17/684/1869/py_684_1869.py
[WI-684][TI-1869] - [INFO] 2024-04-27 21:15:40.765 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-684][TI-1869] - [INFO] 2024-04-27 21:15:40.768 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13377949373536_17/684/1869/684_1869.sh
[WI-684][TI-1869] - [INFO] 2024-04-27 21:15:40.791 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 209
[WI-0][TI-0] - [INFO] 2024-04-27 21:15:41.451 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9181818181818182 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-1869] - [INFO] 2024-04-27 21:15:41.671 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1869)
[WI-0][TI-0] - [INFO] 2024-04-27 21:15:41.804 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
[WI-0][TI-0] - [INFO] 2024-04-27 21:15:42.455 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7668711656441718 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:15:42.816 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	Traceback (most recent call last):
	  File "/tmp/dolphinscheduler/exec/process/default/13010050770016/13377949373536_17/684/1869/py_684_1869.py", line 9, in <module>
	    import findspark
	ModuleNotFoundError: No module named 'findspark'
[WI-684][TI-1869] - [INFO] 2024-04-27 21:15:42.826 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13377949373536_17/684/1869, processId:209 ,exitStatusCode:1 ,processWaitForStatus:true ,processExitValue:1
[WI-684][TI-1869] - [INFO] 2024-04-27 21:15:42.836 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-684][TI-1869] - [INFO] 2024-04-27 21:15:42.837 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-684][TI-1869] - [INFO] 2024-04-27 21:15:42.838 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-684][TI-1869] - [INFO] 2024-04-27 21:15:42.841 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-684][TI-1869] - [INFO] 2024-04-27 21:15:42.869 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: FAILURE to master : 172.18.1.1:1234
[WI-684][TI-1869] - [INFO] 2024-04-27 21:15:42.884 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-684][TI-1869] - [INFO] 2024-04-27 21:15:42.884 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13377949373536_17/684/1869
[WI-684][TI-1869] - [INFO] 2024-04-27 21:15:42.945 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13377949373536_17/684/1869
[WI-684][TI-1869] - [INFO] 2024-04-27 21:15:42.957 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-0] - [INFO] 2024-04-27 21:15:43.457 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7595307917888563 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-1869] - [INFO] 2024-04-27 21:15:43.703 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1869, success=true)
[WI-0][TI-0] - [INFO] 2024-04-27 21:15:43.969 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1870, taskName=keyword filtering, firstSubmitTime=1714223743816, startTime=0, taskType=PYTHON, workflowInstanceHost=172.18.0.9:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13377949373536, processDefineVersion=17, appIds=null, processInstanceId=684, scheduleTime=0, globalParams=[{"prop":"keywords","direct":"IN","type":"VARCHAR","value":"\"singapore\", \"lol\""}], executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[],"rawScript":"from pyspark.sql import SparkSession\nfrom pyspark.sql.functions import col, from_json\nfrom pyspark.sql.types import StringType, StructType, StructField, IntegerType\nimport os\n\n# Initialize Spark session in local mode\nimport findspark\nfindspark.init()\n\n# Set the environment variable\nos.environ[\"HADOOP_HOME\"] = r\"C:\\Users\\Intern-9CT2\\Downloads\\winutils-master\\winutils-master\\hadoop-3.3.5\"\n\nspark = SparkSession.builder \\\n    .master(\"local\") \\\n    .appName(\"Reddit Keyword Filtering\") \\\n    .config(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1\") \\\n    .config(\"spark.sql.streaming.checkpointLocation\", r\"C:\\CSIT_WORK\\tmp\") \\\n    .getOrCreate()\n\n# define the schema for the JSON data\nschema = StructType([\n    StructField(\"user\", StringType(), nullable=True),\n    StructField(\"content\", StringType(), nullable=True),\n    StructField(\"url\", StringType(), nullable=True),\n    StructField(\"context\", StringType(), nullable=True),\n    StructField(\"score\", IntegerType(), nullable=True),\n    StructField(\"subreddit\", StringType(), nullable=True),\n    StructField(\"type\", StringType(), nullable=True),\n    StructField(\"id\", StringType(), nullable=True),\n    StructField(\"datetime\", StringType(), nullable=True)  # Assuming the datetime is string type, you can change it to TimestampType if needed\n])\n\n# define the parameters for the input and output kafka broker and topic\nkafka_broker = \"kafka:9092\"\ninput_kafka_topic = \"reddit_post_preprocessed\"\noutput_kafka_topic = \"reddit_post_filtered\"\n\n# Subscribe to the input topic\ndf = spark \\\n    .readStream \\\n    .format(\"kafka\") \\\n    .option(\"kafka.bootstrap.servers\", kafka_broker) \\\n    .option(\"subscribe\", input_kafka_topic) \\\n    .load()\n\n# parse the JSON data in the 'value' column using the defined schema then create a dataframe containing the reddit data\ndf = df.select(col(\"value\").cast(\"string\")) \\\n    .withColumn(\"value\", from_json(\"value\", schema)) \\\n\nparsed_df = df \\\n    .select(\"value.*\")\n\n# filter rows containing specific keywords\nkeywords = ['singapore', 'sg']\n\n# initialize the filter condition with False\nfilter_condition = col(\"content\").contains(keywords[0])\n\n# loop through the rest of the keywords and update the filter condition\nfor keyword in keywords[1:]:\n    filter_condition = filter_condition | col(\"content\").contains(keyword)\n\n# apply the filter condition to the DataFrame\nfiltered_df = parsed_df.filter(filter_condition)\n\n# stream the data to kafka\nkafka_write = filtered_df \\\n    .selectExpr(\"'' AS key\", \"to_json(struct(*)) AS value\") \\\n    .writeStream \\\n    .format(\"kafka\") \\\n    .option(\"kafka.bootstrap.servers\", kafka_broker) \\\n    .option(\"topic\", output_kafka_topic) \\\n    .start()\n\n# Wait for the termination of the query\nkafka_write.awaitTermination()\n","resourceList":[]}, environmentConfig=export HADOOP_HOME=/opt/hadoop-3.4.0
export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export PYSPARK_DRIVER_PYTHON=/bin/python3.11
export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='keyword filtering'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, keywords=Property{prop='keywords', direct=IN, type=VARCHAR, value='"singapore", "lol"'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240427'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1870'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13377752024032'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240427211543'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='684'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240426'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='filter_data'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13377949373536'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-684][TI-1870] - [INFO] 2024-04-27 21:15:43.976 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: keyword filtering to wait queue success
[WI-684][TI-1870] - [INFO] 2024-04-27 21:15:43.977 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-684][TI-1870] - [INFO] 2024-04-27 21:15:43.981 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-684][TI-1870] - [INFO] 2024-04-27 21:15:44.002 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-684][TI-1870] - [INFO] 2024-04-27 21:15:44.004 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-684][TI-1870] - [INFO] 2024-04-27 21:15:44.005 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1714223744004
[WI-684][TI-1870] - [INFO] 2024-04-27 21:15:44.005 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 684_1870
[WI-684][TI-1870] - [INFO] 2024-04-27 21:15:44.008 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1870,
  "taskName" : "keyword filtering",
  "firstSubmitTime" : 1714223743816,
  "startTime" : 1714223744004,
  "taskType" : "PYTHON",
  "workflowInstanceHost" : "172.18.0.9:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240427/13377949373536/17/684/1870.log",
  "processId" : 0,
  "processDefineCode" : 13377949373536,
  "processDefineVersion" : 17,
  "processInstanceId" : 684,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"keywords\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"\\\"singapore\\\", \\\"lol\\\"\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[],\"rawScript\":\"from pyspark.sql import SparkSession\\nfrom pyspark.sql.functions import col, from_json\\nfrom pyspark.sql.types import StringType, StructType, StructField, IntegerType\\nimport os\\n\\n# Initialize Spark session in local mode\\nimport findspark\\nfindspark.init()\\n\\n# Set the environment variable\\nos.environ[\\\"HADOOP_HOME\\\"] = r\\\"C:\\\\Users\\\\Intern-9CT2\\\\Downloads\\\\winutils-master\\\\winutils-master\\\\hadoop-3.3.5\\\"\\n\\nspark = SparkSession.builder \\\\\\n    .master(\\\"local\\\") \\\\\\n    .appName(\\\"Reddit Keyword Filtering\\\") \\\\\\n    .config(\\\"spark.jars.packages\\\", \\\"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1\\\") \\\\\\n    .config(\\\"spark.sql.streaming.checkpointLocation\\\", r\\\"C:\\\\CSIT_WORK\\\\tmp\\\") \\\\\\n    .getOrCreate()\\n\\n# define the schema for the JSON data\\nschema = StructType([\\n    StructField(\\\"user\\\", StringType(), nullable=True),\\n    StructField(\\\"content\\\", StringType(), nullable=True),\\n    StructField(\\\"url\\\", StringType(), nullable=True),\\n    StructField(\\\"context\\\", StringType(), nullable=True),\\n    StructField(\\\"score\\\", IntegerType(), nullable=True),\\n    StructField(\\\"subreddit\\\", StringType(), nullable=True),\\n    StructField(\\\"type\\\", StringType(), nullable=True),\\n    StructField(\\\"id\\\", StringType(), nullable=True),\\n    StructField(\\\"datetime\\\", StringType(), nullable=True)  # Assuming the datetime is string type, you can change it to TimestampType if needed\\n])\\n\\n# define the parameters for the input and output kafka broker and topic\\nkafka_broker = \\\"kafka:9092\\\"\\ninput_kafka_topic = \\\"reddit_post_preprocessed\\\"\\noutput_kafka_topic = \\\"reddit_post_filtered\\\"\\n\\n# Subscribe to the input topic\\ndf = spark \\\\\\n    .readStream \\\\\\n    .format(\\\"kafka\\\") \\\\\\n    .option(\\\"kafka.bootstrap.servers\\\", kafka_broker) \\\\\\n    .option(\\\"subscribe\\\", input_kafka_topic) \\\\\\n    .load()\\n\\n# parse the JSON data in the 'value' column using the defined schema then create a dataframe containing the reddit data\\ndf = df.select(col(\\\"value\\\").cast(\\\"string\\\")) \\\\\\n    .withColumn(\\\"value\\\", from_json(\\\"value\\\", schema)) \\\\\\n\\nparsed_df = df \\\\\\n    .select(\\\"value.*\\\")\\n\\n# filter rows containing specific keywords\\nkeywords = ['singapore', 'sg']\\n\\n# initialize the filter condition with False\\nfilter_condition = col(\\\"content\\\").contains(keywords[0])\\n\\n# loop through the rest of the keywords and update the filter condition\\nfor keyword in keywords[1:]:\\n    filter_condition = filter_condition | col(\\\"content\\\").contains(keyword)\\n\\n# apply the filter condition to the DataFrame\\nfiltered_df = parsed_df.filter(filter_condition)\\n\\n# stream the data to kafka\\nkafka_write = filtered_df \\\\\\n    .selectExpr(\\\"'' AS key\\\", \\\"to_json(struct(*)) AS value\\\") \\\\\\n    .writeStream \\\\\\n    .format(\\\"kafka\\\") \\\\\\n    .option(\\\"kafka.bootstrap.servers\\\", kafka_broker) \\\\\\n    .option(\\\"topic\\\", output_kafka_topic) \\\\\\n    .start()\\n\\n# Wait for the termination of the query\\nkafka_write.awaitTermination()\\n\",\"resourceList\":[]}",
  "environmentConfig" : "export HADOOP_HOME=/opt/hadoop-3.4.0\nexport SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3\nexport JAVA_HOME=/opt/java/openjdk\nexport PYSPARK_DRIVER_PYTHON=/bin/python3.11\nexport PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "keyword filtering"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "keywords" : {
      "prop" : "keywords",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "\"singapore\", \"lol\""
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240427"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1870"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13377752024032"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240427211543"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "684"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240426"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "filter_data"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13377949373536"
    }
  },
  "taskAppId" : "684_1870",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "varPool" : "[]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-684][TI-1870] - [INFO] 2024-04-27 21:15:44.017 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-684][TI-1870] - [INFO] 2024-04-27 21:15:44.019 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-684][TI-1870] - [INFO] 2024-04-27 21:15:44.020 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-684][TI-1870] - [INFO] 2024-04-27 21:15:44.049 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-684][TI-1870] - [INFO] 2024-04-27 21:15:44.050 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-684][TI-1870] - [INFO] 2024-04-27 21:15:44.051 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13377949373536_17/684/1870 check successfully
[WI-684][TI-1870] - [INFO] 2024-04-27 21:15:44.051 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.python.PythonTaskChannel successfully
[WI-684][TI-1870] - [INFO] 2024-04-27 21:15:44.053 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-684][TI-1870] - [INFO] 2024-04-27 21:15:44.054 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-684][TI-1870] - [INFO] 2024-04-27 21:15:44.054 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: PYTHON create successfully
[WI-684][TI-1870] - [INFO] 2024-04-27 21:15:44.055 +0800 o.a.d.p.t.p.PythonTask:[75] - Initialize python task params {
  "localParams" : [ ],
  "varPool" : null,
  "rawScript" : "from pyspark.sql import SparkSession\nfrom pyspark.sql.functions import col, from_json\nfrom pyspark.sql.types import StringType, StructType, StructField, IntegerType\nimport os\n\n# Initialize Spark session in local mode\nimport findspark\nfindspark.init()\n\n# Set the environment variable\nos.environ[\"HADOOP_HOME\"] = r\"C:\\Users\\Intern-9CT2\\Downloads\\winutils-master\\winutils-master\\hadoop-3.3.5\"\n\nspark = SparkSession.builder \\\n    .master(\"local\") \\\n    .appName(\"Reddit Keyword Filtering\") \\\n    .config(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1\") \\\n    .config(\"spark.sql.streaming.checkpointLocation\", r\"C:\\CSIT_WORK\\tmp\") \\\n    .getOrCreate()\n\n# define the schema for the JSON data\nschema = StructType([\n    StructField(\"user\", StringType(), nullable=True),\n    StructField(\"content\", StringType(), nullable=True),\n    StructField(\"url\", StringType(), nullable=True),\n    StructField(\"context\", StringType(), nullable=True),\n    StructField(\"score\", IntegerType(), nullable=True),\n    StructField(\"subreddit\", StringType(), nullable=True),\n    StructField(\"type\", StringType(), nullable=True),\n    StructField(\"id\", StringType(), nullable=True),\n    StructField(\"datetime\", StringType(), nullable=True)  # Assuming the datetime is string type, you can change it to TimestampType if needed\n])\n\n# define the parameters for the input and output kafka broker and topic\nkafka_broker = \"kafka:9092\"\ninput_kafka_topic = \"reddit_post_preprocessed\"\noutput_kafka_topic = \"reddit_post_filtered\"\n\n# Subscribe to the input topic\ndf = spark \\\n    .readStream \\\n    .format(\"kafka\") \\\n    .option(\"kafka.bootstrap.servers\", kafka_broker) \\\n    .option(\"subscribe\", input_kafka_topic) \\\n    .load()\n\n# parse the JSON data in the 'value' column using the defined schema then create a dataframe containing the reddit data\ndf = df.select(col(\"value\").cast(\"string\")) \\\n    .withColumn(\"value\", from_json(\"value\", schema)) \\\n\nparsed_df = df \\\n    .select(\"value.*\")\n\n# filter rows containing specific keywords\nkeywords = ['singapore', 'sg']\n\n# initialize the filter condition with False\nfilter_condition = col(\"content\").contains(keywords[0])\n\n# loop through the rest of the keywords and update the filter condition\nfor keyword in keywords[1:]:\n    filter_condition = filter_condition | col(\"content\").contains(keyword)\n\n# apply the filter condition to the DataFrame\nfiltered_df = parsed_df.filter(filter_condition)\n\n# stream the data to kafka\nkafka_write = filtered_df \\\n    .selectExpr(\"'' AS key\", \"to_json(struct(*)) AS value\") \\\n    .writeStream \\\n    .format(\"kafka\") \\\n    .option(\"kafka.bootstrap.servers\", kafka_broker) \\\n    .option(\"topic\", output_kafka_topic) \\\n    .start()\n\n# Wait for the termination of the query\nkafka_write.awaitTermination()\n",
  "resourceList" : [ ]
}
[WI-684][TI-1870] - [INFO] 2024-04-27 21:15:44.056 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-684][TI-1870] - [INFO] 2024-04-27 21:15:44.092 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [] successfully
[WI-684][TI-1870] - [INFO] 2024-04-27 21:15:44.097 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-684][TI-1870] - [INFO] 2024-04-27 21:15:44.097 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-684][TI-1870] - [INFO] 2024-04-27 21:15:44.098 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-684][TI-1870] - [INFO] 2024-04-27 21:15:44.098 +0800 o.a.d.p.t.p.PythonTask:[165] - raw python script : from pyspark.sql import SparkSession
from pyspark.sql.functions import col, from_json
from pyspark.sql.types import StringType, StructType, StructField, IntegerType
import os

# Initialize Spark session in local mode
import findspark
findspark.init()

# Set the environment variable
os.environ["HADOOP_HOME"] = r"C:\Users\Intern-9CT2\Downloads\winutils-master\winutils-master\hadoop-3.3.5"

spark = SparkSession.builder \
    .master("local") \
    .appName("Reddit Keyword Filtering") \
    .config("spark.jars.packages", "org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1") \
    .config("spark.sql.streaming.checkpointLocation", r"C:\CSIT_WORK\tmp") \
    .getOrCreate()

# define the schema for the JSON data
schema = StructType([
    StructField("user", StringType(), nullable=True),
    StructField("content", StringType(), nullable=True),
    StructField("url", StringType(), nullable=True),
    StructField("context", StringType(), nullable=True),
    StructField("score", IntegerType(), nullable=True),
    StructField("subreddit", StringType(), nullable=True),
    StructField("type", StringType(), nullable=True),
    StructField("id", StringType(), nullable=True),
    StructField("datetime", StringType(), nullable=True)  # Assuming the datetime is string type, you can change it to TimestampType if needed
])

# define the parameters for the input and output kafka broker and topic
kafka_broker = "kafka:9092"
input_kafka_topic = "reddit_post_preprocessed"
output_kafka_topic = "reddit_post_filtered"

# Subscribe to the input topic
df = spark \
    .readStream \
    .format("kafka") \
    .option("kafka.bootstrap.servers", kafka_broker) \
    .option("subscribe", input_kafka_topic) \
    .load()

# parse the JSON data in the 'value' column using the defined schema then create a dataframe containing the reddit data
df = df.select(col("value").cast("string")) \
    .withColumn("value", from_json("value", schema)) \

parsed_df = df \
    .select("value.*")

# filter rows containing specific keywords
keywords = ['singapore', 'sg']

# initialize the filter condition with False
filter_condition = col("content").contains(keywords[0])

# loop through the rest of the keywords and update the filter condition
for keyword in keywords[1:]:
    filter_condition = filter_condition | col("content").contains(keyword)

# apply the filter condition to the DataFrame
filtered_df = parsed_df.filter(filter_condition)

# stream the data to kafka
kafka_write = filtered_df \
    .selectExpr("'' AS key", "to_json(struct(*)) AS value") \
    .writeStream \
    .format("kafka") \
    .option("kafka.bootstrap.servers", kafka_broker) \
    .option("topic", output_kafka_topic) \
    .start()

# Wait for the termination of the query
kafka_write.awaitTermination()

[WI-684][TI-1870] - [INFO] 2024-04-27 21:15:44.099 +0800 o.a.d.p.t.p.PythonTask:[131] - tenantCode :default, task dir:/tmp/dolphinscheduler/exec/process/default/13010050770016/13377949373536_17/684/1870
[WI-684][TI-1870] - [INFO] 2024-04-27 21:15:44.102 +0800 o.a.d.p.t.p.PythonTask:[134] - generate python script file:/tmp/dolphinscheduler/exec/process/default/13010050770016/13377949373536_17/684/1870/py_684_1870.py
[WI-684][TI-1870] - [INFO] 2024-04-27 21:15:44.103 +0800 o.a.d.p.t.p.PythonTask:[141] - #-*- encoding=utf8 -*-

from pyspark.sql import SparkSession
from pyspark.sql.functions import col, from_json
from pyspark.sql.types import StringType, StructType, StructField, IntegerType
import os

# Initialize Spark session in local mode
import findspark
findspark.init()

# Set the environment variable
os.environ["HADOOP_HOME"] = r"C:\Users\Intern-9CT2\Downloads\winutils-master\winutils-master\hadoop-3.3.5"

spark = SparkSession.builder \
    .master("local") \
    .appName("Reddit Keyword Filtering") \
    .config("spark.jars.packages", "org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1") \
    .config("spark.sql.streaming.checkpointLocation", r"C:\CSIT_WORK\tmp") \
    .getOrCreate()

# define the schema for the JSON data
schema = StructType([
    StructField("user", StringType(), nullable=True),
    StructField("content", StringType(), nullable=True),
    StructField("url", StringType(), nullable=True),
    StructField("context", StringType(), nullable=True),
    StructField("score", IntegerType(), nullable=True),
    StructField("subreddit", StringType(), nullable=True),
    StructField("type", StringType(), nullable=True),
    StructField("id", StringType(), nullable=True),
    StructField("datetime", StringType(), nullable=True)  # Assuming the datetime is string type, you can change it to TimestampType if needed
])

# define the parameters for the input and output kafka broker and topic
kafka_broker = "kafka:9092"
input_kafka_topic = "reddit_post_preprocessed"
output_kafka_topic = "reddit_post_filtered"

# Subscribe to the input topic
df = spark \
    .readStream \
    .format("kafka") \
    .option("kafka.bootstrap.servers", kafka_broker) \
    .option("subscribe", input_kafka_topic) \
    .load()

# parse the JSON data in the 'value' column using the defined schema then create a dataframe containing the reddit data
df = df.select(col("value").cast("string")) \
    .withColumn("value", from_json("value", schema)) \

parsed_df = df \
    .select("value.*")

# filter rows containing specific keywords
keywords = ['singapore', 'sg']

# initialize the filter condition with False
filter_condition = col("content").contains(keywords[0])

# loop through the rest of the keywords and update the filter condition
for keyword in keywords[1:]:
    filter_condition = filter_condition | col("content").contains(keyword)

# apply the filter condition to the DataFrame
filtered_df = parsed_df.filter(filter_condition)

# stream the data to kafka
kafka_write = filtered_df \
    .selectExpr("'' AS key", "to_json(struct(*)) AS value") \
    .writeStream \
    .format("kafka") \
    .option("kafka.bootstrap.servers", kafka_broker) \
    .option("topic", output_kafka_topic) \
    .start()

# Wait for the termination of the query
kafka_write.awaitTermination()

[WI-684][TI-1870] - [INFO] 2024-04-27 21:15:44.109 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-684][TI-1870] - [INFO] 2024-04-27 21:15:44.109 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-684][TI-1870] - [INFO] 2024-04-27 21:15:44.109 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export HADOOP_HOME=/opt/hadoop-3.4.0
export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export PYSPARK_DRIVER_PYTHON=/bin/python3.11
export PYTHON_LAUNCHER=/bin/python3.11
${PYTHON_LAUNCHER} /tmp/dolphinscheduler/exec/process/default/13010050770016/13377949373536_17/684/1870/py_684_1870.py
[WI-684][TI-1870] - [INFO] 2024-04-27 21:15:44.116 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-684][TI-1870] - [INFO] 2024-04-27 21:15:44.116 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13377949373536_17/684/1870/684_1870.sh
[WI-684][TI-1870] - [INFO] 2024-04-27 21:15:44.132 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 223
[WI-0][TI-0] - [INFO] 2024-04-27 21:15:44.458 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.878125 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-1870] - [INFO] 2024-04-27 21:15:44.703 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1870, success=true)
[WI-0][TI-1870] - [INFO] 2024-04-27 21:15:44.758 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1870)
[WI-0][TI-0] - [INFO] 2024-04-27 21:15:45.136 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
	Traceback (most recent call last):
	  File "/tmp/dolphinscheduler/exec/process/default/13010050770016/13377949373536_17/684/1870/py_684_1870.py", line 9, in <module>
	    import findspark
	ModuleNotFoundError: No module named 'findspark'
[WI-684][TI-1870] - [INFO] 2024-04-27 21:15:45.140 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13377949373536_17/684/1870, processId:223 ,exitStatusCode:1 ,processWaitForStatus:true ,processExitValue:1
[WI-684][TI-1870] - [INFO] 2024-04-27 21:15:45.142 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-684][TI-1870] - [INFO] 2024-04-27 21:15:45.143 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-684][TI-1870] - [INFO] 2024-04-27 21:15:45.152 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-684][TI-1870] - [INFO] 2024-04-27 21:15:45.153 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-684][TI-1870] - [INFO] 2024-04-27 21:15:45.195 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: FAILURE to master : 172.18.1.1:1234
[WI-684][TI-1870] - [INFO] 2024-04-27 21:15:45.196 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-684][TI-1870] - [INFO] 2024-04-27 21:15:45.197 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13377949373536_17/684/1870
[WI-684][TI-1870] - [INFO] 2024-04-27 21:15:45.199 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13377949373536_17/684/1870
[WI-684][TI-1870] - [INFO] 2024-04-27 21:15:45.201 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-0] - [INFO] 2024-04-27 21:15:45.461 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8466076696165191 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-1870] - [INFO] 2024-04-27 21:15:45.672 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1870, success=true)
[WI-0][TI-0] - [INFO] 2024-04-27 21:15:45.766 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1871, taskName=keyword filtering, firstSubmitTime=1714223745717, startTime=0, taskType=PYTHON, workflowInstanceHost=172.18.0.9:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13377949373536, processDefineVersion=17, appIds=null, processInstanceId=684, scheduleTime=0, globalParams=[{"prop":"keywords","direct":"IN","type":"VARCHAR","value":"\"singapore\", \"lol\""}], executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[],"rawScript":"from pyspark.sql import SparkSession\nfrom pyspark.sql.functions import col, from_json\nfrom pyspark.sql.types import StringType, StructType, StructField, IntegerType\nimport os\n\n# Initialize Spark session in local mode\nimport findspark\nfindspark.init()\n\n# Set the environment variable\nos.environ[\"HADOOP_HOME\"] = r\"C:\\Users\\Intern-9CT2\\Downloads\\winutils-master\\winutils-master\\hadoop-3.3.5\"\n\nspark = SparkSession.builder \\\n    .master(\"local\") \\\n    .appName(\"Reddit Keyword Filtering\") \\\n    .config(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1\") \\\n    .config(\"spark.sql.streaming.checkpointLocation\", r\"C:\\CSIT_WORK\\tmp\") \\\n    .getOrCreate()\n\n# define the schema for the JSON data\nschema = StructType([\n    StructField(\"user\", StringType(), nullable=True),\n    StructField(\"content\", StringType(), nullable=True),\n    StructField(\"url\", StringType(), nullable=True),\n    StructField(\"context\", StringType(), nullable=True),\n    StructField(\"score\", IntegerType(), nullable=True),\n    StructField(\"subreddit\", StringType(), nullable=True),\n    StructField(\"type\", StringType(), nullable=True),\n    StructField(\"id\", StringType(), nullable=True),\n    StructField(\"datetime\", StringType(), nullable=True)  # Assuming the datetime is string type, you can change it to TimestampType if needed\n])\n\n# define the parameters for the input and output kafka broker and topic\nkafka_broker = \"kafka:9092\"\ninput_kafka_topic = \"reddit_post_preprocessed\"\noutput_kafka_topic = \"reddit_post_filtered\"\n\n# Subscribe to the input topic\ndf = spark \\\n    .readStream \\\n    .format(\"kafka\") \\\n    .option(\"kafka.bootstrap.servers\", kafka_broker) \\\n    .option(\"subscribe\", input_kafka_topic) \\\n    .load()\n\n# parse the JSON data in the 'value' column using the defined schema then create a dataframe containing the reddit data\ndf = df.select(col(\"value\").cast(\"string\")) \\\n    .withColumn(\"value\", from_json(\"value\", schema)) \\\n\nparsed_df = df \\\n    .select(\"value.*\")\n\n# filter rows containing specific keywords\nkeywords = ['singapore', 'sg']\n\n# initialize the filter condition with False\nfilter_condition = col(\"content\").contains(keywords[0])\n\n# loop through the rest of the keywords and update the filter condition\nfor keyword in keywords[1:]:\n    filter_condition = filter_condition | col(\"content\").contains(keyword)\n\n# apply the filter condition to the DataFrame\nfiltered_df = parsed_df.filter(filter_condition)\n\n# stream the data to kafka\nkafka_write = filtered_df \\\n    .selectExpr(\"'' AS key\", \"to_json(struct(*)) AS value\") \\\n    .writeStream \\\n    .format(\"kafka\") \\\n    .option(\"kafka.bootstrap.servers\", kafka_broker) \\\n    .option(\"topic\", output_kafka_topic) \\\n    .start()\n\n# Wait for the termination of the query\nkafka_write.awaitTermination()\n","resourceList":[]}, environmentConfig=export HADOOP_HOME=/opt/hadoop-3.4.0
export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export PYSPARK_DRIVER_PYTHON=/bin/python3.11
export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='keyword filtering'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, keywords=Property{prop='keywords', direct=IN, type=VARCHAR, value='"singapore", "lol"'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240427'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1871'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13377752024032'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240427211545'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='684'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240426'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='filter_data'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13377949373536'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-684][TI-1871] - [INFO] 2024-04-27 21:15:45.792 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: keyword filtering to wait queue success
[WI-684][TI-1871] - [INFO] 2024-04-27 21:15:45.793 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-684][TI-1871] - [INFO] 2024-04-27 21:15:45.795 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-684][TI-1871] - [INFO] 2024-04-27 21:15:45.796 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-684][TI-1871] - [INFO] 2024-04-27 21:15:45.796 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-684][TI-1871] - [INFO] 2024-04-27 21:15:45.796 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1714223745796
[WI-684][TI-1871] - [INFO] 2024-04-27 21:15:45.797 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 684_1871
[WI-684][TI-1871] - [INFO] 2024-04-27 21:15:45.798 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1871,
  "taskName" : "keyword filtering",
  "firstSubmitTime" : 1714223745717,
  "startTime" : 1714223745796,
  "taskType" : "PYTHON",
  "workflowInstanceHost" : "172.18.0.9:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240427/13377949373536/17/684/1871.log",
  "processId" : 0,
  "processDefineCode" : 13377949373536,
  "processDefineVersion" : 17,
  "processInstanceId" : 684,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"keywords\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"\\\"singapore\\\", \\\"lol\\\"\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[],\"rawScript\":\"from pyspark.sql import SparkSession\\nfrom pyspark.sql.functions import col, from_json\\nfrom pyspark.sql.types import StringType, StructType, StructField, IntegerType\\nimport os\\n\\n# Initialize Spark session in local mode\\nimport findspark\\nfindspark.init()\\n\\n# Set the environment variable\\nos.environ[\\\"HADOOP_HOME\\\"] = r\\\"C:\\\\Users\\\\Intern-9CT2\\\\Downloads\\\\winutils-master\\\\winutils-master\\\\hadoop-3.3.5\\\"\\n\\nspark = SparkSession.builder \\\\\\n    .master(\\\"local\\\") \\\\\\n    .appName(\\\"Reddit Keyword Filtering\\\") \\\\\\n    .config(\\\"spark.jars.packages\\\", \\\"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1\\\") \\\\\\n    .config(\\\"spark.sql.streaming.checkpointLocation\\\", r\\\"C:\\\\CSIT_WORK\\\\tmp\\\") \\\\\\n    .getOrCreate()\\n\\n# define the schema for the JSON data\\nschema = StructType([\\n    StructField(\\\"user\\\", StringType(), nullable=True),\\n    StructField(\\\"content\\\", StringType(), nullable=True),\\n    StructField(\\\"url\\\", StringType(), nullable=True),\\n    StructField(\\\"context\\\", StringType(), nullable=True),\\n    StructField(\\\"score\\\", IntegerType(), nullable=True),\\n    StructField(\\\"subreddit\\\", StringType(), nullable=True),\\n    StructField(\\\"type\\\", StringType(), nullable=True),\\n    StructField(\\\"id\\\", StringType(), nullable=True),\\n    StructField(\\\"datetime\\\", StringType(), nullable=True)  # Assuming the datetime is string type, you can change it to TimestampType if needed\\n])\\n\\n# define the parameters for the input and output kafka broker and topic\\nkafka_broker = \\\"kafka:9092\\\"\\ninput_kafka_topic = \\\"reddit_post_preprocessed\\\"\\noutput_kafka_topic = \\\"reddit_post_filtered\\\"\\n\\n# Subscribe to the input topic\\ndf = spark \\\\\\n    .readStream \\\\\\n    .format(\\\"kafka\\\") \\\\\\n    .option(\\\"kafka.bootstrap.servers\\\", kafka_broker) \\\\\\n    .option(\\\"subscribe\\\", input_kafka_topic) \\\\\\n    .load()\\n\\n# parse the JSON data in the 'value' column using the defined schema then create a dataframe containing the reddit data\\ndf = df.select(col(\\\"value\\\").cast(\\\"string\\\")) \\\\\\n    .withColumn(\\\"value\\\", from_json(\\\"value\\\", schema)) \\\\\\n\\nparsed_df = df \\\\\\n    .select(\\\"value.*\\\")\\n\\n# filter rows containing specific keywords\\nkeywords = ['singapore', 'sg']\\n\\n# initialize the filter condition with False\\nfilter_condition = col(\\\"content\\\").contains(keywords[0])\\n\\n# loop through the rest of the keywords and update the filter condition\\nfor keyword in keywords[1:]:\\n    filter_condition = filter_condition | col(\\\"content\\\").contains(keyword)\\n\\n# apply the filter condition to the DataFrame\\nfiltered_df = parsed_df.filter(filter_condition)\\n\\n# stream the data to kafka\\nkafka_write = filtered_df \\\\\\n    .selectExpr(\\\"'' AS key\\\", \\\"to_json(struct(*)) AS value\\\") \\\\\\n    .writeStream \\\\\\n    .format(\\\"kafka\\\") \\\\\\n    .option(\\\"kafka.bootstrap.servers\\\", kafka_broker) \\\\\\n    .option(\\\"topic\\\", output_kafka_topic) \\\\\\n    .start()\\n\\n# Wait for the termination of the query\\nkafka_write.awaitTermination()\\n\",\"resourceList\":[]}",
  "environmentConfig" : "export HADOOP_HOME=/opt/hadoop-3.4.0\nexport SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3\nexport JAVA_HOME=/opt/java/openjdk\nexport PYSPARK_DRIVER_PYTHON=/bin/python3.11\nexport PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "keyword filtering"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "keywords" : {
      "prop" : "keywords",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "\"singapore\", \"lol\""
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240427"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1871"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13377752024032"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240427211545"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "684"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240426"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "filter_data"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13377949373536"
    }
  },
  "taskAppId" : "684_1871",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "varPool" : "[]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-684][TI-1871] - [INFO] 2024-04-27 21:15:45.809 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-684][TI-1871] - [INFO] 2024-04-27 21:15:45.825 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-684][TI-1871] - [INFO] 2024-04-27 21:15:45.827 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-684][TI-1871] - [INFO] 2024-04-27 21:15:45.875 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-684][TI-1871] - [INFO] 2024-04-27 21:15:45.878 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-684][TI-1871] - [INFO] 2024-04-27 21:15:45.881 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13377949373536_17/684/1871 check successfully
[WI-684][TI-1871] - [INFO] 2024-04-27 21:15:45.882 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.python.PythonTaskChannel successfully
[WI-684][TI-1871] - [INFO] 2024-04-27 21:15:45.887 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-684][TI-1871] - [INFO] 2024-04-27 21:15:45.890 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-684][TI-1871] - [INFO] 2024-04-27 21:15:45.895 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: PYTHON create successfully
[WI-684][TI-1871] - [INFO] 2024-04-27 21:15:45.897 +0800 o.a.d.p.t.p.PythonTask:[75] - Initialize python task params {
  "localParams" : [ ],
  "varPool" : null,
  "rawScript" : "from pyspark.sql import SparkSession\nfrom pyspark.sql.functions import col, from_json\nfrom pyspark.sql.types import StringType, StructType, StructField, IntegerType\nimport os\n\n# Initialize Spark session in local mode\nimport findspark\nfindspark.init()\n\n# Set the environment variable\nos.environ[\"HADOOP_HOME\"] = r\"C:\\Users\\Intern-9CT2\\Downloads\\winutils-master\\winutils-master\\hadoop-3.3.5\"\n\nspark = SparkSession.builder \\\n    .master(\"local\") \\\n    .appName(\"Reddit Keyword Filtering\") \\\n    .config(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1\") \\\n    .config(\"spark.sql.streaming.checkpointLocation\", r\"C:\\CSIT_WORK\\tmp\") \\\n    .getOrCreate()\n\n# define the schema for the JSON data\nschema = StructType([\n    StructField(\"user\", StringType(), nullable=True),\n    StructField(\"content\", StringType(), nullable=True),\n    StructField(\"url\", StringType(), nullable=True),\n    StructField(\"context\", StringType(), nullable=True),\n    StructField(\"score\", IntegerType(), nullable=True),\n    StructField(\"subreddit\", StringType(), nullable=True),\n    StructField(\"type\", StringType(), nullable=True),\n    StructField(\"id\", StringType(), nullable=True),\n    StructField(\"datetime\", StringType(), nullable=True)  # Assuming the datetime is string type, you can change it to TimestampType if needed\n])\n\n# define the parameters for the input and output kafka broker and topic\nkafka_broker = \"kafka:9092\"\ninput_kafka_topic = \"reddit_post_preprocessed\"\noutput_kafka_topic = \"reddit_post_filtered\"\n\n# Subscribe to the input topic\ndf = spark \\\n    .readStream \\\n    .format(\"kafka\") \\\n    .option(\"kafka.bootstrap.servers\", kafka_broker) \\\n    .option(\"subscribe\", input_kafka_topic) \\\n    .load()\n\n# parse the JSON data in the 'value' column using the defined schema then create a dataframe containing the reddit data\ndf = df.select(col(\"value\").cast(\"string\")) \\\n    .withColumn(\"value\", from_json(\"value\", schema)) \\\n\nparsed_df = df \\\n    .select(\"value.*\")\n\n# filter rows containing specific keywords\nkeywords = ['singapore', 'sg']\n\n# initialize the filter condition with False\nfilter_condition = col(\"content\").contains(keywords[0])\n\n# loop through the rest of the keywords and update the filter condition\nfor keyword in keywords[1:]:\n    filter_condition = filter_condition | col(\"content\").contains(keyword)\n\n# apply the filter condition to the DataFrame\nfiltered_df = parsed_df.filter(filter_condition)\n\n# stream the data to kafka\nkafka_write = filtered_df \\\n    .selectExpr(\"'' AS key\", \"to_json(struct(*)) AS value\") \\\n    .writeStream \\\n    .format(\"kafka\") \\\n    .option(\"kafka.bootstrap.servers\", kafka_broker) \\\n    .option(\"topic\", output_kafka_topic) \\\n    .start()\n\n# Wait for the termination of the query\nkafka_write.awaitTermination()\n",
  "resourceList" : [ ]
}
[WI-684][TI-1871] - [INFO] 2024-04-27 21:15:45.898 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-684][TI-1871] - [INFO] 2024-04-27 21:15:45.898 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [] successfully
[WI-684][TI-1871] - [INFO] 2024-04-27 21:15:45.898 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-684][TI-1871] - [INFO] 2024-04-27 21:15:45.899 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-684][TI-1871] - [INFO] 2024-04-27 21:15:45.899 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-684][TI-1871] - [INFO] 2024-04-27 21:15:45.899 +0800 o.a.d.p.t.p.PythonTask:[165] - raw python script : from pyspark.sql import SparkSession
from pyspark.sql.functions import col, from_json
from pyspark.sql.types import StringType, StructType, StructField, IntegerType
import os

# Initialize Spark session in local mode
import findspark
findspark.init()

# Set the environment variable
os.environ["HADOOP_HOME"] = r"C:\Users\Intern-9CT2\Downloads\winutils-master\winutils-master\hadoop-3.3.5"

spark = SparkSession.builder \
    .master("local") \
    .appName("Reddit Keyword Filtering") \
    .config("spark.jars.packages", "org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1") \
    .config("spark.sql.streaming.checkpointLocation", r"C:\CSIT_WORK\tmp") \
    .getOrCreate()

# define the schema for the JSON data
schema = StructType([
    StructField("user", StringType(), nullable=True),
    StructField("content", StringType(), nullable=True),
    StructField("url", StringType(), nullable=True),
    StructField("context", StringType(), nullable=True),
    StructField("score", IntegerType(), nullable=True),
    StructField("subreddit", StringType(), nullable=True),
    StructField("type", StringType(), nullable=True),
    StructField("id", StringType(), nullable=True),
    StructField("datetime", StringType(), nullable=True)  # Assuming the datetime is string type, you can change it to TimestampType if needed
])

# define the parameters for the input and output kafka broker and topic
kafka_broker = "kafka:9092"
input_kafka_topic = "reddit_post_preprocessed"
output_kafka_topic = "reddit_post_filtered"

# Subscribe to the input topic
df = spark \
    .readStream \
    .format("kafka") \
    .option("kafka.bootstrap.servers", kafka_broker) \
    .option("subscribe", input_kafka_topic) \
    .load()

# parse the JSON data in the 'value' column using the defined schema then create a dataframe containing the reddit data
df = df.select(col("value").cast("string")) \
    .withColumn("value", from_json("value", schema)) \

parsed_df = df \
    .select("value.*")

# filter rows containing specific keywords
keywords = ['singapore', 'sg']

# initialize the filter condition with False
filter_condition = col("content").contains(keywords[0])

# loop through the rest of the keywords and update the filter condition
for keyword in keywords[1:]:
    filter_condition = filter_condition | col("content").contains(keyword)

# apply the filter condition to the DataFrame
filtered_df = parsed_df.filter(filter_condition)

# stream the data to kafka
kafka_write = filtered_df \
    .selectExpr("'' AS key", "to_json(struct(*)) AS value") \
    .writeStream \
    .format("kafka") \
    .option("kafka.bootstrap.servers", kafka_broker) \
    .option("topic", output_kafka_topic) \
    .start()

# Wait for the termination of the query
kafka_write.awaitTermination()

[WI-684][TI-1871] - [INFO] 2024-04-27 21:15:45.901 +0800 o.a.d.p.t.p.PythonTask:[131] - tenantCode :default, task dir:/tmp/dolphinscheduler/exec/process/default/13010050770016/13377949373536_17/684/1871
[WI-684][TI-1871] - [INFO] 2024-04-27 21:15:45.901 +0800 o.a.d.p.t.p.PythonTask:[134] - generate python script file:/tmp/dolphinscheduler/exec/process/default/13010050770016/13377949373536_17/684/1871/py_684_1871.py
[WI-684][TI-1871] - [INFO] 2024-04-27 21:15:45.902 +0800 o.a.d.p.t.p.PythonTask:[141] - #-*- encoding=utf8 -*-

from pyspark.sql import SparkSession
from pyspark.sql.functions import col, from_json
from pyspark.sql.types import StringType, StructType, StructField, IntegerType
import os

# Initialize Spark session in local mode
import findspark
findspark.init()

# Set the environment variable
os.environ["HADOOP_HOME"] = r"C:\Users\Intern-9CT2\Downloads\winutils-master\winutils-master\hadoop-3.3.5"

spark = SparkSession.builder \
    .master("local") \
    .appName("Reddit Keyword Filtering") \
    .config("spark.jars.packages", "org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1") \
    .config("spark.sql.streaming.checkpointLocation", r"C:\CSIT_WORK\tmp") \
    .getOrCreate()

# define the schema for the JSON data
schema = StructType([
    StructField("user", StringType(), nullable=True),
    StructField("content", StringType(), nullable=True),
    StructField("url", StringType(), nullable=True),
    StructField("context", StringType(), nullable=True),
    StructField("score", IntegerType(), nullable=True),
    StructField("subreddit", StringType(), nullable=True),
    StructField("type", StringType(), nullable=True),
    StructField("id", StringType(), nullable=True),
    StructField("datetime", StringType(), nullable=True)  # Assuming the datetime is string type, you can change it to TimestampType if needed
])

# define the parameters for the input and output kafka broker and topic
kafka_broker = "kafka:9092"
input_kafka_topic = "reddit_post_preprocessed"
output_kafka_topic = "reddit_post_filtered"

# Subscribe to the input topic
df = spark \
    .readStream \
    .format("kafka") \
    .option("kafka.bootstrap.servers", kafka_broker) \
    .option("subscribe", input_kafka_topic) \
    .load()

# parse the JSON data in the 'value' column using the defined schema then create a dataframe containing the reddit data
df = df.select(col("value").cast("string")) \
    .withColumn("value", from_json("value", schema)) \

parsed_df = df \
    .select("value.*")

# filter rows containing specific keywords
keywords = ['singapore', 'sg']

# initialize the filter condition with False
filter_condition = col("content").contains(keywords[0])

# loop through the rest of the keywords and update the filter condition
for keyword in keywords[1:]:
    filter_condition = filter_condition | col("content").contains(keyword)

# apply the filter condition to the DataFrame
filtered_df = parsed_df.filter(filter_condition)

# stream the data to kafka
kafka_write = filtered_df \
    .selectExpr("'' AS key", "to_json(struct(*)) AS value") \
    .writeStream \
    .format("kafka") \
    .option("kafka.bootstrap.servers", kafka_broker) \
    .option("topic", output_kafka_topic) \
    .start()

# Wait for the termination of the query
kafka_write.awaitTermination()

[WI-684][TI-1871] - [INFO] 2024-04-27 21:15:45.904 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-684][TI-1871] - [INFO] 2024-04-27 21:15:45.912 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-684][TI-1871] - [INFO] 2024-04-27 21:15:45.922 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export HADOOP_HOME=/opt/hadoop-3.4.0
export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export PYSPARK_DRIVER_PYTHON=/bin/python3.11
export PYTHON_LAUNCHER=/bin/python3.11
${PYTHON_LAUNCHER} /tmp/dolphinscheduler/exec/process/default/13010050770016/13377949373536_17/684/1871/py_684_1871.py
[WI-684][TI-1871] - [INFO] 2024-04-27 21:15:45.924 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-684][TI-1871] - [INFO] 2024-04-27 21:15:45.925 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13377949373536_17/684/1871/684_1871.sh
[WI-684][TI-1871] - [INFO] 2024-04-27 21:15:45.954 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 237
[WI-0][TI-0] - [INFO] 2024-04-27 21:15:46.462 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9598853868194842 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-1871] - [INFO] 2024-04-27 21:15:46.690 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1871, success=true)
[WI-0][TI-1871] - [INFO] 2024-04-27 21:15:46.718 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1871)
[WI-0][TI-0] - [INFO] 2024-04-27 21:15:46.983 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
	Traceback (most recent call last):
	  File "/tmp/dolphinscheduler/exec/process/default/13010050770016/13377949373536_17/684/1871/py_684_1871.py", line 9, in <module>
	    import findspark
	ModuleNotFoundError: No module named 'findspark'
[WI-684][TI-1871] - [INFO] 2024-04-27 21:15:46.987 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13377949373536_17/684/1871, processId:237 ,exitStatusCode:1 ,processWaitForStatus:true ,processExitValue:1
[WI-684][TI-1871] - [INFO] 2024-04-27 21:15:46.993 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-684][TI-1871] - [INFO] 2024-04-27 21:15:46.999 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-684][TI-1871] - [INFO] 2024-04-27 21:15:47.000 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-684][TI-1871] - [INFO] 2024-04-27 21:15:47.001 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-684][TI-1871] - [INFO] 2024-04-27 21:15:47.030 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: FAILURE to master : 172.18.1.1:1234
[WI-684][TI-1871] - [INFO] 2024-04-27 21:15:47.036 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-684][TI-1871] - [INFO] 2024-04-27 21:15:47.036 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13377949373536_17/684/1871
[WI-684][TI-1871] - [INFO] 2024-04-27 21:15:47.037 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13377949373536_17/684/1871
[WI-684][TI-1871] - [INFO] 2024-04-27 21:15:47.037 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-0] - [INFO] 2024-04-27 21:15:47.464 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-1871] - [INFO] 2024-04-27 21:15:47.670 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1871, success=true)
[WI-0][TI-0] - [INFO] 2024-04-27 21:15:48.488 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9161849710982659 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:15:49.499 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8655383941286012 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:15:50.511 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7196615565049844 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:15:51.513 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7147239263803681 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:15:52.527 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9133126934984521 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:16:14.672 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7293447293447294 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:16:31.850 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7439024390243902 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:16:34.885 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8861538461538462 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:16:35.904 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9317507418397626 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:16:36.908 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8929577464788732 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:16:37.922 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.864406779661017 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:16:38.924 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8652291105121294 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:16:39.926 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9239766081871345 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:16:40.938 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8898550724637682 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:16:41.939 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7951807228915664 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:16:42.945 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8271604938271605 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:16:43.948 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7109660487675238 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:16:46.051 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8983516483516484 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:16:52.104 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8076923076923078 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:16:53.142 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8885714285714286 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:16:54.145 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8592814371257486 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:16:56.195 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7408292894622638 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:17:00.257 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8402366863905326 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:17:01.335 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9352112676056339 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:17:04.352 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.838150289017341 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:17:06.460 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9404761904761905 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:17:07.486 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8795180722891567 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:17:08.492 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8717201166180758 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:17:09.506 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7465940054495913 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:17:22.605 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7630674846625767 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:17:29.659 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8403614457831325 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:17:33.725 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9137380191693291 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:17:34.806 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8582887700534759 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:17:38.948 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8439306358381503 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:17:40.058 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1873, taskName=keyword filtering, firstSubmitTime=1714223860003, startTime=0, taskType=PYTHON, workflowInstanceHost=172.18.0.9:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13377949373536, processDefineVersion=18, appIds=null, processInstanceId=685, scheduleTime=0, globalParams=[{"prop":"keywords","direct":"IN","type":"VARCHAR","value":"\"singapore\", \"lol\""}], executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[],"rawScript":"from pyspark.sql import SparkSession\nfrom pyspark.sql.functions import col, from_json\nfrom pyspark.sql.types import StringType, StructType, StructField, IntegerType\n\nspark = SparkSession.builder \\\n    .master(\"local\") \\\n    .appName(\"Reddit Keyword Filtering\") \\\n    .config(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1\") \\\n    .config(\"spark.sql.streaming.checkpointLocation\", r\"C:\\CSIT_WORK\\tmp\") \\\n    .getOrCreate()\n\n# define the schema for the JSON data\nschema = StructType([\n    StructField(\"user\", StringType(), nullable=True),\n    StructField(\"content\", StringType(), nullable=True),\n    StructField(\"url\", StringType(), nullable=True),\n    StructField(\"context\", StringType(), nullable=True),\n    StructField(\"score\", IntegerType(), nullable=True),\n    StructField(\"subreddit\", StringType(), nullable=True),\n    StructField(\"type\", StringType(), nullable=True),\n    StructField(\"id\", StringType(), nullable=True),\n    StructField(\"datetime\", StringType(), nullable=True)  # Assuming the datetime is string type, you can change it to TimestampType if needed\n])\n\n# define the parameters for the input and output kafka broker and topic\nkafka_broker = \"kafka:9092\"\ninput_kafka_topic = \"reddit_post_preprocessed\"\noutput_kafka_topic = \"reddit_post_filtered\"\n\n# Subscribe to the input topic\ndf = spark \\\n    .readStream \\\n    .format(\"kafka\") \\\n    .option(\"kafka.bootstrap.servers\", kafka_broker) \\\n    .option(\"subscribe\", input_kafka_topic) \\\n    .load()\n\n# parse the JSON data in the 'value' column using the defined schema then create a dataframe containing the reddit data\ndf = df.select(col(\"value\").cast(\"string\")) \\\n    .withColumn(\"value\", from_json(\"value\", schema)) \\\n\nparsed_df = df \\\n    .select(\"value.*\")\n\n# filter rows containing specific keywords\nkeywords = ['singapore', 'sg']\n\n# initialize the filter condition with False\nfilter_condition = col(\"content\").contains(keywords[0])\n\n# loop through the rest of the keywords and update the filter condition\nfor keyword in keywords[1:]:\n    filter_condition = filter_condition | col(\"content\").contains(keyword)\n\n# apply the filter condition to the DataFrame\nfiltered_df = parsed_df.filter(filter_condition)\n\n# stream the data to kafka\nkafka_write = filtered_df \\\n    .selectExpr(\"'' AS key\", \"to_json(struct(*)) AS value\") \\\n    .writeStream \\\n    .format(\"kafka\") \\\n    .option(\"kafka.bootstrap.servers\", kafka_broker) \\\n    .option(\"topic\", output_kafka_topic) \\\n    .start()\n\n# Wait for the termination of the query\nkafka_write.awaitTermination()\n","resourceList":[]}, environmentConfig=export HADOOP_HOME=/opt/hadoop-3.4.0
export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export PYSPARK_DRIVER_PYTHON=/bin/python3.11
export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='keyword filtering'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, keywords=Property{prop='keywords', direct=IN, type=VARCHAR, value='"singapore", "lol"'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240427'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1873'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13377752024032'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240427211740'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='685'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240426'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='filter_data'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13377949373536'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=null, dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-685][TI-1873] - [INFO] 2024-04-27 21:17:40.088 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: keyword filtering to wait queue success
[WI-685][TI-1873] - [INFO] 2024-04-27 21:17:40.088 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-685][TI-1873] - [INFO] 2024-04-27 21:17:40.092 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-685][TI-1873] - [INFO] 2024-04-27 21:17:40.092 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-685][TI-1873] - [INFO] 2024-04-27 21:17:40.092 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-685][TI-1873] - [INFO] 2024-04-27 21:17:40.092 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1714223860092
[WI-685][TI-1873] - [INFO] 2024-04-27 21:17:40.093 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 685_1873
[WI-685][TI-1873] - [INFO] 2024-04-27 21:17:40.093 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1873,
  "taskName" : "keyword filtering",
  "firstSubmitTime" : 1714223860003,
  "startTime" : 1714223860092,
  "taskType" : "PYTHON",
  "workflowInstanceHost" : "172.18.0.9:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240427/13377949373536/18/685/1873.log",
  "processId" : 0,
  "processDefineCode" : 13377949373536,
  "processDefineVersion" : 18,
  "processInstanceId" : 685,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"keywords\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"\\\"singapore\\\", \\\"lol\\\"\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[],\"rawScript\":\"from pyspark.sql import SparkSession\\nfrom pyspark.sql.functions import col, from_json\\nfrom pyspark.sql.types import StringType, StructType, StructField, IntegerType\\n\\nspark = SparkSession.builder \\\\\\n    .master(\\\"local\\\") \\\\\\n    .appName(\\\"Reddit Keyword Filtering\\\") \\\\\\n    .config(\\\"spark.jars.packages\\\", \\\"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1\\\") \\\\\\n    .config(\\\"spark.sql.streaming.checkpointLocation\\\", r\\\"C:\\\\CSIT_WORK\\\\tmp\\\") \\\\\\n    .getOrCreate()\\n\\n# define the schema for the JSON data\\nschema = StructType([\\n    StructField(\\\"user\\\", StringType(), nullable=True),\\n    StructField(\\\"content\\\", StringType(), nullable=True),\\n    StructField(\\\"url\\\", StringType(), nullable=True),\\n    StructField(\\\"context\\\", StringType(), nullable=True),\\n    StructField(\\\"score\\\", IntegerType(), nullable=True),\\n    StructField(\\\"subreddit\\\", StringType(), nullable=True),\\n    StructField(\\\"type\\\", StringType(), nullable=True),\\n    StructField(\\\"id\\\", StringType(), nullable=True),\\n    StructField(\\\"datetime\\\", StringType(), nullable=True)  # Assuming the datetime is string type, you can change it to TimestampType if needed\\n])\\n\\n# define the parameters for the input and output kafka broker and topic\\nkafka_broker = \\\"kafka:9092\\\"\\ninput_kafka_topic = \\\"reddit_post_preprocessed\\\"\\noutput_kafka_topic = \\\"reddit_post_filtered\\\"\\n\\n# Subscribe to the input topic\\ndf = spark \\\\\\n    .readStream \\\\\\n    .format(\\\"kafka\\\") \\\\\\n    .option(\\\"kafka.bootstrap.servers\\\", kafka_broker) \\\\\\n    .option(\\\"subscribe\\\", input_kafka_topic) \\\\\\n    .load()\\n\\n# parse the JSON data in the 'value' column using the defined schema then create a dataframe containing the reddit data\\ndf = df.select(col(\\\"value\\\").cast(\\\"string\\\")) \\\\\\n    .withColumn(\\\"value\\\", from_json(\\\"value\\\", schema)) \\\\\\n\\nparsed_df = df \\\\\\n    .select(\\\"value.*\\\")\\n\\n# filter rows containing specific keywords\\nkeywords = ['singapore', 'sg']\\n\\n# initialize the filter condition with False\\nfilter_condition = col(\\\"content\\\").contains(keywords[0])\\n\\n# loop through the rest of the keywords and update the filter condition\\nfor keyword in keywords[1:]:\\n    filter_condition = filter_condition | col(\\\"content\\\").contains(keyword)\\n\\n# apply the filter condition to the DataFrame\\nfiltered_df = parsed_df.filter(filter_condition)\\n\\n# stream the data to kafka\\nkafka_write = filtered_df \\\\\\n    .selectExpr(\\\"'' AS key\\\", \\\"to_json(struct(*)) AS value\\\") \\\\\\n    .writeStream \\\\\\n    .format(\\\"kafka\\\") \\\\\\n    .option(\\\"kafka.bootstrap.servers\\\", kafka_broker) \\\\\\n    .option(\\\"topic\\\", output_kafka_topic) \\\\\\n    .start()\\n\\n# Wait for the termination of the query\\nkafka_write.awaitTermination()\\n\",\"resourceList\":[]}",
  "environmentConfig" : "export HADOOP_HOME=/opt/hadoop-3.4.0\nexport SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3\nexport JAVA_HOME=/opt/java/openjdk\nexport PYSPARK_DRIVER_PYTHON=/bin/python3.11\nexport PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "keyword filtering"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "keywords" : {
      "prop" : "keywords",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "\"singapore\", \"lol\""
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240427"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1873"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13377752024032"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240427211740"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "685"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240426"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "filter_data"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13377949373536"
    }
  },
  "taskAppId" : "685_1873",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-685][TI-1873] - [INFO] 2024-04-27 21:17:40.097 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-685][TI-1873] - [INFO] 2024-04-27 21:17:40.098 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-685][TI-1873] - [INFO] 2024-04-27 21:17:40.098 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-685][TI-1873] - [INFO] 2024-04-27 21:17:40.126 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-685][TI-1873] - [INFO] 2024-04-27 21:17:40.127 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-685][TI-1873] - [INFO] 2024-04-27 21:17:40.130 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13377949373536_18/685/1873 check successfully
[WI-685][TI-1873] - [INFO] 2024-04-27 21:17:40.130 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.python.PythonTaskChannel successfully
[WI-685][TI-1873] - [INFO] 2024-04-27 21:17:40.131 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-685][TI-1873] - [INFO] 2024-04-27 21:17:40.132 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-685][TI-1873] - [INFO] 2024-04-27 21:17:40.141 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: PYTHON create successfully
[WI-685][TI-1873] - [INFO] 2024-04-27 21:17:40.142 +0800 o.a.d.p.t.p.PythonTask:[75] - Initialize python task params {
  "localParams" : [ ],
  "varPool" : null,
  "rawScript" : "from pyspark.sql import SparkSession\nfrom pyspark.sql.functions import col, from_json\nfrom pyspark.sql.types import StringType, StructType, StructField, IntegerType\n\nspark = SparkSession.builder \\\n    .master(\"local\") \\\n    .appName(\"Reddit Keyword Filtering\") \\\n    .config(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1\") \\\n    .config(\"spark.sql.streaming.checkpointLocation\", r\"C:\\CSIT_WORK\\tmp\") \\\n    .getOrCreate()\n\n# define the schema for the JSON data\nschema = StructType([\n    StructField(\"user\", StringType(), nullable=True),\n    StructField(\"content\", StringType(), nullable=True),\n    StructField(\"url\", StringType(), nullable=True),\n    StructField(\"context\", StringType(), nullable=True),\n    StructField(\"score\", IntegerType(), nullable=True),\n    StructField(\"subreddit\", StringType(), nullable=True),\n    StructField(\"type\", StringType(), nullable=True),\n    StructField(\"id\", StringType(), nullable=True),\n    StructField(\"datetime\", StringType(), nullable=True)  # Assuming the datetime is string type, you can change it to TimestampType if needed\n])\n\n# define the parameters for the input and output kafka broker and topic\nkafka_broker = \"kafka:9092\"\ninput_kafka_topic = \"reddit_post_preprocessed\"\noutput_kafka_topic = \"reddit_post_filtered\"\n\n# Subscribe to the input topic\ndf = spark \\\n    .readStream \\\n    .format(\"kafka\") \\\n    .option(\"kafka.bootstrap.servers\", kafka_broker) \\\n    .option(\"subscribe\", input_kafka_topic) \\\n    .load()\n\n# parse the JSON data in the 'value' column using the defined schema then create a dataframe containing the reddit data\ndf = df.select(col(\"value\").cast(\"string\")) \\\n    .withColumn(\"value\", from_json(\"value\", schema)) \\\n\nparsed_df = df \\\n    .select(\"value.*\")\n\n# filter rows containing specific keywords\nkeywords = ['singapore', 'sg']\n\n# initialize the filter condition with False\nfilter_condition = col(\"content\").contains(keywords[0])\n\n# loop through the rest of the keywords and update the filter condition\nfor keyword in keywords[1:]:\n    filter_condition = filter_condition | col(\"content\").contains(keyword)\n\n# apply the filter condition to the DataFrame\nfiltered_df = parsed_df.filter(filter_condition)\n\n# stream the data to kafka\nkafka_write = filtered_df \\\n    .selectExpr(\"'' AS key\", \"to_json(struct(*)) AS value\") \\\n    .writeStream \\\n    .format(\"kafka\") \\\n    .option(\"kafka.bootstrap.servers\", kafka_broker) \\\n    .option(\"topic\", output_kafka_topic) \\\n    .start()\n\n# Wait for the termination of the query\nkafka_write.awaitTermination()\n",
  "resourceList" : [ ]
}
[WI-685][TI-1873] - [INFO] 2024-04-27 21:17:40.142 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-685][TI-1873] - [INFO] 2024-04-27 21:17:40.142 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: null successfully
[WI-685][TI-1873] - [INFO] 2024-04-27 21:17:40.142 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-685][TI-1873] - [INFO] 2024-04-27 21:17:40.142 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-685][TI-1873] - [INFO] 2024-04-27 21:17:40.142 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-685][TI-1873] - [INFO] 2024-04-27 21:17:40.143 +0800 o.a.d.p.t.p.PythonTask:[165] - raw python script : from pyspark.sql import SparkSession
from pyspark.sql.functions import col, from_json
from pyspark.sql.types import StringType, StructType, StructField, IntegerType

spark = SparkSession.builder \
    .master("local") \
    .appName("Reddit Keyword Filtering") \
    .config("spark.jars.packages", "org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1") \
    .config("spark.sql.streaming.checkpointLocation", r"C:\CSIT_WORK\tmp") \
    .getOrCreate()

# define the schema for the JSON data
schema = StructType([
    StructField("user", StringType(), nullable=True),
    StructField("content", StringType(), nullable=True),
    StructField("url", StringType(), nullable=True),
    StructField("context", StringType(), nullable=True),
    StructField("score", IntegerType(), nullable=True),
    StructField("subreddit", StringType(), nullable=True),
    StructField("type", StringType(), nullable=True),
    StructField("id", StringType(), nullable=True),
    StructField("datetime", StringType(), nullable=True)  # Assuming the datetime is string type, you can change it to TimestampType if needed
])

# define the parameters for the input and output kafka broker and topic
kafka_broker = "kafka:9092"
input_kafka_topic = "reddit_post_preprocessed"
output_kafka_topic = "reddit_post_filtered"

# Subscribe to the input topic
df = spark \
    .readStream \
    .format("kafka") \
    .option("kafka.bootstrap.servers", kafka_broker) \
    .option("subscribe", input_kafka_topic) \
    .load()

# parse the JSON data in the 'value' column using the defined schema then create a dataframe containing the reddit data
df = df.select(col("value").cast("string")) \
    .withColumn("value", from_json("value", schema)) \

parsed_df = df \
    .select("value.*")

# filter rows containing specific keywords
keywords = ['singapore', 'sg']

# initialize the filter condition with False
filter_condition = col("content").contains(keywords[0])

# loop through the rest of the keywords and update the filter condition
for keyword in keywords[1:]:
    filter_condition = filter_condition | col("content").contains(keyword)

# apply the filter condition to the DataFrame
filtered_df = parsed_df.filter(filter_condition)

# stream the data to kafka
kafka_write = filtered_df \
    .selectExpr("'' AS key", "to_json(struct(*)) AS value") \
    .writeStream \
    .format("kafka") \
    .option("kafka.bootstrap.servers", kafka_broker) \
    .option("topic", output_kafka_topic) \
    .start()

# Wait for the termination of the query
kafka_write.awaitTermination()

[WI-685][TI-1873] - [INFO] 2024-04-27 21:17:40.143 +0800 o.a.d.p.t.p.PythonTask:[131] - tenantCode :default, task dir:/tmp/dolphinscheduler/exec/process/default/13010050770016/13377949373536_18/685/1873
[WI-685][TI-1873] - [INFO] 2024-04-27 21:17:40.144 +0800 o.a.d.p.t.p.PythonTask:[134] - generate python script file:/tmp/dolphinscheduler/exec/process/default/13010050770016/13377949373536_18/685/1873/py_685_1873.py
[WI-685][TI-1873] - [INFO] 2024-04-27 21:17:40.144 +0800 o.a.d.p.t.p.PythonTask:[141] - #-*- encoding=utf8 -*-

from pyspark.sql import SparkSession
from pyspark.sql.functions import col, from_json
from pyspark.sql.types import StringType, StructType, StructField, IntegerType

spark = SparkSession.builder \
    .master("local") \
    .appName("Reddit Keyword Filtering") \
    .config("spark.jars.packages", "org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1") \
    .config("spark.sql.streaming.checkpointLocation", r"C:\CSIT_WORK\tmp") \
    .getOrCreate()

# define the schema for the JSON data
schema = StructType([
    StructField("user", StringType(), nullable=True),
    StructField("content", StringType(), nullable=True),
    StructField("url", StringType(), nullable=True),
    StructField("context", StringType(), nullable=True),
    StructField("score", IntegerType(), nullable=True),
    StructField("subreddit", StringType(), nullable=True),
    StructField("type", StringType(), nullable=True),
    StructField("id", StringType(), nullable=True),
    StructField("datetime", StringType(), nullable=True)  # Assuming the datetime is string type, you can change it to TimestampType if needed
])

# define the parameters for the input and output kafka broker and topic
kafka_broker = "kafka:9092"
input_kafka_topic = "reddit_post_preprocessed"
output_kafka_topic = "reddit_post_filtered"

# Subscribe to the input topic
df = spark \
    .readStream \
    .format("kafka") \
    .option("kafka.bootstrap.servers", kafka_broker) \
    .option("subscribe", input_kafka_topic) \
    .load()

# parse the JSON data in the 'value' column using the defined schema then create a dataframe containing the reddit data
df = df.select(col("value").cast("string")) \
    .withColumn("value", from_json("value", schema)) \

parsed_df = df \
    .select("value.*")

# filter rows containing specific keywords
keywords = ['singapore', 'sg']

# initialize the filter condition with False
filter_condition = col("content").contains(keywords[0])

# loop through the rest of the keywords and update the filter condition
for keyword in keywords[1:]:
    filter_condition = filter_condition | col("content").contains(keyword)

# apply the filter condition to the DataFrame
filtered_df = parsed_df.filter(filter_condition)

# stream the data to kafka
kafka_write = filtered_df \
    .selectExpr("'' AS key", "to_json(struct(*)) AS value") \
    .writeStream \
    .format("kafka") \
    .option("kafka.bootstrap.servers", kafka_broker) \
    .option("topic", output_kafka_topic) \
    .start()

# Wait for the termination of the query
kafka_write.awaitTermination()

[WI-685][TI-1873] - [INFO] 2024-04-27 21:17:40.145 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-685][TI-1873] - [INFO] 2024-04-27 21:17:40.145 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-685][TI-1873] - [INFO] 2024-04-27 21:17:40.146 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export HADOOP_HOME=/opt/hadoop-3.4.0
export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export PYSPARK_DRIVER_PYTHON=/bin/python3.11
export PYTHON_LAUNCHER=/bin/python3.11
${PYTHON_LAUNCHER} /tmp/dolphinscheduler/exec/process/default/13010050770016/13377949373536_18/685/1873/py_685_1873.py
[WI-685][TI-1873] - [INFO] 2024-04-27 21:17:40.147 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-685][TI-1873] - [INFO] 2024-04-27 21:17:40.147 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13377949373536_18/685/1873/685_1873.sh
[WI-685][TI-1873] - [INFO] 2024-04-27 21:17:40.165 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 272
[WI-0][TI-1873] - [INFO] 2024-04-27 21:17:40.494 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1873, success=true)
[WI-0][TI-1873] - [INFO] 2024-04-27 21:17:40.541 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1873)
[WI-0][TI-0] - [INFO] 2024-04-27 21:17:41.020 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8581992641223577 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:17:41.166 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
[WI-0][TI-0] - [INFO] 2024-04-27 21:17:42.097 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9011797905616755 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:17:43.121 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8407828868357531 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:17:44.137 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9214685166989595 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:17:45.139 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7920792079207921 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:17:46.161 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7048192771084337 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:17:47.163 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7666666666666667 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:17:49.183 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.704412279500175 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:17:50.199 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7732642891043461 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:17:50.225 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	:: loading settings :: url = jar:file:/opt/spark-3.5.1-bin-hadoop3/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml
	Ivy Default Cache set to: /home/default/.ivy2/cache
	The jars for the packages stored in: /home/default/.ivy2/jars
	org.apache.spark#spark-sql-kafka-0-10_2.12 added as a dependency
	:: resolving dependencies :: org.apache.spark#spark-submit-parent-d66b7f5f-3ffa-400e-98e8-72ab3c57affb;1.0
		confs: [default]
[WI-0][TI-0] - [INFO] 2024-04-27 21:17:51.201 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8758169934640523 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:17:52.216 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.776470588235294 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:17:54.236 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	Exception in thread "main" java.io.FileNotFoundException: /home/default/.ivy2/cache/resolved-org.apache.spark-spark-submit-parent-d66b7f5f-3ffa-400e-98e8-72ab3c57affb-1.0.xml (No such file or directory)
		at java.io.FileOutputStream.open0(Native Method)
		at java.io.FileOutputStream.open(FileOutputStream.java:270)
		at java.io.FileOutputStream.<init>(FileOutputStream.java:213)
		at java.io.FileOutputStream.<init>(FileOutputStream.java:162)
		at org.apache.ivy.plugins.parser.xml.XmlModuleDescriptorWriter.write(XmlModuleDescriptorWriter.java:71)
		at org.apache.ivy.plugins.parser.xml.XmlModuleDescriptorWriter.write(XmlModuleDescriptorWriter.java:63)
		at org.apache.ivy.core.module.descriptor.DefaultModuleDescriptor.toIvyFile(DefaultModuleDescriptor.java:553)
		at org.apache.ivy.core.cache.DefaultResolutionCacheManager.saveResolvedModuleDescriptor(DefaultResolutionCacheManager.java:184)
		at org.apache.ivy.core.resolve.ResolveEngine.resolve(ResolveEngine.java:259)
		at org.apache.ivy.Ivy.resolve(Ivy.java:522)
		at org.apache.spark.deploy.SparkSubmitUtils$.resolveMavenCoordinates(SparkSubmit.scala:1580)
		at org.apache.spark.util.DependencyUtils$.resolveMavenDependencies(DependencyUtils.scala:185)
		at org.apache.spark.deploy.SparkSubmit.prepareSubmitEnvironment(SparkSubmit.scala:334)
		at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:964)
		at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:194)
		at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:217)
		at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:91)
		at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1120)
		at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1129)
		at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
	Traceback (most recent call last):
	  File "/tmp/dolphinscheduler/exec/process/default/13010050770016/13377949373536_18/685/1873/py_685_1873.py", line 12, in <module>
	    .getOrCreate()
	     ^^^^^^^^^^^^^
	  File "/usr/local/lib/python3.11/dist-packages/pyspark/sql/session.py", line 497, in getOrCreate
	    sc = SparkContext.getOrCreate(sparkConf)
	         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
	  File "/usr/local/lib/python3.11/dist-packages/pyspark/context.py", line 515, in getOrCreate
	    SparkContext(conf=conf or SparkConf())
	  File "/usr/local/lib/python3.11/dist-packages/pyspark/context.py", line 201, in __init__
	    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
	  File "/usr/local/lib/python3.11/dist-packages/pyspark/context.py", line 436, in _ensure_initialized
	    SparkContext._gateway = gateway or launch_gateway(conf)
	                                       ^^^^^^^^^^^^^^^^^^^^
	  File "/usr/local/lib/python3.11/dist-packages/pyspark/java_gateway.py", line 107, in launch_gateway
	    raise PySparkRuntimeError(
	pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[WI-685][TI-1873] - [INFO] 2024-04-27 21:17:54.238 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13377949373536_18/685/1873, processId:272 ,exitStatusCode:1 ,processWaitForStatus:true ,processExitValue:1
[WI-685][TI-1873] - [INFO] 2024-04-27 21:17:54.242 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-685][TI-1873] - [INFO] 2024-04-27 21:17:54.242 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-685][TI-1873] - [INFO] 2024-04-27 21:17:54.246 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-685][TI-1873] - [INFO] 2024-04-27 21:17:54.250 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-0][TI-0] - [INFO] 2024-04-27 21:17:54.260 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.75 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-685][TI-1873] - [INFO] 2024-04-27 21:17:54.260 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: FAILURE to master : 172.18.1.1:1234
[WI-685][TI-1873] - [INFO] 2024-04-27 21:17:54.262 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-685][TI-1873] - [INFO] 2024-04-27 21:17:54.262 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13377949373536_18/685/1873
[WI-685][TI-1873] - [INFO] 2024-04-27 21:17:54.264 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13377949373536_18/685/1873
[WI-685][TI-1873] - [INFO] 2024-04-27 21:17:54.265 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-1873] - [INFO] 2024-04-27 21:17:54.520 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1873, success=true)
[WI-0][TI-0] - [INFO] 2024-04-27 21:17:55.281 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7462235649546828 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:20:38.217 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7095890410958904 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:20:42.268 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8658536585365854 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:20:43.332 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.821917808219178 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:21:55.808 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9329608938547486 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:22:13.004 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7130434782608696 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:22:14.045 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7127148344837085 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:22:15.047 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7275362318840579 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:22:20.075 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8328690807799444 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:22:21.101 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7275362318840579 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:22:26.119 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7222222222222223 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:22:45.213 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8205882352941176 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:22:46.231 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7877906976744187 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:22:47.234 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7464387464387465 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:22:49.251 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7971014492753623 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:22:53.403 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7129909365558912 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:22:54.437 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7650429799426934 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:22:56.465 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8372093023255813 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:23:01.493 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8475609756097561 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:23:07.580 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7485549132947977 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:23:10.701 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8108108108108107 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:23:11.714 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8125 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:23:12.716 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9198813056379822 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:23:13.718 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8666666666666667 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:23:15.737 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7864583333333334 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:23:17.873 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8497267759562841 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:23:38.975 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7310126582278481 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:23:40.032 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9310344827586208 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:23:49.070 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9213483146067415 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:23:53.123 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7384615384615385 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:23:54.143 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8785310734463276 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:23:55.148 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7392638036809815 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:23:56.154 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8571428571428571 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:24:01.182 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8307692307692308 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:24:03.223 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7165109034267912 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:24:04.248 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8508771929824561 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:24:05.705 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1881, taskName=keyword filtering, firstSubmitTime=1714224245691, startTime=0, taskType=PYTHON, workflowInstanceHost=172.18.0.9:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13377949373536, processDefineVersion=19, appIds=null, processInstanceId=686, scheduleTime=0, globalParams=[{"prop":"keywords","direct":"IN","type":"VARCHAR","value":"\"singapore\", \"lol\""}], executorId=1, cmdTypeIfComplement=7, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[],"rawScript":"from pyspark.sql import SparkSession\nfrom pyspark.sql.functions import col, from_json\nfrom pyspark.sql.types import StringType, StructType, StructField, IntegerType\n\nspark = SparkSession.builder \\\n    .master(\"local\") \\\n    .appName(\"Reddit Keyword Filtering\") \\\n    .config(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1\") \\\n    .config(\"spark.sql.streaming.checkpointLocation\", r\"/tmp/\") \\\n    .config(\"spark.driver.extraJavaOptions\", \"-Divy.cache.dir=/tmp -Divy.home=/tmp\") \\\n    .getOrCreate()\n\n# define the schema for the JSON data\nschema = StructType([\n    StructField(\"user\", StringType(), nullable=True),\n    StructField(\"content\", StringType(), nullable=True),\n    StructField(\"url\", StringType(), nullable=True),\n    StructField(\"context\", StringType(), nullable=True),\n    StructField(\"score\", IntegerType(), nullable=True),\n    StructField(\"subreddit\", StringType(), nullable=True),\n    StructField(\"type\", StringType(), nullable=True),\n    StructField(\"id\", StringType(), nullable=True),\n    StructField(\"datetime\", StringType(), nullable=True)  # Assuming the datetime is string type, you can change it to TimestampType if needed\n])\n\n# define the parameters for the input and output kafka broker and topic\nkafka_broker = \"kafka:9092\"\ninput_kafka_topic = \"reddit_post_preprocessed\"\noutput_kafka_topic = \"reddit_post_filtered\"\n\n# Subscribe to the input topic\ndf = spark \\\n    .readStream \\\n    .format(\"kafka\") \\\n    .option(\"kafka.bootstrap.servers\", kafka_broker) \\\n    .option(\"subscribe\", input_kafka_topic) \\\n    .load()\n\n# parse the JSON data in the 'value' column using the defined schema then create a dataframe containing the reddit data\ndf = df.select(col(\"value\").cast(\"string\")) \\\n    .withColumn(\"value\", from_json(\"value\", schema)) \\\n\nparsed_df = df \\\n    .select(\"value.*\")\n\n# filter rows containing specific keywords\nkeywords = ['singapore', 'sg']\n\n# initialize the filter condition with False\nfilter_condition = col(\"content\").contains(keywords[0])\n\n# loop through the rest of the keywords and update the filter condition\nfor keyword in keywords[1:]:\n    filter_condition = filter_condition | col(\"content\").contains(keyword)\n\n# apply the filter condition to the DataFrame\nfiltered_df = parsed_df.filter(filter_condition)\n\n# stream the data to kafka\nkafka_write = filtered_df \\\n    .selectExpr(\"'' AS key\", \"to_json(struct(*)) AS value\") \\\n    .writeStream \\\n    .format(\"kafka\") \\\n    .option(\"kafka.bootstrap.servers\", kafka_broker) \\\n    .option(\"topic\", output_kafka_topic) \\\n    .start()\n\n# Wait for the termination of the query\nkafka_write.awaitTermination()\n","resourceList":[]}, environmentConfig=export HADOOP_HOME=/opt/hadoop-3.4.0
export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export PYSPARK_DRIVER_PYTHON=/bin/python3.11
export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='keyword filtering'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, keywords=Property{prop='keywords', direct=IN, type=VARCHAR, value='"singapore", "lol"'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240427'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1881'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13377752024032'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240427212405'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='686'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240426'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='filter_data'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13377949373536'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=null, dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-686][TI-1881] - [INFO] 2024-04-27 21:24:05.711 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-686][TI-1881] - [INFO] 2024-04-27 21:24:05.711 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: keyword filtering to wait queue success
[WI-686][TI-1881] - [INFO] 2024-04-27 21:24:05.716 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-686][TI-1881] - [INFO] 2024-04-27 21:24:05.717 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-686][TI-1881] - [INFO] 2024-04-27 21:24:05.718 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-686][TI-1881] - [INFO] 2024-04-27 21:24:05.718 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1714224245718
[WI-686][TI-1881] - [INFO] 2024-04-27 21:24:05.718 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 686_1881
[WI-686][TI-1881] - [INFO] 2024-04-27 21:24:05.720 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1881,
  "taskName" : "keyword filtering",
  "firstSubmitTime" : 1714224245691,
  "startTime" : 1714224245718,
  "taskType" : "PYTHON",
  "workflowInstanceHost" : "172.18.0.9:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240427/13377949373536/19/686/1881.log",
  "processId" : 0,
  "processDefineCode" : 13377949373536,
  "processDefineVersion" : 19,
  "processInstanceId" : 686,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"keywords\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"\\\"singapore\\\", \\\"lol\\\"\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 7,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[],\"rawScript\":\"from pyspark.sql import SparkSession\\nfrom pyspark.sql.functions import col, from_json\\nfrom pyspark.sql.types import StringType, StructType, StructField, IntegerType\\n\\nspark = SparkSession.builder \\\\\\n    .master(\\\"local\\\") \\\\\\n    .appName(\\\"Reddit Keyword Filtering\\\") \\\\\\n    .config(\\\"spark.jars.packages\\\", \\\"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1\\\") \\\\\\n    .config(\\\"spark.sql.streaming.checkpointLocation\\\", r\\\"/tmp/\\\") \\\\\\n    .config(\\\"spark.driver.extraJavaOptions\\\", \\\"-Divy.cache.dir=/tmp -Divy.home=/tmp\\\") \\\\\\n    .getOrCreate()\\n\\n# define the schema for the JSON data\\nschema = StructType([\\n    StructField(\\\"user\\\", StringType(), nullable=True),\\n    StructField(\\\"content\\\", StringType(), nullable=True),\\n    StructField(\\\"url\\\", StringType(), nullable=True),\\n    StructField(\\\"context\\\", StringType(), nullable=True),\\n    StructField(\\\"score\\\", IntegerType(), nullable=True),\\n    StructField(\\\"subreddit\\\", StringType(), nullable=True),\\n    StructField(\\\"type\\\", StringType(), nullable=True),\\n    StructField(\\\"id\\\", StringType(), nullable=True),\\n    StructField(\\\"datetime\\\", StringType(), nullable=True)  # Assuming the datetime is string type, you can change it to TimestampType if needed\\n])\\n\\n# define the parameters for the input and output kafka broker and topic\\nkafka_broker = \\\"kafka:9092\\\"\\ninput_kafka_topic = \\\"reddit_post_preprocessed\\\"\\noutput_kafka_topic = \\\"reddit_post_filtered\\\"\\n\\n# Subscribe to the input topic\\ndf = spark \\\\\\n    .readStream \\\\\\n    .format(\\\"kafka\\\") \\\\\\n    .option(\\\"kafka.bootstrap.servers\\\", kafka_broker) \\\\\\n    .option(\\\"subscribe\\\", input_kafka_topic) \\\\\\n    .load()\\n\\n# parse the JSON data in the 'value' column using the defined schema then create a dataframe containing the reddit data\\ndf = df.select(col(\\\"value\\\").cast(\\\"string\\\")) \\\\\\n    .withColumn(\\\"value\\\", from_json(\\\"value\\\", schema)) \\\\\\n\\nparsed_df = df \\\\\\n    .select(\\\"value.*\\\")\\n\\n# filter rows containing specific keywords\\nkeywords = ['singapore', 'sg']\\n\\n# initialize the filter condition with False\\nfilter_condition = col(\\\"content\\\").contains(keywords[0])\\n\\n# loop through the rest of the keywords and update the filter condition\\nfor keyword in keywords[1:]:\\n    filter_condition = filter_condition | col(\\\"content\\\").contains(keyword)\\n\\n# apply the filter condition to the DataFrame\\nfiltered_df = parsed_df.filter(filter_condition)\\n\\n# stream the data to kafka\\nkafka_write = filtered_df \\\\\\n    .selectExpr(\\\"'' AS key\\\", \\\"to_json(struct(*)) AS value\\\") \\\\\\n    .writeStream \\\\\\n    .format(\\\"kafka\\\") \\\\\\n    .option(\\\"kafka.bootstrap.servers\\\", kafka_broker) \\\\\\n    .option(\\\"topic\\\", output_kafka_topic) \\\\\\n    .start()\\n\\n# Wait for the termination of the query\\nkafka_write.awaitTermination()\\n\",\"resourceList\":[]}",
  "environmentConfig" : "export HADOOP_HOME=/opt/hadoop-3.4.0\nexport SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3\nexport JAVA_HOME=/opt/java/openjdk\nexport PYSPARK_DRIVER_PYTHON=/bin/python3.11\nexport PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "keyword filtering"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "keywords" : {
      "prop" : "keywords",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "\"singapore\", \"lol\""
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240427"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1881"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13377752024032"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240427212405"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "686"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240426"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "filter_data"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13377949373536"
    }
  },
  "taskAppId" : "686_1881",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-686][TI-1881] - [INFO] 2024-04-27 21:24:05.721 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-686][TI-1881] - [INFO] 2024-04-27 21:24:05.721 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-686][TI-1881] - [INFO] 2024-04-27 21:24:05.721 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-686][TI-1881] - [INFO] 2024-04-27 21:24:05.725 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-686][TI-1881] - [INFO] 2024-04-27 21:24:05.726 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-686][TI-1881] - [INFO] 2024-04-27 21:24:05.727 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13377949373536_19/686/1881 check successfully
[WI-686][TI-1881] - [INFO] 2024-04-27 21:24:05.732 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.python.PythonTaskChannel successfully
[WI-686][TI-1881] - [INFO] 2024-04-27 21:24:05.734 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-686][TI-1881] - [INFO] 2024-04-27 21:24:05.735 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-686][TI-1881] - [INFO] 2024-04-27 21:24:05.737 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: PYTHON create successfully
[WI-686][TI-1881] - [INFO] 2024-04-27 21:24:05.737 +0800 o.a.d.p.t.p.PythonTask:[75] - Initialize python task params {
  "localParams" : [ ],
  "varPool" : null,
  "rawScript" : "from pyspark.sql import SparkSession\nfrom pyspark.sql.functions import col, from_json\nfrom pyspark.sql.types import StringType, StructType, StructField, IntegerType\n\nspark = SparkSession.builder \\\n    .master(\"local\") \\\n    .appName(\"Reddit Keyword Filtering\") \\\n    .config(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1\") \\\n    .config(\"spark.sql.streaming.checkpointLocation\", r\"/tmp/\") \\\n    .config(\"spark.driver.extraJavaOptions\", \"-Divy.cache.dir=/tmp -Divy.home=/tmp\") \\\n    .getOrCreate()\n\n# define the schema for the JSON data\nschema = StructType([\n    StructField(\"user\", StringType(), nullable=True),\n    StructField(\"content\", StringType(), nullable=True),\n    StructField(\"url\", StringType(), nullable=True),\n    StructField(\"context\", StringType(), nullable=True),\n    StructField(\"score\", IntegerType(), nullable=True),\n    StructField(\"subreddit\", StringType(), nullable=True),\n    StructField(\"type\", StringType(), nullable=True),\n    StructField(\"id\", StringType(), nullable=True),\n    StructField(\"datetime\", StringType(), nullable=True)  # Assuming the datetime is string type, you can change it to TimestampType if needed\n])\n\n# define the parameters for the input and output kafka broker and topic\nkafka_broker = \"kafka:9092\"\ninput_kafka_topic = \"reddit_post_preprocessed\"\noutput_kafka_topic = \"reddit_post_filtered\"\n\n# Subscribe to the input topic\ndf = spark \\\n    .readStream \\\n    .format(\"kafka\") \\\n    .option(\"kafka.bootstrap.servers\", kafka_broker) \\\n    .option(\"subscribe\", input_kafka_topic) \\\n    .load()\n\n# parse the JSON data in the 'value' column using the defined schema then create a dataframe containing the reddit data\ndf = df.select(col(\"value\").cast(\"string\")) \\\n    .withColumn(\"value\", from_json(\"value\", schema)) \\\n\nparsed_df = df \\\n    .select(\"value.*\")\n\n# filter rows containing specific keywords\nkeywords = ['singapore', 'sg']\n\n# initialize the filter condition with False\nfilter_condition = col(\"content\").contains(keywords[0])\n\n# loop through the rest of the keywords and update the filter condition\nfor keyword in keywords[1:]:\n    filter_condition = filter_condition | col(\"content\").contains(keyword)\n\n# apply the filter condition to the DataFrame\nfiltered_df = parsed_df.filter(filter_condition)\n\n# stream the data to kafka\nkafka_write = filtered_df \\\n    .selectExpr(\"'' AS key\", \"to_json(struct(*)) AS value\") \\\n    .writeStream \\\n    .format(\"kafka\") \\\n    .option(\"kafka.bootstrap.servers\", kafka_broker) \\\n    .option(\"topic\", output_kafka_topic) \\\n    .start()\n\n# Wait for the termination of the query\nkafka_write.awaitTermination()\n",
  "resourceList" : [ ]
}
[WI-686][TI-1881] - [INFO] 2024-04-27 21:24:05.738 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-686][TI-1881] - [INFO] 2024-04-27 21:24:05.738 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: null successfully
[WI-686][TI-1881] - [INFO] 2024-04-27 21:24:05.738 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-686][TI-1881] - [INFO] 2024-04-27 21:24:05.738 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-686][TI-1881] - [INFO] 2024-04-27 21:24:05.738 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-686][TI-1881] - [INFO] 2024-04-27 21:24:05.738 +0800 o.a.d.p.t.p.PythonTask:[165] - raw python script : from pyspark.sql import SparkSession
from pyspark.sql.functions import col, from_json
from pyspark.sql.types import StringType, StructType, StructField, IntegerType

spark = SparkSession.builder \
    .master("local") \
    .appName("Reddit Keyword Filtering") \
    .config("spark.jars.packages", "org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1") \
    .config("spark.sql.streaming.checkpointLocation", r"/tmp/") \
    .config("spark.driver.extraJavaOptions", "-Divy.cache.dir=/tmp -Divy.home=/tmp") \
    .getOrCreate()

# define the schema for the JSON data
schema = StructType([
    StructField("user", StringType(), nullable=True),
    StructField("content", StringType(), nullable=True),
    StructField("url", StringType(), nullable=True),
    StructField("context", StringType(), nullable=True),
    StructField("score", IntegerType(), nullable=True),
    StructField("subreddit", StringType(), nullable=True),
    StructField("type", StringType(), nullable=True),
    StructField("id", StringType(), nullable=True),
    StructField("datetime", StringType(), nullable=True)  # Assuming the datetime is string type, you can change it to TimestampType if needed
])

# define the parameters for the input and output kafka broker and topic
kafka_broker = "kafka:9092"
input_kafka_topic = "reddit_post_preprocessed"
output_kafka_topic = "reddit_post_filtered"

# Subscribe to the input topic
df = spark \
    .readStream \
    .format("kafka") \
    .option("kafka.bootstrap.servers", kafka_broker) \
    .option("subscribe", input_kafka_topic) \
    .load()

# parse the JSON data in the 'value' column using the defined schema then create a dataframe containing the reddit data
df = df.select(col("value").cast("string")) \
    .withColumn("value", from_json("value", schema)) \

parsed_df = df \
    .select("value.*")

# filter rows containing specific keywords
keywords = ['singapore', 'sg']

# initialize the filter condition with False
filter_condition = col("content").contains(keywords[0])

# loop through the rest of the keywords and update the filter condition
for keyword in keywords[1:]:
    filter_condition = filter_condition | col("content").contains(keyword)

# apply the filter condition to the DataFrame
filtered_df = parsed_df.filter(filter_condition)

# stream the data to kafka
kafka_write = filtered_df \
    .selectExpr("'' AS key", "to_json(struct(*)) AS value") \
    .writeStream \
    .format("kafka") \
    .option("kafka.bootstrap.servers", kafka_broker) \
    .option("topic", output_kafka_topic) \
    .start()

# Wait for the termination of the query
kafka_write.awaitTermination()

[WI-686][TI-1881] - [INFO] 2024-04-27 21:24:05.739 +0800 o.a.d.p.t.p.PythonTask:[131] - tenantCode :default, task dir:/tmp/dolphinscheduler/exec/process/default/13010050770016/13377949373536_19/686/1881
[WI-686][TI-1881] - [INFO] 2024-04-27 21:24:05.740 +0800 o.a.d.p.t.p.PythonTask:[134] - generate python script file:/tmp/dolphinscheduler/exec/process/default/13010050770016/13377949373536_19/686/1881/py_686_1881.py
[WI-686][TI-1881] - [INFO] 2024-04-27 21:24:05.740 +0800 o.a.d.p.t.p.PythonTask:[141] - #-*- encoding=utf8 -*-

from pyspark.sql import SparkSession
from pyspark.sql.functions import col, from_json
from pyspark.sql.types import StringType, StructType, StructField, IntegerType

spark = SparkSession.builder \
    .master("local") \
    .appName("Reddit Keyword Filtering") \
    .config("spark.jars.packages", "org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1") \
    .config("spark.sql.streaming.checkpointLocation", r"/tmp/") \
    .config("spark.driver.extraJavaOptions", "-Divy.cache.dir=/tmp -Divy.home=/tmp") \
    .getOrCreate()

# define the schema for the JSON data
schema = StructType([
    StructField("user", StringType(), nullable=True),
    StructField("content", StringType(), nullable=True),
    StructField("url", StringType(), nullable=True),
    StructField("context", StringType(), nullable=True),
    StructField("score", IntegerType(), nullable=True),
    StructField("subreddit", StringType(), nullable=True),
    StructField("type", StringType(), nullable=True),
    StructField("id", StringType(), nullable=True),
    StructField("datetime", StringType(), nullable=True)  # Assuming the datetime is string type, you can change it to TimestampType if needed
])

# define the parameters for the input and output kafka broker and topic
kafka_broker = "kafka:9092"
input_kafka_topic = "reddit_post_preprocessed"
output_kafka_topic = "reddit_post_filtered"

# Subscribe to the input topic
df = spark \
    .readStream \
    .format("kafka") \
    .option("kafka.bootstrap.servers", kafka_broker) \
    .option("subscribe", input_kafka_topic) \
    .load()

# parse the JSON data in the 'value' column using the defined schema then create a dataframe containing the reddit data
df = df.select(col("value").cast("string")) \
    .withColumn("value", from_json("value", schema)) \

parsed_df = df \
    .select("value.*")

# filter rows containing specific keywords
keywords = ['singapore', 'sg']

# initialize the filter condition with False
filter_condition = col("content").contains(keywords[0])

# loop through the rest of the keywords and update the filter condition
for keyword in keywords[1:]:
    filter_condition = filter_condition | col("content").contains(keyword)

# apply the filter condition to the DataFrame
filtered_df = parsed_df.filter(filter_condition)

# stream the data to kafka
kafka_write = filtered_df \
    .selectExpr("'' AS key", "to_json(struct(*)) AS value") \
    .writeStream \
    .format("kafka") \
    .option("kafka.bootstrap.servers", kafka_broker) \
    .option("topic", output_kafka_topic) \
    .start()

# Wait for the termination of the query
kafka_write.awaitTermination()

[WI-686][TI-1881] - [INFO] 2024-04-27 21:24:05.741 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-686][TI-1881] - [INFO] 2024-04-27 21:24:05.741 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-686][TI-1881] - [INFO] 2024-04-27 21:24:05.741 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export HADOOP_HOME=/opt/hadoop-3.4.0
export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export PYSPARK_DRIVER_PYTHON=/bin/python3.11
export PYTHON_LAUNCHER=/bin/python3.11
${PYTHON_LAUNCHER} /tmp/dolphinscheduler/exec/process/default/13010050770016/13377949373536_19/686/1881/py_686_1881.py
[WI-686][TI-1881] - [INFO] 2024-04-27 21:24:05.742 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-686][TI-1881] - [INFO] 2024-04-27 21:24:05.742 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13377949373536_19/686/1881/686_1881.sh
[WI-686][TI-1881] - [INFO] 2024-04-27 21:24:05.746 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 403
[WI-0][TI-1881] - [INFO] 2024-04-27 21:24:06.170 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1881, success=true)
[WI-0][TI-1881] - [INFO] 2024-04-27 21:24:06.182 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1881)
[WI-0][TI-0] - [INFO] 2024-04-27 21:24:06.752 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
[WI-0][TI-0] - [INFO] 2024-04-27 21:24:07.270 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8432055749128919 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:24:08.322 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7435897435897436 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:24:10.404 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8006134969325153 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:24:10.885 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	:: loading settings :: url = jar:file:/opt/spark-3.5.1-bin-hadoop3/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml
	Ivy Default Cache set to: /tmp
	The jars for the packages stored in: /tmp/jars
	org.apache.spark#spark-sql-kafka-0-10_2.12 added as a dependency
	:: resolving dependencies :: org.apache.spark#spark-submit-parent-126ed219-e557-4ea9-aea5-365e840d21d2;1.0
		confs: [default]
[WI-0][TI-0] - [INFO] 2024-04-27 21:24:11.496 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9571045576407506 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:24:15.515 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8140243902439025 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:24:16.542 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9123287671232876 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:24:17.545 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7547169811320754 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:24:17.896 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
		found org.apache.spark#spark-sql-kafka-0-10_2.12;3.5.1 in central
[WI-0][TI-0] - [INFO] 2024-04-27 21:24:18.899 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
		found org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.5.1 in central
		found org.apache.kafka#kafka-clients;3.4.1 in central
[WI-0][TI-0] - [INFO] 2024-04-27 21:24:19.920 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
		found org.lz4#lz4-java;1.8.0 in central
		found org.xerial.snappy#snappy-java;1.1.10.3 in central
[WI-0][TI-0] - [INFO] 2024-04-27 21:24:21.929 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
		found org.slf4j#slf4j-api;2.0.7 in central
[WI-0][TI-0] - [INFO] 2024-04-27 21:24:25.934 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
		found org.apache.hadoop#hadoop-client-runtime;3.3.4 in central
		found org.apache.hadoop#hadoop-client-api;3.3.4 in central
[WI-0][TI-0] - [INFO] 2024-04-27 21:24:28.946 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
		found commons-logging#commons-logging;1.1.3 in central
[WI-0][TI-0] - [INFO] 2024-04-27 21:24:29.961 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
		found com.google.code.findbugs#jsr305;3.0.0 in central
[WI-0][TI-0] - [INFO] 2024-04-27 21:24:32.965 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
		found org.apache.commons#commons-pool2;2.11.1 in central
	downloading https://repo1.maven.org/maven2/org/apache/spark/spark-sql-kafka-0-10_2.12/3.5.1/spark-sql-kafka-0-10_2.12-3.5.1.jar ...
[WI-0][TI-0] - [INFO] 2024-04-27 21:24:33.966 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
		[SUCCESSFUL ] org.apache.spark#spark-sql-kafka-0-10_2.12;3.5.1!spark-sql-kafka-0-10_2.12.jar (743ms)
	downloading https://repo1.maven.org/maven2/org/apache/spark/spark-token-provider-kafka-0-10_2.12/3.5.1/spark-token-provider-kafka-0-10_2.12-3.5.1.jar ...
		[SUCCESSFUL ] org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.5.1!spark-token-provider-kafka-0-10_2.12.jar (460ms)
	downloading https://repo1.maven.org/maven2/org/apache/kafka/kafka-clients/3.4.1/kafka-clients-3.4.1.jar ...
[WI-0][TI-0] - [INFO] 2024-04-27 21:24:34.969 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
		[SUCCESSFUL ] org.apache.kafka#kafka-clients;3.4.1!kafka-clients.jar (1285ms)
[WI-0][TI-0] - [INFO] 2024-04-27 21:24:35.971 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	downloading https://repo1.maven.org/maven2/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar ...
		[SUCCESSFUL ] com.google.code.findbugs#jsr305;3.0.0!jsr305.jar (455ms)
	downloading https://repo1.maven.org/maven2/org/apache/commons/commons-pool2/2.11.1/commons-pool2-2.11.1.jar ...
		[SUCCESSFUL ] org.apache.commons#commons-pool2;2.11.1!commons-pool2.jar (444ms)
[WI-0][TI-0] - [INFO] 2024-04-27 21:24:36.975 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	downloading https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-client-runtime/3.3.4/hadoop-client-runtime-3.3.4.jar ...
[WI-0][TI-0] - [INFO] 2024-04-27 21:24:37.978 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
		[SUCCESSFUL ] org.apache.hadoop#hadoop-client-runtime;3.3.4!hadoop-client-runtime.jar (1849ms)
	downloading https://repo1.maven.org/maven2/org/lz4/lz4-java/1.8.0/lz4-java-1.8.0.jar ...
[WI-0][TI-0] - [INFO] 2024-04-27 21:24:38.998 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
		[SUCCESSFUL ] org.lz4#lz4-java;1.8.0!lz4-java.jar (461ms)
	downloading https://repo1.maven.org/maven2/org/xerial/snappy/snappy-java/1.1.10.3/snappy-java-1.1.10.3.jar ...
		[SUCCESSFUL ] org.xerial.snappy#snappy-java;1.1.10.3!snappy-java.jar(bundle) (509ms)
	downloading https://repo1.maven.org/maven2/org/slf4j/slf4j-api/2.0.7/slf4j-api-2.0.7.jar ...
[WI-0][TI-0] - [INFO] 2024-04-27 21:24:39.999 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
		[SUCCESSFUL ] org.slf4j#slf4j-api;2.0.7!slf4j-api.jar (441ms)
	downloading https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-client-api/3.3.4/hadoop-client-api-3.3.4.jar ...
[WI-0][TI-0] - [INFO] 2024-04-27 21:24:41.091 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
		[SUCCESSFUL ] org.apache.hadoop#hadoop-client-api;3.3.4!hadoop-client-api.jar (1230ms)
	downloading https://repo1.maven.org/maven2/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar ...
		[SUCCESSFUL ] commons-logging#commons-logging;1.1.3!commons-logging.jar (431ms)
	:: resolution report :: resolve 21869ms :: artifacts dl 8325ms
		:: modules in use:
		com.google.code.findbugs#jsr305;3.0.0 from central in [default]
		commons-logging#commons-logging;1.1.3 from central in [default]
		org.apache.commons#commons-pool2;2.11.1 from central in [default]
		org.apache.hadoop#hadoop-client-api;3.3.4 from central in [default]
		org.apache.hadoop#hadoop-client-runtime;3.3.4 from central in [default]
		org.apache.kafka#kafka-clients;3.4.1 from central in [default]
		org.apache.spark#spark-sql-kafka-0-10_2.12;3.5.1 from central in [default]
		org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.5.1 from central in [default]
		org.lz4#lz4-java;1.8.0 from central in [default]
		org.slf4j#slf4j-api;2.0.7 from central in [default]
		org.xerial.snappy#snappy-java;1.1.10.3 from central in [default]
		---------------------------------------------------------------------
		|                  |            modules            ||   artifacts   |
		|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
		---------------------------------------------------------------------
		|      default     |   11  |   11  |   11  |   0   ||   11  |   11  |
		---------------------------------------------------------------------
	:: retrieving :: org.apache.spark#spark-submit-parent-126ed219-e557-4ea9-aea5-365e840d21d2
		confs: [default]
		11 artifacts copied, 0 already retrieved (56767kB/284ms)
[WI-0][TI-0] - [INFO] 2024-04-27 21:24:42.093 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/27 21:24:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[WI-0][TI-0] - [INFO] 2024-04-27 21:24:42.666 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.737313432835821 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:24:43.096 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	Setting default log level to "WARN".
	To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[WI-0][TI-0] - [INFO] 2024-04-27 21:24:43.730 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7131147540983607 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:24:47.764 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8140243902439024 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:24:56.117 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/27 21:24:56 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.
[WI-0][TI-0] - [INFO] 2024-04-27 21:24:56.910 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7675159235668789 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:24:58.975 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7047970479704797 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:24:59.136 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/27 21:24:58 WARN AdminClientConfig: These configurations '[key.deserializer, value.deserializer, enable.auto.commit, max.poll.records, auto.offset.reset]' were supplied but are not used yet.
[WI-0][TI-0] - [INFO] 2024-04-27 21:25:00.202 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/27 21:24:59 WARN KafkaOffsetReaderAdmin: Error in attempt 1 getting Kafka offsets: 
	java.util.concurrent.ExecutionException: org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
		at java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:357)
		at java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1908)
		at org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:165)
		at org.apache.spark.sql.kafka010.ConsumerStrategy.retrieveAllPartitions(ConsumerStrategy.scala:66)
		at org.apache.spark.sql.kafka010.ConsumerStrategy.retrieveAllPartitions$(ConsumerStrategy.scala:65)
		at org.apache.spark.sql.kafka010.SubscribeStrategy.retrieveAllPartitions(ConsumerStrategy.scala:102)
		at org.apache.spark.sql.kafka010.SubscribeStrategy.assignedTopicPartitions(ConsumerStrategy.scala:113)
		at org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.$anonfun$partitionsAssignedToAdmin$1(KafkaOffsetReaderAdmin.scala:499)
		at org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.withRetries(KafkaOffsetReaderAdmin.scala:518)
		at org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.partitionsAssignedToAdmin(KafkaOffsetReaderAdmin.scala:498)
		at org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.fetchLatestOffsets(KafkaOffsetReaderAdmin.scala:297)
		at org.apache.spark.sql.kafka010.KafkaMicroBatchStream.$anonfun$getOrCreateInitialPartitionOffsets$1(KafkaMicroBatchStream.scala:246)
		at scala.Option.getOrElse(Option.scala:189)
		at org.apache.spark.sql.kafka010.KafkaMicroBatchStream.getOrCreateInitialPartitionOffsets(KafkaMicroBatchStream.scala:241)
		at org.apache.spark.sql.kafka010.KafkaMicroBatchStream.initialOffset(KafkaMicroBatchStream.scala:98)
		at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$getStartOffset$2(MicroBatchExecution.scala:457)
		at scala.Option.getOrElse(Option.scala:189)
		at org.apache.spark.sql.execution.streaming.MicroBatchExecution.getStartOffset(MicroBatchExecution.scala:457)
		at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$4(MicroBatchExecution.scala:491)
		at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)
		at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)
		at org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)
		at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$2(MicroBatchExecution.scala:490)
		at scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:286)
		at scala.collection.Iterator.foreach(Iterator.scala:943)
		at scala.collection.Iterator.foreach$(Iterator.scala:943)
		at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
		at scala.collection.IterableLike.foreach(IterableLike.scala:74)
		at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
		at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
		at scala.collection.TraversableLike.map(TraversableLike.scala:286)
		at scala.collection.TraversableLike.map$(TraversableLike.scala:279)
		at scala.collection.AbstractTraversable.map(Traversable.scala:108)
		at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$1(MicroBatchExecution.scala:479)
		at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
		at org.apache.spark.sql.execution.streaming.MicroBatchExecution.withProgressLocked(MicroBatchExecution.scala:810)
		at org.apache.spark.sql.execution.streaming.MicroBatchExecution.constructNextBatch(MicroBatchExecution.scala:475)
		at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:268)
		at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
		at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)
		at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)
		at org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)
		at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)
		at org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)
		at org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)
		at org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)
		at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
		at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
		at org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)
		at org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)
		at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
		at org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)
		at org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)
	Caused by: org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[WI-0][TI-0] - [INFO] 2024-04-27 21:25:01.217 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/27 21:25:00 WARN AdminClientConfig: These configurations '[key.deserializer, value.deserializer, enable.auto.commit, max.poll.records, auto.offset.reset]' were supplied but are not used yet.
	24/04/27 21:25:01 WARN KafkaOffsetReaderAdmin: Error in attempt 2 getting Kafka offsets: 
	java.util.concurrent.ExecutionException: org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
		at java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:357)
		at java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1908)
		at org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:165)
		at org.apache.spark.sql.kafka010.ConsumerStrategy.retrieveAllPartitions(ConsumerStrategy.scala:66)
		at org.apache.spark.sql.kafka010.ConsumerStrategy.retrieveAllPartitions$(ConsumerStrategy.scala:65)
		at org.apache.spark.sql.kafka010.SubscribeStrategy.retrieveAllPartitions(ConsumerStrategy.scala:102)
		at org.apache.spark.sql.kafka010.SubscribeStrategy.assignedTopicPartitions(ConsumerStrategy.scala:113)
		at org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.$anonfun$partitionsAssignedToAdmin$1(KafkaOffsetReaderAdmin.scala:499)
		at org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.withRetries(KafkaOffsetReaderAdmin.scala:518)
		at org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.partitionsAssignedToAdmin(KafkaOffsetReaderAdmin.scala:498)
		at org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.fetchLatestOffsets(KafkaOffsetReaderAdmin.scala:297)
		at org.apache.spark.sql.kafka010.KafkaMicroBatchStream.$anonfun$getOrCreateInitialPartitionOffsets$1(KafkaMicroBatchStream.scala:246)
		at scala.Option.getOrElse(Option.scala:189)
		at org.apache.spark.sql.kafka010.KafkaMicroBatchStream.getOrCreateInitialPartitionOffsets(KafkaMicroBatchStream.scala:241)
		at org.apache.spark.sql.kafka010.KafkaMicroBatchStream.initialOffset(KafkaMicroBatchStream.scala:98)
		at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$getStartOffset$2(MicroBatchExecution.scala:457)
		at scala.Option.getOrElse(Option.scala:189)
		at org.apache.spark.sql.execution.streaming.MicroBatchExecution.getStartOffset(MicroBatchExecution.scala:457)
		at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$4(MicroBatchExecution.scala:491)
		at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)
		at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)
		at org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)
		at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$2(MicroBatchExecution.scala:490)
		at scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:286)
		at scala.collection.Iterator.foreach(Iterator.scala:943)
		at scala.collection.Iterator.foreach$(Iterator.scala:943)
		at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
		at scala.collection.IterableLike.foreach(IterableLike.scala:74)
		at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
		at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
		at scala.collection.TraversableLike.map(TraversableLike.scala:286)
		at scala.collection.TraversableLike.map$(TraversableLike.scala:279)
		at scala.collection.AbstractTraversable.map(Traversable.scala:108)
		at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$1(MicroBatchExecution.scala:479)
		at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
		at org.apache.spark.sql.execution.streaming.MicroBatchExecution.withProgressLocked(MicroBatchExecution.scala:810)
		at org.apache.spark.sql.execution.streaming.MicroBatchExecution.constructNextBatch(MicroBatchExecution.scala:475)
		at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:268)
		at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
		at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)
		at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)
		at org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)
		at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)
		at org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)
		at org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)
		at org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)
		at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
		at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
		at org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)
		at org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)
		at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
		at org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)
		at org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)
	Caused by: org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[WI-0][TI-0] - [INFO] 2024-04-27 21:25:02.221 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/27 21:25:02 WARN AdminClientConfig: These configurations '[key.deserializer, value.deserializer, enable.auto.commit, max.poll.records, auto.offset.reset]' were supplied but are not used yet.
	24/04/27 21:25:02 WARN KafkaOffsetReaderAdmin: Error in attempt 3 getting Kafka offsets: 
	java.util.concurrent.ExecutionException: org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
		at java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:357)
		at java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1908)
		at org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:165)
		at org.apache.spark.sql.kafka010.ConsumerStrategy.retrieveAllPartitions(ConsumerStrategy.scala:66)
		at org.apache.spark.sql.kafka010.ConsumerStrategy.retrieveAllPartitions$(ConsumerStrategy.scala:65)
		at org.apache.spark.sql.kafka010.SubscribeStrategy.retrieveAllPartitions(ConsumerStrategy.scala:102)
		at org.apache.spark.sql.kafka010.SubscribeStrategy.assignedTopicPartitions(ConsumerStrategy.scala:113)
		at org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.$anonfun$partitionsAssignedToAdmin$1(KafkaOffsetReaderAdmin.scala:499)
		at org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.withRetries(KafkaOffsetReaderAdmin.scala:518)
		at org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.partitionsAssignedToAdmin(KafkaOffsetReaderAdmin.scala:498)
		at org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.fetchLatestOffsets(KafkaOffsetReaderAdmin.scala:297)
		at org.apache.spark.sql.kafka010.KafkaMicroBatchStream.$anonfun$getOrCreateInitialPartitionOffsets$1(KafkaMicroBatchStream.scala:246)
		at scala.Option.getOrElse(Option.scala:189)
		at org.apache.spark.sql.kafka010.KafkaMicroBatchStream.getOrCreateInitialPartitionOffsets(KafkaMicroBatchStream.scala:241)
		at org.apache.spark.sql.kafka010.KafkaMicroBatchStream.initialOffset(KafkaMicroBatchStream.scala:98)
		at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$getStartOffset$2(MicroBatchExecution.scala:457)
		at scala.Option.getOrElse(Option.scala:189)
		at org.apache.spark.sql.execution.streaming.MicroBatchExecution.getStartOffset(MicroBatchExecution.scala:457)
		at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$4(MicroBatchExecution.scala:491)
		at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)
		at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)
		at org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)
		at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$2(MicroBatchExecution.scala:490)
		at scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:286)
		at scala.collection.Iterator.foreach(Iterator.scala:943)
		at scala.collection.Iterator.foreach$(Iterator.scala:943)
		at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
		at scala.collection.IterableLike.foreach(IterableLike.scala:74)
		at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
		at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
		at scala.collection.TraversableLike.map(TraversableLike.scala:286)
		at scala.collection.TraversableLike.map$(TraversableLike.scala:279)
		at scala.collection.AbstractTraversable.map(Traversable.scala:108)
		at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$1(MicroBatchExecution.scala:479)
		at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
		at org.apache.spark.sql.execution.streaming.MicroBatchExecution.withProgressLocked(MicroBatchExecution.scala:810)
		at org.apache.spark.sql.execution.streaming.MicroBatchExecution.constructNextBatch(MicroBatchExecution.scala:475)
		at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:268)
		at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
		at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)
		at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)
		at org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)
		at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)
		at org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)
		at org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)
		at org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)
		at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
		at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
		at org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)
		at org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)
		at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
		at org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)
		at org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)
	Caused by: org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[WI-0][TI-0] - [INFO] 2024-04-27 21:25:04.036 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7530864197530864 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:25:04.249 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/27 21:25:03 ERROR MicroBatchExecution: Query [id = 42501461-b109-43a5-8455-e107f59228ea, runId = 64cce5fd-cbae-43b8-b39e-c76d523ea0f2] terminated with error
	java.util.concurrent.ExecutionException: org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
		at java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:357)
		at java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1908)
		at org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:165)
		at org.apache.spark.sql.kafka010.ConsumerStrategy.retrieveAllPartitions(ConsumerStrategy.scala:66)
		at org.apache.spark.sql.kafka010.ConsumerStrategy.retrieveAllPartitions$(ConsumerStrategy.scala:65)
		at org.apache.spark.sql.kafka010.SubscribeStrategy.retrieveAllPartitions(ConsumerStrategy.scala:102)
		at org.apache.spark.sql.kafka010.SubscribeStrategy.assignedTopicPartitions(ConsumerStrategy.scala:113)
		at org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.$anonfun$partitionsAssignedToAdmin$1(KafkaOffsetReaderAdmin.scala:499)
		at org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.withRetries(KafkaOffsetReaderAdmin.scala:518)
		at org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.partitionsAssignedToAdmin(KafkaOffsetReaderAdmin.scala:498)
		at org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.fetchLatestOffsets(KafkaOffsetReaderAdmin.scala:297)
		at org.apache.spark.sql.kafka010.KafkaMicroBatchStream.$anonfun$getOrCreateInitialPartitionOffsets$1(KafkaMicroBatchStream.scala:246)
		at scala.Option.getOrElse(Option.scala:189)
		at org.apache.spark.sql.kafka010.KafkaMicroBatchStream.getOrCreateInitialPartitionOffsets(KafkaMicroBatchStream.scala:241)
		at org.apache.spark.sql.kafka010.KafkaMicroBatchStream.initialOffset(KafkaMicroBatchStream.scala:98)
		at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$getStartOffset$2(MicroBatchExecution.scala:457)
		at scala.Option.getOrElse(Option.scala:189)
		at org.apache.spark.sql.execution.streaming.MicroBatchExecution.getStartOffset(MicroBatchExecution.scala:457)
		at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$4(MicroBatchExecution.scala:491)
		at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)
		at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)
		at org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)
		at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$2(MicroBatchExecution.scala:490)
		at scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:286)
		at scala.collection.Iterator.foreach(Iterator.scala:943)
		at scala.collection.Iterator.foreach$(Iterator.scala:943)
		at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
		at scala.collection.IterableLike.foreach(IterableLike.scala:74)
		at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
		at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
		at scala.collection.TraversableLike.map(TraversableLike.scala:286)
		at scala.collection.TraversableLike.map$(TraversableLike.scala:279)
		at scala.collection.AbstractTraversable.map(Traversable.scala:108)
		at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$1(MicroBatchExecution.scala:479)
		at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
		at org.apache.spark.sql.execution.streaming.MicroBatchExecution.withProgressLocked(MicroBatchExecution.scala:810)
		at org.apache.spark.sql.execution.streaming.MicroBatchExecution.constructNextBatch(MicroBatchExecution.scala:475)
		at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:268)
		at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
		at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)
		at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)
		at org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)
		at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)
		at org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)
		at org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)
		at org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)
		at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
		at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
		at org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)
		at org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)
		at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
		at org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)
		at org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)
	Caused by: org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
	Traceback (most recent call last):
	  File "/tmp/dolphinscheduler/exec/process/default/13010050770016/13377949373536_19/686/1881/py_686_1881.py", line 71, in <module>
	    kafka_write.awaitTermination()
	  File "/usr/local/lib/python3.11/dist-packages/pyspark/sql/streaming/query.py", line 221, in awaitTermination
	    return self._jsq.awaitTermination()
	           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
	  File "/usr/local/lib/python3.11/dist-packages/py4j/java_gateway.py", line 1322, in __call__
	    return_value = get_return_value(
	                   ^^^^^^^^^^^^^^^^^
	  File "/usr/local/lib/python3.11/dist-packages/pyspark/errors/exceptions/captured.py", line 185, in deco
	    raise converted from None
	pyspark.errors.exceptions.captured.StreamingQueryException: [STREAM_FAILED] Query [id = 42501461-b109-43a5-8455-e107f59228ea, runId = 64cce5fd-cbae-43b8-b39e-c76d523ea0f2] terminated with exception: org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[WI-686][TI-1881] - [INFO] 2024-04-27 21:25:05.260 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13377949373536_19/686/1881, processId:403 ,exitStatusCode:1 ,processWaitForStatus:true ,processExitValue:1
[WI-686][TI-1881] - [INFO] 2024-04-27 21:25:05.262 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-686][TI-1881] - [INFO] 2024-04-27 21:25:05.262 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-686][TI-1881] - [INFO] 2024-04-27 21:25:05.266 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-686][TI-1881] - [INFO] 2024-04-27 21:25:05.269 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-686][TI-1881] - [INFO] 2024-04-27 21:25:05.280 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: FAILURE to master : 172.18.1.1:1234
[WI-686][TI-1881] - [INFO] 2024-04-27 21:25:05.282 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-686][TI-1881] - [INFO] 2024-04-27 21:25:05.283 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13377949373536_19/686/1881
[WI-686][TI-1881] - [INFO] 2024-04-27 21:25:05.288 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13377949373536_19/686/1881
[WI-686][TI-1881] - [INFO] 2024-04-27 21:25:05.292 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-1881] - [INFO] 2024-04-27 21:25:05.415 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1881, success=true)
[WI-0][TI-0] - [INFO] 2024-04-27 21:25:05.510 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1882, taskName=keyword filtering, firstSubmitTime=1714224305489, startTime=0, taskType=PYTHON, workflowInstanceHost=172.18.0.9:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13377949373536, processDefineVersion=19, appIds=null, processInstanceId=686, scheduleTime=0, globalParams=[{"prop":"keywords","direct":"IN","type":"VARCHAR","value":"\"singapore\", \"lol\""}], executorId=1, cmdTypeIfComplement=7, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[],"rawScript":"from pyspark.sql import SparkSession\nfrom pyspark.sql.functions import col, from_json\nfrom pyspark.sql.types import StringType, StructType, StructField, IntegerType\n\nspark = SparkSession.builder \\\n    .master(\"local\") \\\n    .appName(\"Reddit Keyword Filtering\") \\\n    .config(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1\") \\\n    .config(\"spark.sql.streaming.checkpointLocation\", r\"/tmp/\") \\\n    .config(\"spark.driver.extraJavaOptions\", \"-Divy.cache.dir=/tmp -Divy.home=/tmp\") \\\n    .getOrCreate()\n\n# define the schema for the JSON data\nschema = StructType([\n    StructField(\"user\", StringType(), nullable=True),\n    StructField(\"content\", StringType(), nullable=True),\n    StructField(\"url\", StringType(), nullable=True),\n    StructField(\"context\", StringType(), nullable=True),\n    StructField(\"score\", IntegerType(), nullable=True),\n    StructField(\"subreddit\", StringType(), nullable=True),\n    StructField(\"type\", StringType(), nullable=True),\n    StructField(\"id\", StringType(), nullable=True),\n    StructField(\"datetime\", StringType(), nullable=True)  # Assuming the datetime is string type, you can change it to TimestampType if needed\n])\n\n# define the parameters for the input and output kafka broker and topic\nkafka_broker = \"kafka:9092\"\ninput_kafka_topic = \"reddit_post_preprocessed\"\noutput_kafka_topic = \"reddit_post_filtered\"\n\n# Subscribe to the input topic\ndf = spark \\\n    .readStream \\\n    .format(\"kafka\") \\\n    .option(\"kafka.bootstrap.servers\", kafka_broker) \\\n    .option(\"subscribe\", input_kafka_topic) \\\n    .load()\n\n# parse the JSON data in the 'value' column using the defined schema then create a dataframe containing the reddit data\ndf = df.select(col(\"value\").cast(\"string\")) \\\n    .withColumn(\"value\", from_json(\"value\", schema)) \\\n\nparsed_df = df \\\n    .select(\"value.*\")\n\n# filter rows containing specific keywords\nkeywords = ['singapore', 'sg']\n\n# initialize the filter condition with False\nfilter_condition = col(\"content\").contains(keywords[0])\n\n# loop through the rest of the keywords and update the filter condition\nfor keyword in keywords[1:]:\n    filter_condition = filter_condition | col(\"content\").contains(keyword)\n\n# apply the filter condition to the DataFrame\nfiltered_df = parsed_df.filter(filter_condition)\n\n# stream the data to kafka\nkafka_write = filtered_df \\\n    .selectExpr(\"'' AS key\", \"to_json(struct(*)) AS value\") \\\n    .writeStream \\\n    .format(\"kafka\") \\\n    .option(\"kafka.bootstrap.servers\", kafka_broker) \\\n    .option(\"topic\", output_kafka_topic) \\\n    .start()\n\n# Wait for the termination of the query\nkafka_write.awaitTermination()\n","resourceList":[]}, environmentConfig=export HADOOP_HOME=/opt/hadoop-3.4.0
export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export PYSPARK_DRIVER_PYTHON=/bin/python3.11
export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='keyword filtering'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, keywords=Property{prop='keywords', direct=IN, type=VARCHAR, value='"singapore", "lol"'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240427'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1882'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13377752024032'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240427212505'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='686'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240426'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='filter_data'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13377949373536'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-686][TI-1882] - [INFO] 2024-04-27 21:25:05.513 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: keyword filtering to wait queue success
[WI-686][TI-1882] - [INFO] 2024-04-27 21:25:05.513 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-686][TI-1882] - [INFO] 2024-04-27 21:25:05.517 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-686][TI-1882] - [INFO] 2024-04-27 21:25:05.518 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-686][TI-1882] - [INFO] 2024-04-27 21:25:05.519 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-686][TI-1882] - [INFO] 2024-04-27 21:25:05.519 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1714224305519
[WI-686][TI-1882] - [INFO] 2024-04-27 21:25:05.521 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 686_1882
[WI-686][TI-1882] - [INFO] 2024-04-27 21:25:05.523 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1882,
  "taskName" : "keyword filtering",
  "firstSubmitTime" : 1714224305489,
  "startTime" : 1714224305519,
  "taskType" : "PYTHON",
  "workflowInstanceHost" : "172.18.0.9:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240427/13377949373536/19/686/1882.log",
  "processId" : 0,
  "processDefineCode" : 13377949373536,
  "processDefineVersion" : 19,
  "processInstanceId" : 686,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"keywords\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"\\\"singapore\\\", \\\"lol\\\"\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 7,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[],\"rawScript\":\"from pyspark.sql import SparkSession\\nfrom pyspark.sql.functions import col, from_json\\nfrom pyspark.sql.types import StringType, StructType, StructField, IntegerType\\n\\nspark = SparkSession.builder \\\\\\n    .master(\\\"local\\\") \\\\\\n    .appName(\\\"Reddit Keyword Filtering\\\") \\\\\\n    .config(\\\"spark.jars.packages\\\", \\\"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1\\\") \\\\\\n    .config(\\\"spark.sql.streaming.checkpointLocation\\\", r\\\"/tmp/\\\") \\\\\\n    .config(\\\"spark.driver.extraJavaOptions\\\", \\\"-Divy.cache.dir=/tmp -Divy.home=/tmp\\\") \\\\\\n    .getOrCreate()\\n\\n# define the schema for the JSON data\\nschema = StructType([\\n    StructField(\\\"user\\\", StringType(), nullable=True),\\n    StructField(\\\"content\\\", StringType(), nullable=True),\\n    StructField(\\\"url\\\", StringType(), nullable=True),\\n    StructField(\\\"context\\\", StringType(), nullable=True),\\n    StructField(\\\"score\\\", IntegerType(), nullable=True),\\n    StructField(\\\"subreddit\\\", StringType(), nullable=True),\\n    StructField(\\\"type\\\", StringType(), nullable=True),\\n    StructField(\\\"id\\\", StringType(), nullable=True),\\n    StructField(\\\"datetime\\\", StringType(), nullable=True)  # Assuming the datetime is string type, you can change it to TimestampType if needed\\n])\\n\\n# define the parameters for the input and output kafka broker and topic\\nkafka_broker = \\\"kafka:9092\\\"\\ninput_kafka_topic = \\\"reddit_post_preprocessed\\\"\\noutput_kafka_topic = \\\"reddit_post_filtered\\\"\\n\\n# Subscribe to the input topic\\ndf = spark \\\\\\n    .readStream \\\\\\n    .format(\\\"kafka\\\") \\\\\\n    .option(\\\"kafka.bootstrap.servers\\\", kafka_broker) \\\\\\n    .option(\\\"subscribe\\\", input_kafka_topic) \\\\\\n    .load()\\n\\n# parse the JSON data in the 'value' column using the defined schema then create a dataframe containing the reddit data\\ndf = df.select(col(\\\"value\\\").cast(\\\"string\\\")) \\\\\\n    .withColumn(\\\"value\\\", from_json(\\\"value\\\", schema)) \\\\\\n\\nparsed_df = df \\\\\\n    .select(\\\"value.*\\\")\\n\\n# filter rows containing specific keywords\\nkeywords = ['singapore', 'sg']\\n\\n# initialize the filter condition with False\\nfilter_condition = col(\\\"content\\\").contains(keywords[0])\\n\\n# loop through the rest of the keywords and update the filter condition\\nfor keyword in keywords[1:]:\\n    filter_condition = filter_condition | col(\\\"content\\\").contains(keyword)\\n\\n# apply the filter condition to the DataFrame\\nfiltered_df = parsed_df.filter(filter_condition)\\n\\n# stream the data to kafka\\nkafka_write = filtered_df \\\\\\n    .selectExpr(\\\"'' AS key\\\", \\\"to_json(struct(*)) AS value\\\") \\\\\\n    .writeStream \\\\\\n    .format(\\\"kafka\\\") \\\\\\n    .option(\\\"kafka.bootstrap.servers\\\", kafka_broker) \\\\\\n    .option(\\\"topic\\\", output_kafka_topic) \\\\\\n    .start()\\n\\n# Wait for the termination of the query\\nkafka_write.awaitTermination()\\n\",\"resourceList\":[]}",
  "environmentConfig" : "export HADOOP_HOME=/opt/hadoop-3.4.0\nexport SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3\nexport JAVA_HOME=/opt/java/openjdk\nexport PYSPARK_DRIVER_PYTHON=/bin/python3.11\nexport PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "keyword filtering"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "keywords" : {
      "prop" : "keywords",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "\"singapore\", \"lol\""
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240427"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1882"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13377752024032"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240427212505"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "686"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240426"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "filter_data"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13377949373536"
    }
  },
  "taskAppId" : "686_1882",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "varPool" : "[]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-686][TI-1882] - [INFO] 2024-04-27 21:25:05.525 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-686][TI-1882] - [INFO] 2024-04-27 21:25:05.525 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-686][TI-1882] - [INFO] 2024-04-27 21:25:05.525 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-686][TI-1882] - [INFO] 2024-04-27 21:25:05.533 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-686][TI-1882] - [INFO] 2024-04-27 21:25:05.536 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-686][TI-1882] - [INFO] 2024-04-27 21:25:05.538 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13377949373536_19/686/1882 check successfully
[WI-686][TI-1882] - [INFO] 2024-04-27 21:25:05.539 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.python.PythonTaskChannel successfully
[WI-686][TI-1882] - [INFO] 2024-04-27 21:25:05.540 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-686][TI-1882] - [INFO] 2024-04-27 21:25:05.541 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-686][TI-1882] - [INFO] 2024-04-27 21:25:05.541 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: PYTHON create successfully
[WI-686][TI-1882] - [INFO] 2024-04-27 21:25:05.544 +0800 o.a.d.p.t.p.PythonTask:[75] - Initialize python task params {
  "localParams" : [ ],
  "varPool" : null,
  "rawScript" : "from pyspark.sql import SparkSession\nfrom pyspark.sql.functions import col, from_json\nfrom pyspark.sql.types import StringType, StructType, StructField, IntegerType\n\nspark = SparkSession.builder \\\n    .master(\"local\") \\\n    .appName(\"Reddit Keyword Filtering\") \\\n    .config(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1\") \\\n    .config(\"spark.sql.streaming.checkpointLocation\", r\"/tmp/\") \\\n    .config(\"spark.driver.extraJavaOptions\", \"-Divy.cache.dir=/tmp -Divy.home=/tmp\") \\\n    .getOrCreate()\n\n# define the schema for the JSON data\nschema = StructType([\n    StructField(\"user\", StringType(), nullable=True),\n    StructField(\"content\", StringType(), nullable=True),\n    StructField(\"url\", StringType(), nullable=True),\n    StructField(\"context\", StringType(), nullable=True),\n    StructField(\"score\", IntegerType(), nullable=True),\n    StructField(\"subreddit\", StringType(), nullable=True),\n    StructField(\"type\", StringType(), nullable=True),\n    StructField(\"id\", StringType(), nullable=True),\n    StructField(\"datetime\", StringType(), nullable=True)  # Assuming the datetime is string type, you can change it to TimestampType if needed\n])\n\n# define the parameters for the input and output kafka broker and topic\nkafka_broker = \"kafka:9092\"\ninput_kafka_topic = \"reddit_post_preprocessed\"\noutput_kafka_topic = \"reddit_post_filtered\"\n\n# Subscribe to the input topic\ndf = spark \\\n    .readStream \\\n    .format(\"kafka\") \\\n    .option(\"kafka.bootstrap.servers\", kafka_broker) \\\n    .option(\"subscribe\", input_kafka_topic) \\\n    .load()\n\n# parse the JSON data in the 'value' column using the defined schema then create a dataframe containing the reddit data\ndf = df.select(col(\"value\").cast(\"string\")) \\\n    .withColumn(\"value\", from_json(\"value\", schema)) \\\n\nparsed_df = df \\\n    .select(\"value.*\")\n\n# filter rows containing specific keywords\nkeywords = ['singapore', 'sg']\n\n# initialize the filter condition with False\nfilter_condition = col(\"content\").contains(keywords[0])\n\n# loop through the rest of the keywords and update the filter condition\nfor keyword in keywords[1:]:\n    filter_condition = filter_condition | col(\"content\").contains(keyword)\n\n# apply the filter condition to the DataFrame\nfiltered_df = parsed_df.filter(filter_condition)\n\n# stream the data to kafka\nkafka_write = filtered_df \\\n    .selectExpr(\"'' AS key\", \"to_json(struct(*)) AS value\") \\\n    .writeStream \\\n    .format(\"kafka\") \\\n    .option(\"kafka.bootstrap.servers\", kafka_broker) \\\n    .option(\"topic\", output_kafka_topic) \\\n    .start()\n\n# Wait for the termination of the query\nkafka_write.awaitTermination()\n",
  "resourceList" : [ ]
}
[WI-686][TI-1882] - [INFO] 2024-04-27 21:25:05.545 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-686][TI-1882] - [INFO] 2024-04-27 21:25:05.545 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [] successfully
[WI-686][TI-1882] - [INFO] 2024-04-27 21:25:05.546 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-686][TI-1882] - [INFO] 2024-04-27 21:25:05.546 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-686][TI-1882] - [INFO] 2024-04-27 21:25:05.547 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-686][TI-1882] - [INFO] 2024-04-27 21:25:05.547 +0800 o.a.d.p.t.p.PythonTask:[165] - raw python script : from pyspark.sql import SparkSession
from pyspark.sql.functions import col, from_json
from pyspark.sql.types import StringType, StructType, StructField, IntegerType

spark = SparkSession.builder \
    .master("local") \
    .appName("Reddit Keyword Filtering") \
    .config("spark.jars.packages", "org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1") \
    .config("spark.sql.streaming.checkpointLocation", r"/tmp/") \
    .config("spark.driver.extraJavaOptions", "-Divy.cache.dir=/tmp -Divy.home=/tmp") \
    .getOrCreate()

# define the schema for the JSON data
schema = StructType([
    StructField("user", StringType(), nullable=True),
    StructField("content", StringType(), nullable=True),
    StructField("url", StringType(), nullable=True),
    StructField("context", StringType(), nullable=True),
    StructField("score", IntegerType(), nullable=True),
    StructField("subreddit", StringType(), nullable=True),
    StructField("type", StringType(), nullable=True),
    StructField("id", StringType(), nullable=True),
    StructField("datetime", StringType(), nullable=True)  # Assuming the datetime is string type, you can change it to TimestampType if needed
])

# define the parameters for the input and output kafka broker and topic
kafka_broker = "kafka:9092"
input_kafka_topic = "reddit_post_preprocessed"
output_kafka_topic = "reddit_post_filtered"

# Subscribe to the input topic
df = spark \
    .readStream \
    .format("kafka") \
    .option("kafka.bootstrap.servers", kafka_broker) \
    .option("subscribe", input_kafka_topic) \
    .load()

# parse the JSON data in the 'value' column using the defined schema then create a dataframe containing the reddit data
df = df.select(col("value").cast("string")) \
    .withColumn("value", from_json("value", schema)) \

parsed_df = df \
    .select("value.*")

# filter rows containing specific keywords
keywords = ['singapore', 'sg']

# initialize the filter condition with False
filter_condition = col("content").contains(keywords[0])

# loop through the rest of the keywords and update the filter condition
for keyword in keywords[1:]:
    filter_condition = filter_condition | col("content").contains(keyword)

# apply the filter condition to the DataFrame
filtered_df = parsed_df.filter(filter_condition)

# stream the data to kafka
kafka_write = filtered_df \
    .selectExpr("'' AS key", "to_json(struct(*)) AS value") \
    .writeStream \
    .format("kafka") \
    .option("kafka.bootstrap.servers", kafka_broker) \
    .option("topic", output_kafka_topic) \
    .start()

# Wait for the termination of the query
kafka_write.awaitTermination()

[WI-686][TI-1882] - [INFO] 2024-04-27 21:25:05.549 +0800 o.a.d.p.t.p.PythonTask:[131] - tenantCode :default, task dir:/tmp/dolphinscheduler/exec/process/default/13010050770016/13377949373536_19/686/1882
[WI-686][TI-1882] - [INFO] 2024-04-27 21:25:05.550 +0800 o.a.d.p.t.p.PythonTask:[134] - generate python script file:/tmp/dolphinscheduler/exec/process/default/13010050770016/13377949373536_19/686/1882/py_686_1882.py
[WI-686][TI-1882] - [INFO] 2024-04-27 21:25:05.550 +0800 o.a.d.p.t.p.PythonTask:[141] - #-*- encoding=utf8 -*-

from pyspark.sql import SparkSession
from pyspark.sql.functions import col, from_json
from pyspark.sql.types import StringType, StructType, StructField, IntegerType

spark = SparkSession.builder \
    .master("local") \
    .appName("Reddit Keyword Filtering") \
    .config("spark.jars.packages", "org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1") \
    .config("spark.sql.streaming.checkpointLocation", r"/tmp/") \
    .config("spark.driver.extraJavaOptions", "-Divy.cache.dir=/tmp -Divy.home=/tmp") \
    .getOrCreate()

# define the schema for the JSON data
schema = StructType([
    StructField("user", StringType(), nullable=True),
    StructField("content", StringType(), nullable=True),
    StructField("url", StringType(), nullable=True),
    StructField("context", StringType(), nullable=True),
    StructField("score", IntegerType(), nullable=True),
    StructField("subreddit", StringType(), nullable=True),
    StructField("type", StringType(), nullable=True),
    StructField("id", StringType(), nullable=True),
    StructField("datetime", StringType(), nullable=True)  # Assuming the datetime is string type, you can change it to TimestampType if needed
])

# define the parameters for the input and output kafka broker and topic
kafka_broker = "kafka:9092"
input_kafka_topic = "reddit_post_preprocessed"
output_kafka_topic = "reddit_post_filtered"

# Subscribe to the input topic
df = spark \
    .readStream \
    .format("kafka") \
    .option("kafka.bootstrap.servers", kafka_broker) \
    .option("subscribe", input_kafka_topic) \
    .load()

# parse the JSON data in the 'value' column using the defined schema then create a dataframe containing the reddit data
df = df.select(col("value").cast("string")) \
    .withColumn("value", from_json("value", schema)) \

parsed_df = df \
    .select("value.*")

# filter rows containing specific keywords
keywords = ['singapore', 'sg']

# initialize the filter condition with False
filter_condition = col("content").contains(keywords[0])

# loop through the rest of the keywords and update the filter condition
for keyword in keywords[1:]:
    filter_condition = filter_condition | col("content").contains(keyword)

# apply the filter condition to the DataFrame
filtered_df = parsed_df.filter(filter_condition)

# stream the data to kafka
kafka_write = filtered_df \
    .selectExpr("'' AS key", "to_json(struct(*)) AS value") \
    .writeStream \
    .format("kafka") \
    .option("kafka.bootstrap.servers", kafka_broker) \
    .option("topic", output_kafka_topic) \
    .start()

# Wait for the termination of the query
kafka_write.awaitTermination()

[WI-686][TI-1882] - [INFO] 2024-04-27 21:25:05.553 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-686][TI-1882] - [INFO] 2024-04-27 21:25:05.553 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-686][TI-1882] - [INFO] 2024-04-27 21:25:05.556 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export HADOOP_HOME=/opt/hadoop-3.4.0
export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export PYSPARK_DRIVER_PYTHON=/bin/python3.11
export PYTHON_LAUNCHER=/bin/python3.11
${PYTHON_LAUNCHER} /tmp/dolphinscheduler/exec/process/default/13010050770016/13377949373536_19/686/1882/py_686_1882.py
[WI-686][TI-1882] - [INFO] 2024-04-27 21:25:05.557 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-686][TI-1882] - [INFO] 2024-04-27 21:25:05.558 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13377949373536_19/686/1882/686_1882.sh
[WI-686][TI-1882] - [INFO] 2024-04-27 21:25:05.562 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 626
[WI-0][TI-1882] - [INFO] 2024-04-27 21:25:06.424 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1882, success=true)
[WI-0][TI-1882] - [INFO] 2024-04-27 21:25:06.438 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1882)
[WI-0][TI-0] - [INFO] 2024-04-27 21:25:06.566 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
[WI-0][TI-0] - [INFO] 2024-04-27 21:25:08.600 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	:: loading settings :: url = jar:file:/opt/spark-3.5.1-bin-hadoop3/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml
	Ivy Default Cache set to: /tmp
	The jars for the packages stored in: /tmp/jars
	org.apache.spark#spark-sql-kafka-0-10_2.12 added as a dependency
	:: resolving dependencies :: org.apache.spark#spark-submit-parent-79a7f1cc-e576-4bb9-8a4a-fed46a07b6c1;1.0
		confs: [default]
[WI-0][TI-0] - [INFO] 2024-04-27 21:25:09.101 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7147147147147148 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:25:09.605 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
		found org.apache.spark#spark-sql-kafka-0-10_2.12;3.5.1 in central
		found org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.5.1 in central
		found org.apache.kafka#kafka-clients;3.4.1 in central
		found org.lz4#lz4-java;1.8.0 in central
		found org.xerial.snappy#snappy-java;1.1.10.3 in central
		found org.slf4j#slf4j-api;2.0.7 in central
		found org.apache.hadoop#hadoop-client-runtime;3.3.4 in central
		found org.apache.hadoop#hadoop-client-api;3.3.4 in central
		found commons-logging#commons-logging;1.1.3 in central
		found com.google.code.findbugs#jsr305;3.0.0 in central
		found org.apache.commons#commons-pool2;2.11.1 in central
[WI-0][TI-0] - [INFO] 2024-04-27 21:25:10.142 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8481481481481481 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:25:10.610 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	:: resolution report :: resolve 971ms :: artifacts dl 93ms
		:: modules in use:
		com.google.code.findbugs#jsr305;3.0.0 from central in [default]
		commons-logging#commons-logging;1.1.3 from central in [default]
		org.apache.commons#commons-pool2;2.11.1 from central in [default]
		org.apache.hadoop#hadoop-client-api;3.3.4 from central in [default]
		org.apache.hadoop#hadoop-client-runtime;3.3.4 from central in [default]
		org.apache.kafka#kafka-clients;3.4.1 from central in [default]
		org.apache.spark#spark-sql-kafka-0-10_2.12;3.5.1 from central in [default]
		org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.5.1 from central in [default]
		org.lz4#lz4-java;1.8.0 from central in [default]
		org.slf4j#slf4j-api;2.0.7 from central in [default]
		org.xerial.snappy#snappy-java;1.1.10.3 from central in [default]
		---------------------------------------------------------------------
		|                  |            modules            ||   artifacts   |
		|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
		---------------------------------------------------------------------
		|      default     |   11  |   0   |   0   |   0   ||   11  |   0   |
		---------------------------------------------------------------------
	:: retrieving :: org.apache.spark#spark-submit-parent-79a7f1cc-e576-4bb9-8a4a-fed46a07b6c1
		confs: [default]
		0 artifacts copied, 11 already retrieved (0kB/23ms)
[WI-0][TI-0] - [INFO] 2024-04-27 21:25:11.144 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7967741935483871 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:25:11.611 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/27 21:25:10 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
	Setting default log level to "WARN".
	To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[WI-0][TI-0] - [INFO] 2024-04-27 21:25:13.158 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7373737373737373 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:25:14.195 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8555133079847909 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:25:20.273 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9028210453444098 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:25:22.443 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7508416335817604 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:25:22.653 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/27 21:25:22 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.
[WI-0][TI-0] - [INFO] 2024-04-27 21:25:24.661 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/27 21:25:23 WARN AdminClientConfig: These configurations '[key.deserializer, value.deserializer, enable.auto.commit, max.poll.records, auto.offset.reset]' were supplied but are not used yet.
[WI-0][TI-0] - [INFO] 2024-04-27 21:25:25.662 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/27 21:25:24 WARN KafkaOffsetReaderAdmin: Error in attempt 1 getting Kafka offsets: 
	java.util.concurrent.ExecutionException: org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
		at java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:357)
		at java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1908)
		at org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:165)
		at org.apache.spark.sql.kafka010.ConsumerStrategy.retrieveAllPartitions(ConsumerStrategy.scala:66)
		at org.apache.spark.sql.kafka010.ConsumerStrategy.retrieveAllPartitions$(ConsumerStrategy.scala:65)
		at org.apache.spark.sql.kafka010.SubscribeStrategy.retrieveAllPartitions(ConsumerStrategy.scala:102)
		at org.apache.spark.sql.kafka010.SubscribeStrategy.assignedTopicPartitions(ConsumerStrategy.scala:113)
		at org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.$anonfun$partitionsAssignedToAdmin$1(KafkaOffsetReaderAdmin.scala:499)
		at org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.withRetries(KafkaOffsetReaderAdmin.scala:518)
		at org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.partitionsAssignedToAdmin(KafkaOffsetReaderAdmin.scala:498)
		at org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.fetchLatestOffsets(KafkaOffsetReaderAdmin.scala:297)
		at org.apache.spark.sql.kafka010.KafkaMicroBatchStream.$anonfun$getOrCreateInitialPartitionOffsets$1(KafkaMicroBatchStream.scala:246)
		at scala.Option.getOrElse(Option.scala:189)
		at org.apache.spark.sql.kafka010.KafkaMicroBatchStream.getOrCreateInitialPartitionOffsets(KafkaMicroBatchStream.scala:241)
		at org.apache.spark.sql.kafka010.KafkaMicroBatchStream.initialOffset(KafkaMicroBatchStream.scala:98)
		at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$getStartOffset$2(MicroBatchExecution.scala:457)
		at scala.Option.getOrElse(Option.scala:189)
		at org.apache.spark.sql.execution.streaming.MicroBatchExecution.getStartOffset(MicroBatchExecution.scala:457)
		at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$4(MicroBatchExecution.scala:491)
		at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)
		at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)
		at org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)
		at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$2(MicroBatchExecution.scala:490)
		at scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:286)
		at scala.collection.Iterator.foreach(Iterator.scala:943)
		at scala.collection.Iterator.foreach$(Iterator.scala:943)
		at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
		at scala.collection.IterableLike.foreach(IterableLike.scala:74)
		at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
		at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
		at scala.collection.TraversableLike.map(TraversableLike.scala:286)
		at scala.collection.TraversableLike.map$(TraversableLike.scala:279)
		at scala.collection.AbstractTraversable.map(Traversable.scala:108)
		at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$1(MicroBatchExecution.scala:479)
		at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
		at org.apache.spark.sql.execution.streaming.MicroBatchExecution.withProgressLocked(MicroBatchExecution.scala:810)
		at org.apache.spark.sql.execution.streaming.MicroBatchExecution.constructNextBatch(MicroBatchExecution.scala:475)
		at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:268)
		at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
		at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)
		at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)
		at org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)
		at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)
		at org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)
		at org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)
		at org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)
		at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
		at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
		at org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)
		at org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)
		at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
		at org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)
		at org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)
	Caused by: org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[WI-0][TI-0] - [INFO] 2024-04-27 21:25:26.665 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/27 21:25:25 WARN AdminClientConfig: These configurations '[key.deserializer, value.deserializer, enable.auto.commit, max.poll.records, auto.offset.reset]' were supplied but are not used yet.
	24/04/27 21:25:25 WARN KafkaOffsetReaderAdmin: Error in attempt 2 getting Kafka offsets: 
	java.util.concurrent.ExecutionException: org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
		at java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:357)
		at java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1908)
		at org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:165)
		at org.apache.spark.sql.kafka010.ConsumerStrategy.retrieveAllPartitions(ConsumerStrategy.scala:66)
		at org.apache.spark.sql.kafka010.ConsumerStrategy.retrieveAllPartitions$(ConsumerStrategy.scala:65)
		at org.apache.spark.sql.kafka010.SubscribeStrategy.retrieveAllPartitions(ConsumerStrategy.scala:102)
		at org.apache.spark.sql.kafka010.SubscribeStrategy.assignedTopicPartitions(ConsumerStrategy.scala:113)
		at org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.$anonfun$partitionsAssignedToAdmin$1(KafkaOffsetReaderAdmin.scala:499)
		at org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.withRetries(KafkaOffsetReaderAdmin.scala:518)
		at org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.partitionsAssignedToAdmin(KafkaOffsetReaderAdmin.scala:498)
		at org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.fetchLatestOffsets(KafkaOffsetReaderAdmin.scala:297)
		at org.apache.spark.sql.kafka010.KafkaMicroBatchStream.$anonfun$getOrCreateInitialPartitionOffsets$1(KafkaMicroBatchStream.scala:246)
		at scala.Option.getOrElse(Option.scala:189)
		at org.apache.spark.sql.kafka010.KafkaMicroBatchStream.getOrCreateInitialPartitionOffsets(KafkaMicroBatchStream.scala:241)
		at org.apache.spark.sql.kafka010.KafkaMicroBatchStream.initialOffset(KafkaMicroBatchStream.scala:98)
		at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$getStartOffset$2(MicroBatchExecution.scala:457)
		at scala.Option.getOrElse(Option.scala:189)
		at org.apache.spark.sql.execution.streaming.MicroBatchExecution.getStartOffset(MicroBatchExecution.scala:457)
		at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$4(MicroBatchExecution.scala:491)
		at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)
		at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)
		at org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)
		at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$2(MicroBatchExecution.scala:490)
		at scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:286)
		at scala.collection.Iterator.foreach(Iterator.scala:943)
		at scala.collection.Iterator.foreach$(Iterator.scala:943)
		at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
		at scala.collection.IterableLike.foreach(IterableLike.scala:74)
		at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
		at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
		at scala.collection.TraversableLike.map(TraversableLike.scala:286)
		at scala.collection.TraversableLike.map$(TraversableLike.scala:279)
		at scala.collection.AbstractTraversable.map(Traversable.scala:108)
		at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$1(MicroBatchExecution.scala:479)
		at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
		at org.apache.spark.sql.execution.streaming.MicroBatchExecution.withProgressLocked(MicroBatchExecution.scala:810)
		at org.apache.spark.sql.execution.streaming.MicroBatchExecution.constructNextBatch(MicroBatchExecution.scala:475)
		at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:268)
		at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
		at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)
		at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)
		at org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)
		at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)
		at org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)
		at org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)
		at org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)
		at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
		at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
		at org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)
		at org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)
		at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
		at org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)
		at org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)
	Caused by: org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[WI-0][TI-0] - [INFO] 2024-04-27 21:25:27.675 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/27 21:25:27 WARN AdminClientConfig: These configurations '[key.deserializer, value.deserializer, enable.auto.commit, max.poll.records, auto.offset.reset]' were supplied but are not used yet.
	24/04/27 21:25:27 WARN KafkaOffsetReaderAdmin: Error in attempt 3 getting Kafka offsets: 
	java.util.concurrent.ExecutionException: org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
		at java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:357)
		at java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1908)
		at org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:165)
		at org.apache.spark.sql.kafka010.ConsumerStrategy.retrieveAllPartitions(ConsumerStrategy.scala:66)
		at org.apache.spark.sql.kafka010.ConsumerStrategy.retrieveAllPartitions$(ConsumerStrategy.scala:65)
		at org.apache.spark.sql.kafka010.SubscribeStrategy.retrieveAllPartitions(ConsumerStrategy.scala:102)
		at org.apache.spark.sql.kafka010.SubscribeStrategy.assignedTopicPartitions(ConsumerStrategy.scala:113)
		at org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.$anonfun$partitionsAssignedToAdmin$1(KafkaOffsetReaderAdmin.scala:499)
		at org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.withRetries(KafkaOffsetReaderAdmin.scala:518)
		at org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.partitionsAssignedToAdmin(KafkaOffsetReaderAdmin.scala:498)
		at org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.fetchLatestOffsets(KafkaOffsetReaderAdmin.scala:297)
		at org.apache.spark.sql.kafka010.KafkaMicroBatchStream.$anonfun$getOrCreateInitialPartitionOffsets$1(KafkaMicroBatchStream.scala:246)
		at scala.Option.getOrElse(Option.scala:189)
		at org.apache.spark.sql.kafka010.KafkaMicroBatchStream.getOrCreateInitialPartitionOffsets(KafkaMicroBatchStream.scala:241)
		at org.apache.spark.sql.kafka010.KafkaMicroBatchStream.initialOffset(KafkaMicroBatchStream.scala:98)
		at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$getStartOffset$2(MicroBatchExecution.scala:457)
		at scala.Option.getOrElse(Option.scala:189)
		at org.apache.spark.sql.execution.streaming.MicroBatchExecution.getStartOffset(MicroBatchExecution.scala:457)
		at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$4(MicroBatchExecution.scala:491)
		at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)
		at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)
		at org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)
		at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$2(MicroBatchExecution.scala:490)
		at scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:286)
		at scala.collection.Iterator.foreach(Iterator.scala:943)
		at scala.collection.Iterator.foreach$(Iterator.scala:943)
		at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
		at scala.collection.IterableLike.foreach(IterableLike.scala:74)
		at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
		at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
		at scala.collection.TraversableLike.map(TraversableLike.scala:286)
		at scala.collection.TraversableLike.map$(TraversableLike.scala:279)
		at scala.collection.AbstractTraversable.map(Traversable.scala:108)
		at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$1(MicroBatchExecution.scala:479)
		at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
		at org.apache.spark.sql.execution.streaming.MicroBatchExecution.withProgressLocked(MicroBatchExecution.scala:810)
		at org.apache.spark.sql.execution.streaming.MicroBatchExecution.constructNextBatch(MicroBatchExecution.scala:475)
		at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:268)
		at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
		at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)
		at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)
		at org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)
		at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)
		at org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)
		at org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)
		at org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)
		at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
		at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
		at org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)
		at org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)
		at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
		at org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)
		at org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)
	Caused by: org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[WI-0][TI-0] - [INFO] 2024-04-27 21:25:28.678 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/27 21:25:28 ERROR MicroBatchExecution: Query [id = 96174c41-2a64-445c-831d-cba2d3a51e73, runId = ed755fd9-ac3c-4f89-bab1-0214df27b6f4] terminated with error
	java.util.concurrent.ExecutionException: org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
		at java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:357)
		at java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1908)
		at org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:165)
		at org.apache.spark.sql.kafka010.ConsumerStrategy.retrieveAllPartitions(ConsumerStrategy.scala:66)
		at org.apache.spark.sql.kafka010.ConsumerStrategy.retrieveAllPartitions$(ConsumerStrategy.scala:65)
		at org.apache.spark.sql.kafka010.SubscribeStrategy.retrieveAllPartitions(ConsumerStrategy.scala:102)
		at org.apache.spark.sql.kafka010.SubscribeStrategy.assignedTopicPartitions(ConsumerStrategy.scala:113)
		at org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.$anonfun$partitionsAssignedToAdmin$1(KafkaOffsetReaderAdmin.scala:499)
		at org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.withRetries(KafkaOffsetReaderAdmin.scala:518)
		at org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.partitionsAssignedToAdmin(KafkaOffsetReaderAdmin.scala:498)
		at org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.fetchLatestOffsets(KafkaOffsetReaderAdmin.scala:297)
		at org.apache.spark.sql.kafka010.KafkaMicroBatchStream.$anonfun$getOrCreateInitialPartitionOffsets$1(KafkaMicroBatchStream.scala:246)
		at scala.Option.getOrElse(Option.scala:189)
		at org.apache.spark.sql.kafka010.KafkaMicroBatchStream.getOrCreateInitialPartitionOffsets(KafkaMicroBatchStream.scala:241)
		at org.apache.spark.sql.kafka010.KafkaMicroBatchStream.initialOffset(KafkaMicroBatchStream.scala:98)
		at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$getStartOffset$2(MicroBatchExecution.scala:457)
		at scala.Option.getOrElse(Option.scala:189)
		at org.apache.spark.sql.execution.streaming.MicroBatchExecution.getStartOffset(MicroBatchExecution.scala:457)
		at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$4(MicroBatchExecution.scala:491)
		at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)
		at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)
		at org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)
		at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$2(MicroBatchExecution.scala:490)
		at scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:286)
		at scala.collection.Iterator.foreach(Iterator.scala:943)
		at scala.collection.Iterator.foreach$(Iterator.scala:943)
		at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
		at scala.collection.IterableLike.foreach(IterableLike.scala:74)
		at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
		at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
		at scala.collection.TraversableLike.map(TraversableLike.scala:286)
		at scala.collection.TraversableLike.map$(TraversableLike.scala:279)
		at scala.collection.AbstractTraversable.map(Traversable.scala:108)
		at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$1(MicroBatchExecution.scala:479)
		at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
		at org.apache.spark.sql.execution.streaming.MicroBatchExecution.withProgressLocked(MicroBatchExecution.scala:810)
		at org.apache.spark.sql.execution.streaming.MicroBatchExecution.constructNextBatch(MicroBatchExecution.scala:475)
		at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:268)
		at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
		at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)
		at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)
		at org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)
		at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)
		at org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)
		at org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)
		at org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)
		at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
		at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
		at org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)
		at org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)
		at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
		at org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)
		at org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)
	Caused by: org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
	Traceback (most recent call last):
	  File "/tmp/dolphinscheduler/exec/process/default/13010050770016/13377949373536_19/686/1882/py_686_1882.py", line 71, in <module>
	    kafka_write.awaitTermination()
	  File "/usr/local/lib/python3.11/dist-packages/pyspark/sql/streaming/query.py", line 221, in awaitTermination
	    return self._jsq.awaitTermination()
	           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
	  File "/usr/local/lib/python3.11/dist-packages/py4j/java_gateway.py", line 1322, in __call__
	    return_value = get_return_value(
	                   ^^^^^^^^^^^^^^^^^
	  File "/usr/local/lib/python3.11/dist-packages/pyspark/errors/exceptions/captured.py", line 185, in deco
	    raise converted from None
	pyspark.errors.exceptions.captured.StreamingQueryException: [STREAM_FAILED] Query [id = 96174c41-2a64-445c-831d-cba2d3a51e73, runId = ed755fd9-ac3c-4f89-bab1-0214df27b6f4] terminated with exception: org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[WI-686][TI-1882] - [INFO] 2024-04-27 21:25:29.681 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13377949373536_19/686/1882, processId:626 ,exitStatusCode:1 ,processWaitForStatus:true ,processExitValue:1
[WI-686][TI-1882] - [INFO] 2024-04-27 21:25:29.682 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-686][TI-1882] - [INFO] 2024-04-27 21:25:29.682 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-686][TI-1882] - [INFO] 2024-04-27 21:25:29.682 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-686][TI-1882] - [INFO] 2024-04-27 21:25:29.683 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-686][TI-1882] - [INFO] 2024-04-27 21:25:29.694 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: FAILURE to master : 172.18.1.1:1234
[WI-686][TI-1882] - [INFO] 2024-04-27 21:25:29.699 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-686][TI-1882] - [INFO] 2024-04-27 21:25:29.700 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13377949373536_19/686/1882
[WI-686][TI-1882] - [INFO] 2024-04-27 21:25:29.704 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13377949373536_19/686/1882
[WI-686][TI-1882] - [INFO] 2024-04-27 21:25:29.706 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-1882] - [INFO] 2024-04-27 21:25:30.674 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1882, success=true)
[WI-0][TI-0] - [INFO] 2024-04-27 21:25:30.784 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1883, taskName=keyword filtering, firstSubmitTime=1714224330769, startTime=0, taskType=PYTHON, workflowInstanceHost=172.18.0.9:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13377949373536, processDefineVersion=19, appIds=null, processInstanceId=686, scheduleTime=0, globalParams=[{"prop":"keywords","direct":"IN","type":"VARCHAR","value":"\"singapore\", \"lol\""}], executorId=1, cmdTypeIfComplement=7, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[],"rawScript":"from pyspark.sql import SparkSession\nfrom pyspark.sql.functions import col, from_json\nfrom pyspark.sql.types import StringType, StructType, StructField, IntegerType\n\nspark = SparkSession.builder \\\n    .master(\"local\") \\\n    .appName(\"Reddit Keyword Filtering\") \\\n    .config(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1\") \\\n    .config(\"spark.sql.streaming.checkpointLocation\", r\"/tmp/\") \\\n    .config(\"spark.driver.extraJavaOptions\", \"-Divy.cache.dir=/tmp -Divy.home=/tmp\") \\\n    .getOrCreate()\n\n# define the schema for the JSON data\nschema = StructType([\n    StructField(\"user\", StringType(), nullable=True),\n    StructField(\"content\", StringType(), nullable=True),\n    StructField(\"url\", StringType(), nullable=True),\n    StructField(\"context\", StringType(), nullable=True),\n    StructField(\"score\", IntegerType(), nullable=True),\n    StructField(\"subreddit\", StringType(), nullable=True),\n    StructField(\"type\", StringType(), nullable=True),\n    StructField(\"id\", StringType(), nullable=True),\n    StructField(\"datetime\", StringType(), nullable=True)  # Assuming the datetime is string type, you can change it to TimestampType if needed\n])\n\n# define the parameters for the input and output kafka broker and topic\nkafka_broker = \"kafka:9092\"\ninput_kafka_topic = \"reddit_post_preprocessed\"\noutput_kafka_topic = \"reddit_post_filtered\"\n\n# Subscribe to the input topic\ndf = spark \\\n    .readStream \\\n    .format(\"kafka\") \\\n    .option(\"kafka.bootstrap.servers\", kafka_broker) \\\n    .option(\"subscribe\", input_kafka_topic) \\\n    .load()\n\n# parse the JSON data in the 'value' column using the defined schema then create a dataframe containing the reddit data\ndf = df.select(col(\"value\").cast(\"string\")) \\\n    .withColumn(\"value\", from_json(\"value\", schema)) \\\n\nparsed_df = df \\\n    .select(\"value.*\")\n\n# filter rows containing specific keywords\nkeywords = ['singapore', 'sg']\n\n# initialize the filter condition with False\nfilter_condition = col(\"content\").contains(keywords[0])\n\n# loop through the rest of the keywords and update the filter condition\nfor keyword in keywords[1:]:\n    filter_condition = filter_condition | col(\"content\").contains(keyword)\n\n# apply the filter condition to the DataFrame\nfiltered_df = parsed_df.filter(filter_condition)\n\n# stream the data to kafka\nkafka_write = filtered_df \\\n    .selectExpr(\"'' AS key\", \"to_json(struct(*)) AS value\") \\\n    .writeStream \\\n    .format(\"kafka\") \\\n    .option(\"kafka.bootstrap.servers\", kafka_broker) \\\n    .option(\"topic\", output_kafka_topic) \\\n    .start()\n\n# Wait for the termination of the query\nkafka_write.awaitTermination()\n","resourceList":[]}, environmentConfig=export HADOOP_HOME=/opt/hadoop-3.4.0
export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export PYSPARK_DRIVER_PYTHON=/bin/python3.11
export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='keyword filtering'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, keywords=Property{prop='keywords', direct=IN, type=VARCHAR, value='"singapore", "lol"'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240427'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1883'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13377752024032'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240427212530'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='686'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240426'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='filter_data'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13377949373536'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-686][TI-1883] - [INFO] 2024-04-27 21:25:30.786 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: keyword filtering to wait queue success
[WI-686][TI-1883] - [INFO] 2024-04-27 21:25:30.786 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-686][TI-1883] - [INFO] 2024-04-27 21:25:30.788 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-686][TI-1883] - [INFO] 2024-04-27 21:25:30.789 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-686][TI-1883] - [INFO] 2024-04-27 21:25:30.789 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-686][TI-1883] - [INFO] 2024-04-27 21:25:30.789 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1714224330789
[WI-686][TI-1883] - [INFO] 2024-04-27 21:25:30.789 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 686_1883
[WI-686][TI-1883] - [INFO] 2024-04-27 21:25:30.791 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1883,
  "taskName" : "keyword filtering",
  "firstSubmitTime" : 1714224330769,
  "startTime" : 1714224330789,
  "taskType" : "PYTHON",
  "workflowInstanceHost" : "172.18.0.9:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240427/13377949373536/19/686/1883.log",
  "processId" : 0,
  "processDefineCode" : 13377949373536,
  "processDefineVersion" : 19,
  "processInstanceId" : 686,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"keywords\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"\\\"singapore\\\", \\\"lol\\\"\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 7,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[],\"rawScript\":\"from pyspark.sql import SparkSession\\nfrom pyspark.sql.functions import col, from_json\\nfrom pyspark.sql.types import StringType, StructType, StructField, IntegerType\\n\\nspark = SparkSession.builder \\\\\\n    .master(\\\"local\\\") \\\\\\n    .appName(\\\"Reddit Keyword Filtering\\\") \\\\\\n    .config(\\\"spark.jars.packages\\\", \\\"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1\\\") \\\\\\n    .config(\\\"spark.sql.streaming.checkpointLocation\\\", r\\\"/tmp/\\\") \\\\\\n    .config(\\\"spark.driver.extraJavaOptions\\\", \\\"-Divy.cache.dir=/tmp -Divy.home=/tmp\\\") \\\\\\n    .getOrCreate()\\n\\n# define the schema for the JSON data\\nschema = StructType([\\n    StructField(\\\"user\\\", StringType(), nullable=True),\\n    StructField(\\\"content\\\", StringType(), nullable=True),\\n    StructField(\\\"url\\\", StringType(), nullable=True),\\n    StructField(\\\"context\\\", StringType(), nullable=True),\\n    StructField(\\\"score\\\", IntegerType(), nullable=True),\\n    StructField(\\\"subreddit\\\", StringType(), nullable=True),\\n    StructField(\\\"type\\\", StringType(), nullable=True),\\n    StructField(\\\"id\\\", StringType(), nullable=True),\\n    StructField(\\\"datetime\\\", StringType(), nullable=True)  # Assuming the datetime is string type, you can change it to TimestampType if needed\\n])\\n\\n# define the parameters for the input and output kafka broker and topic\\nkafka_broker = \\\"kafka:9092\\\"\\ninput_kafka_topic = \\\"reddit_post_preprocessed\\\"\\noutput_kafka_topic = \\\"reddit_post_filtered\\\"\\n\\n# Subscribe to the input topic\\ndf = spark \\\\\\n    .readStream \\\\\\n    .format(\\\"kafka\\\") \\\\\\n    .option(\\\"kafka.bootstrap.servers\\\", kafka_broker) \\\\\\n    .option(\\\"subscribe\\\", input_kafka_topic) \\\\\\n    .load()\\n\\n# parse the JSON data in the 'value' column using the defined schema then create a dataframe containing the reddit data\\ndf = df.select(col(\\\"value\\\").cast(\\\"string\\\")) \\\\\\n    .withColumn(\\\"value\\\", from_json(\\\"value\\\", schema)) \\\\\\n\\nparsed_df = df \\\\\\n    .select(\\\"value.*\\\")\\n\\n# filter rows containing specific keywords\\nkeywords = ['singapore', 'sg']\\n\\n# initialize the filter condition with False\\nfilter_condition = col(\\\"content\\\").contains(keywords[0])\\n\\n# loop through the rest of the keywords and update the filter condition\\nfor keyword in keywords[1:]:\\n    filter_condition = filter_condition | col(\\\"content\\\").contains(keyword)\\n\\n# apply the filter condition to the DataFrame\\nfiltered_df = parsed_df.filter(filter_condition)\\n\\n# stream the data to kafka\\nkafka_write = filtered_df \\\\\\n    .selectExpr(\\\"'' AS key\\\", \\\"to_json(struct(*)) AS value\\\") \\\\\\n    .writeStream \\\\\\n    .format(\\\"kafka\\\") \\\\\\n    .option(\\\"kafka.bootstrap.servers\\\", kafka_broker) \\\\\\n    .option(\\\"topic\\\", output_kafka_topic) \\\\\\n    .start()\\n\\n# Wait for the termination of the query\\nkafka_write.awaitTermination()\\n\",\"resourceList\":[]}",
  "environmentConfig" : "export HADOOP_HOME=/opt/hadoop-3.4.0\nexport SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3\nexport JAVA_HOME=/opt/java/openjdk\nexport PYSPARK_DRIVER_PYTHON=/bin/python3.11\nexport PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "keyword filtering"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "keywords" : {
      "prop" : "keywords",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "\"singapore\", \"lol\""
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240427"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1883"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13377752024032"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240427212530"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "686"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240426"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "filter_data"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13377949373536"
    }
  },
  "taskAppId" : "686_1883",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "varPool" : "[]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-686][TI-1883] - [INFO] 2024-04-27 21:25:30.792 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-686][TI-1883] - [INFO] 2024-04-27 21:25:30.793 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-686][TI-1883] - [INFO] 2024-04-27 21:25:30.793 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-686][TI-1883] - [INFO] 2024-04-27 21:25:30.797 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-686][TI-1883] - [INFO] 2024-04-27 21:25:30.798 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-686][TI-1883] - [INFO] 2024-04-27 21:25:30.799 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13377949373536_19/686/1883 check successfully
[WI-686][TI-1883] - [INFO] 2024-04-27 21:25:30.800 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.python.PythonTaskChannel successfully
[WI-686][TI-1883] - [INFO] 2024-04-27 21:25:30.801 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-686][TI-1883] - [INFO] 2024-04-27 21:25:30.801 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-686][TI-1883] - [INFO] 2024-04-27 21:25:30.801 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: PYTHON create successfully
[WI-686][TI-1883] - [INFO] 2024-04-27 21:25:30.802 +0800 o.a.d.p.t.p.PythonTask:[75] - Initialize python task params {
  "localParams" : [ ],
  "varPool" : null,
  "rawScript" : "from pyspark.sql import SparkSession\nfrom pyspark.sql.functions import col, from_json\nfrom pyspark.sql.types import StringType, StructType, StructField, IntegerType\n\nspark = SparkSession.builder \\\n    .master(\"local\") \\\n    .appName(\"Reddit Keyword Filtering\") \\\n    .config(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1\") \\\n    .config(\"spark.sql.streaming.checkpointLocation\", r\"/tmp/\") \\\n    .config(\"spark.driver.extraJavaOptions\", \"-Divy.cache.dir=/tmp -Divy.home=/tmp\") \\\n    .getOrCreate()\n\n# define the schema for the JSON data\nschema = StructType([\n    StructField(\"user\", StringType(), nullable=True),\n    StructField(\"content\", StringType(), nullable=True),\n    StructField(\"url\", StringType(), nullable=True),\n    StructField(\"context\", StringType(), nullable=True),\n    StructField(\"score\", IntegerType(), nullable=True),\n    StructField(\"subreddit\", StringType(), nullable=True),\n    StructField(\"type\", StringType(), nullable=True),\n    StructField(\"id\", StringType(), nullable=True),\n    StructField(\"datetime\", StringType(), nullable=True)  # Assuming the datetime is string type, you can change it to TimestampType if needed\n])\n\n# define the parameters for the input and output kafka broker and topic\nkafka_broker = \"kafka:9092\"\ninput_kafka_topic = \"reddit_post_preprocessed\"\noutput_kafka_topic = \"reddit_post_filtered\"\n\n# Subscribe to the input topic\ndf = spark \\\n    .readStream \\\n    .format(\"kafka\") \\\n    .option(\"kafka.bootstrap.servers\", kafka_broker) \\\n    .option(\"subscribe\", input_kafka_topic) \\\n    .load()\n\n# parse the JSON data in the 'value' column using the defined schema then create a dataframe containing the reddit data\ndf = df.select(col(\"value\").cast(\"string\")) \\\n    .withColumn(\"value\", from_json(\"value\", schema)) \\\n\nparsed_df = df \\\n    .select(\"value.*\")\n\n# filter rows containing specific keywords\nkeywords = ['singapore', 'sg']\n\n# initialize the filter condition with False\nfilter_condition = col(\"content\").contains(keywords[0])\n\n# loop through the rest of the keywords and update the filter condition\nfor keyword in keywords[1:]:\n    filter_condition = filter_condition | col(\"content\").contains(keyword)\n\n# apply the filter condition to the DataFrame\nfiltered_df = parsed_df.filter(filter_condition)\n\n# stream the data to kafka\nkafka_write = filtered_df \\\n    .selectExpr(\"'' AS key\", \"to_json(struct(*)) AS value\") \\\n    .writeStream \\\n    .format(\"kafka\") \\\n    .option(\"kafka.bootstrap.servers\", kafka_broker) \\\n    .option(\"topic\", output_kafka_topic) \\\n    .start()\n\n# Wait for the termination of the query\nkafka_write.awaitTermination()\n",
  "resourceList" : [ ]
}
[WI-686][TI-1883] - [INFO] 2024-04-27 21:25:30.803 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-686][TI-1883] - [INFO] 2024-04-27 21:25:30.804 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [] successfully
[WI-686][TI-1883] - [INFO] 2024-04-27 21:25:30.804 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-686][TI-1883] - [INFO] 2024-04-27 21:25:30.805 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-686][TI-1883] - [INFO] 2024-04-27 21:25:30.806 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-686][TI-1883] - [INFO] 2024-04-27 21:25:30.806 +0800 o.a.d.p.t.p.PythonTask:[165] - raw python script : from pyspark.sql import SparkSession
from pyspark.sql.functions import col, from_json
from pyspark.sql.types import StringType, StructType, StructField, IntegerType

spark = SparkSession.builder \
    .master("local") \
    .appName("Reddit Keyword Filtering") \
    .config("spark.jars.packages", "org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1") \
    .config("spark.sql.streaming.checkpointLocation", r"/tmp/") \
    .config("spark.driver.extraJavaOptions", "-Divy.cache.dir=/tmp -Divy.home=/tmp") \
    .getOrCreate()

# define the schema for the JSON data
schema = StructType([
    StructField("user", StringType(), nullable=True),
    StructField("content", StringType(), nullable=True),
    StructField("url", StringType(), nullable=True),
    StructField("context", StringType(), nullable=True),
    StructField("score", IntegerType(), nullable=True),
    StructField("subreddit", StringType(), nullable=True),
    StructField("type", StringType(), nullable=True),
    StructField("id", StringType(), nullable=True),
    StructField("datetime", StringType(), nullable=True)  # Assuming the datetime is string type, you can change it to TimestampType if needed
])

# define the parameters for the input and output kafka broker and topic
kafka_broker = "kafka:9092"
input_kafka_topic = "reddit_post_preprocessed"
output_kafka_topic = "reddit_post_filtered"

# Subscribe to the input topic
df = spark \
    .readStream \
    .format("kafka") \
    .option("kafka.bootstrap.servers", kafka_broker) \
    .option("subscribe", input_kafka_topic) \
    .load()

# parse the JSON data in the 'value' column using the defined schema then create a dataframe containing the reddit data
df = df.select(col("value").cast("string")) \
    .withColumn("value", from_json("value", schema)) \

parsed_df = df \
    .select("value.*")

# filter rows containing specific keywords
keywords = ['singapore', 'sg']

# initialize the filter condition with False
filter_condition = col("content").contains(keywords[0])

# loop through the rest of the keywords and update the filter condition
for keyword in keywords[1:]:
    filter_condition = filter_condition | col("content").contains(keyword)

# apply the filter condition to the DataFrame
filtered_df = parsed_df.filter(filter_condition)

# stream the data to kafka
kafka_write = filtered_df \
    .selectExpr("'' AS key", "to_json(struct(*)) AS value") \
    .writeStream \
    .format("kafka") \
    .option("kafka.bootstrap.servers", kafka_broker) \
    .option("topic", output_kafka_topic) \
    .start()

# Wait for the termination of the query
kafka_write.awaitTermination()

[WI-686][TI-1883] - [INFO] 2024-04-27 21:25:30.808 +0800 o.a.d.p.t.p.PythonTask:[131] - tenantCode :default, task dir:/tmp/dolphinscheduler/exec/process/default/13010050770016/13377949373536_19/686/1883
[WI-686][TI-1883] - [INFO] 2024-04-27 21:25:30.809 +0800 o.a.d.p.t.p.PythonTask:[134] - generate python script file:/tmp/dolphinscheduler/exec/process/default/13010050770016/13377949373536_19/686/1883/py_686_1883.py
[WI-686][TI-1883] - [INFO] 2024-04-27 21:25:30.810 +0800 o.a.d.p.t.p.PythonTask:[141] - #-*- encoding=utf8 -*-

from pyspark.sql import SparkSession
from pyspark.sql.functions import col, from_json
from pyspark.sql.types import StringType, StructType, StructField, IntegerType

spark = SparkSession.builder \
    .master("local") \
    .appName("Reddit Keyword Filtering") \
    .config("spark.jars.packages", "org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1") \
    .config("spark.sql.streaming.checkpointLocation", r"/tmp/") \
    .config("spark.driver.extraJavaOptions", "-Divy.cache.dir=/tmp -Divy.home=/tmp") \
    .getOrCreate()

# define the schema for the JSON data
schema = StructType([
    StructField("user", StringType(), nullable=True),
    StructField("content", StringType(), nullable=True),
    StructField("url", StringType(), nullable=True),
    StructField("context", StringType(), nullable=True),
    StructField("score", IntegerType(), nullable=True),
    StructField("subreddit", StringType(), nullable=True),
    StructField("type", StringType(), nullable=True),
    StructField("id", StringType(), nullable=True),
    StructField("datetime", StringType(), nullable=True)  # Assuming the datetime is string type, you can change it to TimestampType if needed
])

# define the parameters for the input and output kafka broker and topic
kafka_broker = "kafka:9092"
input_kafka_topic = "reddit_post_preprocessed"
output_kafka_topic = "reddit_post_filtered"

# Subscribe to the input topic
df = spark \
    .readStream \
    .format("kafka") \
    .option("kafka.bootstrap.servers", kafka_broker) \
    .option("subscribe", input_kafka_topic) \
    .load()

# parse the JSON data in the 'value' column using the defined schema then create a dataframe containing the reddit data
df = df.select(col("value").cast("string")) \
    .withColumn("value", from_json("value", schema)) \

parsed_df = df \
    .select("value.*")

# filter rows containing specific keywords
keywords = ['singapore', 'sg']

# initialize the filter condition with False
filter_condition = col("content").contains(keywords[0])

# loop through the rest of the keywords and update the filter condition
for keyword in keywords[1:]:
    filter_condition = filter_condition | col("content").contains(keyword)

# apply the filter condition to the DataFrame
filtered_df = parsed_df.filter(filter_condition)

# stream the data to kafka
kafka_write = filtered_df \
    .selectExpr("'' AS key", "to_json(struct(*)) AS value") \
    .writeStream \
    .format("kafka") \
    .option("kafka.bootstrap.servers", kafka_broker) \
    .option("topic", output_kafka_topic) \
    .start()

# Wait for the termination of the query
kafka_write.awaitTermination()

[WI-686][TI-1883] - [INFO] 2024-04-27 21:25:30.811 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-686][TI-1883] - [INFO] 2024-04-27 21:25:30.812 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-686][TI-1883] - [INFO] 2024-04-27 21:25:30.812 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export HADOOP_HOME=/opt/hadoop-3.4.0
export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export PYSPARK_DRIVER_PYTHON=/bin/python3.11
export PYTHON_LAUNCHER=/bin/python3.11
${PYTHON_LAUNCHER} /tmp/dolphinscheduler/exec/process/default/13010050770016/13377949373536_19/686/1883/py_686_1883.py
[WI-686][TI-1883] - [INFO] 2024-04-27 21:25:30.812 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-686][TI-1883] - [INFO] 2024-04-27 21:25:30.813 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13377949373536_19/686/1883/686_1883.sh
[WI-686][TI-1883] - [INFO] 2024-04-27 21:25:30.816 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 838
[WI-0][TI-1883] - [INFO] 2024-04-27 21:25:31.684 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1883, success=true)
[WI-0][TI-1883] - [INFO] 2024-04-27 21:25:31.699 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1883)
[WI-0][TI-0] - [INFO] 2024-04-27 21:25:31.819 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
[WI-0][TI-0] - [INFO] 2024-04-27 21:25:34.827 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	:: loading settings :: url = jar:file:/opt/spark-3.5.1-bin-hadoop3/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml
	Ivy Default Cache set to: /tmp
	The jars for the packages stored in: /tmp/jars
	org.apache.spark#spark-sql-kafka-0-10_2.12 added as a dependency
	:: resolving dependencies :: org.apache.spark#spark-submit-parent-667864b3-a792-473b-a4a1-8c780ab7f7ba;1.0
		confs: [default]
		found org.apache.spark#spark-sql-kafka-0-10_2.12;3.5.1 in central
		found org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.5.1 in central
		found org.apache.kafka#kafka-clients;3.4.1 in central
		found org.lz4#lz4-java;1.8.0 in central
		found org.xerial.snappy#snappy-java;1.1.10.3 in central
		found org.slf4j#slf4j-api;2.0.7 in central
		found org.apache.hadoop#hadoop-client-runtime;3.3.4 in central
[WI-0][TI-0] - [INFO] 2024-04-27 21:25:35.568 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7762237762237763 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:25:35.833 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
		found org.apache.hadoop#hadoop-client-api;3.3.4 in central
		found commons-logging#commons-logging;1.1.3 in central
		found com.google.code.findbugs#jsr305;3.0.0 in central
		found org.apache.commons#commons-pool2;2.11.1 in central
	:: resolution report :: resolve 728ms :: artifacts dl 19ms
		:: modules in use:
		com.google.code.findbugs#jsr305;3.0.0 from central in [default]
		commons-logging#commons-logging;1.1.3 from central in [default]
		org.apache.commons#commons-pool2;2.11.1 from central in [default]
		org.apache.hadoop#hadoop-client-api;3.3.4 from central in [default]
		org.apache.hadoop#hadoop-client-runtime;3.3.4 from central in [default]
		org.apache.kafka#kafka-clients;3.4.1 from central in [default]
		org.apache.spark#spark-sql-kafka-0-10_2.12;3.5.1 from central in [default]
		org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.5.1 from central in [default]
		org.lz4#lz4-java;1.8.0 from central in [default]
		org.slf4j#slf4j-api;2.0.7 from central in [default]
		org.xerial.snappy#snappy-java;1.1.10.3 from central in [default]
		---------------------------------------------------------------------
		|                  |            modules            ||   artifacts   |
		|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
		---------------------------------------------------------------------
		|      default     |   11  |   0   |   0   |   0   ||   11  |   0   |
		---------------------------------------------------------------------
	:: retrieving :: org.apache.spark#spark-submit-parent-667864b3-a792-473b-a4a1-8c780ab7f7ba
		confs: [default]
		0 artifacts copied, 11 already retrieved (0kB/36ms)
	24/04/27 21:25:35 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[WI-0][TI-0] - [INFO] 2024-04-27 21:25:36.836 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	Setting default log level to "WARN".
	To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[WI-0][TI-0] - [INFO] 2024-04-27 21:25:38.616 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.887459807073955 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:25:39.637 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8394648829431438 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:25:40.641 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8913738019169328 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:25:45.863 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/27 21:25:45 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.
[WI-0][TI-0] - [INFO] 2024-04-27 21:25:46.867 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/27 21:25:46 WARN AdminClientConfig: These configurations '[key.deserializer, value.deserializer, enable.auto.commit, max.poll.records, auto.offset.reset]' were supplied but are not used yet.
[WI-0][TI-0] - [INFO] 2024-04-27 21:25:50.876 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	
	[Stage 0:>                                                          (0 + 1) / 1]
	
	                                                                                
[WI-0][TI-0] - [INFO] 2024-04-27 21:26:11.156 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8826979472140762 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:26:55.877 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8563218390804598 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:26:56.902 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8813479748547783 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:26:57.907 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.898599506644386 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:26:58.914 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8416422287390029 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:26:59.941 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7962382445141066 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:27:00.944 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7971830985915493 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:27:03.961 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7739130434782608 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:27:06.025 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8551136363636364 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:27:07.063 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7935103244837759 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:27:10.086 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8333333333333333 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:27:11.104 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9517045454545455 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:27:12.107 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9246987951807228 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:29:28.099 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7138728323699421 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:29:29.142 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8571428571428572 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:29:30.149 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7616279069767442 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:29:40.180 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.754985754985755 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:29:50.244 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.804733727810651 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:29:51.103 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	
	[Stage 1:>                                                          (0 + 1) / 1]
[WI-0][TI-0] - [INFO] 2024-04-27 21:29:51.304 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8655306133595498 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:29:52.349 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.75 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:29:53.356 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9179810725552051 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:29:55.113 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	
	                                                                                
[WI-0][TI-0] - [INFO] 2024-04-27 21:30:08.613 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8169014084507042 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:30:09.662 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8425414364640884 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:30:13.689 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7767857142857142 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:30:14.721 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.773224043715847 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:30:16.809 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7872340425531914 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:30:25.873 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8289855072463768 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:30:27.076 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.925925925925926 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:30:28.079 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9774647887323944 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:30:29.083 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9738372093023255 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:30:30.090 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9909638554216867 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:30:34.123 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.782770552440043 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:30:35.151 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8023598820058998 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:30:36.152 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8961424332344213 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:30:48.257 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9061488673139159 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:30:48.325 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	
	[Stage 2:>                                                          (0 + 1) / 1]
[WI-0][TI-0] - [INFO] 2024-04-27 21:30:49.328 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	
	                                                                                
[WI-0][TI-0] - [INFO] 2024-04-27 21:30:58.317 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8441926345609065 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:30:59.346 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8028169014084507 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:31:00.353 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9642857142857143 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:31:01.356 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9295774647887324 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:31:02.362 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9615384615384615 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:31:03.363 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9536231884057971 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:31:04.368 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9577039274924471 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:31:05.383 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9423631123919308 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:31:17.629 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7307692307692307 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:31:21.678 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7335243553008596 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:35:29.109 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9008498583569405 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:35:32.194 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8136094674556212 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:35:39.275 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8567164179104478 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:35:40.302 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.783625730994152 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:35:41.312 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8270893371757925 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:35:42.313 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7579787234042552 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:35:50.334 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8370786516853932 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:35:51.352 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7792915531335151 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:35:53.432 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7184986595174263 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:35:57.501 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7590361445783134 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:35:58.514 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7319884726224783 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:35:59.528 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7774566473988439 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:36:02.543 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8901734104046243 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:36:03.599 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.759375 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:36:04.602 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7894736842105263 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:36:05.612 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7305194805194806 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:36:06.615 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9464285714285714 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:36:26.715 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.707427255414323 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:36:28.787 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.830028328611898 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:36:29.859 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9293193717277487 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:36:32.906 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7218934911242604 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:36:33.962 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9584487534626038 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:36:49.029 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8548895899053628 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:37:02.093 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.732919254658385 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:37:03.123 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7457627118644069 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:37:39.288 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8761904761904762 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:37:40.307 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7146974063400576 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:37:41.309 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7082066869300911 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:37:46.346 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7692307692307692 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:38:00.417 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7833827893175074 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:38:01.458 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8801169590643275 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:38:02.460 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8959537572254336 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:38:03.478 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8622754491017964 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:38:04.480 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8273972602739725 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:38:06.541 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9405099150141643 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:38:07.594 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9213483146067415 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:38:08.598 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7739130434782608 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:38:09.599 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7601156069364161 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:38:10.604 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7777777777777778 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:38:11.626 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.816559319962996 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:38:12.632 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8466352052855121 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:38:17.650 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8259587020648967 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:38:18.709 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8102981029810299 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:38:22.768 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7896341463414634 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:38:23.784 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7537537537537538 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:38:25.836 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7014084507042253 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:38:27.861 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8457142857142858 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:38:51.964 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7057057057057057 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:38:59.183 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7289972899728997 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:39:01.224 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8027777777777778 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:39:02.315 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8194070080862533 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:39:03.317 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7191358024691359 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:39:04.318 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7966101694915255 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:39:05.333 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9159159159159159 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:39:06.363 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8882521489971347 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:39:18.450 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.752112676056338 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:39:20.549 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8656895164894093 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:39:21.609 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8801169590643274 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:39:25.642 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9098921960810903 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:39:27.966 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8411458333333333 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:39:28.980 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7077363896848138 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:39:31.030 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8753541076487252 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:39:32.055 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7493036211699164 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:39:33.077 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7323529411764707 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:39:34.079 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8158730158730159 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:39:35.080 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9067796610169492 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:39:36.085 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9164345403899722 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:39:37.095 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8873239436619719 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:39:38.108 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8695652173913043 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:39:39.126 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8898305084745762 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:39:39.975 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1884, taskName=sentiment anaysis, firstSubmitTime=1714225179934, startTime=0, taskType=PYTHON, workflowInstanceHost=172.18.0.9:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13386218435520, processDefineVersion=15, appIds=null, processInstanceId=687, scheduleTime=0, globalParams=null, executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[],"rawScript":"# use kafka streaming api\nfrom pyspark.sql.functions import udf, col, from_json\nfrom pyspark.sql.types import FloatType, ArrayType, StringType, StructType, StructField, IntegerType\nimport nltk\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA\nfrom pyspark.sql import SparkSession\n\n# download the model\nnltk.download('vader_lexicon')\n\n# init the sentiment analysis object\nsia = SIA()\n\n# init Spark session\nspark = SparkSession.builder \\\n    .master('local') \\\n    .appName(\"Sentiment Analysis\") \\\n    .config(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1\") \\\n    .config(\"spark.sql.streaming.checkpointLocation\", r\"/tmp/\") \\\n    .config(\"spark.driver.extraJavaOptions\", \"-Divy.cache.dir=/tmp -Divy.home=/tmp\") \\\n    .getOrCreate()\n\n# define a udf to perform sentiment analysis\ndef analyze_sentiment(message):\n    # Perform sentiment analysis\n    pol_score = sia.polarity_scores(message)\n    # Return the compound score\n    return [pol_score['neg'], pol_score['neu'], pol_score['pos'], pol_score['compound']]\n\n# Register the function as a UDF\nanalyze_sentiment_udf = udf(lambda x:analyze_sentiment(x), ArrayType(FloatType()))\n\n# define the schema for the JSON data\nschema = StructType([\n    StructField(\"user\", StringType(), nullable=True),\n    StructField(\"content\", StringType(), nullable=True),\n    StructField(\"url\", StringType(), nullable=True),\n    StructField(\"context\", StringType(), nullable=True),\n    StructField(\"score\", IntegerType(), nullable=True),\n    StructField(\"subreddit\", StringType(), nullable=True),\n    StructField(\"type\", StringType(), nullable=True),\n    StructField(\"id\", StringType(), nullable=True),\n    StructField(\"datetime\", StringType(), nullable=True)  # Assuming the datetime is string type, you can change it to TimestampType if needed\n])\n\n\n# define the parameters for the input and output kafka broker and topic\nkafka_broker = \"kafka:9092\"\ninput_kafka_topic = \"reddit_post_filtered\"\noutput_kafka_topic = \"reddit_post_sa\"\n\n# Subscribe to the input topic\ndf = spark \\\n    .readStream \\\n    .format(\"kafka\") \\\n    .option(\"kafka.bootstrap.servers\", kafka_broker) \\\n    .option(\"subscribe\", input_kafka_topic) \\\n    .load()\n\n# parse the JSON data in the 'value' column using the defined schema then create a dataframe containing the reddit data\ndf = df.select(col(\"value\").cast(\"string\")) \\\n    .withColumn(\"value\", from_json(\"value\", schema)) \\\n\nparsed_df = df \\\n    .select(\"value.*\")\n\n# perform sentiment analysis on the parsed dataframe \nsa_reddit_df = parsed_df.withColumn('sentiment_score', analyze_sentiment_udf(parsed_df['content']))\n\n# split the sentiment_score column into separate columns\nsa_reddit_df = sa_reddit_df.withColumn(\"negative\", sa_reddit_df[\"sentiment_score\"][0]) \\\n            .withColumn(\"neutral\", sa_reddit_df[\"sentiment_score\"][1]) \\\n            .withColumn(\"positive\", sa_reddit_df[\"sentiment_score\"][2]) \\\n            .withColumn(\"compound\", sa_reddit_df[\"sentiment_score\"][3]) \\\n            .drop('sentiment_score')  # drop sentiment_score column after splitting\n\n# stream the data to kafka\nkafka_write = sa_reddit_df \\\n    .selectExpr(\"'' AS key\", \"to_json(struct(*)) AS value\") \\\n    .writeStream \\\n    .format(\"kafka\") \\\n    .option(\"kafka.bootstrap.servers\", kafka_broker) \\\n    .option(\"topic\", output_kafka_topic) \\\n    .start()\n\n# Wait for the termination of the query\nkafka_write.awaitTermination()","resourceList":[]}, environmentConfig=export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export PYSPARK_DRIVER_PYTHON=/bin/python3.11
export PYSPARK_PYTHON=/bin/python3.11
export PYTHON_LAUNCHER=/bin/python3.11
export NLTK_DATA=/local_storage/nltk_data, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='sentiment anaysis'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='687'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240427'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240426'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1884'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='sentiment_analysis_subprocess'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13386027735104'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13386218435520'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240427213939'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=null, dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-687][TI-1884] - [INFO] 2024-04-27 21:39:39.977 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: sentiment anaysis to wait queue success
[WI-687][TI-1884] - [INFO] 2024-04-27 21:39:39.977 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-687][TI-1884] - [INFO] 2024-04-27 21:39:39.980 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-687][TI-1884] - [INFO] 2024-04-27 21:39:39.980 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-687][TI-1884] - [INFO] 2024-04-27 21:39:39.980 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-687][TI-1884] - [INFO] 2024-04-27 21:39:39.980 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1714225179980
[WI-687][TI-1884] - [INFO] 2024-04-27 21:39:39.981 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 687_1884
[WI-687][TI-1884] - [INFO] 2024-04-27 21:39:39.986 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1884,
  "taskName" : "sentiment anaysis",
  "firstSubmitTime" : 1714225179934,
  "startTime" : 1714225179980,
  "taskType" : "PYTHON",
  "workflowInstanceHost" : "172.18.0.9:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240427/13386218435520/15/687/1884.log",
  "processId" : 0,
  "processDefineCode" : 13386218435520,
  "processDefineVersion" : 15,
  "processInstanceId" : 687,
  "scheduleTime" : 0,
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[],\"rawScript\":\"# use kafka streaming api\\nfrom pyspark.sql.functions import udf, col, from_json\\nfrom pyspark.sql.types import FloatType, ArrayType, StringType, StructType, StructField, IntegerType\\nimport nltk\\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA\\nfrom pyspark.sql import SparkSession\\n\\n# download the model\\nnltk.download('vader_lexicon')\\n\\n# init the sentiment analysis object\\nsia = SIA()\\n\\n# init Spark session\\nspark = SparkSession.builder \\\\\\n    .master('local') \\\\\\n    .appName(\\\"Sentiment Analysis\\\") \\\\\\n    .config(\\\"spark.jars.packages\\\", \\\"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1\\\") \\\\\\n    .config(\\\"spark.sql.streaming.checkpointLocation\\\", r\\\"/tmp/\\\") \\\\\\n    .config(\\\"spark.driver.extraJavaOptions\\\", \\\"-Divy.cache.dir=/tmp -Divy.home=/tmp\\\") \\\\\\n    .getOrCreate()\\n\\n# define a udf to perform sentiment analysis\\ndef analyze_sentiment(message):\\n    # Perform sentiment analysis\\n    pol_score = sia.polarity_scores(message)\\n    # Return the compound score\\n    return [pol_score['neg'], pol_score['neu'], pol_score['pos'], pol_score['compound']]\\n\\n# Register the function as a UDF\\nanalyze_sentiment_udf = udf(lambda x:analyze_sentiment(x), ArrayType(FloatType()))\\n\\n# define the schema for the JSON data\\nschema = StructType([\\n    StructField(\\\"user\\\", StringType(), nullable=True),\\n    StructField(\\\"content\\\", StringType(), nullable=True),\\n    StructField(\\\"url\\\", StringType(), nullable=True),\\n    StructField(\\\"context\\\", StringType(), nullable=True),\\n    StructField(\\\"score\\\", IntegerType(), nullable=True),\\n    StructField(\\\"subreddit\\\", StringType(), nullable=True),\\n    StructField(\\\"type\\\", StringType(), nullable=True),\\n    StructField(\\\"id\\\", StringType(), nullable=True),\\n    StructField(\\\"datetime\\\", StringType(), nullable=True)  # Assuming the datetime is string type, you can change it to TimestampType if needed\\n])\\n\\n\\n# define the parameters for the input and output kafka broker and topic\\nkafka_broker = \\\"kafka:9092\\\"\\ninput_kafka_topic = \\\"reddit_post_filtered\\\"\\noutput_kafka_topic = \\\"reddit_post_sa\\\"\\n\\n# Subscribe to the input topic\\ndf = spark \\\\\\n    .readStream \\\\\\n    .format(\\\"kafka\\\") \\\\\\n    .option(\\\"kafka.bootstrap.servers\\\", kafka_broker) \\\\\\n    .option(\\\"subscribe\\\", input_kafka_topic) \\\\\\n    .load()\\n\\n# parse the JSON data in the 'value' column using the defined schema then create a dataframe containing the reddit data\\ndf = df.select(col(\\\"value\\\").cast(\\\"string\\\")) \\\\\\n    .withColumn(\\\"value\\\", from_json(\\\"value\\\", schema)) \\\\\\n\\nparsed_df = df \\\\\\n    .select(\\\"value.*\\\")\\n\\n# perform sentiment analysis on the parsed dataframe \\nsa_reddit_df = parsed_df.withColumn('sentiment_score', analyze_sentiment_udf(parsed_df['content']))\\n\\n# split the sentiment_score column into separate columns\\nsa_reddit_df = sa_reddit_df.withColumn(\\\"negative\\\", sa_reddit_df[\\\"sentiment_score\\\"][0]) \\\\\\n            .withColumn(\\\"neutral\\\", sa_reddit_df[\\\"sentiment_score\\\"][1]) \\\\\\n            .withColumn(\\\"positive\\\", sa_reddit_df[\\\"sentiment_score\\\"][2]) \\\\\\n            .withColumn(\\\"compound\\\", sa_reddit_df[\\\"sentiment_score\\\"][3]) \\\\\\n            .drop('sentiment_score')  # drop sentiment_score column after splitting\\n\\n# stream the data to kafka\\nkafka_write = sa_reddit_df \\\\\\n    .selectExpr(\\\"'' AS key\\\", \\\"to_json(struct(*)) AS value\\\") \\\\\\n    .writeStream \\\\\\n    .format(\\\"kafka\\\") \\\\\\n    .option(\\\"kafka.bootstrap.servers\\\", kafka_broker) \\\\\\n    .option(\\\"topic\\\", output_kafka_topic) \\\\\\n    .start()\\n\\n# Wait for the termination of the query\\nkafka_write.awaitTermination()\",\"resourceList\":[]}",
  "environmentConfig" : "export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3\nexport JAVA_HOME=/opt/java/openjdk\nexport PYSPARK_DRIVER_PYTHON=/bin/python3.11\nexport PYSPARK_PYTHON=/bin/python3.11\nexport PYTHON_LAUNCHER=/bin/python3.11\nexport NLTK_DATA=/local_storage/nltk_data",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "sentiment anaysis"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "687"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240427"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240426"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1884"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "sentiment_analysis_subprocess"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13386027735104"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13386218435520"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240427213939"
    }
  },
  "taskAppId" : "687_1884",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-687][TI-1884] - [INFO] 2024-04-27 21:39:39.988 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-687][TI-1884] - [INFO] 2024-04-27 21:39:39.988 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-687][TI-1884] - [INFO] 2024-04-27 21:39:39.988 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-687][TI-1884] - [INFO] 2024-04-27 21:39:40.006 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-687][TI-1884] - [INFO] 2024-04-27 21:39:40.007 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-687][TI-1884] - [INFO] 2024-04-27 21:39:40.009 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13386218435520_15/687/1884 check successfully
[WI-687][TI-1884] - [INFO] 2024-04-27 21:39:40.009 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.python.PythonTaskChannel successfully
[WI-687][TI-1884] - [INFO] 2024-04-27 21:39:40.009 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-687][TI-1884] - [INFO] 2024-04-27 21:39:40.010 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-687][TI-1884] - [INFO] 2024-04-27 21:39:40.012 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: PYTHON create successfully
[WI-687][TI-1884] - [INFO] 2024-04-27 21:39:40.016 +0800 o.a.d.p.t.p.PythonTask:[75] - Initialize python task params {
  "localParams" : [ ],
  "varPool" : null,
  "rawScript" : "# use kafka streaming api\nfrom pyspark.sql.functions import udf, col, from_json\nfrom pyspark.sql.types import FloatType, ArrayType, StringType, StructType, StructField, IntegerType\nimport nltk\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA\nfrom pyspark.sql import SparkSession\n\n# download the model\nnltk.download('vader_lexicon')\n\n# init the sentiment analysis object\nsia = SIA()\n\n# init Spark session\nspark = SparkSession.builder \\\n    .master('local') \\\n    .appName(\"Sentiment Analysis\") \\\n    .config(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1\") \\\n    .config(\"spark.sql.streaming.checkpointLocation\", r\"/tmp/\") \\\n    .config(\"spark.driver.extraJavaOptions\", \"-Divy.cache.dir=/tmp -Divy.home=/tmp\") \\\n    .getOrCreate()\n\n# define a udf to perform sentiment analysis\ndef analyze_sentiment(message):\n    # Perform sentiment analysis\n    pol_score = sia.polarity_scores(message)\n    # Return the compound score\n    return [pol_score['neg'], pol_score['neu'], pol_score['pos'], pol_score['compound']]\n\n# Register the function as a UDF\nanalyze_sentiment_udf = udf(lambda x:analyze_sentiment(x), ArrayType(FloatType()))\n\n# define the schema for the JSON data\nschema = StructType([\n    StructField(\"user\", StringType(), nullable=True),\n    StructField(\"content\", StringType(), nullable=True),\n    StructField(\"url\", StringType(), nullable=True),\n    StructField(\"context\", StringType(), nullable=True),\n    StructField(\"score\", IntegerType(), nullable=True),\n    StructField(\"subreddit\", StringType(), nullable=True),\n    StructField(\"type\", StringType(), nullable=True),\n    StructField(\"id\", StringType(), nullable=True),\n    StructField(\"datetime\", StringType(), nullable=True)  # Assuming the datetime is string type, you can change it to TimestampType if needed\n])\n\n\n# define the parameters for the input and output kafka broker and topic\nkafka_broker = \"kafka:9092\"\ninput_kafka_topic = \"reddit_post_filtered\"\noutput_kafka_topic = \"reddit_post_sa\"\n\n# Subscribe to the input topic\ndf = spark \\\n    .readStream \\\n    .format(\"kafka\") \\\n    .option(\"kafka.bootstrap.servers\", kafka_broker) \\\n    .option(\"subscribe\", input_kafka_topic) \\\n    .load()\n\n# parse the JSON data in the 'value' column using the defined schema then create a dataframe containing the reddit data\ndf = df.select(col(\"value\").cast(\"string\")) \\\n    .withColumn(\"value\", from_json(\"value\", schema)) \\\n\nparsed_df = df \\\n    .select(\"value.*\")\n\n# perform sentiment analysis on the parsed dataframe \nsa_reddit_df = parsed_df.withColumn('sentiment_score', analyze_sentiment_udf(parsed_df['content']))\n\n# split the sentiment_score column into separate columns\nsa_reddit_df = sa_reddit_df.withColumn(\"negative\", sa_reddit_df[\"sentiment_score\"][0]) \\\n            .withColumn(\"neutral\", sa_reddit_df[\"sentiment_score\"][1]) \\\n            .withColumn(\"positive\", sa_reddit_df[\"sentiment_score\"][2]) \\\n            .withColumn(\"compound\", sa_reddit_df[\"sentiment_score\"][3]) \\\n            .drop('sentiment_score')  # drop sentiment_score column after splitting\n\n# stream the data to kafka\nkafka_write = sa_reddit_df \\\n    .selectExpr(\"'' AS key\", \"to_json(struct(*)) AS value\") \\\n    .writeStream \\\n    .format(\"kafka\") \\\n    .option(\"kafka.bootstrap.servers\", kafka_broker) \\\n    .option(\"topic\", output_kafka_topic) \\\n    .start()\n\n# Wait for the termination of the query\nkafka_write.awaitTermination()",
  "resourceList" : [ ]
}
[WI-687][TI-1884] - [INFO] 2024-04-27 21:39:40.018 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-687][TI-1884] - [INFO] 2024-04-27 21:39:40.019 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: null successfully
[WI-687][TI-1884] - [INFO] 2024-04-27 21:39:40.019 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-687][TI-1884] - [INFO] 2024-04-27 21:39:40.019 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-687][TI-1884] - [INFO] 2024-04-27 21:39:40.019 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-687][TI-1884] - [INFO] 2024-04-27 21:39:40.019 +0800 o.a.d.p.t.p.PythonTask:[165] - raw python script : # use kafka streaming api
from pyspark.sql.functions import udf, col, from_json
from pyspark.sql.types import FloatType, ArrayType, StringType, StructType, StructField, IntegerType
import nltk
from nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA
from pyspark.sql import SparkSession

# download the model
nltk.download('vader_lexicon')

# init the sentiment analysis object
sia = SIA()

# init Spark session
spark = SparkSession.builder \
    .master('local') \
    .appName("Sentiment Analysis") \
    .config("spark.jars.packages", "org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1") \
    .config("spark.sql.streaming.checkpointLocation", r"/tmp/") \
    .config("spark.driver.extraJavaOptions", "-Divy.cache.dir=/tmp -Divy.home=/tmp") \
    .getOrCreate()

# define a udf to perform sentiment analysis
def analyze_sentiment(message):
    # Perform sentiment analysis
    pol_score = sia.polarity_scores(message)
    # Return the compound score
    return [pol_score['neg'], pol_score['neu'], pol_score['pos'], pol_score['compound']]

# Register the function as a UDF
analyze_sentiment_udf = udf(lambda x:analyze_sentiment(x), ArrayType(FloatType()))

# define the schema for the JSON data
schema = StructType([
    StructField("user", StringType(), nullable=True),
    StructField("content", StringType(), nullable=True),
    StructField("url", StringType(), nullable=True),
    StructField("context", StringType(), nullable=True),
    StructField("score", IntegerType(), nullable=True),
    StructField("subreddit", StringType(), nullable=True),
    StructField("type", StringType(), nullable=True),
    StructField("id", StringType(), nullable=True),
    StructField("datetime", StringType(), nullable=True)  # Assuming the datetime is string type, you can change it to TimestampType if needed
])


# define the parameters for the input and output kafka broker and topic
kafka_broker = "kafka:9092"
input_kafka_topic = "reddit_post_filtered"
output_kafka_topic = "reddit_post_sa"

# Subscribe to the input topic
df = spark \
    .readStream \
    .format("kafka") \
    .option("kafka.bootstrap.servers", kafka_broker) \
    .option("subscribe", input_kafka_topic) \
    .load()

# parse the JSON data in the 'value' column using the defined schema then create a dataframe containing the reddit data
df = df.select(col("value").cast("string")) \
    .withColumn("value", from_json("value", schema)) \

parsed_df = df \
    .select("value.*")

# perform sentiment analysis on the parsed dataframe 
sa_reddit_df = parsed_df.withColumn('sentiment_score', analyze_sentiment_udf(parsed_df['content']))

# split the sentiment_score column into separate columns
sa_reddit_df = sa_reddit_df.withColumn("negative", sa_reddit_df["sentiment_score"][0]) \
            .withColumn("neutral", sa_reddit_df["sentiment_score"][1]) \
            .withColumn("positive", sa_reddit_df["sentiment_score"][2]) \
            .withColumn("compound", sa_reddit_df["sentiment_score"][3]) \
            .drop('sentiment_score')  # drop sentiment_score column after splitting

# stream the data to kafka
kafka_write = sa_reddit_df \
    .selectExpr("'' AS key", "to_json(struct(*)) AS value") \
    .writeStream \
    .format("kafka") \
    .option("kafka.bootstrap.servers", kafka_broker) \
    .option("topic", output_kafka_topic) \
    .start()

# Wait for the termination of the query
kafka_write.awaitTermination()
[WI-687][TI-1884] - [INFO] 2024-04-27 21:39:40.020 +0800 o.a.d.p.t.p.PythonTask:[131] - tenantCode :default, task dir:/tmp/dolphinscheduler/exec/process/default/13010050770016/13386218435520_15/687/1884
[WI-687][TI-1884] - [INFO] 2024-04-27 21:39:40.021 +0800 o.a.d.p.t.p.PythonTask:[134] - generate python script file:/tmp/dolphinscheduler/exec/process/default/13010050770016/13386218435520_15/687/1884/py_687_1884.py
[WI-687][TI-1884] - [INFO] 2024-04-27 21:39:40.027 +0800 o.a.d.p.t.p.PythonTask:[141] - #-*- encoding=utf8 -*-

# use kafka streaming api
from pyspark.sql.functions import udf, col, from_json
from pyspark.sql.types import FloatType, ArrayType, StringType, StructType, StructField, IntegerType
import nltk
from nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA
from pyspark.sql import SparkSession

# download the model
nltk.download('vader_lexicon')

# init the sentiment analysis object
sia = SIA()

# init Spark session
spark = SparkSession.builder \
    .master('local') \
    .appName("Sentiment Analysis") \
    .config("spark.jars.packages", "org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1") \
    .config("spark.sql.streaming.checkpointLocation", r"/tmp/") \
    .config("spark.driver.extraJavaOptions", "-Divy.cache.dir=/tmp -Divy.home=/tmp") \
    .getOrCreate()

# define a udf to perform sentiment analysis
def analyze_sentiment(message):
    # Perform sentiment analysis
    pol_score = sia.polarity_scores(message)
    # Return the compound score
    return [pol_score['neg'], pol_score['neu'], pol_score['pos'], pol_score['compound']]

# Register the function as a UDF
analyze_sentiment_udf = udf(lambda x:analyze_sentiment(x), ArrayType(FloatType()))

# define the schema for the JSON data
schema = StructType([
    StructField("user", StringType(), nullable=True),
    StructField("content", StringType(), nullable=True),
    StructField("url", StringType(), nullable=True),
    StructField("context", StringType(), nullable=True),
    StructField("score", IntegerType(), nullable=True),
    StructField("subreddit", StringType(), nullable=True),
    StructField("type", StringType(), nullable=True),
    StructField("id", StringType(), nullable=True),
    StructField("datetime", StringType(), nullable=True)  # Assuming the datetime is string type, you can change it to TimestampType if needed
])


# define the parameters for the input and output kafka broker and topic
kafka_broker = "kafka:9092"
input_kafka_topic = "reddit_post_filtered"
output_kafka_topic = "reddit_post_sa"

# Subscribe to the input topic
df = spark \
    .readStream \
    .format("kafka") \
    .option("kafka.bootstrap.servers", kafka_broker) \
    .option("subscribe", input_kafka_topic) \
    .load()

# parse the JSON data in the 'value' column using the defined schema then create a dataframe containing the reddit data
df = df.select(col("value").cast("string")) \
    .withColumn("value", from_json("value", schema)) \

parsed_df = df \
    .select("value.*")

# perform sentiment analysis on the parsed dataframe 
sa_reddit_df = parsed_df.withColumn('sentiment_score', analyze_sentiment_udf(parsed_df['content']))

# split the sentiment_score column into separate columns
sa_reddit_df = sa_reddit_df.withColumn("negative", sa_reddit_df["sentiment_score"][0]) \
            .withColumn("neutral", sa_reddit_df["sentiment_score"][1]) \
            .withColumn("positive", sa_reddit_df["sentiment_score"][2]) \
            .withColumn("compound", sa_reddit_df["sentiment_score"][3]) \
            .drop('sentiment_score')  # drop sentiment_score column after splitting

# stream the data to kafka
kafka_write = sa_reddit_df \
    .selectExpr("'' AS key", "to_json(struct(*)) AS value") \
    .writeStream \
    .format("kafka") \
    .option("kafka.bootstrap.servers", kafka_broker) \
    .option("topic", output_kafka_topic) \
    .start()

# Wait for the termination of the query
kafka_write.awaitTermination()
[WI-687][TI-1884] - [INFO] 2024-04-27 21:39:40.036 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-687][TI-1884] - [INFO] 2024-04-27 21:39:40.037 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-687][TI-1884] - [INFO] 2024-04-27 21:39:40.037 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export PYSPARK_DRIVER_PYTHON=/bin/python3.11
export PYSPARK_PYTHON=/bin/python3.11
export PYTHON_LAUNCHER=/bin/python3.11
export NLTK_DATA=/local_storage/nltk_data
${PYTHON_LAUNCHER} /tmp/dolphinscheduler/exec/process/default/13010050770016/13386218435520_15/687/1884/py_687_1884.py
[WI-687][TI-1884] - [INFO] 2024-04-27 21:39:40.037 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-687][TI-1884] - [INFO] 2024-04-27 21:39:40.037 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13386218435520_15/687/1884/687_1884.sh
[WI-687][TI-1884] - [INFO] 2024-04-27 21:39:40.055 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 1366
[WI-0][TI-1884] - [INFO] 2024-04-27 21:39:40.875 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1884, success=true)
[WI-0][TI-1884] - [INFO] 2024-04-27 21:39:40.905 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1884)
[WI-0][TI-0] - [INFO] 2024-04-27 21:39:41.057 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
[WI-0][TI-0] - [INFO] 2024-04-27 21:39:41.266 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8074866310160428 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:39:42.065 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	[nltk_data] Downloading package vader_lexicon to
	[nltk_data]     /local_storage/nltk_data...
	[nltk_data]   Package vader_lexicon is already up-to-date!
[WI-0][TI-0] - [INFO] 2024-04-27 21:39:42.283 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7597765363128492 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:39:43.300 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9021406727828746 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:39:44.301 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8666666666666667 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:39:45.302 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8618618618618619 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:39:46.314 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9411764705882353 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:39:47.325 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.845679012345679 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:39:48.111 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	:: loading settings :: url = jar:file:/opt/spark-3.5.1-bin-hadoop3/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml
	Ivy Default Cache set to: /tmp
	The jars for the packages stored in: /tmp/jars
	org.apache.spark#spark-sql-kafka-0-10_2.12 added as a dependency
	:: resolving dependencies :: org.apache.spark#spark-submit-parent-1f8f7fc0-07eb-4035-abd6-2a523ddb7f53;1.0
		confs: [default]
[WI-0][TI-0] - [INFO] 2024-04-27 21:39:48.329 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7467105263157895 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:39:49.117 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
		found org.apache.spark#spark-sql-kafka-0-10_2.12;3.5.1 in central
		found org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.5.1 in central
		found org.apache.kafka#kafka-clients;3.4.1 in central
		found org.lz4#lz4-java;1.8.0 in central
		found org.xerial.snappy#snappy-java;1.1.10.3 in central
		found org.slf4j#slf4j-api;2.0.7 in central
		found org.apache.hadoop#hadoop-client-runtime;3.3.4 in central
		found org.apache.hadoop#hadoop-client-api;3.3.4 in central
[WI-0][TI-0] - [INFO] 2024-04-27 21:39:49.332 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8933333333333333 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:39:50.120 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
		found commons-logging#commons-logging;1.1.3 in central
		found com.google.code.findbugs#jsr305;3.0.0 in central
		found org.apache.commons#commons-pool2;2.11.1 in central
	:: resolution report :: resolve 1636ms :: artifacts dl 104ms
		:: modules in use:
		com.google.code.findbugs#jsr305;3.0.0 from central in [default]
		commons-logging#commons-logging;1.1.3 from central in [default]
		org.apache.commons#commons-pool2;2.11.1 from central in [default]
		org.apache.hadoop#hadoop-client-api;3.3.4 from central in [default]
		org.apache.hadoop#hadoop-client-runtime;3.3.4 from central in [default]
		org.apache.kafka#kafka-clients;3.4.1 from central in [default]
		org.apache.spark#spark-sql-kafka-0-10_2.12;3.5.1 from central in [default]
		org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.5.1 from central in [default]
		org.lz4#lz4-java;1.8.0 from central in [default]
		org.slf4j#slf4j-api;2.0.7 from central in [default]
		org.xerial.snappy#snappy-java;1.1.10.3 from central in [default]
		---------------------------------------------------------------------
		|                  |            modules            ||   artifacts   |
		|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
		---------------------------------------------------------------------
		|      default     |   11  |   0   |   0   |   0   ||   11  |   0   |
		---------------------------------------------------------------------
	:: retrieving :: org.apache.spark#spark-submit-parent-1f8f7fc0-07eb-4035-abd6-2a523ddb7f53
		confs: [default]
		0 artifacts copied, 11 already retrieved (0kB/27ms)
[WI-0][TI-0] - [INFO] 2024-04-27 21:39:50.342 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.86478139298424 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:39:51.124 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/27 21:39:50 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[WI-0][TI-0] - [INFO] 2024-04-27 21:39:51.361 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.852112676056338 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:39:52.127 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	Setting default log level to "WARN".
	To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[WI-0][TI-0] - [INFO] 2024-04-27 21:39:52.392 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7363636363636363 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:39:53.410 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7692307692307692 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:39:54.472 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8306777829241933 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:39:56.154 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/27 21:39:55 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
[WI-0][TI-0] - [INFO] 2024-04-27 21:39:56.516 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7658402203856749 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:39:58.597 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8264705882352941 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:39:59.643 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9195710455764075 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:40:00.660 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7861635220125787 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:40:01.662 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8658008658008658 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:40:02.671 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8562091503267973 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:40:03.672 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8356643356643356 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:40:04.675 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8863636363636364 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:40:08.189 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/27 21:40:07 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.
[WI-0][TI-0] - [INFO] 2024-04-27 21:40:10.205 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/27 21:40:09 WARN AdminClientConfig: These configurations '[key.deserializer, value.deserializer, enable.auto.commit, max.poll.records, auto.offset.reset]' were supplied but are not used yet.
[WI-0][TI-0] - [INFO] 2024-04-27 21:40:11.261 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1885, taskName=sentiment anaysis, firstSubmitTime=1714225211237, startTime=0, taskType=PYTHON, workflowInstanceHost=172.18.0.9:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13386218435520, processDefineVersion=15, appIds=null, processInstanceId=688, scheduleTime=0, globalParams=null, executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[],"rawScript":"# use kafka streaming api\nfrom pyspark.sql.functions import udf, col, from_json\nfrom pyspark.sql.types import FloatType, ArrayType, StringType, StructType, StructField, IntegerType\nimport nltk\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA\nfrom pyspark.sql import SparkSession\n\n# download the model\nnltk.download('vader_lexicon')\n\n# init the sentiment analysis object\nsia = SIA()\n\n# init Spark session\nspark = SparkSession.builder \\\n    .master('local') \\\n    .appName(\"Sentiment Analysis\") \\\n    .config(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1\") \\\n    .config(\"spark.sql.streaming.checkpointLocation\", r\"/tmp/\") \\\n    .config(\"spark.driver.extraJavaOptions\", \"-Divy.cache.dir=/tmp -Divy.home=/tmp\") \\\n    .getOrCreate()\n\n# define a udf to perform sentiment analysis\ndef analyze_sentiment(message):\n    # Perform sentiment analysis\n    pol_score = sia.polarity_scores(message)\n    # Return the compound score\n    return [pol_score['neg'], pol_score['neu'], pol_score['pos'], pol_score['compound']]\n\n# Register the function as a UDF\nanalyze_sentiment_udf = udf(lambda x:analyze_sentiment(x), ArrayType(FloatType()))\n\n# define the schema for the JSON data\nschema = StructType([\n    StructField(\"user\", StringType(), nullable=True),\n    StructField(\"content\", StringType(), nullable=True),\n    StructField(\"url\", StringType(), nullable=True),\n    StructField(\"context\", StringType(), nullable=True),\n    StructField(\"score\", IntegerType(), nullable=True),\n    StructField(\"subreddit\", StringType(), nullable=True),\n    StructField(\"type\", StringType(), nullable=True),\n    StructField(\"id\", StringType(), nullable=True),\n    StructField(\"datetime\", StringType(), nullable=True)  # Assuming the datetime is string type, you can change it to TimestampType if needed\n])\n\n\n# define the parameters for the input and output kafka broker and topic\nkafka_broker = \"kafka:9092\"\ninput_kafka_topic = \"reddit_post_filtered\"\noutput_kafka_topic = \"reddit_post_sa\"\n\n# Subscribe to the input topic\ndf = spark \\\n    .readStream \\\n    .format(\"kafka\") \\\n    .option(\"kafka.bootstrap.servers\", kafka_broker) \\\n    .option(\"subscribe\", input_kafka_topic) \\\n    .load()\n\n# parse the JSON data in the 'value' column using the defined schema then create a dataframe containing the reddit data\ndf = df.select(col(\"value\").cast(\"string\")) \\\n    .withColumn(\"value\", from_json(\"value\", schema)) \\\n\nparsed_df = df \\\n    .select(\"value.*\")\n\n# perform sentiment analysis on the parsed dataframe \nsa_reddit_df = parsed_df.withColumn('sentiment_score', analyze_sentiment_udf(parsed_df['content']))\n\n# split the sentiment_score column into separate columns\nsa_reddit_df = sa_reddit_df.withColumn(\"negative\", sa_reddit_df[\"sentiment_score\"][0]) \\\n            .withColumn(\"neutral\", sa_reddit_df[\"sentiment_score\"][1]) \\\n            .withColumn(\"positive\", sa_reddit_df[\"sentiment_score\"][2]) \\\n            .withColumn(\"compound\", sa_reddit_df[\"sentiment_score\"][3]) \\\n            .drop('sentiment_score')  # drop sentiment_score column after splitting\n\n# stream the data to kafka\nkafka_write = sa_reddit_df \\\n    .selectExpr(\"'' AS key\", \"to_json(struct(*)) AS value\") \\\n    .writeStream \\\n    .format(\"kafka\") \\\n    .option(\"kafka.bootstrap.servers\", kafka_broker) \\\n    .option(\"topic\", output_kafka_topic) \\\n    .start()\n\n# Wait for the termination of the query\nkafka_write.awaitTermination()","resourceList":[]}, environmentConfig=export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export PYSPARK_DRIVER_PYTHON=/bin/python3.11
export PYSPARK_PYTHON=/bin/python3.11
export PYTHON_LAUNCHER=/bin/python3.11
export NLTK_DATA=/local_storage/nltk_data, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='sentiment anaysis'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='688'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240427'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240426'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1885'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='sentiment_analysis_subprocess'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13386027735104'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13386218435520'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240427214011'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=null, dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-688][TI-1885] - [INFO] 2024-04-27 21:40:11.274 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: sentiment anaysis to wait queue success
[WI-688][TI-1885] - [INFO] 2024-04-27 21:40:11.276 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-688][TI-1885] - [INFO] 2024-04-27 21:40:11.278 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-688][TI-1885] - [INFO] 2024-04-27 21:40:11.278 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-688][TI-1885] - [INFO] 2024-04-27 21:40:11.279 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-688][TI-1885] - [INFO] 2024-04-27 21:40:11.279 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1714225211279
[WI-688][TI-1885] - [INFO] 2024-04-27 21:40:11.286 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 688_1885
[WI-688][TI-1885] - [INFO] 2024-04-27 21:40:11.288 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1885,
  "taskName" : "sentiment anaysis",
  "firstSubmitTime" : 1714225211237,
  "startTime" : 1714225211279,
  "taskType" : "PYTHON",
  "workflowInstanceHost" : "172.18.0.9:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240427/13386218435520/15/688/1885.log",
  "processId" : 0,
  "processDefineCode" : 13386218435520,
  "processDefineVersion" : 15,
  "processInstanceId" : 688,
  "scheduleTime" : 0,
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[],\"rawScript\":\"# use kafka streaming api\\nfrom pyspark.sql.functions import udf, col, from_json\\nfrom pyspark.sql.types import FloatType, ArrayType, StringType, StructType, StructField, IntegerType\\nimport nltk\\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA\\nfrom pyspark.sql import SparkSession\\n\\n# download the model\\nnltk.download('vader_lexicon')\\n\\n# init the sentiment analysis object\\nsia = SIA()\\n\\n# init Spark session\\nspark = SparkSession.builder \\\\\\n    .master('local') \\\\\\n    .appName(\\\"Sentiment Analysis\\\") \\\\\\n    .config(\\\"spark.jars.packages\\\", \\\"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1\\\") \\\\\\n    .config(\\\"spark.sql.streaming.checkpointLocation\\\", r\\\"/tmp/\\\") \\\\\\n    .config(\\\"spark.driver.extraJavaOptions\\\", \\\"-Divy.cache.dir=/tmp -Divy.home=/tmp\\\") \\\\\\n    .getOrCreate()\\n\\n# define a udf to perform sentiment analysis\\ndef analyze_sentiment(message):\\n    # Perform sentiment analysis\\n    pol_score = sia.polarity_scores(message)\\n    # Return the compound score\\n    return [pol_score['neg'], pol_score['neu'], pol_score['pos'], pol_score['compound']]\\n\\n# Register the function as a UDF\\nanalyze_sentiment_udf = udf(lambda x:analyze_sentiment(x), ArrayType(FloatType()))\\n\\n# define the schema for the JSON data\\nschema = StructType([\\n    StructField(\\\"user\\\", StringType(), nullable=True),\\n    StructField(\\\"content\\\", StringType(), nullable=True),\\n    StructField(\\\"url\\\", StringType(), nullable=True),\\n    StructField(\\\"context\\\", StringType(), nullable=True),\\n    StructField(\\\"score\\\", IntegerType(), nullable=True),\\n    StructField(\\\"subreddit\\\", StringType(), nullable=True),\\n    StructField(\\\"type\\\", StringType(), nullable=True),\\n    StructField(\\\"id\\\", StringType(), nullable=True),\\n    StructField(\\\"datetime\\\", StringType(), nullable=True)  # Assuming the datetime is string type, you can change it to TimestampType if needed\\n])\\n\\n\\n# define the parameters for the input and output kafka broker and topic\\nkafka_broker = \\\"kafka:9092\\\"\\ninput_kafka_topic = \\\"reddit_post_filtered\\\"\\noutput_kafka_topic = \\\"reddit_post_sa\\\"\\n\\n# Subscribe to the input topic\\ndf = spark \\\\\\n    .readStream \\\\\\n    .format(\\\"kafka\\\") \\\\\\n    .option(\\\"kafka.bootstrap.servers\\\", kafka_broker) \\\\\\n    .option(\\\"subscribe\\\", input_kafka_topic) \\\\\\n    .load()\\n\\n# parse the JSON data in the 'value' column using the defined schema then create a dataframe containing the reddit data\\ndf = df.select(col(\\\"value\\\").cast(\\\"string\\\")) \\\\\\n    .withColumn(\\\"value\\\", from_json(\\\"value\\\", schema)) \\\\\\n\\nparsed_df = df \\\\\\n    .select(\\\"value.*\\\")\\n\\n# perform sentiment analysis on the parsed dataframe \\nsa_reddit_df = parsed_df.withColumn('sentiment_score', analyze_sentiment_udf(parsed_df['content']))\\n\\n# split the sentiment_score column into separate columns\\nsa_reddit_df = sa_reddit_df.withColumn(\\\"negative\\\", sa_reddit_df[\\\"sentiment_score\\\"][0]) \\\\\\n            .withColumn(\\\"neutral\\\", sa_reddit_df[\\\"sentiment_score\\\"][1]) \\\\\\n            .withColumn(\\\"positive\\\", sa_reddit_df[\\\"sentiment_score\\\"][2]) \\\\\\n            .withColumn(\\\"compound\\\", sa_reddit_df[\\\"sentiment_score\\\"][3]) \\\\\\n            .drop('sentiment_score')  # drop sentiment_score column after splitting\\n\\n# stream the data to kafka\\nkafka_write = sa_reddit_df \\\\\\n    .selectExpr(\\\"'' AS key\\\", \\\"to_json(struct(*)) AS value\\\") \\\\\\n    .writeStream \\\\\\n    .format(\\\"kafka\\\") \\\\\\n    .option(\\\"kafka.bootstrap.servers\\\", kafka_broker) \\\\\\n    .option(\\\"topic\\\", output_kafka_topic) \\\\\\n    .start()\\n\\n# Wait for the termination of the query\\nkafka_write.awaitTermination()\",\"resourceList\":[]}",
  "environmentConfig" : "export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3\nexport JAVA_HOME=/opt/java/openjdk\nexport PYSPARK_DRIVER_PYTHON=/bin/python3.11\nexport PYSPARK_PYTHON=/bin/python3.11\nexport PYTHON_LAUNCHER=/bin/python3.11\nexport NLTK_DATA=/local_storage/nltk_data",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "sentiment anaysis"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "688"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240427"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240426"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1885"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "sentiment_analysis_subprocess"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13386027735104"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13386218435520"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240427214011"
    }
  },
  "taskAppId" : "688_1885",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-688][TI-1885] - [INFO] 2024-04-27 21:40:11.303 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-688][TI-1885] - [INFO] 2024-04-27 21:40:11.304 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-688][TI-1885] - [INFO] 2024-04-27 21:40:11.304 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-688][TI-1885] - [INFO] 2024-04-27 21:40:11.312 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-688][TI-1885] - [INFO] 2024-04-27 21:40:11.313 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-688][TI-1885] - [INFO] 2024-04-27 21:40:11.314 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13386218435520_15/688/1885 check successfully
[WI-688][TI-1885] - [INFO] 2024-04-27 21:40:11.314 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.python.PythonTaskChannel successfully
[WI-688][TI-1885] - [INFO] 2024-04-27 21:40:11.315 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-688][TI-1885] - [INFO] 2024-04-27 21:40:11.316 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-688][TI-1885] - [INFO] 2024-04-27 21:40:11.334 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: PYTHON create successfully
[WI-688][TI-1885] - [INFO] 2024-04-27 21:40:11.335 +0800 o.a.d.p.t.p.PythonTask:[75] - Initialize python task params {
  "localParams" : [ ],
  "varPool" : null,
  "rawScript" : "# use kafka streaming api\nfrom pyspark.sql.functions import udf, col, from_json\nfrom pyspark.sql.types import FloatType, ArrayType, StringType, StructType, StructField, IntegerType\nimport nltk\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA\nfrom pyspark.sql import SparkSession\n\n# download the model\nnltk.download('vader_lexicon')\n\n# init the sentiment analysis object\nsia = SIA()\n\n# init Spark session\nspark = SparkSession.builder \\\n    .master('local') \\\n    .appName(\"Sentiment Analysis\") \\\n    .config(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1\") \\\n    .config(\"spark.sql.streaming.checkpointLocation\", r\"/tmp/\") \\\n    .config(\"spark.driver.extraJavaOptions\", \"-Divy.cache.dir=/tmp -Divy.home=/tmp\") \\\n    .getOrCreate()\n\n# define a udf to perform sentiment analysis\ndef analyze_sentiment(message):\n    # Perform sentiment analysis\n    pol_score = sia.polarity_scores(message)\n    # Return the compound score\n    return [pol_score['neg'], pol_score['neu'], pol_score['pos'], pol_score['compound']]\n\n# Register the function as a UDF\nanalyze_sentiment_udf = udf(lambda x:analyze_sentiment(x), ArrayType(FloatType()))\n\n# define the schema for the JSON data\nschema = StructType([\n    StructField(\"user\", StringType(), nullable=True),\n    StructField(\"content\", StringType(), nullable=True),\n    StructField(\"url\", StringType(), nullable=True),\n    StructField(\"context\", StringType(), nullable=True),\n    StructField(\"score\", IntegerType(), nullable=True),\n    StructField(\"subreddit\", StringType(), nullable=True),\n    StructField(\"type\", StringType(), nullable=True),\n    StructField(\"id\", StringType(), nullable=True),\n    StructField(\"datetime\", StringType(), nullable=True)  # Assuming the datetime is string type, you can change it to TimestampType if needed\n])\n\n\n# define the parameters for the input and output kafka broker and topic\nkafka_broker = \"kafka:9092\"\ninput_kafka_topic = \"reddit_post_filtered\"\noutput_kafka_topic = \"reddit_post_sa\"\n\n# Subscribe to the input topic\ndf = spark \\\n    .readStream \\\n    .format(\"kafka\") \\\n    .option(\"kafka.bootstrap.servers\", kafka_broker) \\\n    .option(\"subscribe\", input_kafka_topic) \\\n    .load()\n\n# parse the JSON data in the 'value' column using the defined schema then create a dataframe containing the reddit data\ndf = df.select(col(\"value\").cast(\"string\")) \\\n    .withColumn(\"value\", from_json(\"value\", schema)) \\\n\nparsed_df = df \\\n    .select(\"value.*\")\n\n# perform sentiment analysis on the parsed dataframe \nsa_reddit_df = parsed_df.withColumn('sentiment_score', analyze_sentiment_udf(parsed_df['content']))\n\n# split the sentiment_score column into separate columns\nsa_reddit_df = sa_reddit_df.withColumn(\"negative\", sa_reddit_df[\"sentiment_score\"][0]) \\\n            .withColumn(\"neutral\", sa_reddit_df[\"sentiment_score\"][1]) \\\n            .withColumn(\"positive\", sa_reddit_df[\"sentiment_score\"][2]) \\\n            .withColumn(\"compound\", sa_reddit_df[\"sentiment_score\"][3]) \\\n            .drop('sentiment_score')  # drop sentiment_score column after splitting\n\n# stream the data to kafka\nkafka_write = sa_reddit_df \\\n    .selectExpr(\"'' AS key\", \"to_json(struct(*)) AS value\") \\\n    .writeStream \\\n    .format(\"kafka\") \\\n    .option(\"kafka.bootstrap.servers\", kafka_broker) \\\n    .option(\"topic\", output_kafka_topic) \\\n    .start()\n\n# Wait for the termination of the query\nkafka_write.awaitTermination()",
  "resourceList" : [ ]
}
[WI-688][TI-1885] - [INFO] 2024-04-27 21:40:11.352 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-688][TI-1885] - [INFO] 2024-04-27 21:40:11.355 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: null successfully
[WI-688][TI-1885] - [INFO] 2024-04-27 21:40:11.356 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-688][TI-1885] - [INFO] 2024-04-27 21:40:11.356 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-688][TI-1885] - [INFO] 2024-04-27 21:40:11.356 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-688][TI-1885] - [INFO] 2024-04-27 21:40:11.356 +0800 o.a.d.p.t.p.PythonTask:[165] - raw python script : # use kafka streaming api
from pyspark.sql.functions import udf, col, from_json
from pyspark.sql.types import FloatType, ArrayType, StringType, StructType, StructField, IntegerType
import nltk
from nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA
from pyspark.sql import SparkSession

# download the model
nltk.download('vader_lexicon')

# init the sentiment analysis object
sia = SIA()

# init Spark session
spark = SparkSession.builder \
    .master('local') \
    .appName("Sentiment Analysis") \
    .config("spark.jars.packages", "org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1") \
    .config("spark.sql.streaming.checkpointLocation", r"/tmp/") \
    .config("spark.driver.extraJavaOptions", "-Divy.cache.dir=/tmp -Divy.home=/tmp") \
    .getOrCreate()

# define a udf to perform sentiment analysis
def analyze_sentiment(message):
    # Perform sentiment analysis
    pol_score = sia.polarity_scores(message)
    # Return the compound score
    return [pol_score['neg'], pol_score['neu'], pol_score['pos'], pol_score['compound']]

# Register the function as a UDF
analyze_sentiment_udf = udf(lambda x:analyze_sentiment(x), ArrayType(FloatType()))

# define the schema for the JSON data
schema = StructType([
    StructField("user", StringType(), nullable=True),
    StructField("content", StringType(), nullable=True),
    StructField("url", StringType(), nullable=True),
    StructField("context", StringType(), nullable=True),
    StructField("score", IntegerType(), nullable=True),
    StructField("subreddit", StringType(), nullable=True),
    StructField("type", StringType(), nullable=True),
    StructField("id", StringType(), nullable=True),
    StructField("datetime", StringType(), nullable=True)  # Assuming the datetime is string type, you can change it to TimestampType if needed
])


# define the parameters for the input and output kafka broker and topic
kafka_broker = "kafka:9092"
input_kafka_topic = "reddit_post_filtered"
output_kafka_topic = "reddit_post_sa"

# Subscribe to the input topic
df = spark \
    .readStream \
    .format("kafka") \
    .option("kafka.bootstrap.servers", kafka_broker) \
    .option("subscribe", input_kafka_topic) \
    .load()

# parse the JSON data in the 'value' column using the defined schema then create a dataframe containing the reddit data
df = df.select(col("value").cast("string")) \
    .withColumn("value", from_json("value", schema)) \

parsed_df = df \
    .select("value.*")

# perform sentiment analysis on the parsed dataframe 
sa_reddit_df = parsed_df.withColumn('sentiment_score', analyze_sentiment_udf(parsed_df['content']))

# split the sentiment_score column into separate columns
sa_reddit_df = sa_reddit_df.withColumn("negative", sa_reddit_df["sentiment_score"][0]) \
            .withColumn("neutral", sa_reddit_df["sentiment_score"][1]) \
            .withColumn("positive", sa_reddit_df["sentiment_score"][2]) \
            .withColumn("compound", sa_reddit_df["sentiment_score"][3]) \
            .drop('sentiment_score')  # drop sentiment_score column after splitting

# stream the data to kafka
kafka_write = sa_reddit_df \
    .selectExpr("'' AS key", "to_json(struct(*)) AS value") \
    .writeStream \
    .format("kafka") \
    .option("kafka.bootstrap.servers", kafka_broker) \
    .option("topic", output_kafka_topic) \
    .start()

# Wait for the termination of the query
kafka_write.awaitTermination()
[WI-688][TI-1885] - [INFO] 2024-04-27 21:40:11.357 +0800 o.a.d.p.t.p.PythonTask:[131] - tenantCode :default, task dir:/tmp/dolphinscheduler/exec/process/default/13010050770016/13386218435520_15/688/1885
[WI-688][TI-1885] - [INFO] 2024-04-27 21:40:11.357 +0800 o.a.d.p.t.p.PythonTask:[134] - generate python script file:/tmp/dolphinscheduler/exec/process/default/13010050770016/13386218435520_15/688/1885/py_688_1885.py
[WI-688][TI-1885] - [INFO] 2024-04-27 21:40:11.358 +0800 o.a.d.p.t.p.PythonTask:[141] - #-*- encoding=utf8 -*-

# use kafka streaming api
from pyspark.sql.functions import udf, col, from_json
from pyspark.sql.types import FloatType, ArrayType, StringType, StructType, StructField, IntegerType
import nltk
from nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA
from pyspark.sql import SparkSession

# download the model
nltk.download('vader_lexicon')

# init the sentiment analysis object
sia = SIA()

# init Spark session
spark = SparkSession.builder \
    .master('local') \
    .appName("Sentiment Analysis") \
    .config("spark.jars.packages", "org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1") \
    .config("spark.sql.streaming.checkpointLocation", r"/tmp/") \
    .config("spark.driver.extraJavaOptions", "-Divy.cache.dir=/tmp -Divy.home=/tmp") \
    .getOrCreate()

# define a udf to perform sentiment analysis
def analyze_sentiment(message):
    # Perform sentiment analysis
    pol_score = sia.polarity_scores(message)
    # Return the compound score
    return [pol_score['neg'], pol_score['neu'], pol_score['pos'], pol_score['compound']]

# Register the function as a UDF
analyze_sentiment_udf = udf(lambda x:analyze_sentiment(x), ArrayType(FloatType()))

# define the schema for the JSON data
schema = StructType([
    StructField("user", StringType(), nullable=True),
    StructField("content", StringType(), nullable=True),
    StructField("url", StringType(), nullable=True),
    StructField("context", StringType(), nullable=True),
    StructField("score", IntegerType(), nullable=True),
    StructField("subreddit", StringType(), nullable=True),
    StructField("type", StringType(), nullable=True),
    StructField("id", StringType(), nullable=True),
    StructField("datetime", StringType(), nullable=True)  # Assuming the datetime is string type, you can change it to TimestampType if needed
])


# define the parameters for the input and output kafka broker and topic
kafka_broker = "kafka:9092"
input_kafka_topic = "reddit_post_filtered"
output_kafka_topic = "reddit_post_sa"

# Subscribe to the input topic
df = spark \
    .readStream \
    .format("kafka") \
    .option("kafka.bootstrap.servers", kafka_broker) \
    .option("subscribe", input_kafka_topic) \
    .load()

# parse the JSON data in the 'value' column using the defined schema then create a dataframe containing the reddit data
df = df.select(col("value").cast("string")) \
    .withColumn("value", from_json("value", schema)) \

parsed_df = df \
    .select("value.*")

# perform sentiment analysis on the parsed dataframe 
sa_reddit_df = parsed_df.withColumn('sentiment_score', analyze_sentiment_udf(parsed_df['content']))

# split the sentiment_score column into separate columns
sa_reddit_df = sa_reddit_df.withColumn("negative", sa_reddit_df["sentiment_score"][0]) \
            .withColumn("neutral", sa_reddit_df["sentiment_score"][1]) \
            .withColumn("positive", sa_reddit_df["sentiment_score"][2]) \
            .withColumn("compound", sa_reddit_df["sentiment_score"][3]) \
            .drop('sentiment_score')  # drop sentiment_score column after splitting

# stream the data to kafka
kafka_write = sa_reddit_df \
    .selectExpr("'' AS key", "to_json(struct(*)) AS value") \
    .writeStream \
    .format("kafka") \
    .option("kafka.bootstrap.servers", kafka_broker) \
    .option("topic", output_kafka_topic) \
    .start()

# Wait for the termination of the query
kafka_write.awaitTermination()
[WI-688][TI-1885] - [INFO] 2024-04-27 21:40:11.382 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-688][TI-1885] - [INFO] 2024-04-27 21:40:11.382 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-688][TI-1885] - [INFO] 2024-04-27 21:40:11.383 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export PYSPARK_DRIVER_PYTHON=/bin/python3.11
export PYSPARK_PYTHON=/bin/python3.11
export PYTHON_LAUNCHER=/bin/python3.11
export NLTK_DATA=/local_storage/nltk_data
${PYTHON_LAUNCHER} /tmp/dolphinscheduler/exec/process/default/13010050770016/13386218435520_15/688/1885/py_688_1885.py
[WI-688][TI-1885] - [INFO] 2024-04-27 21:40:11.384 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-688][TI-1885] - [INFO] 2024-04-27 21:40:11.384 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13386218435520_15/688/1885/688_1885.sh
[WI-688][TI-1885] - [INFO] 2024-04-27 21:40:11.449 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 1608
[WI-0][TI-0] - [INFO] 2024-04-27 21:40:11.450 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
[WI-0][TI-0] - [INFO] 2024-04-27 21:40:11.757 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7639344262295081 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-1885] - [INFO] 2024-04-27 21:40:12.274 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1885, success=true)
[WI-0][TI-1885] - [INFO] 2024-04-27 21:40:12.292 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1885)
[WI-0][TI-0] - [INFO] 2024-04-27 21:40:12.800 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7510204081632653 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:40:13.494 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	[nltk_data] Downloading package vader_lexicon to
	[nltk_data]     /local_storage/nltk_data...
	[nltk_data]   Package vader_lexicon is already up-to-date!
[WI-0][TI-0] - [INFO] 2024-04-27 21:40:13.802 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7473684210526316 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:40:14.244 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/27 21:40:13 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
[WI-0][TI-0] - [INFO] 2024-04-27 21:40:14.829 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8933333333333334 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:40:15.856 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8803986710963455 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:40:16.262 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	
	[Stage 0:>                                                          (0 + 0) / 1]
	
	[Stage 0:>                                                          (0 + 1) / 1]
[WI-0][TI-0] - [INFO] 2024-04-27 21:40:16.870 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.854508453651997 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:40:17.873 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8101983002832862 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:40:18.268 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	
	                                                                                
[WI-0][TI-0] - [INFO] 2024-04-27 21:40:19.517 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	:: loading settings :: url = jar:file:/opt/spark-3.5.1-bin-hadoop3/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml
	Ivy Default Cache set to: /tmp
	The jars for the packages stored in: /tmp/jars
	org.apache.spark#spark-sql-kafka-0-10_2.12 added as a dependency
	:: resolving dependencies :: org.apache.spark#spark-submit-parent-e9babde4-d6a4-428b-8606-d865be5fbef1;1.0
		confs: [default]
[WI-0][TI-0] - [INFO] 2024-04-27 21:40:19.885 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7263843648208469 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:40:20.519 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
		found org.apache.spark#spark-sql-kafka-0-10_2.12;3.5.1 in central
		found org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.5.1 in central
		found org.apache.kafka#kafka-clients;3.4.1 in central
		found org.lz4#lz4-java;1.8.0 in central
		found org.xerial.snappy#snappy-java;1.1.10.3 in central
		found org.slf4j#slf4j-api;2.0.7 in central
		found org.apache.hadoop#hadoop-client-runtime;3.3.4 in central
		found org.apache.hadoop#hadoop-client-api;3.3.4 in central
		found commons-logging#commons-logging;1.1.3 in central
		found com.google.code.findbugs#jsr305;3.0.0 in central
		found org.apache.commons#commons-pool2;2.11.1 in central
	:: resolution report :: resolve 1179ms :: artifacts dl 35ms
		:: modules in use:
		com.google.code.findbugs#jsr305;3.0.0 from central in [default]
		commons-logging#commons-logging;1.1.3 from central in [default]
		org.apache.commons#commons-pool2;2.11.1 from central in [default]
		org.apache.hadoop#hadoop-client-api;3.3.4 from central in [default]
		org.apache.hadoop#hadoop-client-runtime;3.3.4 from central in [default]
		org.apache.kafka#kafka-clients;3.4.1 from central in [default]
		org.apache.spark#spark-sql-kafka-0-10_2.12;3.5.1 from central in [default]
		org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.5.1 from central in [default]
		org.lz4#lz4-java;1.8.0 from central in [default]
		org.slf4j#slf4j-api;2.0.7 from central in [default]
		org.xerial.snappy#snappy-java;1.1.10.3 from central in [default]
		---------------------------------------------------------------------
		|                  |            modules            ||   artifacts   |
		|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
		---------------------------------------------------------------------
		|      default     |   11  |   0   |   0   |   0   ||   11  |   0   |
		---------------------------------------------------------------------
	:: retrieving :: org.apache.spark#spark-submit-parent-e9babde4-d6a4-428b-8606-d865be5fbef1
		confs: [default]
		0 artifacts copied, 11 already retrieved (0kB/19ms)
[WI-0][TI-0] - [INFO] 2024-04-27 21:40:20.914 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7798165137614679 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:40:21.588 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/27 21:40:21 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[WI-0][TI-0] - [INFO] 2024-04-27 21:40:22.595 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	Setting default log level to "WARN".
	To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[WI-0][TI-0] - [INFO] 2024-04-27 21:40:23.932 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7319277108433735 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:40:24.614 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/27 21:40:23 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
	24/04/27 21:40:23 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
[WI-0][TI-0] - [INFO] 2024-04-27 21:40:29.977 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7766990291262136 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:40:31.040 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7745098039215685 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:40:32.046 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.927170868347339 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:40:33.050 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8734567901234568 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:40:34.068 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9335664335664335 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:40:35.094 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8516320474777448 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:40:36.103 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9632768361581922 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:40:37.116 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.969283276450512 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:40:37.722 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/27 21:40:37 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.
[WI-0][TI-0] - [INFO] 2024-04-27 21:40:38.122 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9712460063897763 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:40:38.513 +0800 o.a.d.s.w.r.o.TaskInstanceKillOperationFunction:[55] - Receive TaskInstanceKillRequest: TaskInstanceKillRequest(taskInstanceId=1885)
[WI-0][TI-1885] - [ERROR] 2024-04-27 21:40:38.568 +0800 o.a.d.s.w.r.o.TaskInstanceKillOperationFunction:[139] - kill task error
java.io.IOException: Cannot run program "pstree": error=2, No such file or directory
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1048)
	at org.apache.dolphinscheduler.common.shell.AbstractShell.runCommand(AbstractShell.java:138)
	at org.apache.dolphinscheduler.common.shell.AbstractShell.run(AbstractShell.java:118)
	at org.apache.dolphinscheduler.common.shell.ShellExecutor.execute(ShellExecutor.java:125)
	at org.apache.dolphinscheduler.common.shell.ShellExecutor.execCommand(ShellExecutor.java:103)
	at org.apache.dolphinscheduler.common.shell.ShellExecutor.execCommand(ShellExecutor.java:86)
	at org.apache.dolphinscheduler.common.utils.OSUtils.exeShell(OSUtils.java:345)
	at org.apache.dolphinscheduler.common.utils.OSUtils.exeCmd(OSUtils.java:334)
	at org.apache.dolphinscheduler.plugin.task.api.utils.ProcessUtils.getPidsStr(ProcessUtils.java:129)
	at org.apache.dolphinscheduler.server.worker.runner.operator.TaskInstanceKillOperationFunction.killProcess(TaskInstanceKillOperationFunction.java:130)
	at org.apache.dolphinscheduler.server.worker.runner.operator.TaskInstanceKillOperationFunction.doKill(TaskInstanceKillOperationFunction.java:96)
	at org.apache.dolphinscheduler.server.worker.runner.operator.TaskInstanceKillOperationFunction.operate(TaskInstanceKillOperationFunction.java:69)
	at org.apache.dolphinscheduler.server.worker.rpc.TaskInstanceOperatorImpl.killTask(TaskInstanceOperatorImpl.java:49)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.dolphinscheduler.extract.base.server.ServerMethodInvokerImpl.invoke(ServerMethodInvokerImpl.java:41)
	at org.apache.dolphinscheduler.extract.base.server.JdkDynamicServerHandler.lambda$processReceived$0(JdkDynamicServerHandler.java:108)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.io.IOException: error=2, No such file or directory
	at java.lang.UNIXProcess.forkAndExec(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:247)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	... 21 common frames omitted
[WI-0][TI-1885] - [INFO] 2024-04-27 21:40:38.606 +0800 o.a.d.p.t.a.u.ProcessUtils:[182] - Get appIds from worker 172.18.1.1:1234, taskLogPath: /opt/dolphinscheduler/logs/20240427/13386218435520/15/688/1885.log
[WI-0][TI-1885] - [INFO] 2024-04-27 21:40:38.608 +0800 o.a.d.p.t.a.u.LogUtils:[79] - Start finding appId in /opt/dolphinscheduler/logs/20240427/13386218435520/15/688/1885.log, fetch way: log 
[WI-0][TI-1885] - [INFO] 2024-04-27 21:40:38.615 +0800 o.a.d.p.t.a.u.ProcessUtils:[188] - The appId is empty
[WI-0][TI-1885] - [INFO] 2024-04-27 21:40:38.616 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[220] - Begin to kill process process, pid is : 1608
[WI-0][TI-0] - [INFO] 2024-04-27 21:40:39.140 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9966002416695681 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:40:40.171 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9732937685459941 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:40:41.216 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9191229748137844 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:40:42.225 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9858757062146892 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:40:43.238 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.944954128440367 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [ERROR] 2024-04-27 21:40:43.591 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[279] - Parse var pool error
java.io.IOException: Stream closed
	at java.io.BufferedInputStream.getBufIfOpen(BufferedInputStream.java:170)
	at java.io.BufferedInputStream.read1(BufferedInputStream.java:283)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:345)
	at sun.nio.cs.StreamDecoder.readBytes(StreamDecoder.java:284)
	at sun.nio.cs.StreamDecoder.implRead(StreamDecoder.java:326)
	at sun.nio.cs.StreamDecoder.read(StreamDecoder.java:178)
	at java.io.InputStreamReader.read(InputStreamReader.java:184)
	at java.io.BufferedReader.fill(BufferedReader.java:161)
	at java.io.BufferedReader.readLine(BufferedReader.java:324)
	at java.io.BufferedReader.readLine(BufferedReader.java:389)
	at org.apache.dolphinscheduler.plugin.task.api.AbstractCommandExecutor.lambda$parseProcessOutput$1(AbstractCommandExecutor.java:273)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
[WI-0][TI-1885] - [INFO] 2024-04-27 21:40:43.627 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[225] - Success kill task: 688_1885, pid: 1608
[WI-0][TI-1885] - [INFO] 2024-04-27 21:40:43.628 +0800 o.a.d.s.w.r.o.TaskInstanceKillOperationFunction:[119] - kill task by cancelApplication, taskInstanceId: 1885
[WI-688][TI-1885] - [INFO] 2024-04-27 21:40:43.771 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has killed. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13386218435520_15/688/1885, processId:1608 ,exitStatusCode:137 ,processWaitForStatus:true ,processExitValue:137
[WI-688][TI-1885] - [INFO] 2024-04-27 21:40:43.774 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-688][TI-1885] - [INFO] 2024-04-27 21:40:43.776 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-688][TI-1885] - [INFO] 2024-04-27 21:40:43.777 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-688][TI-1885] - [INFO] 2024-04-27 21:40:43.779 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-688][TI-1885] - [INFO] 2024-04-27 21:40:43.803 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: KILL to master : 172.18.1.1:1234
[WI-688][TI-1885] - [INFO] 2024-04-27 21:40:43.803 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-688][TI-1885] - [INFO] 2024-04-27 21:40:43.804 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13386218435520_15/688/1885
[WI-688][TI-1885] - [INFO] 2024-04-27 21:40:43.805 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13386218435520_15/688/1885
[WI-688][TI-1885] - [INFO] 2024-04-27 21:40:43.806 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-0] - [INFO] 2024-04-27 21:40:44.247 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8508474576271187 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:40:45.251 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8666666666666667 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:40:46.257 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7647058823529411 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:40:47.268 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.957754436221851 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:40:48.296 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8253012048192772 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:40:49.299 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8737864077669903 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:40:50.301 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.888888888888889 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:40:51.348 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9162011173184358 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:40:52.352 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.925 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:40:53.358 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8333333333333333 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:40:54.364 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7865497076023391 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:40:55.370 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7887323943661972 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:40:56.420 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9103641456582632 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:40:57.421 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9211347179119918 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:40:58.423 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.937142857142857 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:40:59.428 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9230769230769231 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:41:00.432 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9709302325581395 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:41:01.497 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9720670391061452 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:41:02.510 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9371185754755161 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:41:04.913 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9028871391076115 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:41:05.942 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7110481586402266 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:41:07.969 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8197674418604651 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:41:09.049 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8708791208791209 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:41:10.056 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8338368580060423 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:41:22.761 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9090909090909091 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:41:24.822 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7931034482758621 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:41:25.856 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8421052631578947 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:41:25.886 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	
	[Stage 3:>                                                          (0 + 1) / 1]
[WI-0][TI-0] - [INFO] 2024-04-27 21:41:26.859 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8542274052478134 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:41:26.923 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	
	                                                                                
[WI-0][TI-0] - [INFO] 2024-04-27 21:41:27.874 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	
	[Stage 1:>                                                          (0 + 1) / 1]
[WI-0][TI-0] - [INFO] 2024-04-27 21:41:27.875 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9025974025974026 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:41:28.921 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8846153846153846 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:41:29.941 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8473684210526315 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:41:30.981 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9737704918032786 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:41:31.944 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/27 21:41:31 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[WI-0][TI-0] - [INFO] 2024-04-27 21:41:32.143 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.946058091286307 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:41:33.164 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9940476190476191 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:41:34.166 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:41:35.167 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8456375838926175 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:41:35.970 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	
	                                                                                
[WI-0][TI-0] - [INFO] 2024-04-27 21:41:36.205 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9749303621169916 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:41:37.217 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.0029498525073748 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:41:38.227 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.94 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:41:39.243 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9530386740331492 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:41:40.269 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9553072625698324 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:41:41.279 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9697802197802198 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:41:42.281 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9452554744525549 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:41:43.286 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9622093023255813 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:41:44.294 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9697802197802198 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:41:45.313 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8846153846153846 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:41:52.607 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8214285714285714 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-1885] - [INFO] 2024-04-27 21:41:54.028 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1885, processInstanceId=688, status=9, startTime=1714225211279, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240427/13386218435520/15/688/1885.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13386218435520_15/688/1885, endTime=1714225243778, processId=1608, appIds=null, varPool=[], eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1885] - [INFO] 2024-04-27 21:41:54.033 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1885, processInstanceId=688, status=9, startTime=1714225211279, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240427/13386218435520/15/688/1885.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13386218435520_15/688/1885, endTime=1714225243778, processId=1608, appIds=null, varPool=[], eventCreateTime=0, eventSendTime=1714225314028)
[WI-0][TI-0] - [INFO] 2024-04-27 21:41:59.761 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8813559322033898 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:42:03.810 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.845679012345679 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:42:22.877 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7208588957055214 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:42:24.917 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9228723404255319 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:42:25.957 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9760000000000001 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:42:26.981 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9446808510638297 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:42:27.984 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9050445103857567 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:42:28.987 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8902439024390243 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:42:34.010 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8633720930232558 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:42:40.160 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7314814814814815 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:42:48.193 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8353293413173652 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:42:48.396 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	
	[Stage 4:>                                                          (0 + 1) / 1]
	
	                                                                                
[WI-0][TI-0] - [INFO] 2024-04-27 21:42:49.206 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9040247678018576 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:42:50.210 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	
	[Stage 2:>                                                          (0 + 1) / 1]
	24/04/27 21:42:49 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[WI-0][TI-0] - [INFO] 2024-04-27 21:42:50.211 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9708029197080292 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:42:51.238 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9750692520775623 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:42:52.219 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	
	                                                                                
[WI-0][TI-0] - [INFO] 2024-04-27 21:42:52.249 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9469026548672567 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:42:53.259 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9833333333333334 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:42:54.280 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9701492537313433 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:42:55.283 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9026548672566372 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:42:56.309 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9570200573065903 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:42:57.316 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7175141242937852 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:43:04.358 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9056047197640118 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:43:05.463 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9159663865546217 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:43:06.472 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9523809523809523 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:43:07.498 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9642857142857143 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:43:08.541 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9940476190476191 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:43:09.552 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9573863636363635 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:43:10.570 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7303030303030303 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:43:15.647 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8898305084745762 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:43:19.683 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7113702623906705 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:43:22.727 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7309941520467835 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:43:23.784 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.861271676300578 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:43:24.810 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.934844192634561 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:43:37.876 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9174041297935103 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:43:38.915 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9116809116809117 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:43:39.920 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8187134502923976 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:43:43.551 +0800 o.a.d.s.w.r.o.TaskInstanceKillOperationFunction:[55] - Receive TaskInstanceKillRequest: TaskInstanceKillRequest(taskInstanceId=1884)
[WI-0][TI-1884] - [ERROR] 2024-04-27 21:43:43.566 +0800 o.a.d.s.w.r.o.TaskInstanceKillOperationFunction:[139] - kill task error
java.io.IOException: Cannot run program "pstree": error=2, No such file or directory
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1048)
	at org.apache.dolphinscheduler.common.shell.AbstractShell.runCommand(AbstractShell.java:138)
	at org.apache.dolphinscheduler.common.shell.AbstractShell.run(AbstractShell.java:118)
	at org.apache.dolphinscheduler.common.shell.ShellExecutor.execute(ShellExecutor.java:125)
	at org.apache.dolphinscheduler.common.shell.ShellExecutor.execCommand(ShellExecutor.java:103)
	at org.apache.dolphinscheduler.common.shell.ShellExecutor.execCommand(ShellExecutor.java:86)
	at org.apache.dolphinscheduler.common.utils.OSUtils.exeShell(OSUtils.java:345)
	at org.apache.dolphinscheduler.common.utils.OSUtils.exeCmd(OSUtils.java:334)
	at org.apache.dolphinscheduler.plugin.task.api.utils.ProcessUtils.getPidsStr(ProcessUtils.java:129)
	at org.apache.dolphinscheduler.server.worker.runner.operator.TaskInstanceKillOperationFunction.killProcess(TaskInstanceKillOperationFunction.java:130)
	at org.apache.dolphinscheduler.server.worker.runner.operator.TaskInstanceKillOperationFunction.doKill(TaskInstanceKillOperationFunction.java:96)
	at org.apache.dolphinscheduler.server.worker.runner.operator.TaskInstanceKillOperationFunction.operate(TaskInstanceKillOperationFunction.java:69)
	at org.apache.dolphinscheduler.server.worker.rpc.TaskInstanceOperatorImpl.killTask(TaskInstanceOperatorImpl.java:49)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.dolphinscheduler.extract.base.server.ServerMethodInvokerImpl.invoke(ServerMethodInvokerImpl.java:41)
	at org.apache.dolphinscheduler.extract.base.server.JdkDynamicServerHandler.lambda$processReceived$0(JdkDynamicServerHandler.java:108)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.io.IOException: error=2, No such file or directory
	at java.lang.UNIXProcess.forkAndExec(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:247)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	... 21 common frames omitted
[WI-0][TI-1884] - [INFO] 2024-04-27 21:43:43.590 +0800 o.a.d.p.t.a.u.ProcessUtils:[182] - Get appIds from worker 172.18.1.1:1234, taskLogPath: /opt/dolphinscheduler/logs/20240427/13386218435520/15/687/1884.log
[WI-0][TI-1884] - [INFO] 2024-04-27 21:43:43.591 +0800 o.a.d.p.t.a.u.LogUtils:[79] - Start finding appId in /opt/dolphinscheduler/logs/20240427/13386218435520/15/687/1884.log, fetch way: log 
[WI-0][TI-1884] - [INFO] 2024-04-27 21:43:43.594 +0800 o.a.d.p.t.a.u.ProcessUtils:[188] - The appId is empty
[WI-0][TI-1884] - [INFO] 2024-04-27 21:43:43.595 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[220] - Begin to kill process process, pid is : 1366
[WI-0][TI-0] - [INFO] 2024-04-27 21:43:44.096 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8523444753946146 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:43:45.123 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8985915492957747 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:43:46.125 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9369627507163323 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:43:47.128 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.908284023668639 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:43:47.884 +0800 o.a.d.s.w.r.o.TaskInstanceKillOperationFunction:[55] - Receive TaskInstanceKillRequest: TaskInstanceKillRequest(taskInstanceId=1883)
[WI-0][TI-1883] - [ERROR] 2024-04-27 21:43:47.906 +0800 o.a.d.s.w.r.o.TaskInstanceKillOperationFunction:[139] - kill task error
java.io.IOException: Cannot run program "pstree": error=2, No such file or directory
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1048)
	at org.apache.dolphinscheduler.common.shell.AbstractShell.runCommand(AbstractShell.java:138)
	at org.apache.dolphinscheduler.common.shell.AbstractShell.run(AbstractShell.java:118)
	at org.apache.dolphinscheduler.common.shell.ShellExecutor.execute(ShellExecutor.java:125)
	at org.apache.dolphinscheduler.common.shell.ShellExecutor.execCommand(ShellExecutor.java:103)
	at org.apache.dolphinscheduler.common.shell.ShellExecutor.execCommand(ShellExecutor.java:86)
	at org.apache.dolphinscheduler.common.utils.OSUtils.exeShell(OSUtils.java:345)
	at org.apache.dolphinscheduler.common.utils.OSUtils.exeCmd(OSUtils.java:334)
	at org.apache.dolphinscheduler.plugin.task.api.utils.ProcessUtils.getPidsStr(ProcessUtils.java:129)
	at org.apache.dolphinscheduler.server.worker.runner.operator.TaskInstanceKillOperationFunction.killProcess(TaskInstanceKillOperationFunction.java:130)
	at org.apache.dolphinscheduler.server.worker.runner.operator.TaskInstanceKillOperationFunction.doKill(TaskInstanceKillOperationFunction.java:96)
	at org.apache.dolphinscheduler.server.worker.runner.operator.TaskInstanceKillOperationFunction.operate(TaskInstanceKillOperationFunction.java:69)
	at org.apache.dolphinscheduler.server.worker.rpc.TaskInstanceOperatorImpl.killTask(TaskInstanceOperatorImpl.java:49)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.dolphinscheduler.extract.base.server.ServerMethodInvokerImpl.invoke(ServerMethodInvokerImpl.java:41)
	at org.apache.dolphinscheduler.extract.base.server.JdkDynamicServerHandler.lambda$processReceived$0(JdkDynamicServerHandler.java:108)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.io.IOException: error=2, No such file or directory
	at java.lang.UNIXProcess.forkAndExec(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:247)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	... 21 common frames omitted
[WI-0][TI-1883] - [INFO] 2024-04-27 21:43:47.907 +0800 o.a.d.p.t.a.u.ProcessUtils:[182] - Get appIds from worker 172.18.1.1:1234, taskLogPath: /opt/dolphinscheduler/logs/20240427/13377949373536/19/686/1883.log
[WI-0][TI-1883] - [INFO] 2024-04-27 21:43:47.907 +0800 o.a.d.p.t.a.u.LogUtils:[79] - Start finding appId in /opt/dolphinscheduler/logs/20240427/13377949373536/19/686/1883.log, fetch way: log 
[WI-0][TI-1883] - [INFO] 2024-04-27 21:43:47.910 +0800 o.a.d.p.t.a.u.ProcessUtils:[188] - The appId is empty
[WI-0][TI-1883] - [INFO] 2024-04-27 21:43:47.913 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[220] - Begin to kill process process, pid is : 838
[WI-0][TI-0] - [INFO] 2024-04-27 21:43:48.143 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8760806916426512 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-1884] - [INFO] 2024-04-27 21:43:48.628 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[225] - Success kill task: 687_1884, pid: 1366
[WI-0][TI-1884] - [INFO] 2024-04-27 21:43:48.633 +0800 o.a.d.s.w.r.o.TaskInstanceKillOperationFunction:[119] - kill task by cancelApplication, taskInstanceId: 1884
[WI-0][TI-0] - [INFO] 2024-04-27 21:43:49.145 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8322147651006712 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:43:50.147 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9164265129682998 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:43:51.152 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7227138643067847 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-1883] - [INFO] 2024-04-27 21:43:52.918 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[225] - Success kill task: 686_1883, pid: 838
[WI-0][TI-1883] - [INFO] 2024-04-27 21:43:52.927 +0800 o.a.d.s.w.r.o.TaskInstanceKillOperationFunction:[119] - kill task by cancelApplication, taskInstanceId: 1883
[WI-0][TI-0] - [INFO] 2024-04-27 21:44:02.244 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7696793002915452 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:44:03.267 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7640449438202247 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:44:05.289 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8535911602209945 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:44:06.714 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.768361581920904 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:44:07.718 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8810186330282793 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:44:09.800 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8800000000000001 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:44:11.209 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1887, taskName=keyword filtering, firstSubmitTime=1714225451182, startTime=0, taskType=PYTHON, workflowInstanceHost=172.18.0.9:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13377949373536, processDefineVersion=19, appIds=null, processInstanceId=689, scheduleTime=0, globalParams=[{"prop":"keywords","direct":"IN","type":"VARCHAR","value":"\"singapore\", \"lol\""}], executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[],"rawScript":"from pyspark.sql import SparkSession\nfrom pyspark.sql.functions import col, from_json\nfrom pyspark.sql.types import StringType, StructType, StructField, IntegerType\n\nspark = SparkSession.builder \\\n    .master(\"local\") \\\n    .appName(\"Reddit Keyword Filtering\") \\\n    .config(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1\") \\\n    .config(\"spark.sql.streaming.checkpointLocation\", r\"/tmp/\") \\\n    .config(\"spark.driver.extraJavaOptions\", \"-Divy.cache.dir=/tmp -Divy.home=/tmp\") \\\n    .getOrCreate()\n\n# define the schema for the JSON data\nschema = StructType([\n    StructField(\"user\", StringType(), nullable=True),\n    StructField(\"content\", StringType(), nullable=True),\n    StructField(\"url\", StringType(), nullable=True),\n    StructField(\"context\", StringType(), nullable=True),\n    StructField(\"score\", IntegerType(), nullable=True),\n    StructField(\"subreddit\", StringType(), nullable=True),\n    StructField(\"type\", StringType(), nullable=True),\n    StructField(\"id\", StringType(), nullable=True),\n    StructField(\"datetime\", StringType(), nullable=True)  # Assuming the datetime is string type, you can change it to TimestampType if needed\n])\n\n# define the parameters for the input and output kafka broker and topic\nkafka_broker = \"kafka:9092\"\ninput_kafka_topic = \"reddit_post_preprocessed\"\noutput_kafka_topic = \"reddit_post_filtered\"\n\n# Subscribe to the input topic\ndf = spark \\\n    .readStream \\\n    .format(\"kafka\") \\\n    .option(\"kafka.bootstrap.servers\", kafka_broker) \\\n    .option(\"subscribe\", input_kafka_topic) \\\n    .load()\n\n# parse the JSON data in the 'value' column using the defined schema then create a dataframe containing the reddit data\ndf = df.select(col(\"value\").cast(\"string\")) \\\n    .withColumn(\"value\", from_json(\"value\", schema)) \\\n\nparsed_df = df \\\n    .select(\"value.*\")\n\n# filter rows containing specific keywords\nkeywords = ['singapore', 'sg']\n\n# initialize the filter condition with False\nfilter_condition = col(\"content\").contains(keywords[0])\n\n# loop through the rest of the keywords and update the filter condition\nfor keyword in keywords[1:]:\n    filter_condition = filter_condition | col(\"content\").contains(keyword)\n\n# apply the filter condition to the DataFrame\nfiltered_df = parsed_df.filter(filter_condition)\n\n# stream the data to kafka\nkafka_write = filtered_df \\\n    .selectExpr(\"'' AS key\", \"to_json(struct(*)) AS value\") \\\n    .writeStream \\\n    .format(\"kafka\") \\\n    .option(\"kafka.bootstrap.servers\", kafka_broker) \\\n    .option(\"topic\", output_kafka_topic) \\\n    .start()\n\n# Wait for the termination of the query\nkafka_write.awaitTermination()\n","resourceList":[]}, environmentConfig=export HADOOP_HOME=/opt/hadoop-3.4.0
export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export PYSPARK_DRIVER_PYTHON=/bin/python3.11
export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='keyword filtering'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, keywords=Property{prop='keywords', direct=IN, type=VARCHAR, value='"singapore", "lol"'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240427'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1887'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13377752024032'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240427214411'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='689'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240426'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='filter_data'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13377949373536'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=null, dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-689][TI-1887] - [INFO] 2024-04-27 21:44:11.213 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: keyword filtering to wait queue success
[WI-689][TI-1887] - [INFO] 2024-04-27 21:44:11.213 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-689][TI-1887] - [INFO] 2024-04-27 21:44:11.216 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-689][TI-1887] - [INFO] 2024-04-27 21:44:11.217 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-689][TI-1887] - [INFO] 2024-04-27 21:44:11.217 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-689][TI-1887] - [INFO] 2024-04-27 21:44:11.217 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1714225451217
[WI-689][TI-1887] - [INFO] 2024-04-27 21:44:11.217 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 689_1887
[WI-689][TI-1887] - [INFO] 2024-04-27 21:44:11.218 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1887,
  "taskName" : "keyword filtering",
  "firstSubmitTime" : 1714225451182,
  "startTime" : 1714225451217,
  "taskType" : "PYTHON",
  "workflowInstanceHost" : "172.18.0.9:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240427/13377949373536/19/689/1887.log",
  "processId" : 0,
  "processDefineCode" : 13377949373536,
  "processDefineVersion" : 19,
  "processInstanceId" : 689,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"keywords\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"\\\"singapore\\\", \\\"lol\\\"\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[],\"rawScript\":\"from pyspark.sql import SparkSession\\nfrom pyspark.sql.functions import col, from_json\\nfrom pyspark.sql.types import StringType, StructType, StructField, IntegerType\\n\\nspark = SparkSession.builder \\\\\\n    .master(\\\"local\\\") \\\\\\n    .appName(\\\"Reddit Keyword Filtering\\\") \\\\\\n    .config(\\\"spark.jars.packages\\\", \\\"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1\\\") \\\\\\n    .config(\\\"spark.sql.streaming.checkpointLocation\\\", r\\\"/tmp/\\\") \\\\\\n    .config(\\\"spark.driver.extraJavaOptions\\\", \\\"-Divy.cache.dir=/tmp -Divy.home=/tmp\\\") \\\\\\n    .getOrCreate()\\n\\n# define the schema for the JSON data\\nschema = StructType([\\n    StructField(\\\"user\\\", StringType(), nullable=True),\\n    StructField(\\\"content\\\", StringType(), nullable=True),\\n    StructField(\\\"url\\\", StringType(), nullable=True),\\n    StructField(\\\"context\\\", StringType(), nullable=True),\\n    StructField(\\\"score\\\", IntegerType(), nullable=True),\\n    StructField(\\\"subreddit\\\", StringType(), nullable=True),\\n    StructField(\\\"type\\\", StringType(), nullable=True),\\n    StructField(\\\"id\\\", StringType(), nullable=True),\\n    StructField(\\\"datetime\\\", StringType(), nullable=True)  # Assuming the datetime is string type, you can change it to TimestampType if needed\\n])\\n\\n# define the parameters for the input and output kafka broker and topic\\nkafka_broker = \\\"kafka:9092\\\"\\ninput_kafka_topic = \\\"reddit_post_preprocessed\\\"\\noutput_kafka_topic = \\\"reddit_post_filtered\\\"\\n\\n# Subscribe to the input topic\\ndf = spark \\\\\\n    .readStream \\\\\\n    .format(\\\"kafka\\\") \\\\\\n    .option(\\\"kafka.bootstrap.servers\\\", kafka_broker) \\\\\\n    .option(\\\"subscribe\\\", input_kafka_topic) \\\\\\n    .load()\\n\\n# parse the JSON data in the 'value' column using the defined schema then create a dataframe containing the reddit data\\ndf = df.select(col(\\\"value\\\").cast(\\\"string\\\")) \\\\\\n    .withColumn(\\\"value\\\", from_json(\\\"value\\\", schema)) \\\\\\n\\nparsed_df = df \\\\\\n    .select(\\\"value.*\\\")\\n\\n# filter rows containing specific keywords\\nkeywords = ['singapore', 'sg']\\n\\n# initialize the filter condition with False\\nfilter_condition = col(\\\"content\\\").contains(keywords[0])\\n\\n# loop through the rest of the keywords and update the filter condition\\nfor keyword in keywords[1:]:\\n    filter_condition = filter_condition | col(\\\"content\\\").contains(keyword)\\n\\n# apply the filter condition to the DataFrame\\nfiltered_df = parsed_df.filter(filter_condition)\\n\\n# stream the data to kafka\\nkafka_write = filtered_df \\\\\\n    .selectExpr(\\\"'' AS key\\\", \\\"to_json(struct(*)) AS value\\\") \\\\\\n    .writeStream \\\\\\n    .format(\\\"kafka\\\") \\\\\\n    .option(\\\"kafka.bootstrap.servers\\\", kafka_broker) \\\\\\n    .option(\\\"topic\\\", output_kafka_topic) \\\\\\n    .start()\\n\\n# Wait for the termination of the query\\nkafka_write.awaitTermination()\\n\",\"resourceList\":[]}",
  "environmentConfig" : "export HADOOP_HOME=/opt/hadoop-3.4.0\nexport SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3\nexport JAVA_HOME=/opt/java/openjdk\nexport PYSPARK_DRIVER_PYTHON=/bin/python3.11\nexport PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "keyword filtering"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "keywords" : {
      "prop" : "keywords",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "\"singapore\", \"lol\""
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240427"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1887"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13377752024032"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240427214411"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "689"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240426"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "filter_data"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13377949373536"
    }
  },
  "taskAppId" : "689_1887",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-689][TI-1887] - [INFO] 2024-04-27 21:44:11.219 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-689][TI-1887] - [INFO] 2024-04-27 21:44:11.220 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-689][TI-1887] - [INFO] 2024-04-27 21:44:11.220 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-0][TI-0] - [INFO] 2024-04-27 21:44:11.226 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1886, taskName=sentiment anaysis, firstSubmitTime=1714225451181, startTime=0, taskType=PYTHON, workflowInstanceHost=172.18.0.9:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13386218435520, processDefineVersion=15, appIds=null, processInstanceId=690, scheduleTime=0, globalParams=null, executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[],"rawScript":"# use kafka streaming api\nfrom pyspark.sql.functions import udf, col, from_json\nfrom pyspark.sql.types import FloatType, ArrayType, StringType, StructType, StructField, IntegerType\nimport nltk\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA\nfrom pyspark.sql import SparkSession\n\n# download the model\nnltk.download('vader_lexicon')\n\n# init the sentiment analysis object\nsia = SIA()\n\n# init Spark session\nspark = SparkSession.builder \\\n    .master('local') \\\n    .appName(\"Sentiment Analysis\") \\\n    .config(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1\") \\\n    .config(\"spark.sql.streaming.checkpointLocation\", r\"/tmp/\") \\\n    .config(\"spark.driver.extraJavaOptions\", \"-Divy.cache.dir=/tmp -Divy.home=/tmp\") \\\n    .getOrCreate()\n\n# define a udf to perform sentiment analysis\ndef analyze_sentiment(message):\n    # Perform sentiment analysis\n    pol_score = sia.polarity_scores(message)\n    # Return the compound score\n    return [pol_score['neg'], pol_score['neu'], pol_score['pos'], pol_score['compound']]\n\n# Register the function as a UDF\nanalyze_sentiment_udf = udf(lambda x:analyze_sentiment(x), ArrayType(FloatType()))\n\n# define the schema for the JSON data\nschema = StructType([\n    StructField(\"user\", StringType(), nullable=True),\n    StructField(\"content\", StringType(), nullable=True),\n    StructField(\"url\", StringType(), nullable=True),\n    StructField(\"context\", StringType(), nullable=True),\n    StructField(\"score\", IntegerType(), nullable=True),\n    StructField(\"subreddit\", StringType(), nullable=True),\n    StructField(\"type\", StringType(), nullable=True),\n    StructField(\"id\", StringType(), nullable=True),\n    StructField(\"datetime\", StringType(), nullable=True)  # Assuming the datetime is string type, you can change it to TimestampType if needed\n])\n\n\n# define the parameters for the input and output kafka broker and topic\nkafka_broker = \"kafka:9092\"\ninput_kafka_topic = \"reddit_post_filtered\"\noutput_kafka_topic = \"reddit_post_sa\"\n\n# Subscribe to the input topic\ndf = spark \\\n    .readStream \\\n    .format(\"kafka\") \\\n    .option(\"kafka.bootstrap.servers\", kafka_broker) \\\n    .option(\"subscribe\", input_kafka_topic) \\\n    .load()\n\n# parse the JSON data in the 'value' column using the defined schema then create a dataframe containing the reddit data\ndf = df.select(col(\"value\").cast(\"string\")) \\\n    .withColumn(\"value\", from_json(\"value\", schema)) \\\n\nparsed_df = df \\\n    .select(\"value.*\")\n\n# perform sentiment analysis on the parsed dataframe \nsa_reddit_df = parsed_df.withColumn('sentiment_score', analyze_sentiment_udf(parsed_df['content']))\n\n# split the sentiment_score column into separate columns\nsa_reddit_df = sa_reddit_df.withColumn(\"negative\", sa_reddit_df[\"sentiment_score\"][0]) \\\n            .withColumn(\"neutral\", sa_reddit_df[\"sentiment_score\"][1]) \\\n            .withColumn(\"positive\", sa_reddit_df[\"sentiment_score\"][2]) \\\n            .withColumn(\"compound\", sa_reddit_df[\"sentiment_score\"][3]) \\\n            .drop('sentiment_score')  # drop sentiment_score column after splitting\n\n# stream the data to kafka\nkafka_write = sa_reddit_df \\\n    .selectExpr(\"'' AS key\", \"to_json(struct(*)) AS value\") \\\n    .writeStream \\\n    .format(\"kafka\") \\\n    .option(\"kafka.bootstrap.servers\", kafka_broker) \\\n    .option(\"topic\", output_kafka_topic) \\\n    .start()\n\n# Wait for the termination of the query\nkafka_write.awaitTermination()","resourceList":[]}, environmentConfig=export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export PYSPARK_DRIVER_PYTHON=/bin/python3.11
export PYSPARK_PYTHON=/bin/python3.11
export PYTHON_LAUNCHER=/bin/python3.11
export NLTK_DATA=/local_storage/nltk_data, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='sentiment anaysis'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='690'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240427'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240426'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1886'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='sentiment_analysis_subprocess'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13386027735104'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13386218435520'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240427214411'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=null, dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-690][TI-1886] - [INFO] 2024-04-27 21:44:11.234 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: sentiment anaysis to wait queue success
[WI-689][TI-1887] - [INFO] 2024-04-27 21:44:11.237 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-689][TI-1887] - [INFO] 2024-04-27 21:44:11.237 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-689][TI-1887] - [INFO] 2024-04-27 21:44:11.238 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13377949373536_19/689/1887 check successfully
[WI-689][TI-1887] - [INFO] 2024-04-27 21:44:11.238 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.python.PythonTaskChannel successfully
[WI-689][TI-1887] - [INFO] 2024-04-27 21:44:11.241 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-689][TI-1887] - [INFO] 2024-04-27 21:44:11.242 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-689][TI-1887] - [INFO] 2024-04-27 21:44:11.243 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: PYTHON create successfully
[WI-689][TI-1887] - [INFO] 2024-04-27 21:44:11.243 +0800 o.a.d.p.t.p.PythonTask:[75] - Initialize python task params {
  "localParams" : [ ],
  "varPool" : null,
  "rawScript" : "from pyspark.sql import SparkSession\nfrom pyspark.sql.functions import col, from_json\nfrom pyspark.sql.types import StringType, StructType, StructField, IntegerType\n\nspark = SparkSession.builder \\\n    .master(\"local\") \\\n    .appName(\"Reddit Keyword Filtering\") \\\n    .config(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1\") \\\n    .config(\"spark.sql.streaming.checkpointLocation\", r\"/tmp/\") \\\n    .config(\"spark.driver.extraJavaOptions\", \"-Divy.cache.dir=/tmp -Divy.home=/tmp\") \\\n    .getOrCreate()\n\n# define the schema for the JSON data\nschema = StructType([\n    StructField(\"user\", StringType(), nullable=True),\n    StructField(\"content\", StringType(), nullable=True),\n    StructField(\"url\", StringType(), nullable=True),\n    StructField(\"context\", StringType(), nullable=True),\n    StructField(\"score\", IntegerType(), nullable=True),\n    StructField(\"subreddit\", StringType(), nullable=True),\n    StructField(\"type\", StringType(), nullable=True),\n    StructField(\"id\", StringType(), nullable=True),\n    StructField(\"datetime\", StringType(), nullable=True)  # Assuming the datetime is string type, you can change it to TimestampType if needed\n])\n\n# define the parameters for the input and output kafka broker and topic\nkafka_broker = \"kafka:9092\"\ninput_kafka_topic = \"reddit_post_preprocessed\"\noutput_kafka_topic = \"reddit_post_filtered\"\n\n# Subscribe to the input topic\ndf = spark \\\n    .readStream \\\n    .format(\"kafka\") \\\n    .option(\"kafka.bootstrap.servers\", kafka_broker) \\\n    .option(\"subscribe\", input_kafka_topic) \\\n    .load()\n\n# parse the JSON data in the 'value' column using the defined schema then create a dataframe containing the reddit data\ndf = df.select(col(\"value\").cast(\"string\")) \\\n    .withColumn(\"value\", from_json(\"value\", schema)) \\\n\nparsed_df = df \\\n    .select(\"value.*\")\n\n# filter rows containing specific keywords\nkeywords = ['singapore', 'sg']\n\n# initialize the filter condition with False\nfilter_condition = col(\"content\").contains(keywords[0])\n\n# loop through the rest of the keywords and update the filter condition\nfor keyword in keywords[1:]:\n    filter_condition = filter_condition | col(\"content\").contains(keyword)\n\n# apply the filter condition to the DataFrame\nfiltered_df = parsed_df.filter(filter_condition)\n\n# stream the data to kafka\nkafka_write = filtered_df \\\n    .selectExpr(\"'' AS key\", \"to_json(struct(*)) AS value\") \\\n    .writeStream \\\n    .format(\"kafka\") \\\n    .option(\"kafka.bootstrap.servers\", kafka_broker) \\\n    .option(\"topic\", output_kafka_topic) \\\n    .start()\n\n# Wait for the termination of the query\nkafka_write.awaitTermination()\n",
  "resourceList" : [ ]
}
[WI-689][TI-1887] - [INFO] 2024-04-27 21:44:11.248 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-689][TI-1887] - [INFO] 2024-04-27 21:44:11.248 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: null successfully
[WI-689][TI-1887] - [INFO] 2024-04-27 21:44:11.248 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-689][TI-1887] - [INFO] 2024-04-27 21:44:11.248 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-689][TI-1887] - [INFO] 2024-04-27 21:44:11.248 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-690][TI-1886] - [INFO] 2024-04-27 21:44:11.234 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-690][TI-1886] - [INFO] 2024-04-27 21:44:11.249 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-690][TI-1886] - [INFO] 2024-04-27 21:44:11.249 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-690][TI-1886] - [INFO] 2024-04-27 21:44:11.249 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-690][TI-1886] - [INFO] 2024-04-27 21:44:11.249 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1714225451249
[WI-689][TI-1887] - [INFO] 2024-04-27 21:44:11.248 +0800 o.a.d.p.t.p.PythonTask:[165] - raw python script : from pyspark.sql import SparkSession
from pyspark.sql.functions import col, from_json
from pyspark.sql.types import StringType, StructType, StructField, IntegerType

spark = SparkSession.builder \
    .master("local") \
    .appName("Reddit Keyword Filtering") \
    .config("spark.jars.packages", "org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1") \
    .config("spark.sql.streaming.checkpointLocation", r"/tmp/") \
    .config("spark.driver.extraJavaOptions", "-Divy.cache.dir=/tmp -Divy.home=/tmp") \
    .getOrCreate()

# define the schema for the JSON data
schema = StructType([
    StructField("user", StringType(), nullable=True),
    StructField("content", StringType(), nullable=True),
    StructField("url", StringType(), nullable=True),
    StructField("context", StringType(), nullable=True),
    StructField("score", IntegerType(), nullable=True),
    StructField("subreddit", StringType(), nullable=True),
    StructField("type", StringType(), nullable=True),
    StructField("id", StringType(), nullable=True),
    StructField("datetime", StringType(), nullable=True)  # Assuming the datetime is string type, you can change it to TimestampType if needed
])

# define the parameters for the input and output kafka broker and topic
kafka_broker = "kafka:9092"
input_kafka_topic = "reddit_post_preprocessed"
output_kafka_topic = "reddit_post_filtered"

# Subscribe to the input topic
df = spark \
    .readStream \
    .format("kafka") \
    .option("kafka.bootstrap.servers", kafka_broker) \
    .option("subscribe", input_kafka_topic) \
    .load()

# parse the JSON data in the 'value' column using the defined schema then create a dataframe containing the reddit data
df = df.select(col("value").cast("string")) \
    .withColumn("value", from_json("value", schema)) \

parsed_df = df \
    .select("value.*")

# filter rows containing specific keywords
keywords = ['singapore', 'sg']

# initialize the filter condition with False
filter_condition = col("content").contains(keywords[0])

# loop through the rest of the keywords and update the filter condition
for keyword in keywords[1:]:
    filter_condition = filter_condition | col("content").contains(keyword)

# apply the filter condition to the DataFrame
filtered_df = parsed_df.filter(filter_condition)

# stream the data to kafka
kafka_write = filtered_df \
    .selectExpr("'' AS key", "to_json(struct(*)) AS value") \
    .writeStream \
    .format("kafka") \
    .option("kafka.bootstrap.servers", kafka_broker) \
    .option("topic", output_kafka_topic) \
    .start()

# Wait for the termination of the query
kafka_write.awaitTermination()

[WI-689][TI-1887] - [INFO] 2024-04-27 21:44:11.250 +0800 o.a.d.p.t.p.PythonTask:[131] - tenantCode :default, task dir:/tmp/dolphinscheduler/exec/process/default/13010050770016/13377949373536_19/689/1887
[WI-689][TI-1887] - [INFO] 2024-04-27 21:44:11.250 +0800 o.a.d.p.t.p.PythonTask:[134] - generate python script file:/tmp/dolphinscheduler/exec/process/default/13010050770016/13377949373536_19/689/1887/py_689_1887.py
[WI-689][TI-1887] - [INFO] 2024-04-27 21:44:11.251 +0800 o.a.d.p.t.p.PythonTask:[141] - #-*- encoding=utf8 -*-

from pyspark.sql import SparkSession
from pyspark.sql.functions import col, from_json
from pyspark.sql.types import StringType, StructType, StructField, IntegerType

spark = SparkSession.builder \
    .master("local") \
    .appName("Reddit Keyword Filtering") \
    .config("spark.jars.packages", "org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1") \
    .config("spark.sql.streaming.checkpointLocation", r"/tmp/") \
    .config("spark.driver.extraJavaOptions", "-Divy.cache.dir=/tmp -Divy.home=/tmp") \
    .getOrCreate()

# define the schema for the JSON data
schema = StructType([
    StructField("user", StringType(), nullable=True),
    StructField("content", StringType(), nullable=True),
    StructField("url", StringType(), nullable=True),
    StructField("context", StringType(), nullable=True),
    StructField("score", IntegerType(), nullable=True),
    StructField("subreddit", StringType(), nullable=True),
    StructField("type", StringType(), nullable=True),
    StructField("id", StringType(), nullable=True),
    StructField("datetime", StringType(), nullable=True)  # Assuming the datetime is string type, you can change it to TimestampType if needed
])

# define the parameters for the input and output kafka broker and topic
kafka_broker = "kafka:9092"
input_kafka_topic = "reddit_post_preprocessed"
output_kafka_topic = "reddit_post_filtered"

# Subscribe to the input topic
df = spark \
    .readStream \
    .format("kafka") \
    .option("kafka.bootstrap.servers", kafka_broker) \
    .option("subscribe", input_kafka_topic) \
    .load()

# parse the JSON data in the 'value' column using the defined schema then create a dataframe containing the reddit data
df = df.select(col("value").cast("string")) \
    .withColumn("value", from_json("value", schema)) \

parsed_df = df \
    .select("value.*")

# filter rows containing specific keywords
keywords = ['singapore', 'sg']

# initialize the filter condition with False
filter_condition = col("content").contains(keywords[0])

# loop through the rest of the keywords and update the filter condition
for keyword in keywords[1:]:
    filter_condition = filter_condition | col("content").contains(keyword)

# apply the filter condition to the DataFrame
filtered_df = parsed_df.filter(filter_condition)

# stream the data to kafka
kafka_write = filtered_df \
    .selectExpr("'' AS key", "to_json(struct(*)) AS value") \
    .writeStream \
    .format("kafka") \
    .option("kafka.bootstrap.servers", kafka_broker) \
    .option("topic", output_kafka_topic) \
    .start()

# Wait for the termination of the query
kafka_write.awaitTermination()

[WI-689][TI-1887] - [INFO] 2024-04-27 21:44:11.253 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-689][TI-1887] - [INFO] 2024-04-27 21:44:11.254 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-689][TI-1887] - [INFO] 2024-04-27 21:44:11.254 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export HADOOP_HOME=/opt/hadoop-3.4.0
export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export PYSPARK_DRIVER_PYTHON=/bin/python3.11
export PYTHON_LAUNCHER=/bin/python3.11
${PYTHON_LAUNCHER} /tmp/dolphinscheduler/exec/process/default/13010050770016/13377949373536_19/689/1887/py_689_1887.py
[WI-689][TI-1887] - [INFO] 2024-04-27 21:44:11.254 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-689][TI-1887] - [INFO] 2024-04-27 21:44:11.254 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13377949373536_19/689/1887/689_1887.sh
[WI-690][TI-1886] - [INFO] 2024-04-27 21:44:11.249 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 690_1886
[WI-690][TI-1886] - [INFO] 2024-04-27 21:44:11.255 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1886,
  "taskName" : "sentiment anaysis",
  "firstSubmitTime" : 1714225451181,
  "startTime" : 1714225451249,
  "taskType" : "PYTHON",
  "workflowInstanceHost" : "172.18.0.9:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240427/13386218435520/15/690/1886.log",
  "processId" : 0,
  "processDefineCode" : 13386218435520,
  "processDefineVersion" : 15,
  "processInstanceId" : 690,
  "scheduleTime" : 0,
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[],\"rawScript\":\"# use kafka streaming api\\nfrom pyspark.sql.functions import udf, col, from_json\\nfrom pyspark.sql.types import FloatType, ArrayType, StringType, StructType, StructField, IntegerType\\nimport nltk\\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA\\nfrom pyspark.sql import SparkSession\\n\\n# download the model\\nnltk.download('vader_lexicon')\\n\\n# init the sentiment analysis object\\nsia = SIA()\\n\\n# init Spark session\\nspark = SparkSession.builder \\\\\\n    .master('local') \\\\\\n    .appName(\\\"Sentiment Analysis\\\") \\\\\\n    .config(\\\"spark.jars.packages\\\", \\\"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1\\\") \\\\\\n    .config(\\\"spark.sql.streaming.checkpointLocation\\\", r\\\"/tmp/\\\") \\\\\\n    .config(\\\"spark.driver.extraJavaOptions\\\", \\\"-Divy.cache.dir=/tmp -Divy.home=/tmp\\\") \\\\\\n    .getOrCreate()\\n\\n# define a udf to perform sentiment analysis\\ndef analyze_sentiment(message):\\n    # Perform sentiment analysis\\n    pol_score = sia.polarity_scores(message)\\n    # Return the compound score\\n    return [pol_score['neg'], pol_score['neu'], pol_score['pos'], pol_score['compound']]\\n\\n# Register the function as a UDF\\nanalyze_sentiment_udf = udf(lambda x:analyze_sentiment(x), ArrayType(FloatType()))\\n\\n# define the schema for the JSON data\\nschema = StructType([\\n    StructField(\\\"user\\\", StringType(), nullable=True),\\n    StructField(\\\"content\\\", StringType(), nullable=True),\\n    StructField(\\\"url\\\", StringType(), nullable=True),\\n    StructField(\\\"context\\\", StringType(), nullable=True),\\n    StructField(\\\"score\\\", IntegerType(), nullable=True),\\n    StructField(\\\"subreddit\\\", StringType(), nullable=True),\\n    StructField(\\\"type\\\", StringType(), nullable=True),\\n    StructField(\\\"id\\\", StringType(), nullable=True),\\n    StructField(\\\"datetime\\\", StringType(), nullable=True)  # Assuming the datetime is string type, you can change it to TimestampType if needed\\n])\\n\\n\\n# define the parameters for the input and output kafka broker and topic\\nkafka_broker = \\\"kafka:9092\\\"\\ninput_kafka_topic = \\\"reddit_post_filtered\\\"\\noutput_kafka_topic = \\\"reddit_post_sa\\\"\\n\\n# Subscribe to the input topic\\ndf = spark \\\\\\n    .readStream \\\\\\n    .format(\\\"kafka\\\") \\\\\\n    .option(\\\"kafka.bootstrap.servers\\\", kafka_broker) \\\\\\n    .option(\\\"subscribe\\\", input_kafka_topic) \\\\\\n    .load()\\n\\n# parse the JSON data in the 'value' column using the defined schema then create a dataframe containing the reddit data\\ndf = df.select(col(\\\"value\\\").cast(\\\"string\\\")) \\\\\\n    .withColumn(\\\"value\\\", from_json(\\\"value\\\", schema)) \\\\\\n\\nparsed_df = df \\\\\\n    .select(\\\"value.*\\\")\\n\\n# perform sentiment analysis on the parsed dataframe \\nsa_reddit_df = parsed_df.withColumn('sentiment_score', analyze_sentiment_udf(parsed_df['content']))\\n\\n# split the sentiment_score column into separate columns\\nsa_reddit_df = sa_reddit_df.withColumn(\\\"negative\\\", sa_reddit_df[\\\"sentiment_score\\\"][0]) \\\\\\n            .withColumn(\\\"neutral\\\", sa_reddit_df[\\\"sentiment_score\\\"][1]) \\\\\\n            .withColumn(\\\"positive\\\", sa_reddit_df[\\\"sentiment_score\\\"][2]) \\\\\\n            .withColumn(\\\"compound\\\", sa_reddit_df[\\\"sentiment_score\\\"][3]) \\\\\\n            .drop('sentiment_score')  # drop sentiment_score column after splitting\\n\\n# stream the data to kafka\\nkafka_write = sa_reddit_df \\\\\\n    .selectExpr(\\\"'' AS key\\\", \\\"to_json(struct(*)) AS value\\\") \\\\\\n    .writeStream \\\\\\n    .format(\\\"kafka\\\") \\\\\\n    .option(\\\"kafka.bootstrap.servers\\\", kafka_broker) \\\\\\n    .option(\\\"topic\\\", output_kafka_topic) \\\\\\n    .start()\\n\\n# Wait for the termination of the query\\nkafka_write.awaitTermination()\",\"resourceList\":[]}",
  "environmentConfig" : "export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3\nexport JAVA_HOME=/opt/java/openjdk\nexport PYSPARK_DRIVER_PYTHON=/bin/python3.11\nexport PYSPARK_PYTHON=/bin/python3.11\nexport PYTHON_LAUNCHER=/bin/python3.11\nexport NLTK_DATA=/local_storage/nltk_data",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "sentiment anaysis"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "690"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240427"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240426"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1886"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "sentiment_analysis_subprocess"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13386027735104"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13386218435520"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240427214411"
    }
  },
  "taskAppId" : "690_1886",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-690][TI-1886] - [INFO] 2024-04-27 21:44:11.256 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-690][TI-1886] - [INFO] 2024-04-27 21:44:11.257 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-690][TI-1886] - [INFO] 2024-04-27 21:44:11.257 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-690][TI-1886] - [INFO] 2024-04-27 21:44:11.270 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-690][TI-1886] - [INFO] 2024-04-27 21:44:11.270 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-690][TI-1886] - [INFO] 2024-04-27 21:44:11.271 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13386218435520_15/690/1886 check successfully
[WI-690][TI-1886] - [INFO] 2024-04-27 21:44:11.271 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.python.PythonTaskChannel successfully
[WI-690][TI-1886] - [INFO] 2024-04-27 21:44:11.272 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-690][TI-1886] - [INFO] 2024-04-27 21:44:11.273 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-690][TI-1886] - [INFO] 2024-04-27 21:44:11.273 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: PYTHON create successfully
[WI-690][TI-1886] - [INFO] 2024-04-27 21:44:11.273 +0800 o.a.d.p.t.p.PythonTask:[75] - Initialize python task params {
  "localParams" : [ ],
  "varPool" : null,
  "rawScript" : "# use kafka streaming api\nfrom pyspark.sql.functions import udf, col, from_json\nfrom pyspark.sql.types import FloatType, ArrayType, StringType, StructType, StructField, IntegerType\nimport nltk\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA\nfrom pyspark.sql import SparkSession\n\n# download the model\nnltk.download('vader_lexicon')\n\n# init the sentiment analysis object\nsia = SIA()\n\n# init Spark session\nspark = SparkSession.builder \\\n    .master('local') \\\n    .appName(\"Sentiment Analysis\") \\\n    .config(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1\") \\\n    .config(\"spark.sql.streaming.checkpointLocation\", r\"/tmp/\") \\\n    .config(\"spark.driver.extraJavaOptions\", \"-Divy.cache.dir=/tmp -Divy.home=/tmp\") \\\n    .getOrCreate()\n\n# define a udf to perform sentiment analysis\ndef analyze_sentiment(message):\n    # Perform sentiment analysis\n    pol_score = sia.polarity_scores(message)\n    # Return the compound score\n    return [pol_score['neg'], pol_score['neu'], pol_score['pos'], pol_score['compound']]\n\n# Register the function as a UDF\nanalyze_sentiment_udf = udf(lambda x:analyze_sentiment(x), ArrayType(FloatType()))\n\n# define the schema for the JSON data\nschema = StructType([\n    StructField(\"user\", StringType(), nullable=True),\n    StructField(\"content\", StringType(), nullable=True),\n    StructField(\"url\", StringType(), nullable=True),\n    StructField(\"context\", StringType(), nullable=True),\n    StructField(\"score\", IntegerType(), nullable=True),\n    StructField(\"subreddit\", StringType(), nullable=True),\n    StructField(\"type\", StringType(), nullable=True),\n    StructField(\"id\", StringType(), nullable=True),\n    StructField(\"datetime\", StringType(), nullable=True)  # Assuming the datetime is string type, you can change it to TimestampType if needed\n])\n\n\n# define the parameters for the input and output kafka broker and topic\nkafka_broker = \"kafka:9092\"\ninput_kafka_topic = \"reddit_post_filtered\"\noutput_kafka_topic = \"reddit_post_sa\"\n\n# Subscribe to the input topic\ndf = spark \\\n    .readStream \\\n    .format(\"kafka\") \\\n    .option(\"kafka.bootstrap.servers\", kafka_broker) \\\n    .option(\"subscribe\", input_kafka_topic) \\\n    .load()\n\n# parse the JSON data in the 'value' column using the defined schema then create a dataframe containing the reddit data\ndf = df.select(col(\"value\").cast(\"string\")) \\\n    .withColumn(\"value\", from_json(\"value\", schema)) \\\n\nparsed_df = df \\\n    .select(\"value.*\")\n\n# perform sentiment analysis on the parsed dataframe \nsa_reddit_df = parsed_df.withColumn('sentiment_score', analyze_sentiment_udf(parsed_df['content']))\n\n# split the sentiment_score column into separate columns\nsa_reddit_df = sa_reddit_df.withColumn(\"negative\", sa_reddit_df[\"sentiment_score\"][0]) \\\n            .withColumn(\"neutral\", sa_reddit_df[\"sentiment_score\"][1]) \\\n            .withColumn(\"positive\", sa_reddit_df[\"sentiment_score\"][2]) \\\n            .withColumn(\"compound\", sa_reddit_df[\"sentiment_score\"][3]) \\\n            .drop('sentiment_score')  # drop sentiment_score column after splitting\n\n# stream the data to kafka\nkafka_write = sa_reddit_df \\\n    .selectExpr(\"'' AS key\", \"to_json(struct(*)) AS value\") \\\n    .writeStream \\\n    .format(\"kafka\") \\\n    .option(\"kafka.bootstrap.servers\", kafka_broker) \\\n    .option(\"topic\", output_kafka_topic) \\\n    .start()\n\n# Wait for the termination of the query\nkafka_write.awaitTermination()",
  "resourceList" : [ ]
}
[WI-690][TI-1886] - [INFO] 2024-04-27 21:44:11.274 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-690][TI-1886] - [INFO] 2024-04-27 21:44:11.274 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: null successfully
[WI-690][TI-1886] - [INFO] 2024-04-27 21:44:11.275 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-690][TI-1886] - [INFO] 2024-04-27 21:44:11.277 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-690][TI-1886] - [INFO] 2024-04-27 21:44:11.277 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-690][TI-1886] - [INFO] 2024-04-27 21:44:11.277 +0800 o.a.d.p.t.p.PythonTask:[165] - raw python script : # use kafka streaming api
from pyspark.sql.functions import udf, col, from_json
from pyspark.sql.types import FloatType, ArrayType, StringType, StructType, StructField, IntegerType
import nltk
from nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA
from pyspark.sql import SparkSession

# download the model
nltk.download('vader_lexicon')

# init the sentiment analysis object
sia = SIA()

# init Spark session
spark = SparkSession.builder \
    .master('local') \
    .appName("Sentiment Analysis") \
    .config("spark.jars.packages", "org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1") \
    .config("spark.sql.streaming.checkpointLocation", r"/tmp/") \
    .config("spark.driver.extraJavaOptions", "-Divy.cache.dir=/tmp -Divy.home=/tmp") \
    .getOrCreate()

# define a udf to perform sentiment analysis
def analyze_sentiment(message):
    # Perform sentiment analysis
    pol_score = sia.polarity_scores(message)
    # Return the compound score
    return [pol_score['neg'], pol_score['neu'], pol_score['pos'], pol_score['compound']]

# Register the function as a UDF
analyze_sentiment_udf = udf(lambda x:analyze_sentiment(x), ArrayType(FloatType()))

# define the schema for the JSON data
schema = StructType([
    StructField("user", StringType(), nullable=True),
    StructField("content", StringType(), nullable=True),
    StructField("url", StringType(), nullable=True),
    StructField("context", StringType(), nullable=True),
    StructField("score", IntegerType(), nullable=True),
    StructField("subreddit", StringType(), nullable=True),
    StructField("type", StringType(), nullable=True),
    StructField("id", StringType(), nullable=True),
    StructField("datetime", StringType(), nullable=True)  # Assuming the datetime is string type, you can change it to TimestampType if needed
])


# define the parameters for the input and output kafka broker and topic
kafka_broker = "kafka:9092"
input_kafka_topic = "reddit_post_filtered"
output_kafka_topic = "reddit_post_sa"

# Subscribe to the input topic
df = spark \
    .readStream \
    .format("kafka") \
    .option("kafka.bootstrap.servers", kafka_broker) \
    .option("subscribe", input_kafka_topic) \
    .load()

# parse the JSON data in the 'value' column using the defined schema then create a dataframe containing the reddit data
df = df.select(col("value").cast("string")) \
    .withColumn("value", from_json("value", schema)) \

parsed_df = df \
    .select("value.*")

# perform sentiment analysis on the parsed dataframe 
sa_reddit_df = parsed_df.withColumn('sentiment_score', analyze_sentiment_udf(parsed_df['content']))

# split the sentiment_score column into separate columns
sa_reddit_df = sa_reddit_df.withColumn("negative", sa_reddit_df["sentiment_score"][0]) \
            .withColumn("neutral", sa_reddit_df["sentiment_score"][1]) \
            .withColumn("positive", sa_reddit_df["sentiment_score"][2]) \
            .withColumn("compound", sa_reddit_df["sentiment_score"][3]) \
            .drop('sentiment_score')  # drop sentiment_score column after splitting

# stream the data to kafka
kafka_write = sa_reddit_df \
    .selectExpr("'' AS key", "to_json(struct(*)) AS value") \
    .writeStream \
    .format("kafka") \
    .option("kafka.bootstrap.servers", kafka_broker) \
    .option("topic", output_kafka_topic) \
    .start()

# Wait for the termination of the query
kafka_write.awaitTermination()
[WI-690][TI-1886] - [INFO] 2024-04-27 21:44:11.281 +0800 o.a.d.p.t.p.PythonTask:[131] - tenantCode :default, task dir:/tmp/dolphinscheduler/exec/process/default/13010050770016/13386218435520_15/690/1886
[WI-690][TI-1886] - [INFO] 2024-04-27 21:44:11.286 +0800 o.a.d.p.t.p.PythonTask:[134] - generate python script file:/tmp/dolphinscheduler/exec/process/default/13010050770016/13386218435520_15/690/1886/py_690_1886.py
[WI-690][TI-1886] - [INFO] 2024-04-27 21:44:11.286 +0800 o.a.d.p.t.p.PythonTask:[141] - #-*- encoding=utf8 -*-

# use kafka streaming api
from pyspark.sql.functions import udf, col, from_json
from pyspark.sql.types import FloatType, ArrayType, StringType, StructType, StructField, IntegerType
import nltk
from nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA
from pyspark.sql import SparkSession

# download the model
nltk.download('vader_lexicon')

# init the sentiment analysis object
sia = SIA()

# init Spark session
spark = SparkSession.builder \
    .master('local') \
    .appName("Sentiment Analysis") \
    .config("spark.jars.packages", "org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1") \
    .config("spark.sql.streaming.checkpointLocation", r"/tmp/") \
    .config("spark.driver.extraJavaOptions", "-Divy.cache.dir=/tmp -Divy.home=/tmp") \
    .getOrCreate()

# define a udf to perform sentiment analysis
def analyze_sentiment(message):
    # Perform sentiment analysis
    pol_score = sia.polarity_scores(message)
    # Return the compound score
    return [pol_score['neg'], pol_score['neu'], pol_score['pos'], pol_score['compound']]

# Register the function as a UDF
analyze_sentiment_udf = udf(lambda x:analyze_sentiment(x), ArrayType(FloatType()))

# define the schema for the JSON data
schema = StructType([
    StructField("user", StringType(), nullable=True),
    StructField("content", StringType(), nullable=True),
    StructField("url", StringType(), nullable=True),
    StructField("context", StringType(), nullable=True),
    StructField("score", IntegerType(), nullable=True),
    StructField("subreddit", StringType(), nullable=True),
    StructField("type", StringType(), nullable=True),
    StructField("id", StringType(), nullable=True),
    StructField("datetime", StringType(), nullable=True)  # Assuming the datetime is string type, you can change it to TimestampType if needed
])


# define the parameters for the input and output kafka broker and topic
kafka_broker = "kafka:9092"
input_kafka_topic = "reddit_post_filtered"
output_kafka_topic = "reddit_post_sa"

# Subscribe to the input topic
df = spark \
    .readStream \
    .format("kafka") \
    .option("kafka.bootstrap.servers", kafka_broker) \
    .option("subscribe", input_kafka_topic) \
    .load()

# parse the JSON data in the 'value' column using the defined schema then create a dataframe containing the reddit data
df = df.select(col("value").cast("string")) \
    .withColumn("value", from_json("value", schema)) \

parsed_df = df \
    .select("value.*")

# perform sentiment analysis on the parsed dataframe 
sa_reddit_df = parsed_df.withColumn('sentiment_score', analyze_sentiment_udf(parsed_df['content']))

# split the sentiment_score column into separate columns
sa_reddit_df = sa_reddit_df.withColumn("negative", sa_reddit_df["sentiment_score"][0]) \
            .withColumn("neutral", sa_reddit_df["sentiment_score"][1]) \
            .withColumn("positive", sa_reddit_df["sentiment_score"][2]) \
            .withColumn("compound", sa_reddit_df["sentiment_score"][3]) \
            .drop('sentiment_score')  # drop sentiment_score column after splitting

# stream the data to kafka
kafka_write = sa_reddit_df \
    .selectExpr("'' AS key", "to_json(struct(*)) AS value") \
    .writeStream \
    .format("kafka") \
    .option("kafka.bootstrap.servers", kafka_broker) \
    .option("topic", output_kafka_topic) \
    .start()

# Wait for the termination of the query
kafka_write.awaitTermination()
[WI-689][TI-1887] - [INFO] 2024-04-27 21:44:11.294 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 2255
[WI-690][TI-1886] - [INFO] 2024-04-27 21:44:11.305 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-690][TI-1886] - [INFO] 2024-04-27 21:44:11.310 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-690][TI-1886] - [INFO] 2024-04-27 21:44:11.313 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export PYSPARK_DRIVER_PYTHON=/bin/python3.11
export PYSPARK_PYTHON=/bin/python3.11
export PYTHON_LAUNCHER=/bin/python3.11
export NLTK_DATA=/local_storage/nltk_data
${PYTHON_LAUNCHER} /tmp/dolphinscheduler/exec/process/default/13010050770016/13386218435520_15/690/1886/py_690_1886.py
[WI-690][TI-1886] - [INFO] 2024-04-27 21:44:11.313 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-690][TI-1886] - [INFO] 2024-04-27 21:44:11.314 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13386218435520_15/690/1886/690_1886.sh
[WI-690][TI-1886] - [INFO] 2024-04-27 21:44:11.328 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 2261
[WI-0][TI-0] - [INFO] 2024-04-27 21:44:11.858 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7204968944099379 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-1886] - [INFO] 2024-04-27 21:44:11.980 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionRunningEvent(taskInstanceId=1886, processInstanceId=690, startTime=1714225451249, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, status=TaskExecutionStatus{code=1, desc='running'}, logPath=/opt/dolphinscheduler/logs/20240427/13386218435520/15/690/1886.log, executePath=null, processId=0, appIds=null, eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1886] - [INFO] 2024-04-27 21:44:12.007 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionRunningEvent(taskInstanceId=1886, processInstanceId=690, startTime=1714225451249, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, status=TaskExecutionStatus{code=1, desc='running'}, logPath=/opt/dolphinscheduler/logs/20240427/13386218435520/15/690/1886.log, executePath=null, processId=0, appIds=null, eventCreateTime=0, eventSendTime=1714225451973)
[WI-0][TI-1886] - [INFO] 2024-04-27 21:44:12.008 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionInfoEvent(taskInstanceId=1886, processInstanceId=690, startTime=1714225451249, workflowInstanceHost=172.18.0.9:5678, taskInstanceHost=172.18.1.1:1234, logPath=null, processId=0, eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1886] - [INFO] 2024-04-27 21:44:12.019 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionInfoEvent(taskInstanceId=1886, processInstanceId=690, startTime=1714225451249, workflowInstanceHost=172.18.0.9:5678, taskInstanceHost=172.18.1.1:1234, logPath=null, processId=0, eventCreateTime=0, eventSendTime=1714225451973)
[WI-0][TI-1887] - [INFO] 2024-04-27 21:44:12.021 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionRunningEvent(taskInstanceId=1887, processInstanceId=689, startTime=1714225451217, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, status=TaskExecutionStatus{code=1, desc='running'}, logPath=/opt/dolphinscheduler/logs/20240427/13377949373536/19/689/1887.log, executePath=null, processId=0, appIds=null, eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1887] - [INFO] 2024-04-27 21:44:12.036 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionRunningEvent(taskInstanceId=1887, processInstanceId=689, startTime=1714225451217, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, status=TaskExecutionStatus{code=1, desc='running'}, logPath=/opt/dolphinscheduler/logs/20240427/13377949373536/19/689/1887.log, executePath=null, processId=0, appIds=null, eventCreateTime=0, eventSendTime=1714225451973)
[WI-0][TI-1887] - [INFO] 2024-04-27 21:44:12.036 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionInfoEvent(taskInstanceId=1887, processInstanceId=689, startTime=1714225451217, workflowInstanceHost=172.18.0.9:5678, taskInstanceHost=172.18.1.1:1234, logPath=null, processId=0, eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1886] - [INFO] 2024-04-27 21:44:12.093 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1886, success=true)
[WI-0][TI-1887] - [INFO] 2024-04-27 21:44:12.101 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionInfoEvent(taskInstanceId=1887, processInstanceId=689, startTime=1714225451217, workflowInstanceHost=172.18.0.9:5678, taskInstanceHost=172.18.1.1:1234, logPath=null, processId=0, eventCreateTime=0, eventSendTime=1714225451973)
[WI-0][TI-1886] - [INFO] 2024-04-27 21:44:12.110 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1886)
[WI-0][TI-1887] - [INFO] 2024-04-27 21:44:12.144 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1887, success=true)
[WI-0][TI-1886] - [INFO] 2024-04-27 21:44:12.173 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1886, success=true)
[WI-0][TI-1887] - [INFO] 2024-04-27 21:44:12.180 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1887)
[WI-0][TI-1887] - [INFO] 2024-04-27 21:44:12.265 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1887, success=true)
[WI-0][TI-1886] - [INFO] 2024-04-27 21:44:12.267 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1886)
[WI-0][TI-0] - [INFO] 2024-04-27 21:44:12.299 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
[WI-0][TI-0] - [INFO] 2024-04-27 21:44:12.330 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
	[nltk_data] Downloading package vader_lexicon to
	[nltk_data]     /local_storage/nltk_data...
	[nltk_data]   Package vader_lexicon is already up-to-date!
[WI-0][TI-1887] - [INFO] 2024-04-27 21:44:12.340 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1887)
[WI-0][TI-0] - [INFO] 2024-04-27 21:44:12.877 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9971751412429379 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:44:13.883 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8304093567251462 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:44:14.885 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.888235294117647 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:44:15.893 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7560137457044673 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:44:16.896 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7896440129449838 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:44:17.458 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	:: loading settings :: url = jar:file:/opt/spark-3.5.1-bin-hadoop3/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml
	Ivy Default Cache set to: /tmp
	The jars for the packages stored in: /tmp/jars
	org.apache.spark#spark-sql-kafka-0-10_2.12 added as a dependency
	:: resolving dependencies :: org.apache.spark#spark-submit-parent-f5d87c4f-2b37-4896-9f11-735d533db733;1.0
		confs: [default]
		found org.apache.spark#spark-sql-kafka-0-10_2.12;3.5.1 in central
		found org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.5.1 in central
[WI-0][TI-0] - [INFO] 2024-04-27 21:44:17.472 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	:: loading settings :: url = jar:file:/opt/spark-3.5.1-bin-hadoop3/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml
	Ivy Default Cache set to: /tmp
	The jars for the packages stored in: /tmp/jars
	org.apache.spark#spark-sql-kafka-0-10_2.12 added as a dependency
	:: resolving dependencies :: org.apache.spark#spark-submit-parent-a88d8f78-0d95-4cfd-a0b1-cb0de5b42782;1.0
		confs: [default]
[WI-0][TI-0] - [INFO] 2024-04-27 21:44:17.900 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8765957446808511 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:44:18.478 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
		found org.apache.spark#spark-sql-kafka-0-10_2.12;3.5.1 in central
		found org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.5.1 in central
		found org.apache.kafka#kafka-clients;3.4.1 in central
		found org.lz4#lz4-java;1.8.0 in central
		found org.xerial.snappy#snappy-java;1.1.10.3 in central
		found org.slf4j#slf4j-api;2.0.7 in central
		found org.apache.hadoop#hadoop-client-runtime;3.3.4 in central
		found org.apache.hadoop#hadoop-client-api;3.3.4 in central
[WI-0][TI-0] - [INFO] 2024-04-27 21:44:18.478 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
		found org.apache.kafka#kafka-clients;3.4.1 in central
		found org.lz4#lz4-java;1.8.0 in central
		found org.xerial.snappy#snappy-java;1.1.10.3 in central
		found org.slf4j#slf4j-api;2.0.7 in central
		found org.apache.hadoop#hadoop-client-runtime;3.3.4 in central
		found org.apache.hadoop#hadoop-client-api;3.3.4 in central
		found commons-logging#commons-logging;1.1.3 in central
		found com.google.code.findbugs#jsr305;3.0.0 in central
		found org.apache.commons#commons-pool2;2.11.1 in central
	:: resolution report :: resolve 1578ms :: artifacts dl 36ms
		:: modules in use:
		com.google.code.findbugs#jsr305;3.0.0 from central in [default]
		commons-logging#commons-logging;1.1.3 from central in [default]
		org.apache.commons#commons-pool2;2.11.1 from central in [default]
		org.apache.hadoop#hadoop-client-api;3.3.4 from central in [default]
		org.apache.hadoop#hadoop-client-runtime;3.3.4 from central in [default]
		org.apache.kafka#kafka-clients;3.4.1 from central in [default]
		org.apache.spark#spark-sql-kafka-0-10_2.12;3.5.1 from central in [default]
		org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.5.1 from central in [default]
		org.lz4#lz4-java;1.8.0 from central in [default]
		org.slf4j#slf4j-api;2.0.7 from central in [default]
		org.xerial.snappy#snappy-java;1.1.10.3 from central in [default]
		---------------------------------------------------------------------
		|                  |            modules            ||   artifacts   |
		|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
		---------------------------------------------------------------------
		|      default     |   11  |   0   |   0   |   0   ||   11  |   0   |
		---------------------------------------------------------------------
	:: retrieving :: org.apache.spark#spark-submit-parent-f5d87c4f-2b37-4896-9f11-735d533db733
		confs: [default]
[WI-0][TI-0] - [INFO] 2024-04-27 21:44:18.902 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8340248962655601 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:44:19.492 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
		found com.google.code.findbugs#jsr305;3.0.0 in central
		found org.apache.commons#commons-pool2;2.11.1 in central
	:: resolution report :: resolve 1422ms :: artifacts dl 55ms
		:: modules in use:
		com.google.code.findbugs#jsr305;3.0.0 from central in [default]
		commons-logging#commons-logging;1.1.3 from central in [default]
		org.apache.commons#commons-pool2;2.11.1 from central in [default]
		org.apache.hadoop#hadoop-client-api;3.3.4 from central in [default]
		org.apache.hadoop#hadoop-client-runtime;3.3.4 from central in [default]
		org.apache.kafka#kafka-clients;3.4.1 from central in [default]
		org.apache.spark#spark-sql-kafka-0-10_2.12;3.5.1 from central in [default]
		org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.5.1 from central in [default]
		org.lz4#lz4-java;1.8.0 from central in [default]
		org.slf4j#slf4j-api;2.0.7 from central in [default]
		org.xerial.snappy#snappy-java;1.1.10.3 from central in [default]
		---------------------------------------------------------------------
		|                  |            modules            ||   artifacts   |
		|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
		---------------------------------------------------------------------
		|      default     |   11  |   0   |   0   |   0   ||   11  |   0   |
		---------------------------------------------------------------------
	:: retrieving :: org.apache.spark#spark-submit-parent-a88d8f78-0d95-4cfd-a0b1-cb0de5b42782
		confs: [default]
		0 artifacts copied, 11 already retrieved (0kB/23ms)
[WI-0][TI-0] - [INFO] 2024-04-27 21:44:19.514 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/27 21:44:19 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[WI-0][TI-0] - [INFO] 2024-04-27 21:44:19.904 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9227947491105386 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:44:20.495 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/27 21:44:19 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
	Setting default log level to "WARN".
	To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[WI-0][TI-0] - [INFO] 2024-04-27 21:44:20.515 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	Setting default log level to "WARN".
	To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[WI-0][TI-0] - [INFO] 2024-04-27 21:44:20.905 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7975206611570248 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:44:21.912 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8906752411575563 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:44:22.928 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9171974522292994 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:44:23.931 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8551236749116607 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:44:24.555 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/27 21:44:23 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
	24/04/27 21:44:23 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
	24/04/27 21:44:23 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
[WI-0][TI-0] - [INFO] 2024-04-27 21:44:24.565 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/27 21:44:24 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
	24/04/27 21:44:24 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
	24/04/27 21:44:24 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
	24/04/27 21:44:24 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.
[WI-0][TI-0] - [INFO] 2024-04-27 21:44:24.940 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7142857142857143 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:44:25.944 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8433048433048433 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:44:26.947 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8328530259365995 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:44:27.959 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7925072046109509 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:44:28.969 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7300613496932515 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:44:29.970 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8078078078078078 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:44:30.972 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8828828828828829 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:44:31.985 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.71280276816609 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:44:34.022 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7072072072072072 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:44:35.094 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8687782805429864 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:44:36.150 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9423728813559322 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:44:36.671 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/27 21:44:35 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.
[WI-0][TI-0] - [INFO] 2024-04-27 21:44:36.681 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/27 21:44:36 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.
[WI-0][TI-0] - [INFO] 2024-04-27 21:44:37.157 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7878787878787878 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:44:38.162 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.867579908675799 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:44:38.681 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/27 21:44:37 WARN AdminClientConfig: These configurations '[key.deserializer, value.deserializer, enable.auto.commit, max.poll.records, auto.offset.reset]' were supplied but are not used yet.
[WI-0][TI-0] - [INFO] 2024-04-27 21:44:39.182 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7593220338983051 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:44:39.684 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/27 21:44:38 WARN AdminClientConfig: These configurations '[key.deserializer, value.deserializer, enable.auto.commit, max.poll.records, auto.offset.reset]' were supplied but are not used yet.
[WI-0][TI-0] - [INFO] 2024-04-27 21:44:40.185 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8855876249764195 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:44:41.192 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8299319727891157 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:44:42.195 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8799999999999999 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:44:43.198 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8443708609271523 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:44:43.729 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/27 21:44:43 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
[WI-0][TI-0] - [INFO] 2024-04-27 21:44:43.731 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	
	[Stage 0:>                                                          (0 + 0) / 1]
[WI-0][TI-0] - [INFO] 2024-04-27 21:44:44.204 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.882882882882883 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:44:44.740 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	
	[Stage 0:>                                                          (0 + 1) / 1]
[WI-0][TI-0] - [INFO] 2024-04-27 21:44:45.233 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8419452887537994 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:44:45.741 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	
	[Stage 0:>                                                          (0 + 1) / 1]
[WI-0][TI-0] - [INFO] 2024-04-27 21:44:45.742 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	
	                                                                                
[WI-0][TI-0] - [INFO] 2024-04-27 21:44:46.236 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7316293929712461 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:44:46.742 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	
	[Stage 0:===========================================================(1 + 0) / 1]
	
	                                                                                
[WI-0][TI-0] - [INFO] 2024-04-27 21:44:47.238 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7126099706744868 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:44:50.251 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8522727272727273 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:44:52.276 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7002224565823925 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:44:54.306 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7001699641460754 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:44:55.428 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7000617979136643 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:44:56.435 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7000866522869205 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:44:57.437 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7005294578008533 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:44:58.517 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7015691659429073 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:44:59.530 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.782258064516129 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:45:00.728 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7019495372712204 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:45:01.730 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7019978541728306 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:45:02.732 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7019578883406346 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:45:03.735 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7025400771797882 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:45:04.738 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7021931101291314 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:45:05.751 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7020093866020214 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:45:06.755 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7020336444703195 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:45:07.757 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7021708406106938 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:45:08.833 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.702283182377812 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:45:09.850 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.702570896602626 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:45:10.872 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7891737891737892 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:45:11.875 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.703166805055817 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:45:12.878 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7026235878739291 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:45:13.880 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7023124111207613 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:45:14.882 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7207977207977208 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:45:15.913 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8484848484848484 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:45:16.916 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.742296918767507 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:45:17.920 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7342857142857142 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:45:18.924 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8155235410794446 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:45:19.928 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7032876967273352 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:45:20.943 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7033980501445928 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:45:21.955 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7314285714285714 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:45:22.958 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.736231884057971 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:45:23.960 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7033604703322294 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:45:24.964 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7034909060830781 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:45:25.975 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7043134864203658 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:45:27.286 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.70461830045398 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:45:28.298 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7905027932960894 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:45:29.305 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8779840848806366 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:45:30.320 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7045282282052995 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:45:31.334 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8678160919540231 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:45:32.338 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.777456647398844 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:45:33.345 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.704406143523865 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:45:34.347 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7043011586512307 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:45:35.349 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7049962857624605 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:45:36.368 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.704242701165332 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:45:37.371 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8817276758542736 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:45:38.373 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8914285714285715 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [ERROR] 2024-04-27 21:45:38.647 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[279] - Parse var pool error
java.io.IOException: Stream closed
	at java.io.BufferedInputStream.getBufIfOpen(BufferedInputStream.java:170)
	at java.io.BufferedInputStream.read1(BufferedInputStream.java:283)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:345)
	at sun.nio.cs.StreamDecoder.readBytes(StreamDecoder.java:284)
	at sun.nio.cs.StreamDecoder.implRead(StreamDecoder.java:326)
	at sun.nio.cs.StreamDecoder.read(StreamDecoder.java:178)
	at java.io.InputStreamReader.read(InputStreamReader.java:184)
	at java.io.BufferedReader.fill(BufferedReader.java:161)
	at java.io.BufferedReader.readLine(BufferedReader.java:324)
	at java.io.BufferedReader.readLine(BufferedReader.java:389)
	at org.apache.dolphinscheduler.plugin.task.api.AbstractCommandExecutor.lambda$parseProcessOutput$1(AbstractCommandExecutor.java:273)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
[WI-686][TI-1883] - [INFO] 2024-04-27 21:45:38.869 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has killed. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13377949373536_19/686/1883, processId:838 ,exitStatusCode:137 ,processWaitForStatus:true ,processExitValue:137
[WI-686][TI-1883] - [INFO] 2024-04-27 21:45:38.869 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-686][TI-1883] - [INFO] 2024-04-27 21:45:38.870 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-686][TI-1883] - [INFO] 2024-04-27 21:45:38.870 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-686][TI-1883] - [INFO] 2024-04-27 21:45:38.871 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-686][TI-1883] - [INFO] 2024-04-27 21:45:38.910 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: KILL to master : 172.18.1.1:1234
[WI-686][TI-1883] - [INFO] 2024-04-27 21:45:38.911 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-686][TI-1883] - [INFO] 2024-04-27 21:45:38.912 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13377949373536_19/686/1883
[WI-686][TI-1883] - [INFO] 2024-04-27 21:45:38.913 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13377949373536_19/686/1883
[WI-686][TI-1883] - [INFO] 2024-04-27 21:45:38.914 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-1883] - [INFO] 2024-04-27 21:45:39.296 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1883, processInstanceId=686, status=9, startTime=1714224330789, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240427/13377949373536/19/686/1883.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13377949373536_19/686/1883, endTime=1714225538871, processId=838, appIds=null, varPool=[], eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1883] - [INFO] 2024-04-27 21:45:39.302 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1883, processInstanceId=686, status=9, startTime=1714224330789, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240427/13377949373536/19/686/1883.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13377949373536_19/686/1883, endTime=1714225538871, processId=838, appIds=null, varPool=[], eventCreateTime=0, eventSendTime=1714225539294)
[WI-0][TI-0] - [INFO] 2024-04-27 21:45:39.304 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	
	[Stage 1:>                                                          (0 + 0) / 1]
	
	[Stage 1:>                                                          (0 + 1) / 1]
[WI-0][TI-0] - [INFO] 2024-04-27 21:45:39.378 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.955621301775148 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:45:40.389 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9938271604938272 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [ERROR] 2024-04-27 21:45:40.430 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[279] - Parse var pool error
java.io.IOException: Stream closed
	at java.io.BufferedInputStream.getBufIfOpen(BufferedInputStream.java:170)
	at java.io.BufferedInputStream.read1(BufferedInputStream.java:283)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:345)
	at sun.nio.cs.StreamDecoder.readBytes(StreamDecoder.java:284)
	at sun.nio.cs.StreamDecoder.implRead(StreamDecoder.java:326)
	at sun.nio.cs.StreamDecoder.read(StreamDecoder.java:178)
	at java.io.InputStreamReader.read(InputStreamReader.java:184)
	at java.io.BufferedReader.fill(BufferedReader.java:161)
	at java.io.BufferedReader.readLine(BufferedReader.java:324)
	at java.io.BufferedReader.readLine(BufferedReader.java:389)
	at org.apache.dolphinscheduler.plugin.task.api.AbstractCommandExecutor.lambda$parseProcessOutput$1(AbstractCommandExecutor.java:273)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
[WI-687][TI-1884] - [INFO] 2024-04-27 21:45:40.918 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has killed. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13386218435520_15/687/1884, processId:1366 ,exitStatusCode:137 ,processWaitForStatus:true ,processExitValue:137
[WI-687][TI-1884] - [INFO] 2024-04-27 21:45:40.919 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-687][TI-1884] - [INFO] 2024-04-27 21:45:40.920 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-687][TI-1884] - [INFO] 2024-04-27 21:45:40.920 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-687][TI-1884] - [INFO] 2024-04-27 21:45:40.923 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-687][TI-1884] - [INFO] 2024-04-27 21:45:40.931 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: KILL to master : 172.18.1.1:1234
[WI-687][TI-1884] - [INFO] 2024-04-27 21:45:40.934 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-687][TI-1884] - [INFO] 2024-04-27 21:45:40.937 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13386218435520_15/687/1884
[WI-687][TI-1884] - [INFO] 2024-04-27 21:45:40.949 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13386218435520_15/687/1884
[WI-687][TI-1884] - [INFO] 2024-04-27 21:45:40.954 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-0] - [INFO] 2024-04-27 21:45:41.309 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	
	[Stage 1:>                                                          (0 + 0) / 1]
	
	[Stage 1:>                                                          (0 + 1) / 1]
[WI-0][TI-1884] - [INFO] 2024-04-27 21:45:41.312 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1884, processInstanceId=687, status=9, startTime=1714225179980, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240427/13386218435520/15/687/1884.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13386218435520_15/687/1884, endTime=1714225540921, processId=1366, appIds=null, varPool=[], eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1884] - [INFO] 2024-04-27 21:45:41.335 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1884, processInstanceId=687, status=9, startTime=1714225179980, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240427/13386218435520/15/687/1884.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13386218435520_15/687/1884, endTime=1714225540921, processId=1366, appIds=null, varPool=[], eventCreateTime=0, eventSendTime=1714225541312)
[WI-0][TI-0] - [INFO] 2024-04-27 21:45:41.426 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.0168067226890756 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:45:42.442 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9749103942652331 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:45:43.446 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7447552447552448 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:45:44.449 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.89 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:45:45.333 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	
	                                                                                
[WI-0][TI-0] - [INFO] 2024-04-27 21:45:45.335 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/27 21:45:44 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[WI-0][TI-0] - [INFO] 2024-04-27 21:45:45.451 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9707112970711297 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:45:46.464 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7171144828222479 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:45:47.465 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9196141479099679 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:45:48.337 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	
	                                                                                
	24/04/27 21:45:48 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[WI-0][TI-0] - [INFO] 2024-04-27 21:45:48.467 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7486187845303868 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:45:49.472 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7168369091817225 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:45:50.474 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7170289837782465 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:45:51.762 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7170661659206378 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:45:52.765 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7169373208496775 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:45:53.766 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7169677426025431 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:45:54.768 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7170771018448705 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:45:55.774 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7171194536968991 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:45:56.785 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7170836633994102 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:45:57.786 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7168319383070713 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:45:58.788 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7168665355946439 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:45:59.790 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7170385278575769 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:46:00.807 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7171566358392905 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:46:01.814 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8323170731707317 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:46:02.829 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7176235003865352 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:46:03.837 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8688750395158741 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:46:04.865 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7178410258612736 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:46:05.869 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9028571428571429 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:46:06.906 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7584269662921348 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:46:07.909 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8093841642228738 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:46:08.928 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7427745664739884 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:46:09.948 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9083333333333332 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:46:11.050 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9796437659033078 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:46:12.079 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.0028735632183907 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:46:13.092 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9855907780979827 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:46:14.115 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9690140845070423 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:46:15.154 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8517441860465116 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:46:16.157 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7672413793103448 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:46:17.172 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7198500545603201 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:46:18.174 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7193155861178184 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:46:19.177 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7186944256213991 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:46:20.179 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.718781913015261 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:46:21.187 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.96986301369863 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:46:22.202 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9339339339339339 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:46:23.205 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9638888888888888 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:46:24.207 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9573863636363635 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:46:25.209 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9628571428571429 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:46:26.220 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9395770392749245 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:46:27.244 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7823691460055097 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:46:28.249 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7211379087649643 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:46:29.252 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7207619118063443 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:46:30.254 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.747093023255814 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:46:31.256 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7206945067460734 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:46:32.259 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7168674698795181 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:46:33.263 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7202942519191553 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:46:34.265 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.720304790173416 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:46:35.268 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7204250853399761 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:46:36.270 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7207147879146505 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:46:37.310 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.720121265481292 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:46:38.311 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7204028158215384 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:46:39.497 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7208905580423185 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:46:40.499 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7205370294371221 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:46:41.505 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7210677200148887 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:46:42.508 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7207112088849016 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:46:43.510 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7208474108503456 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:46:44.512 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7203459490155282 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:46:45.516 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7210699071997353 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:46:46.518 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7942028985507247 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:46:47.550 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7209185937753515 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:46:48.682 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7208322993914059 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:46:49.684 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7162998558844021 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:46:50.717 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7125607639717368 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:46:51.731 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9164345403899721 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:46:52.742 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7129140937419471 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:46:53.744 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.76 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-1885] - [INFO] 2024-04-27 21:46:54.139 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1885, processInstanceId=688, status=9, startTime=1714225211279, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240427/13386218435520/15/688/1885.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13386218435520_15/688/1885, endTime=1714225243778, processId=1608, appIds=null, varPool=[], eventCreateTime=0, eventSendTime=1714225314028)
[WI-0][TI-1885] - [INFO] 2024-04-27 21:46:54.154 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1885, processInstanceId=688, status=9, startTime=1714225211279, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240427/13386218435520/15/688/1885.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13386218435520_15/688/1885, endTime=1714225243778, processId=1608, appIds=null, varPool=[], eventCreateTime=0, eventSendTime=1714225614139)
[WI-0][TI-0] - [INFO] 2024-04-27 21:46:54.746 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7535014005602241 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:46:55.752 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8746438746438746 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:46:56.753 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9715909090909091 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:46:58.031 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9444444444444443 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:46:59.038 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9538904899135446 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:47:00.051 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.863905325443787 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:47:01.057 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8005698005698005 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:47:02.066 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7736389684813754 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:47:03.069 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7105980638244398 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:47:04.072 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7107811908465916 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:47:05.081 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.711002295351079 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:47:06.084 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.711342104342238 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:47:07.086 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7114283987261836 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:47:08.131 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7039106145251397 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:47:09.132 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7112888165659766 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:47:10.137 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7109317089310313 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:47:11.149 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7994186046511628 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:47:12.162 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7108867722241841 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:47:13.175 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9666666666666668 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:47:14.187 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8781163434903047 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:47:15.189 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7105384133286249 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:47:16.191 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7092263012556828 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:47:17.193 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7093565381715453 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:47:18.289 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7912087912087912 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:47:19.293 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8523676880222841 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:47:20.297 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7594202898550725 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:47:21.303 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9206349206349206 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:47:22.305 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9488636363636364 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:47:23.323 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9195046439628483 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:47:24.333 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7105223076947549 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:47:25.356 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8114123376623376 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:47:26.866 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7100532559626636 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:47:27.883 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7097609685331705 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:47:28.897 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.709811074949655 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:47:29.899 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7096774578390296 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:47:30.902 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7094012760434065 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:47:31.906 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7093418243825776 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:47:32.908 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7089684122787762 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:47:33.910 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7088568658516023 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:47:34.917 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7089938631569905 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:47:35.918 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7089825295627857 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:47:36.920 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7090710111315779 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:47:37.924 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7097973553356175 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:47:38.942 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7096118422936332 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:47:39.946 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7091453754163605 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:47:40.948 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.709359719531322 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:47:41.950 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7095098399457896 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:47:42.951 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.70953548965899 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:47:43.955 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7094639090640121 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:47:44.958 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.709135234832072 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:47:45.967 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7093098119498236 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:47:46.968 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7092068154270498 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:47:47.970 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7091847447435983 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:47:48.978 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7092664659228648 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:47:49.981 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.709291519131107 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:47:50.983 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7094617218791656 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:47:51.984 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7094740496483006 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:47:52.985 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7092931098109955 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:47:53.987 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.709455557994598 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:47:54.990 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7100649872268405 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:47:55.993 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7096078655939122 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:47:56.995 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.709883252049591 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:47:57.997 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.709651211620871 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:47:59.008 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7096386850167499 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:48:00.012 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7098587953463069 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:48:01.014 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7097530151337285 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:48:02.015 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7097333304701096 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:48:03.018 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.710058823342273 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:48:04.020 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7100554431475101 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:48:05.022 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7100546478075659 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:48:06.023 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7087984083657036 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:48:07.026 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7093541521517127 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:48:08.028 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7093863634194527 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:48:09.043 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7091227082279508 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:48:10.052 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8319088319088318 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:48:11.062 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9532967032967032 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:48:12.065 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8966480446927374 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:48:13.068 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8290322580645162 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:48:14.070 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8074534161490683 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:48:15.073 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8816901408450705 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:48:16.082 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9485714285714286 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:48:17.087 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9030470914127424 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:48:18.088 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9199999999999999 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:48:19.117 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7417582417582418 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:48:20.149 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8651685393258427 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:48:21.165 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.930835734870317 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:48:22.177 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9726027397260274 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:48:23.193 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.939655172413793 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:48:24.204 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8961424332344213 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:48:25.269 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8616714697406339 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:48:26.272 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.819929294011417 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:48:27.276 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9277777777777778 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:48:28.282 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8889051689051689 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:48:29.339 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8022922636103151 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:48:30.353 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7161572911994044 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:48:31.375 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7384105960264901 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:48:32.385 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8774373259052924 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:48:33.388 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8764044943820225 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:48:34.401 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7412622664336604 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:48:35.416 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.715044212947498 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:48:36.418 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8271059952357949 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:48:37.439 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8595988538681949 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:48:38.442 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9148351648351648 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:48:39.463 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7151615255892674 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:48:40.465 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7020057306590258 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:48:41.471 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8333333333333334 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:48:42.487 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8674351585014409 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:48:43.489 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8743016759776536 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:48:44.513 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7156647769389592 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:48:45.519 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8839255362201538 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:48:46.528 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7723342939481268 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:48:47.535 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9203539823008849 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:48:48.540 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9046242774566474 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:48:49.594 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7857142857142857 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:48:50.608 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9043144133984881 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:48:51.617 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7834757834757835 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:48:52.622 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8804664723032071 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:48:53.633 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8096590909090908 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:48:54.657 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7462235649546828 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:48:55.667 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8662952646239555 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:48:56.671 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9217391304347826 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:48:57.875 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9123287671232877 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:48:58.877 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8858858858858859 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:48:59.909 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9478021978021978 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:49:00.911 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9150141643059491 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:49:01.914 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7855072463768116 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:49:02.921 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8457300275482094 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:49:03.952 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9482288828337875 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:49:05.032 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.0098744641763626 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:49:06.051 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8315217391304348 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:49:07.054 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7205640709952248 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:49:08.056 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8826979472140764 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:49:09.063 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7209559747527288 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:49:10.076 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7208694815337972 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:49:11.085 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8635103151052707 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:49:12.088 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7333333333333334 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:49:13.100 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7212633736411617 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:49:14.147 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.720772847730577 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:49:15.150 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8348348348348348 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:49:16.153 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9161676646706588 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:49:17.155 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7209104415409234 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:49:18.169 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7665706051873199 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:49:19.175 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7179354724796473 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:49:20.188 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7183488504156447 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:49:21.192 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7167289417842975 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:49:22.194 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7171922273017933 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:49:23.198 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7174336129748577 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:49:24.199 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7174332153048856 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:49:25.200 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7180458258969049 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:49:26.204 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7180454282269327 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:49:27.206 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.716543229907327 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:49:28.209 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.716543229907327 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:49:29.211 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7160942605088266 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:49:30.221 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7161668352787348 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:49:31.223 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.716954619493464 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:49:32.224 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.716779247035768 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:49:33.225 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.716587172439244 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:49:34.227 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7165400485475502 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:49:35.229 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7176515361195682 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:49:36.233 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7499999999999999 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:49:37.234 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7235402330664172 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:49:38.235 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7256045378915856 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:49:39.238 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7285606176291871 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:49:40.250 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7282975589426433 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:49:41.254 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7241623877377669 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:49:42.259 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7240941873375518 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:49:43.260 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7240925966576635 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:49:44.262 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7241914176457301 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:49:45.264 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7248167536768566 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:49:46.266 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7248666612583551 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:49:47.268 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7246342231596629 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:49:48.270 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7246340243246768 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:49:49.272 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7240691341293095 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:49:50.287 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7241683527873484 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:49:51.288 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7245190977027401 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:49:52.365 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.72469427132545 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:49:53.368 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7251627265525831 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:49:54.370 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7253150341518972 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:49:55.372 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7256293922648418 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:49:56.374 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7260908882674633 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:49:57.375 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7259073635753394 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:49:58.376 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7261726094467297 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:49:59.377 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7264450133776179 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:50:00.396 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7267329264374179 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:50:01.399 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7273338057652602 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:50:02.414 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7276865390305124 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:50:03.416 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7275040085133188 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:50:04.417 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7278273142006356 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:50:05.419 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7280893787122492 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:50:06.422 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7282949740878246 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:50:07.424 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7287447388262691 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:50:08.425 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7289393982776118 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:50:09.427 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7291525493826572 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:50:10.438 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7293726597122142 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:50:11.439 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7296106651905158 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:50:12.441 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7296786667557448 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:50:13.444 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7300172827369874 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:50:14.445 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7304899134988276 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:50:15.446 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7308879811408993 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:50:16.448 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7313075229614642 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:50:17.450 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7313087159713805 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:50:18.452 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7316791455503912 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:50:19.456 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7320869561067792 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:50:20.479 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7361586989511056 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:50:21.486 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.737535432394514 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:50:22.500 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7375026246218158 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:50:23.501 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.717948717948718 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:50:24.503 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7377905376816158 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:50:25.505 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7384828811030411 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:50:26.507 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7387952508661252 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:50:27.510 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7392684781329236 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:50:28.512 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7389175343825458 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:50:29.515 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7392428284197231 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:50:30.528 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7395275601197464 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:50:31.530 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7399826934028142 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:50:32.531 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7395728944965657 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:50:33.536 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7387976368859578 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:50:34.537 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7392155880266343 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:50:35.538 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7396271764477573 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:50:36.544 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7399586343695023 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:50:37.550 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.739793601331081 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:50:38.560 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7358932542447293 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:50:39.562 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7352074723778438 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-1883] - [INFO] 2024-04-27 21:50:40.053 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1883, processInstanceId=686, status=9, startTime=1714224330789, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240427/13377949373536/19/686/1883.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13377949373536_19/686/1883, endTime=1714225538871, processId=838, appIds=null, varPool=[], eventCreateTime=0, eventSendTime=1714225539294)
[WI-0][TI-1883] - [INFO] 2024-04-27 21:50:40.074 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1883, processInstanceId=686, status=9, startTime=1714224330789, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240427/13377949373536/19/686/1883.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13377949373536_19/686/1883, endTime=1714225538871, processId=838, appIds=null, varPool=[], eventCreateTime=0, eventSendTime=1714225840052)
[WI-0][TI-0] - [INFO] 2024-04-27 21:50:40.575 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7354065061988795 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:50:41.576 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7360887090360162 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-1884] - [INFO] 2024-04-27 21:50:42.081 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1884, processInstanceId=687, status=9, startTime=1714225179980, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240427/13386218435520/15/687/1884.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13386218435520_15/687/1884, endTime=1714225540921, processId=1366, appIds=null, varPool=[], eventCreateTime=0, eventSendTime=1714225541312)
[WI-0][TI-1884] - [INFO] 2024-04-27 21:50:42.088 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1884, processInstanceId=687, status=9, startTime=1714225179980, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240427/13386218435520/15/687/1884.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13386218435520_15/687/1884, endTime=1714225540921, processId=1366, appIds=null, varPool=[], eventCreateTime=0, eventSendTime=1714225842081)
[WI-0][TI-0] - [INFO] 2024-04-27 21:50:42.580 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7315208729014956 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:50:43.584 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7310490374795995 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:50:44.585 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7314087299693635 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:50:45.589 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7319097941342089 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:50:46.590 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7321352730083892 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:50:47.592 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7309444502769373 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:50:48.593 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7325325453105166 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:50:49.595 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7323430555688112 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:50:50.609 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7327120933029195 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:50:51.615 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7330692009378649 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:50:52.628 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7470238095238095 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:50:53.632 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.875 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:50:54.634 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7335875637464965 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:50:55.636 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7338880034104177 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:50:56.645 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.734213297447595 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:50:57.647 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7344749642892365 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:50:58.648 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7350517845837667 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:50:59.651 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.735204688688039 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:51:00.670 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7356814949845863 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:51:01.681 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.942528735632184 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:51:02.684 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9647058823529411 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:51:03.686 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8222222222222222 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:51:04.689 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9694444444444444 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:51:05.694 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8702064896755163 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:51:06.729 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7453661506501109 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:51:07.731 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7485152991591666 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:51:08.740 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8795518207282913 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:51:09.764 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8027210884353742 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:51:10.931 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9410440743774077 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:51:11.942 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7499592388278598 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:51:12.959 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9526315789473684 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:51:13.966 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7492539711323414 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:51:14.992 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.846153846153846 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:51:15.994 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.962059620596206 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:51:16.995 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.925414364640884 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:51:18.002 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.925207756232687 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:51:19.006 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.925 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:51:20.016 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9245283018867925 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:51:21.040 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9741379310344828 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:51:22.043 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.905292479108635 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:51:23.049 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.978082191780822 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:51:24.061 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9483695652173914 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:51:25.076 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9164420485175203 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:51:26.083 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9550898203592814 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:51:27.086 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9615384615384615 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:51:28.093 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8918043407839327 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:51:29.094 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7590609103142866 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:51:30.097 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7592078493689773 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:51:31.114 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7602972662575438 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:51:32.116 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7604233276386994 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:51:33.117 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7592364816069684 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:51:34.118 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7590889460473196 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:51:35.121 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7596892288702037 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:51:36.123 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7596486665330495 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:51:37.125 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7588205188161524 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:51:38.129 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7585779401331717 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:51:39.131 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7585924550871533 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:51:40.132 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7576909372604038 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:51:41.144 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7582647750301433 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:51:42.147 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7534277163245114 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:51:43.149 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7518821719779468 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:51:44.151 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7524456703284118 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:51:45.152 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7523693176937687 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:51:46.153 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7519442084935943 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:51:47.154 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7464734626874219 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:51:48.156 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7463607232503316 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:51:49.157 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7463605244153456 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:51:50.159 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7468719279994656 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:51:51.173 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7457858913056619 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:51:52.177 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7460986587387181 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:51:53.184 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7459232862810222 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:51:54.202 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7459230874460362 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-1885] - [INFO] 2024-04-27 21:51:54.677 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1885, processInstanceId=688, status=9, startTime=1714225211279, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240427/13386218435520/15/688/1885.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13386218435520_15/688/1885, endTime=1714225243778, processId=1608, appIds=null, varPool=[], eventCreateTime=0, eventSendTime=1714225614139)
[WI-0][TI-1885] - [INFO] 2024-04-27 21:51:54.693 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1885, processInstanceId=688, status=9, startTime=1714225211279, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240427/13386218435520/15/688/1885.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13386218435520_15/688/1885, endTime=1714225243778, processId=1608, appIds=null, varPool=[], eventCreateTime=0, eventSendTime=1714225914677)
[WI-0][TI-0] - [INFO] 2024-04-27 21:51:55.204 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.745310675689003 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:51:56.205 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.745310476854017 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:51:57.214 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7459863169716 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:51:58.220 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7461241096169324 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:51:59.221 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7451048814784416 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:52:00.223 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7449372635852016 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:52:01.236 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7456133025377707 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:52:02.237 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7457133165357537 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:52:03.238 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7449183742615268 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:52:04.239 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7454440939646424 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:52:05.245 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7450649156462456 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:52:06.247 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7450577575867477 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:52:07.248 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7454832644568942 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:52:08.249 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7459843286217395 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:52:09.252 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7460215107641308 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:52:10.254 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7463211550881078 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:52:11.271 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7463205585831496 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:52:12.273 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7462947100349632 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:52:13.279 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7456172792374917 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:52:14.280 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7462632941071673 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:52:15.282 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7462628964371952 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:52:16.292 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7455136862097598 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:52:17.301 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7464094378219138 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:52:18.311 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7285714285714286 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:52:19.328 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7455514648571092 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:52:20.339 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7460628684412292 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:52:21.362 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7374631268436578 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:52:22.365 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7462744288663861 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:52:23.368 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7060518731988472 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:52:24.370 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7472365913638808 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:52:25.372 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7296511627906976 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:52:26.374 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.747429461300349 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:52:27.383 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7470902488141481 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:52:28.389 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7468206285730647 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:52:29.395 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7468317633322835 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:52:30.397 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7473290496323939 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:52:31.424 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7478241487476577 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:52:32.437 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7469240227658106 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:52:33.438 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7471864849473963 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:52:34.443 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7471864849473963 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:52:35.445 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7474449704292608 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:52:36.448 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7543352601156069 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:52:37.459 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9090909090909091 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:52:38.269 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	
	[Stage 2:>                                                          (0 + 1) / 1]
[WI-0][TI-0] - [INFO] 2024-04-27 21:52:38.464 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7470900499791621 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:52:39.273 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	
	                                                                                
[WI-0][TI-0] - [INFO] 2024-04-27 21:52:39.541 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9836512261580382 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:52:40.553 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9542857142857142 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:52:41.818 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/27 21:52:40 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
	
	[Stage 3:>                                                          (0 + 1) / 1]
[WI-0][TI-0] - [INFO] 2024-04-27 21:52:41.830 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9681274900398407 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:52:42.824 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	
	                                                                                
[WI-0][TI-0] - [INFO] 2024-04-27 21:52:42.848 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8984026522001205 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:52:43.850 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9652777777777779 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:52:44.832 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/27 21:52:43 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
	
	[Stage 4:>                                                          (0 + 1) / 1]
	
	                                                                                
[WI-0][TI-0] - [INFO] 2024-04-27 21:52:44.851 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7575943034571837 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:52:45.856 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7194444444444444 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:52:46.859 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8930635838150289 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:52:47.861 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9504132231404958 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:52:48.870 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8961424332344214 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:52:49.903 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9670254403131114 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:52:50.957 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9713631722820539 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:52:52.146 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7530205414666357 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:52:53.147 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7595196226271033 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:52:54.149 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7593933624109617 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:52:55.158 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7134670487106016 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:52:56.165 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8039772727272727 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:52:57.168 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7600874953472613 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:52:58.174 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7592758509342064 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:52:59.178 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9156976744186047 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:53:00.181 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7573964497041421 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:53:01.186 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9362880886426592 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:53:02.251 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7019344285063929 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:53:03.253 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7593533965787657 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:53:04.254 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7591501872230229 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:53:05.256 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7591923402400654 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:53:06.257 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.759278833458997 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:53:07.259 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7590106050628159 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:53:08.262 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.759022932831951 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:53:09.264 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7587556986107001 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:53:10.266 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7591259293547248 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:53:11.267 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7588260861957618 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:53:12.279 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.758838612799883 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:53:13.281 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7585761506182973 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:53:14.283 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7588580986285158 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:53:15.285 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7587167269534344 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:53:16.286 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7591237421698782 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:53:17.288 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7590338687561837 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:53:18.290 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7586119409157862 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:53:19.292 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.758646737038345 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:53:20.295 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7587958632778823 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:53:21.298 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7586089583909955 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:53:22.314 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7576807966761153 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:53:23.316 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7576807966761153 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:53:24.317 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7571049705565153 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:53:25.319 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7573413853549285 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:53:26.322 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7569721487858341 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:53:27.324 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7573348238003887 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:53:28.326 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.756832168955655 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:53:29.327 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7574408028479532 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:53:30.330 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7578422506847877 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:53:31.333 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7573220983612816 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:53:32.346 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7573704152628916 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:53:33.349 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7564150131549227 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:53:34.350 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7564110364552017 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:53:35.353 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7560036235687858 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:53:36.355 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7563911529565968 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:53:37.380 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.757403620705562 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:53:38.382 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7562819925492554 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:53:39.384 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7570447235557421 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:53:40.390 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7570685837540682 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:53:41.394 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7567868345788357 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:53:42.428 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7573994451708549 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:53:43.432 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7578002965027312 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:53:44.434 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.75735590030891 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:53:45.436 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.75735590030891 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:53:46.438 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7570586420047657 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:53:47.439 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.75685205245426 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:53:48.444 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7563933401414432 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:53:49.445 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7525120812137523 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:53:50.447 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7509452615236805 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:53:51.449 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7499192729956639 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:53:52.460 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7499485017386132 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:53:53.462 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7459059876372359 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:53:54.464 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7463400444117825 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:53:55.466 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.746361916260248 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:53:56.467 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7460497453321498 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:53:57.477 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7461577127295749 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:53:58.478 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7462074214760873 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:53:59.480 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7456681809939204 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:54:00.483 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7457809204310106 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:54:01.485 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7454639774632473 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:54:02.501 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7455248209689785 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:54:03.503 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7449539657240297 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:54:04.504 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.747697093191572 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:54:05.506 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7537685194906006 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:54:06.508 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7567232073832998 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:54:07.509 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7606710760313173 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:54:08.511 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7589543347617639 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:54:09.512 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7587417801616767 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:54:10.513 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7585353894461571 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:54:11.515 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7588286710505805 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:54:12.532 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7583804969920244 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:54:13.534 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7584073397151411 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:54:14.536 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7581822585109328 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:54:15.538 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7582196394883101 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:54:16.540 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7583341684402748 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:54:17.545 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7587403883167744 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:54:18.549 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7586157187805211 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:54:19.555 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7579287439037193 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:54:20.556 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7582110895839099 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:54:21.558 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7582110895839099 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:54:22.568 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7582490670662455 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:54:23.570 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7585711797436461 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:54:24.571 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7587895005583286 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:54:25.573 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.758715136273546 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:54:26.574 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7586139292656467 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:54:27.576 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7588382151299108 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:54:28.578 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7590885483773474 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:54:29.580 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7586644333521033 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:54:30.581 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7586769599562245 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:54:31.582 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7587002236495923 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:54:32.594 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7586797436460292 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:54:33.597 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7589113864047772 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:54:34.598 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7586236721799632 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:54:35.600 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7585017863335146 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:54:36.604 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7589491650521266 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:54:37.606 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7584065443751968 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:54:38.607 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7585335999312827 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:54:39.609 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7584988038087239 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:54:40.610 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7585835075127811 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:54:41.612 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7584075385501271 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:54:42.624 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7584047548603224 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:54:43.626 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7591676847017952 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:54:44.627 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7584504869071138 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:54:45.629 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7589640776760803 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:54:46.630 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7583641925231682 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:54:47.632 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7584437265175882 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:54:48.634 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7585841040177392 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:54:49.636 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7584898562343517 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:54:50.641 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.758307126882172 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:54:51.642 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7590034470033181 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:54:52.658 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7624253971132341 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:54:53.664 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7606114255355024 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:54:54.672 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.763911688633956 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:54:55.679 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8804347826086957 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:54:56.682 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8725212464589236 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:54:57.684 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7621283376440758 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:54:58.688 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.756907726250354 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:54:59.692 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7578223671861827 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:55:00.696 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.756976125485555 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:55:01.698 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7571890777556143 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:55:02.729 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7565581743448785 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:55:03.731 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7565707009489996 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:55:04.735 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7534626038781164 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:55:05.739 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7568049285625662 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:55:06.742 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7470331831731518 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:55:07.743 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7470391482227333 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:55:08.746 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7465824242597772 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:55:09.749 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7474767840270289 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:55:10.753 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7194029850746269 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:55:11.756 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7466705081585971 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:55:12.771 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7466828359277322 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:55:13.773 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7468480678011395 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:55:14.775 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7466166238773777 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:55:15.776 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7468914138280984 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:55:16.778 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7468912149931124 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:55:17.781 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7464718720075335 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:55:18.783 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7468349446920602 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:55:19.785 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7474982582055222 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:55:20.787 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.74752152189889 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:55:21.788 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7471980173765871 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:55:22.832 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7460431837776103 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:55:23.833 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.745158765759661 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:55:24.835 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7461338525312489 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:55:25.836 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7461710346736402 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:55:26.840 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7462963007148515 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:55:27.842 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7461354432111373 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:55:28.845 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7467156437004304 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:55:29.846 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7467406969086727 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:55:30.848 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7462400304137995 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:55:31.853 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7466408817456758 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:55:32.880 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7135135135135136 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:55:33.881 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7532153605594103 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:55:34.882 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7573207065163793 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:55:35.885 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.760573845723139 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:55:36.886 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.759890648711072 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:55:37.887 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7592639208350433 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:55:38.889 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.759270482389583 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:55:39.890 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7590475883702212 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-1883] - [INFO] 2024-04-27 21:55:40.248 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1883, processInstanceId=686, status=9, startTime=1714224330789, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240427/13377949373536/19/686/1883.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13377949373536_19/686/1883, endTime=1714225538871, processId=838, appIds=null, varPool=[], eventCreateTime=0, eventSendTime=1714225840052)
[WI-0][TI-1883] - [INFO] 2024-04-27 21:55:40.260 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1883, processInstanceId=686, status=9, startTime=1714224330789, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240427/13377949373536/19/686/1883.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13377949373536_19/686/1883, endTime=1714225538871, processId=838, appIds=null, varPool=[], eventCreateTime=0, eventSendTime=1714226140248)
[WI-0][TI-0] - [INFO] 2024-04-27 21:55:40.892 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7597693593695818 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:55:42.019 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7589362407780333 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-1884] - [INFO] 2024-04-27 21:55:42.263 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1884, processInstanceId=687, status=9, startTime=1714225179980, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240427/13386218435520/15/687/1884.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13386218435520_15/687/1884, endTime=1714225540921, processId=1366, appIds=null, varPool=[], eventCreateTime=0, eventSendTime=1714225842081)
[WI-0][TI-1884] - [INFO] 2024-04-27 21:55:42.268 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1884, processInstanceId=687, status=9, startTime=1714225179980, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240427/13386218435520/15/687/1884.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13386218435520_15/687/1884, endTime=1714225540921, processId=1366, appIds=null, varPool=[], eventCreateTime=0, eventSendTime=1714226142263)
[WI-0][TI-0] - [INFO] 2024-04-27 21:55:43.032 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7589360419430473 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:55:44.033 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7579613528414315 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:55:45.035 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7581224091801317 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:55:46.040 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7576889489105434 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:55:47.042 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7576883524055852 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:55:48.044 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7582625878452969 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:55:49.045 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7582625878452969 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:55:50.047 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.757831314760555 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:55:51.049 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7572550909709829 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:55:52.052 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7574300657587066 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:55:53.061 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7573298529257375 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:55:54.064 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7573292564207794 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:55:55.066 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7566552058180708 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:55:56.069 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7572684129150481 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:55:57.070 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7569413293629963 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:55:58.072 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7569538559671175 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:55:59.073 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.757071566278859 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:56:00.075 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7570711686088868 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:56:01.077 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7575463842255457 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:56:02.079 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7576342692893797 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:56:03.090 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7569423235379266 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:56:04.092 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7567317572876999 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:56:05.095 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7571053682264873 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:56:06.097 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7574926987793122 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:56:07.099 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7574048137154783 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:56:08.101 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7559533183173152 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:56:09.102 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7559672367663387 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:56:10.104 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7568254085661293 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:56:11.106 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7531755935622003 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:56:12.108 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7511645765132933 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:56:13.122 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.751703021655516 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:56:14.125 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7525168532534176 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:56:15.129 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7468912149931124 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:56:16.131 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7455779099102539 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:56:17.133 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7450730678806735 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:56:18.134 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.745058751761678 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:56:19.136 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.745058751761678 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:56:20.137 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7451088581781625 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:56:21.140 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7470119078296446 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:56:22.157 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7861111111111112 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:56:23.204 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7530986444225991 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:56:24.217 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7563356779954888 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:56:25.222 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7597598152902514 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:56:26.233 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7577569504757724 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:56:27.235 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7611610054369439 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:56:28.237 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7587026096694249 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:56:29.239 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7587002236495923 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:56:30.242 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7587123525837414 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:56:31.247 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7573626606984357 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:56:32.248 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.757587741902644 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:56:33.266 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7576899430854735 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:56:34.269 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7580971571369035 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:56:35.272 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.758703206174383 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:56:36.277 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7584783238051608 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:56:37.278 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.758427422048732 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:56:38.279 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7582860503736507 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:56:39.280 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7582661668750458 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:56:40.283 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7580907944173498 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:56:41.285 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7580699167438146 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:56:42.286 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7580824433479357 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:56:43.298 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7580629575193029 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:56:44.301 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7580480448953492 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:56:45.305 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7581126662658153 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:56:46.309 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.75809934432175 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:56:47.311 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.757903690695477 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:56:48.318 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.758303547852423 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:56:49.323 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7576177659855375 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:56:50.326 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7576243275400771 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:56:51.328 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7574682420760281 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:56:52.329 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7574626746964187 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:56:53.342 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7573968603160363 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:56:54.352 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7573459585596075 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:56:55.353 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7573455608896354 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-1885] - [INFO] 2024-04-27 21:56:55.410 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1885, processInstanceId=688, status=9, startTime=1714225211279, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240427/13386218435520/15/688/1885.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13386218435520_15/688/1885, endTime=1714225243778, processId=1608, appIds=null, varPool=[], eventCreateTime=0, eventSendTime=1714225914677)
[WI-0][TI-1885] - [INFO] 2024-04-27 21:56:55.417 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1885, processInstanceId=688, status=9, startTime=1714225211279, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240427/13386218435520/15/688/1885.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13386218435520_15/688/1885, endTime=1714225243778, processId=1608, appIds=null, varPool=[], eventCreateTime=0, eventSendTime=1714226215410)
[WI-0][TI-0] - [INFO] 2024-04-27 21:56:56.363 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.75757183510376 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:56:57.367 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.757535647136299 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:56:58.378 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.757527892571843 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:56:59.380 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7574229076992088 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:57:00.381 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7573765791474593 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:57:01.382 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.757375584972529 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:57:02.385 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7573453620546494 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:57:03.394 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.757363853708352 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:57:04.395 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7575308750966337 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:57:05.396 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7589491650521266 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:57:06.398 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7610440904651466 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:57:07.400 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7422096317280454 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:57:08.402 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7629799478893269 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:57:09.404 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.766566334532706 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:57:10.406 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7564100422802714 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:57:11.408 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7552464599419084 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:57:12.410 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7553526378244589 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:57:13.425 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.755904603745733 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:57:14.427 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7560636717345728 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:57:15.428 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7469341633500991 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:57:16.430 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7461111853428393 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:57:17.432 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7461105888378811 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:57:18.433 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7456272209867941 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:57:19.444 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.745694427212079 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:57:20.446 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7459085724920546 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:57:21.453 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7460065981401771 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:57:22.455 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.745011031365026 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:57:23.476 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7449961187410723 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:57:24.478 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7458566765606955 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:57:25.484 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7454771005723266 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:57:26.487 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7452997397647703 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:57:27.489 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7449895571865327 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:57:28.494 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7449491936843645 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:57:29.495 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7457314105194842 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:57:30.498 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7506925207756232 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:57:31.501 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7459210990961757 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:57:32.505 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7457270361497912 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:57:33.523 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7460147503746051 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:57:34.527 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7460567045566616 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:57:35.538 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8717201166180759 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:57:36.542 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7446859361628347 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:57:37.544 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7447422064638868 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:57:38.546 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7455757227254073 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:57:39.549 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.746002223770484 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:57:40.570 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.745562599616328 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:57:41.577 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7456880644925254 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:57:42.578 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7447640783123523 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:57:43.592 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7447718328768083 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:57:44.593 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7448603144456003 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:57:45.597 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7451476310004422 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:57:46.598 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7454480706643634 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:57:47.601 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7456482974953155 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:57:48.604 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7445531143921535 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:57:49.607 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7449734515526626 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:57:50.611 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.745270908691793 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:57:51.617 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7455691611708677 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:57:52.618 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7499210625105382 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:57:53.630 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.752202693975459 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:57:54.631 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7559026153958726 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:57:55.633 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7570610280245983 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:57:56.634 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7594991426235401 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:57:57.636 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7574895174195354 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:57:58.637 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7570417410309515 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:57:59.640 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7570530746251563 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:58:00.642 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7571338016294925 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:58:01.646 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7567413013670303 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:58:02.649 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7563110224572187 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:58:03.678 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7562957121632928 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:58:04.679 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7563315024607817 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:58:05.680 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7566184213456516 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:58:06.683 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7562048445746681 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:58:07.686 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7561169595108341 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:58:08.688 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7559254814192682 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:58:09.690 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7559491427826082 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:58:10.691 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7561561300030859 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:58:11.693 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7565788531834277 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:58:12.696 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7564796345253888 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:58:13.710 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7560189338627116 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:58:14.724 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7560296709519583 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:58:15.728 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7560197292026558 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:58:16.730 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7562298977829104 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:58:17.731 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7561571241780162 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:58:18.733 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7561517556333929 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:58:19.735 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7562819925492554 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:58:20.736 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7561432057289927 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:58:21.738 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7511321664105672 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:58:22.738 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7458280443227044 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:58:23.752 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.745834605877244 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:58:24.754 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7442488968634974 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:58:25.756 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7442481015235533 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:58:26.757 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7399628099042093 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:58:27.760 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7391899383134339 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:58:28.767 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7397663609379921 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:58:29.770 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7394390785509543 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:58:30.772 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7384353595413752 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:58:31.774 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7386178900585688 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:58:32.776 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7390052206113937 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:58:33.787 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.739742103069694 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:58:34.790 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7457713763516802 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:58:35.792 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7478788283688214 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:58:36.794 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7509221966652987 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:58:37.795 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7532666599858111 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:58:38.800 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7449856733524356 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:58:39.804 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8104395604395604 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:58:40.806 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7515316258975411 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:58:41.825 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7517557129268192 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:58:42.833 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7522003079556264 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:58:43.853 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7513994006318181 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:58:44.857 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7514097400510926 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:58:45.859 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7514721742367123 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:58:46.860 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7514463256885258 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:58:47.862 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7518801836280863 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:58:48.865 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7514039738364972 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:58:49.866 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7514252491800045 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:58:50.868 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7511600033086142 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:58:51.872 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7511602021436002 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:58:52.874 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7499312030948267 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:58:53.884 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7499312030948267 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:58:54.886 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.75034378569088 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:58:55.888 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7502853282049814 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:58:56.890 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7498152822979598 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:58:57.892 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7495868208989886 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:58:58.894 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7501882967317891 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:58:59.896 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7501871037218728 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:59:00.897 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7507893748946175 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:59:01.898 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.750775456445594 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:59:02.901 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.74991191610118 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:59:03.914 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7498234345323879 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:59:04.916 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7499226531904266 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:59:05.921 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.749448630583684 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:59:06.924 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.750575627284614 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:59:07.932 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8961424332344213 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:59:09.001 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8764367816091955 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:59:10.012 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8997289972899729 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:59:11.014 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7512653858512205 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:59:12.016 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7514328049094744 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:59:13.018 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9627659574468086 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:59:14.081 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9727520435967303 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:59:15.086 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9705882352941176 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:59:16.097 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8967551622418879 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:59:17.100 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7533853644724828 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:59:18.101 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7532597007612994 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:59:19.105 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7531686343376887 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:59:20.108 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.704225352112676 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:59:21.112 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.75319826075061 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:59:22.114 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7524711212066262 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:59:23.115 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7524832501407752 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:59:24.124 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7528079476729944 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:59:25.131 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9289617486338798 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:59:26.133 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.884180790960452 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:59:27.134 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7529097511858519 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:59:28.137 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7500459308817775 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:59:29.269 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7477833875755175 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:59:30.272 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7474938838358292 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:59:31.276 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7463865717985181 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:59:32.278 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7408913692890615 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:59:33.281 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7401863004285292 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:59:34.296 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7401853062535989 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:59:35.297 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.740661516045188 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:59:36.298 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.740889380939201 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:59:37.301 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9162011173184357 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:59:38.313 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.917142857142857 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:59:39.318 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9405099150141644 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:59:40.322 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7468426992565163 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:59:41.340 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7461869414725242 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:59:42.342 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9085872576177285 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:59:43.348 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.914364640883978 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:59:44.393 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.893573159600919 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:59:45.395 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8954802259887005 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:59:46.404 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8028169014084507 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:59:47.405 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7444694048630266 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:59:48.407 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[65] - Worker OverLoad: the SystemMemoryUsedPercentage: 0.7445306460387299 is over then the MaxSystemMemoryUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:59:49.410 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7752808988764045 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:59:50.412 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9749071494893222 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:59:51.414 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9011379459355645 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:59:52.417 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.885558583106267 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:59:53.421 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8760330578512396 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:59:54.440 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9361034164358264 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:59:55.441 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9070502108697381 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:59:56.443 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8923512747875354 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:59:57.446 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8943089430894309 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:59:58.447 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9322033898305084 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-27 21:59:59.452 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9397260273972602 is over then the MaxCpuUsagePercentageThresholds 0.7
