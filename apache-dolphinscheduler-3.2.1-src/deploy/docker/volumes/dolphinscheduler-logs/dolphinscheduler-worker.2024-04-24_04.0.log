[WI-0][TI-0] - [WARN] 2024-04-24 04:08:33.228 +0800 o.s.c.k.c.p.AbstractKubernetesProfileEnvironmentPostProcessor:[258] - Not running inside kubernetes. Skipping 'kubernetes' profile activation.
[WI-0][TI-0] - [WARN] 2024-04-24 04:08:38.179 +0800 o.s.c.k.c.p.AbstractKubernetesProfileEnvironmentPostProcessor:[258] - Not running inside kubernetes. Skipping 'kubernetes' profile activation.
[WI-0][TI-0] - [INFO] 2024-04-24 04:08:38.197 +0800 o.a.d.s.w.WorkerServer:[634] - No active profile set, falling back to 1 default profile: "default"
[WI-0][TI-0] - [INFO] 2024-04-24 04:08:47.984 +0800 o.s.c.c.s.GenericScope:[283] - BeanFactory id=7e7bf7c6-2cb3-34d2-a0d5-a56161c67d0e
[WI-0][TI-0] - [INFO] 2024-04-24 04:08:50.051 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'org.springframework.cloud.commons.config.CommonsConfigAutoConfiguration' of type [org.springframework.cloud.commons.config.CommonsConfigAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-04-24 04:08:50.131 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'org.springframework.cloud.client.loadbalancer.LoadBalancerDefaultMappingsProviderAutoConfiguration' of type [org.springframework.cloud.client.loadbalancer.LoadBalancerDefaultMappingsProviderAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-04-24 04:08:50.134 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'loadBalancerClientsDefaultsMappingsProvider' of type [org.springframework.cloud.client.loadbalancer.LoadBalancerDefaultMappingsProviderAutoConfiguration$$Lambda$392/189820624] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-04-24 04:08:50.142 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'defaultsBindHandlerAdvisor' of type [org.springframework.cloud.commons.config.DefaultsBindHandlerAdvisor] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-04-24 04:08:50.386 +0800 o.a.d.c.u.NetUtils:[312] - Get all NetworkInterfaces: [name:eth0 (eth0), name:lo (lo)]
[WI-0][TI-0] - [INFO] 2024-04-24 04:08:50.870 +0800 o.a.d.s.w.c.WorkerConfig:[98] - 
****************************Worker Configuration**************************************
  listen-port -> 1234
  exec-threads -> 100
  max-heartbeat-interval -> PT10S
  host-weight -> 100
  tenantConfig -> TenantConfig(autoCreateTenantEnabled=true, distributedTenantEnabled=false, defaultTenantEnabled=false)
  server-load-protection -> WorkerServerLoadProtection(enabled=true, maxCpuUsagePercentageThresholds=0.7, maxJVMMemoryUsagePercentageThresholds=0.7, maxSystemMemoryUsagePercentageThresholds=0.7, maxDiskUsagePercentageThresholds=0.7)
  registry-disconnect-strategy -> ConnectStrategyProperties(strategy=WAITING, maxWaitingTime=PT1M40S)
  task-execute-threads-full-policy: REJECT
  address -> 172.18.1.1:1234
  registry-path: /nodes/worker/172.18.1.1:1234
****************************Worker Configuration**************************************
[WI-0][TI-0] - [INFO] 2024-04-24 04:08:50.871 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'workerConfig' of type [org.apache.dolphinscheduler.server.worker.config.WorkerConfig$$EnhancerBySpringCGLIB$$153d90bb] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-04-24 04:08:51.563 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'io.kubernetes.client.spring.extended.manifests.config.KubernetesManifestsAutoConfiguration' of type [io.kubernetes.client.spring.extended.manifests.config.KubernetesManifestsAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-04-24 04:08:51.645 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'kubernetes.manifests-io.kubernetes.client.spring.extended.manifests.config.KubernetesManifestsProperties' of type [io.kubernetes.client.spring.extended.manifests.config.KubernetesManifestsProperties] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-04-24 04:08:51.658 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'io.kubernetes.client.spring.extended.controller.config.KubernetesInformerAutoConfiguration' of type [io.kubernetes.client.spring.extended.controller.config.KubernetesInformerAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-04-24 04:08:51.715 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'defaultApiClient' of type [io.kubernetes.client.openapi.ApiClient] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-04-24 04:08:52.450 +0800 o.e.j.u.log:[170] - Logging initialized @33188ms to org.eclipse.jetty.util.log.Slf4jLog
[WI-0][TI-0] - [INFO] 2024-04-24 04:08:55.170 +0800 o.s.b.w.e.j.JettyServletWebServerFactory:[166] - Server initialized with port: 1235
[WI-0][TI-0] - [INFO] 2024-04-24 04:08:55.195 +0800 o.e.j.s.Server:[375] - jetty-9.4.48.v20220622; built: 2022-06-21T20:42:25.880Z; git: 6b67c5719d1f4371b33655ff2d047d24e171e49a; jvm 1.8.0_402-b06
[WI-0][TI-0] - [INFO] 2024-04-24 04:08:55.648 +0800 o.e.j.s.h.C.application:[2368] - Initializing Spring embedded WebApplicationContext
[WI-0][TI-0] - [INFO] 2024-04-24 04:08:55.652 +0800 o.s.b.w.s.c.ServletWebServerApplicationContext:[292] - Root WebApplicationContext: initialization completed in 17266 ms
[WI-0][TI-0] - [INFO] 2024-04-24 04:08:58.408 +0800 o.e.j.s.session:[334] - DefaultSessionIdManager workerName=node0
[WI-0][TI-0] - [INFO] 2024-04-24 04:08:58.409 +0800 o.e.j.s.session:[339] - No SessionScavenger set, using defaults
[WI-0][TI-0] - [INFO] 2024-04-24 04:08:58.411 +0800 o.e.j.s.session:[132] - node0 Scavenging every 660000ms
[WI-0][TI-0] - [INFO] 2024-04-24 04:08:58.433 +0800 o.e.j.s.h.ContextHandler:[921] - Started o.s.b.w.e.j.JettyEmbeddedWebAppContext@5403431a{application,/,[file:///tmp/jetty-docbase.1235.1990172417420492770/],AVAILABLE}
[WI-0][TI-0] - [INFO] 2024-04-24 04:08:58.434 +0800 o.e.j.s.Server:[415] - Started @39173ms
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:00.417 +0800 o.a.c.f.i.CuratorFrameworkImpl:[338] - Starting
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:00.473 +0800 o.a.z.ZooKeeper:[98] - Client environment:zookeeper.version=3.8.0-5a02a05eddb59aee6ac762f7ea82e92a68eb9c0f, built on 2022-02-25 08:49 UTC
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:00.474 +0800 o.a.z.ZooKeeper:[98] - Client environment:host.name=5afbfd5249fc
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:00.474 +0800 o.a.z.ZooKeeper:[98] - Client environment:java.version=1.8.0_402
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:00.474 +0800 o.a.z.ZooKeeper:[98] - Client environment:java.vendor=Temurin
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:00.474 +0800 o.a.z.ZooKeeper:[98] - Client environment:java.home=/opt/java/openjdk
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:00.475 +0800 o.a.z.ZooKeeper:[98] - Client environment:java.class.path=/opt/dolphinscheduler/conf:/opt/dolphinscheduler/libs/kerb-client-1.0.1.jar:/opt/dolphinscheduler/libs/spring-cloud-starter-kubernetes-client-config-2.1.3.jar:/opt/dolphinscheduler/libs/oauth2-oidc-sdk-9.35.jar:/opt/dolphinscheduler/libs/jsqlparser-4.4.jar:/opt/dolphinscheduler/libs/reactive-streams-1.0.4.jar:/opt/dolphinscheduler/libs/kubernetes-model-extensions-5.10.2.jar:/opt/dolphinscheduler/libs/zookeeper-3.8.0.jar:/opt/dolphinscheduler/libs/kubernetes-model-apps-5.10.2.jar:/opt/dolphinscheduler/libs/grpc-api-1.41.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-pigeon-3.2.1.jar:/opt/dolphinscheduler/libs/client-java-api-13.0.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-obs-3.2.1.jar:/opt/dolphinscheduler/libs/spring-web-5.3.22.jar:/opt/dolphinscheduler/libs/aws-java-sdk-emr-1.12.300.jar:/opt/dolphinscheduler/libs/spring-context-5.3.22.jar:/opt/dolphinscheduler/libs/gapic-google-cloud-storage-v2-2.18.0-alpha.jar:/opt/dolphinscheduler/libs/spring-cloud-kubernetes-client-config-2.1.3.jar:/opt/dolphinscheduler/libs/jetty-io-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/annotations-13.0.jar:/opt/dolphinscheduler/libs/jpam-1.1.jar:/opt/dolphinscheduler/libs/joda-time-2.10.13.jar:/opt/dolphinscheduler/libs/spring-cloud-kubernetes-client-autoconfig-2.1.3.jar:/opt/dolphinscheduler/libs/kerb-identity-1.0.1.jar:/opt/dolphinscheduler/libs/vertica-jdbc-12.0.4-0.jar:/opt/dolphinscheduler/libs/grpc-googleapis-1.52.1.jar:/opt/dolphinscheduler/libs/aliyun-java-sdk-kms-2.11.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-dvc-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-hana-3.2.1.jar:/opt/dolphinscheduler/libs/kubernetes-httpclient-okhttp-6.0.0.jar:/opt/dolphinscheduler/libs/jline-2.12.jar:/opt/dolphinscheduler/libs/sshd-core-2.8.0.jar:/opt/dolphinscheduler/libs/jna-platform-5.10.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-sqlserver-3.2.1.jar:/opt/dolphinscheduler/libs/commons-beanutils-1.9.4.jar:/opt/dolphinscheduler/libs/grpc-services-1.41.0.jar:/opt/dolphinscheduler/libs/jmespath-java-1.12.300.jar:/opt/dolphinscheduler/libs/curator-client-5.3.0.jar:/opt/dolphinscheduler/libs/proto-google-common-protos-2.0.1.jar:/opt/dolphinscheduler/libs/mybatis-3.5.10.jar:/opt/dolphinscheduler/libs/jackson-annotations-2.13.4.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-all-3.2.1.jar:/opt/dolphinscheduler/libs/jakarta.xml.bind-api-2.3.3.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-jupyter-3.2.1.jar:/opt/dolphinscheduler/libs/mybatis-plus-extension-3.5.2.jar:/opt/dolphinscheduler/libs/j2objc-annotations-1.3.jar:/opt/dolphinscheduler/libs/Java-WebSocket-1.5.1.jar:/opt/dolphinscheduler/libs/azure-storage-common-12.20.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-sagemaker-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-databend-3.2.1.jar:/opt/dolphinscheduler/libs/google-auth-library-oauth2-http-1.15.0.jar:/opt/dolphinscheduler/libs/jetty-security-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-python-3.2.1.jar:/opt/dolphinscheduler/libs/snappy-java-1.1.10.1.jar:/opt/dolphinscheduler/libs/kubernetes-model-batch-5.10.2.jar:/opt/dolphinscheduler/libs/netty-transport-native-epoll-4.1.53.Final-linux-x86_64.jar:/opt/dolphinscheduler/libs/jackson-core-asl-1.9.13.jar:/opt/dolphinscheduler/libs/gson-fire-1.8.5.jar:/opt/dolphinscheduler/libs/clickhouse-jdbc-0.4.6.jar:/opt/dolphinscheduler/libs/grpc-netty-shaded-1.41.0.jar:/opt/dolphinscheduler/libs/caffeine-2.9.3.jar:/opt/dolphinscheduler/libs/aliyun-java-sdk-core-4.5.10.jar:/opt/dolphinscheduler/libs/jackson-module-jaxb-annotations-2.13.3.jar:/opt/dolphinscheduler/libs/jetty-http-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/jersey-servlet-1.19.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-dinky-3.2.1.jar:/opt/dolphinscheduler/libs/simpleclient_tracer_common-0.15.0.jar:/opt/dolphinscheduler/libs/netty-handler-4.1.53.Final.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-datafactory-3.2.1.jar:/opt/dolphinscheduler/libs/json-path-2.7.0.jar:/opt/dolphinscheduler/libs/mybatis-plus-annotation-3.5.2.jar:/opt/dolphinscheduler/libs/azure-resourcemanager-datafactory-1.0.0-beta.19.jar:/opt/dolphinscheduler/libs/commons-codec-1.11.jar:/opt/dolphinscheduler/libs/dolphinscheduler-extract-master-3.2.1.jar:/opt/dolphinscheduler/libs/spring-aop-5.3.22.jar:/opt/dolphinscheduler/libs/kubernetes-model-core-5.10.2.jar:/opt/dolphinscheduler/libs/kubernetes-model-networking-5.10.2.jar:/opt/dolphinscheduler/libs/kotlin-stdlib-jdk7-1.6.21.jar:/opt/dolphinscheduler/libs/kerby-xdr-1.0.1.jar:/opt/dolphinscheduler/libs/aliyun-java-sdk-ram-3.1.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-k8s-3.2.1.jar:/opt/dolphinscheduler/libs/guava-31.1-jre.jar:/opt/dolphinscheduler/libs/netty-codec-dns-4.1.53.Final.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-kubeflow-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-azure-sql-3.2.1.jar:/opt/dolphinscheduler/libs/HikariCP-4.0.3.jar:/opt/dolphinscheduler/libs/hive-metastore-2.3.9.jar:/opt/dolphinscheduler/libs/msal4j-1.13.3.jar:/opt/dolphinscheduler/libs/jackson-core-2.13.4.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-hive-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-mr-3.2.1.jar:/opt/dolphinscheduler/libs/kubernetes-model-node-5.10.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-common-3.2.1.jar:/opt/dolphinscheduler/libs/jose4j-0.7.8.jar:/opt/dolphinscheduler/libs/jul-to-slf4j-1.7.36.jar:/opt/dolphinscheduler/libs/azure-identity-1.7.1.jar:/opt/dolphinscheduler/libs/spring-boot-autoconfigure-2.7.3.jar:/opt/dolphinscheduler/libs/commons-math3-3.1.1.jar:/opt/dolphinscheduler/libs/jackson-jaxrs-json-provider-2.13.3.jar:/opt/dolphinscheduler/libs/perfmark-api-0.23.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-doris-3.2.1.jar:/opt/dolphinscheduler/libs/httpclient-4.5.13.jar:/opt/dolphinscheduler/libs/hive-service-2.3.9.jar:/opt/dolphinscheduler/libs/kerby-util-1.0.1.jar:/opt/dolphinscheduler/libs/commons-collections-3.2.2.jar:/opt/dolphinscheduler/libs/hadoop-yarn-client-3.2.4.jar:/opt/dolphinscheduler/libs/commons-text-1.8.jar:/opt/dolphinscheduler/libs/dolphinscheduler-worker-3.2.1.jar:/opt/dolphinscheduler/libs/hadoop-yarn-common-3.2.4.jar:/opt/dolphinscheduler/libs/zeppelin-client-0.10.1.jar:/opt/dolphinscheduler/libs/azure-core-management-1.10.1.jar:/opt/dolphinscheduler/libs/hadoop-mapreduce-client-jobclient-3.2.4.jar:/opt/dolphinscheduler/libs/jta-1.1.jar:/opt/dolphinscheduler/libs/annotations-4.1.1.4.jar:/opt/dolphinscheduler/libs/dolphinscheduler-extract-alert-3.2.1.jar:/opt/dolphinscheduler/libs/curator-framework-5.3.0.jar:/opt/dolphinscheduler/libs/hive-jdbc-2.3.9.jar:/opt/dolphinscheduler/libs/kyuubi-hive-jdbc-shaded-1.7.0.jar:/opt/dolphinscheduler/libs/client-java-proto-13.0.2.jar:/opt/dolphinscheduler/libs/checker-qual-3.19.0.jar:/opt/dolphinscheduler/libs/jetty-servlet-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/google-cloud-core-grpc-2.10.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-shell-3.2.1.jar:/opt/dolphinscheduler/libs/spring-security-rsa-1.0.10.RELEASE.jar:/opt/dolphinscheduler/libs/avro-1.7.7.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-postgresql-3.2.1.jar:/opt/dolphinscheduler/libs/netty-nio-client-2.17.282.jar:/opt/dolphinscheduler/libs/spring-webmvc-5.3.22.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-mysql-3.2.1.jar:/opt/dolphinscheduler/libs/opentracing-util-0.33.0.jar:/opt/dolphinscheduler/libs/auto-value-1.10.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-all-3.2.1.jar:/opt/dolphinscheduler/libs/jetcd-core-0.5.11.jar:/opt/dolphinscheduler/libs/grpc-context-1.41.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-datasync-3.2.1.jar:/opt/dolphinscheduler/libs/jackson-dataformat-cbor-2.13.3.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-gcs-3.2.1.jar:/opt/dolphinscheduler/libs/client-java-extended-13.0.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-redshift-3.2.1.jar:/opt/dolphinscheduler/libs/opencsv-2.3.jar:/opt/dolphinscheduler/libs/jcip-annotations-1.0-1.jar:/opt/dolphinscheduler/libs/accessors-smart-2.4.8.jar:/opt/dolphinscheduler/libs/hadoop-client-3.2.4.jar:/opt/dolphinscheduler/libs/commons-collections4-4.3.jar:/opt/dolphinscheduler/libs/metrics-core-4.2.11.jar:/opt/dolphinscheduler/libs/netty-resolver-4.1.53.Final.jar:/opt/dolphinscheduler/libs/parquet-hadoop-bundle-1.8.1.jar:/opt/dolphinscheduler/libs/bucket4j-core-6.2.0.jar:/opt/dolphinscheduler/libs/spring-cloud-starter-3.1.3.jar:/opt/dolphinscheduler/libs/mssql-jdbc-11.2.1.jre8.jar:/opt/dolphinscheduler/libs/netty-tcnative-boringssl-static-2.0.53.Final.jar:/opt/dolphinscheduler/libs/kubernetes-model-coordination-5.10.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-linkis-3.2.1.jar:/opt/dolphinscheduler/libs/commons-net-3.6.jar:/opt/dolphinscheduler/libs/netty-transport-native-kqueue-4.1.53.Final-osx-x86_64.jar:/opt/dolphinscheduler/libs/dolphinscheduler-meter-3.2.1.jar:/opt/dolphinscheduler/libs/kubernetes-client-api-6.0.0.jar:/opt/dolphinscheduler/libs/kubernetes-model-certificates-5.10.2.jar:/opt/dolphinscheduler/libs/opencensus-api-0.31.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-mlflow-3.2.1.jar:/opt/dolphinscheduler/libs/kotlin-stdlib-jdk8-1.6.21.jar:/opt/dolphinscheduler/libs/dolphinscheduler-registry-jdbc-3.2.1.jar:/opt/dolphinscheduler/libs/audience-annotations-0.12.0.jar:/opt/dolphinscheduler/libs/simpleclient_httpserver-0.15.0.jar:/opt/dolphinscheduler/libs/jetty-xml-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/kerby-asn1-1.0.1.jar:/opt/dolphinscheduler/libs/lang-tag-1.6.jar:/opt/dolphinscheduler/libs/api-common-2.6.0.jar:/opt/dolphinscheduler/libs/HdrHistogram-2.1.12.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-abs-3.2.1.jar:/opt/dolphinscheduler/libs/failsafe-2.4.4.jar:/opt/dolphinscheduler/libs/hbase-noop-htrace-4.1.1.jar:/opt/dolphinscheduler/libs/jamon-runtime-2.3.1.jar:/opt/dolphinscheduler/libs/jetty-util-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/threetenbp-1.6.5.jar:/opt/dolphinscheduler/libs/jakarta.activation-api-1.2.2.jar:/opt/dolphinscheduler/libs/kubernetes-model-common-5.10.2.jar:/opt/dolphinscheduler/libs/okhttp-4.9.3.jar:/opt/dolphinscheduler/libs/profiles-2.17.282.jar:/opt/dolphinscheduler/libs/hadoop-auth-3.2.4.jar:/opt/dolphinscheduler/libs/grpc-netty-1.41.0.jar:/opt/dolphinscheduler/libs/httpcore-nio-4.4.15.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-seatunnel-3.2.1.jar:/opt/dolphinscheduler/libs/aws-java-sdk-sagemaker-1.12.300.jar:/opt/dolphinscheduler/libs/oshi-core-6.1.1.jar:/opt/dolphinscheduler/libs/bonecp-0.8.0.RELEASE.jar:/opt/dolphinscheduler/libs/jackson-module-parameter-names-2.13.3.jar:/opt/dolphinscheduler/libs/bcutil-jdk15on-1.69.jar:/opt/dolphinscheduler/libs/aws-json-protocol-2.17.282.jar:/opt/dolphinscheduler/libs/dolphinscheduler-extract-base-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-all-3.2.1.jar:/opt/dolphinscheduler/libs/derby-10.14.2.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-snowflake-3.2.1.jar:/opt/dolphinscheduler/libs/netty-codec-http2-4.1.53.Final.jar:/opt/dolphinscheduler/libs/jetty-continuation-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/jackson-mapper-asl-1.9.13.jar:/opt/dolphinscheduler/libs/datanucleus-core-4.1.17.jar:/opt/dolphinscheduler/libs/netty-tcnative-boringssl-static-2.0.53.Final-osx-aarch_64.jar:/opt/dolphinscheduler/libs/failureaccess-1.0.1.jar:/opt/dolphinscheduler/libs/error_prone_annotations-2.5.1.jar:/opt/dolphinscheduler/libs/kerb-admin-1.0.1.jar:/opt/dolphinscheduler/libs/token-provider-1.0.1.jar:/opt/dolphinscheduler/libs/reactor-netty-core-1.0.22.jar:/opt/dolphinscheduler/libs/dolphinscheduler-registry-all-3.2.1.jar:/opt/dolphinscheduler/libs/jakarta.servlet-api-4.0.4.jar:/opt/dolphinscheduler/libs/http-client-spi-2.17.282.jar:/opt/dolphinscheduler/libs/regions-2.17.282.jar:/opt/dolphinscheduler/libs/logback-core-1.2.11.jar:/opt/dolphinscheduler/libs/json-1.8.jar:/opt/dolphinscheduler/libs/gax-grpc-2.23.0.jar:/opt/dolphinscheduler/libs/google-http-client-1.42.3.jar:/opt/dolphinscheduler/libs/hive-serde-2.3.9.jar:/opt/dolphinscheduler/libs/jettison-1.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-http-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-registry-zookeeper-3.2.1.jar:/opt/dolphinscheduler/libs/spring-security-crypto-5.7.3.jar:/opt/dolphinscheduler/libs/auth-2.17.282.jar:/opt/dolphinscheduler/libs/proto-google-cloud-storage-v2-2.18.0-alpha.jar:/opt/dolphinscheduler/libs/jetty-server-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/javax.annotation-api-1.3.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-starrocks-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-dataquality-3.2.1.jar:/opt/dolphinscheduler/libs/jcl-over-slf4j-1.7.36.jar:/opt/dolphinscheduler/libs/commons-lang3-3.12.0.jar:/opt/dolphinscheduler/libs/tomcat-embed-el-9.0.65.jar:/opt/dolphinscheduler/libs/opentracing-noop-0.33.0.jar:/opt/dolphinscheduler/libs/client-java-13.0.2.jar:/opt/dolphinscheduler/libs/spring-beans-5.3.22.jar:/opt/dolphinscheduler/libs/snakeyaml-1.33.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-ssh-3.2.1.jar:/opt/dolphinscheduler/libs/commons-pool-1.6.jar:/opt/dolphinscheduler/libs/javax.servlet-api-3.1.0.jar:/opt/dolphinscheduler/libs/hadoop-common-3.2.4.jar:/opt/dolphinscheduler/libs/kubernetes-model-apiextensions-5.10.2.jar:/opt/dolphinscheduler/libs/spring-boot-2.7.3.jar:/opt/dolphinscheduler/libs/bcprov-ext-jdk15on-1.69.jar:/opt/dolphinscheduler/libs/spring-boot-starter-2.7.3.jar:/opt/dolphinscheduler/libs/paranamer-2.3.jar:/opt/dolphinscheduler/libs/httpmime-4.5.13.jar:/opt/dolphinscheduler/libs/reactor-core-3.4.22.jar:/opt/dolphinscheduler/libs/azure-core-1.36.0.jar:/opt/dolphinscheduler/libs/bcpkix-jdk15on-1.69.jar:/opt/dolphinscheduler/libs/kubernetes-model-scheduling-5.10.2.jar:/opt/dolphinscheduler/libs/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/dolphinscheduler/libs/websocket-client-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/unirest-java-3.7.04-standalone.jar:/opt/dolphinscheduler/libs/hadoop-mapreduce-client-core-3.2.4.jar:/opt/dolphinscheduler/libs/google-auth-library-credentials-1.15.0.jar:/opt/dolphinscheduler/libs/azure-storage-internal-avro-12.6.0.jar:/opt/dolphinscheduler/libs/jackson-datatype-jdk8-2.13.3.jar:/opt/dolphinscheduler/libs/spring-expression-5.3.22.jar:/opt/dolphinscheduler/libs/aspectjweaver-1.9.7.jar:/opt/dolphinscheduler/libs/websocket-common-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/client-java-api-fluent-13.0.2.jar:/opt/dolphinscheduler/libs/mybatis-plus-3.5.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-athena-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-oss-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-openmldb-3.2.1.jar:/opt/dolphinscheduler/libs/curator-recipes-5.3.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-api-3.2.1.jar:/opt/dolphinscheduler/libs/netty-all-4.1.53.Final.jar:/opt/dolphinscheduler/libs/netty-resolver-dns-4.1.53.Final.jar:/opt/dolphinscheduler/libs/kubernetes-model-autoscaling-5.10.2.jar:/opt/dolphinscheduler/libs/kerb-util-1.0.1.jar:/opt/dolphinscheduler/libs/grpc-alts-1.41.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-presto-3.2.1.jar:/opt/dolphinscheduler/libs/kerb-simplekdc-1.0.1.jar:/opt/dolphinscheduler/libs/protobuf-java-util-3.17.2.jar:/opt/dolphinscheduler/libs/azure-core-http-netty-1.13.0.jar:/opt/dolphinscheduler/libs/transaction-api-1.1.jar:/opt/dolphinscheduler/libs/datanucleus-api-jdo-4.2.4.jar:/opt/dolphinscheduler/libs/zeppelin-common-0.10.1.jar:/opt/dolphinscheduler/libs/zt-zip-1.15.jar:/opt/dolphinscheduler/libs/animal-sniffer-annotations-1.19.jar:/opt/dolphinscheduler/libs/google-http-client-jackson2-1.42.3.jar:/opt/dolphinscheduler/libs/netty-buffer-4.1.53.Final.jar:/opt/dolphinscheduler/libs/jsr305-3.0.0.jar:/opt/dolphinscheduler/libs/netty-transport-classes-epoll-4.1.79.Final.jar:/opt/dolphinscheduler/libs/spring-boot-actuator-autoconfigure-2.7.3.jar:/opt/dolphinscheduler/libs/simpleclient-0.15.0.jar:/opt/dolphinscheduler/libs/aliyun-sdk-oss-3.15.1.jar:/opt/dolphinscheduler/libs/json-utils-2.17.282.jar:/opt/dolphinscheduler/libs/tephra-api-0.6.0.jar:/opt/dolphinscheduler/libs/spring-jdbc-5.3.22.jar:/opt/dolphinscheduler/libs/grpc-xds-1.41.0.jar:/opt/dolphinscheduler/libs/logback-classic-1.2.11.jar:/opt/dolphinscheduler/libs/google-cloud-storage-2.18.0.jar:/opt/dolphinscheduler/libs/micrometer-registry-prometheus-1.9.3.jar:/opt/dolphinscheduler/libs/grpc-core-1.41.0.jar:/opt/dolphinscheduler/libs/aws-java-sdk-kms-1.12.300.jar:/opt/dolphinscheduler/libs/kubernetes-model-rbac-5.10.2.jar:/opt/dolphinscheduler/libs/ini4j-0.5.4.jar:/opt/dolphinscheduler/libs/spring-boot-starter-web-2.7.3.jar:/opt/dolphinscheduler/libs/spring-cloud-commons-3.1.3.jar:/opt/dolphinscheduler/libs/netty-codec-http-4.1.53.Final.jar:/opt/dolphinscheduler/libs/jetty-client-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/jetcd-common-0.5.11.jar:/opt/dolphinscheduler/libs/metrics-spi-2.17.282.jar:/opt/dolphinscheduler/libs/utils-2.17.282.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-emr-3.2.1.jar:/opt/dolphinscheduler/libs/protocol-core-2.17.282.jar:/opt/dolphinscheduler/libs/micrometer-core-1.9.3.jar:/opt/dolphinscheduler/libs/netty-transport-native-unix-common-4.1.53.Final.jar:/opt/dolphinscheduler/libs/zjsonpatch-0.4.11.jar:/opt/dolphinscheduler/libs/annotations-2.17.282.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-sql-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-extract-common-3.2.1.jar:/opt/dolphinscheduler/libs/apache-client-2.17.282.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-oceanbase-3.2.1.jar:/opt/dolphinscheduler/libs/jdo-api-3.0.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-datax-3.2.1.jar:/opt/dolphinscheduler/libs/postgresql-42.4.1.jar:/opt/dolphinscheduler/libs/jetty-util-ajax-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/gax-2.23.0.jar:/opt/dolphinscheduler/libs/grpc-stub-1.41.0.jar:/opt/dolphinscheduler/libs/libfb303-0.9.3.jar:/opt/dolphinscheduler/libs/spring-core-5.3.22.jar:/opt/dolphinscheduler/libs/jaxb-api-2.3.1.jar:/opt/dolphinscheduler/libs/hive-service-rpc-2.3.9.jar:/opt/dolphinscheduler/libs/kubernetes-model-flowcontrol-5.10.2.jar:/opt/dolphinscheduler/libs/commons-logging-1.1.1.jar:/opt/dolphinscheduler/libs/mybatis-spring-2.0.7.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-oracle-3.2.1.jar:/opt/dolphinscheduler/libs/opencensus-proto-0.2.0.jar:/opt/dolphinscheduler/libs/grpc-protobuf-1.41.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-clickhouse-3.2.1.jar:/opt/dolphinscheduler/libs/spring-cloud-starter-bootstrap-3.1.3.jar:/opt/dolphinscheduler/libs/kubernetes-model-admissionregistration-5.10.2.jar:/opt/dolphinscheduler/libs/grpc-google-cloud-storage-v2-2.18.0-alpha.jar:/opt/dolphinscheduler/libs/esdk-obs-java-bundle-3.23.3.jar:/opt/dolphinscheduler/libs/dnsjava-2.1.7.jar:/opt/dolphinscheduler/libs/asm-9.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-spark-3.2.1.jar:/opt/dolphinscheduler/libs/netty-tcnative-boringssl-static-2.0.53.Final-linux-aarch_64.jar:/opt/dolphinscheduler/libs/re2j-1.6.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-vertica-3.2.1.jar:/opt/dolphinscheduler/libs/json-smart-2.4.8.jar:/opt/dolphinscheduler/libs/reactor-netty-http-1.0.22.jar:/opt/dolphinscheduler/libs/google-api-services-storage-v1-rev20220705-2.0.0.jar:/opt/dolphinscheduler/libs/kubernetes-client-6.0.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-kyuubi-3.2.1.jar:/opt/dolphinscheduler/libs/auto-value-annotations-1.10.1.jar:/opt/dolphinscheduler/libs/commons-cli-1.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-data-quality-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-chunjun-3.2.1.jar:/opt/dolphinscheduler/libs/kerb-server-1.0.1.jar:/opt/dolphinscheduler/libs/content-type-2.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-remoteshell-3.2.1.jar:/opt/dolphinscheduler/libs/opencensus-contrib-http-util-0.31.1.jar:/opt/dolphinscheduler/libs/druid-1.2.20.jar:/opt/dolphinscheduler/libs/javolution-5.5.1.jar:/opt/dolphinscheduler/libs/protobuf-java-3.17.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-db2-3.2.1.jar:/opt/dolphinscheduler/libs/aws-java-sdk-core-1.12.300.jar:/opt/dolphinscheduler/libs/spring-boot-starter-logging-2.7.3.jar:/opt/dolphinscheduler/libs/kerby-pkix-1.0.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-procedure-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-registry-etcd-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-sqoop-3.2.1.jar:/opt/dolphinscheduler/libs/zookeeper-jute-3.8.0.jar:/opt/dolphinscheduler/libs/netty-resolver-dns-native-macos-4.1.53.Final-osx-x86_64.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-sagemaker-3.2.1.jar:/opt/dolphinscheduler/libs/spring-boot-configuration-processor-2.6.1.jar:/opt/dolphinscheduler/libs/hive-common-2.3.9.jar:/opt/dolphinscheduler/libs/kerb-common-1.0.1.jar:/opt/dolphinscheduler/libs/stax-api-1.0.1.jar:/opt/dolphinscheduler/libs/kubernetes-model-storageclass-5.10.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-s3-3.2.1.jar:/opt/dolphinscheduler/libs/spring-boot-starter-jetty-2.7.3.jar:/opt/dolphinscheduler/libs/okio-2.8.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-dms-3.2.1.jar:/opt/dolphinscheduler/libs/simpleclient_common-0.15.0.jar:/opt/dolphinscheduler/libs/sdk-core-2.17.282.jar:/opt/dolphinscheduler/libs/javax.activation-api-1.2.0.jar:/opt/dolphinscheduler/libs/netty-handler-proxy-4.1.53.Final.jar:/opt/dolphinscheduler/libs/kerby-config-1.0.1.jar:/opt/dolphinscheduler/libs/netty-tcnative-classes-2.0.53.Final.jar:/opt/dolphinscheduler/libs/jackson-jaxrs-base-2.13.3.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-trino-3.2.1.jar:/opt/dolphinscheduler/libs/presto-jdbc-0.238.1.jar:/opt/dolphinscheduler/libs/websocket-api-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-flink-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-api-3.2.1.jar:/opt/dolphinscheduler/libs/kubernetes-model-metrics-5.10.2.jar:/opt/dolphinscheduler/libs/datasync-2.17.282.jar:/opt/dolphinscheduler/libs/hadoop-yarn-api-3.2.4.jar:/opt/dolphinscheduler/libs/google-http-client-apache-v2-1.42.3.jar:/opt/dolphinscheduler/libs/hadoop-annotations-3.2.4.jar:/opt/dolphinscheduler/libs/google-oauth-client-1.34.1.jar:/opt/dolphinscheduler/libs/sshd-common-2.8.0.jar:/opt/dolphinscheduler/libs/LatencyUtils-2.0.3.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-spark-3.2.1.jar:/opt/dolphinscheduler/libs/slf4j-api-1.7.36.jar:/opt/dolphinscheduler/libs/snowflake-jdbc-3.13.29.jar:/opt/dolphinscheduler/libs/jackson-datatype-jsr310-2.13.3.jar:/opt/dolphinscheduler/libs/trino-jdbc-402.jar:/opt/dolphinscheduler/libs/logging-interceptor-4.9.3.jar:/opt/dolphinscheduler/libs/simpleclient_tracer_otel_agent-0.15.0.jar:/opt/dolphinscheduler/libs/janino-3.0.16.jar:/opt/dolphinscheduler/libs/jackson-dataformat-yaml-2.13.3.jar:/opt/dolphinscheduler/libs/ion-java-1.0.2.jar:/opt/dolphinscheduler/libs/commons-dbcp-1.4.jar:/opt/dolphinscheduler/libs/jsp-api-2.1.jar:/opt/dolphinscheduler/libs/google-http-client-gson-1.42.3.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-hivecli-3.2.1.jar:/opt/dolphinscheduler/libs/spring-boot-actuator-2.7.3.jar:/opt/dolphinscheduler/libs/google-cloud-core-http-2.10.0.jar:/opt/dolphinscheduler/libs/DmJdbcDriver18-8.1.2.79.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-java-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-dameng-3.2.1.jar:/opt/dolphinscheduler/libs/sshd-sftp-2.8.0.jar:/opt/dolphinscheduler/libs/kerb-crypto-1.0.1.jar:/opt/dolphinscheduler/libs/conscrypt-openjdk-uber-2.5.2.jar:/opt/dolphinscheduler/libs/httpcore-4.4.15.jar:/opt/dolphinscheduler/libs/lz4-java-1.4.0.jar:/opt/dolphinscheduler/libs/guava-retrying-2.0.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-flink-stream-3.2.1.jar:/opt/dolphinscheduler/libs/spring-tx-5.3.22.jar:/opt/dolphinscheduler/libs/grpc-auth-1.41.0.jar:/opt/dolphinscheduler/libs/netty-tcnative-boringssl-static-2.0.53.Final-osx-x86_64.jar:/opt/dolphinscheduler/libs/databend-jdbc-0.0.7.jar:/opt/dolphinscheduler/libs/bcprov-jdk15on-1.69.jar:/opt/dolphinscheduler/libs/commons-lang-2.6.jar:/opt/dolphinscheduler/libs/kubernetes-model-policy-5.10.2.jar:/opt/dolphinscheduler/libs/commons-io-2.11.0.jar:/opt/dolphinscheduler/libs/grpc-grpclb-1.41.0.jar:/opt/dolphinscheduler/libs/netty-tcnative-boringssl-static-2.0.53.Final-linux-x86_64.jar:/opt/dolphinscheduler/libs/opentracing-api-0.33.0.jar:/opt/dolphinscheduler/libs/sshd-scp-2.8.0.jar:/opt/dolphinscheduler/libs/reload4j-1.2.18.3.jar:/opt/dolphinscheduler/libs/netty-tcnative-2.0.48.Final.jar:/opt/dolphinscheduler/libs/jdom2-2.0.6.1.jar:/opt/dolphinscheduler/libs/spring-boot-starter-json-2.7.3.jar:/opt/dolphinscheduler/libs/netty-transport-native-epoll-4.1.53.Final.jar:/opt/dolphinscheduler/libs/google-cloud-core-2.10.0.jar:/opt/dolphinscheduler/libs/javax.jdo-3.2.0-m3.jar:/opt/dolphinscheduler/libs/gax-httpjson-0.108.0.jar:/opt/dolphinscheduler/libs/mybatis-plus-core-3.5.2.jar:/opt/dolphinscheduler/libs/auto-service-annotations-1.0.1.jar:/opt/dolphinscheduler/libs/nimbus-jose-jwt-9.22.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-zeppelin-3.2.1.jar:/opt/dolphinscheduler/libs/commons-compress-1.21.jar:/opt/dolphinscheduler/libs/hadoop-hdfs-client-3.2.4.jar:/opt/dolphinscheduler/libs/msal4j-persistence-extension-1.1.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-pytorch-3.2.1.jar:/opt/dolphinscheduler/libs/netty-tcnative-boringssl-static-2.0.53.Final-windows-x86_64.jar:/opt/dolphinscheduler/libs/jetty-servlets-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/woodstox-core-6.4.0.jar:/opt/dolphinscheduler/libs/spring-cloud-kubernetes-commons-2.1.3.jar:/opt/dolphinscheduler/libs/grpc-protobuf-lite-1.41.0.jar:/opt/dolphinscheduler/libs/jetty-webapp-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/eventstream-1.0.1.jar:/opt/dolphinscheduler/libs/commons-compiler-3.1.7.jar:/opt/dolphinscheduler/libs/netty-transport-4.1.53.Final.jar:/opt/dolphinscheduler/libs/spring-cloud-context-3.1.3.jar:/opt/dolphinscheduler/libs/aws-java-sdk-dms-1.12.300.jar:/opt/dolphinscheduler/libs/hive-storage-api-2.4.0.jar:/opt/dolphinscheduler/libs/client-java-spring-integration-13.0.2.jar:/opt/dolphinscheduler/libs/spring-boot-starter-actuator-2.7.3.jar:/opt/dolphinscheduler/libs/third-party-jackson-core-2.17.282.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-hdfs-3.2.1.jar:/opt/dolphinscheduler/libs/netty-codec-4.1.53.Final.jar:/opt/dolphinscheduler/libs/google-http-client-appengine-1.42.3.jar:/opt/dolphinscheduler/libs/commons-configuration2-2.1.1.jar:/opt/dolphinscheduler/libs/datanucleus-rdbms-4.1.19.jar:/opt/dolphinscheduler/libs/swagger-annotations-1.6.2.jar:/opt/dolphinscheduler/libs/simpleclient_tracer_otel-0.15.0.jar:/opt/dolphinscheduler/libs/kotlin-stdlib-common-1.6.21.jar:/opt/dolphinscheduler/libs/aws-core-2.17.282.jar:/opt/dolphinscheduler/libs/kerb-core-1.0.1.jar:/opt/dolphinscheduler/libs/httpasyncclient-4.1.5.jar:/opt/dolphinscheduler/libs/dolphinscheduler-extract-worker-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-spi-3.2.1.jar:/opt/dolphinscheduler/libs/okhttp-2.7.5.jar:/opt/dolphinscheduler/libs/google-api-client-2.2.0.jar:/opt/dolphinscheduler/libs/kotlin-stdlib-1.6.21.jar:/opt/dolphinscheduler/libs/jakarta.websocket-api-1.1.2.jar:/opt/dolphinscheduler/libs/libthrift-0.9.3.jar:/opt/dolphinscheduler/libs/spring-boot-starter-aop-2.7.3.jar:/opt/dolphinscheduler/libs/netty-common-4.1.53.Final.jar:/opt/dolphinscheduler/libs/log4j-1.2-api-2.17.2.jar:/opt/dolphinscheduler/libs/jackson-databind-2.13.4.jar:/opt/dolphinscheduler/libs/jackson-dataformat-xml-2.13.3.jar:/opt/dolphinscheduler/libs/kubernetes-model-events-5.10.2.jar:/opt/dolphinscheduler/libs/gson-2.9.1.jar:/opt/dolphinscheduler/libs/proto-google-iam-v1-1.9.0.jar:/opt/dolphinscheduler/libs/netty-codec-socks-4.1.53.Final.jar:/opt/dolphinscheduler/libs/zjsonpatch-0.3.0.jar:/opt/dolphinscheduler/libs/hadoop-mapreduce-client-common-3.2.4.jar:/opt/dolphinscheduler/libs/dolphinscheduler-registry-api-3.2.1.jar:/opt/dolphinscheduler/libs/azure-storage-blob-12.21.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-zeppelin-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-api-3.2.1.jar:/opt/dolphinscheduler/libs/aws-java-sdk-s3-1.12.300.jar:/opt/dolphinscheduler/libs/stax2-api-4.2.1.jar:/opt/dolphinscheduler/libs/jakarta.annotation-api-1.3.5.jar:/opt/dolphinscheduler/libs/kubernetes-model-discovery-5.10.2.jar:/opt/dolphinscheduler/libs/jna-5.10.0.jar:/opt/dolphinscheduler/libs/spring-jcl-5.3.22.jar
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:00.475 +0800 o.a.z.ZooKeeper:[98] - Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:00.475 +0800 o.a.z.ZooKeeper:[98] - Client environment:java.io.tmpdir=/tmp
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:00.475 +0800 o.a.z.ZooKeeper:[98] - Client environment:java.compiler=<NA>
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:00.475 +0800 o.a.z.ZooKeeper:[98] - Client environment:os.name=Linux
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:00.476 +0800 o.a.z.ZooKeeper:[98] - Client environment:os.arch=amd64
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:00.476 +0800 o.a.z.ZooKeeper:[98] - Client environment:os.version=6.5.0-28-generic
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:00.476 +0800 o.a.z.ZooKeeper:[98] - Client environment:user.name=root
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:00.476 +0800 o.a.z.ZooKeeper:[98] - Client environment:user.home=/root
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:00.476 +0800 o.a.z.ZooKeeper:[98] - Client environment:user.dir=/opt/dolphinscheduler
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:00.476 +0800 o.a.z.ZooKeeper:[98] - Client environment:os.memory.free=3215MB
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:00.476 +0800 o.a.z.ZooKeeper:[98] - Client environment:os.memory.max=3840MB
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:00.476 +0800 o.a.z.ZooKeeper:[98] - Client environment:os.memory.total=3840MB
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:00.578 +0800 o.a.z.ZooKeeper:[637] - Initiating client connection, connectString=dolphinscheduler-zookeeper:2181 sessionTimeout=30000 watcher=org.apache.curator.ConnectionState@1de08775
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:00.593 +0800 o.a.z.c.X509Util:[77] - Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:00.598 +0800 o.a.z.ClientCnxnSocket:[239] - jute.maxbuffer value is 1048575 Bytes
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:00.702 +0800 o.a.z.ClientCnxn:[1732] - zookeeper.request.timeout value is 0. feature enabled=false
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:00.766 +0800 o.a.c.f.i.CuratorFrameworkImpl:[386] - Default schema
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:00.772 +0800 o.a.z.ClientCnxn:[1171] - Opening socket connection to server dolphinscheduler-zookeeper/172.18.0.3:2181.
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:00.800 +0800 o.a.z.ClientCnxn:[1173] - SASL config status: Will not attempt to authenticate using SASL (unknown error)
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:00.831 +0800 o.a.z.ClientCnxn:[1005] - Socket connection established, initiating session, client: /172.18.1.1:59030, server: dolphinscheduler-zookeeper/172.18.0.3:2181
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:00.851 +0800 o.a.z.ClientCnxn:[1444] - Session establishment complete on server dolphinscheduler-zookeeper/172.18.0.3:2181, session id = 0x1000019e4510001, negotiated timeout = 30000
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:00.900 +0800 o.a.c.f.s.ConnectionStateManager:[252] - State change: CONNECTED
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:01.122 +0800 o.a.c.f.i.EnsembleTracker:[201] - New config event received: {}
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:01.122 +0800 o.a.c.f.i.EnsembleTracker:[201] - New config event received: {}
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:01.420 +0800 o.a.d.s.w.r.WorkerRpcServer:[41] - WorkerRpcServer starting...
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:02.350 +0800 o.a.d.e.b.NettyRemotingServer:[112] - WorkerRpcServer bind success at port: 1234
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:02.354 +0800 o.a.d.s.w.r.WorkerRpcServer:[43] - WorkerRpcServer started...
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:02.471 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: JAVA - JavaTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:02.499 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: JAVA - JavaTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:02.504 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: JUPYTER - JupyterTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:02.506 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: JUPYTER - JupyterTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:02.511 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: SPARK - SparkTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:02.527 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: SPARK - SparkTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:02.530 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: FLINK_STREAM - FlinkStreamTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:02.560 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: FLINK_STREAM - FlinkStreamTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:02.560 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: PYTHON - PythonTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:02.561 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: PYTHON - PythonTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:02.562 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: DATASYNC - DatasyncTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:02.563 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: DATASYNC - DatasyncTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:02.564 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: DATA_FACTORY - DatafactoryTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:02.595 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: DATA_FACTORY - DatafactoryTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:02.725 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: CHUNJUN - ChunJunTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:02.749 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: CHUNJUN - ChunJunTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:02.765 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: REMOTESHELL - RemoteShellTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:02.769 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: REMOTESHELL - RemoteShellTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:02.784 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: PIGEON - PigeonTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:02.789 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: PIGEON - PigeonTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:02.799 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: SHELL - ShellTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:02.802 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: SHELL - ShellTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:02.802 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: PROCEDURE - ProcedureTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:02.806 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: PROCEDURE - ProcedureTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:02.887 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: MR - MapReduceTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:02.891 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: MR - MapReduceTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:02.899 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: SQOOP - SqoopTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:02.903 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: SQOOP - SqoopTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:02.908 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: PYTORCH - PytorchTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:02.913 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: PYTORCH - PytorchTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:02.962 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: K8S - K8sTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:02.966 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: K8S - K8sTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:02.966 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: SEATUNNEL - SeatunnelTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:02.972 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: SEATUNNEL - SeatunnelTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:02.973 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: SAGEMAKER - SagemakerTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:02.976 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: SAGEMAKER - SagemakerTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:02.977 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: HTTP - HttpTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:02.980 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: HTTP - HttpTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:02.981 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: EMR - EmrTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:02.988 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: EMR - EmrTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:02.991 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: DMS - DmsTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:03.014 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: DMS - DmsTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:03.015 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: DATA_QUALITY - DataQualityTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:03.021 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: DATA_QUALITY - DataQualityTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:03.033 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: KUBEFLOW - KubeflowTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:03.036 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: KUBEFLOW - KubeflowTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:03.037 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: SQL - SqlTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:03.110 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: SQL - SqlTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:03.111 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: DVC - DvcTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:03.113 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: DVC - DvcTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:03.124 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: DATAX - DataxTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:03.130 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: DATAX - DataxTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:03.130 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: ZEPPELIN - ZeppelinTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:03.135 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: ZEPPELIN - ZeppelinTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:03.136 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: DINKY - DinkyTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:03.139 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: DINKY - DinkyTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:03.139 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: MLFLOW - MlflowTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:03.141 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: MLFLOW - MlflowTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:03.147 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: OPENMLDB - OpenmldbTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:03.151 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: OPENMLDB - OpenmldbTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:03.151 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: LINKIS - LinkisTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:03.154 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: LINKIS - LinkisTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:03.155 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: FLINK - FlinkTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:03.157 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: FLINK - FlinkTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:03.168 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: HIVECLI - HiveCliTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:03.173 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: HIVECLI - HiveCliTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:03.543 +0800 o.a.d.c.u.JSONUtils:[72] - init timezone: sun.util.calendar.ZoneInfo[id="Asia/Shanghai",offset=28800000,dstSavings=0,useDaylight=false,transitions=31,lastRule=null]
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:03.685 +0800 o.a.d.s.w.r.WorkerRegistryClient:[104] - Worker node: 172.18.1.1:1234 registry to ZK /nodes/worker/172.18.1.1:1234 successfully
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:04.792 +0800 o.a.d.c.m.BaseHeartBeatTask:[48] - Starting WorkerHeartBeatTask...
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:04.796 +0800 o.a.d.c.m.BaseHeartBeatTask:[50] - Started WorkerHeartBeatTask, heartBeatInterval: 10000...
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:04.796 +0800 o.a.d.s.w.r.WorkerRegistryClient:[114] - Worker node: 172.18.1.1:1234 registry finished
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:04.797 +0800 o.a.d.s.w.m.MessageRetryRunner:[69] - Message retry runner staring
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:04.851 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.1695652173913043 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:04.901 +0800 o.a.d.s.w.m.MessageRetryRunner:[72] - Injected message sender: TaskInstanceExecutionFinishEventSender
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:04.901 +0800 o.a.d.s.w.m.MessageRetryRunner:[72] - Injected message sender: TaskInstanceExecutionInfoUpdateEventSender
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:04.901 +0800 o.a.d.s.w.m.MessageRetryRunner:[72] - Injected message sender: TaskInstanceExecutionRunningEventSender
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:04.903 +0800 o.a.d.s.w.m.MessageRetryRunner:[75] - Message retry runner started
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:06.603 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.452054794520548 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:07.793 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.2645502645502646 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:08.958 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.6727272727272728 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:09.970 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.4516129032258065 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:11.372 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.49789029535865 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:12.377 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.4554455445544554 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:13.397 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.7971014492753623 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:14.517 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.5639534883720931 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:15.560 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.949579831932773 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:16.654 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.9184782608695652 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:17.800 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.8312499999999998 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:17.841 +0800 o.s.b.a.e.w.EndpointLinksResolver:[58] - Exposing 3 endpoint(s) beneath base path '/actuator'
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:18.038 +0800 o.e.j.s.h.C.application:[2368] - Initializing Spring DispatcherServlet 'dispatcherServlet'
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:18.038 +0800 o.s.w.s.DispatcherServlet:[525] - Initializing Servlet 'dispatcherServlet'
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:18.039 +0800 o.s.w.s.DispatcherServlet:[547] - Completed initialization in 1 ms
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:18.080 +0800 o.e.j.s.AbstractConnector:[333] - Started ServerConnector@1f45db49{HTTP/1.1, (http/1.1)}{0.0.0.0:1235}
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:18.082 +0800 o.s.b.w.e.j.JettyWebServer:[172] - Jetty started on port(s) 1235 (http/1.1) with context path '/'
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:18.139 +0800 o.a.d.s.w.WorkerServer:[61] - Started WorkerServer in 53.239 seconds (JVM running for 58.877)
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:18.825 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.8838709677419354 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:19.826 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.0952380952380951 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:20.829 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.1846846846846848 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:22.164 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7407407407407407 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:23.462 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8047619047619048 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:28.512 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8237082066869301 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:30.862 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7425657457699972 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:09:31.873 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7608695652173914 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:10:43.283 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7045454545454546 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:10:44.302 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9333333333333333 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:10:45.326 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7254901960784313 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:10:48.356 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8451612903225807 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:10:49.407 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8528610354223433 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:10:50.409 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8961424332344214 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:10:51.416 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9327956989247311 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:10:57.446 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7067039106145252 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:10:58.466 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.710455764075067 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:12:03.909 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7057142857142857 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:12:13.494 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1274, taskName=search for intake JSON files, firstSubmitTime=1713903133022, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.10:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=89, appIds=null, processInstanceId=542, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"processing"}], executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":""}],"rawScript":"# find 1 raw file in the folder\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\n\n# check if raw_file_dir is empty, then set raw_file_dir to null\nif [ -z \"$raw_file_dir\" ]; then\n    raw_file_dir=null\nfi\n\necho \"#{setValue(raw_file_dir=${raw_file_dir})}\"","resourceList":[]}, environmentConfig=export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='search for intake JSON files'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240424'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1274'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13340113777664'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240424041213'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='processing'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='542'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240423'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=null, dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-542][TI-1274] - [INFO] 2024-04-24 04:12:13.564 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: search for intake JSON files to wait queue success
[WI-542][TI-1274] - [INFO] 2024-04-24 04:12:13.581 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-542][TI-1274] - [INFO] 2024-04-24 04:12:13.593 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-542][TI-1274] - [INFO] 2024-04-24 04:12:13.598 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-542][TI-1274] - [INFO] 2024-04-24 04:12:13.599 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-542][TI-1274] - [INFO] 2024-04-24 04:12:13.599 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713903133599
[WI-542][TI-1274] - [INFO] 2024-04-24 04:12:13.602 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 542_1274
[WI-542][TI-1274] - [INFO] 2024-04-24 04:12:13.618 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1274,
  "taskName" : "search for intake JSON files",
  "firstSubmitTime" : 1713903133022,
  "startTime" : 1713903133599,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.10:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240424/13201021801792/89/542/1274.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 89,
  "processInstanceId" : 542,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"processing\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[{\"prop\":\"raw_file_dir\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"\"}],\"rawScript\":\"# find 1 raw file in the folder\\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\\n\\n# check if raw_file_dir is empty, then set raw_file_dir to null\\nif [ -z \\\"$raw_file_dir\\\" ]; then\\n    raw_file_dir=null\\nfi\\n\\necho \\\"#{setValue(raw_file_dir=${raw_file_dir})}\\\"\",\"resourceList\":[]}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "search for intake JSON files"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240424"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1274"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13340113777664"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240424041213"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "processing"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "542"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "542_1274",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-542][TI-1274] - [INFO] 2024-04-24 04:12:13.630 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-542][TI-1274] - [INFO] 2024-04-24 04:12:13.634 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-542][TI-1274] - [INFO] 2024-04-24 04:12:13.635 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-542][TI-1274] - [INFO] 2024-04-24 04:12:13.819 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-542][TI-1274] - [INFO] 2024-04-24 04:12:13.869 +0800 o.a.d.c.u.OSUtils:[231] - create linux os user: default
[WI-542][TI-1274] - [INFO] 2024-04-24 04:12:13.871 +0800 o.a.d.c.u.OSUtils:[233] - execute cmd: sudo useradd -g root
 default
[WI-0][TI-1274] - [INFO] 2024-04-24 04:12:13.900 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1274, success=true)
[WI-0][TI-0] - [INFO] 2024-04-24 04:12:14.013 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8603519131787895 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-542][TI-1274] - [INFO] 2024-04-24 04:12:14.045 +0800 o.a.d.c.u.OSUtils:[190] - create user default success
[WI-542][TI-1274] - [INFO] 2024-04-24 04:12:14.046 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-542][TI-1274] - [INFO] 2024-04-24 04:12:14.052 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_89/542/1274 check successfully
[WI-542][TI-1274] - [INFO] 2024-04-24 04:12:14.053 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-542][TI-1274] - [INFO] 2024-04-24 04:12:14.062 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-542][TI-1274] - [INFO] 2024-04-24 04:12:14.082 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-542][TI-1274] - [INFO] 2024-04-24 04:12:14.085 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-542][TI-1274] - [INFO] 2024-04-24 04:12:14.089 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ {
    "prop" : "raw_file_dir",
    "direct" : "OUT",
    "type" : "VARCHAR",
    "value" : ""
  } ],
  "varPool" : null,
  "rawScript" : "# find 1 raw file in the folder\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\n\n# check if raw_file_dir is empty, then set raw_file_dir to null\nif [ -z \"$raw_file_dir\" ]; then\n    raw_file_dir=null\nfi\n\necho \"#{setValue(raw_file_dir=${raw_file_dir})}\"",
  "resourceList" : [ ]
}
[WI-542][TI-1274] - [INFO] 2024-04-24 04:12:14.090 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-542][TI-1274] - [INFO] 2024-04-24 04:12:14.090 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: null successfully
[WI-542][TI-1274] - [INFO] 2024-04-24 04:12:14.094 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-542][TI-1274] - [INFO] 2024-04-24 04:12:14.094 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-542][TI-1274] - [INFO] 2024-04-24 04:12:14.094 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-542][TI-1274] - [INFO] 2024-04-24 04:12:14.122 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-542][TI-1274] - [INFO] 2024-04-24 04:12:14.123 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-542][TI-1274] - [INFO] 2024-04-24 04:12:14.123 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export PYTHON_LAUNCHER=/bin/python3.11
# find 1 raw file in the folder
raw_file_dir=$(find /local_storage/reddit/processing -type f -name '*.json'| head -n 1)

# check if raw_file_dir is empty, then set raw_file_dir to null
if [ -z "$raw_file_dir" ]; then
    raw_file_dir=null
fi

echo "#{setValue(raw_file_dir=${raw_file_dir})}"
[WI-542][TI-1274] - [INFO] 2024-04-24 04:12:14.123 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-542][TI-1274] - [INFO] 2024-04-24 04:12:14.125 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_89/542/1274/542_1274.sh
[WI-542][TI-1274] - [INFO] 2024-04-24 04:12:14.131 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 117
[WI-0][TI-1274] - [INFO] 2024-04-24 04:12:14.875 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1274)
[WI-0][TI-0] - [INFO] 2024-04-24 04:12:15.132 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
	#{setValue(raw_file_dir=/local_storage/reddit/processing/500-20240423.json)}
[WI-542][TI-1274] - [INFO] 2024-04-24 04:12:15.136 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_89/542/1274, processId:117 ,exitStatusCode:0 ,processWaitForStatus:true ,processExitValue:0
[WI-542][TI-1274] - [INFO] 2024-04-24 04:12:15.137 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-542][TI-1274] - [INFO] 2024-04-24 04:12:15.141 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-542][TI-1274] - [INFO] 2024-04-24 04:12:15.147 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-542][TI-1274] - [INFO] 2024-04-24 04:12:15.158 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-542][TI-1274] - [INFO] 2024-04-24 04:12:15.174 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: SUCCESS to master : 172.18.1.1:1234
[WI-542][TI-1274] - [INFO] 2024-04-24 04:12:15.175 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-542][TI-1274] - [INFO] 2024-04-24 04:12:15.178 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_89/542/1274
[WI-542][TI-1274] - [INFO] 2024-04-24 04:12:15.241 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_89/542/1274
[WI-542][TI-1274] - [INFO] 2024-04-24 04:12:15.260 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-1274] - [INFO] 2024-04-24 04:12:15.866 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1274, success=true)
[WI-0][TI-0] - [INFO] 2024-04-24 04:12:17.042 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1276, taskName=move to processing, firstSubmitTime=1713903137018, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.10:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=89, appIds=null, processInstanceId=542, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"processing"}], executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":""}],"rawScript":"# move file to the reddit processing folder\n# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error\nfilename=$(basename \"${raw_file_dir}\")\nif ! grep -q \"${REDDIT_HOME}/processing\" <<< \"${raw_file_dir}\"; then\n    mv ${raw_file_dir} ${REDDIT_HOME}/processing\nelse\n    echo JSON is already in processing\nfi\n\n# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing\necho \"#{setValue(raw_file_dir=${REDDIT_HOME}/processing/${filename})}\"","resourceList":[]}, environmentConfig=export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='move to processing'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240424'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1276'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13340390094208'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240424041217'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='processing'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='542'}, raw_file_dir=Property{prop='raw_file_dir', direct=IN, type=VARCHAR, value='/local_storage/reddit/processing/500-20240423.json'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240423'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-542][TI-1276] - [INFO] 2024-04-24 04:12:17.051 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: move to processing to wait queue success
[WI-542][TI-1276] - [INFO] 2024-04-24 04:12:17.053 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-542][TI-1276] - [INFO] 2024-04-24 04:12:17.065 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-542][TI-1276] - [INFO] 2024-04-24 04:12:17.065 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-542][TI-1276] - [INFO] 2024-04-24 04:12:17.065 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-542][TI-1276] - [INFO] 2024-04-24 04:12:17.065 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713903137065
[WI-542][TI-1276] - [INFO] 2024-04-24 04:12:17.065 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 542_1276
[WI-542][TI-1276] - [INFO] 2024-04-24 04:12:17.069 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1276,
  "taskName" : "move to processing",
  "firstSubmitTime" : 1713903137018,
  "startTime" : 1713903137065,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.10:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240424/13201021801792/89/542/1276.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 89,
  "processInstanceId" : 542,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"processing\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[{\"prop\":\"raw_file_dir\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"\"}],\"rawScript\":\"# move file to the reddit processing folder\\n# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error\\nfilename=$(basename \\\"${raw_file_dir}\\\")\\nif ! grep -q \\\"${REDDIT_HOME}/processing\\\" <<< \\\"${raw_file_dir}\\\"; then\\n    mv ${raw_file_dir} ${REDDIT_HOME}/processing\\nelse\\n    echo JSON is already in processing\\nfi\\n\\n# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing\\necho \\\"#{setValue(raw_file_dir=${REDDIT_HOME}/processing/${filename})}\\\"\",\"resourceList\":[]}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "move to processing"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240424"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1276"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13340390094208"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240424041217"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "processing"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "542"
    },
    "raw_file_dir" : {
      "prop" : "raw_file_dir",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit/processing/500-20240423.json"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "542_1276",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"raw_file_dir\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"/local_storage/reddit/processing/500-20240423.json\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-542][TI-1276] - [INFO] 2024-04-24 04:12:17.069 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-542][TI-1276] - [INFO] 2024-04-24 04:12:17.070 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-542][TI-1276] - [INFO] 2024-04-24 04:12:17.070 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-542][TI-1276] - [INFO] 2024-04-24 04:12:17.085 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-542][TI-1276] - [INFO] 2024-04-24 04:12:17.089 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-542][TI-1276] - [INFO] 2024-04-24 04:12:17.095 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_89/542/1276 check successfully
[WI-542][TI-1276] - [INFO] 2024-04-24 04:12:17.109 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-542][TI-1276] - [INFO] 2024-04-24 04:12:17.112 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-542][TI-1276] - [INFO] 2024-04-24 04:12:17.113 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-542][TI-1276] - [INFO] 2024-04-24 04:12:17.113 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-542][TI-1276] - [INFO] 2024-04-24 04:12:17.113 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ {
    "prop" : "raw_file_dir",
    "direct" : "OUT",
    "type" : "VARCHAR",
    "value" : ""
  } ],
  "varPool" : null,
  "rawScript" : "# move file to the reddit processing folder\n# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error\nfilename=$(basename \"${raw_file_dir}\")\nif ! grep -q \"${REDDIT_HOME}/processing\" <<< \"${raw_file_dir}\"; then\n    mv ${raw_file_dir} ${REDDIT_HOME}/processing\nelse\n    echo JSON is already in processing\nfi\n\n# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing\necho \"#{setValue(raw_file_dir=${REDDIT_HOME}/processing/${filename})}\"",
  "resourceList" : [ ]
}
[WI-542][TI-1276] - [INFO] 2024-04-24 04:12:17.114 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-542][TI-1276] - [INFO] 2024-04-24 04:12:17.117 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}] successfully
[WI-542][TI-1276] - [INFO] 2024-04-24 04:12:17.117 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-542][TI-1276] - [INFO] 2024-04-24 04:12:17.119 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-542][TI-1276] - [INFO] 2024-04-24 04:12:17.123 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-542][TI-1276] - [INFO] 2024-04-24 04:12:17.124 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-542][TI-1276] - [INFO] 2024-04-24 04:12:17.125 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-542][TI-1276] - [INFO] 2024-04-24 04:12:17.125 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export PYTHON_LAUNCHER=/bin/python3.11
# move file to the reddit processing folder
# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error
filename=$(basename "/local_storage/reddit/processing/500-20240423.json")
if ! grep -q "/local_storage/reddit/processing" <<< "/local_storage/reddit/processing/500-20240423.json"; then
    mv /local_storage/reddit/processing/500-20240423.json /local_storage/reddit/processing
else
    echo JSON is already in processing
fi

# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing
echo "#{setValue(raw_file_dir=/local_storage/reddit/processing/${filename})}"
[WI-542][TI-1276] - [INFO] 2024-04-24 04:12:17.125 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-542][TI-1276] - [INFO] 2024-04-24 04:12:17.125 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_89/542/1276/542_1276.sh
[WI-542][TI-1276] - [INFO] 2024-04-24 04:12:17.148 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 133
[WI-0][TI-1276] - [INFO] 2024-04-24 04:12:17.906 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1276, success=true)
[WI-0][TI-1276] - [INFO] 2024-04-24 04:12:17.926 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1276)
[WI-0][TI-0] - [INFO] 2024-04-24 04:12:18.066 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8878205128205128 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:12:18.150 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
	JSON is already in processing
	#{setValue(raw_file_dir=/local_storage/reddit/processing/500-20240423.json)}
[WI-542][TI-1276] - [INFO] 2024-04-24 04:12:18.154 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_89/542/1276, processId:133 ,exitStatusCode:0 ,processWaitForStatus:true ,processExitValue:0
[WI-542][TI-1276] - [INFO] 2024-04-24 04:12:18.155 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-542][TI-1276] - [INFO] 2024-04-24 04:12:18.155 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-542][TI-1276] - [INFO] 2024-04-24 04:12:18.155 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-542][TI-1276] - [INFO] 2024-04-24 04:12:18.155 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-542][TI-1276] - [INFO] 2024-04-24 04:12:18.183 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: SUCCESS to master : 172.18.1.1:1234
[WI-542][TI-1276] - [INFO] 2024-04-24 04:12:18.184 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-542][TI-1276] - [INFO] 2024-04-24 04:12:18.184 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_89/542/1276
[WI-542][TI-1276] - [INFO] 2024-04-24 04:12:18.185 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_89/542/1276
[WI-542][TI-1276] - [INFO] 2024-04-24 04:12:18.185 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-1276] - [INFO] 2024-04-24 04:12:18.880 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1276, success=true)
[WI-0][TI-0] - [INFO] 2024-04-24 04:12:18.930 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1277, taskName=spark preprocessing, firstSubmitTime=1713903138911, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.10:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=89, appIds=null, processInstanceId=542, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"processing"}], executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[],"rawScript":"$SPARK_HOME/bin/spark-submit \\\n    --master spark://spark-master:7077 \\\n    --deploy-mode cluster \\\n    --conf spark.driver.cores=2 \\\n    --conf spark.driver.memory=2G \\\n    --conf spark.executor.instances=1 \\\n    --conf spark.executor.cores=2 \\\n    --conf spark.executor.memory=2G \\\n    --files ${raw_file_dir} \\\n    --name reddit_preprocessing spark_reddit_preprocessing.py\n\n# $SPARK_HOME/bin/spark-submit \\\n#     --master local \\\n#     --files ${raw_file_dir} \\\n#     --name reddit_preprocessing spark_reddit_preprocessing.py\n","resourceList":[{"id":null,"resourceName":"file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py","res":null}]}, environmentConfig=export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export PYSPARK_DRIVER_PYTHON=/bin/python3.11
export PYTHON_LAUNCHER=/bin/python3.11
export PYSPARK_PYTHON=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='spark preprocessing'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240424'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1277'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13210058002752'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240424041218'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='processing'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='542'}, raw_file_dir=Property{prop='raw_file_dir', direct=IN, type=VARCHAR, value='/local_storage/reddit/processing/500-20240423.json'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240423'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-542][TI-1277] - [INFO] 2024-04-24 04:12:18.931 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: spark preprocessing to wait queue success
[WI-542][TI-1277] - [INFO] 2024-04-24 04:12:18.931 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-542][TI-1277] - [INFO] 2024-04-24 04:12:18.934 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-542][TI-1277] - [INFO] 2024-04-24 04:12:18.934 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-542][TI-1277] - [INFO] 2024-04-24 04:12:18.934 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-542][TI-1277] - [INFO] 2024-04-24 04:12:18.935 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713903138935
[WI-542][TI-1277] - [INFO] 2024-04-24 04:12:18.935 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 542_1277
[WI-542][TI-1277] - [INFO] 2024-04-24 04:12:18.938 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1277,
  "taskName" : "spark preprocessing",
  "firstSubmitTime" : 1713903138911,
  "startTime" : 1713903138935,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.10:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240424/13201021801792/89/542/1277.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 89,
  "processInstanceId" : 542,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"processing\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[],\"rawScript\":\"$SPARK_HOME/bin/spark-submit \\\\\\n    --master spark://spark-master:7077 \\\\\\n    --deploy-mode cluster \\\\\\n    --conf spark.driver.cores=2 \\\\\\n    --conf spark.driver.memory=2G \\\\\\n    --conf spark.executor.instances=1 \\\\\\n    --conf spark.executor.cores=2 \\\\\\n    --conf spark.executor.memory=2G \\\\\\n    --files ${raw_file_dir} \\\\\\n    --name reddit_preprocessing spark_reddit_preprocessing.py\\n\\n# $SPARK_HOME/bin/spark-submit \\\\\\n#     --master local \\\\\\n#     --files ${raw_file_dir} \\\\\\n#     --name reddit_preprocessing spark_reddit_preprocessing.py\\n\",\"resourceList\":[{\"id\":null,\"resourceName\":\"file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py\",\"res\":null}]}",
  "environmentConfig" : "export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3\nexport JAVA_HOME=/opt/java/openjdk\nexport PYSPARK_DRIVER_PYTHON=/bin/python3.11\nexport PYTHON_LAUNCHER=/bin/python3.11\nexport PYSPARK_PYTHON=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "spark preprocessing"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240424"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1277"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13210058002752"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240424041218"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "processing"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "542"
    },
    "raw_file_dir" : {
      "prop" : "raw_file_dir",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit/processing/500-20240423.json"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "542_1277",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"raw_file_dir\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"/local_storage/reddit/processing/500-20240423.json\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-542][TI-1277] - [INFO] 2024-04-24 04:12:18.938 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-542][TI-1277] - [INFO] 2024-04-24 04:12:18.938 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-542][TI-1277] - [INFO] 2024-04-24 04:12:18.938 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-542][TI-1277] - [INFO] 2024-04-24 04:12:18.969 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-542][TI-1277] - [INFO] 2024-04-24 04:12:18.971 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-542][TI-1277] - [INFO] 2024-04-24 04:12:18.971 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_89/542/1277 check successfully
[WI-542][TI-1277] - [INFO] 2024-04-24 04:12:18.971 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-542][TI-1277] - [INFO] 2024-04-24 04:12:19.069 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py=ResourceContext.ResourceItem(resourceAbsolutePathInStorage=file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py, resourceRelativePath=spark_reddit_preprocessing.py, resourceAbsolutePathInLocal=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_89/542/1277/spark_reddit_preprocessing.py)})
[WI-542][TI-1277] - [INFO] 2024-04-24 04:12:19.071 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-542][TI-1277] - [INFO] 2024-04-24 04:12:19.074 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-542][TI-1277] - [INFO] 2024-04-24 04:12:19.076 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ ],
  "varPool" : null,
  "rawScript" : "$SPARK_HOME/bin/spark-submit \\\n    --master spark://spark-master:7077 \\\n    --deploy-mode cluster \\\n    --conf spark.driver.cores=2 \\\n    --conf spark.driver.memory=2G \\\n    --conf spark.executor.instances=1 \\\n    --conf spark.executor.cores=2 \\\n    --conf spark.executor.memory=2G \\\n    --files ${raw_file_dir} \\\n    --name reddit_preprocessing spark_reddit_preprocessing.py\n\n# $SPARK_HOME/bin/spark-submit \\\n#     --master local \\\n#     --files ${raw_file_dir} \\\n#     --name reddit_preprocessing spark_reddit_preprocessing.py\n",
  "resourceList" : [ {
    "id" : null,
    "resourceName" : "file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py",
    "res" : null
  } ]
}
[WI-542][TI-1277] - [INFO] 2024-04-24 04:12:19.077 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-542][TI-1277] - [INFO] 2024-04-24 04:12:19.077 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}] successfully
[WI-542][TI-1277] - [INFO] 2024-04-24 04:12:19.077 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-542][TI-1277] - [INFO] 2024-04-24 04:12:19.077 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-542][TI-1277] - [INFO] 2024-04-24 04:12:19.078 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-542][TI-1277] - [INFO] 2024-04-24 04:12:19.079 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-542][TI-1277] - [INFO] 2024-04-24 04:12:19.080 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-542][TI-1277] - [INFO] 2024-04-24 04:12:19.080 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export PYSPARK_DRIVER_PYTHON=/bin/python3.11
export PYTHON_LAUNCHER=/bin/python3.11
export PYSPARK_PYTHON=/bin/python3.11
$SPARK_HOME/bin/spark-submit \
    --master spark://spark-master:7077 \
    --deploy-mode cluster \
    --conf spark.driver.cores=2 \
    --conf spark.driver.memory=2G \
    --conf spark.executor.instances=1 \
    --conf spark.executor.cores=2 \
    --conf spark.executor.memory=2G \
    --files /local_storage/reddit/processing/500-20240423.json \
    --name reddit_preprocessing spark_reddit_preprocessing.py

# $SPARK_HOME/bin/spark-submit \
#     --master local \
#     --files /local_storage/reddit/processing/500-20240423.json \
#     --name reddit_preprocessing spark_reddit_preprocessing.py

[WI-542][TI-1277] - [INFO] 2024-04-24 04:12:19.080 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-542][TI-1277] - [INFO] 2024-04-24 04:12:19.080 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_89/542/1277/542_1277.sh
[WI-542][TI-1277] - [INFO] 2024-04-24 04:12:19.085 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 148
[WI-0][TI-0] - [INFO] 2024-04-24 04:12:19.115 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7355371900826446 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-1277] - [INFO] 2024-04-24 04:12:19.887 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1277, success=true)
[WI-0][TI-1277] - [INFO] 2024-04-24 04:12:19.922 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1277)
[WI-0][TI-0] - [INFO] 2024-04-24 04:12:20.093 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
[WI-0][TI-0] - [INFO] 2024-04-24 04:12:21.141 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7178082191780822 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:12:22.173 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7478991596638656 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:12:23.176 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7674418604651163 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:12:24.179 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9312597962382446 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:12:25.185 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7991803278688524 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:12:26.123 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	Exception in thread "main" org.apache.spark.SparkException: Cluster deploy mode is currently not supported for python applications on standalone clusters.
		at org.apache.spark.deploy.SparkSubmit.error(SparkSubmit.scala:1047)
		at org.apache.spark.deploy.SparkSubmit.prepareSubmitEnvironment(SparkSubmit.scala:293)
		at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:964)
		at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:194)
		at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:217)
		at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:91)
		at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1120)
		at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1129)
		at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
[WI-542][TI-1277] - [INFO] 2024-04-24 04:12:26.125 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_89/542/1277, processId:148 ,exitStatusCode:1 ,processWaitForStatus:true ,processExitValue:1
[WI-542][TI-1277] - [INFO] 2024-04-24 04:12:26.125 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-542][TI-1277] - [INFO] 2024-04-24 04:12:26.125 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-542][TI-1277] - [INFO] 2024-04-24 04:12:26.125 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-542][TI-1277] - [INFO] 2024-04-24 04:12:26.126 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-542][TI-1277] - [INFO] 2024-04-24 04:12:26.142 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: FAILURE to master : 172.18.1.1:1234
[WI-542][TI-1277] - [INFO] 2024-04-24 04:12:26.143 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-542][TI-1277] - [INFO] 2024-04-24 04:12:26.143 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_89/542/1277
[WI-542][TI-1277] - [INFO] 2024-04-24 04:12:26.145 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_89/542/1277
[WI-542][TI-1277] - [INFO] 2024-04-24 04:12:26.145 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-1277] - [INFO] 2024-04-24 04:12:26.887 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1277, success=true)
[WI-0][TI-0] - [INFO] 2024-04-24 04:12:27.218 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7831978319783198 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:12:30.249 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7094017094017094 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:12:31.266 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.836111111111111 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:15:51.252 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7198879551820728 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:17:47.578 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.703030303030303 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:18:14.837 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8696883852691217 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:18:15.887 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7667638483965014 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:18:16.895 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9323529411764706 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:18:24.025 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1278, taskName=search for intake JSON files, firstSubmitTime=1713903503984, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.10:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=90, appIds=null, processInstanceId=543, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"processing"}], executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":""}],"rawScript":"# find 1 raw file in the folder\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\n\n# check if raw_file_dir is empty, then set raw_file_dir to null\nif [ -z \"$raw_file_dir\" ]; then\n    raw_file_dir=null\nfi\n\necho \"#{setValue(raw_file_dir=${raw_file_dir})}\"","resourceList":[]}, environmentConfig=export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='search for intake JSON files'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240424'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1278'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13340113777664'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240424041824'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='processing'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='543'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240423'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=null, dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-543][TI-1278] - [INFO] 2024-04-24 04:18:24.032 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: search for intake JSON files to wait queue success
[WI-543][TI-1278] - [INFO] 2024-04-24 04:18:24.041 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-543][TI-1278] - [INFO] 2024-04-24 04:18:24.045 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-543][TI-1278] - [INFO] 2024-04-24 04:18:24.045 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-543][TI-1278] - [INFO] 2024-04-24 04:18:24.046 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-543][TI-1278] - [INFO] 2024-04-24 04:18:24.046 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713903504046
[WI-543][TI-1278] - [INFO] 2024-04-24 04:18:24.046 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 543_1278
[WI-543][TI-1278] - [INFO] 2024-04-24 04:18:24.047 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1278,
  "taskName" : "search for intake JSON files",
  "firstSubmitTime" : 1713903503984,
  "startTime" : 1713903504046,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.10:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240424/13201021801792/90/543/1278.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 90,
  "processInstanceId" : 543,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"processing\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[{\"prop\":\"raw_file_dir\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"\"}],\"rawScript\":\"# find 1 raw file in the folder\\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\\n\\n# check if raw_file_dir is empty, then set raw_file_dir to null\\nif [ -z \\\"$raw_file_dir\\\" ]; then\\n    raw_file_dir=null\\nfi\\n\\necho \\\"#{setValue(raw_file_dir=${raw_file_dir})}\\\"\",\"resourceList\":[]}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "search for intake JSON files"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240424"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1278"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13340113777664"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240424041824"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "processing"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "543"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "543_1278",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-543][TI-1278] - [INFO] 2024-04-24 04:18:24.048 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-543][TI-1278] - [INFO] 2024-04-24 04:18:24.048 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-543][TI-1278] - [INFO] 2024-04-24 04:18:24.048 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-543][TI-1278] - [INFO] 2024-04-24 04:18:24.068 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-543][TI-1278] - [INFO] 2024-04-24 04:18:24.068 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-543][TI-1278] - [INFO] 2024-04-24 04:18:24.069 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/543/1278 check successfully
[WI-543][TI-1278] - [INFO] 2024-04-24 04:18:24.069 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-543][TI-1278] - [INFO] 2024-04-24 04:18:24.070 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-543][TI-1278] - [INFO] 2024-04-24 04:18:24.070 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-543][TI-1278] - [INFO] 2024-04-24 04:18:24.071 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-543][TI-1278] - [INFO] 2024-04-24 04:18:24.071 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ {
    "prop" : "raw_file_dir",
    "direct" : "OUT",
    "type" : "VARCHAR",
    "value" : ""
  } ],
  "varPool" : null,
  "rawScript" : "# find 1 raw file in the folder\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\n\n# check if raw_file_dir is empty, then set raw_file_dir to null\nif [ -z \"$raw_file_dir\" ]; then\n    raw_file_dir=null\nfi\n\necho \"#{setValue(raw_file_dir=${raw_file_dir})}\"",
  "resourceList" : [ ]
}
[WI-543][TI-1278] - [INFO] 2024-04-24 04:18:24.071 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-543][TI-1278] - [INFO] 2024-04-24 04:18:24.071 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: null successfully
[WI-543][TI-1278] - [INFO] 2024-04-24 04:18:24.072 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-543][TI-1278] - [INFO] 2024-04-24 04:18:24.072 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-543][TI-1278] - [INFO] 2024-04-24 04:18:24.072 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-543][TI-1278] - [INFO] 2024-04-24 04:18:24.072 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-543][TI-1278] - [INFO] 2024-04-24 04:18:24.073 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-543][TI-1278] - [INFO] 2024-04-24 04:18:24.073 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export PYTHON_LAUNCHER=/bin/python3.11
# find 1 raw file in the folder
raw_file_dir=$(find /local_storage/reddit/processing -type f -name '*.json'| head -n 1)

# check if raw_file_dir is empty, then set raw_file_dir to null
if [ -z "$raw_file_dir" ]; then
    raw_file_dir=null
fi

echo "#{setValue(raw_file_dir=${raw_file_dir})}"
[WI-543][TI-1278] - [INFO] 2024-04-24 04:18:24.077 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-543][TI-1278] - [INFO] 2024-04-24 04:18:24.080 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/543/1278/543_1278.sh
[WI-543][TI-1278] - [INFO] 2024-04-24 04:18:24.129 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 268
[WI-0][TI-0] - [INFO] 2024-04-24 04:18:24.137 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
[WI-0][TI-0] - [INFO] 2024-04-24 04:18:24.948 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9690140845070422 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-1278] - [INFO] 2024-04-24 04:18:24.966 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1278, success=true)
[WI-0][TI-1278] - [INFO] 2024-04-24 04:18:25.054 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1278)
[WI-0][TI-0] - [INFO] 2024-04-24 04:18:25.170 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	#{setValue(raw_file_dir=/local_storage/reddit/processing/500-20240423.json)}
[WI-543][TI-1278] - [INFO] 2024-04-24 04:18:25.171 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/543/1278, processId:268 ,exitStatusCode:0 ,processWaitForStatus:true ,processExitValue:0
[WI-543][TI-1278] - [INFO] 2024-04-24 04:18:25.172 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-543][TI-1278] - [INFO] 2024-04-24 04:18:25.172 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-543][TI-1278] - [INFO] 2024-04-24 04:18:25.172 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-543][TI-1278] - [INFO] 2024-04-24 04:18:25.173 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-543][TI-1278] - [INFO] 2024-04-24 04:18:25.194 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: SUCCESS to master : 172.18.1.1:1234
[WI-543][TI-1278] - [INFO] 2024-04-24 04:18:25.195 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-543][TI-1278] - [INFO] 2024-04-24 04:18:25.195 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/543/1278
[WI-543][TI-1278] - [INFO] 2024-04-24 04:18:25.196 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/543/1278
[WI-543][TI-1278] - [INFO] 2024-04-24 04:18:25.197 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-1278] - [INFO] 2024-04-24 04:18:25.946 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1278, success=true)
[WI-0][TI-0] - [INFO] 2024-04-24 04:18:27.101 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7049689440993788 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:18:27.181 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1280, taskName=move to processing, firstSubmitTime=1713903507122, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.10:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=90, appIds=null, processInstanceId=543, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"processing"}], executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":""}],"rawScript":"# move file to the reddit processing folder\n# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error\nfilename=$(basename \"${raw_file_dir}\")\nif ! grep -q \"${REDDIT_HOME}/processing\" <<< \"${raw_file_dir}\"; then\n    mv ${raw_file_dir} ${REDDIT_HOME}/processing\nelse\n    echo JSON is already in processing\nfi\n\n# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing\necho \"#{setValue(raw_file_dir=${REDDIT_HOME}/processing/${filename})}\"","resourceList":[]}, environmentConfig=export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='move to processing'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240424'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1280'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13340390094208'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240424041827'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='processing'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='543'}, raw_file_dir=Property{prop='raw_file_dir', direct=IN, type=VARCHAR, value='/local_storage/reddit/processing/500-20240423.json'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240423'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-543][TI-1280] - [INFO] 2024-04-24 04:18:27.184 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: move to processing to wait queue success
[WI-543][TI-1280] - [INFO] 2024-04-24 04:18:27.185 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-543][TI-1280] - [INFO] 2024-04-24 04:18:27.200 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-543][TI-1280] - [INFO] 2024-04-24 04:18:27.204 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-543][TI-1280] - [INFO] 2024-04-24 04:18:27.226 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-543][TI-1280] - [INFO] 2024-04-24 04:18:27.228 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713903507228
[WI-543][TI-1280] - [INFO] 2024-04-24 04:18:27.230 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 543_1280
[WI-543][TI-1280] - [INFO] 2024-04-24 04:18:27.231 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1280,
  "taskName" : "move to processing",
  "firstSubmitTime" : 1713903507122,
  "startTime" : 1713903507228,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.10:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240424/13201021801792/90/543/1280.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 90,
  "processInstanceId" : 543,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"processing\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[{\"prop\":\"raw_file_dir\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"\"}],\"rawScript\":\"# move file to the reddit processing folder\\n# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error\\nfilename=$(basename \\\"${raw_file_dir}\\\")\\nif ! grep -q \\\"${REDDIT_HOME}/processing\\\" <<< \\\"${raw_file_dir}\\\"; then\\n    mv ${raw_file_dir} ${REDDIT_HOME}/processing\\nelse\\n    echo JSON is already in processing\\nfi\\n\\n# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing\\necho \\\"#{setValue(raw_file_dir=${REDDIT_HOME}/processing/${filename})}\\\"\",\"resourceList\":[]}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "move to processing"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240424"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1280"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13340390094208"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240424041827"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "processing"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "543"
    },
    "raw_file_dir" : {
      "prop" : "raw_file_dir",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit/processing/500-20240423.json"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "543_1280",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"raw_file_dir\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"/local_storage/reddit/processing/500-20240423.json\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-543][TI-1280] - [INFO] 2024-04-24 04:18:27.233 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-543][TI-1280] - [INFO] 2024-04-24 04:18:27.234 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-543][TI-1280] - [INFO] 2024-04-24 04:18:27.234 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-543][TI-1280] - [INFO] 2024-04-24 04:18:27.249 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-543][TI-1280] - [INFO] 2024-04-24 04:18:27.249 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-543][TI-1280] - [INFO] 2024-04-24 04:18:27.250 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/543/1280 check successfully
[WI-543][TI-1280] - [INFO] 2024-04-24 04:18:27.250 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-543][TI-1280] - [INFO] 2024-04-24 04:18:27.250 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-543][TI-1280] - [INFO] 2024-04-24 04:18:27.251 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-543][TI-1280] - [INFO] 2024-04-24 04:18:27.251 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-543][TI-1280] - [INFO] 2024-04-24 04:18:27.252 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ {
    "prop" : "raw_file_dir",
    "direct" : "OUT",
    "type" : "VARCHAR",
    "value" : ""
  } ],
  "varPool" : null,
  "rawScript" : "# move file to the reddit processing folder\n# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error\nfilename=$(basename \"${raw_file_dir}\")\nif ! grep -q \"${REDDIT_HOME}/processing\" <<< \"${raw_file_dir}\"; then\n    mv ${raw_file_dir} ${REDDIT_HOME}/processing\nelse\n    echo JSON is already in processing\nfi\n\n# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing\necho \"#{setValue(raw_file_dir=${REDDIT_HOME}/processing/${filename})}\"",
  "resourceList" : [ ]
}
[WI-543][TI-1280] - [INFO] 2024-04-24 04:18:27.252 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-543][TI-1280] - [INFO] 2024-04-24 04:18:27.252 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}] successfully
[WI-543][TI-1280] - [INFO] 2024-04-24 04:18:27.252 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-543][TI-1280] - [INFO] 2024-04-24 04:18:27.252 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-543][TI-1280] - [INFO] 2024-04-24 04:18:27.252 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-543][TI-1280] - [INFO] 2024-04-24 04:18:27.270 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-543][TI-1280] - [INFO] 2024-04-24 04:18:27.270 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-543][TI-1280] - [INFO] 2024-04-24 04:18:27.270 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export PYTHON_LAUNCHER=/bin/python3.11
# move file to the reddit processing folder
# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error
filename=$(basename "/local_storage/reddit/processing/500-20240423.json")
if ! grep -q "/local_storage/reddit/processing" <<< "/local_storage/reddit/processing/500-20240423.json"; then
    mv /local_storage/reddit/processing/500-20240423.json /local_storage/reddit/processing
else
    echo JSON is already in processing
fi

# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing
echo "#{setValue(raw_file_dir=/local_storage/reddit/processing/${filename})}"
[WI-543][TI-1280] - [INFO] 2024-04-24 04:18:27.270 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-543][TI-1280] - [INFO] 2024-04-24 04:18:27.270 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/543/1280/543_1280.sh
[WI-543][TI-1280] - [INFO] 2024-04-24 04:18:27.310 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 288
[WI-0][TI-1280] - [INFO] 2024-04-24 04:18:28.028 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1280, success=true)
[WI-0][TI-1280] - [INFO] 2024-04-24 04:18:28.068 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1280)
[WI-0][TI-0] - [INFO] 2024-04-24 04:18:28.172 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7302452316076294 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:18:28.320 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
	JSON is already in processing
	#{setValue(raw_file_dir=/local_storage/reddit/processing/500-20240423.json)}
[WI-543][TI-1280] - [INFO] 2024-04-24 04:18:28.325 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/543/1280, processId:288 ,exitStatusCode:0 ,processWaitForStatus:true ,processExitValue:0
[WI-543][TI-1280] - [INFO] 2024-04-24 04:18:28.330 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-543][TI-1280] - [INFO] 2024-04-24 04:18:28.330 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-543][TI-1280] - [INFO] 2024-04-24 04:18:28.330 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-543][TI-1280] - [INFO] 2024-04-24 04:18:28.331 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-543][TI-1280] - [INFO] 2024-04-24 04:18:28.336 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: SUCCESS to master : 172.18.1.1:1234
[WI-543][TI-1280] - [INFO] 2024-04-24 04:18:28.337 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-543][TI-1280] - [INFO] 2024-04-24 04:18:28.342 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/543/1280
[WI-543][TI-1280] - [INFO] 2024-04-24 04:18:28.343 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/543/1280
[WI-543][TI-1280] - [INFO] 2024-04-24 04:18:28.348 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-1280] - [INFO] 2024-04-24 04:18:29.032 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1280, success=true)
[WI-0][TI-0] - [INFO] 2024-04-24 04:18:29.174 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1281, taskName=spark preprocessing, firstSubmitTime=1713903509150, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.10:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=90, appIds=null, processInstanceId=543, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"processing"}], executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[],"rawScript":"$SPARK_HOME/bin/spark-submit \\\n    --master spark://spark-master:7077 \\\n    --deploy-mode client \\\n    --conf spark.driver.cores=2 \\\n    --conf spark.driver.memory=2G \\\n    --conf spark.executor.instances=1 \\\n    --conf spark.executor.cores=2 \\\n    --conf spark.executor.memory=2G \\\n    --files ${raw_file_dir} \\\n    --name reddit_preprocessing testing.py\n\n# $SPARK_HOME/bin/spark-submit \\\n#     --master local \\\n#     --files ${raw_file_dir} \\\n#     --name reddit_preprocessing spark_reddit_preprocessing.py\n","resourceList":[{"id":null,"resourceName":"file:/dolphinscheduler/default/resources/testing.py","res":null}]}, environmentConfig=export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export PYSPARK_DRIVER_PYTHON=/bin/python3.11
export PYTHON_LAUNCHER=/bin/python3.11
export PYSPARK_PYTHON=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='spark preprocessing'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240424'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1281'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13210058002752'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240424041829'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='processing'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='543'}, raw_file_dir=Property{prop='raw_file_dir', direct=IN, type=VARCHAR, value='/local_storage/reddit/processing/500-20240423.json'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240423'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-543][TI-1281] - [INFO] 2024-04-24 04:18:29.177 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: spark preprocessing to wait queue success
[WI-543][TI-1281] - [INFO] 2024-04-24 04:18:29.178 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-543][TI-1281] - [INFO] 2024-04-24 04:18:29.182 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-543][TI-1281] - [INFO] 2024-04-24 04:18:29.183 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-543][TI-1281] - [INFO] 2024-04-24 04:18:29.183 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-543][TI-1281] - [INFO] 2024-04-24 04:18:29.184 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713903509183
[WI-543][TI-1281] - [INFO] 2024-04-24 04:18:29.185 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 543_1281
[WI-543][TI-1281] - [INFO] 2024-04-24 04:18:29.190 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1281,
  "taskName" : "spark preprocessing",
  "firstSubmitTime" : 1713903509150,
  "startTime" : 1713903509183,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.10:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240424/13201021801792/90/543/1281.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 90,
  "processInstanceId" : 543,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"processing\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[],\"rawScript\":\"$SPARK_HOME/bin/spark-submit \\\\\\n    --master spark://spark-master:7077 \\\\\\n    --deploy-mode client \\\\\\n    --conf spark.driver.cores=2 \\\\\\n    --conf spark.driver.memory=2G \\\\\\n    --conf spark.executor.instances=1 \\\\\\n    --conf spark.executor.cores=2 \\\\\\n    --conf spark.executor.memory=2G \\\\\\n    --files ${raw_file_dir} \\\\\\n    --name reddit_preprocessing testing.py\\n\\n# $SPARK_HOME/bin/spark-submit \\\\\\n#     --master local \\\\\\n#     --files ${raw_file_dir} \\\\\\n#     --name reddit_preprocessing spark_reddit_preprocessing.py\\n\",\"resourceList\":[{\"id\":null,\"resourceName\":\"file:/dolphinscheduler/default/resources/testing.py\",\"res\":null}]}",
  "environmentConfig" : "export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3\nexport JAVA_HOME=/opt/java/openjdk\nexport PYSPARK_DRIVER_PYTHON=/bin/python3.11\nexport PYTHON_LAUNCHER=/bin/python3.11\nexport PYSPARK_PYTHON=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "spark preprocessing"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240424"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1281"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13210058002752"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240424041829"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "processing"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "543"
    },
    "raw_file_dir" : {
      "prop" : "raw_file_dir",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit/processing/500-20240423.json"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "543_1281",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"raw_file_dir\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"/local_storage/reddit/processing/500-20240423.json\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-543][TI-1281] - [INFO] 2024-04-24 04:18:29.193 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-543][TI-1281] - [INFO] 2024-04-24 04:18:29.194 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-543][TI-1281] - [INFO] 2024-04-24 04:18:29.194 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-543][TI-1281] - [INFO] 2024-04-24 04:18:29.210 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-543][TI-1281] - [INFO] 2024-04-24 04:18:29.212 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-543][TI-1281] - [INFO] 2024-04-24 04:18:29.213 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/543/1281 check successfully
[WI-543][TI-1281] - [INFO] 2024-04-24 04:18:29.214 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-543][TI-1281] - [INFO] 2024-04-24 04:18:29.247 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={file:/dolphinscheduler/default/resources/testing.py=ResourceContext.ResourceItem(resourceAbsolutePathInStorage=file:/dolphinscheduler/default/resources/testing.py, resourceRelativePath=testing.py, resourceAbsolutePathInLocal=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/543/1281/testing.py)})
[WI-543][TI-1281] - [INFO] 2024-04-24 04:18:29.250 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-543][TI-1281] - [INFO] 2024-04-24 04:18:29.252 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-543][TI-1281] - [INFO] 2024-04-24 04:18:29.265 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ ],
  "varPool" : null,
  "rawScript" : "$SPARK_HOME/bin/spark-submit \\\n    --master spark://spark-master:7077 \\\n    --deploy-mode client \\\n    --conf spark.driver.cores=2 \\\n    --conf spark.driver.memory=2G \\\n    --conf spark.executor.instances=1 \\\n    --conf spark.executor.cores=2 \\\n    --conf spark.executor.memory=2G \\\n    --files ${raw_file_dir} \\\n    --name reddit_preprocessing testing.py\n\n# $SPARK_HOME/bin/spark-submit \\\n#     --master local \\\n#     --files ${raw_file_dir} \\\n#     --name reddit_preprocessing spark_reddit_preprocessing.py\n",
  "resourceList" : [ {
    "id" : null,
    "resourceName" : "file:/dolphinscheduler/default/resources/testing.py",
    "res" : null
  } ]
}
[WI-543][TI-1281] - [INFO] 2024-04-24 04:18:29.266 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-543][TI-1281] - [INFO] 2024-04-24 04:18:29.266 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}] successfully
[WI-543][TI-1281] - [INFO] 2024-04-24 04:18:29.266 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-543][TI-1281] - [INFO] 2024-04-24 04:18:29.267 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-543][TI-1281] - [INFO] 2024-04-24 04:18:29.268 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-543][TI-1281] - [INFO] 2024-04-24 04:18:29.269 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-543][TI-1281] - [INFO] 2024-04-24 04:18:29.269 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-543][TI-1281] - [INFO] 2024-04-24 04:18:29.270 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export PYSPARK_DRIVER_PYTHON=/bin/python3.11
export PYTHON_LAUNCHER=/bin/python3.11
export PYSPARK_PYTHON=/bin/python3.11
$SPARK_HOME/bin/spark-submit \
    --master spark://spark-master:7077 \
    --deploy-mode client \
    --conf spark.driver.cores=2 \
    --conf spark.driver.memory=2G \
    --conf spark.executor.instances=1 \
    --conf spark.executor.cores=2 \
    --conf spark.executor.memory=2G \
    --files /local_storage/reddit/processing/500-20240423.json \
    --name reddit_preprocessing testing.py

# $SPARK_HOME/bin/spark-submit \
#     --master local \
#     --files /local_storage/reddit/processing/500-20240423.json \
#     --name reddit_preprocessing spark_reddit_preprocessing.py

[WI-543][TI-1281] - [INFO] 2024-04-24 04:18:29.271 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-543][TI-1281] - [INFO] 2024-04-24 04:18:29.271 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/543/1281/543_1281.sh
[WI-543][TI-1281] - [INFO] 2024-04-24 04:18:29.280 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 300
[WI-0][TI-1281] - [INFO] 2024-04-24 04:18:30.039 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1281, success=true)
[WI-0][TI-1281] - [INFO] 2024-04-24 04:18:30.062 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1281)
[WI-0][TI-0] - [INFO] 2024-04-24 04:18:30.282 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
[WI-0][TI-0] - [INFO] 2024-04-24 04:18:35.300 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 04:18:34 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[WI-0][TI-0] - [INFO] 2024-04-24 04:18:36.214 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9150943396226415 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:18:38.248 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7970507821254089 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:18:38.307 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 04:18:38 INFO SparkContext: Running Spark version 3.5.1
	24/04/24 04:18:38 INFO SparkContext: OS info Linux, 6.5.0-28-generic, amd64
	24/04/24 04:18:38 INFO SparkContext: Java version 1.8.0_402
	24/04/24 04:18:38 INFO ResourceUtils: ==============================================================
	24/04/24 04:18:38 INFO ResourceUtils: No custom resources configured for spark.driver.
	24/04/24 04:18:38 INFO ResourceUtils: ==============================================================
	24/04/24 04:18:38 INFO SparkContext: Submitted application: reddit_preprocessing
	24/04/24 04:18:38 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 2, script: , vendor: , memory -> name: memory, amount: 2048, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
[WI-0][TI-0] - [INFO] 2024-04-24 04:18:39.273 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7811365939025514 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:18:39.309 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 04:18:38 INFO ResourceProfile: Limiting resource is cpus at 2 tasks per executor
	24/04/24 04:18:38 INFO ResourceProfileManager: Added ResourceProfile id: 0
	24/04/24 04:18:38 INFO SecurityManager: Changing view acls to: default
	24/04/24 04:18:38 INFO SecurityManager: Changing modify acls to: default
	24/04/24 04:18:38 INFO SecurityManager: Changing view acls groups to: 
	24/04/24 04:18:38 INFO SecurityManager: Changing modify acls groups to: 
	24/04/24 04:18:38 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: default; groups with view permissions: EMPTY; users with modify permissions: default; groups with modify permissions: EMPTY
[WI-0][TI-0] - [INFO] 2024-04-24 04:18:40.277 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8348169869613028 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:18:40.323 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 04:18:40 INFO Utils: Successfully started service 'sparkDriver' on port 41329.
[WI-0][TI-0] - [INFO] 2024-04-24 04:18:41.279 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9242424242424243 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:18:41.326 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 04:18:41 INFO SparkEnv: Registering MapOutputTracker
	24/04/24 04:18:41 INFO SparkEnv: Registering BlockManagerMaster
	24/04/24 04:18:41 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
	24/04/24 04:18:41 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
	24/04/24 04:18:41 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
[WI-0][TI-0] - [INFO] 2024-04-24 04:18:42.283 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9691876750700279 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:18:42.330 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 04:18:41 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-115f5e46-5534-46df-ade5-c78cd3fe19c0
	24/04/24 04:18:41 INFO MemoryStore: MemoryStore started with capacity 912.3 MiB
	24/04/24 04:18:41 INFO SparkEnv: Registering OutputCommitCoordinator
	24/04/24 04:18:42 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
[WI-0][TI-0] - [INFO] 2024-04-24 04:18:43.285 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9322033898305084 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:18:43.341 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 04:18:42 INFO Utils: Successfully started service 'SparkUI' on port 4040.
	24/04/24 04:18:42 INFO SparkContext: Added file file:///local_storage/reddit/processing/500-20240423.json at spark://5afbfd5249fc:41329/files/500-20240423.json with timestamp 1713903518010
	24/04/24 04:18:42 INFO Utils: Copying /local_storage/reddit/processing/500-20240423.json to /tmp/spark-f43e7caf-c736-48f9-8a29-324fecc0b24d/userFiles-0fb1bb22-22bc-415d-86df-8d4dce533323/500-20240423.json
[WI-0][TI-0] - [INFO] 2024-04-24 04:18:44.292 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8944281524926686 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:18:44.346 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 04:18:43 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
	24/04/24 04:18:43 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.4:7077 after 120 ms (0 ms spent in bootstraps)
	24/04/24 04:18:44 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20240423201844-0000
[WI-0][TI-0] - [INFO] 2024-04-24 04:18:45.322 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9510703363914373 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:18:45.350 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 04:18:44 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45513.
	24/04/24 04:18:44 INFO NettyBlockTransferService: Server created on 5afbfd5249fc:45513
	24/04/24 04:18:44 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
	24/04/24 04:18:44 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20240423201844-0000/0 on worker-20240423200818-172.18.0.6-42177 (172.18.0.6:42177) with 2 core(s)
	24/04/24 04:18:44 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 5afbfd5249fc, 45513, None)
	24/04/24 04:18:44 INFO StandaloneSchedulerBackend: Granted executor ID app-20240423201844-0000/0 on hostPort 172.18.0.6:42177 with 2 core(s), 2.0 GiB RAM
	24/04/24 04:18:44 INFO BlockManagerMasterEndpoint: Registering block manager 5afbfd5249fc:45513 with 912.3 MiB RAM, BlockManagerId(driver, 5afbfd5249fc, 45513, None)
	24/04/24 04:18:44 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 5afbfd5249fc, 45513, None)
	24/04/24 04:18:44 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 5afbfd5249fc, 45513, None)
[WI-0][TI-0] - [INFO] 2024-04-24 04:18:46.323 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9588607594936709 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:18:46.353 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 04:18:45 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20240423201844-0000/0 is now RUNNING
	24/04/24 04:18:46 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
[WI-0][TI-0] - [INFO] 2024-04-24 04:18:47.356 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9713375796178344 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:18:48.356 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 04:18:48 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
	24/04/24 04:18:48 INFO SharedState: Warehouse path is 'file:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/543/1281/spark-warehouse'.
[WI-0][TI-0] - [INFO] 2024-04-24 04:18:48.366 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9511825572801182 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:18:49.445 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9242153501534673 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:18:50.488 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9600000000000001 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:18:51.489 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8808664259927798 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:18:52.496 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9580645161290322 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:18:53.506 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9850746268656717 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:18:54.518 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9463087248322148 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:18:55.524 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9941176470588236 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:18:56.569 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9088397790055248 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:18:57.583 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9470198675496688 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:18:58.605 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9425981873111783 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:18:59.384 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 04:18:58 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.6:33232) with ID 0,  ResourceProfileId 0
	24/04/24 04:18:59 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.6:45165 with 1048.8 MiB RAM, BlockManagerId(0, 172.18.0.6, 45165, None)
[WI-0][TI-0] - [INFO] 2024-04-24 04:18:59.627 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8495297805642634 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:19:01.661 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7574123989218329 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:19:02.710 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.906060606060606 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:19:03.715 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9851190476190477 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:19:04.749 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.947945205479452 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:19:05.764 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9179521361010601 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:19:06.769 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9286699507389163 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:19:07.771 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9003115264797508 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:19:08.776 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.972972972972973 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:19:09.788 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.961864406779661 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:19:10.412 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 04:19:09 INFO CodeGenerator: Code generated in 1503.922971 ms
[WI-0][TI-0] - [INFO] 2024-04-24 04:19:10.791 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9435215946843855 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:19:11.417 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 04:19:10 INFO SparkContext: Starting job: json at NativeMethodAccessorImpl.java:0
	24/04/24 04:19:10 INFO DAGScheduler: Got job 0 (json at NativeMethodAccessorImpl.java:0) with 2 output partitions
	24/04/24 04:19:10 INFO DAGScheduler: Final stage: ResultStage 0 (json at NativeMethodAccessorImpl.java:0)
	24/04/24 04:19:10 INFO DAGScheduler: Parents of final stage: List()
	24/04/24 04:19:10 INFO DAGScheduler: Missing parents: List()
	24/04/24 04:19:10 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[6] at json at NativeMethodAccessorImpl.java:0), which has no missing parents
	24/04/24 04:19:11 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 20.9 KiB, free 912.3 MiB)
[WI-0][TI-0] - [INFO] 2024-04-24 04:19:11.796 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9093959731543624 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:19:12.420 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 04:19:11 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 10.2 KiB, free 912.3 MiB)
	24/04/24 04:19:11 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 5afbfd5249fc:45513 (size: 10.2 KiB, free: 912.3 MiB)
	24/04/24 04:19:11 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1585
	24/04/24 04:19:11 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (MapPartitionsRDD[6] at json at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
	24/04/24 04:19:11 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks resource profile 0
	24/04/24 04:19:11 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.6, executor 0, partition 0, PROCESS_LOCAL, 7776 bytes) 
	24/04/24 04:19:11 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1) (172.18.0.6, executor 0, partition 1, PROCESS_LOCAL, 8093 bytes) 
[WI-0][TI-0] - [INFO] 2024-04-24 04:19:12.823 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.752021563342318 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:19:13.824 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9202279202279201 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:19:14.828 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8866279069767441 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:19:15.829 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.884272997032641 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:19:16.833 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8035714285714286 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:19:17.835 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7881355932203389 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:19:18.838 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8096590909090909 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:19:19.840 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8186968838526912 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:19:23.863 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8238636363636364 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:19:24.889 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.846820809248555 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:19:25.894 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8571428571428571 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:19:26.895 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8658536585365854 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:19:27.897 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8221574344023324 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:19:28.904 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7256637168141593 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:19:29.907 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8628571428571429 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:23:09.580 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7236467236467237 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:23:10.602 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7534626038781164 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:23:11.606 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.775811209439528 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:23:12.609 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7589041095890412 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:23:13.610 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7008310249307479 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:23:15.628 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7441860465116279 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:23:16.674 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8638965980695049 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:23:17.677 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8401378579003183 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:23:18.681 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8477611940298507 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:23:19.697 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7202216066481993 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:23:20.698 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8347578347578347 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:23:22.715 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7590027700831025 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:23:23.732 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7000000000000001 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:23:24.735 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7514450867052023 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:23:25.738 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8507462686567164 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:23:26.740 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7099219213734533 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:23:27.742 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7671609212705103 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:23:30.768 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7924528301886792 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:23:31.798 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7432432432432433 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:23:35.828 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8292011019283747 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:23:39.911 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8602739726027396 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:23:40.937 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.793193717277487 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:23:49.981 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8710601719197708 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:24:36.187 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7039106145251397 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:24:37.232 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.772972972972973 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:24:38.234 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7590027700831024 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:24:39.866 +0800 o.a.d.s.w.r.o.TaskInstanceKillOperationFunction:[55] - Receive TaskInstanceKillRequest: TaskInstanceKillRequest(taskInstanceId=1281)
[WI-0][TI-1281] - [ERROR] 2024-04-24 04:24:39.880 +0800 o.a.d.s.w.r.o.TaskInstanceKillOperationFunction:[139] - kill task error
java.io.IOException: Cannot run program "pstree": error=2, No such file or directory
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1048)
	at org.apache.dolphinscheduler.common.shell.AbstractShell.runCommand(AbstractShell.java:138)
	at org.apache.dolphinscheduler.common.shell.AbstractShell.run(AbstractShell.java:118)
	at org.apache.dolphinscheduler.common.shell.ShellExecutor.execute(ShellExecutor.java:125)
	at org.apache.dolphinscheduler.common.shell.ShellExecutor.execCommand(ShellExecutor.java:103)
	at org.apache.dolphinscheduler.common.shell.ShellExecutor.execCommand(ShellExecutor.java:86)
	at org.apache.dolphinscheduler.common.utils.OSUtils.exeShell(OSUtils.java:345)
	at org.apache.dolphinscheduler.common.utils.OSUtils.exeCmd(OSUtils.java:334)
	at org.apache.dolphinscheduler.plugin.task.api.utils.ProcessUtils.getPidsStr(ProcessUtils.java:129)
	at org.apache.dolphinscheduler.server.worker.runner.operator.TaskInstanceKillOperationFunction.killProcess(TaskInstanceKillOperationFunction.java:130)
	at org.apache.dolphinscheduler.server.worker.runner.operator.TaskInstanceKillOperationFunction.doKill(TaskInstanceKillOperationFunction.java:96)
	at org.apache.dolphinscheduler.server.worker.runner.operator.TaskInstanceKillOperationFunction.operate(TaskInstanceKillOperationFunction.java:69)
	at org.apache.dolphinscheduler.server.worker.rpc.TaskInstanceOperatorImpl.killTask(TaskInstanceOperatorImpl.java:49)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.dolphinscheduler.extract.base.server.ServerMethodInvokerImpl.invoke(ServerMethodInvokerImpl.java:41)
	at org.apache.dolphinscheduler.extract.base.server.JdkDynamicServerHandler.lambda$processReceived$0(JdkDynamicServerHandler.java:108)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.io.IOException: error=2, No such file or directory
	at java.lang.UNIXProcess.forkAndExec(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:247)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	... 21 common frames omitted
[WI-0][TI-1281] - [INFO] 2024-04-24 04:24:39.882 +0800 o.a.d.p.t.a.u.ProcessUtils:[182] - Get appIds from worker 172.18.1.1:1234, taskLogPath: /opt/dolphinscheduler/logs/20240424/13201021801792/90/543/1281.log
[WI-0][TI-1281] - [INFO] 2024-04-24 04:24:39.884 +0800 o.a.d.p.t.a.u.LogUtils:[79] - Start finding appId in /opt/dolphinscheduler/logs/20240424/13201021801792/90/543/1281.log, fetch way: log 
[WI-0][TI-1281] - [INFO] 2024-04-24 04:24:39.897 +0800 o.a.d.p.t.a.u.ProcessUtils:[188] - The appId is empty
[WI-0][TI-1281] - [INFO] 2024-04-24 04:24:39.899 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[220] - Begin to kill process process, pid is : 300
[WI-0][TI-0] - [INFO] 2024-04-24 04:24:43.257 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7074163102633741 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-1281] - [INFO] 2024-04-24 04:24:44.909 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[225] - Success kill task: 543_1281, pid: 300
[WI-0][TI-1281] - [INFO] 2024-04-24 04:24:44.912 +0800 o.a.d.s.w.r.o.TaskInstanceKillOperationFunction:[119] - kill task by cancelApplication, taskInstanceId: 1281
[WI-0][TI-0] - [INFO] 2024-04-24 04:24:58.350 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7698863636363636 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:24:59.420 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9080779944289694 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:25:08.452 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7823529411764706 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:25:08.547 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1282, taskName=search for intake JSON files, firstSubmitTime=1713903908534, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.10:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=90, appIds=null, processInstanceId=544, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"in"}], executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":""}],"rawScript":"# find 1 raw file in the folder\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\n\n# check if raw_file_dir is empty, then set raw_file_dir to null\nif [ -z \"$raw_file_dir\" ]; then\n    raw_file_dir=null\nfi\n\necho \"#{setValue(raw_file_dir=${raw_file_dir})}\"","resourceList":[]}, environmentConfig=export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='search for intake JSON files'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240424'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1282'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13340113777664'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240424042508'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='in'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='544'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240423'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=null, dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-544][TI-1282] - [INFO] 2024-04-24 04:25:08.550 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: search for intake JSON files to wait queue success
[WI-544][TI-1282] - [INFO] 2024-04-24 04:25:08.550 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-544][TI-1282] - [INFO] 2024-04-24 04:25:08.552 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-544][TI-1282] - [INFO] 2024-04-24 04:25:08.554 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-544][TI-1282] - [INFO] 2024-04-24 04:25:08.555 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-544][TI-1282] - [INFO] 2024-04-24 04:25:08.556 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713903908556
[WI-544][TI-1282] - [INFO] 2024-04-24 04:25:08.557 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 544_1282
[WI-544][TI-1282] - [INFO] 2024-04-24 04:25:08.558 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1282,
  "taskName" : "search for intake JSON files",
  "firstSubmitTime" : 1713903908534,
  "startTime" : 1713903908556,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.10:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240424/13201021801792/90/544/1282.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 90,
  "processInstanceId" : 544,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"in\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[{\"prop\":\"raw_file_dir\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"\"}],\"rawScript\":\"# find 1 raw file in the folder\\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\\n\\n# check if raw_file_dir is empty, then set raw_file_dir to null\\nif [ -z \\\"$raw_file_dir\\\" ]; then\\n    raw_file_dir=null\\nfi\\n\\necho \\\"#{setValue(raw_file_dir=${raw_file_dir})}\\\"\",\"resourceList\":[]}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "search for intake JSON files"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240424"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1282"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13340113777664"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240424042508"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "in"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "544"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "544_1282",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-544][TI-1282] - [INFO] 2024-04-24 04:25:08.558 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-544][TI-1282] - [INFO] 2024-04-24 04:25:08.558 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-544][TI-1282] - [INFO] 2024-04-24 04:25:08.558 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-544][TI-1282] - [INFO] 2024-04-24 04:25:08.567 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-544][TI-1282] - [INFO] 2024-04-24 04:25:08.567 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-544][TI-1282] - [INFO] 2024-04-24 04:25:08.569 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/544/1282 check successfully
[WI-544][TI-1282] - [INFO] 2024-04-24 04:25:08.570 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-544][TI-1282] - [INFO] 2024-04-24 04:25:08.571 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-544][TI-1282] - [INFO] 2024-04-24 04:25:08.572 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-544][TI-1282] - [INFO] 2024-04-24 04:25:08.572 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-544][TI-1282] - [INFO] 2024-04-24 04:25:08.572 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ {
    "prop" : "raw_file_dir",
    "direct" : "OUT",
    "type" : "VARCHAR",
    "value" : ""
  } ],
  "varPool" : null,
  "rawScript" : "# find 1 raw file in the folder\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\n\n# check if raw_file_dir is empty, then set raw_file_dir to null\nif [ -z \"$raw_file_dir\" ]; then\n    raw_file_dir=null\nfi\n\necho \"#{setValue(raw_file_dir=${raw_file_dir})}\"",
  "resourceList" : [ ]
}
[WI-544][TI-1282] - [INFO] 2024-04-24 04:25:08.573 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-544][TI-1282] - [INFO] 2024-04-24 04:25:08.573 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: null successfully
[WI-544][TI-1282] - [INFO] 2024-04-24 04:25:08.573 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-544][TI-1282] - [INFO] 2024-04-24 04:25:08.574 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-544][TI-1282] - [INFO] 2024-04-24 04:25:08.579 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-544][TI-1282] - [INFO] 2024-04-24 04:25:08.581 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-544][TI-1282] - [INFO] 2024-04-24 04:25:08.595 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-544][TI-1282] - [INFO] 2024-04-24 04:25:08.595 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export PYTHON_LAUNCHER=/bin/python3.11
# find 1 raw file in the folder
raw_file_dir=$(find /local_storage/reddit/in -type f -name '*.json'| head -n 1)

# check if raw_file_dir is empty, then set raw_file_dir to null
if [ -z "$raw_file_dir" ]; then
    raw_file_dir=null
fi

echo "#{setValue(raw_file_dir=${raw_file_dir})}"
[WI-544][TI-1282] - [INFO] 2024-04-24 04:25:08.595 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-544][TI-1282] - [INFO] 2024-04-24 04:25:08.595 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/544/1282/544_1282.sh
[WI-544][TI-1282] - [INFO] 2024-04-24 04:25:08.631 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 503
[WI-0][TI-1282] - [INFO] 2024-04-24 04:25:09.163 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1282, success=true)
[WI-0][TI-1282] - [INFO] 2024-04-24 04:25:09.212 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1282)
[WI-0][TI-0] - [INFO] 2024-04-24 04:25:09.634 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
	#{setValue(raw_file_dir=null)}
[WI-544][TI-1282] - [INFO] 2024-04-24 04:25:09.637 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/544/1282, processId:503 ,exitStatusCode:0 ,processWaitForStatus:true ,processExitValue:0
[WI-544][TI-1282] - [INFO] 2024-04-24 04:25:09.639 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-544][TI-1282] - [INFO] 2024-04-24 04:25:09.639 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-544][TI-1282] - [INFO] 2024-04-24 04:25:09.647 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-544][TI-1282] - [INFO] 2024-04-24 04:25:09.649 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-544][TI-1282] - [INFO] 2024-04-24 04:25:09.681 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: SUCCESS to master : 172.18.1.1:1234
[WI-544][TI-1282] - [INFO] 2024-04-24 04:25:09.682 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-544][TI-1282] - [INFO] 2024-04-24 04:25:09.684 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/544/1282
[WI-544][TI-1282] - [INFO] 2024-04-24 04:25:09.685 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/544/1282
[WI-544][TI-1282] - [INFO] 2024-04-24 04:25:09.686 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-1282] - [INFO] 2024-04-24 04:25:10.157 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1282, success=true)
[WI-0][TI-0] - [INFO] 2024-04-24 04:25:11.292 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1284, taskName=end workflow, firstSubmitTime=1713903911282, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.10:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=90, appIds=null, processInstanceId=544, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"in"}], executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[],"rawScript":"echo No Files Detected - End Workflow","resourceList":[]}, environmentConfig=export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='end workflow'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240424'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1284'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13348985859488'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240424042511'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='in'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='544'}, raw_file_dir=Property{prop='raw_file_dir', direct=IN, type=VARCHAR, value='null'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240423'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"null"}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-544][TI-1284] - [INFO] 2024-04-24 04:25:11.295 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: end workflow to wait queue success
[WI-544][TI-1284] - [INFO] 2024-04-24 04:25:11.295 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-544][TI-1284] - [INFO] 2024-04-24 04:25:11.297 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-544][TI-1284] - [INFO] 2024-04-24 04:25:11.298 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-544][TI-1284] - [INFO] 2024-04-24 04:25:11.298 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-544][TI-1284] - [INFO] 2024-04-24 04:25:11.298 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713903911298
[WI-544][TI-1284] - [INFO] 2024-04-24 04:25:11.298 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 544_1284
[WI-544][TI-1284] - [INFO] 2024-04-24 04:25:11.298 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1284,
  "taskName" : "end workflow",
  "firstSubmitTime" : 1713903911282,
  "startTime" : 1713903911298,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.10:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240424/13201021801792/90/544/1284.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 90,
  "processInstanceId" : 544,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"in\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[],\"rawScript\":\"echo No Files Detected - End Workflow\",\"resourceList\":[]}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "end workflow"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240424"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1284"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13348985859488"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240424042511"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "in"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "544"
    },
    "raw_file_dir" : {
      "prop" : "raw_file_dir",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "null"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "544_1284",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"raw_file_dir\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"null\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-544][TI-1284] - [INFO] 2024-04-24 04:25:11.299 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-544][TI-1284] - [INFO] 2024-04-24 04:25:11.300 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-544][TI-1284] - [INFO] 2024-04-24 04:25:11.300 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-544][TI-1284] - [INFO] 2024-04-24 04:25:11.309 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-544][TI-1284] - [INFO] 2024-04-24 04:25:11.310 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-544][TI-1284] - [INFO] 2024-04-24 04:25:11.311 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/544/1284 check successfully
[WI-544][TI-1284] - [INFO] 2024-04-24 04:25:11.311 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-544][TI-1284] - [INFO] 2024-04-24 04:25:11.311 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-544][TI-1284] - [INFO] 2024-04-24 04:25:11.312 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-544][TI-1284] - [INFO] 2024-04-24 04:25:11.317 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-544][TI-1284] - [INFO] 2024-04-24 04:25:11.321 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ ],
  "varPool" : null,
  "rawScript" : "echo No Files Detected - End Workflow",
  "resourceList" : [ ]
}
[WI-544][TI-1284] - [INFO] 2024-04-24 04:25:11.321 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-544][TI-1284] - [INFO] 2024-04-24 04:25:11.322 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"null"}] successfully
[WI-544][TI-1284] - [INFO] 2024-04-24 04:25:11.322 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-544][TI-1284] - [INFO] 2024-04-24 04:25:11.323 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-544][TI-1284] - [INFO] 2024-04-24 04:25:11.324 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-544][TI-1284] - [INFO] 2024-04-24 04:25:11.325 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-544][TI-1284] - [INFO] 2024-04-24 04:25:11.325 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-544][TI-1284] - [INFO] 2024-04-24 04:25:11.325 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export PYTHON_LAUNCHER=/bin/python3.11
echo No Files Detected - End Workflow
[WI-544][TI-1284] - [INFO] 2024-04-24 04:25:11.326 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-544][TI-1284] - [INFO] 2024-04-24 04:25:11.327 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/544/1284/544_1284.sh
[WI-544][TI-1284] - [INFO] 2024-04-24 04:25:11.332 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 517
[WI-0][TI-1284] - [INFO] 2024-04-24 04:25:12.162 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1284, success=true)
[WI-0][TI-1284] - [INFO] 2024-04-24 04:25:12.171 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1284)
[WI-0][TI-0] - [INFO] 2024-04-24 04:25:12.335 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
	No Files Detected - End Workflow
[WI-544][TI-1284] - [INFO] 2024-04-24 04:25:12.338 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/544/1284, processId:517 ,exitStatusCode:0 ,processWaitForStatus:true ,processExitValue:0
[WI-544][TI-1284] - [INFO] 2024-04-24 04:25:12.339 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-544][TI-1284] - [INFO] 2024-04-24 04:25:12.339 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-544][TI-1284] - [INFO] 2024-04-24 04:25:12.340 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-544][TI-1284] - [INFO] 2024-04-24 04:25:12.341 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-544][TI-1284] - [INFO] 2024-04-24 04:25:12.344 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: SUCCESS to master : 172.18.1.1:1234
[WI-544][TI-1284] - [INFO] 2024-04-24 04:25:12.345 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-544][TI-1284] - [INFO] 2024-04-24 04:25:12.345 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/544/1284
[WI-544][TI-1284] - [INFO] 2024-04-24 04:25:12.346 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/544/1284
[WI-544][TI-1284] - [INFO] 2024-04-24 04:25:12.346 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-1284] - [INFO] 2024-04-24 04:25:13.164 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1284, success=true)
[WI-0][TI-0] - [INFO] 2024-04-24 04:25:13.613 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8136359622008302 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:25:14.660 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8319327731092436 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:25:19.685 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8157894736842105 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:25:20.699 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7661971830985916 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:25:34.763 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8683473389355743 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:25:35.786 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1285, taskName=search for intake JSON files, firstSubmitTime=1713903935723, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.10:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=90, appIds=null, processInstanceId=545, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"processing"}], executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":""}],"rawScript":"# find 1 raw file in the folder\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\n\n# check if raw_file_dir is empty, then set raw_file_dir to null\nif [ -z \"$raw_file_dir\" ]; then\n    raw_file_dir=null\nfi\n\necho \"#{setValue(raw_file_dir=${raw_file_dir})}\"","resourceList":[]}, environmentConfig=export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='search for intake JSON files'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240424'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1285'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13340113777664'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240424042535'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='processing'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='545'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240423'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=null, dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-545][TI-1285] - [INFO] 2024-04-24 04:25:35.788 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: search for intake JSON files to wait queue success
[WI-545][TI-1285] - [INFO] 2024-04-24 04:25:35.788 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-545][TI-1285] - [INFO] 2024-04-24 04:25:35.802 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-545][TI-1285] - [INFO] 2024-04-24 04:25:35.802 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-545][TI-1285] - [INFO] 2024-04-24 04:25:35.802 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-545][TI-1285] - [INFO] 2024-04-24 04:25:35.802 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713903935802
[WI-545][TI-1285] - [INFO] 2024-04-24 04:25:35.803 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 545_1285
[WI-545][TI-1285] - [INFO] 2024-04-24 04:25:35.803 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1285,
  "taskName" : "search for intake JSON files",
  "firstSubmitTime" : 1713903935723,
  "startTime" : 1713903935802,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.10:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240424/13201021801792/90/545/1285.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 90,
  "processInstanceId" : 545,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"processing\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[{\"prop\":\"raw_file_dir\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"\"}],\"rawScript\":\"# find 1 raw file in the folder\\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\\n\\n# check if raw_file_dir is empty, then set raw_file_dir to null\\nif [ -z \\\"$raw_file_dir\\\" ]; then\\n    raw_file_dir=null\\nfi\\n\\necho \\\"#{setValue(raw_file_dir=${raw_file_dir})}\\\"\",\"resourceList\":[]}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "search for intake JSON files"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240424"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1285"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13340113777664"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240424042535"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "processing"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "545"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "545_1285",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-545][TI-1285] - [INFO] 2024-04-24 04:25:35.810 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-545][TI-1285] - [INFO] 2024-04-24 04:25:35.810 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-545][TI-1285] - [INFO] 2024-04-24 04:25:35.810 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-545][TI-1285] - [INFO] 2024-04-24 04:25:35.824 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-545][TI-1285] - [INFO] 2024-04-24 04:25:35.828 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-545][TI-1285] - [INFO] 2024-04-24 04:25:35.829 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/545/1285 check successfully
[WI-545][TI-1285] - [INFO] 2024-04-24 04:25:35.829 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-545][TI-1285] - [INFO] 2024-04-24 04:25:35.829 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-545][TI-1285] - [INFO] 2024-04-24 04:25:35.830 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-545][TI-1285] - [INFO] 2024-04-24 04:25:35.830 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-545][TI-1285] - [INFO] 2024-04-24 04:25:35.831 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ {
    "prop" : "raw_file_dir",
    "direct" : "OUT",
    "type" : "VARCHAR",
    "value" : ""
  } ],
  "varPool" : null,
  "rawScript" : "# find 1 raw file in the folder\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\n\n# check if raw_file_dir is empty, then set raw_file_dir to null\nif [ -z \"$raw_file_dir\" ]; then\n    raw_file_dir=null\nfi\n\necho \"#{setValue(raw_file_dir=${raw_file_dir})}\"",
  "resourceList" : [ ]
}
[WI-545][TI-1285] - [INFO] 2024-04-24 04:25:35.831 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-545][TI-1285] - [INFO] 2024-04-24 04:25:35.831 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: null successfully
[WI-545][TI-1285] - [INFO] 2024-04-24 04:25:35.831 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-545][TI-1285] - [INFO] 2024-04-24 04:25:35.831 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-545][TI-1285] - [INFO] 2024-04-24 04:25:35.831 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-545][TI-1285] - [INFO] 2024-04-24 04:25:35.832 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-545][TI-1285] - [INFO] 2024-04-24 04:25:35.832 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-545][TI-1285] - [INFO] 2024-04-24 04:25:35.832 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export PYTHON_LAUNCHER=/bin/python3.11
# find 1 raw file in the folder
raw_file_dir=$(find /local_storage/reddit/processing -type f -name '*.json'| head -n 1)

# check if raw_file_dir is empty, then set raw_file_dir to null
if [ -z "$raw_file_dir" ]; then
    raw_file_dir=null
fi

echo "#{setValue(raw_file_dir=${raw_file_dir})}"
[WI-545][TI-1285] - [INFO] 2024-04-24 04:25:35.832 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-545][TI-1285] - [INFO] 2024-04-24 04:25:35.832 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/545/1285/545_1285.sh
[WI-545][TI-1285] - [INFO] 2024-04-24 04:25:35.843 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 532
[WI-0][TI-1285] - [INFO] 2024-04-24 04:25:36.206 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1285, success=true)
[WI-0][TI-1285] - [INFO] 2024-04-24 04:25:36.215 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1285)
[WI-0][TI-0] - [INFO] 2024-04-24 04:25:36.848 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
	#{setValue(raw_file_dir=/local_storage/reddit/processing/500-20240423.json)}
[WI-545][TI-1285] - [INFO] 2024-04-24 04:25:36.852 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/545/1285, processId:532 ,exitStatusCode:0 ,processWaitForStatus:true ,processExitValue:0
[WI-545][TI-1285] - [INFO] 2024-04-24 04:25:36.853 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-545][TI-1285] - [INFO] 2024-04-24 04:25:36.853 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-545][TI-1285] - [INFO] 2024-04-24 04:25:36.854 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-545][TI-1285] - [INFO] 2024-04-24 04:25:36.855 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-545][TI-1285] - [INFO] 2024-04-24 04:25:36.858 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: SUCCESS to master : 172.18.1.1:1234
[WI-545][TI-1285] - [INFO] 2024-04-24 04:25:36.859 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-545][TI-1285] - [INFO] 2024-04-24 04:25:36.859 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/545/1285
[WI-545][TI-1285] - [INFO] 2024-04-24 04:25:36.860 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/545/1285
[WI-545][TI-1285] - [INFO] 2024-04-24 04:25:36.860 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-1285] - [INFO] 2024-04-24 04:25:37.201 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1285, success=true)
[WI-0][TI-0] - [INFO] 2024-04-24 04:25:38.264 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1287, taskName=move to processing, firstSubmitTime=1713903938251, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.10:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=90, appIds=null, processInstanceId=545, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"processing"}], executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":""}],"rawScript":"# move file to the reddit processing folder\n# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error\nfilename=$(basename \"${raw_file_dir}\")\nif ! grep -q \"${REDDIT_HOME}/processing\" <<< \"${raw_file_dir}\"; then\n    mv ${raw_file_dir} ${REDDIT_HOME}/processing\nelse\n    echo JSON is already in processing\nfi\n\n# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing\necho \"#{setValue(raw_file_dir=${REDDIT_HOME}/processing/${filename})}\"","resourceList":[]}, environmentConfig=export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='move to processing'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240424'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1287'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13340390094208'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240424042538'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='processing'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='545'}, raw_file_dir=Property{prop='raw_file_dir', direct=IN, type=VARCHAR, value='/local_storage/reddit/processing/500-20240423.json'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240423'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-545][TI-1287] - [INFO] 2024-04-24 04:25:38.265 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: move to processing to wait queue success
[WI-545][TI-1287] - [INFO] 2024-04-24 04:25:38.269 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-545][TI-1287] - [INFO] 2024-04-24 04:25:38.270 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-545][TI-1287] - [INFO] 2024-04-24 04:25:38.270 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-545][TI-1287] - [INFO] 2024-04-24 04:25:38.270 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-545][TI-1287] - [INFO] 2024-04-24 04:25:38.270 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713903938270
[WI-545][TI-1287] - [INFO] 2024-04-24 04:25:38.270 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 545_1287
[WI-545][TI-1287] - [INFO] 2024-04-24 04:25:38.271 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1287,
  "taskName" : "move to processing",
  "firstSubmitTime" : 1713903938251,
  "startTime" : 1713903938270,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.10:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240424/13201021801792/90/545/1287.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 90,
  "processInstanceId" : 545,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"processing\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[{\"prop\":\"raw_file_dir\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"\"}],\"rawScript\":\"# move file to the reddit processing folder\\n# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error\\nfilename=$(basename \\\"${raw_file_dir}\\\")\\nif ! grep -q \\\"${REDDIT_HOME}/processing\\\" <<< \\\"${raw_file_dir}\\\"; then\\n    mv ${raw_file_dir} ${REDDIT_HOME}/processing\\nelse\\n    echo JSON is already in processing\\nfi\\n\\n# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing\\necho \\\"#{setValue(raw_file_dir=${REDDIT_HOME}/processing/${filename})}\\\"\",\"resourceList\":[]}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "move to processing"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240424"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1287"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13340390094208"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240424042538"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "processing"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "545"
    },
    "raw_file_dir" : {
      "prop" : "raw_file_dir",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit/processing/500-20240423.json"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "545_1287",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"raw_file_dir\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"/local_storage/reddit/processing/500-20240423.json\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-545][TI-1287] - [INFO] 2024-04-24 04:25:38.272 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-545][TI-1287] - [INFO] 2024-04-24 04:25:38.272 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-545][TI-1287] - [INFO] 2024-04-24 04:25:38.273 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-545][TI-1287] - [INFO] 2024-04-24 04:25:38.275 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-545][TI-1287] - [INFO] 2024-04-24 04:25:38.276 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-545][TI-1287] - [INFO] 2024-04-24 04:25:38.277 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/545/1287 check successfully
[WI-545][TI-1287] - [INFO] 2024-04-24 04:25:38.277 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-545][TI-1287] - [INFO] 2024-04-24 04:25:38.277 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-545][TI-1287] - [INFO] 2024-04-24 04:25:38.278 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-545][TI-1287] - [INFO] 2024-04-24 04:25:38.278 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-545][TI-1287] - [INFO] 2024-04-24 04:25:38.279 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ {
    "prop" : "raw_file_dir",
    "direct" : "OUT",
    "type" : "VARCHAR",
    "value" : ""
  } ],
  "varPool" : null,
  "rawScript" : "# move file to the reddit processing folder\n# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error\nfilename=$(basename \"${raw_file_dir}\")\nif ! grep -q \"${REDDIT_HOME}/processing\" <<< \"${raw_file_dir}\"; then\n    mv ${raw_file_dir} ${REDDIT_HOME}/processing\nelse\n    echo JSON is already in processing\nfi\n\n# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing\necho \"#{setValue(raw_file_dir=${REDDIT_HOME}/processing/${filename})}\"",
  "resourceList" : [ ]
}
[WI-545][TI-1287] - [INFO] 2024-04-24 04:25:38.279 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-545][TI-1287] - [INFO] 2024-04-24 04:25:38.279 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}] successfully
[WI-545][TI-1287] - [INFO] 2024-04-24 04:25:38.280 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-545][TI-1287] - [INFO] 2024-04-24 04:25:38.280 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-545][TI-1287] - [INFO] 2024-04-24 04:25:38.280 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-545][TI-1287] - [INFO] 2024-04-24 04:25:38.281 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-545][TI-1287] - [INFO] 2024-04-24 04:25:38.281 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-545][TI-1287] - [INFO] 2024-04-24 04:25:38.281 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export PYTHON_LAUNCHER=/bin/python3.11
# move file to the reddit processing folder
# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error
filename=$(basename "/local_storage/reddit/processing/500-20240423.json")
if ! grep -q "/local_storage/reddit/processing" <<< "/local_storage/reddit/processing/500-20240423.json"; then
    mv /local_storage/reddit/processing/500-20240423.json /local_storage/reddit/processing
else
    echo JSON is already in processing
fi

# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing
echo "#{setValue(raw_file_dir=/local_storage/reddit/processing/${filename})}"
[WI-545][TI-1287] - [INFO] 2024-04-24 04:25:38.281 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-545][TI-1287] - [INFO] 2024-04-24 04:25:38.282 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/545/1287/545_1287.sh
[WI-545][TI-1287] - [INFO] 2024-04-24 04:25:38.287 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 545
[WI-0][TI-1287] - [INFO] 2024-04-24 04:25:39.213 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1287, success=true)
[WI-0][TI-1287] - [INFO] 2024-04-24 04:25:39.219 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1287)
[WI-0][TI-0] - [INFO] 2024-04-24 04:25:39.288 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
	JSON is already in processing
	#{setValue(raw_file_dir=/local_storage/reddit/processing/500-20240423.json)}
[WI-545][TI-1287] - [INFO] 2024-04-24 04:25:39.296 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/545/1287, processId:545 ,exitStatusCode:0 ,processWaitForStatus:true ,processExitValue:0
[WI-545][TI-1287] - [INFO] 2024-04-24 04:25:39.297 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-545][TI-1287] - [INFO] 2024-04-24 04:25:39.297 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-545][TI-1287] - [INFO] 2024-04-24 04:25:39.297 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-545][TI-1287] - [INFO] 2024-04-24 04:25:39.297 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-545][TI-1287] - [INFO] 2024-04-24 04:25:39.301 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: SUCCESS to master : 172.18.1.1:1234
[WI-545][TI-1287] - [INFO] 2024-04-24 04:25:39.301 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-545][TI-1287] - [INFO] 2024-04-24 04:25:39.301 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/545/1287
[WI-545][TI-1287] - [INFO] 2024-04-24 04:25:39.302 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/545/1287
[WI-545][TI-1287] - [INFO] 2024-04-24 04:25:39.302 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-1287] - [INFO] 2024-04-24 04:25:40.207 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1287, success=true)
[WI-0][TI-0] - [INFO] 2024-04-24 04:25:40.288 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1288, taskName=spark preprocessing, firstSubmitTime=1713903940276, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.10:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=90, appIds=null, processInstanceId=545, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"processing"}], executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[],"rawScript":"$SPARK_HOME/bin/spark-submit \\\n    --master spark://spark-master:7077 \\\n    --deploy-mode client \\\n    --conf spark.driver.cores=2 \\\n    --conf spark.driver.memory=2G \\\n    --conf spark.executor.instances=1 \\\n    --conf spark.executor.cores=2 \\\n    --conf spark.executor.memory=2G \\\n    --files ${raw_file_dir} \\\n    --name reddit_preprocessing testing.py\n\n# $SPARK_HOME/bin/spark-submit \\\n#     --master local \\\n#     --files ${raw_file_dir} \\\n#     --name reddit_preprocessing spark_reddit_preprocessing.py\n","resourceList":[{"id":null,"resourceName":"file:/dolphinscheduler/default/resources/testing.py","res":null}]}, environmentConfig=export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export PYSPARK_DRIVER_PYTHON=/bin/python3.11
export PYTHON_LAUNCHER=/bin/python3.11
export PYSPARK_PYTHON=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='spark preprocessing'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240424'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1288'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13210058002752'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240424042540'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='processing'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='545'}, raw_file_dir=Property{prop='raw_file_dir', direct=IN, type=VARCHAR, value='/local_storage/reddit/processing/500-20240423.json'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240423'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-545][TI-1288] - [INFO] 2024-04-24 04:25:40.289 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: spark preprocessing to wait queue success
[WI-545][TI-1288] - [INFO] 2024-04-24 04:25:40.289 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-545][TI-1288] - [INFO] 2024-04-24 04:25:40.290 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-545][TI-1288] - [INFO] 2024-04-24 04:25:40.290 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-545][TI-1288] - [INFO] 2024-04-24 04:25:40.291 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-545][TI-1288] - [INFO] 2024-04-24 04:25:40.291 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713903940291
[WI-545][TI-1288] - [INFO] 2024-04-24 04:25:40.291 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 545_1288
[WI-545][TI-1288] - [INFO] 2024-04-24 04:25:40.291 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1288,
  "taskName" : "spark preprocessing",
  "firstSubmitTime" : 1713903940276,
  "startTime" : 1713903940291,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.10:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240424/13201021801792/90/545/1288.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 90,
  "processInstanceId" : 545,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"processing\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[],\"rawScript\":\"$SPARK_HOME/bin/spark-submit \\\\\\n    --master spark://spark-master:7077 \\\\\\n    --deploy-mode client \\\\\\n    --conf spark.driver.cores=2 \\\\\\n    --conf spark.driver.memory=2G \\\\\\n    --conf spark.executor.instances=1 \\\\\\n    --conf spark.executor.cores=2 \\\\\\n    --conf spark.executor.memory=2G \\\\\\n    --files ${raw_file_dir} \\\\\\n    --name reddit_preprocessing testing.py\\n\\n# $SPARK_HOME/bin/spark-submit \\\\\\n#     --master local \\\\\\n#     --files ${raw_file_dir} \\\\\\n#     --name reddit_preprocessing spark_reddit_preprocessing.py\\n\",\"resourceList\":[{\"id\":null,\"resourceName\":\"file:/dolphinscheduler/default/resources/testing.py\",\"res\":null}]}",
  "environmentConfig" : "export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3\nexport JAVA_HOME=/opt/java/openjdk\nexport PYSPARK_DRIVER_PYTHON=/bin/python3.11\nexport PYTHON_LAUNCHER=/bin/python3.11\nexport PYSPARK_PYTHON=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "spark preprocessing"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240424"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1288"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13210058002752"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240424042540"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "processing"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "545"
    },
    "raw_file_dir" : {
      "prop" : "raw_file_dir",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit/processing/500-20240423.json"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "545_1288",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"raw_file_dir\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"/local_storage/reddit/processing/500-20240423.json\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-545][TI-1288] - [INFO] 2024-04-24 04:25:40.292 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-545][TI-1288] - [INFO] 2024-04-24 04:25:40.292 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-545][TI-1288] - [INFO] 2024-04-24 04:25:40.292 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-545][TI-1288] - [INFO] 2024-04-24 04:25:40.294 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-545][TI-1288] - [INFO] 2024-04-24 04:25:40.295 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-545][TI-1288] - [INFO] 2024-04-24 04:25:40.296 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/545/1288 check successfully
[WI-545][TI-1288] - [INFO] 2024-04-24 04:25:40.296 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-545][TI-1288] - [INFO] 2024-04-24 04:25:40.297 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={file:/dolphinscheduler/default/resources/testing.py=ResourceContext.ResourceItem(resourceAbsolutePathInStorage=file:/dolphinscheduler/default/resources/testing.py, resourceRelativePath=testing.py, resourceAbsolutePathInLocal=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/545/1288/testing.py)})
[WI-545][TI-1288] - [INFO] 2024-04-24 04:25:40.298 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-545][TI-1288] - [INFO] 2024-04-24 04:25:40.298 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-545][TI-1288] - [INFO] 2024-04-24 04:25:40.298 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ ],
  "varPool" : null,
  "rawScript" : "$SPARK_HOME/bin/spark-submit \\\n    --master spark://spark-master:7077 \\\n    --deploy-mode client \\\n    --conf spark.driver.cores=2 \\\n    --conf spark.driver.memory=2G \\\n    --conf spark.executor.instances=1 \\\n    --conf spark.executor.cores=2 \\\n    --conf spark.executor.memory=2G \\\n    --files ${raw_file_dir} \\\n    --name reddit_preprocessing testing.py\n\n# $SPARK_HOME/bin/spark-submit \\\n#     --master local \\\n#     --files ${raw_file_dir} \\\n#     --name reddit_preprocessing spark_reddit_preprocessing.py\n",
  "resourceList" : [ {
    "id" : null,
    "resourceName" : "file:/dolphinscheduler/default/resources/testing.py",
    "res" : null
  } ]
}
[WI-545][TI-1288] - [INFO] 2024-04-24 04:25:40.298 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-545][TI-1288] - [INFO] 2024-04-24 04:25:40.298 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}] successfully
[WI-545][TI-1288] - [INFO] 2024-04-24 04:25:40.298 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-545][TI-1288] - [INFO] 2024-04-24 04:25:40.298 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-545][TI-1288] - [INFO] 2024-04-24 04:25:40.298 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-545][TI-1288] - [INFO] 2024-04-24 04:25:40.299 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-545][TI-1288] - [INFO] 2024-04-24 04:25:40.299 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-545][TI-1288] - [INFO] 2024-04-24 04:25:40.300 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export PYSPARK_DRIVER_PYTHON=/bin/python3.11
export PYTHON_LAUNCHER=/bin/python3.11
export PYSPARK_PYTHON=/bin/python3.11
$SPARK_HOME/bin/spark-submit \
    --master spark://spark-master:7077 \
    --deploy-mode client \
    --conf spark.driver.cores=2 \
    --conf spark.driver.memory=2G \
    --conf spark.executor.instances=1 \
    --conf spark.executor.cores=2 \
    --conf spark.executor.memory=2G \
    --files /local_storage/reddit/processing/500-20240423.json \
    --name reddit_preprocessing testing.py

# $SPARK_HOME/bin/spark-submit \
#     --master local \
#     --files /local_storage/reddit/processing/500-20240423.json \
#     --name reddit_preprocessing spark_reddit_preprocessing.py

[WI-545][TI-1288] - [INFO] 2024-04-24 04:25:40.300 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-545][TI-1288] - [INFO] 2024-04-24 04:25:40.300 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/545/1288/545_1288.sh
[WI-545][TI-1288] - [INFO] 2024-04-24 04:25:40.311 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 557
[WI-0][TI-1288] - [INFO] 2024-04-24 04:25:41.213 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1288, success=true)
[WI-0][TI-1288] - [INFO] 2024-04-24 04:25:41.224 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1288)
[WI-0][TI-0] - [INFO] 2024-04-24 04:25:41.313 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
[WI-0][TI-0] - [INFO] 2024-04-24 04:25:42.319 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 04:25:42 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[WI-0][TI-0] - [INFO] 2024-04-24 04:25:43.330 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 04:25:42 INFO SparkContext: Running Spark version 3.5.1
	24/04/24 04:25:42 INFO SparkContext: OS info Linux, 6.5.0-28-generic, amd64
	24/04/24 04:25:42 INFO SparkContext: Java version 1.8.0_402
	24/04/24 04:25:42 INFO ResourceUtils: ==============================================================
	24/04/24 04:25:42 INFO ResourceUtils: No custom resources configured for spark.driver.
	24/04/24 04:25:42 INFO ResourceUtils: ==============================================================
	24/04/24 04:25:42 INFO SparkContext: Submitted application: reddit_preprocessing
	24/04/24 04:25:42 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 2, script: , vendor: , memory -> name: memory, amount: 2048, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
	24/04/24 04:25:42 INFO ResourceProfile: Limiting resource is cpus at 2 tasks per executor
	24/04/24 04:25:42 INFO ResourceProfileManager: Added ResourceProfile id: 0
	24/04/24 04:25:42 INFO SecurityManager: Changing view acls to: default
	24/04/24 04:25:42 INFO SecurityManager: Changing modify acls to: default
	24/04/24 04:25:42 INFO SecurityManager: Changing view acls groups to: 
	24/04/24 04:25:42 INFO SecurityManager: Changing modify acls groups to: 
	24/04/24 04:25:42 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: default; groups with view permissions: EMPTY; users with modify permissions: default; groups with modify permissions: EMPTY
[WI-0][TI-0] - [INFO] 2024-04-24 04:25:43.827 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7953020134228188 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:25:44.340 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 04:25:43 INFO Utils: Successfully started service 'sparkDriver' on port 45547.
	24/04/24 04:25:43 INFO SparkEnv: Registering MapOutputTracker
	24/04/24 04:25:43 INFO SparkEnv: Registering BlockManagerMaster
	24/04/24 04:25:43 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
	24/04/24 04:25:43 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
	24/04/24 04:25:43 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
	24/04/24 04:25:43 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-a6a534ba-b45a-4c0d-8814-cadcf8ce265d
	24/04/24 04:25:43 INFO MemoryStore: MemoryStore started with capacity 912.3 MiB
	24/04/24 04:25:43 INFO SparkEnv: Registering OutputCommitCoordinator
	24/04/24 04:25:44 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
	24/04/24 04:25:44 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
	24/04/24 04:25:44 INFO Utils: Successfully started service 'SparkUI' on port 4041.
	24/04/24 04:25:44 INFO SparkContext: Added file file:///local_storage/reddit/processing/500-20240423.json at spark://5afbfd5249fc:45547/files/500-20240423.json with timestamp 1713903942770
	24/04/24 04:25:44 INFO Utils: Copying /local_storage/reddit/processing/500-20240423.json to /tmp/spark-69eb39d3-ed10-448e-8d75-fffe9b1d016f/userFiles-e70866dd-c5bd-4563-b51a-f573deb69d80/500-20240423.json
[WI-0][TI-0] - [INFO] 2024-04-24 04:25:44.851 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7756410256410255 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:25:45.343 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 04:25:44 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
	24/04/24 04:25:44 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.4:7077 after 66 ms (0 ms spent in bootstraps)
	24/04/24 04:25:45 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20240423202545-0001
	24/04/24 04:25:45 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33753.
	24/04/24 04:25:45 INFO NettyBlockTransferService: Server created on 5afbfd5249fc:33753
	24/04/24 04:25:45 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
	24/04/24 04:25:45 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 5afbfd5249fc, 33753, None)
[WI-0][TI-0] - [INFO] 2024-04-24 04:25:45.857 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9323529411764706 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:25:46.350 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 04:25:45 INFO BlockManagerMasterEndpoint: Registering block manager 5afbfd5249fc:33753 with 912.3 MiB RAM, BlockManagerId(driver, 5afbfd5249fc, 33753, None)
	24/04/24 04:25:45 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 5afbfd5249fc, 33753, None)
	24/04/24 04:25:45 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 5afbfd5249fc, 33753, None)
[WI-0][TI-0] - [INFO] 2024-04-24 04:25:46.868 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8863636363636362 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:25:47.362 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 04:25:46 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
	
	[
	    {"name": "t3_abc123", "author": "user1", "body": "Sample comment 1", "permalink": "/r/subreddit1/post/abc123", "unix_time": 1619520000},
	    {"name": "t1_def456", "author": "user2", "body": "Sample comment 2", "permalink": "/r/subreddit2/post/def456", "unix_time": 1619521000}
	]
	
	24/04/24 04:25:47 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
	24/04/24 04:25:47 INFO SharedState: Warehouse path is 'file:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/545/1288/spark-warehouse'.
[WI-0][TI-0] - [INFO] 2024-04-24 04:25:47.882 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8494208494208495 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:25:48.901 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8844444444444445 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:25:50.977 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8615916955017301 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:25:55.038 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8833819241982507 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:25:57.444 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 04:25:57 INFO CodeGenerator: Code generated in 520.254391 ms
	24/04/24 04:25:57 INFO SparkContext: Starting job: json at NativeMethodAccessorImpl.java:0
	24/04/24 04:25:57 INFO DAGScheduler: Got job 0 (json at NativeMethodAccessorImpl.java:0) with 2 output partitions
	24/04/24 04:25:57 INFO DAGScheduler: Final stage: ResultStage 0 (json at NativeMethodAccessorImpl.java:0)
	24/04/24 04:25:57 INFO DAGScheduler: Parents of final stage: List()
	24/04/24 04:25:57 INFO DAGScheduler: Missing parents: List()
	24/04/24 04:25:57 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[6] at json at NativeMethodAccessorImpl.java:0), which has no missing parents
[WI-0][TI-0] - [INFO] 2024-04-24 04:25:58.452 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 04:25:57 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 20.9 KiB, free 912.3 MiB)
	24/04/24 04:25:57 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 10.2 KiB, free 912.3 MiB)
	24/04/24 04:25:57 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 5afbfd5249fc:33753 (size: 10.2 KiB, free: 912.3 MiB)
	24/04/24 04:25:57 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1585
	24/04/24 04:25:57 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (MapPartitionsRDD[6] at json at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
	24/04/24 04:25:57 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks resource profile 0
[WI-0][TI-0] - [INFO] 2024-04-24 04:26:13.474 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 04:26:12 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
[WI-0][TI-0] - [INFO] 2024-04-24 04:26:28.497 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 04:26:27 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
[WI-0][TI-0] - [INFO] 2024-04-24 04:26:43.517 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 04:26:42 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
[WI-0][TI-0] - [INFO] 2024-04-24 04:26:58.532 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 04:26:57 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
[WI-0][TI-0] - [INFO] 2024-04-24 04:27:13.555 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 04:27:12 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
[WI-0][TI-0] - [INFO] 2024-04-24 04:27:28.564 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 04:27:27 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
[WI-0][TI-0] - [INFO] 2024-04-24 04:27:43.577 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 04:27:42 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
[WI-0][TI-0] - [INFO] 2024-04-24 04:27:58.599 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 04:27:57 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
[WI-0][TI-0] - [ERROR] 2024-04-24 04:28:04.339 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[279] - Parse var pool error
java.io.IOException: Stream closed
	at java.io.BufferedInputStream.getBufIfOpen(BufferedInputStream.java:170)
	at java.io.BufferedInputStream.read1(BufferedInputStream.java:283)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:345)
	at sun.nio.cs.StreamDecoder.readBytes(StreamDecoder.java:284)
	at sun.nio.cs.StreamDecoder.implRead(StreamDecoder.java:326)
	at sun.nio.cs.StreamDecoder.read(StreamDecoder.java:178)
	at java.io.InputStreamReader.read(InputStreamReader.java:184)
	at java.io.BufferedReader.fill(BufferedReader.java:161)
	at java.io.BufferedReader.readLine(BufferedReader.java:324)
	at java.io.BufferedReader.readLine(BufferedReader.java:389)
	at org.apache.dolphinscheduler.plugin.task.api.AbstractCommandExecutor.lambda$parseProcessOutput$1(AbstractCommandExecutor.java:273)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
[WI-543][TI-1281] - [INFO] 2024-04-24 04:28:04.493 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has killed. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/543/1281, processId:300 ,exitStatusCode:137 ,processWaitForStatus:true ,processExitValue:137
[WI-543][TI-1281] - [INFO] 2024-04-24 04:28:04.494 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-543][TI-1281] - [INFO] 2024-04-24 04:28:04.494 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-543][TI-1281] - [INFO] 2024-04-24 04:28:04.494 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-543][TI-1281] - [INFO] 2024-04-24 04:28:04.578 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-0][TI-0] - [INFO] 2024-04-24 04:28:04.611 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 04:28:04 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20240423202545-0001/0 on worker-20240423200818-172.18.0.6-42177 (172.18.0.6:42177) with 2 core(s)
	24/04/24 04:28:04 INFO StandaloneSchedulerBackend: Granted executor ID app-20240423202545-0001/0 on hostPort 172.18.0.6:42177 with 2 core(s), 2.0 GiB RAM
	24/04/24 04:28:04 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20240423202545-0001/0 is now RUNNING
[WI-543][TI-1281] - [INFO] 2024-04-24 04:28:04.612 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: KILL to master : 172.18.1.1:1234
[WI-543][TI-1281] - [INFO] 2024-04-24 04:28:04.616 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-543][TI-1281] - [INFO] 2024-04-24 04:28:04.616 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/543/1281
[WI-543][TI-1281] - [INFO] 2024-04-24 04:28:04.617 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/543/1281
[WI-543][TI-1281] - [INFO] 2024-04-24 04:28:04.617 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-0] - [INFO] 2024-04-24 04:28:05.583 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9673366834170853 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:28:07.632 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.765273311897106 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:28:09.694 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7983425414364641 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:28:10.621 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 04:28:09 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.6:35438) with ID 0,  ResourceProfileId 0
	24/04/24 04:28:09 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.6:38539 with 1048.8 MiB RAM, BlockManagerId(0, 172.18.0.6, 38539, None)
	24/04/24 04:28:10 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.6, executor 0, partition 0, PROCESS_LOCAL, 7776 bytes) 
	24/04/24 04:28:10 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1) (172.18.0.6, executor 0, partition 1, PROCESS_LOCAL, 8093 bytes) 
[WI-0][TI-0] - [INFO] 2024-04-24 04:28:59.319 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8097826086956521 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-1281] - [INFO] 2024-04-24 04:29:08.104 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1281, processInstanceId=543, status=9, startTime=1713903509183, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, logPath=/opt/dolphinscheduler/logs/20240424/13201021801792/90/543/1281.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/543/1281, endTime=1713904084494, processId=300, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1281] - [INFO] 2024-04-24 04:29:08.110 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1281, processInstanceId=543, status=9, startTime=1713903509183, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, logPath=/opt/dolphinscheduler/logs/20240424/13201021801792/90/543/1281.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/543/1281, endTime=1713904084494, processId=300, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], eventCreateTime=0, eventSendTime=1713904148104)
[WI-0][TI-0] - [INFO] 2024-04-24 04:34:04.907 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 04:34:04 ERROR StandaloneSchedulerBackend: Application has been killed. Reason: Master removed our application: KILLED
	24/04/24 04:34:04 INFO TaskSchedulerImpl: Cancelling stage 0
	24/04/24 04:34:04 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage cancelled: Job aborted due to stage failure: Master removed our application: KILLED
	24/04/24 04:34:04 INFO TaskSchedulerImpl: Stage 0 was cancelled
	24/04/24 04:34:04 INFO DAGScheduler: ResultStage 0 (json at NativeMethodAccessorImpl.java:0) failed in 487.296 s due to Job aborted due to stage failure: Master removed our application: KILLED
	24/04/24 04:34:04 INFO SparkContext: SparkContext is stopping with exitCode 0.
	24/04/24 04:34:04 INFO DAGScheduler: Job 0 failed: json at NativeMethodAccessorImpl.java:0, took 487.528189 s
	24/04/24 04:34:04 INFO SparkUI: Stopped Spark web UI at http://5afbfd5249fc:4041
[WI-0][TI-0] - [INFO] 2024-04-24 04:34:05.706 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8586666666666666 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:34:05.910 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 04:34:04 INFO StandaloneSchedulerBackend: Shutting down all executors
	24/04/24 04:34:04 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Asking each executor to shut down
	24/04/24 04:34:04 ERROR Utils: Uncaught exception in thread stop-spark-context
	org.apache.spark.SparkException: Exception thrown in awaitResult: 
		at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
		at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
		at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
		at org.apache.spark.deploy.client.StandaloneAppClient.stop(StandaloneAppClient.scala:288)
		at org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend.org$apache$spark$scheduler$cluster$StandaloneSchedulerBackend$$stop(StandaloneSchedulerBackend.scala:275)
		at org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend.stop(StandaloneSchedulerBackend.scala:142)
		at org.apache.spark.scheduler.SchedulerBackend.stop(SchedulerBackend.scala:33)
		at org.apache.spark.scheduler.SchedulerBackend.stop$(SchedulerBackend.scala:33)
		at org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend.stop(CoarseGrainedSchedulerBackend.scala:54)
		at org.apache.spark.scheduler.TaskSchedulerImpl.$anonfun$stop$2(TaskSchedulerImpl.scala:992)
		at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1375)
		at org.apache.spark.scheduler.TaskSchedulerImpl.stop(TaskSchedulerImpl.scala:992)
		at org.apache.spark.scheduler.DAGScheduler.$anonfun$stop$4(DAGScheduler.scala:2976)
		at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1375)
		at org.apache.spark.scheduler.DAGScheduler.stop(DAGScheduler.scala:2976)
		at org.apache.spark.SparkContext.$anonfun$stop$12(SparkContext.scala:2263)
		at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1375)
		at org.apache.spark.SparkContext.stop(SparkContext.scala:2263)
		at org.apache.spark.SparkContext.stop(SparkContext.scala:2216)
		at org.apache.spark.SparkContext$$anon$3.run(SparkContext.scala:2203)
	Caused by: org.apache.spark.SparkException: Could not find AppClient.
		at org.apache.spark.rpc.netty.Dispatcher.postMessage(Dispatcher.scala:178)
		at org.apache.spark.rpc.netty.Dispatcher.postLocalMessage(Dispatcher.scala:144)
		at org.apache.spark.rpc.netty.NettyRpcEnv.askAbortable(NettyRpcEnv.scala:242)
		at org.apache.spark.rpc.netty.NettyRpcEndpointRef.askAbortable(NettyRpcEnv.scala:554)
		at org.apache.spark.rpc.netty.NettyRpcEndpointRef.ask(NettyRpcEnv.scala:558)
		at org.apache.spark.rpc.RpcEndpointRef.ask(RpcEndpointRef.scala:72)
		... 17 more
	24/04/24 04:34:05 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
	Traceback (most recent call last):
	  File "/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/545/1288/testing.py", line 38, in <module>
	    raw_df = spark.read.json(spark.sparkContext.parallelize([example_json]))
	             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
	  File "/opt/spark-3.5.1-bin-hadoop3/python/lib/pyspark.zip/pyspark/sql/readwriter.py", line 440, in json
	  File "/opt/spark-3.5.1-bin-hadoop3/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
	  File "/opt/spark-3.5.1-bin-hadoop3/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 179, in deco
	  File "/opt/spark-3.5.1-bin-hadoop3/python/lib/py4j-0.10.9.7-src.zip/py4j/protocol.py", line 326, in get_return_value
	py4j.protocol.Py4JJavaError: An error occurred while calling o32.json.
	: org.apache.spark.SparkException: Job aborted due to stage failure: Master removed our application: KILLED
		at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)
		at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)
		at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)
		at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
		at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
		at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
		at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)
		at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)
		at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)
		at scala.Option.foreach(Option.scala:407)
		at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)
		at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)
		at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)
		at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)
		at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
		at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:989)
		at org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)
		at org.apache.spark.SparkContext.runJob(SparkContext.scala:2493)
		at org.apache.spark.sql.catalyst.json.JsonInferSchema.infer(JsonInferSchema.scala:120)
		at org.apache.spark.sql.execution.datasources.json.TextInputJsonDataSource$.$anonfun$inferFromDataset$5(JsonDataSource.scala:109)
		at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)
		at org.apache.spark.sql.execution.datasources.json.TextInputJsonDataSource$.inferFromDataset(JsonDataSource.scala:109)
		at org.apache.spark.sql.DataFrameReader.$anonfun$json$4(DataFrameReader.scala:416)
		at scala.Option.getOrElse(Option.scala:189)
		at org.apache.spark.sql.DataFrameReader.json(DataFrameReader.scala:416)
		at org.apache.spark.sql.DataFrameReader.json(DataFrameReader.scala:391)
		at org.apache.spark.sql.DataFrameReader.json(DataFrameReader.scala:377)
		at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
		at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
		at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
		at java.lang.reflect.Method.invoke(Method.java:498)
		at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
		at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
		at py4j.Gateway.invoke(Gateway.java:282)
		at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
		at py4j.commands.CallCommand.execute(CallCommand.java:79)
		at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
		at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
		at java.lang.Thread.run(Thread.java:750)
	
	24/04/24 04:34:05 INFO MemoryStore: MemoryStore cleared
	24/04/24 04:34:05 INFO BlockManager: BlockManager stopped
	24/04/24 04:34:05 INFO BlockManagerMaster: BlockManagerMaster stopped
	24/04/24 04:34:05 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
	24/04/24 04:34:05 INFO ShutdownHookManager: Shutdown hook called
	24/04/24 04:34:05 INFO ShutdownHookManager: Deleting directory /tmp/spark-d0080942-4ce6-4569-9d22-9f2c3d59cd0f
	24/04/24 04:34:05 INFO SparkContext: Successfully stopped SparkContext
	24/04/24 04:34:05 INFO ShutdownHookManager: Deleting directory /tmp/spark-69eb39d3-ed10-448e-8d75-fffe9b1d016f/pyspark-72d19037-8908-41f3-87bd-fa8f35df187e
	24/04/24 04:34:05 INFO ShutdownHookManager: Deleting directory /tmp/spark-69eb39d3-ed10-448e-8d75-fffe9b1d016f/userFiles-e70866dd-c5bd-4563-b51a-f573deb69d80
	24/04/24 04:34:05 INFO ShutdownHookManager: Deleting directory /tmp/spark-69eb39d3-ed10-448e-8d75-fffe9b1d016f
[WI-545][TI-1288] - [INFO] 2024-04-24 04:34:05.912 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/545/1288, processId:557 ,exitStatusCode:1 ,processWaitForStatus:true ,processExitValue:1
[WI-545][TI-1288] - [INFO] 2024-04-24 04:34:05.914 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-545][TI-1288] - [INFO] 2024-04-24 04:34:05.915 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-545][TI-1288] - [INFO] 2024-04-24 04:34:05.915 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-545][TI-1288] - [INFO] 2024-04-24 04:34:05.917 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-545][TI-1288] - [INFO] 2024-04-24 04:34:05.934 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: FAILURE to master : 172.18.1.1:1234
[WI-545][TI-1288] - [INFO] 2024-04-24 04:34:05.934 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-545][TI-1288] - [INFO] 2024-04-24 04:34:05.935 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/545/1288
[WI-545][TI-1288] - [INFO] 2024-04-24 04:34:05.936 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/545/1288
[WI-545][TI-1288] - [INFO] 2024-04-24 04:34:05.937 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-1288] - [INFO] 2024-04-24 04:34:06.502 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1288, processInstanceId=545, status=6, startTime=1713903940291, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, logPath=/opt/dolphinscheduler/logs/20240424/13201021801792/90/545/1288.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/545/1288, endTime=1713904445917, processId=557, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1288] - [INFO] 2024-04-24 04:34:06.507 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1288, processInstanceId=545, status=6, startTime=1713903940291, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, logPath=/opt/dolphinscheduler/logs/20240424/13201021801792/90/545/1288.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/545/1288, endTime=1713904445917, processId=557, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], eventCreateTime=0, eventSendTime=1713904446501)
[WI-0][TI-1288] - [INFO] 2024-04-24 04:34:06.597 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1288, success=true)
[WI-0][TI-1288] - [INFO] 2024-04-24 04:34:06.602 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1288, success=true)
[WI-0][TI-0] - [INFO] 2024-04-24 04:34:06.721 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.747093023255814 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:34:07.723 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.783625730994152 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-1281] - [INFO] 2024-04-24 04:34:08.510 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1281, processInstanceId=543, status=9, startTime=1713903509183, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, logPath=/opt/dolphinscheduler/logs/20240424/13201021801792/90/543/1281.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/543/1281, endTime=1713904084494, processId=300, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], eventCreateTime=0, eventSendTime=1713904148104)
[WI-0][TI-1281] - [INFO] 2024-04-24 04:34:08.520 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1281, processInstanceId=543, status=9, startTime=1713903509183, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, logPath=/opt/dolphinscheduler/logs/20240424/13201021801792/90/543/1281.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/543/1281, endTime=1713904084494, processId=300, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], eventCreateTime=0, eventSendTime=1713904448510)
[WI-0][TI-0] - [INFO] 2024-04-24 04:34:16.835 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1289, taskName=search for intake JSON files, firstSubmitTime=1713904456821, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.10:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=90, appIds=null, processInstanceId=546, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"processing"}], executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":""}],"rawScript":"# find 1 raw file in the folder\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\n\n# check if raw_file_dir is empty, then set raw_file_dir to null\nif [ -z \"$raw_file_dir\" ]; then\n    raw_file_dir=null\nfi\n\necho \"#{setValue(raw_file_dir=${raw_file_dir})}\"","resourceList":[]}, environmentConfig=export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='search for intake JSON files'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240424'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1289'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13340113777664'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240424043416'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='processing'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='546'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240423'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=null, dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-546][TI-1289] - [INFO] 2024-04-24 04:34:16.838 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: search for intake JSON files to wait queue success
[WI-546][TI-1289] - [INFO] 2024-04-24 04:34:16.838 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-546][TI-1289] - [INFO] 2024-04-24 04:34:16.851 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-546][TI-1289] - [INFO] 2024-04-24 04:34:16.851 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-546][TI-1289] - [INFO] 2024-04-24 04:34:16.851 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-546][TI-1289] - [INFO] 2024-04-24 04:34:16.852 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713904456852
[WI-546][TI-1289] - [INFO] 2024-04-24 04:34:16.852 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 546_1289
[WI-546][TI-1289] - [INFO] 2024-04-24 04:34:16.852 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1289,
  "taskName" : "search for intake JSON files",
  "firstSubmitTime" : 1713904456821,
  "startTime" : 1713904456852,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.10:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240424/13201021801792/90/546/1289.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 90,
  "processInstanceId" : 546,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"processing\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[{\"prop\":\"raw_file_dir\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"\"}],\"rawScript\":\"# find 1 raw file in the folder\\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\\n\\n# check if raw_file_dir is empty, then set raw_file_dir to null\\nif [ -z \\\"$raw_file_dir\\\" ]; then\\n    raw_file_dir=null\\nfi\\n\\necho \\\"#{setValue(raw_file_dir=${raw_file_dir})}\\\"\",\"resourceList\":[]}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "search for intake JSON files"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240424"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1289"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13340113777664"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240424043416"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "processing"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "546"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "546_1289",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-546][TI-1289] - [INFO] 2024-04-24 04:34:16.873 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-546][TI-1289] - [INFO] 2024-04-24 04:34:16.874 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-546][TI-1289] - [INFO] 2024-04-24 04:34:16.874 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-546][TI-1289] - [INFO] 2024-04-24 04:34:16.916 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-546][TI-1289] - [INFO] 2024-04-24 04:34:16.921 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-546][TI-1289] - [INFO] 2024-04-24 04:34:16.922 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/546/1289 check successfully
[WI-546][TI-1289] - [INFO] 2024-04-24 04:34:16.923 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-546][TI-1289] - [INFO] 2024-04-24 04:34:16.923 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-546][TI-1289] - [INFO] 2024-04-24 04:34:16.923 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-546][TI-1289] - [INFO] 2024-04-24 04:34:16.924 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-546][TI-1289] - [INFO] 2024-04-24 04:34:16.926 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ {
    "prop" : "raw_file_dir",
    "direct" : "OUT",
    "type" : "VARCHAR",
    "value" : ""
  } ],
  "varPool" : null,
  "rawScript" : "# find 1 raw file in the folder\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\n\n# check if raw_file_dir is empty, then set raw_file_dir to null\nif [ -z \"$raw_file_dir\" ]; then\n    raw_file_dir=null\nfi\n\necho \"#{setValue(raw_file_dir=${raw_file_dir})}\"",
  "resourceList" : [ ]
}
[WI-546][TI-1289] - [INFO] 2024-04-24 04:34:16.926 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-546][TI-1289] - [INFO] 2024-04-24 04:34:16.926 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: null successfully
[WI-546][TI-1289] - [INFO] 2024-04-24 04:34:16.927 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-546][TI-1289] - [INFO] 2024-04-24 04:34:16.927 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-546][TI-1289] - [INFO] 2024-04-24 04:34:16.927 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-546][TI-1289] - [INFO] 2024-04-24 04:34:16.928 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-546][TI-1289] - [INFO] 2024-04-24 04:34:16.928 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-546][TI-1289] - [INFO] 2024-04-24 04:34:16.928 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export PYTHON_LAUNCHER=/bin/python3.11
# find 1 raw file in the folder
raw_file_dir=$(find /local_storage/reddit/processing -type f -name '*.json'| head -n 1)

# check if raw_file_dir is empty, then set raw_file_dir to null
if [ -z "$raw_file_dir" ]; then
    raw_file_dir=null
fi

echo "#{setValue(raw_file_dir=${raw_file_dir})}"
[WI-546][TI-1289] - [INFO] 2024-04-24 04:34:16.928 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-546][TI-1289] - [INFO] 2024-04-24 04:34:16.928 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/546/1289/546_1289.sh
[WI-546][TI-1289] - [INFO] 2024-04-24 04:34:16.934 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 816
[WI-0][TI-1289] - [INFO] 2024-04-24 04:34:17.536 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionRunningEvent(taskInstanceId=1289, processInstanceId=546, startTime=1713904456852, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, status=TaskExecutionStatus{code=1, desc='running'}, logPath=/opt/dolphinscheduler/logs/20240424/13201021801792/90/546/1289.log, executePath=null, processId=0, appIds=null, eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1289] - [INFO] 2024-04-24 04:34:17.557 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionRunningEvent(taskInstanceId=1289, processInstanceId=546, startTime=1713904456852, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, status=TaskExecutionStatus{code=1, desc='running'}, logPath=/opt/dolphinscheduler/logs/20240424/13201021801792/90/546/1289.log, executePath=null, processId=0, appIds=null, eventCreateTime=0, eventSendTime=1713904457536)
[WI-0][TI-1289] - [INFO] 2024-04-24 04:34:17.559 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionInfoEvent(taskInstanceId=1289, processInstanceId=546, startTime=1713904456852, workflowInstanceHost=172.18.0.10:5678, taskInstanceHost=172.18.1.1:1234, logPath=null, processId=0, eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1289] - [INFO] 2024-04-24 04:34:17.574 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionInfoEvent(taskInstanceId=1289, processInstanceId=546, startTime=1713904456852, workflowInstanceHost=172.18.0.10:5678, taskInstanceHost=172.18.1.1:1234, logPath=null, processId=0, eventCreateTime=0, eventSendTime=1713904457536)
[WI-0][TI-1289] - [INFO] 2024-04-24 04:34:17.597 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1289, success=true)
[WI-0][TI-1289] - [INFO] 2024-04-24 04:34:17.607 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1289)
[WI-0][TI-1289] - [INFO] 2024-04-24 04:34:17.614 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1289, success=true)
[WI-0][TI-1289] - [INFO] 2024-04-24 04:34:17.620 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1289)
[WI-0][TI-0] - [INFO] 2024-04-24 04:34:17.943 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
	#{setValue(raw_file_dir=/local_storage/reddit/processing/500-20240423.json)}
[WI-546][TI-1289] - [INFO] 2024-04-24 04:34:17.961 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/546/1289, processId:816 ,exitStatusCode:0 ,processWaitForStatus:true ,processExitValue:0
[WI-546][TI-1289] - [INFO] 2024-04-24 04:34:17.961 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-546][TI-1289] - [INFO] 2024-04-24 04:34:17.962 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-546][TI-1289] - [INFO] 2024-04-24 04:34:17.962 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-546][TI-1289] - [INFO] 2024-04-24 04:34:17.962 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-546][TI-1289] - [INFO] 2024-04-24 04:34:17.996 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: SUCCESS to master : 172.18.1.1:1234
[WI-546][TI-1289] - [INFO] 2024-04-24 04:34:18.002 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-546][TI-1289] - [INFO] 2024-04-24 04:34:18.002 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/546/1289
[WI-546][TI-1289] - [INFO] 2024-04-24 04:34:18.003 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/546/1289
[WI-546][TI-1289] - [INFO] 2024-04-24 04:34:18.003 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-1289] - [INFO] 2024-04-24 04:34:18.576 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1289, success=true)
[WI-0][TI-0] - [INFO] 2024-04-24 04:34:18.772 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7343283582089553 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:34:19.795 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1291, taskName=move to processing, firstSubmitTime=1713904459740, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.10:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=90, appIds=null, processInstanceId=546, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"processing"}], executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":""}],"rawScript":"# move file to the reddit processing folder\n# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error\nfilename=$(basename \"${raw_file_dir}\")\nif ! grep -q \"${REDDIT_HOME}/processing\" <<< \"${raw_file_dir}\"; then\n    mv ${raw_file_dir} ${REDDIT_HOME}/processing\nelse\n    echo JSON is already in processing\nfi\n\n# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing\necho \"#{setValue(raw_file_dir=${REDDIT_HOME}/processing/${filename})}\"","resourceList":[]}, environmentConfig=export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='move to processing'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240424'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1291'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13340390094208'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240424043419'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='processing'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='546'}, raw_file_dir=Property{prop='raw_file_dir', direct=IN, type=VARCHAR, value='/local_storage/reddit/processing/500-20240423.json'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240423'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-546][TI-1291] - [INFO] 2024-04-24 04:34:19.798 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: move to processing to wait queue success
[WI-546][TI-1291] - [INFO] 2024-04-24 04:34:19.798 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-546][TI-1291] - [INFO] 2024-04-24 04:34:19.801 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-546][TI-1291] - [INFO] 2024-04-24 04:34:19.801 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-546][TI-1291] - [INFO] 2024-04-24 04:34:19.801 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-546][TI-1291] - [INFO] 2024-04-24 04:34:19.801 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713904459801
[WI-546][TI-1291] - [INFO] 2024-04-24 04:34:19.801 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 546_1291
[WI-546][TI-1291] - [INFO] 2024-04-24 04:34:19.801 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1291,
  "taskName" : "move to processing",
  "firstSubmitTime" : 1713904459740,
  "startTime" : 1713904459801,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.10:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240424/13201021801792/90/546/1291.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 90,
  "processInstanceId" : 546,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"processing\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[{\"prop\":\"raw_file_dir\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"\"}],\"rawScript\":\"# move file to the reddit processing folder\\n# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error\\nfilename=$(basename \\\"${raw_file_dir}\\\")\\nif ! grep -q \\\"${REDDIT_HOME}/processing\\\" <<< \\\"${raw_file_dir}\\\"; then\\n    mv ${raw_file_dir} ${REDDIT_HOME}/processing\\nelse\\n    echo JSON is already in processing\\nfi\\n\\n# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing\\necho \\\"#{setValue(raw_file_dir=${REDDIT_HOME}/processing/${filename})}\\\"\",\"resourceList\":[]}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "move to processing"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240424"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1291"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13340390094208"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240424043419"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "processing"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "546"
    },
    "raw_file_dir" : {
      "prop" : "raw_file_dir",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit/processing/500-20240423.json"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "546_1291",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"raw_file_dir\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"/local_storage/reddit/processing/500-20240423.json\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-546][TI-1291] - [INFO] 2024-04-24 04:34:19.802 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-546][TI-1291] - [INFO] 2024-04-24 04:34:19.802 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-546][TI-1291] - [INFO] 2024-04-24 04:34:19.802 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-0][TI-0] - [INFO] 2024-04-24 04:34:19.807 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7333333333333334 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-546][TI-1291] - [INFO] 2024-04-24 04:34:19.823 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-546][TI-1291] - [INFO] 2024-04-24 04:34:19.824 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-546][TI-1291] - [INFO] 2024-04-24 04:34:19.828 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/546/1291 check successfully
[WI-546][TI-1291] - [INFO] 2024-04-24 04:34:19.829 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-546][TI-1291] - [INFO] 2024-04-24 04:34:19.829 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-546][TI-1291] - [INFO] 2024-04-24 04:34:19.830 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-546][TI-1291] - [INFO] 2024-04-24 04:34:19.830 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-546][TI-1291] - [INFO] 2024-04-24 04:34:19.830 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ {
    "prop" : "raw_file_dir",
    "direct" : "OUT",
    "type" : "VARCHAR",
    "value" : ""
  } ],
  "varPool" : null,
  "rawScript" : "# move file to the reddit processing folder\n# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error\nfilename=$(basename \"${raw_file_dir}\")\nif ! grep -q \"${REDDIT_HOME}/processing\" <<< \"${raw_file_dir}\"; then\n    mv ${raw_file_dir} ${REDDIT_HOME}/processing\nelse\n    echo JSON is already in processing\nfi\n\n# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing\necho \"#{setValue(raw_file_dir=${REDDIT_HOME}/processing/${filename})}\"",
  "resourceList" : [ ]
}
[WI-546][TI-1291] - [INFO] 2024-04-24 04:34:19.831 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-546][TI-1291] - [INFO] 2024-04-24 04:34:19.831 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}] successfully
[WI-546][TI-1291] - [INFO] 2024-04-24 04:34:19.831 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-546][TI-1291] - [INFO] 2024-04-24 04:34:19.831 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-546][TI-1291] - [INFO] 2024-04-24 04:34:19.831 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-546][TI-1291] - [INFO] 2024-04-24 04:34:19.832 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-546][TI-1291] - [INFO] 2024-04-24 04:34:19.832 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-546][TI-1291] - [INFO] 2024-04-24 04:34:19.832 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export PYTHON_LAUNCHER=/bin/python3.11
# move file to the reddit processing folder
# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error
filename=$(basename "/local_storage/reddit/processing/500-20240423.json")
if ! grep -q "/local_storage/reddit/processing" <<< "/local_storage/reddit/processing/500-20240423.json"; then
    mv /local_storage/reddit/processing/500-20240423.json /local_storage/reddit/processing
else
    echo JSON is already in processing
fi

# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing
echo "#{setValue(raw_file_dir=/local_storage/reddit/processing/${filename})}"
[WI-546][TI-1291] - [INFO] 2024-04-24 04:34:19.833 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-546][TI-1291] - [INFO] 2024-04-24 04:34:19.833 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/546/1291/546_1291.sh
[WI-546][TI-1291] - [INFO] 2024-04-24 04:34:19.845 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 829
[WI-0][TI-1291] - [INFO] 2024-04-24 04:34:20.618 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionRunningEvent(taskInstanceId=1291, processInstanceId=546, startTime=1713904459801, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, status=TaskExecutionStatus{code=1, desc='running'}, logPath=/opt/dolphinscheduler/logs/20240424/13201021801792/90/546/1291.log, executePath=null, processId=0, appIds=null, eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1291] - [INFO] 2024-04-24 04:34:20.641 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionRunningEvent(taskInstanceId=1291, processInstanceId=546, startTime=1713904459801, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, status=TaskExecutionStatus{code=1, desc='running'}, logPath=/opt/dolphinscheduler/logs/20240424/13201021801792/90/546/1291.log, executePath=null, processId=0, appIds=null, eventCreateTime=0, eventSendTime=1713904460595)
[WI-0][TI-1291] - [INFO] 2024-04-24 04:34:20.642 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionInfoEvent(taskInstanceId=1291, processInstanceId=546, startTime=1713904459801, workflowInstanceHost=172.18.0.10:5678, taskInstanceHost=172.18.1.1:1234, logPath=null, processId=0, eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1291] - [INFO] 2024-04-24 04:34:20.654 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1291, success=true)
[WI-0][TI-1291] - [INFO] 2024-04-24 04:34:20.675 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionInfoEvent(taskInstanceId=1291, processInstanceId=546, startTime=1713904459801, workflowInstanceHost=172.18.0.10:5678, taskInstanceHost=172.18.1.1:1234, logPath=null, processId=0, eventCreateTime=0, eventSendTime=1713904460595)
[WI-0][TI-1291] - [WARN] 2024-04-24 04:34:20.676 +0800 o.a.d.s.w.m.MessageRetryRunner:[139] - Retry send message to master error
java.util.ConcurrentModificationException: null
	at java.util.ArrayList$Itr.checkForComodification(ArrayList.java:911)
	at java.util.ArrayList$Itr.next(ArrayList.java:861)
	at org.apache.dolphinscheduler.server.worker.message.MessageRetryRunner.run(MessageRetryRunner.java:127)
[WI-0][TI-1291] - [INFO] 2024-04-24 04:34:20.709 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1291)
[WI-0][TI-1291] - [INFO] 2024-04-24 04:34:20.718 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1291, success=true)
[WI-0][TI-1291] - [INFO] 2024-04-24 04:34:20.733 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1291)
[WI-0][TI-0] - [INFO] 2024-04-24 04:34:20.809 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8734939759036144 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:34:20.847 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
	JSON is already in processing
	#{setValue(raw_file_dir=/local_storage/reddit/processing/500-20240423.json)}
[WI-546][TI-1291] - [INFO] 2024-04-24 04:34:20.852 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/546/1291, processId:829 ,exitStatusCode:0 ,processWaitForStatus:true ,processExitValue:0
[WI-546][TI-1291] - [INFO] 2024-04-24 04:34:20.853 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-546][TI-1291] - [INFO] 2024-04-24 04:34:20.853 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-546][TI-1291] - [INFO] 2024-04-24 04:34:20.854 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-546][TI-1291] - [INFO] 2024-04-24 04:34:20.854 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-546][TI-1291] - [INFO] 2024-04-24 04:34:20.865 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: SUCCESS to master : 172.18.1.1:1234
[WI-546][TI-1291] - [INFO] 2024-04-24 04:34:20.866 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-546][TI-1291] - [INFO] 2024-04-24 04:34:20.866 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/546/1291
[WI-546][TI-1291] - [INFO] 2024-04-24 04:34:20.867 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/546/1291
[WI-546][TI-1291] - [INFO] 2024-04-24 04:34:20.867 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-1291] - [INFO] 2024-04-24 04:34:21.587 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1291, success=true)
[WI-0][TI-0] - [INFO] 2024-04-24 04:34:21.682 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1292, taskName=spark preprocessing, firstSubmitTime=1713904461665, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.10:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=90, appIds=null, processInstanceId=546, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"processing"}], executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[],"rawScript":"$SPARK_HOME/bin/spark-submit \\\n    --master spark://spark-master:7077 \\\n    --deploy-mode client \\\n    --conf spark.driver.cores=2 \\\n    --conf spark.driver.memory=2G \\\n    --conf spark.executor.instances=1 \\\n    --conf spark.executor.cores=2 \\\n    --conf spark.executor.memory=2G \\\n    --files ${raw_file_dir} \\\n    --name reddit_preprocessing testing.py\n\n# $SPARK_HOME/bin/spark-submit \\\n#     --master local \\\n#     --files ${raw_file_dir} \\\n#     --name reddit_preprocessing spark_reddit_preprocessing.py\n","resourceList":[{"id":null,"resourceName":"file:/dolphinscheduler/default/resources/testing.py","res":null}]}, environmentConfig=export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export PYSPARK_DRIVER_PYTHON=/bin/python3.11
export PYTHON_LAUNCHER=/bin/python3.11
export PYSPARK_PYTHON=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='spark preprocessing'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240424'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1292'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13210058002752'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240424043421'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='processing'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='546'}, raw_file_dir=Property{prop='raw_file_dir', direct=IN, type=VARCHAR, value='/local_storage/reddit/processing/500-20240423.json'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240423'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-546][TI-1292] - [INFO] 2024-04-24 04:34:21.685 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: spark preprocessing to wait queue success
[WI-546][TI-1292] - [INFO] 2024-04-24 04:34:21.685 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-546][TI-1292] - [INFO] 2024-04-24 04:34:21.688 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-546][TI-1292] - [INFO] 2024-04-24 04:34:21.689 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-546][TI-1292] - [INFO] 2024-04-24 04:34:21.691 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-546][TI-1292] - [INFO] 2024-04-24 04:34:21.692 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713904461692
[WI-546][TI-1292] - [INFO] 2024-04-24 04:34:21.692 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 546_1292
[WI-546][TI-1292] - [INFO] 2024-04-24 04:34:21.693 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1292,
  "taskName" : "spark preprocessing",
  "firstSubmitTime" : 1713904461665,
  "startTime" : 1713904461692,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.10:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240424/13201021801792/90/546/1292.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 90,
  "processInstanceId" : 546,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"processing\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[],\"rawScript\":\"$SPARK_HOME/bin/spark-submit \\\\\\n    --master spark://spark-master:7077 \\\\\\n    --deploy-mode client \\\\\\n    --conf spark.driver.cores=2 \\\\\\n    --conf spark.driver.memory=2G \\\\\\n    --conf spark.executor.instances=1 \\\\\\n    --conf spark.executor.cores=2 \\\\\\n    --conf spark.executor.memory=2G \\\\\\n    --files ${raw_file_dir} \\\\\\n    --name reddit_preprocessing testing.py\\n\\n# $SPARK_HOME/bin/spark-submit \\\\\\n#     --master local \\\\\\n#     --files ${raw_file_dir} \\\\\\n#     --name reddit_preprocessing spark_reddit_preprocessing.py\\n\",\"resourceList\":[{\"id\":null,\"resourceName\":\"file:/dolphinscheduler/default/resources/testing.py\",\"res\":null}]}",
  "environmentConfig" : "export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3\nexport JAVA_HOME=/opt/java/openjdk\nexport PYSPARK_DRIVER_PYTHON=/bin/python3.11\nexport PYTHON_LAUNCHER=/bin/python3.11\nexport PYSPARK_PYTHON=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "spark preprocessing"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240424"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1292"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13210058002752"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240424043421"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "processing"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "546"
    },
    "raw_file_dir" : {
      "prop" : "raw_file_dir",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit/processing/500-20240423.json"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "546_1292",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"raw_file_dir\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"/local_storage/reddit/processing/500-20240423.json\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-546][TI-1292] - [INFO] 2024-04-24 04:34:21.706 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-546][TI-1292] - [INFO] 2024-04-24 04:34:21.706 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-546][TI-1292] - [INFO] 2024-04-24 04:34:21.706 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-546][TI-1292] - [INFO] 2024-04-24 04:34:21.746 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-546][TI-1292] - [INFO] 2024-04-24 04:34:21.747 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-546][TI-1292] - [INFO] 2024-04-24 04:34:21.749 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/546/1292 check successfully
[WI-546][TI-1292] - [INFO] 2024-04-24 04:34:21.749 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-546][TI-1292] - [INFO] 2024-04-24 04:34:21.758 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={file:/dolphinscheduler/default/resources/testing.py=ResourceContext.ResourceItem(resourceAbsolutePathInStorage=file:/dolphinscheduler/default/resources/testing.py, resourceRelativePath=testing.py, resourceAbsolutePathInLocal=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/546/1292/testing.py)})
[WI-546][TI-1292] - [INFO] 2024-04-24 04:34:21.759 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-546][TI-1292] - [INFO] 2024-04-24 04:34:21.759 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-546][TI-1292] - [INFO] 2024-04-24 04:34:21.760 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ ],
  "varPool" : null,
  "rawScript" : "$SPARK_HOME/bin/spark-submit \\\n    --master spark://spark-master:7077 \\\n    --deploy-mode client \\\n    --conf spark.driver.cores=2 \\\n    --conf spark.driver.memory=2G \\\n    --conf spark.executor.instances=1 \\\n    --conf spark.executor.cores=2 \\\n    --conf spark.executor.memory=2G \\\n    --files ${raw_file_dir} \\\n    --name reddit_preprocessing testing.py\n\n# $SPARK_HOME/bin/spark-submit \\\n#     --master local \\\n#     --files ${raw_file_dir} \\\n#     --name reddit_preprocessing spark_reddit_preprocessing.py\n",
  "resourceList" : [ {
    "id" : null,
    "resourceName" : "file:/dolphinscheduler/default/resources/testing.py",
    "res" : null
  } ]
}
[WI-546][TI-1292] - [INFO] 2024-04-24 04:34:21.760 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-546][TI-1292] - [INFO] 2024-04-24 04:34:21.764 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}] successfully
[WI-546][TI-1292] - [INFO] 2024-04-24 04:34:21.764 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-546][TI-1292] - [INFO] 2024-04-24 04:34:21.765 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-546][TI-1292] - [INFO] 2024-04-24 04:34:21.765 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-546][TI-1292] - [INFO] 2024-04-24 04:34:21.766 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-546][TI-1292] - [INFO] 2024-04-24 04:34:21.768 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-546][TI-1292] - [INFO] 2024-04-24 04:34:21.768 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export PYSPARK_DRIVER_PYTHON=/bin/python3.11
export PYTHON_LAUNCHER=/bin/python3.11
export PYSPARK_PYTHON=/bin/python3.11
$SPARK_HOME/bin/spark-submit \
    --master spark://spark-master:7077 \
    --deploy-mode client \
    --conf spark.driver.cores=2 \
    --conf spark.driver.memory=2G \
    --conf spark.executor.instances=1 \
    --conf spark.executor.cores=2 \
    --conf spark.executor.memory=2G \
    --files /local_storage/reddit/processing/500-20240423.json \
    --name reddit_preprocessing testing.py

# $SPARK_HOME/bin/spark-submit \
#     --master local \
#     --files /local_storage/reddit/processing/500-20240423.json \
#     --name reddit_preprocessing spark_reddit_preprocessing.py

[WI-546][TI-1292] - [INFO] 2024-04-24 04:34:21.769 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-546][TI-1292] - [INFO] 2024-04-24 04:34:21.769 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/546/1292/546_1292.sh
[WI-546][TI-1292] - [INFO] 2024-04-24 04:34:21.807 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 841
[WI-0][TI-1292] - [INFO] 2024-04-24 04:34:22.632 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1292, success=true)
[WI-0][TI-1292] - [INFO] 2024-04-24 04:34:22.678 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1292)
[WI-0][TI-0] - [INFO] 2024-04-24 04:34:22.812 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
[WI-0][TI-0] - [INFO] 2024-04-24 04:34:22.833 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7927170868347339 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:34:23.904 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7643595823864572 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:34:26.820 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 04:34:25 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[WI-0][TI-0] - [INFO] 2024-04-24 04:34:27.838 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 04:34:27 INFO SparkContext: Running Spark version 3.5.1
	24/04/24 04:34:27 INFO SparkContext: OS info Linux, 6.5.0-28-generic, amd64
	24/04/24 04:34:27 INFO SparkContext: Java version 1.8.0_402
	24/04/24 04:34:27 INFO ResourceUtils: ==============================================================
	24/04/24 04:34:27 INFO ResourceUtils: No custom resources configured for spark.driver.
	24/04/24 04:34:27 INFO ResourceUtils: ==============================================================
	24/04/24 04:34:27 INFO SparkContext: Submitted application: reddit_preprocessing
	24/04/24 04:34:27 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 2, script: , vendor: , memory -> name: memory, amount: 2048, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
	24/04/24 04:34:27 INFO ResourceProfile: Limiting resource is cpus at 2 tasks per executor
	24/04/24 04:34:27 INFO ResourceProfileManager: Added ResourceProfile id: 0
	24/04/24 04:34:27 INFO SecurityManager: Changing view acls to: default
	24/04/24 04:34:27 INFO SecurityManager: Changing modify acls to: default
	24/04/24 04:34:27 INFO SecurityManager: Changing view acls groups to: 
	24/04/24 04:34:27 INFO SecurityManager: Changing modify acls groups to: 
	24/04/24 04:34:27 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: default; groups with view permissions: EMPTY; users with modify permissions: default; groups with modify permissions: EMPTY
	24/04/24 04:34:27 INFO Utils: Successfully started service 'sparkDriver' on port 40747.
[WI-0][TI-0] - [INFO] 2024-04-24 04:34:28.840 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 04:34:27 INFO SparkEnv: Registering MapOutputTracker
	24/04/24 04:34:28 INFO SparkEnv: Registering BlockManagerMaster
	24/04/24 04:34:28 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
	24/04/24 04:34:28 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
	24/04/24 04:34:28 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
	24/04/24 04:34:28 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-b3e00cfd-634c-47c0-bab2-98e87c64d0e4
	24/04/24 04:34:28 INFO MemoryStore: MemoryStore started with capacity 912.3 MiB
	24/04/24 04:34:28 INFO SparkEnv: Registering OutputCommitCoordinator
	24/04/24 04:34:28 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
	24/04/24 04:34:28 INFO Utils: Successfully started service 'SparkUI' on port 4040.
	24/04/24 04:34:28 INFO SparkContext: Added file file:///local_storage/reddit/processing/500-20240423.json at spark://5afbfd5249fc:40747/files/500-20240423.json with timestamp 1713904467007
	24/04/24 04:34:28 INFO Utils: Copying /local_storage/reddit/processing/500-20240423.json to /tmp/spark-082f2b86-a2f1-4295-9f8a-88f8674ad3c5/userFiles-b751f194-d5dd-411b-afb7-af34c12e9558/500-20240423.json
[WI-0][TI-0] - [INFO] 2024-04-24 04:34:28.953 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8096774193548387 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:34:29.843 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 04:34:29 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
	24/04/24 04:34:29 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.4:7077 after 156 ms (0 ms spent in bootstraps)
[WI-0][TI-0] - [INFO] 2024-04-24 04:34:30.005 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9245810055865922 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:34:30.850 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 04:34:29 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20240423203429-0002
	24/04/24 04:34:30 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20240423203429-0002/0 on worker-20240423200818-172.18.0.6-42177 (172.18.0.6:42177) with 2 core(s)
	24/04/24 04:34:30 INFO StandaloneSchedulerBackend: Granted executor ID app-20240423203429-0002/0 on hostPort 172.18.0.6:42177 with 2 core(s), 2.0 GiB RAM
	24/04/24 04:34:30 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46641.
	24/04/24 04:34:30 INFO NettyBlockTransferService: Server created on 5afbfd5249fc:46641
	24/04/24 04:34:30 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
	24/04/24 04:34:30 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20240423203429-0002/0 is now RUNNING
	24/04/24 04:34:30 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 5afbfd5249fc, 46641, None)
	24/04/24 04:34:30 INFO BlockManagerMasterEndpoint: Registering block manager 5afbfd5249fc:46641 with 912.3 MiB RAM, BlockManagerId(driver, 5afbfd5249fc, 46641, None)
	24/04/24 04:34:30 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 5afbfd5249fc, 46641, None)
	24/04/24 04:34:30 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 5afbfd5249fc, 46641, None)
[WI-0][TI-0] - [INFO] 2024-04-24 04:34:31.018 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9237804878048781 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:34:31.861 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 04:34:31 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
[WI-0][TI-0] - [INFO] 2024-04-24 04:34:32.033 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8547297297297297 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:34:32.873 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	
	[
	    {"name": "t3_abc123", "author": "user1", "body": "Sample comment 1", "permalink": "/r/subreddit1/post/abc123", "unix_time": 1619520000},
	    {"name": "t1_def456", "author": "user2", "body": "Sample comment 2", "permalink": "/r/subreddit2/post/def456", "unix_time": 1619521000}
	]
	
	24/04/24 04:34:31 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
	24/04/24 04:34:31 INFO SharedState: Warehouse path is 'file:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/546/1292/spark-warehouse'.
[WI-0][TI-0] - [INFO] 2024-04-24 04:34:33.037 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8987341772151899 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:34:34.040 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7533632286995515 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:34:35.921 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 04:34:35 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.6:49764) with ID 0,  ResourceProfileId 0
[WI-0][TI-0] - [INFO] 2024-04-24 04:34:36.924 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 04:34:35 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.6:33089 with 1048.8 MiB RAM, BlockManagerId(0, 172.18.0.6, 33089, None)
[WI-0][TI-0] - [INFO] 2024-04-24 04:34:38.949 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 04:34:38 INFO CodeGenerator: Code generated in 405.801929 ms
	24/04/24 04:34:38 INFO SparkContext: Starting job: json at NativeMethodAccessorImpl.java:0
	24/04/24 04:34:38 INFO DAGScheduler: Got job 0 (json at NativeMethodAccessorImpl.java:0) with 2 output partitions
	24/04/24 04:34:38 INFO DAGScheduler: Final stage: ResultStage 0 (json at NativeMethodAccessorImpl.java:0)
	24/04/24 04:34:38 INFO DAGScheduler: Parents of final stage: List()
	24/04/24 04:34:38 INFO DAGScheduler: Missing parents: List()
	24/04/24 04:34:38 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[6] at json at NativeMethodAccessorImpl.java:0), which has no missing parents
	24/04/24 04:34:38 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 20.9 KiB, free 912.3 MiB)
	24/04/24 04:34:38 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 10.2 KiB, free 912.3 MiB)
	24/04/24 04:34:38 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 5afbfd5249fc:46641 (size: 10.2 KiB, free: 912.3 MiB)
	24/04/24 04:34:38 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1585
	24/04/24 04:34:38 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (MapPartitionsRDD[6] at json at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
	24/04/24 04:34:38 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks resource profile 0
	24/04/24 04:34:38 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.6, executor 0, partition 0, PROCESS_LOCAL, 7776 bytes) 
	24/04/24 04:34:38 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1) (172.18.0.6, executor 0, partition 1, PROCESS_LOCAL, 8093 bytes) 
[WI-0][TI-0] - [INFO] 2024-04-24 04:36:51.547 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 04:36:51 WARN TransportChannelHandler: Exception in connection from /172.18.1.1:52100
	java.lang.IllegalArgumentException: Too large frame: 5135603447292250188
		at org.sparkproject.guava.base.Preconditions.checkArgument(Preconditions.java:119)
		at org.apache.spark.network.util.TransportFrameDecoder.decodeNext(TransportFrameDecoder.java:148)
		at org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:98)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
		at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)
		at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:440)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
		at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)
		at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)
		at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:788)
		at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)
		at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)
		at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)
		at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
		at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
		at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
		at java.lang.Thread.run(Thread.java:750)
[WI-0][TI-0] - [INFO] 2024-04-24 04:38:10.937 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7265193370165746 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-1281] - [INFO] 2024-04-24 04:39:08.731 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1281, processInstanceId=543, status=9, startTime=1713903509183, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, logPath=/opt/dolphinscheduler/logs/20240424/13201021801792/90/543/1281.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/543/1281, endTime=1713904084494, processId=300, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], eventCreateTime=0, eventSendTime=1713904448510)
[WI-0][TI-1281] - [INFO] 2024-04-24 04:39:08.744 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1281, processInstanceId=543, status=9, startTime=1713903509183, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, logPath=/opt/dolphinscheduler/logs/20240424/13201021801792/90/543/1281.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/543/1281, endTime=1713904084494, processId=300, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], eventCreateTime=0, eventSendTime=1713904748731)
[WI-0][TI-0] - [INFO] 2024-04-24 04:41:49.538 +0800 o.a.d.s.w.r.o.TaskInstanceKillOperationFunction:[55] - Receive TaskInstanceKillRequest: TaskInstanceKillRequest(taskInstanceId=1292)
[WI-0][TI-1292] - [ERROR] 2024-04-24 04:41:49.551 +0800 o.a.d.s.w.r.o.TaskInstanceKillOperationFunction:[139] - kill task error
java.io.IOException: Cannot run program "pstree": error=2, No such file or directory
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1048)
	at org.apache.dolphinscheduler.common.shell.AbstractShell.runCommand(AbstractShell.java:138)
	at org.apache.dolphinscheduler.common.shell.AbstractShell.run(AbstractShell.java:118)
	at org.apache.dolphinscheduler.common.shell.ShellExecutor.execute(ShellExecutor.java:125)
	at org.apache.dolphinscheduler.common.shell.ShellExecutor.execCommand(ShellExecutor.java:103)
	at org.apache.dolphinscheduler.common.shell.ShellExecutor.execCommand(ShellExecutor.java:86)
	at org.apache.dolphinscheduler.common.utils.OSUtils.exeShell(OSUtils.java:345)
	at org.apache.dolphinscheduler.common.utils.OSUtils.exeCmd(OSUtils.java:334)
	at org.apache.dolphinscheduler.plugin.task.api.utils.ProcessUtils.getPidsStr(ProcessUtils.java:129)
	at org.apache.dolphinscheduler.server.worker.runner.operator.TaskInstanceKillOperationFunction.killProcess(TaskInstanceKillOperationFunction.java:130)
	at org.apache.dolphinscheduler.server.worker.runner.operator.TaskInstanceKillOperationFunction.doKill(TaskInstanceKillOperationFunction.java:96)
	at org.apache.dolphinscheduler.server.worker.runner.operator.TaskInstanceKillOperationFunction.operate(TaskInstanceKillOperationFunction.java:69)
	at org.apache.dolphinscheduler.server.worker.rpc.TaskInstanceOperatorImpl.killTask(TaskInstanceOperatorImpl.java:49)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.dolphinscheduler.extract.base.server.ServerMethodInvokerImpl.invoke(ServerMethodInvokerImpl.java:41)
	at org.apache.dolphinscheduler.extract.base.server.JdkDynamicServerHandler.lambda$processReceived$0(JdkDynamicServerHandler.java:108)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.io.IOException: error=2, No such file or directory
	at java.lang.UNIXProcess.forkAndExec(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:247)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	... 21 common frames omitted
[WI-0][TI-1292] - [INFO] 2024-04-24 04:41:49.555 +0800 o.a.d.p.t.a.u.ProcessUtils:[182] - Get appIds from worker 172.18.1.1:1234, taskLogPath: /opt/dolphinscheduler/logs/20240424/13201021801792/90/546/1292.log
[WI-0][TI-1292] - [INFO] 2024-04-24 04:41:49.557 +0800 o.a.d.p.t.a.u.LogUtils:[79] - Start finding appId in /opt/dolphinscheduler/logs/20240424/13201021801792/90/546/1292.log, fetch way: log 
[WI-0][TI-1292] - [INFO] 2024-04-24 04:41:49.560 +0800 o.a.d.p.t.a.u.ProcessUtils:[188] - The appId is empty
[WI-0][TI-1292] - [INFO] 2024-04-24 04:41:49.561 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[220] - Begin to kill process process, pid is : 841
[WI-0][TI-1292] - [INFO] 2024-04-24 04:41:54.576 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[225] - Success kill task: 546_1292, pid: 841
[WI-0][TI-1292] - [INFO] 2024-04-24 04:41:54.581 +0800 o.a.d.s.w.r.o.TaskInstanceKillOperationFunction:[119] - kill task by cancelApplication, taskInstanceId: 1292
[WI-0][TI-0] - [INFO] 2024-04-24 04:42:28.691 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.915204678362573 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:42:38.930 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1293, taskName=search for intake JSON files, firstSubmitTime=1713904958867, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.10:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=91, appIds=null, processInstanceId=547, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"processing"}], executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":""}],"rawScript":"# find 1 raw file in the folder\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\n\n# check if raw_file_dir is empty, then set raw_file_dir to null\nif [ -z \"$raw_file_dir\" ]; then\n    raw_file_dir=null\nfi\n\necho \"#{setValue(raw_file_dir=${raw_file_dir})}\"","resourceList":[]}, environmentConfig=export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='search for intake JSON files'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240424'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1293'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13340113777664'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240424044238'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='processing'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='547'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240423'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=null, dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-547][TI-1293] - [INFO] 2024-04-24 04:42:38.952 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: search for intake JSON files to wait queue success
[WI-547][TI-1293] - [INFO] 2024-04-24 04:42:38.953 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-547][TI-1293] - [INFO] 2024-04-24 04:42:38.956 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-547][TI-1293] - [INFO] 2024-04-24 04:42:38.956 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-547][TI-1293] - [INFO] 2024-04-24 04:42:38.957 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-547][TI-1293] - [INFO] 2024-04-24 04:42:38.957 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713904958957
[WI-547][TI-1293] - [INFO] 2024-04-24 04:42:38.957 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 547_1293
[WI-547][TI-1293] - [INFO] 2024-04-24 04:42:38.957 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1293,
  "taskName" : "search for intake JSON files",
  "firstSubmitTime" : 1713904958867,
  "startTime" : 1713904958957,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.10:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240424/13201021801792/91/547/1293.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 91,
  "processInstanceId" : 547,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"processing\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[{\"prop\":\"raw_file_dir\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"\"}],\"rawScript\":\"# find 1 raw file in the folder\\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\\n\\n# check if raw_file_dir is empty, then set raw_file_dir to null\\nif [ -z \\\"$raw_file_dir\\\" ]; then\\n    raw_file_dir=null\\nfi\\n\\necho \\\"#{setValue(raw_file_dir=${raw_file_dir})}\\\"\",\"resourceList\":[]}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "search for intake JSON files"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240424"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1293"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13340113777664"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240424044238"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "processing"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "547"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "547_1293",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-547][TI-1293] - [INFO] 2024-04-24 04:42:38.958 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-547][TI-1293] - [INFO] 2024-04-24 04:42:38.958 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-547][TI-1293] - [INFO] 2024-04-24 04:42:38.958 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-547][TI-1293] - [INFO] 2024-04-24 04:42:38.978 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-547][TI-1293] - [INFO] 2024-04-24 04:42:38.979 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-547][TI-1293] - [INFO] 2024-04-24 04:42:38.980 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_91/547/1293 check successfully
[WI-547][TI-1293] - [INFO] 2024-04-24 04:42:38.980 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-547][TI-1293] - [INFO] 2024-04-24 04:42:38.981 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-547][TI-1293] - [INFO] 2024-04-24 04:42:38.981 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-547][TI-1293] - [INFO] 2024-04-24 04:42:38.981 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-547][TI-1293] - [INFO] 2024-04-24 04:42:38.987 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ {
    "prop" : "raw_file_dir",
    "direct" : "OUT",
    "type" : "VARCHAR",
    "value" : ""
  } ],
  "varPool" : null,
  "rawScript" : "# find 1 raw file in the folder\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\n\n# check if raw_file_dir is empty, then set raw_file_dir to null\nif [ -z \"$raw_file_dir\" ]; then\n    raw_file_dir=null\nfi\n\necho \"#{setValue(raw_file_dir=${raw_file_dir})}\"",
  "resourceList" : [ ]
}
[WI-547][TI-1293] - [INFO] 2024-04-24 04:42:38.990 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-547][TI-1293] - [INFO] 2024-04-24 04:42:38.990 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: null successfully
[WI-547][TI-1293] - [INFO] 2024-04-24 04:42:38.990 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-547][TI-1293] - [INFO] 2024-04-24 04:42:38.990 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-547][TI-1293] - [INFO] 2024-04-24 04:42:38.990 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-547][TI-1293] - [INFO] 2024-04-24 04:42:38.997 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-547][TI-1293] - [INFO] 2024-04-24 04:42:38.998 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-547][TI-1293] - [INFO] 2024-04-24 04:42:39.000 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export PYTHON_LAUNCHER=/bin/python3.11
# find 1 raw file in the folder
raw_file_dir=$(find /local_storage/reddit/processing -type f -name '*.json'| head -n 1)

# check if raw_file_dir is empty, then set raw_file_dir to null
if [ -z "$raw_file_dir" ]; then
    raw_file_dir=null
fi

echo "#{setValue(raw_file_dir=${raw_file_dir})}"
[WI-547][TI-1293] - [INFO] 2024-04-24 04:42:39.001 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-547][TI-1293] - [INFO] 2024-04-24 04:42:39.001 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_91/547/1293/547_1293.sh
[WI-547][TI-1293] - [INFO] 2024-04-24 04:42:39.019 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 1055
[WI-0][TI-1293] - [INFO] 2024-04-24 04:42:39.340 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionRunningEvent(taskInstanceId=1293, processInstanceId=547, startTime=1713904958957, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, status=TaskExecutionStatus{code=1, desc='running'}, logPath=/opt/dolphinscheduler/logs/20240424/13201021801792/91/547/1293.log, executePath=null, processId=0, appIds=null, eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1293] - [INFO] 2024-04-24 04:42:39.344 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionRunningEvent(taskInstanceId=1293, processInstanceId=547, startTime=1713904958957, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, status=TaskExecutionStatus{code=1, desc='running'}, logPath=/opt/dolphinscheduler/logs/20240424/13201021801792/91/547/1293.log, executePath=null, processId=0, appIds=null, eventCreateTime=0, eventSendTime=1713904959339)
[WI-0][TI-1293] - [INFO] 2024-04-24 04:42:39.344 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionInfoEvent(taskInstanceId=1293, processInstanceId=547, startTime=1713904958957, workflowInstanceHost=172.18.0.10:5678, taskInstanceHost=172.18.1.1:1234, logPath=null, processId=0, eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1293] - [INFO] 2024-04-24 04:42:39.348 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionInfoEvent(taskInstanceId=1293, processInstanceId=547, startTime=1713904958957, workflowInstanceHost=172.18.0.10:5678, taskInstanceHost=172.18.1.1:1234, logPath=null, processId=0, eventCreateTime=0, eventSendTime=1713904959339)
[WI-0][TI-1293] - [INFO] 2024-04-24 04:42:39.949 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1293, success=true)
[WI-0][TI-1293] - [INFO] 2024-04-24 04:42:39.962 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1293)
[WI-0][TI-1293] - [INFO] 2024-04-24 04:42:39.989 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1293, success=true)
[WI-0][TI-1293] - [INFO] 2024-04-24 04:42:40.013 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1293)
[WI-0][TI-0] - [INFO] 2024-04-24 04:42:40.021 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
	#{setValue(raw_file_dir=/local_storage/reddit/processing/500-20240423.json)}
[WI-547][TI-1293] - [INFO] 2024-04-24 04:42:40.024 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_91/547/1293, processId:1055 ,exitStatusCode:0 ,processWaitForStatus:true ,processExitValue:0
[WI-547][TI-1293] - [INFO] 2024-04-24 04:42:40.024 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-547][TI-1293] - [INFO] 2024-04-24 04:42:40.024 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-547][TI-1293] - [INFO] 2024-04-24 04:42:40.024 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-547][TI-1293] - [INFO] 2024-04-24 04:42:40.025 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-547][TI-1293] - [INFO] 2024-04-24 04:42:40.037 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: SUCCESS to master : 172.18.1.1:1234
[WI-547][TI-1293] - [INFO] 2024-04-24 04:42:40.037 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-547][TI-1293] - [INFO] 2024-04-24 04:42:40.037 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_91/547/1293
[WI-547][TI-1293] - [INFO] 2024-04-24 04:42:40.039 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_91/547/1293
[WI-547][TI-1293] - [INFO] 2024-04-24 04:42:40.039 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-1293] - [INFO] 2024-04-24 04:42:40.349 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1293, processInstanceId=547, status=7, startTime=1713904958957, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, logPath=/opt/dolphinscheduler/logs/20240424/13201021801792/91/547/1293.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_91/547/1293, endTime=1713904960025, processId=1055, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1293] - [INFO] 2024-04-24 04:42:40.354 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1293, processInstanceId=547, status=7, startTime=1713904958957, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, logPath=/opt/dolphinscheduler/logs/20240424/13201021801792/91/547/1293.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_91/547/1293, endTime=1713904960025, processId=1055, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], eventCreateTime=0, eventSendTime=1713904960349)
[WI-0][TI-1293] - [INFO] 2024-04-24 04:42:40.944 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1293, success=true)
[WI-0][TI-1293] - [INFO] 2024-04-24 04:42:40.948 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1293, success=true)
[WI-0][TI-0] - [INFO] 2024-04-24 04:42:42.122 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1295, taskName=move to processing, firstSubmitTime=1713904962070, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.10:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=91, appIds=null, processInstanceId=547, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"processing"}], executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":""}],"rawScript":"# move file to the reddit processing folder\n# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error\nfilename=$(basename \"${raw_file_dir}\")\nif ! grep -q \"${REDDIT_HOME}/processing\" <<< \"${raw_file_dir}\"; then\n    mv ${raw_file_dir} ${REDDIT_HOME}/processing\nelse\n    echo JSON is already in processing\nfi\n\n# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing\necho \"#{setValue(raw_file_dir=${REDDIT_HOME}/processing/${filename})}\"","resourceList":[]}, environmentConfig=export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='move to processing'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240424'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1295'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13340390094208'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240424044242'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='processing'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='547'}, raw_file_dir=Property{prop='raw_file_dir', direct=IN, type=VARCHAR, value='/local_storage/reddit/processing/500-20240423.json'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240423'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-547][TI-1295] - [INFO] 2024-04-24 04:42:42.127 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: move to processing to wait queue success
[WI-547][TI-1295] - [INFO] 2024-04-24 04:42:42.131 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-547][TI-1295] - [INFO] 2024-04-24 04:42:42.146 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-547][TI-1295] - [INFO] 2024-04-24 04:42:42.146 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-547][TI-1295] - [INFO] 2024-04-24 04:42:42.146 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-547][TI-1295] - [INFO] 2024-04-24 04:42:42.146 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713904962146
[WI-547][TI-1295] - [INFO] 2024-04-24 04:42:42.147 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 547_1295
[WI-547][TI-1295] - [INFO] 2024-04-24 04:42:42.188 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1295,
  "taskName" : "move to processing",
  "firstSubmitTime" : 1713904962070,
  "startTime" : 1713904962146,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.10:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240424/13201021801792/91/547/1295.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 91,
  "processInstanceId" : 547,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"processing\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[{\"prop\":\"raw_file_dir\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"\"}],\"rawScript\":\"# move file to the reddit processing folder\\n# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error\\nfilename=$(basename \\\"${raw_file_dir}\\\")\\nif ! grep -q \\\"${REDDIT_HOME}/processing\\\" <<< \\\"${raw_file_dir}\\\"; then\\n    mv ${raw_file_dir} ${REDDIT_HOME}/processing\\nelse\\n    echo JSON is already in processing\\nfi\\n\\n# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing\\necho \\\"#{setValue(raw_file_dir=${REDDIT_HOME}/processing/${filename})}\\\"\",\"resourceList\":[]}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "move to processing"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240424"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1295"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13340390094208"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240424044242"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "processing"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "547"
    },
    "raw_file_dir" : {
      "prop" : "raw_file_dir",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit/processing/500-20240423.json"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "547_1295",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"raw_file_dir\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"/local_storage/reddit/processing/500-20240423.json\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-547][TI-1295] - [INFO] 2024-04-24 04:42:42.189 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-547][TI-1295] - [INFO] 2024-04-24 04:42:42.190 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-547][TI-1295] - [INFO] 2024-04-24 04:42:42.190 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-547][TI-1295] - [INFO] 2024-04-24 04:42:42.209 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-547][TI-1295] - [INFO] 2024-04-24 04:42:42.225 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-547][TI-1295] - [INFO] 2024-04-24 04:42:42.231 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_91/547/1295 check successfully
[WI-547][TI-1295] - [INFO] 2024-04-24 04:42:42.231 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-547][TI-1295] - [INFO] 2024-04-24 04:42:42.233 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-547][TI-1295] - [INFO] 2024-04-24 04:42:42.234 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-547][TI-1295] - [INFO] 2024-04-24 04:42:42.236 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-547][TI-1295] - [INFO] 2024-04-24 04:42:42.238 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ {
    "prop" : "raw_file_dir",
    "direct" : "OUT",
    "type" : "VARCHAR",
    "value" : ""
  } ],
  "varPool" : null,
  "rawScript" : "# move file to the reddit processing folder\n# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error\nfilename=$(basename \"${raw_file_dir}\")\nif ! grep -q \"${REDDIT_HOME}/processing\" <<< \"${raw_file_dir}\"; then\n    mv ${raw_file_dir} ${REDDIT_HOME}/processing\nelse\n    echo JSON is already in processing\nfi\n\n# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing\necho \"#{setValue(raw_file_dir=${REDDIT_HOME}/processing/${filename})}\"",
  "resourceList" : [ ]
}
[WI-547][TI-1295] - [INFO] 2024-04-24 04:42:42.240 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-547][TI-1295] - [INFO] 2024-04-24 04:42:42.241 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}] successfully
[WI-547][TI-1295] - [INFO] 2024-04-24 04:42:42.242 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-547][TI-1295] - [INFO] 2024-04-24 04:42:42.244 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-547][TI-1295] - [INFO] 2024-04-24 04:42:42.245 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-547][TI-1295] - [INFO] 2024-04-24 04:42:42.247 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-547][TI-1295] - [INFO] 2024-04-24 04:42:42.247 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-547][TI-1295] - [INFO] 2024-04-24 04:42:42.247 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export PYTHON_LAUNCHER=/bin/python3.11
# move file to the reddit processing folder
# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error
filename=$(basename "/local_storage/reddit/processing/500-20240423.json")
if ! grep -q "/local_storage/reddit/processing" <<< "/local_storage/reddit/processing/500-20240423.json"; then
    mv /local_storage/reddit/processing/500-20240423.json /local_storage/reddit/processing
else
    echo JSON is already in processing
fi

# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing
echo "#{setValue(raw_file_dir=/local_storage/reddit/processing/${filename})}"
[WI-547][TI-1295] - [INFO] 2024-04-24 04:42:42.247 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-547][TI-1295] - [INFO] 2024-04-24 04:42:42.251 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_91/547/1295/547_1295.sh
[WI-547][TI-1295] - [INFO] 2024-04-24 04:42:42.256 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 1069
[WI-0][TI-1295] - [INFO] 2024-04-24 04:42:42.356 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionRunningEvent(taskInstanceId=1295, processInstanceId=547, startTime=1713904962146, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, status=TaskExecutionStatus{code=1, desc='running'}, logPath=/opt/dolphinscheduler/logs/20240424/13201021801792/91/547/1295.log, executePath=null, processId=0, appIds=null, eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1295] - [INFO] 2024-04-24 04:42:42.367 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionRunningEvent(taskInstanceId=1295, processInstanceId=547, startTime=1713904962146, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, status=TaskExecutionStatus{code=1, desc='running'}, logPath=/opt/dolphinscheduler/logs/20240424/13201021801792/91/547/1295.log, executePath=null, processId=0, appIds=null, eventCreateTime=0, eventSendTime=1713904962355)
[WI-0][TI-1295] - [INFO] 2024-04-24 04:42:42.368 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionInfoEvent(taskInstanceId=1295, processInstanceId=547, startTime=1713904962146, workflowInstanceHost=172.18.0.10:5678, taskInstanceHost=172.18.1.1:1234, logPath=null, processId=0, eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1295] - [INFO] 2024-04-24 04:42:42.372 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionInfoEvent(taskInstanceId=1295, processInstanceId=547, startTime=1713904962146, workflowInstanceHost=172.18.0.10:5678, taskInstanceHost=172.18.1.1:1234, logPath=null, processId=0, eventCreateTime=0, eventSendTime=1713904962355)
[WI-0][TI-0] - [INFO] 2024-04-24 04:42:42.767 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8526011560693642 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-1295] - [INFO] 2024-04-24 04:42:42.954 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1295, success=true)
[WI-0][TI-1295] - [INFO] 2024-04-24 04:42:42.960 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1295)
[WI-0][TI-1295] - [INFO] 2024-04-24 04:42:42.970 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1295, success=true)
[WI-0][TI-1295] - [INFO] 2024-04-24 04:42:42.983 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1295)
[WI-0][TI-0] - [INFO] 2024-04-24 04:42:43.261 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
	JSON is already in processing
	#{setValue(raw_file_dir=/local_storage/reddit/processing/500-20240423.json)}
[WI-547][TI-1295] - [INFO] 2024-04-24 04:42:43.264 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_91/547/1295, processId:1069 ,exitStatusCode:0 ,processWaitForStatus:true ,processExitValue:0
[WI-547][TI-1295] - [INFO] 2024-04-24 04:42:43.265 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-547][TI-1295] - [INFO] 2024-04-24 04:42:43.265 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-547][TI-1295] - [INFO] 2024-04-24 04:42:43.266 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-547][TI-1295] - [INFO] 2024-04-24 04:42:43.267 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-547][TI-1295] - [INFO] 2024-04-24 04:42:43.270 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: SUCCESS to master : 172.18.1.1:1234
[WI-547][TI-1295] - [INFO] 2024-04-24 04:42:43.271 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-547][TI-1295] - [INFO] 2024-04-24 04:42:43.271 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_91/547/1295
[WI-547][TI-1295] - [INFO] 2024-04-24 04:42:43.272 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_91/547/1295
[WI-547][TI-1295] - [INFO] 2024-04-24 04:42:43.272 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-1295] - [INFO] 2024-04-24 04:42:43.375 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1295, processInstanceId=547, status=7, startTime=1713904962146, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, logPath=/opt/dolphinscheduler/logs/20240424/13201021801792/91/547/1295.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_91/547/1295, endTime=1713904963267, processId=1069, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1295] - [INFO] 2024-04-24 04:42:43.379 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1295, processInstanceId=547, status=7, startTime=1713904962146, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, logPath=/opt/dolphinscheduler/logs/20240424/13201021801792/91/547/1295.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_91/547/1295, endTime=1713904963267, processId=1069, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], eventCreateTime=0, eventSendTime=1713904963375)
[WI-0][TI-1295] - [INFO] 2024-04-24 04:42:43.947 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1295, success=true)
[WI-0][TI-1295] - [INFO] 2024-04-24 04:42:43.951 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1295, success=true)
[WI-0][TI-0] - [INFO] 2024-04-24 04:42:43.980 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1296, taskName=spark preprocessing, firstSubmitTime=1713904963967, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.10:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=91, appIds=null, processInstanceId=547, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"processing"}], executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[],"rawScript":"$SPARK_HOME/bin/spark-submit \\\n    --master spark://spark-master:7077 \\\n    --deploy-mode client \\\n    --conf spark.driver.cores=1 \\\n    --conf spark.driver.memory=1G \\\n    --conf spark.executor.instances=1 \\\n    --conf spark.executor.cores=1 \\\n    --conf spark.executor.memory=1G \\\n    --files ${raw_file_dir} \\\n    --name reddit_preprocessing testing.py\n\n# $SPARK_HOME/bin/spark-submit \\\n#     --master local \\\n#     --files ${raw_file_dir} \\\n#     --name reddit_preprocessing spark_reddit_preprocessing.py\n","resourceList":[{"id":null,"resourceName":"file:/dolphinscheduler/default/resources/testing.py","res":null}]}, environmentConfig=export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export PYSPARK_DRIVER_PYTHON=/bin/python3.11
export PYTHON_LAUNCHER=/bin/python3.11
export PYSPARK_PYTHON=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='spark preprocessing'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240424'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1296'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13210058002752'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240424044243'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='processing'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='547'}, raw_file_dir=Property{prop='raw_file_dir', direct=IN, type=VARCHAR, value='/local_storage/reddit/processing/500-20240423.json'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240423'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-547][TI-1296] - [INFO] 2024-04-24 04:42:43.981 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: spark preprocessing to wait queue success
[WI-547][TI-1296] - [INFO] 2024-04-24 04:42:43.981 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-547][TI-1296] - [INFO] 2024-04-24 04:42:43.983 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-547][TI-1296] - [INFO] 2024-04-24 04:42:43.983 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-547][TI-1296] - [INFO] 2024-04-24 04:42:43.983 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-547][TI-1296] - [INFO] 2024-04-24 04:42:43.983 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713904963983
[WI-547][TI-1296] - [INFO] 2024-04-24 04:42:43.983 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 547_1296
[WI-547][TI-1296] - [INFO] 2024-04-24 04:42:43.984 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1296,
  "taskName" : "spark preprocessing",
  "firstSubmitTime" : 1713904963967,
  "startTime" : 1713904963983,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.10:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240424/13201021801792/91/547/1296.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 91,
  "processInstanceId" : 547,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"processing\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[],\"rawScript\":\"$SPARK_HOME/bin/spark-submit \\\\\\n    --master spark://spark-master:7077 \\\\\\n    --deploy-mode client \\\\\\n    --conf spark.driver.cores=1 \\\\\\n    --conf spark.driver.memory=1G \\\\\\n    --conf spark.executor.instances=1 \\\\\\n    --conf spark.executor.cores=1 \\\\\\n    --conf spark.executor.memory=1G \\\\\\n    --files ${raw_file_dir} \\\\\\n    --name reddit_preprocessing testing.py\\n\\n# $SPARK_HOME/bin/spark-submit \\\\\\n#     --master local \\\\\\n#     --files ${raw_file_dir} \\\\\\n#     --name reddit_preprocessing spark_reddit_preprocessing.py\\n\",\"resourceList\":[{\"id\":null,\"resourceName\":\"file:/dolphinscheduler/default/resources/testing.py\",\"res\":null}]}",
  "environmentConfig" : "export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3\nexport JAVA_HOME=/opt/java/openjdk\nexport PYSPARK_DRIVER_PYTHON=/bin/python3.11\nexport PYTHON_LAUNCHER=/bin/python3.11\nexport PYSPARK_PYTHON=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "spark preprocessing"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240424"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1296"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13210058002752"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240424044243"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "processing"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "547"
    },
    "raw_file_dir" : {
      "prop" : "raw_file_dir",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit/processing/500-20240423.json"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "547_1296",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"raw_file_dir\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"/local_storage/reddit/processing/500-20240423.json\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-547][TI-1296] - [INFO] 2024-04-24 04:42:43.985 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-547][TI-1296] - [INFO] 2024-04-24 04:42:43.986 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-547][TI-1296] - [INFO] 2024-04-24 04:42:43.986 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-547][TI-1296] - [INFO] 2024-04-24 04:42:43.990 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-547][TI-1296] - [INFO] 2024-04-24 04:42:43.991 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-547][TI-1296] - [INFO] 2024-04-24 04:42:43.992 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_91/547/1296 check successfully
[WI-547][TI-1296] - [INFO] 2024-04-24 04:42:43.993 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-547][TI-1296] - [INFO] 2024-04-24 04:42:43.995 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={file:/dolphinscheduler/default/resources/testing.py=ResourceContext.ResourceItem(resourceAbsolutePathInStorage=file:/dolphinscheduler/default/resources/testing.py, resourceRelativePath=testing.py, resourceAbsolutePathInLocal=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_91/547/1296/testing.py)})
[WI-547][TI-1296] - [INFO] 2024-04-24 04:42:43.996 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-547][TI-1296] - [INFO] 2024-04-24 04:42:43.996 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-547][TI-1296] - [INFO] 2024-04-24 04:42:43.997 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ ],
  "varPool" : null,
  "rawScript" : "$SPARK_HOME/bin/spark-submit \\\n    --master spark://spark-master:7077 \\\n    --deploy-mode client \\\n    --conf spark.driver.cores=1 \\\n    --conf spark.driver.memory=1G \\\n    --conf spark.executor.instances=1 \\\n    --conf spark.executor.cores=1 \\\n    --conf spark.executor.memory=1G \\\n    --files ${raw_file_dir} \\\n    --name reddit_preprocessing testing.py\n\n# $SPARK_HOME/bin/spark-submit \\\n#     --master local \\\n#     --files ${raw_file_dir} \\\n#     --name reddit_preprocessing spark_reddit_preprocessing.py\n",
  "resourceList" : [ {
    "id" : null,
    "resourceName" : "file:/dolphinscheduler/default/resources/testing.py",
    "res" : null
  } ]
}
[WI-547][TI-1296] - [INFO] 2024-04-24 04:42:43.997 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-547][TI-1296] - [INFO] 2024-04-24 04:42:43.997 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}] successfully
[WI-547][TI-1296] - [INFO] 2024-04-24 04:42:43.998 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-547][TI-1296] - [INFO] 2024-04-24 04:42:43.998 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-547][TI-1296] - [INFO] 2024-04-24 04:42:43.998 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-547][TI-1296] - [INFO] 2024-04-24 04:42:43.999 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-547][TI-1296] - [INFO] 2024-04-24 04:42:43.999 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-547][TI-1296] - [INFO] 2024-04-24 04:42:43.999 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export PYSPARK_DRIVER_PYTHON=/bin/python3.11
export PYTHON_LAUNCHER=/bin/python3.11
export PYSPARK_PYTHON=/bin/python3.11
$SPARK_HOME/bin/spark-submit \
    --master spark://spark-master:7077 \
    --deploy-mode client \
    --conf spark.driver.cores=1 \
    --conf spark.driver.memory=1G \
    --conf spark.executor.instances=1 \
    --conf spark.executor.cores=1 \
    --conf spark.executor.memory=1G \
    --files /local_storage/reddit/processing/500-20240423.json \
    --name reddit_preprocessing testing.py

# $SPARK_HOME/bin/spark-submit \
#     --master local \
#     --files /local_storage/reddit/processing/500-20240423.json \
#     --name reddit_preprocessing spark_reddit_preprocessing.py

[WI-547][TI-1296] - [INFO] 2024-04-24 04:42:43.999 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-547][TI-1296] - [INFO] 2024-04-24 04:42:43.999 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_91/547/1296/547_1296.sh
[WI-547][TI-1296] - [INFO] 2024-04-24 04:42:44.005 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 1081
[WI-0][TI-1296] - [INFO] 2024-04-24 04:42:44.380 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionRunningEvent(taskInstanceId=1296, processInstanceId=547, startTime=1713904963983, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, status=TaskExecutionStatus{code=1, desc='running'}, logPath=/opt/dolphinscheduler/logs/20240424/13201021801792/91/547/1296.log, executePath=null, processId=0, appIds=null, eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1296] - [INFO] 2024-04-24 04:42:44.387 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionRunningEvent(taskInstanceId=1296, processInstanceId=547, startTime=1713904963983, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, status=TaskExecutionStatus{code=1, desc='running'}, logPath=/opt/dolphinscheduler/logs/20240424/13201021801792/91/547/1296.log, executePath=null, processId=0, appIds=null, eventCreateTime=0, eventSendTime=1713904964379)
[WI-0][TI-1296] - [INFO] 2024-04-24 04:42:44.388 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionInfoEvent(taskInstanceId=1296, processInstanceId=547, startTime=1713904963983, workflowInstanceHost=172.18.0.10:5678, taskInstanceHost=172.18.1.1:1234, logPath=null, processId=0, eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1296] - [INFO] 2024-04-24 04:42:44.389 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionInfoEvent(taskInstanceId=1296, processInstanceId=547, startTime=1713904963983, workflowInstanceHost=172.18.0.10:5678, taskInstanceHost=172.18.1.1:1234, logPath=null, processId=0, eventCreateTime=0, eventSendTime=1713904964379)
[WI-0][TI-1296] - [INFO] 2024-04-24 04:42:44.996 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1296, success=true)
[WI-0][TI-0] - [INFO] 2024-04-24 04:42:45.006 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
[WI-0][TI-1296] - [INFO] 2024-04-24 04:42:45.008 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1296)
[WI-0][TI-1296] - [INFO] 2024-04-24 04:42:45.036 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1296, success=true)
[WI-0][TI-1296] - [INFO] 2024-04-24 04:42:45.053 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1296)
[WI-0][TI-0] - [INFO] 2024-04-24 04:42:45.792 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8398791540785498 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:42:46.857 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7476923076923077 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:42:47.863 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.891566265060241 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:42:48.108 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 04:42:48 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[WI-0][TI-0] - [INFO] 2024-04-24 04:42:50.111 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 04:42:49 INFO SparkContext: Running Spark version 3.5.1
	24/04/24 04:42:49 INFO SparkContext: OS info Linux, 6.5.0-28-generic, amd64
	24/04/24 04:42:49 INFO SparkContext: Java version 1.8.0_402
	24/04/24 04:42:49 INFO ResourceUtils: ==============================================================
	24/04/24 04:42:49 INFO ResourceUtils: No custom resources configured for spark.driver.
	24/04/24 04:42:49 INFO ResourceUtils: ==============================================================
	24/04/24 04:42:49 INFO SparkContext: Submitted application: reddit_preprocessing
	24/04/24 04:42:49 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
	24/04/24 04:42:49 INFO ResourceProfile: Limiting resource is cpus at 1 tasks per executor
	24/04/24 04:42:49 INFO ResourceProfileManager: Added ResourceProfile id: 0
	24/04/24 04:42:49 INFO SecurityManager: Changing view acls to: default
	24/04/24 04:42:49 INFO SecurityManager: Changing modify acls to: default
	24/04/24 04:42:49 INFO SecurityManager: Changing view acls groups to: 
	24/04/24 04:42:49 INFO SecurityManager: Changing modify acls groups to: 
	24/04/24 04:42:49 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: default; groups with view permissions: EMPTY; users with modify permissions: default; groups with modify permissions: EMPTY
	24/04/24 04:42:50 INFO Utils: Successfully started service 'sparkDriver' on port 40139.
[WI-0][TI-0] - [INFO] 2024-04-24 04:42:50.116 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8533333333333333 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:42:51.120 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 04:42:50 INFO SparkEnv: Registering MapOutputTracker
	24/04/24 04:42:50 INFO SparkEnv: Registering BlockManagerMaster
	24/04/24 04:42:50 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
	24/04/24 04:42:50 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
	24/04/24 04:42:50 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
	24/04/24 04:42:50 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-a0ddd2e0-99d7-48a6-bf09-9a94cf31f7ab
	24/04/24 04:42:50 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
	24/04/24 04:42:50 INFO SparkEnv: Registering OutputCommitCoordinator
	24/04/24 04:42:50 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
[WI-0][TI-0] - [INFO] 2024-04-24 04:42:51.147 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8639240506329113 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:42:52.143 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 04:42:51 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
	24/04/24 04:42:51 INFO Utils: Successfully started service 'SparkUI' on port 4041.
	24/04/24 04:42:51 INFO SparkContext: Added file file:///local_storage/reddit/processing/500-20240423.json at spark://5afbfd5249fc:40139/files/500-20240423.json with timestamp 1713904969233
	24/04/24 04:42:51 INFO Utils: Copying /local_storage/reddit/processing/500-20240423.json to /tmp/spark-2cda37ab-1568-47d4-8e39-e6ab29613bff/userFiles-2754d12b-fb1d-4a35-a109-67fdb273c810/500-20240423.json
[WI-0][TI-0] - [INFO] 2024-04-24 04:42:52.159 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8878787878787878 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:42:53.157 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 04:42:52 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
	24/04/24 04:42:52 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.4:7077 after 117 ms (0 ms spent in bootstraps)
	24/04/24 04:42:52 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20240423204252-0003
	24/04/24 04:42:52 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36411.
	24/04/24 04:42:52 INFO NettyBlockTransferService: Server created on 5afbfd5249fc:36411
	24/04/24 04:42:52 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
	24/04/24 04:42:52 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 5afbfd5249fc, 36411, None)
	24/04/24 04:42:52 INFO BlockManagerMasterEndpoint: Registering block manager 5afbfd5249fc:36411 with 366.3 MiB RAM, BlockManagerId(driver, 5afbfd5249fc, 36411, None)
	24/04/24 04:42:52 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 5afbfd5249fc, 36411, None)
	24/04/24 04:42:52 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 5afbfd5249fc, 36411, None)
[WI-0][TI-0] - [INFO] 2024-04-24 04:42:54.167 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 04:42:53 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
	
	[
	    {"name": "t3_abc123", "author": "user1", "body": "Sample comment 1", "permalink": "/r/subreddit1/post/abc123", "unix_time": 1619520000},
	    {"name": "t1_def456", "author": "user2", "body": "Sample comment 2", "permalink": "/r/subreddit2/post/def456", "unix_time": 1619521000}
	]
	
	24/04/24 04:42:53 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
	24/04/24 04:42:53 INFO SharedState: Warehouse path is 'file:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_91/547/1296/spark-warehouse'.
[WI-0][TI-0] - [INFO] 2024-04-24 04:42:55.212 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7281553398058251 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:42:57.246 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8297213622291022 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:42:58.265 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7248520710059171 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:42:59.278 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7643504531722054 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:43:00.296 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9090909090909092 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:43:02.363 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9774647887323944 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:43:05.523 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8844884488448845 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:43:06.353 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 04:43:06 INFO CodeGenerator: Code generated in 509.259559 ms
[WI-0][TI-0] - [INFO] 2024-04-24 04:43:07.355 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 04:43:06 INFO SparkContext: Starting job: json at NativeMethodAccessorImpl.java:0
	24/04/24 04:43:06 INFO DAGScheduler: Got job 0 (json at NativeMethodAccessorImpl.java:0) with 2 output partitions
	24/04/24 04:43:06 INFO DAGScheduler: Final stage: ResultStage 0 (json at NativeMethodAccessorImpl.java:0)
	24/04/24 04:43:06 INFO DAGScheduler: Parents of final stage: List()
	24/04/24 04:43:06 INFO DAGScheduler: Missing parents: List()
	24/04/24 04:43:06 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[6] at json at NativeMethodAccessorImpl.java:0), which has no missing parents
	24/04/24 04:43:06 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 20.9 KiB, free 366.3 MiB)
	24/04/24 04:43:07 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 10.2 KiB, free 366.3 MiB)
	24/04/24 04:43:07 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 5afbfd5249fc:36411 (size: 10.2 KiB, free: 366.3 MiB)
	24/04/24 04:43:07 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1585
	24/04/24 04:43:07 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (MapPartitionsRDD[6] at json at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
	24/04/24 04:43:07 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks resource profile 0
[WI-0][TI-0] - [INFO] 2024-04-24 04:43:07.600 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7181008902077152 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:43:22.377 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 04:43:22 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
[WI-0][TI-0] - [INFO] 2024-04-24 04:43:37.392 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 04:43:37 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
[WI-0][TI-0] - [ERROR] 2024-04-24 04:43:39.216 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[279] - Parse var pool error
java.io.IOException: Stream closed
	at java.io.BufferedInputStream.getBufIfOpen(BufferedInputStream.java:170)
	at java.io.BufferedInputStream.read1(BufferedInputStream.java:283)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:345)
	at sun.nio.cs.StreamDecoder.readBytes(StreamDecoder.java:284)
	at sun.nio.cs.StreamDecoder.implRead(StreamDecoder.java:326)
	at sun.nio.cs.StreamDecoder.read(StreamDecoder.java:178)
	at java.io.InputStreamReader.read(InputStreamReader.java:184)
	at java.io.BufferedReader.fill(BufferedReader.java:161)
	at java.io.BufferedReader.readLine(BufferedReader.java:324)
	at java.io.BufferedReader.readLine(BufferedReader.java:389)
	at org.apache.dolphinscheduler.plugin.task.api.AbstractCommandExecutor.lambda$parseProcessOutput$1(AbstractCommandExecutor.java:273)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
[WI-0][TI-0] - [INFO] 2024-04-24 04:43:39.409 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 04:43:39 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20240423204252-0003/0 on worker-20240423200818-172.18.0.6-42177 (172.18.0.6:42177) with 1 core(s)
	24/04/24 04:43:39 INFO StandaloneSchedulerBackend: Granted executor ID app-20240423204252-0003/0 on hostPort 172.18.0.6:42177 with 1 core(s), 1024.0 MiB RAM
	24/04/24 04:43:39 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20240423204252-0003/1 on worker-20240423200818-172.18.0.6-42177 (172.18.0.6:42177) with 1 core(s)
	24/04/24 04:43:39 INFO StandaloneSchedulerBackend: Granted executor ID app-20240423204252-0003/1 on hostPort 172.18.0.6:42177 with 1 core(s), 1024.0 MiB RAM
[WI-546][TI-1292] - [INFO] 2024-04-24 04:43:39.528 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has killed. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/546/1292, processId:841 ,exitStatusCode:137 ,processWaitForStatus:true ,processExitValue:137
[WI-546][TI-1292] - [INFO] 2024-04-24 04:43:39.536 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-546][TI-1292] - [INFO] 2024-04-24 04:43:39.536 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-546][TI-1292] - [INFO] 2024-04-24 04:43:39.537 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-546][TI-1292] - [INFO] 2024-04-24 04:43:39.537 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-546][TI-1292] - [INFO] 2024-04-24 04:43:39.555 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: KILL to master : 172.18.1.1:1234
[WI-546][TI-1292] - [INFO] 2024-04-24 04:43:39.557 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-546][TI-1292] - [INFO] 2024-04-24 04:43:39.558 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/546/1292
[WI-0][TI-1292] - [INFO] 2024-04-24 04:43:39.558 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1292, processInstanceId=546, status=9, startTime=1713904461692, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, logPath=/opt/dolphinscheduler/logs/20240424/13201021801792/90/546/1292.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/546/1292, endTime=1713905019537, processId=841, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], eventCreateTime=0, eventSendTime=0)
[WI-546][TI-1292] - [INFO] 2024-04-24 04:43:39.571 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/546/1292
[WI-546][TI-1292] - [INFO] 2024-04-24 04:43:39.596 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-1292] - [INFO] 2024-04-24 04:43:39.619 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1292, processInstanceId=546, status=9, startTime=1713904461692, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, logPath=/opt/dolphinscheduler/logs/20240424/13201021801792/90/546/1292.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/546/1292, endTime=1713905019537, processId=841, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], eventCreateTime=0, eventSendTime=1713905019555)
[WI-0][TI-0] - [INFO] 2024-04-24 04:43:40.411 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 04:43:39 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20240423204252-0003/0 is now RUNNING
	24/04/24 04:43:39 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20240423204252-0003/1 is now RUNNING
[WI-0][TI-0] - [INFO] 2024-04-24 04:43:40.746 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.0087463556851313 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:43:41.799 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9462686567164178 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:43:42.800 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8166666666666667 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:43:43.804 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7956204379562044 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:43:44.807 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8364312267657993 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:43:45.813 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.725925925925926 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:43:46.517 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 04:43:45 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.6:39272) with ID 0,  ResourceProfileId 0
	24/04/24 04:43:45 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.6:39258) with ID 1,  ResourceProfileId 0
	24/04/24 04:43:46 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.6:35211 with 434.4 MiB RAM, BlockManagerId(0, 172.18.0.6, 35211, None)
	24/04/24 04:43:46 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.6:46567 with 434.4 MiB RAM, BlockManagerId(1, 172.18.0.6, 46567, None)
	24/04/24 04:43:46 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.6, executor 0, partition 0, PROCESS_LOCAL, 7776 bytes) 
	24/04/24 04:43:46 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1) (172.18.0.6, executor 1, partition 1, PROCESS_LOCAL, 8093 bytes) 
[WI-0][TI-1281] - [INFO] 2024-04-24 04:44:09.726 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1281, processInstanceId=543, status=9, startTime=1713903509183, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, logPath=/opt/dolphinscheduler/logs/20240424/13201021801792/90/543/1281.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/543/1281, endTime=1713904084494, processId=300, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], eventCreateTime=0, eventSendTime=1713904748731)
[WI-0][TI-1281] - [INFO] 2024-04-24 04:44:09.734 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1281, processInstanceId=543, status=9, startTime=1713903509183, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, logPath=/opt/dolphinscheduler/logs/20240424/13201021801792/90/543/1281.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/543/1281, endTime=1713904084494, processId=300, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], eventCreateTime=0, eventSendTime=1713905049726)
[WI-0][TI-0] - [INFO] 2024-04-24 04:45:31.141 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8342857142857143 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:45:35.162 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7865497076023391 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:45:36.184 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9051724137931035 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:45:37.186 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8215384615384616 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-1292] - [INFO] 2024-04-24 04:48:39.798 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1292, processInstanceId=546, status=9, startTime=1713904461692, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, logPath=/opt/dolphinscheduler/logs/20240424/13201021801792/90/546/1292.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/546/1292, endTime=1713905019537, processId=841, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], eventCreateTime=0, eventSendTime=1713905019555)
[WI-0][TI-1292] - [INFO] 2024-04-24 04:48:39.802 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1292, processInstanceId=546, status=9, startTime=1713904461692, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, logPath=/opt/dolphinscheduler/logs/20240424/13201021801792/90/546/1292.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/546/1292, endTime=1713905019537, processId=841, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], eventCreateTime=0, eventSendTime=1713905319798)
[WI-0][TI-1281] - [INFO] 2024-04-24 04:49:09.834 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1281, processInstanceId=543, status=9, startTime=1713903509183, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, logPath=/opt/dolphinscheduler/logs/20240424/13201021801792/90/543/1281.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/543/1281, endTime=1713904084494, processId=300, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], eventCreateTime=0, eventSendTime=1713905049726)
[WI-0][TI-1281] - [INFO] 2024-04-24 04:49:09.837 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1281, processInstanceId=543, status=9, startTime=1713903509183, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, logPath=/opt/dolphinscheduler/logs/20240424/13201021801792/90/543/1281.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/543/1281, endTime=1713904084494, processId=300, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], eventCreateTime=0, eventSendTime=1713905349834)
[WI-0][TI-0] - [INFO] 2024-04-24 04:51:35.058 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 04:51:34 ERROR StandaloneSchedulerBackend: Application has been killed. Reason: Master removed our application: KILLED
	24/04/24 04:51:34 INFO TaskSchedulerImpl: Cancelling stage 0
	24/04/24 04:51:34 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage cancelled: Job aborted due to stage failure: Master removed our application: KILLED
	24/04/24 04:51:34 INFO SparkContext: SparkContext is stopping with exitCode 0.
	24/04/24 04:51:34 INFO TaskSchedulerImpl: Stage 0 was cancelled
	24/04/24 04:51:34 INFO DAGScheduler: ResultStage 0 (json at NativeMethodAccessorImpl.java:0) failed in 508.018 s due to Job aborted due to stage failure: Master removed our application: KILLED
	24/04/24 04:51:34 INFO DAGScheduler: Job 0 failed: json at NativeMethodAccessorImpl.java:0, took 508.263360 s
	24/04/24 04:51:34 INFO SparkUI: Stopped Spark web UI at http://5afbfd5249fc:4041
	24/04/24 04:51:34 INFO StandaloneSchedulerBackend: Shutting down all executors
	24/04/24 04:51:34 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Asking each executor to shut down
	24/04/24 04:51:34 ERROR Inbox: Ignoring error
	java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@99852ee rejected from java.util.concurrent.ScheduledThreadPoolExecutor@2a099b13[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0]
		at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2063)
		at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:830)
		at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)
		at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
		at org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend$StandaloneDriverEndpoint.$anonfun$onDisconnected$1(StandaloneSchedulerBackend.scala:346)
		at scala.Option.foreach(Option.scala:407)
		at org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend$StandaloneDriverEndpoint.onDisconnected(StandaloneSchedulerBackend.scala:313)
		at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:141)
		at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
		at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
		at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
		at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
		at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
		at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
		at java.lang.Thread.run(Thread.java:750)
	24/04/24 04:51:34 ERROR Utils: Uncaught exception in thread stop-spark-context
	org.apache.spark.SparkException: Exception thrown in awaitResult: 
		at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
		at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
		at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
		at org.apache.spark.deploy.client.StandaloneAppClient.stop(StandaloneAppClient.scala:288)
		at org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend.org$apache$spark$scheduler$cluster$StandaloneSchedulerBackend$$stop(StandaloneSchedulerBackend.scala:275)
		at org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend.stop(StandaloneSchedulerBackend.scala:142)
		at org.apache.spark.scheduler.SchedulerBackend.stop(SchedulerBackend.scala:33)
		at org.apache.spark.scheduler.SchedulerBackend.stop$(SchedulerBackend.scala:33)
		at org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend.stop(CoarseGrainedSchedulerBackend.scala:54)
		at org.apache.spark.scheduler.TaskSchedulerImpl.$anonfun$stop$2(TaskSchedulerImpl.scala:992)
		at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1375)
		at org.apache.spark.scheduler.TaskSchedulerImpl.stop(TaskSchedulerImpl.scala:992)
		at org.apache.spark.scheduler.DAGScheduler.$anonfun$stop$4(DAGScheduler.scala:2976)
		at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1375)
		at org.apache.spark.scheduler.DAGScheduler.stop(DAGScheduler.scala:2976)
		at org.apache.spark.SparkContext.$anonfun$stop$12(SparkContext.scala:2263)
		at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1375)
		at org.apache.spark.SparkContext.stop(SparkContext.scala:2263)
		at org.apache.spark.SparkContext.stop(SparkContext.scala:2216)
		at org.apache.spark.SparkContext$$anon$3.run(SparkContext.scala:2203)
	Caused by: org.apache.spark.SparkException: Could not find AppClient.
		at org.apache.spark.rpc.netty.Dispatcher.postMessage(Dispatcher.scala:178)
		at org.apache.spark.rpc.netty.Dispatcher.postLocalMessage(Dispatcher.scala:144)
		at org.apache.spark.rpc.netty.NettyRpcEnv.askAbortable(NettyRpcEnv.scala:242)
		at org.apache.spark.rpc.netty.NettyRpcEndpointRef.askAbortable(NettyRpcEnv.scala:554)
		at org.apache.spark.rpc.netty.NettyRpcEndpointRef.ask(NettyRpcEnv.scala:558)
		at org.apache.spark.rpc.RpcEndpointRef.ask(RpcEndpointRef.scala:72)
		... 17 more
[WI-0][TI-0] - [INFO] 2024-04-24 04:51:36.071 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 04:51:35 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
	Traceback (most recent call last):
	  File "/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_91/547/1296/testing.py", line 38, in <module>
	    raw_df = spark.read.json(sc.parallelize([example_json]))
	             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
	  File "/opt/spark-3.5.1-bin-hadoop3/python/lib/pyspark.zip/pyspark/sql/readwriter.py", line 440, in json
	  File "/opt/spark-3.5.1-bin-hadoop3/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
	  File "/opt/spark-3.5.1-bin-hadoop3/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 179, in deco
	  File "/opt/spark-3.5.1-bin-hadoop3/python/lib/py4j-0.10.9.7-src.zip/py4j/protocol.py", line 326, in get_return_value
	py4j.protocol.Py4JJavaError24/04/24 04:51:35 INFO MemoryStore: MemoryStore cleared
	24/04/24 04:51:35 INFO BlockManager: BlockManager stopped
	: An error occurred while calling o32.json.
	: org.apache.spark.SparkException: Job aborted due to stage failure: Master removed our application: KILLED
		at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)
		at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)
		at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)
		at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
		at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
		at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
		at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)
		at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)
		at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)
		at scala.Option.foreach(Option.scala:407)
		at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)
		at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)
		at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)
		at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)
		at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
		at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:989)
		at org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)
		at org.apache.spark.SparkContext.runJob(SparkContext.scala:2493)
		at org.apache.spark.sql.catalyst.json.JsonInferSchema.infer(JsonInferSchema.scala:120)
		at org.apache.spark.sql.execution.datasources.json.TextInputJsonDataSource$.$anonfun$inferFromDataset$5(JsonDataSource.scala:109)
		at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)
		at org.apache.spark.sql.execution.datasources.json.TextInputJsonDataSource$.inferFromDataset(JsonDataSource.scala:109)
		at org.apache.spark.sql.DataFrameReader.$anonfun$json$4(DataFrameReader.scala:416)
		at scala.Option.getOrElse(Option.scala:189)
		at org.apache.spark.sql.DataFrameReader.json(DataFrameReader.scala:416)
		at org.apache.spark.sql.DataFrameReader.json(DataFrameReader.scala:391)
		at org.apache.spark.sql.DataFrameReader.json(DataFrameReader.scala:377)
		at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
		at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
		at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
		at java.lang.reflect.Method.invoke(Method.java:498)
		at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
		at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
		at py4j.Gateway.invoke(Gateway.java:282)
		at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
		at py4j.commands.CallCommand.execute(CallCommand.java:79)
		at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
		at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
		at java.lang.Thread.run(Thread.java:750)
	
	24/04/24 04:51:35 INFO BlockManagerMaster: BlockManagerMaster stopped
	24/04/24 04:51:35 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
	24/04/24 04:51:35 INFO SparkContext: Successfully stopped SparkContext
	24/04/24 04:51:35 INFO ShutdownHookManager: Shutdown hook called
	24/04/24 04:51:35 INFO ShutdownHookManager: Deleting directory /tmp/spark-2cda37ab-1568-47d4-8e39-e6ab29613bff/pyspark-036b1f6d-439b-4db9-a33c-3a1e4d94df43
	24/04/24 04:51:35 INFO ShutdownHookManager: Deleting directory /tmp/spark-2cda37ab-1568-47d4-8e39-e6ab29613bff
	24/04/24 04:51:35 INFO ShutdownHookManager: Deleting directory /tmp/spark-b39ae126-f0aa-4d64-afd9-d11b38ee2c13
[WI-0][TI-0] - [INFO] 2024-04-24 04:51:36.178 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9739884393063585 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-547][TI-1296] - [INFO] 2024-04-24 04:51:37.074 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_91/547/1296, processId:1081 ,exitStatusCode:1 ,processWaitForStatus:true ,processExitValue:1
[WI-547][TI-1296] - [INFO] 2024-04-24 04:51:37.076 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-547][TI-1296] - [INFO] 2024-04-24 04:51:37.076 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-547][TI-1296] - [INFO] 2024-04-24 04:51:37.076 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-547][TI-1296] - [INFO] 2024-04-24 04:51:37.077 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-547][TI-1296] - [INFO] 2024-04-24 04:51:37.120 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: FAILURE to master : 172.18.1.1:1234
[WI-547][TI-1296] - [INFO] 2024-04-24 04:51:37.120 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-547][TI-1296] - [INFO] 2024-04-24 04:51:37.121 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_91/547/1296
[WI-547][TI-1296] - [INFO] 2024-04-24 04:51:37.124 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_91/547/1296
[WI-547][TI-1296] - [INFO] 2024-04-24 04:51:37.126 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-1296] - [INFO] 2024-04-24 04:51:38.082 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1296, processInstanceId=547, status=6, startTime=1713904963983, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, logPath=/opt/dolphinscheduler/logs/20240424/13201021801792/91/547/1296.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_91/547/1296, endTime=1713905497077, processId=1081, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1296] - [INFO] 2024-04-24 04:51:38.086 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1296, processInstanceId=547, status=6, startTime=1713904963983, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, logPath=/opt/dolphinscheduler/logs/20240424/13201021801792/91/547/1296.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_91/547/1296, endTime=1713905497077, processId=1081, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], eventCreateTime=0, eventSendTime=1713905498082)
[WI-0][TI-1296] - [INFO] 2024-04-24 04:51:38.088 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1296, success=true)
[WI-0][TI-1296] - [INFO] 2024-04-24 04:51:38.092 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1296, success=true)
[WI-0][TI-0] - [INFO] 2024-04-24 04:51:39.234 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7008547008547008 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:51:40.280 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7514619883040936 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:51:42.312 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7084548104956269 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:51:46.357 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7923976608187134 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:51:50.384 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8660714285714286 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:51:51.410 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8147058823529412 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:51:57.308 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1297, taskName=search for intake JSON files, firstSubmitTime=1713905517281, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.10:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=91, appIds=null, processInstanceId=548, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"processing"}], executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":""}],"rawScript":"# find 1 raw file in the folder\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\n\n# check if raw_file_dir is empty, then set raw_file_dir to null\nif [ -z \"$raw_file_dir\" ]; then\n    raw_file_dir=null\nfi\n\necho \"#{setValue(raw_file_dir=${raw_file_dir})}\"","resourceList":[]}, environmentConfig=export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='search for intake JSON files'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240424'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1297'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13340113777664'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240424045157'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='processing'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='548'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240423'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=null, dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-548][TI-1297] - [INFO] 2024-04-24 04:51:57.310 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: search for intake JSON files to wait queue success
[WI-548][TI-1297] - [INFO] 2024-04-24 04:51:57.310 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-548][TI-1297] - [INFO] 2024-04-24 04:51:57.324 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-548][TI-1297] - [INFO] 2024-04-24 04:51:57.325 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-548][TI-1297] - [INFO] 2024-04-24 04:51:57.325 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-548][TI-1297] - [INFO] 2024-04-24 04:51:57.325 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713905517325
[WI-548][TI-1297] - [INFO] 2024-04-24 04:51:57.326 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 548_1297
[WI-548][TI-1297] - [INFO] 2024-04-24 04:51:57.328 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1297,
  "taskName" : "search for intake JSON files",
  "firstSubmitTime" : 1713905517281,
  "startTime" : 1713905517325,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.10:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240424/13201021801792/91/548/1297.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 91,
  "processInstanceId" : 548,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"processing\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[{\"prop\":\"raw_file_dir\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"\"}],\"rawScript\":\"# find 1 raw file in the folder\\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\\n\\n# check if raw_file_dir is empty, then set raw_file_dir to null\\nif [ -z \\\"$raw_file_dir\\\" ]; then\\n    raw_file_dir=null\\nfi\\n\\necho \\\"#{setValue(raw_file_dir=${raw_file_dir})}\\\"\",\"resourceList\":[]}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "search for intake JSON files"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240424"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1297"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13340113777664"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240424045157"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "processing"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "548"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "548_1297",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-548][TI-1297] - [INFO] 2024-04-24 04:51:57.329 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-548][TI-1297] - [INFO] 2024-04-24 04:51:57.330 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-548][TI-1297] - [INFO] 2024-04-24 04:51:57.331 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-548][TI-1297] - [INFO] 2024-04-24 04:51:57.357 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-548][TI-1297] - [INFO] 2024-04-24 04:51:57.359 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-548][TI-1297] - [INFO] 2024-04-24 04:51:57.361 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_91/548/1297 check successfully
[WI-548][TI-1297] - [INFO] 2024-04-24 04:51:57.361 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-548][TI-1297] - [INFO] 2024-04-24 04:51:57.361 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-548][TI-1297] - [INFO] 2024-04-24 04:51:57.362 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-548][TI-1297] - [INFO] 2024-04-24 04:51:57.362 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-548][TI-1297] - [INFO] 2024-04-24 04:51:57.362 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ {
    "prop" : "raw_file_dir",
    "direct" : "OUT",
    "type" : "VARCHAR",
    "value" : ""
  } ],
  "varPool" : null,
  "rawScript" : "# find 1 raw file in the folder\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\n\n# check if raw_file_dir is empty, then set raw_file_dir to null\nif [ -z \"$raw_file_dir\" ]; then\n    raw_file_dir=null\nfi\n\necho \"#{setValue(raw_file_dir=${raw_file_dir})}\"",
  "resourceList" : [ ]
}
[WI-548][TI-1297] - [INFO] 2024-04-24 04:51:57.362 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-548][TI-1297] - [INFO] 2024-04-24 04:51:57.362 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: null successfully
[WI-548][TI-1297] - [INFO] 2024-04-24 04:51:57.362 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-548][TI-1297] - [INFO] 2024-04-24 04:51:57.363 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-548][TI-1297] - [INFO] 2024-04-24 04:51:57.363 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-548][TI-1297] - [INFO] 2024-04-24 04:51:57.363 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-548][TI-1297] - [INFO] 2024-04-24 04:51:57.364 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-548][TI-1297] - [INFO] 2024-04-24 04:51:57.364 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export PYTHON_LAUNCHER=/bin/python3.11
# find 1 raw file in the folder
raw_file_dir=$(find /local_storage/reddit/processing -type f -name '*.json'| head -n 1)

# check if raw_file_dir is empty, then set raw_file_dir to null
if [ -z "$raw_file_dir" ]; then
    raw_file_dir=null
fi

echo "#{setValue(raw_file_dir=${raw_file_dir})}"
[WI-548][TI-1297] - [INFO] 2024-04-24 04:51:57.364 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-548][TI-1297] - [INFO] 2024-04-24 04:51:57.371 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_91/548/1297/548_1297.sh
[WI-548][TI-1297] - [INFO] 2024-04-24 04:51:57.386 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 1342
[WI-0][TI-1297] - [INFO] 2024-04-24 04:51:58.113 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1297, success=true)
[WI-0][TI-1297] - [INFO] 2024-04-24 04:51:58.120 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1297)
[WI-0][TI-0] - [INFO] 2024-04-24 04:51:58.390 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
	#{setValue(raw_file_dir=/local_storage/reddit/processing/500-20240423.json)}
[WI-548][TI-1297] - [INFO] 2024-04-24 04:51:58.399 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_91/548/1297, processId:1342 ,exitStatusCode:0 ,processWaitForStatus:true ,processExitValue:0
[WI-548][TI-1297] - [INFO] 2024-04-24 04:51:58.402 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-548][TI-1297] - [INFO] 2024-04-24 04:51:58.402 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-548][TI-1297] - [INFO] 2024-04-24 04:51:58.403 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-548][TI-1297] - [INFO] 2024-04-24 04:51:58.404 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-548][TI-1297] - [INFO] 2024-04-24 04:51:58.408 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: SUCCESS to master : 172.18.1.1:1234
[WI-548][TI-1297] - [INFO] 2024-04-24 04:51:58.409 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-548][TI-1297] - [INFO] 2024-04-24 04:51:58.409 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_91/548/1297
[WI-548][TI-1297] - [INFO] 2024-04-24 04:51:58.410 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_91/548/1297
[WI-548][TI-1297] - [INFO] 2024-04-24 04:51:58.411 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-1297] - [INFO] 2024-04-24 04:51:59.144 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1297, success=true)
[WI-0][TI-1297] - [INFO] 2024-04-24 04:51:59.154 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1297, processInstanceId=548, status=7, startTime=1713905517325, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, logPath=/opt/dolphinscheduler/logs/20240424/13201021801792/91/548/1297.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_91/548/1297, endTime=1713905518403, processId=1342, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1297] - [INFO] 2024-04-24 04:51:59.167 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1297, processInstanceId=548, status=7, startTime=1713905517325, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, logPath=/opt/dolphinscheduler/logs/20240424/13201021801792/91/548/1297.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_91/548/1297, endTime=1713905518403, processId=1342, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], eventCreateTime=0, eventSendTime=1713905519125)
[WI-0][TI-1297] - [WARN] 2024-04-24 04:51:59.167 +0800 o.a.d.s.w.m.MessageRetryRunner:[139] - Retry send message to master error
java.util.ConcurrentModificationException: null
	at java.util.ArrayList$Itr.checkForComodification(ArrayList.java:911)
	at java.util.ArrayList$Itr.next(ArrayList.java:861)
	at org.apache.dolphinscheduler.server.worker.message.MessageRetryRunner.run(MessageRetryRunner.java:127)
[WI-0][TI-0] - [INFO] 2024-04-24 04:51:59.689 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8299120234604105 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-1297] - [INFO] 2024-04-24 04:52:00.108 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1297, success=true)
[WI-0][TI-0] - [INFO] 2024-04-24 04:52:00.246 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1299, taskName=move to processing, firstSubmitTime=1713905520223, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.10:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=91, appIds=null, processInstanceId=548, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"processing"}], executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":""}],"rawScript":"# move file to the reddit processing folder\n# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error\nfilename=$(basename \"${raw_file_dir}\")\nif ! grep -q \"${REDDIT_HOME}/processing\" <<< \"${raw_file_dir}\"; then\n    mv ${raw_file_dir} ${REDDIT_HOME}/processing\nelse\n    echo JSON is already in processing\nfi\n\n# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing\necho \"#{setValue(raw_file_dir=${REDDIT_HOME}/processing/${filename})}\"","resourceList":[]}, environmentConfig=export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='move to processing'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240424'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1299'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13340390094208'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240424045200'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='processing'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='548'}, raw_file_dir=Property{prop='raw_file_dir', direct=IN, type=VARCHAR, value='/local_storage/reddit/processing/500-20240423.json'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240423'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-548][TI-1299] - [INFO] 2024-04-24 04:52:00.249 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: move to processing to wait queue success
[WI-548][TI-1299] - [INFO] 2024-04-24 04:52:00.249 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-548][TI-1299] - [INFO] 2024-04-24 04:52:00.252 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-548][TI-1299] - [INFO] 2024-04-24 04:52:00.253 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-548][TI-1299] - [INFO] 2024-04-24 04:52:00.253 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-548][TI-1299] - [INFO] 2024-04-24 04:52:00.253 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713905520253
[WI-548][TI-1299] - [INFO] 2024-04-24 04:52:00.253 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 548_1299
[WI-548][TI-1299] - [INFO] 2024-04-24 04:52:00.253 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1299,
  "taskName" : "move to processing",
  "firstSubmitTime" : 1713905520223,
  "startTime" : 1713905520253,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.10:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240424/13201021801792/91/548/1299.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 91,
  "processInstanceId" : 548,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"processing\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[{\"prop\":\"raw_file_dir\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"\"}],\"rawScript\":\"# move file to the reddit processing folder\\n# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error\\nfilename=$(basename \\\"${raw_file_dir}\\\")\\nif ! grep -q \\\"${REDDIT_HOME}/processing\\\" <<< \\\"${raw_file_dir}\\\"; then\\n    mv ${raw_file_dir} ${REDDIT_HOME}/processing\\nelse\\n    echo JSON is already in processing\\nfi\\n\\n# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing\\necho \\\"#{setValue(raw_file_dir=${REDDIT_HOME}/processing/${filename})}\\\"\",\"resourceList\":[]}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "move to processing"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240424"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1299"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13340390094208"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240424045200"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "processing"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "548"
    },
    "raw_file_dir" : {
      "prop" : "raw_file_dir",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit/processing/500-20240423.json"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "548_1299",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"raw_file_dir\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"/local_storage/reddit/processing/500-20240423.json\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-548][TI-1299] - [INFO] 2024-04-24 04:52:00.254 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-548][TI-1299] - [INFO] 2024-04-24 04:52:00.254 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-548][TI-1299] - [INFO] 2024-04-24 04:52:00.254 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-548][TI-1299] - [INFO] 2024-04-24 04:52:00.262 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-548][TI-1299] - [INFO] 2024-04-24 04:52:00.263 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-548][TI-1299] - [INFO] 2024-04-24 04:52:00.264 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_91/548/1299 check successfully
[WI-548][TI-1299] - [INFO] 2024-04-24 04:52:00.264 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-548][TI-1299] - [INFO] 2024-04-24 04:52:00.264 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-548][TI-1299] - [INFO] 2024-04-24 04:52:00.265 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-548][TI-1299] - [INFO] 2024-04-24 04:52:00.267 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-548][TI-1299] - [INFO] 2024-04-24 04:52:00.267 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ {
    "prop" : "raw_file_dir",
    "direct" : "OUT",
    "type" : "VARCHAR",
    "value" : ""
  } ],
  "varPool" : null,
  "rawScript" : "# move file to the reddit processing folder\n# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error\nfilename=$(basename \"${raw_file_dir}\")\nif ! grep -q \"${REDDIT_HOME}/processing\" <<< \"${raw_file_dir}\"; then\n    mv ${raw_file_dir} ${REDDIT_HOME}/processing\nelse\n    echo JSON is already in processing\nfi\n\n# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing\necho \"#{setValue(raw_file_dir=${REDDIT_HOME}/processing/${filename})}\"",
  "resourceList" : [ ]
}
[WI-548][TI-1299] - [INFO] 2024-04-24 04:52:00.269 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-548][TI-1299] - [INFO] 2024-04-24 04:52:00.269 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}] successfully
[WI-548][TI-1299] - [INFO] 2024-04-24 04:52:00.269 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-548][TI-1299] - [INFO] 2024-04-24 04:52:00.269 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-548][TI-1299] - [INFO] 2024-04-24 04:52:00.269 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-548][TI-1299] - [INFO] 2024-04-24 04:52:00.270 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-548][TI-1299] - [INFO] 2024-04-24 04:52:00.270 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-548][TI-1299] - [INFO] 2024-04-24 04:52:00.270 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export PYTHON_LAUNCHER=/bin/python3.11
# move file to the reddit processing folder
# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error
filename=$(basename "/local_storage/reddit/processing/500-20240423.json")
if ! grep -q "/local_storage/reddit/processing" <<< "/local_storage/reddit/processing/500-20240423.json"; then
    mv /local_storage/reddit/processing/500-20240423.json /local_storage/reddit/processing
else
    echo JSON is already in processing
fi

# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing
echo "#{setValue(raw_file_dir=/local_storage/reddit/processing/${filename})}"
[WI-548][TI-1299] - [INFO] 2024-04-24 04:52:00.271 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-548][TI-1299] - [INFO] 2024-04-24 04:52:00.271 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_91/548/1299/548_1299.sh
[WI-548][TI-1299] - [INFO] 2024-04-24 04:52:00.281 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 1355
[WI-0][TI-0] - [INFO] 2024-04-24 04:52:00.289 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
[WI-0][TI-0] - [INFO] 2024-04-24 04:52:00.717 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7391304347826086 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-1299] - [INFO] 2024-04-24 04:52:01.117 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1299, success=true)
[WI-0][TI-1299] - [INFO] 2024-04-24 04:52:01.159 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1299)
[WI-0][TI-0] - [INFO] 2024-04-24 04:52:01.376 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	JSON is already in processing
	#{setValue(raw_file_dir=/local_storage/reddit/processing/500-20240423.json)}
[WI-548][TI-1299] - [INFO] 2024-04-24 04:52:01.381 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_91/548/1299, processId:1355 ,exitStatusCode:0 ,processWaitForStatus:true ,processExitValue:0
[WI-548][TI-1299] - [INFO] 2024-04-24 04:52:01.414 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-548][TI-1299] - [INFO] 2024-04-24 04:52:01.415 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-548][TI-1299] - [INFO] 2024-04-24 04:52:01.415 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-548][TI-1299] - [INFO] 2024-04-24 04:52:01.416 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-548][TI-1299] - [INFO] 2024-04-24 04:52:01.423 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: SUCCESS to master : 172.18.1.1:1234
[WI-548][TI-1299] - [INFO] 2024-04-24 04:52:01.424 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-548][TI-1299] - [INFO] 2024-04-24 04:52:01.426 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_91/548/1299
[WI-548][TI-1299] - [INFO] 2024-04-24 04:52:01.431 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_91/548/1299
[WI-548][TI-1299] - [INFO] 2024-04-24 04:52:01.431 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-1299] - [INFO] 2024-04-24 04:52:02.125 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1299, success=true)
[WI-0][TI-0] - [INFO] 2024-04-24 04:52:02.312 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1300, taskName=spark preprocessing, firstSubmitTime=1713905522284, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.10:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=91, appIds=null, processInstanceId=548, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"processing"}], executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[],"rawScript":"$SPARK_HOME/bin/spark-submit \\\n    --master spark://spark-master:7077 \\\n    --deploy-mode client \\\n    --conf spark.driver.cores=1 \\\n    --conf spark.driver.memory=1G \\\n    --conf spark.executor.instances=1 \\\n    --conf spark.executor.cores=1 \\\n    --conf spark.executor.memory=1G \\\n    --files ${raw_file_dir} \\\n    --name reddit_preprocessing testing.py\n\n# $SPARK_HOME/bin/spark-submit \\\n#     --master local \\\n#     --files ${raw_file_dir} \\\n#     --name reddit_preprocessing spark_reddit_preprocessing.py\n","resourceList":[{"id":null,"resourceName":"file:/dolphinscheduler/default/resources/testing.py","res":null}]}, environmentConfig=export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export PYSPARK_DRIVER_PYTHON=/bin/python3.11
export PYTHON_LAUNCHER=/bin/python3.11
export PYSPARK_PYTHON=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='spark preprocessing'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240424'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1300'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13210058002752'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240424045202'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='processing'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='548'}, raw_file_dir=Property{prop='raw_file_dir', direct=IN, type=VARCHAR, value='/local_storage/reddit/processing/500-20240423.json'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240423'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-548][TI-1300] - [INFO] 2024-04-24 04:52:02.314 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: spark preprocessing to wait queue success
[WI-548][TI-1300] - [INFO] 2024-04-24 04:52:02.316 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-548][TI-1300] - [INFO] 2024-04-24 04:52:02.318 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-548][TI-1300] - [INFO] 2024-04-24 04:52:02.318 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-548][TI-1300] - [INFO] 2024-04-24 04:52:02.318 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-548][TI-1300] - [INFO] 2024-04-24 04:52:02.319 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713905522319
[WI-548][TI-1300] - [INFO] 2024-04-24 04:52:02.324 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 548_1300
[WI-548][TI-1300] - [INFO] 2024-04-24 04:52:02.325 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1300,
  "taskName" : "spark preprocessing",
  "firstSubmitTime" : 1713905522284,
  "startTime" : 1713905522319,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.10:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240424/13201021801792/91/548/1300.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 91,
  "processInstanceId" : 548,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"processing\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[],\"rawScript\":\"$SPARK_HOME/bin/spark-submit \\\\\\n    --master spark://spark-master:7077 \\\\\\n    --deploy-mode client \\\\\\n    --conf spark.driver.cores=1 \\\\\\n    --conf spark.driver.memory=1G \\\\\\n    --conf spark.executor.instances=1 \\\\\\n    --conf spark.executor.cores=1 \\\\\\n    --conf spark.executor.memory=1G \\\\\\n    --files ${raw_file_dir} \\\\\\n    --name reddit_preprocessing testing.py\\n\\n# $SPARK_HOME/bin/spark-submit \\\\\\n#     --master local \\\\\\n#     --files ${raw_file_dir} \\\\\\n#     --name reddit_preprocessing spark_reddit_preprocessing.py\\n\",\"resourceList\":[{\"id\":null,\"resourceName\":\"file:/dolphinscheduler/default/resources/testing.py\",\"res\":null}]}",
  "environmentConfig" : "export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3\nexport JAVA_HOME=/opt/java/openjdk\nexport PYSPARK_DRIVER_PYTHON=/bin/python3.11\nexport PYTHON_LAUNCHER=/bin/python3.11\nexport PYSPARK_PYTHON=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "spark preprocessing"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240424"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1300"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13210058002752"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240424045202"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "processing"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "548"
    },
    "raw_file_dir" : {
      "prop" : "raw_file_dir",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit/processing/500-20240423.json"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "548_1300",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"raw_file_dir\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"/local_storage/reddit/processing/500-20240423.json\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-548][TI-1300] - [INFO] 2024-04-24 04:52:02.326 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-548][TI-1300] - [INFO] 2024-04-24 04:52:02.326 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-548][TI-1300] - [INFO] 2024-04-24 04:52:02.326 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-548][TI-1300] - [INFO] 2024-04-24 04:52:02.337 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-548][TI-1300] - [INFO] 2024-04-24 04:52:02.338 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-548][TI-1300] - [INFO] 2024-04-24 04:52:02.339 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_91/548/1300 check successfully
[WI-548][TI-1300] - [INFO] 2024-04-24 04:52:02.340 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-548][TI-1300] - [INFO] 2024-04-24 04:52:02.344 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={file:/dolphinscheduler/default/resources/testing.py=ResourceContext.ResourceItem(resourceAbsolutePathInStorage=file:/dolphinscheduler/default/resources/testing.py, resourceRelativePath=testing.py, resourceAbsolutePathInLocal=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_91/548/1300/testing.py)})
[WI-548][TI-1300] - [INFO] 2024-04-24 04:52:02.345 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-548][TI-1300] - [INFO] 2024-04-24 04:52:02.349 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-548][TI-1300] - [INFO] 2024-04-24 04:52:02.352 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ ],
  "varPool" : null,
  "rawScript" : "$SPARK_HOME/bin/spark-submit \\\n    --master spark://spark-master:7077 \\\n    --deploy-mode client \\\n    --conf spark.driver.cores=1 \\\n    --conf spark.driver.memory=1G \\\n    --conf spark.executor.instances=1 \\\n    --conf spark.executor.cores=1 \\\n    --conf spark.executor.memory=1G \\\n    --files ${raw_file_dir} \\\n    --name reddit_preprocessing testing.py\n\n# $SPARK_HOME/bin/spark-submit \\\n#     --master local \\\n#     --files ${raw_file_dir} \\\n#     --name reddit_preprocessing spark_reddit_preprocessing.py\n",
  "resourceList" : [ {
    "id" : null,
    "resourceName" : "file:/dolphinscheduler/default/resources/testing.py",
    "res" : null
  } ]
}
[WI-548][TI-1300] - [INFO] 2024-04-24 04:52:02.353 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-548][TI-1300] - [INFO] 2024-04-24 04:52:02.353 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}] successfully
[WI-548][TI-1300] - [INFO] 2024-04-24 04:52:02.353 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-548][TI-1300] - [INFO] 2024-04-24 04:52:02.353 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-548][TI-1300] - [INFO] 2024-04-24 04:52:02.353 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-548][TI-1300] - [INFO] 2024-04-24 04:52:02.354 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-548][TI-1300] - [INFO] 2024-04-24 04:52:02.354 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-548][TI-1300] - [INFO] 2024-04-24 04:52:02.354 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export PYSPARK_DRIVER_PYTHON=/bin/python3.11
export PYTHON_LAUNCHER=/bin/python3.11
export PYSPARK_PYTHON=/bin/python3.11
$SPARK_HOME/bin/spark-submit \
    --master spark://spark-master:7077 \
    --deploy-mode client \
    --conf spark.driver.cores=1 \
    --conf spark.driver.memory=1G \
    --conf spark.executor.instances=1 \
    --conf spark.executor.cores=1 \
    --conf spark.executor.memory=1G \
    --files /local_storage/reddit/processing/500-20240423.json \
    --name reddit_preprocessing testing.py

# $SPARK_HOME/bin/spark-submit \
#     --master local \
#     --files /local_storage/reddit/processing/500-20240423.json \
#     --name reddit_preprocessing spark_reddit_preprocessing.py

[WI-548][TI-1300] - [INFO] 2024-04-24 04:52:02.354 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-548][TI-1300] - [INFO] 2024-04-24 04:52:02.354 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_91/548/1300/548_1300.sh
[WI-548][TI-1300] - [INFO] 2024-04-24 04:52:02.397 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 1367
[WI-0][TI-0] - [INFO] 2024-04-24 04:52:02.813 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9093406593406593 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-1300] - [INFO] 2024-04-24 04:52:03.160 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1300, success=true)
[WI-0][TI-1300] - [INFO] 2024-04-24 04:52:03.174 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionInfoEvent(taskInstanceId=1300, processInstanceId=548, startTime=1713905522319, workflowInstanceHost=172.18.0.10:5678, taskInstanceHost=172.18.1.1:1234, logPath=null, processId=0, eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1300] - [INFO] 2024-04-24 04:52:03.215 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionInfoEvent(taskInstanceId=1300, processInstanceId=548, startTime=1713905522319, workflowInstanceHost=172.18.0.10:5678, taskInstanceHost=172.18.1.1:1234, logPath=null, processId=0, eventCreateTime=0, eventSendTime=1713905523174)
[WI-0][TI-1300] - [INFO] 2024-04-24 04:52:03.231 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1300)
[WI-0][TI-1300] - [INFO] 2024-04-24 04:52:03.247 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1300)
[WI-0][TI-0] - [INFO] 2024-04-24 04:52:03.405 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
[WI-0][TI-0] - [INFO] 2024-04-24 04:52:03.834 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8863636363636362 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:52:04.848 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9634464751958224 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:52:05.849 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8526011560693642 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:52:06.854 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7957868047688407 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:52:07.421 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 04:52:07 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[WI-0][TI-0] - [INFO] 2024-04-24 04:52:07.856 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8849840255591055 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:52:08.861 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7465564738292011 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:52:09.434 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 04:52:09 INFO SparkContext: Running Spark version 3.5.1
	24/04/24 04:52:09 INFO SparkContext: OS info Linux, 6.5.0-28-generic, amd64
	24/04/24 04:52:09 INFO SparkContext: Java version 1.8.0_402
[WI-0][TI-0] - [INFO] 2024-04-24 04:52:09.893 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9331306990881458 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:52:10.455 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 04:52:09 INFO ResourceUtils: ==============================================================
	24/04/24 04:52:09 INFO SparkContext: Submitted application: reddit_preprocessing
	24/04/24 04:52:09 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
	24/04/24 04:52:09 INFO ResourceProfile: Limiting resource is cpus at 1 tasks per executor
	24/04/24 04:52:09 INFO ResourceProfileManager: Added ResourceProfile id: 0
	24/04/24 04:52:09 INFO SecurityManager: Changing view acls to: default
	24/04/24 04:52:09 INFO SecurityManager: Changing modify acls to: default
	24/04/24 04:52:09 INFO SecurityManager: Changing view acls groups to: 
	24/04/24 04:52:09 INFO SecurityManager: Changing modify acls groups to: 
	24/04/24 04:52:09 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: default; groups with view permissions: EMPTY; users with modify permissions: default; groups with modify permissions: EMPTY
[WI-0][TI-0] - [INFO] 2024-04-24 04:52:10.896 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8396501457725948 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:52:11.466 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 04:52:10 INFO Utils: Successfully started service 'sparkDriver' on port 40529.
	24/04/24 04:52:10 INFO SparkEnv: Registering MapOutputTracker
	24/04/24 04:52:11 INFO SparkEnv: Registering BlockManagerMaster
	24/04/24 04:52:11 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
	24/04/24 04:52:11 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
	24/04/24 04:52:11 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
	24/04/24 04:52:11 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-4a96a590-86fc-43a1-91cb-36cddc142da1
	24/04/24 04:52:11 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
	24/04/24 04:52:11 INFO SparkEnv: Registering OutputCommitCoordinator
[WI-0][TI-0] - [INFO] 2024-04-24 04:52:11.899 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7509293680297398 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:52:12.498 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 04:52:11 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
	24/04/24 04:52:11 INFO Utils: Successfully started service 'SparkUI' on port 4040.
	24/04/24 04:52:11 INFO SparkContext: Added file file:///local_storage/reddit/processing/500-20240423.json at spark://5afbfd5249fc:40529/files/500-20240423.json with timestamp 1713905529039
	24/04/24 04:52:11 INFO Utils: Copying /local_storage/reddit/processing/500-20240423.json to /tmp/spark-b44cf0ed-2460-4f2f-88eb-d67fdca195b6/userFiles-86ce6847-28b1-41a0-a0d2-ae072b665c89/500-20240423.json
	24/04/24 04:52:12 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
[WI-0][TI-0] - [INFO] 2024-04-24 04:52:12.904 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8895024538163827 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:52:13.506 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 04:52:12 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.4:7077 after 152 ms (0 ms spent in bootstraps)
	24/04/24 04:52:12 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20240423205212-0004
	24/04/24 04:52:12 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20240423205212-0004/0 on worker-20240423200818-172.18.0.6-42177 (172.18.0.6:42177) with 1 core(s)
	24/04/24 04:52:12 INFO StandaloneSchedulerBackend: Granted executor ID app-20240423205212-0004/0 on hostPort 172.18.0.6:42177 with 1 core(s), 1024.0 MiB RAM
	24/04/24 04:52:12 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20240423205212-0004/1 on worker-20240423200818-172.18.0.6-42177 (172.18.0.6:42177) with 1 core(s)
	24/04/24 04:52:12 INFO StandaloneSchedulerBackend: Granted executor ID app-20240423205212-0004/1 on hostPort 172.18.0.6:42177 with 1 core(s), 1024.0 MiB RAM
	24/04/24 04:52:13 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34741.
	24/04/24 04:52:13 INFO NettyBlockTransferService: Server created on 5afbfd5249fc:34741
	24/04/24 04:52:13 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
	24/04/24 04:52:13 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20240423205212-0004/0 is now RUNNING
	24/04/24 04:52:13 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20240423205212-0004/1 is now RUNNING
	24/04/24 04:52:13 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 5afbfd5249fc, 34741, None)
	24/04/24 04:52:13 INFO BlockManagerMasterEndpoint: Registering block manager 5afbfd5249fc:34741 with 366.3 MiB RAM, BlockManagerId(driver, 5afbfd5249fc, 34741, None)
	24/04/24 04:52:13 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 5afbfd5249fc, 34741, None)
	24/04/24 04:52:13 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 5afbfd5249fc, 34741, None)
[WI-0][TI-0] - [INFO] 2024-04-24 04:52:14.012 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9510891554928252 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:52:14.511 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 04:52:14 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
[WI-0][TI-0] - [INFO] 2024-04-24 04:52:15.047 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9896551724137931 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:52:15.515 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	
	[
	    {"name": "t3_abc123", "author": "user1", "body": "Sample comment 1", "permalink": "/r/subreddit1/post/abc123", "unix_time": 1619520000},
	    {"name": "t1_def456", "author": "user2", "body": "Sample comment 2", "permalink": "/r/subreddit2/post/def456", "unix_time": 1619521000}
	]
	
	24/04/24 04:52:15 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
	24/04/24 04:52:15 INFO SharedState: Warehouse path is 'file:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_91/548/1300/spark-warehouse'.
[WI-0][TI-0] - [INFO] 2024-04-24 04:52:16.053 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9130434782608696 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:52:17.064 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.87890625 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:52:18.098 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9367469879518073 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:52:19.107 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9116279069767441 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:52:20.117 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.968421052631579 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:52:21.144 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8839285714285714 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:52:22.145 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9310344827586208 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:52:22.624 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 04:52:21 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.6:59082) with ID 1,  ResourceProfileId 0
	24/04/24 04:52:21 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.6:35663 with 434.4 MiB RAM, BlockManagerId(1, 172.18.0.6, 35663, None)
[WI-0][TI-0] - [INFO] 2024-04-24 04:52:23.161 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9567723342939481 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:52:23.628 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 04:52:23 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.6:59084) with ID 0,  ResourceProfileId 0
	24/04/24 04:52:23 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.6:35237 with 434.4 MiB RAM, BlockManagerId(0, 172.18.0.6, 35237, None)
[WI-0][TI-0] - [INFO] 2024-04-24 04:52:24.194 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9413680781758957 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 04:52:26.632 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 04:52:25 INFO CodeGenerator: Code generated in 490.717498 ms
	24/04/24 04:52:25 INFO SparkContext: Starting job: json at NativeMethodAccessorImpl.java:0
	24/04/24 04:52:25 INFO DAGScheduler: Got job 0 (json at NativeMethodAccessorImpl.java:0) with 2 output partitions
	24/04/24 04:52:25 INFO DAGScheduler: Final stage: ResultStage 0 (json at NativeMethodAccessorImpl.java:0)
	24/04/24 04:52:25 INFO DAGScheduler: Parents of final stage: List()
	24/04/24 04:52:25 INFO DAGScheduler: Missing parents: List()
	24/04/24 04:52:25 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[6] at json at NativeMethodAccessorImpl.java:0), which has no missing parents
	24/04/24 04:52:25 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 20.9 KiB, free 366.3 MiB)
	24/04/24 04:52:25 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 10.2 KiB, free 366.3 MiB)
	24/04/24 04:52:26 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 5afbfd5249fc:34741 (size: 10.2 KiB, free: 366.3 MiB)
	24/04/24 04:52:26 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1585
	24/04/24 04:52:26 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (MapPartitionsRDD[6] at json at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
	24/04/24 04:52:26 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks resource profile 0
	24/04/24 04:52:26 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.6, executor 1, partition 0, PROCESS_LOCAL, 7776 bytes) 
	24/04/24 04:52:26 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1) (172.18.0.6, executor 0, partition 1, PROCESS_LOCAL, 8093 bytes) 
[WI-0][TI-1292] - [INFO] 2024-04-24 04:53:39.842 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1292, processInstanceId=546, status=9, startTime=1713904461692, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, logPath=/opt/dolphinscheduler/logs/20240424/13201021801792/90/546/1292.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/546/1292, endTime=1713905019537, processId=841, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], eventCreateTime=0, eventSendTime=1713905319798)
[WI-0][TI-1292] - [INFO] 2024-04-24 04:53:39.846 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1292, processInstanceId=546, status=9, startTime=1713904461692, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, logPath=/opt/dolphinscheduler/logs/20240424/13201021801792/90/546/1292.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/546/1292, endTime=1713905019537, processId=841, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], eventCreateTime=0, eventSendTime=1713905619842)
[WI-0][TI-1281] - [INFO] 2024-04-24 04:54:09.878 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1281, processInstanceId=543, status=9, startTime=1713903509183, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, logPath=/opt/dolphinscheduler/logs/20240424/13201021801792/90/543/1281.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/543/1281, endTime=1713904084494, processId=300, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], eventCreateTime=0, eventSendTime=1713905349834)
[WI-0][TI-1281] - [INFO] 2024-04-24 04:54:09.882 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1281, processInstanceId=543, status=9, startTime=1713903509183, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, logPath=/opt/dolphinscheduler/logs/20240424/13201021801792/90/543/1281.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/543/1281, endTime=1713904084494, processId=300, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], eventCreateTime=0, eventSendTime=1713905649878)
[WI-0][TI-1292] - [INFO] 2024-04-24 04:58:40.162 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1292, processInstanceId=546, status=9, startTime=1713904461692, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, logPath=/opt/dolphinscheduler/logs/20240424/13201021801792/90/546/1292.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/546/1292, endTime=1713905019537, processId=841, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], eventCreateTime=0, eventSendTime=1713905619842)
[WI-0][TI-1292] - [INFO] 2024-04-24 04:58:40.165 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1292, processInstanceId=546, status=9, startTime=1713904461692, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, logPath=/opt/dolphinscheduler/logs/20240424/13201021801792/90/546/1292.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/546/1292, endTime=1713905019537, processId=841, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], eventCreateTime=0, eventSendTime=1713905920162)
[WI-0][TI-1281] - [INFO] 2024-04-24 04:59:10.831 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1281, processInstanceId=543, status=9, startTime=1713903509183, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, logPath=/opt/dolphinscheduler/logs/20240424/13201021801792/90/543/1281.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/543/1281, endTime=1713904084494, processId=300, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], eventCreateTime=0, eventSendTime=1713905649878)
[WI-0][TI-1281] - [INFO] 2024-04-24 04:59:10.834 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1281, processInstanceId=543, status=9, startTime=1713903509183, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.10:5678, logPath=/opt/dolphinscheduler/logs/20240424/13201021801792/90/543/1281.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_90/543/1281, endTime=1713904084494, processId=300, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], eventCreateTime=0, eventSendTime=1713905950831)
