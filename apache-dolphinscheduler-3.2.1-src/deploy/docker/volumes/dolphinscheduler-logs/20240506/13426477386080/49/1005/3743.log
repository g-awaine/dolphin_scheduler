[INFO] 2024-05-06 01:32:34.633 +0800 - ***********************************************************************************************
[INFO] 2024-05-06 01:32:34.635 +0800 - *********************************  Initialize task context  ***********************************
[INFO] 2024-05-06 01:32:34.635 +0800 - ***********************************************************************************************
[INFO] 2024-05-06 01:32:34.635 +0800 - Begin to initialize task
[INFO] 2024-05-06 01:32:34.635 +0800 - Set task startTime: 1714930354635
[INFO] 2024-05-06 01:32:34.635 +0800 - Set task appId: 1005_3743
[INFO] 2024-05-06 01:32:34.636 +0800 - End initialize task {
  "taskInstanceId" : 3743,
  "taskName" : "persist in postgresql",
  "firstSubmitTime" : 1714930354617,
  "startTime" : 1714930354635,
  "taskType" : "SQL",
  "workflowInstanceHost" : "172.18.0.11:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240506/13426477386080/49/1005/3743.log",
  "processId" : 0,
  "processDefineCode" : 13426477386080,
  "processDefineVersion" : 49,
  "processInstanceId" : 1005,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"input_topic\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"gnews_filtered\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[],\"resourceList\":[],\"type\":\"POSTGRESQL\",\"datasource\":1,\"sql\":\"INSERT INTO filtered_data_persistence\\nVALUES (${authors}, ${content}, ${url}, ${context}, ${type}, ${datetime})\\n\",\"sqlType\":\"1\",\"preStatements\":[],\"postStatements\":[],\"displayRows\":10}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "GNEWS_HOME" : {
      "prop" : "GNEWS_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/google_news"
    },
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "persist in postgresql"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "input_topic" : {
      "prop" : "input_topic",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "gnews_filtered"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240506"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "3743"
    },
    "type" : {
      "prop" : "type",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "article"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13427698681952"
    },
    "filtered_data_message" : {
      "prop" : "filtered_data_message",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : ""
    },
    "content" : {
      "prop" : "content",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "lolcontent"
    },
    "url" : {
      "prop" : "url",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "lol"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240506013234"
    },
    "datetime" : {
      "prop" : "datetime",
      "direct" : "IN",
      "type" : "TIMESTAMP",
      "value" : "24-05-03 13:45:22"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1005"
    },
    "context" : {
      "prop" : "context",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "context"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240505"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "es_filtered_data_persistence_subprocess"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13426477386080"
    },
    "authors" : {
      "prop" : "authors",
      "direct" : "IN",
      "type" : "LIST",
      "value" : "\"{'Erin Hale', 'sss hale'}\""
    }
  },
  "taskAppId" : "1005_3743",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "resourceParametersHelper" : {
    "resourceMap" : {
      "DATASOURCE" : {
        "1" : {
          "resourceType" : "DATASOURCE",
          "type" : "POSTGRESQL",
          "connectionParams" : "{\"user\":\"root\",\"password\":\"******\",\"address\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432\",\"database\":\"persistence\",\"jdbcUrl\":\"jdbc:postgresql://dolphinscheduler-postgresql:5432/persistence\",\"driverClassName\":\"org.postgresql.Driver\",\"validationQuery\":\"select version()\",\"other\":{\"password\":\"****\"}}",
          "DATASOURCE" : null
        }
      }
    }
  },
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"datetime\",\"direct\":\"IN\",\"type\":\"TIMESTAMP\",\"value\":\"24-05-03 13:45:22\"},{\"prop\":\"context\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"context\"},{\"prop\":\"type\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"article\"},{\"prop\":\"filtered_data_message\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"\"},{\"prop\":\"content\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"lolcontent\"},{\"prop\":\"url\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"lol\"},{\"prop\":\"authors\",\"direct\":\"IN\",\"type\":\"LIST\",\"value\":\"\\\"{'Erin Hale', 'sss hale'}\\\"\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[INFO] 2024-05-06 01:32:34.636 +0800 - ***********************************************************************************************
[INFO] 2024-05-06 01:32:34.636 +0800 - *********************************  Load task instance plugin  *********************************
[INFO] 2024-05-06 01:32:34.636 +0800 - ***********************************************************************************************
[INFO] 2024-05-06 01:32:34.639 +0800 - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[INFO] 2024-05-06 01:32:34.639 +0800 - TenantCode: default check successfully
[INFO] 2024-05-06 01:32:34.640 +0800 - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13426477386080_49/1005/3743 check successfully
[INFO] 2024-05-06 01:32:34.640 +0800 - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.sql.SqlTaskChannel successfully
[INFO] 2024-05-06 01:32:34.640 +0800 - Download resources successfully: 
ResourceContext(resourceItemMap={})
[INFO] 2024-05-06 01:32:34.640 +0800 - Download upstream files: [] successfully
[INFO] 2024-05-06 01:32:34.641 +0800 - Initialize sql task parameter {
  "localParams" : [ ],
  "varPool" : null,
  "type" : "POSTGRESQL",
  "datasource" : 1,
  "sql" : "INSERT INTO filtered_data_persistence\nVALUES (${authors}, ${content}, ${url}, ${context}, ${type}, ${datetime})\n",
  "sqlType" : 1,
  "sendEmail" : null,
  "displayRows" : 10,
  "udfs" : null,
  "showType" : null,
  "connParams" : null,
  "preStatements" : [ ],
  "postStatements" : [ ],
  "groupId" : 0,
  "title" : null,
  "limit" : 0
}
[INFO] 2024-05-06 01:32:34.641 +0800 - Task plugin instance: SQL create successfully
[INFO] 2024-05-06 01:32:34.641 +0800 - Success initialized task plugin instance successfully
[INFO] 2024-05-06 01:32:34.641 +0800 - Set taskVarPool: [{"prop":"datetime","direct":"IN","type":"TIMESTAMP","value":"24-05-03 13:45:22"},{"prop":"context","direct":"IN","type":"VARCHAR","value":"context"},{"prop":"type","direct":"IN","type":"VARCHAR","value":"article"},{"prop":"filtered_data_message","direct":"IN","type":"VARCHAR","value":""},{"prop":"content","direct":"IN","type":"VARCHAR","value":"lolcontent"},{"prop":"url","direct":"IN","type":"VARCHAR","value":"lol"},{"prop":"authors","direct":"IN","type":"LIST","value":"\"{'Erin Hale', 'sss hale'}\""}] successfully
[INFO] 2024-05-06 01:32:34.641 +0800 - ***********************************************************************************************
[INFO] 2024-05-06 01:32:34.641 +0800 - *********************************  Execute task instance  *************************************
[INFO] 2024-05-06 01:32:34.641 +0800 - ***********************************************************************************************
[INFO] 2024-05-06 01:32:34.641 +0800 - Full sql parameters: SqlParameters{type='POSTGRESQL', datasource=1, sql='INSERT INTO filtered_data_persistence
VALUES (${authors}, ${content}, ${url}, ${context}, ${type}, ${datetime})
', sqlType=1, sendEmail=null, displayRows=10, limit=0, udfs='null', showType='null', connParams='null', groupId='0', title='null', preStatements=[], postStatements=[]}
[INFO] 2024-05-06 01:32:34.641 +0800 - sql type : POSTGRESQL, datasource : 1, sql : INSERT INTO filtered_data_persistence
VALUES (${authors}, ${content}, ${url}, ${context}, ${type}, ${datetime})
 , localParams : [],udfs : null,showType : null,connParams : null,varPool : [Property{prop='datetime', direct=IN, type=TIMESTAMP, value='24-05-03 13:45:22'}, Property{prop='context', direct=IN, type=VARCHAR, value='context'}, Property{prop='type', direct=IN, type=VARCHAR, value='article'}, Property{prop='filtered_data_message', direct=IN, type=VARCHAR, value=''}, Property{prop='content', direct=IN, type=VARCHAR, value='lolcontent'}, Property{prop='url', direct=IN, type=VARCHAR, value='lol'}, Property{prop='authors', direct=IN, type=LIST, value='"{'Erin Hale', 'sss hale'}"'}] ,query max result limit  0
[INFO] 2024-05-06 01:32:34.642 +0800 - setSqlParamsMap: Property with paramName: authors put in sqlParamsMap of content INSERT INTO filtered_data_persistence
VALUES (${authors}, ${content}, ${url}, ${context}, ${type}, ${datetime})
 successfully.
[INFO] 2024-05-06 01:32:34.643 +0800 - setSqlParamsMap: Property with paramName: content put in sqlParamsMap of content INSERT INTO filtered_data_persistence
VALUES (${authors}, ${content}, ${url}, ${context}, ${type}, ${datetime})
 successfully.
[INFO] 2024-05-06 01:32:34.643 +0800 - setSqlParamsMap: Property with paramName: url put in sqlParamsMap of content INSERT INTO filtered_data_persistence
VALUES (${authors}, ${content}, ${url}, ${context}, ${type}, ${datetime})
 successfully.
[INFO] 2024-05-06 01:32:34.643 +0800 - setSqlParamsMap: Property with paramName: context put in sqlParamsMap of content INSERT INTO filtered_data_persistence
VALUES (${authors}, ${content}, ${url}, ${context}, ${type}, ${datetime})
 successfully.
[INFO] 2024-05-06 01:32:34.644 +0800 - setSqlParamsMap: Property with paramName: type put in sqlParamsMap of content INSERT INTO filtered_data_persistence
VALUES (${authors}, ${content}, ${url}, ${context}, ${type}, ${datetime})
 successfully.
[INFO] 2024-05-06 01:32:34.644 +0800 - setSqlParamsMap: Property with paramName: datetime put in sqlParamsMap of content INSERT INTO filtered_data_persistence
VALUES (${authors}, ${content}, ${url}, ${context}, ${type}, ${datetime})
 successfully.
[ERROR] 2024-05-06 01:32:34.644 +0800 - parse list exception!
com.fasterxml.jackson.databind.exc.MismatchedInputException: Cannot deserialize value of type `java.util.ArrayList<java.lang.Object>` from String value (token `JsonToken.VALUE_STRING`)
 at [Source: (String)""{'Erin Hale', 'sss hale'}""; line: 1, column: 1]
	at com.fasterxml.jackson.databind.exc.MismatchedInputException.from(MismatchedInputException.java:59)
	at com.fasterxml.jackson.databind.DeserializationContext.reportInputMismatch(DeserializationContext.java:1741)
	at com.fasterxml.jackson.databind.DeserializationContext.handleUnexpectedToken(DeserializationContext.java:1515)
	at com.fasterxml.jackson.databind.DeserializationContext.handleUnexpectedToken(DeserializationContext.java:1462)
	at com.fasterxml.jackson.databind.deser.std.CollectionDeserializer.handleNonArray(CollectionDeserializer.java:392)
	at com.fasterxml.jackson.databind.deser.std.CollectionDeserializer._deserializeFromString(CollectionDeserializer.java:326)
	at com.fasterxml.jackson.databind.deser.std.CollectionDeserializer.deserialize(CollectionDeserializer.java:250)
	at com.fasterxml.jackson.databind.deser.std.CollectionDeserializer.deserialize(CollectionDeserializer.java:28)
	at com.fasterxml.jackson.databind.deser.DefaultDeserializationContext.readRootValue(DefaultDeserializationContext.java:323)
	at com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:4674)
	at com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:3629)
	at org.apache.dolphinscheduler.common.utils.JSONUtils.toList(JSONUtils.java:184)
	at org.apache.dolphinscheduler.plugin.task.api.utils.ParameterUtils.expandListParameter(ParameterUtils.java:205)
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.getSqlAndSqlParamsMap(SqlTask.java:459)
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
	at java.util.Collections$2.tryAdvance(Collections.java:4719)
	at java.util.Collections$2.forEachRemaining(Collections.java:4727)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)
	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:566)
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.handle(SqlTask.java:143)
	at org.apache.dolphinscheduler.server.worker.runner.DefaultWorkerTaskExecutor.executeTask(DefaultWorkerTaskExecutor.java:54)
	at org.apache.dolphinscheduler.server.worker.runner.WorkerTaskExecutor.run(WorkerTaskExecutor.java:175)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
[ERROR] 2024-05-06 01:32:34.644 +0800 - sql task error
java.lang.UnsupportedOperationException: null
	at java.util.AbstractList.add(AbstractList.java:148)
	at java.util.AbstractList.add(AbstractList.java:108)
	at org.apache.dolphinscheduler.plugin.task.api.utils.ParameterUtils.expandListParameter(ParameterUtils.java:207)
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.getSqlAndSqlParamsMap(SqlTask.java:459)
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
	at java.util.Collections$2.tryAdvance(Collections.java:4719)
	at java.util.Collections$2.forEachRemaining(Collections.java:4727)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)
	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:566)
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.handle(SqlTask.java:143)
	at org.apache.dolphinscheduler.server.worker.runner.DefaultWorkerTaskExecutor.executeTask(DefaultWorkerTaskExecutor.java:54)
	at org.apache.dolphinscheduler.server.worker.runner.WorkerTaskExecutor.run(WorkerTaskExecutor.java:175)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
[ERROR] 2024-05-06 01:32:34.644 +0800 - Task execute failed, due to meet an exception
org.apache.dolphinscheduler.plugin.task.api.TaskException: Execute sql task failed
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.handle(SqlTask.java:166)
	at org.apache.dolphinscheduler.server.worker.runner.DefaultWorkerTaskExecutor.executeTask(DefaultWorkerTaskExecutor.java:54)
	at org.apache.dolphinscheduler.server.worker.runner.WorkerTaskExecutor.run(WorkerTaskExecutor.java:175)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.lang.UnsupportedOperationException: null
	at java.util.AbstractList.add(AbstractList.java:148)
	at java.util.AbstractList.add(AbstractList.java:108)
	at org.apache.dolphinscheduler.plugin.task.api.utils.ParameterUtils.expandListParameter(ParameterUtils.java:207)
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.getSqlAndSqlParamsMap(SqlTask.java:459)
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
	at java.util.Collections$2.tryAdvance(Collections.java:4719)
	at java.util.Collections$2.forEachRemaining(Collections.java:4727)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)
	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:566)
	at org.apache.dolphinscheduler.plugin.task.sql.SqlTask.handle(SqlTask.java:143)
	... 5 common frames omitted
[INFO] 2024-05-06 01:32:34.644 +0800 - Get appIds from worker 172.18.1.1:1234, taskLogPath: /opt/dolphinscheduler/logs/20240506/13426477386080/49/1005/3743.log
[INFO] 2024-05-06 01:32:34.644 +0800 - Start finding appId in /opt/dolphinscheduler/logs/20240506/13426477386080/49/1005/3743.log, fetch way: log 
[INFO] 2024-05-06 01:32:34.645 +0800 - The appId is empty
[INFO] 2024-05-06 01:32:34.645 +0800 - Cancel the task successfully
[INFO] 2024-05-06 01:32:34.647 +0800 - Get a exception when execute the task, will send the task status: FAILURE to master: 172.18.1.1:1234
[INFO] 2024-05-06 01:32:34.648 +0800 - FINALIZE_SESSION
