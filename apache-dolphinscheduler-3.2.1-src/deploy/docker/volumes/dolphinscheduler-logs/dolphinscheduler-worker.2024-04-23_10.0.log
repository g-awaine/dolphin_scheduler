[WI-0][TI-0] - [INFO] 2024-04-23 10:00:00.482 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:00:00 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
[WI-0][TI-0] - [INFO] 2024-04-23 10:00:15.510 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:00:15 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
[WI-0][TI-0] - [INFO] 2024-04-23 10:00:30.528 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:00:30 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
[WI-0][TI-0] - [INFO] 2024-04-23 10:00:45.557 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:00:45 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
[WI-0][TI-0] - [INFO] 2024-04-23 10:01:00.570 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:01:00 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
[WI-0][TI-0] - [INFO] 2024-04-23 10:01:16.061 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:01:15 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
[WI-0][TI-0] - [INFO] 2024-04-23 10:01:31.100 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:01:30 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
[WI-0][TI-0] - [INFO] 2024-04-23 10:01:46.171 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:01:45 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
[WI-0][TI-0] - [INFO] 2024-04-23 10:02:01.195 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:02:00 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
[WI-0][TI-0] - [INFO] 2024-04-23 10:02:16.222 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:02:15 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
[WI-0][TI-0] - [INFO] 2024-04-23 10:02:31.239 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:02:30 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
[WI-0][TI-0] - [INFO] 2024-04-23 10:02:46.253 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:02:45 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
[WI-0][TI-0] - [INFO] 2024-04-23 10:03:01.276 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:03:00 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
[WI-0][TI-0] - [INFO] 2024-04-23 10:03:16.293 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:03:15 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
[WI-0][TI-0] - [INFO] 2024-04-23 10:03:31.336 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:03:30 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
[WI-0][TI-0] - [INFO] 2024-04-23 10:03:46.388 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:03:45 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
[WI-0][TI-0] - [INFO] 2024-04-23 10:04:00.473 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:04:00 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
[WI-0][TI-0] - [INFO] 2024-04-23 10:04:15.576 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:04:15 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
[WI-0][TI-0] - [INFO] 2024-04-23 10:04:30.629 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:04:30 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
[WI-0][TI-0] - [INFO] 2024-04-23 10:04:45.650 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:04:45 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
[WI-0][TI-0] - [INFO] 2024-04-23 10:05:00.673 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:05:00 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
[WI-0][TI-0] - [INFO] 2024-04-23 10:05:16.134 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:05:16 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
[WI-0][TI-0] - [INFO] 2024-04-23 10:05:31.149 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:05:30 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
[WI-0][TI-0] - [INFO] 2024-04-23 10:05:46.162 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:05:45 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
[WI-0][TI-0] - [INFO] 2024-04-23 10:06:01.195 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:06:00 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
[WI-0][TI-0] - [INFO] 2024-04-23 10:06:16.211 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:06:15 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
[WI-0][TI-0] - [INFO] 2024-04-23 10:06:31.243 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:06:30 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
[WI-0][TI-0] - [INFO] 2024-04-23 10:06:46.298 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:06:45 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
[WI-0][TI-0] - [INFO] 2024-04-23 10:07:00.719 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:07:00 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
[WI-0][TI-0] - [INFO] 2024-04-23 10:07:15.780 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:07:15 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
[WI-0][TI-0] - [INFO] 2024-04-23 10:07:31.177 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:07:30 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
[WI-0][TI-0] - [INFO] 2024-04-23 10:07:46.200 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:07:45 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
[WI-0][TI-0] - [INFO] 2024-04-23 10:07:55.255 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7963525835866261 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:08:01.218 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:08:00 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
[WI-0][TI-0] - [INFO] 2024-04-23 10:08:16.233 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:08:15 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
[WI-0][TI-0] - [INFO] 2024-04-23 10:08:31.314 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:08:30 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
[WI-0][TI-0] - [INFO] 2024-04-23 10:08:46.187 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:08:45 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
[WI-0][TI-0] - [INFO] 2024-04-23 10:09:01.309 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:09:00 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
[WI-0][TI-0] - [INFO] 2024-04-23 10:09:16.329 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:09:15 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
[WI-0][TI-0] - [INFO] 2024-04-23 10:09:22.336 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:09:22 ERROR StandaloneSchedulerBackend: Application has been killed. Reason: Master removed our application: KILLED
	24/04/23 10:09:22 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
	24/04/23 10:09:22 INFO SparkContext: SparkContext is stopping with exitCode 0.
	24/04/23 10:09:22 INFO TaskSchedulerImpl: Cancelling stage 0
	24/04/23 10:09:22 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage cancelled: Job aborted due to stage failure: Master removed our application: KILLED
	24/04/23 10:09:22 INFO DAGScheduler: ResultStage 0 (json at NativeMethodAccessorImpl.java:0) failed in 591.989 s due to Job aborted due to stage failure: Master removed our application: KILLED
	24/04/23 10:09:22 INFO DAGScheduler: Job 0 failed: json at NativeMethodAccessorImpl.java:0, took 592.082550 s
	24/04/23 10:09:22 INFO SparkUI: Stopped Spark web UI at http://c0e814e3f0bd:4042
	24/04/23 10:09:22 INFO StandaloneSchedulerBackend: Shutting down all executors
	24/04/23 10:09:22 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Asking each executor to shut down
	24/04/23 10:09:22 ERROR Utils: Uncaught exception in thread stop-spark-context
	org.apache.spark.SparkException: Exception thrown in awaitResult: 
		at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
		at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
		at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
		at org.apache.spark.deploy.client.StandaloneAppClient.stop(StandaloneAppClient.scala:288)
		at org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend.org$apache$spark$scheduler$cluster$StandaloneSchedulerBackend$$stop(StandaloneSchedulerBackend.scala:275)
		at org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend.stop(StandaloneSchedulerBackend.scala:142)
		at org.apache.spark.scheduler.SchedulerBackend.stop(SchedulerBackend.scala:33)
		at org.apache.spark.scheduler.SchedulerBackend.stop$(SchedulerBackend.scala:33)
		at org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend.stop(CoarseGrainedSchedulerBackend.scala:54)
		at org.apache.spark.scheduler.TaskSchedulerImpl.$anonfun$stop$2(TaskSchedulerImpl.scala:992)
		at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1375)
		at org.apache.spark.scheduler.TaskSchedulerImpl.stop(TaskSchedulerImpl.scala:992)
		at org.apache.spark.scheduler.DAGScheduler.$anonfun$stop$4(DAGScheduler.scala:2976)
		at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1375)
		at org.apache.spark.scheduler.DAGScheduler.stop(DAGScheduler.scala:2976)
		at org.apache.spark.SparkContext.$anonfun$stop$12(SparkContext.scala:2263)
		at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1375)
		at org.apache.spark.SparkContext.stop(SparkContext.scala:2263)
		at org.apache.spark.SparkContext.stop(SparkContext.scala:2216)
		at org.apache.spark.SparkContext$$anon$3.run(SparkContext.scala:2203)
	Caused by: org.apache.spark.SparkException: Could not find AppClient.
		at org.apache.spark.rpc.netty.Dispatcher.postMessage(Dispatcher.scala:178)
		at org.apache.spark.rpc.netty.Dispatcher.postLocalMessage(Dispatcher.scala:144)
		at org.apache.spark.rpc.netty.NettyRpcEnv.askAbortable(NettyRpcEnv.scala:242)
		at org.apache.spark.rpc.netty.NettyRpcEndpointRef.askAbortable(NettyRpcEnv.scala:554)
		at org.apache.spark.rpc.netty.NettyRpcEndpointRef.ask(NettyRpcEnv.scala:558)
		at org.apache.spark.rpc.RpcEndpointRef.ask(RpcEndpointRef.scala:72)
		... 17 more
[WI-0][TI-0] - [INFO] 2024-04-23 10:09:23.338 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:09:22 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
	Traceback (most recent call last):
	  File "/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1119/spark_reddit_preprocessing.py", line 44, in <module>
	    raw_df = spark.read.json(reddit_json_dir)
	             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
	  File "/opt/spark-3.5.1-bin-hadoop3/python/lib/pyspark.zip/pyspark/sql/readwriter.py", line 425, in json
	  File "/opt/spark-3.5.1-bin-hadoop3/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
	  File "/opt/spark-3.5.1-bin-hadoop3/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 179, in deco
	  File "/opt/spark-3.5.1-bin-hadoop3/python/lib/py4j-0.10.9.7-src.zip/py4j/protocol.py", line 326, in get_return_value
	py4j.protocol.Py4JJavaError: An error occurred while calling o30.json.
	: org.apache.spark.SparkException: Job aborted due to stage failure: Master removed our application: KILLED
		at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)
		at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)
		at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)
		at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
		at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
		at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
		at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)
		at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)
		at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)
		at scala.Option.foreach(Option.scala:407)
		at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)
		at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)
		at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)
		at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)
		at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
		at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:989)
		at org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)
		at org.apache.spark.SparkContext.runJob(SparkContext.scala:2493)
		at org.apache.spark.sql.catalyst.json.JsonInferSchema.infer(JsonInferSchema.scala:120)
		at org.apache.spark.sql.execution.datasources.json.TextInputJsonDataSource$.$anonfun$inferFromDataset$5(JsonDataSource.scala:109)
		at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)
		at org.apache.spark.sql.execution.datasources.json.TextInputJsonDataSource$.inferFromDataset(JsonDataSource.scala:109)
		at org.apache.spark.sql.execution.datasources.json.TextInputJsonDataSource$.infer(JsonDataSource.scala:98)
		at org.apache.spark.sql.execution.datasources.json.JsonDataSource.inferSchema(JsonDataSource.scala:64)
		at org.apache.spark.sql.execution.datasources.json.JsonFileFormat.inferSchema(JsonFileFormat.scala:59)
		at org.apache.spark.sql.execution.datasources.DataSource.$anonfun$getOrInferFileFormatSchema$11(DataSource.scala:208)
		at scala.Option.orElse(Option.scala:447)
		at org.apache.spark.sql.execution.datasources.DataSource.getOrInferFileFormatSchema(DataSource.scala:205)
		at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:407)
		at org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)
		at org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)
		at scala.Option.getOrElse(Option.scala:189)
		at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)
		at org.apache.spark.sql.DataFrameReader.json(DataFrameReader.scala:362)
		at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
		at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
		at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
		at java.lang.reflect.Method.invoke(Method.java:498)
		at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
		at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
		at py4j.Gateway.invoke(Gateway.java:282)
		at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
		at py4j.commands.CallCommand.execute(CallCommand.java:79)
		at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
		at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
		at java.lang.Thread.run(Thread.java:750)
	
	24/04/23 10:09:22 INFO MemoryStore: MemoryStore cleared
	24/04/23 10:09:22 INFO BlockManager: BlockManager stopped
	24/04/23 10:09:22 INFO BlockManagerMaster: BlockManagerMaster stopped
	24/04/23 10:09:22 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
	24/04/23 10:09:22 INFO SparkContext: Successfully stopped SparkContext
	24/04/23 10:09:22 INFO ShutdownHookManager: Shutdown hook called
	24/04/23 10:09:22 INFO ShutdownHookManager: Deleting directory /tmp/spark-9b0c8bbe-758e-40fb-8ea7-ff76f865a246/pyspark-9742cb63-9afb-43e4-99be-0b03c5eac29d
	24/04/23 10:09:22 INFO ShutdownHookManager: Deleting directory /tmp/spark-c1ca109e-0ab4-4385-a6c7-9854951b5233
	24/04/23 10:09:22 INFO ShutdownHookManager: Deleting directory /tmp/spark-9b0c8bbe-758e-40fb-8ea7-ff76f865a246
[WI-487][TI-1119] - [INFO] 2024-04-23 10:09:23.339 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1119, processId:1342 ,exitStatusCode:1 ,processWaitForStatus:true ,processExitValue:1
[WI-487][TI-1119] - [INFO] 2024-04-23 10:09:23.339 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-487][TI-1119] - [INFO] 2024-04-23 10:09:23.339 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-487][TI-1119] - [INFO] 2024-04-23 10:09:23.339 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-487][TI-1119] - [INFO] 2024-04-23 10:09:23.340 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-487][TI-1119] - [INFO] 2024-04-23 10:09:23.345 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: FAILURE to master : 172.18.1.1:1234
[WI-487][TI-1119] - [INFO] 2024-04-23 10:09:23.345 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-487][TI-1119] - [INFO] 2024-04-23 10:09:23.345 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1119
[WI-487][TI-1119] - [INFO] 2024-04-23 10:09:23.345 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1119
[WI-487][TI-1119] - [INFO] 2024-04-23 10:09:23.346 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-1119] - [INFO] 2024-04-23 10:09:24.325 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1119, success=true)
[WI-0][TI-0] - [ERROR] 2024-04-23 10:09:29.452 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[279] - Parse var pool error
java.io.IOException: Stream closed
	at java.io.BufferedInputStream.getBufIfOpen(BufferedInputStream.java:170)
	at java.io.BufferedInputStream.read1(BufferedInputStream.java:283)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:345)
	at sun.nio.cs.StreamDecoder.readBytes(StreamDecoder.java:284)
	at sun.nio.cs.StreamDecoder.implRead(StreamDecoder.java:326)
	at sun.nio.cs.StreamDecoder.read(StreamDecoder.java:178)
	at java.io.InputStreamReader.read(InputStreamReader.java:184)
	at java.io.BufferedReader.fill(BufferedReader.java:161)
	at java.io.BufferedReader.readLine(BufferedReader.java:324)
	at java.io.BufferedReader.readLine(BufferedReader.java:389)
	at org.apache.dolphinscheduler.plugin.task.api.AbstractCommandExecutor.lambda$parseProcessOutput$1(AbstractCommandExecutor.java:273)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
[WI-487][TI-1111] - [INFO] 2024-04-23 10:09:30.350 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has killed. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1111, processId:1017 ,exitStatusCode:137 ,processWaitForStatus:true ,processExitValue:137
[WI-487][TI-1111] - [INFO] 2024-04-23 10:09:30.351 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-487][TI-1111] - [INFO] 2024-04-23 10:09:30.351 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-487][TI-1111] - [INFO] 2024-04-23 10:09:30.351 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-487][TI-1111] - [INFO] 2024-04-23 10:09:30.352 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-487][TI-1111] - [INFO] 2024-04-23 10:09:30.355 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: KILL to master : 172.18.1.1:1234
[WI-487][TI-1111] - [INFO] 2024-04-23 10:09:30.356 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-487][TI-1111] - [INFO] 2024-04-23 10:09:30.357 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1111
[WI-487][TI-1111] - [INFO] 2024-04-23 10:09:30.358 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1111
[WI-487][TI-1111] - [INFO] 2024-04-23 10:09:30.359 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-1111] - [INFO] 2024-04-23 10:09:44.698 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1111, processInstanceId=487, status=9, startTime=1713837256404, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1111.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1111, endTime=1713838170352, processId=1017, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1111] - [INFO] 2024-04-23 10:09:44.701 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1111, processInstanceId=487, status=9, startTime=1713837256404, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1111.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1111, endTime=1713838170352, processId=1017, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713838184697)
[WI-0][TI-0] - [INFO] 2024-04-23 10:10:03.534 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1120, taskName=search for intake JSON files, firstSubmitTime=1713838203526, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.9:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=78, appIds=null, processInstanceId=487, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"processing"}], executorId=1, cmdTypeIfComplement=7, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":""}],"rawScript":"# find 1 raw file in the folder\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\n\n# check if raw_file_dir is empty, then set raw_file_dir to null\nif [ -z \"$raw_file_dir\" ]; then\n    raw_file_dir=null\nfi\n\necho \"#{setValue(raw_file_dir=${raw_file_dir})}\"","resourceList":[]}, environmentConfig=export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='search for intake JSON files'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240423'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1120'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13340113777664'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240423101003'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='processing'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='487'}, raw_file_dir=Property{prop='raw_file_dir', direct=OUT, type=VARCHAR, value='/local_storage/reddit/processing/386-20240422.json'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240422'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-487][TI-1120] - [INFO] 2024-04-23 10:10:03.535 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: search for intake JSON files to wait queue success
[WI-487][TI-1120] - [INFO] 2024-04-23 10:10:03.536 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-487][TI-1120] - [INFO] 2024-04-23 10:10:03.537 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-487][TI-1120] - [INFO] 2024-04-23 10:10:03.538 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-487][TI-1120] - [INFO] 2024-04-23 10:10:03.538 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-487][TI-1120] - [INFO] 2024-04-23 10:10:03.538 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713838203538
[WI-487][TI-1120] - [INFO] 2024-04-23 10:10:03.538 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 487_1120
[WI-487][TI-1120] - [INFO] 2024-04-23 10:10:03.538 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1120,
  "taskName" : "search for intake JSON files",
  "firstSubmitTime" : 1713838203526,
  "startTime" : 1713838203538,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.9:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1120.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 78,
  "processInstanceId" : 487,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"processing\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 7,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[{\"prop\":\"raw_file_dir\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"\"}],\"rawScript\":\"# find 1 raw file in the folder\\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\\n\\n# check if raw_file_dir is empty, then set raw_file_dir to null\\nif [ -z \\\"$raw_file_dir\\\" ]; then\\n    raw_file_dir=null\\nfi\\n\\necho \\\"#{setValue(raw_file_dir=${raw_file_dir})}\\\"\",\"resourceList\":[]}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "search for intake JSON files"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1120"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13340113777664"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423101003"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "processing"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "487"
    },
    "raw_file_dir" : {
      "prop" : "raw_file_dir",
      "direct" : "OUT",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit/processing/386-20240422.json"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240422"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "487_1120",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"raw_file_dir\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"/local_storage/reddit/processing/386-20240422.json\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-487][TI-1120] - [INFO] 2024-04-23 10:10:03.539 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-487][TI-1120] - [INFO] 2024-04-23 10:10:03.539 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-487][TI-1120] - [INFO] 2024-04-23 10:10:03.539 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-487][TI-1120] - [INFO] 2024-04-23 10:10:03.544 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-487][TI-1120] - [INFO] 2024-04-23 10:10:03.545 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-487][TI-1120] - [INFO] 2024-04-23 10:10:03.546 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1120 check successfully
[WI-487][TI-1120] - [INFO] 2024-04-23 10:10:03.546 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-487][TI-1120] - [INFO] 2024-04-23 10:10:03.546 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-487][TI-1120] - [INFO] 2024-04-23 10:10:03.546 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-487][TI-1120] - [INFO] 2024-04-23 10:10:03.546 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-487][TI-1120] - [INFO] 2024-04-23 10:10:03.547 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ {
    "prop" : "raw_file_dir",
    "direct" : "OUT",
    "type" : "VARCHAR",
    "value" : ""
  } ],
  "varPool" : null,
  "rawScript" : "# find 1 raw file in the folder\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\n\n# check if raw_file_dir is empty, then set raw_file_dir to null\nif [ -z \"$raw_file_dir\" ]; then\n    raw_file_dir=null\nfi\n\necho \"#{setValue(raw_file_dir=${raw_file_dir})}\"",
  "resourceList" : [ ]
}
[WI-487][TI-1120] - [INFO] 2024-04-23 10:10:03.547 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-487][TI-1120] - [INFO] 2024-04-23 10:10:03.547 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}] successfully
[WI-487][TI-1120] - [INFO] 2024-04-23 10:10:03.547 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-487][TI-1120] - [INFO] 2024-04-23 10:10:03.547 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-487][TI-1120] - [INFO] 2024-04-23 10:10:03.547 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-487][TI-1120] - [INFO] 2024-04-23 10:10:03.548 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-487][TI-1120] - [INFO] 2024-04-23 10:10:03.548 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-487][TI-1120] - [INFO] 2024-04-23 10:10:03.548 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export PYTHON_LAUNCHER=/bin/python3.11
# find 1 raw file in the folder
raw_file_dir=$(find /local_storage/reddit/processing -type f -name '*.json'| head -n 1)

# check if raw_file_dir is empty, then set raw_file_dir to null
if [ -z "$raw_file_dir" ]; then
    raw_file_dir=null
fi

echo "#{setValue(raw_file_dir=/local_storage/reddit/processing/386-20240422.json)}"
[WI-487][TI-1120] - [INFO] 2024-04-23 10:10:03.548 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-487][TI-1120] - [INFO] 2024-04-23 10:10:03.548 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1120/487_1120.sh
[WI-487][TI-1120] - [INFO] 2024-04-23 10:10:03.555 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 1652
[WI-0][TI-1120] - [INFO] 2024-04-23 10:10:03.740 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionRunningEvent(taskInstanceId=1120, processInstanceId=487, startTime=1713838203538, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, status=TaskExecutionStatus{code=1, desc='running'}, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1120.log, executePath=null, processId=0, appIds=null, eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1120] - [INFO] 2024-04-23 10:10:03.743 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionRunningEvent(taskInstanceId=1120, processInstanceId=487, startTime=1713838203538, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, status=TaskExecutionStatus{code=1, desc='running'}, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1120.log, executePath=null, processId=0, appIds=null, eventCreateTime=0, eventSendTime=1713838203739)
[WI-0][TI-1120] - [INFO] 2024-04-23 10:10:03.743 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionInfoEvent(taskInstanceId=1120, processInstanceId=487, startTime=1713838203538, workflowInstanceHost=172.18.0.9:5678, taskInstanceHost=172.18.1.1:1234, logPath=null, processId=0, eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1120] - [INFO] 2024-04-23 10:10:03.746 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionInfoEvent(taskInstanceId=1120, processInstanceId=487, startTime=1713838203538, workflowInstanceHost=172.18.0.9:5678, taskInstanceHost=172.18.1.1:1234, logPath=null, processId=0, eventCreateTime=0, eventSendTime=1713838203739)
[WI-0][TI-1120] - [INFO] 2024-04-23 10:10:04.413 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1120, success=true)
[WI-0][TI-1120] - [INFO] 2024-04-23 10:10:04.458 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1120)
[WI-0][TI-1120] - [INFO] 2024-04-23 10:10:04.472 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1120, success=true)
[WI-0][TI-1120] - [INFO] 2024-04-23 10:10:04.484 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1120)
[WI-0][TI-0] - [INFO] 2024-04-23 10:10:04.556 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
	#{setValue(raw_file_dir=/local_storage/reddit/processing/386-20240422.json)}
[WI-487][TI-1120] - [INFO] 2024-04-23 10:10:04.559 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1120, processId:1652 ,exitStatusCode:0 ,processWaitForStatus:true ,processExitValue:0
[WI-487][TI-1120] - [INFO] 2024-04-23 10:10:04.559 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-487][TI-1120] - [INFO] 2024-04-23 10:10:04.560 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-487][TI-1120] - [INFO] 2024-04-23 10:10:04.560 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-487][TI-1120] - [INFO] 2024-04-23 10:10:04.560 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-487][TI-1120] - [INFO] 2024-04-23 10:10:04.563 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: SUCCESS to master : 172.18.1.1:1234
[WI-487][TI-1120] - [INFO] 2024-04-23 10:10:04.563 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-487][TI-1120] - [INFO] 2024-04-23 10:10:04.563 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1120
[WI-487][TI-1120] - [INFO] 2024-04-23 10:10:04.564 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1120
[WI-487][TI-1120] - [INFO] 2024-04-23 10:10:04.564 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-1120] - [INFO] 2024-04-23 10:10:04.747 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1120, processInstanceId=487, status=7, startTime=1713838203538, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1120.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1120, endTime=1713838204560, processId=1652, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1120] - [INFO] 2024-04-23 10:10:04.756 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1120, processInstanceId=487, status=7, startTime=1713838203538, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1120.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1120, endTime=1713838204560, processId=1652, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713838204747)
[WI-0][TI-1120] - [INFO] 2024-04-23 10:10:05.411 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1120, success=true)
[WI-0][TI-1120] - [INFO] 2024-04-23 10:10:05.415 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1120, success=true)
[WI-0][TI-0] - [INFO] 2024-04-23 10:10:06.564 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1122, taskName=move to processing, firstSubmitTime=1713838206534, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.9:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=78, appIds=null, processInstanceId=487, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"processing"}], executorId=1, cmdTypeIfComplement=7, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":""}],"rawScript":"# move file to the reddit processing folder\n# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error\nfilename=$(basename \"${raw_file_dir}\")\nif ! grep -q \"${REDDIT_HOME}/processing\" <<< \"${raw_file_dir}\"; then\n    mv ${raw_file_dir} ${REDDIT_HOME}/processing\nelse\n    echo JSON is already in processing\nfi\n\n# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing\necho \"#{setValue(raw_file_dir=${REDDIT_HOME}/processing/${filename})}\"","resourceList":[]}, environmentConfig=export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='move to processing'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240423'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1122'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13340390094208'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240423101006'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='processing'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='487'}, raw_file_dir=Property{prop='raw_file_dir', direct=IN, type=VARCHAR, value='/local_storage/reddit/processing/386-20240422.json'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240422'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-487][TI-1122] - [INFO] 2024-04-23 10:10:06.566 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: move to processing to wait queue success
[WI-487][TI-1122] - [INFO] 2024-04-23 10:10:06.566 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-487][TI-1122] - [INFO] 2024-04-23 10:10:06.568 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-487][TI-1122] - [INFO] 2024-04-23 10:10:06.568 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-487][TI-1122] - [INFO] 2024-04-23 10:10:06.568 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-487][TI-1122] - [INFO] 2024-04-23 10:10:06.568 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713838206568
[WI-487][TI-1122] - [INFO] 2024-04-23 10:10:06.568 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 487_1122
[WI-487][TI-1122] - [INFO] 2024-04-23 10:10:06.570 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1122,
  "taskName" : "move to processing",
  "firstSubmitTime" : 1713838206534,
  "startTime" : 1713838206568,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.9:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1122.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 78,
  "processInstanceId" : 487,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"processing\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 7,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[{\"prop\":\"raw_file_dir\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"\"}],\"rawScript\":\"# move file to the reddit processing folder\\n# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error\\nfilename=$(basename \\\"${raw_file_dir}\\\")\\nif ! grep -q \\\"${REDDIT_HOME}/processing\\\" <<< \\\"${raw_file_dir}\\\"; then\\n    mv ${raw_file_dir} ${REDDIT_HOME}/processing\\nelse\\n    echo JSON is already in processing\\nfi\\n\\n# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing\\necho \\\"#{setValue(raw_file_dir=${REDDIT_HOME}/processing/${filename})}\\\"\",\"resourceList\":[]}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "move to processing"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1122"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13340390094208"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423101006"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "processing"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "487"
    },
    "raw_file_dir" : {
      "prop" : "raw_file_dir",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit/processing/386-20240422.json"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240422"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "487_1122",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"raw_file_dir\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"/local_storage/reddit/processing/386-20240422.json\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-487][TI-1122] - [INFO] 2024-04-23 10:10:06.571 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-487][TI-1122] - [INFO] 2024-04-23 10:10:06.571 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-487][TI-1122] - [INFO] 2024-04-23 10:10:06.572 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-487][TI-1122] - [INFO] 2024-04-23 10:10:06.576 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-487][TI-1122] - [INFO] 2024-04-23 10:10:06.576 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-487][TI-1122] - [INFO] 2024-04-23 10:10:06.577 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1122 check successfully
[WI-487][TI-1122] - [INFO] 2024-04-23 10:10:06.577 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-487][TI-1122] - [INFO] 2024-04-23 10:10:06.578 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-487][TI-1122] - [INFO] 2024-04-23 10:10:06.578 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-487][TI-1122] - [INFO] 2024-04-23 10:10:06.578 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-487][TI-1122] - [INFO] 2024-04-23 10:10:06.578 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ {
    "prop" : "raw_file_dir",
    "direct" : "OUT",
    "type" : "VARCHAR",
    "value" : ""
  } ],
  "varPool" : null,
  "rawScript" : "# move file to the reddit processing folder\n# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error\nfilename=$(basename \"${raw_file_dir}\")\nif ! grep -q \"${REDDIT_HOME}/processing\" <<< \"${raw_file_dir}\"; then\n    mv ${raw_file_dir} ${REDDIT_HOME}/processing\nelse\n    echo JSON is already in processing\nfi\n\n# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing\necho \"#{setValue(raw_file_dir=${REDDIT_HOME}/processing/${filename})}\"",
  "resourceList" : [ ]
}
[WI-487][TI-1122] - [INFO] 2024-04-23 10:10:06.578 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-487][TI-1122] - [INFO] 2024-04-23 10:10:06.578 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}] successfully
[WI-487][TI-1122] - [INFO] 2024-04-23 10:10:06.578 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-487][TI-1122] - [INFO] 2024-04-23 10:10:06.578 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-487][TI-1122] - [INFO] 2024-04-23 10:10:06.578 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-487][TI-1122] - [INFO] 2024-04-23 10:10:06.579 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-487][TI-1122] - [INFO] 2024-04-23 10:10:06.579 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-487][TI-1122] - [INFO] 2024-04-23 10:10:06.579 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export PYTHON_LAUNCHER=/bin/python3.11
# move file to the reddit processing folder
# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error
filename=$(basename "/local_storage/reddit/processing/386-20240422.json")
if ! grep -q "/local_storage/reddit/processing" <<< "/local_storage/reddit/processing/386-20240422.json"; then
    mv /local_storage/reddit/processing/386-20240422.json /local_storage/reddit/processing
else
    echo JSON is already in processing
fi

# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing
echo "#{setValue(raw_file_dir=/local_storage/reddit/processing/${filename})}"
[WI-487][TI-1122] - [INFO] 2024-04-23 10:10:06.579 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-487][TI-1122] - [INFO] 2024-04-23 10:10:06.579 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1122/487_1122.sh
[WI-487][TI-1122] - [INFO] 2024-04-23 10:10:06.609 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 1665
[WI-0][TI-0] - [INFO] 2024-04-23 10:10:06.609 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
[WI-0][TI-1122] - [INFO] 2024-04-23 10:10:06.790 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionRunningEvent(taskInstanceId=1122, processInstanceId=487, startTime=1713838206568, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, status=TaskExecutionStatus{code=1, desc='running'}, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1122.log, executePath=null, processId=0, appIds=null, eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1122] - [INFO] 2024-04-23 10:10:06.796 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionRunningEvent(taskInstanceId=1122, processInstanceId=487, startTime=1713838206568, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, status=TaskExecutionStatus{code=1, desc='running'}, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1122.log, executePath=null, processId=0, appIds=null, eventCreateTime=0, eventSendTime=1713838206789)
[WI-0][TI-1122] - [INFO] 2024-04-23 10:10:06.796 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionInfoEvent(taskInstanceId=1122, processInstanceId=487, startTime=1713838206568, workflowInstanceHost=172.18.0.9:5678, taskInstanceHost=172.18.1.1:1234, logPath=null, processId=0, eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1122] - [INFO] 2024-04-23 10:10:06.798 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionInfoEvent(taskInstanceId=1122, processInstanceId=487, startTime=1713838206568, workflowInstanceHost=172.18.0.9:5678, taskInstanceHost=172.18.1.1:1234, logPath=null, processId=0, eventCreateTime=0, eventSendTime=1713838206789)
[WI-0][TI-1122] - [INFO] 2024-04-23 10:10:07.406 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1122, success=true)
[WI-0][TI-1122] - [INFO] 2024-04-23 10:10:07.412 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1122)
[WI-0][TI-1122] - [INFO] 2024-04-23 10:10:07.417 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1122, success=true)
[WI-0][TI-1122] - [INFO] 2024-04-23 10:10:07.424 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1122)
[WI-0][TI-0] - [INFO] 2024-04-23 10:10:07.628 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	JSON is already in processing
	#{setValue(raw_file_dir=/local_storage/reddit/processing/386-20240422.json)}
[WI-487][TI-1122] - [INFO] 2024-04-23 10:10:07.629 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1122, processId:1665 ,exitStatusCode:0 ,processWaitForStatus:true ,processExitValue:0
[WI-487][TI-1122] - [INFO] 2024-04-23 10:10:07.629 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-487][TI-1122] - [INFO] 2024-04-23 10:10:07.629 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-487][TI-1122] - [INFO] 2024-04-23 10:10:07.629 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-487][TI-1122] - [INFO] 2024-04-23 10:10:07.631 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-487][TI-1122] - [INFO] 2024-04-23 10:10:07.634 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: SUCCESS to master : 172.18.1.1:1234
[WI-487][TI-1122] - [INFO] 2024-04-23 10:10:07.634 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-487][TI-1122] - [INFO] 2024-04-23 10:10:07.634 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1122
[WI-487][TI-1122] - [INFO] 2024-04-23 10:10:07.635 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1122
[WI-487][TI-1122] - [INFO] 2024-04-23 10:10:07.635 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-1122] - [INFO] 2024-04-23 10:10:07.801 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1122, processInstanceId=487, status=7, startTime=1713838206568, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1122.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1122, endTime=1713838207630, processId=1665, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1122] - [INFO] 2024-04-23 10:10:07.806 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1122, processInstanceId=487, status=7, startTime=1713838206568, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1122.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1122, endTime=1713838207630, processId=1665, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713838207800)
[WI-0][TI-1122] - [INFO] 2024-04-23 10:10:08.405 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1122, success=true)
[WI-0][TI-1122] - [INFO] 2024-04-23 10:10:08.407 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1122, success=true)
[WI-0][TI-0] - [INFO] 2024-04-23 10:10:08.500 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1123, taskName=spark preprocessing, firstSubmitTime=1713838208477, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.9:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=78, appIds=null, processInstanceId=487, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"processing"}], executorId=1, cmdTypeIfComplement=7, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[],"rawScript":"$SPARK_HOME/bin/spark-submit \\\n    --master spark://spark-master:7077 \\\n    --conf spark.driver.cores=1 \\\n    --conf spark.driver.memory=512M \\\n    --conf spark.executor.instances=2 \\\n    --conf spark.executor.cores=2 \\\n    --conf spark.executor.memory=1G \\\n    --files ${raw_file_dir} \\\n    --name reddit_preprocessing spark_reddit_preprocessing.py\n","resourceList":[{"id":null,"resourceName":"file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py","res":null}]}, environmentConfig=export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export HADOOP_CONF_DIR=/opt/hadoop-3.4.0/etc/hadoop
export PYSPARK_DRIVER_PYTHON=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='spark preprocessing'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240423'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1123'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13210058002752'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240423101008'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='processing'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='487'}, raw_file_dir=Property{prop='raw_file_dir', direct=IN, type=VARCHAR, value='/local_storage/reddit/processing/386-20240422.json'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240422'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-487][TI-1123] - [INFO] 2024-04-23 10:10:08.502 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: spark preprocessing to wait queue success
[WI-487][TI-1123] - [INFO] 2024-04-23 10:10:08.502 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-487][TI-1123] - [INFO] 2024-04-23 10:10:08.503 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-487][TI-1123] - [INFO] 2024-04-23 10:10:08.504 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-487][TI-1123] - [INFO] 2024-04-23 10:10:08.504 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-487][TI-1123] - [INFO] 2024-04-23 10:10:08.504 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713838208504
[WI-487][TI-1123] - [INFO] 2024-04-23 10:10:08.504 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 487_1123
[WI-487][TI-1123] - [INFO] 2024-04-23 10:10:08.504 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1123,
  "taskName" : "spark preprocessing",
  "firstSubmitTime" : 1713838208477,
  "startTime" : 1713838208504,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.9:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1123.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 78,
  "processInstanceId" : 487,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"processing\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 7,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[],\"rawScript\":\"$SPARK_HOME/bin/spark-submit \\\\\\n    --master spark://spark-master:7077 \\\\\\n    --conf spark.driver.cores=1 \\\\\\n    --conf spark.driver.memory=512M \\\\\\n    --conf spark.executor.instances=2 \\\\\\n    --conf spark.executor.cores=2 \\\\\\n    --conf spark.executor.memory=1G \\\\\\n    --files ${raw_file_dir} \\\\\\n    --name reddit_preprocessing spark_reddit_preprocessing.py\\n\",\"resourceList\":[{\"id\":null,\"resourceName\":\"file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py\",\"res\":null}]}",
  "environmentConfig" : "export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3\nexport JAVA_HOME=/opt/java/openjdk\nexport HADOOP_CONF_DIR=/opt/hadoop-3.4.0/etc/hadoop\nexport PYSPARK_DRIVER_PYTHON=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "spark preprocessing"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1123"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13210058002752"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423101008"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "processing"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "487"
    },
    "raw_file_dir" : {
      "prop" : "raw_file_dir",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit/processing/386-20240422.json"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240422"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "487_1123",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"raw_file_dir\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"/local_storage/reddit/processing/386-20240422.json\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-487][TI-1123] - [INFO] 2024-04-23 10:10:08.505 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-487][TI-1123] - [INFO] 2024-04-23 10:10:08.505 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-487][TI-1123] - [INFO] 2024-04-23 10:10:08.505 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-487][TI-1123] - [INFO] 2024-04-23 10:10:08.508 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-487][TI-1123] - [INFO] 2024-04-23 10:10:08.508 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-487][TI-1123] - [INFO] 2024-04-23 10:10:08.509 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1123 check successfully
[WI-487][TI-1123] - [INFO] 2024-04-23 10:10:08.509 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-487][TI-1123] - [INFO] 2024-04-23 10:10:08.511 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py=ResourceContext.ResourceItem(resourceAbsolutePathInStorage=file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py, resourceRelativePath=spark_reddit_preprocessing.py, resourceAbsolutePathInLocal=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1123/spark_reddit_preprocessing.py)})
[WI-487][TI-1123] - [INFO] 2024-04-23 10:10:08.511 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-487][TI-1123] - [INFO] 2024-04-23 10:10:08.511 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-487][TI-1123] - [INFO] 2024-04-23 10:10:08.511 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ ],
  "varPool" : null,
  "rawScript" : "$SPARK_HOME/bin/spark-submit \\\n    --master spark://spark-master:7077 \\\n    --conf spark.driver.cores=1 \\\n    --conf spark.driver.memory=512M \\\n    --conf spark.executor.instances=2 \\\n    --conf spark.executor.cores=2 \\\n    --conf spark.executor.memory=1G \\\n    --files ${raw_file_dir} \\\n    --name reddit_preprocessing spark_reddit_preprocessing.py\n",
  "resourceList" : [ {
    "id" : null,
    "resourceName" : "file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py",
    "res" : null
  } ]
}
[WI-487][TI-1123] - [INFO] 2024-04-23 10:10:08.512 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-487][TI-1123] - [INFO] 2024-04-23 10:10:08.512 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}] successfully
[WI-487][TI-1123] - [INFO] 2024-04-23 10:10:08.512 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-487][TI-1123] - [INFO] 2024-04-23 10:10:08.512 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-487][TI-1123] - [INFO] 2024-04-23 10:10:08.512 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-487][TI-1123] - [INFO] 2024-04-23 10:10:08.512 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-487][TI-1123] - [INFO] 2024-04-23 10:10:08.512 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-487][TI-1123] - [INFO] 2024-04-23 10:10:08.512 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export HADOOP_CONF_DIR=/opt/hadoop-3.4.0/etc/hadoop
export PYSPARK_DRIVER_PYTHON=/bin/python3.11
$SPARK_HOME/bin/spark-submit \
    --master spark://spark-master:7077 \
    --conf spark.driver.cores=1 \
    --conf spark.driver.memory=512M \
    --conf spark.executor.instances=2 \
    --conf spark.executor.cores=2 \
    --conf spark.executor.memory=1G \
    --files /local_storage/reddit/processing/386-20240422.json \
    --name reddit_preprocessing spark_reddit_preprocessing.py

[WI-487][TI-1123] - [INFO] 2024-04-23 10:10:08.512 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-487][TI-1123] - [INFO] 2024-04-23 10:10:08.513 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1123/487_1123.sh
[WI-487][TI-1123] - [INFO] 2024-04-23 10:10:08.517 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 1677
[WI-0][TI-1123] - [INFO] 2024-04-23 10:10:08.830 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionRunningEvent(taskInstanceId=1123, processInstanceId=487, startTime=1713838208504, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, status=TaskExecutionStatus{code=1, desc='running'}, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1123.log, executePath=null, processId=0, appIds=null, eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1123] - [INFO] 2024-04-23 10:10:08.836 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionRunningEvent(taskInstanceId=1123, processInstanceId=487, startTime=1713838208504, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, status=TaskExecutionStatus{code=1, desc='running'}, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1123.log, executePath=null, processId=0, appIds=null, eventCreateTime=0, eventSendTime=1713838208809)
[WI-0][TI-1123] - [INFO] 2024-04-23 10:10:08.836 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionInfoEvent(taskInstanceId=1123, processInstanceId=487, startTime=1713838208504, workflowInstanceHost=172.18.0.9:5678, taskInstanceHost=172.18.1.1:1234, logPath=null, processId=0, eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1123] - [INFO] 2024-04-23 10:10:08.848 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionInfoEvent(taskInstanceId=1123, processInstanceId=487, startTime=1713838208504, workflowInstanceHost=172.18.0.9:5678, taskInstanceHost=172.18.1.1:1234, logPath=null, processId=0, eventCreateTime=0, eventSendTime=1713838208809)
[WI-0][TI-1123] - [INFO] 2024-04-23 10:10:09.405 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1123, success=true)
[WI-0][TI-1123] - [INFO] 2024-04-23 10:10:09.413 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1123)
[WI-0][TI-1123] - [INFO] 2024-04-23 10:10:09.427 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1123, success=true)
[WI-0][TI-1123] - [INFO] 2024-04-23 10:10:09.435 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1123)
[WI-0][TI-0] - [INFO] 2024-04-23 10:10:09.518 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
[WI-0][TI-0] - [INFO] 2024-04-23 10:10:11.522 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:10:10 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[WI-0][TI-0] - [INFO] 2024-04-23 10:10:12.530 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:10:11 INFO SparkContext: Running Spark version 3.5.1
	24/04/23 10:10:11 INFO SparkContext: OS info Linux, 6.5.0-28-generic, amd64
	24/04/23 10:10:11 INFO SparkContext: Java version 1.8.0_402
	24/04/23 10:10:11 INFO ResourceUtils: ==============================================================
	24/04/23 10:10:11 INFO ResourceUtils: No custom resources configured for spark.driver.
	24/04/23 10:10:11 INFO ResourceUtils: ==============================================================
	24/04/23 10:10:11 INFO SparkContext: Submitted application: reddit_preprocessing
	24/04/23 10:10:11 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 2, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
	24/04/23 10:10:11 INFO ResourceProfile: Limiting resource is cpus at 2 tasks per executor
	24/04/23 10:10:11 INFO ResourceProfileManager: Added ResourceProfile id: 0
	24/04/23 10:10:11 INFO SecurityManager: Changing view acls to: default
	24/04/23 10:10:11 INFO SecurityManager: Changing modify acls to: default
	24/04/23 10:10:11 INFO SecurityManager: Changing view acls groups to: 
	24/04/23 10:10:11 INFO SecurityManager: Changing modify acls groups to: 
	24/04/23 10:10:11 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: default; groups with view permissions: EMPTY; users with modify permissions: default; groups with modify permissions: EMPTY
	24/04/23 10:10:12 INFO Utils: Successfully started service 'sparkDriver' on port 40667.
[WI-0][TI-0] - [INFO] 2024-04-23 10:10:12.678 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7204968944099379 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:10:13.532 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:10:12 INFO SparkEnv: Registering MapOutputTracker
	24/04/23 10:10:12 INFO SparkEnv: Registering BlockManagerMaster
	24/04/23 10:10:12 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
	24/04/23 10:10:12 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
	24/04/23 10:10:12 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
	24/04/23 10:10:12 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-255595d7-a12a-4c19-99eb-df9166c18b1b
	24/04/23 10:10:12 INFO MemoryStore: MemoryStore started with capacity 93.3 MiB
	24/04/23 10:10:12 INFO SparkEnv: Registering OutputCommitCoordinator
	24/04/23 10:10:12 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
	24/04/23 10:10:12 INFO Utils: Successfully started service 'SparkUI' on port 4040.
	24/04/23 10:10:12 INFO SparkContext: Added file file:///local_storage/reddit/processing/386-20240422.json at spark://c0e814e3f0bd:40667/files/386-20240422.json with timestamp 1713838211739
	24/04/23 10:10:12 INFO Utils: Copying /local_storage/reddit/processing/386-20240422.json to /tmp/spark-71b53730-ff6f-44b6-b12e-a4d4cc58d593/userFiles-ead2ed75-2563-46a3-9460-c6e30fb17489/386-20240422.json
	24/04/23 10:10:13 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
	24/04/23 10:10:13 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.3:7077 after 35 ms (0 ms spent in bootstraps)
	24/04/23 10:10:13 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20240423021013-0005
	24/04/23 10:10:13 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20240423021013-0005/0 on worker-20240423012857-172.18.0.7-41063 (172.18.0.7:41063) with 2 core(s)
	24/04/23 10:10:13 INFO StandaloneSchedulerBackend: Granted executor ID app-20240423021013-0005/0 on hostPort 172.18.0.7:41063 with 2 core(s), 1024.0 MiB RAM
	24/04/23 10:10:13 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46773.
	24/04/23 10:10:13 INFO NettyBlockTransferService: Server created on c0e814e3f0bd:46773
	24/04/23 10:10:13 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
	24/04/23 10:10:13 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, c0e814e3f0bd, 46773, None)
	24/04/23 10:10:13 INFO BlockManagerMasterEndpoint: Registering block manager c0e814e3f0bd:46773 with 93.3 MiB RAM, BlockManagerId(driver, c0e814e3f0bd, 46773, None)
	24/04/23 10:10:13 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, c0e814e3f0bd, 46773, None)
	24/04/23 10:10:13 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, c0e814e3f0bd, 46773, None)
	24/04/23 10:10:13 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20240423021013-0005/0 is now RUNNING
[WI-0][TI-0] - [INFO] 2024-04-23 10:10:14.536 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:10:13 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
	
	
	
	 /tmp/spark-71b53730-ff6f-44b6-b12e-a4d4cc58d593/userFiles-ead2ed75-2563-46a3-9460-c6e30fb17489/386-20240422.json 
	
	
	
	24/04/23 10:10:14 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
	24/04/23 10:10:14 INFO SharedState: Warehouse path is 'file:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1123/spark-warehouse'.
[WI-0][TI-0] - [INFO] 2024-04-23 10:10:14.748 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8289473684210525 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:10:15.795 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9491525423728814 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:10:16.559 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:10:16 INFO InMemoryFileIndex: It took 48 ms to list leaf files for 1 paths.
	24/04/23 10:10:16 INFO InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.
[WI-0][TI-0] - [INFO] 2024-04-23 10:10:16.807 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8174904942965779 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:10:18.580 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:10:17 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.7:59928) with ID 0,  ResourceProfileId 0
	24/04/23 10:10:18 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.7:40723 with 434.4 MiB RAM, BlockManagerId(0, 172.18.0.7, 40723, None)
[WI-0][TI-0] - [INFO] 2024-04-23 10:10:18.860 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8213333333333334 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:10:19.913 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7254901960784315 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:10:20.921 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7848837209302326 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:10:21.602 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:10:20 INFO FileSourceStrategy: Pushed Filters: 
	24/04/23 10:10:20 INFO FileSourceStrategy: Post-Scan Filters: 
	24/04/23 10:10:21 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 351.5 KiB, free 93.0 MiB)
	24/04/23 10:10:21 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 34.6 KiB, free 92.9 MiB)
	24/04/23 10:10:21 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on c0e814e3f0bd:46773 (size: 34.6 KiB, free: 93.3 MiB)
	24/04/23 10:10:21 INFO SparkContext: Created broadcast 0 from json at NativeMethodAccessorImpl.java:0
[WI-0][TI-0] - [INFO] 2024-04-23 10:10:21.923 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.824 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:10:22.609 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:10:21 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
	24/04/23 10:10:21 INFO SparkContext: Starting job: json at NativeMethodAccessorImpl.java:0
	24/04/23 10:10:21 INFO DAGScheduler: Got job 0 (json at NativeMethodAccessorImpl.java:0) with 1 output partitions
	24/04/23 10:10:21 INFO DAGScheduler: Final stage: ResultStage 0 (json at NativeMethodAccessorImpl.java:0)
	24/04/23 10:10:21 INFO DAGScheduler: Parents of final stage: List()
	24/04/23 10:10:21 INFO DAGScheduler: Missing parents: List()
	24/04/23 10:10:21 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at json at NativeMethodAccessorImpl.java:0), which has no missing parents
	24/04/23 10:10:22 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 16.5 KiB, free 92.9 MiB)
	24/04/23 10:10:22 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.8 KiB, free 92.9 MiB)
	24/04/23 10:10:22 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on c0e814e3f0bd:46773 (size: 7.8 KiB, free: 93.3 MiB)
	24/04/23 10:10:22 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1585
	24/04/23 10:10:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at json at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
	24/04/23 10:10:22 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
	24/04/23 10:10:22 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.7, executor 0, partition 0, PROCESS_LOCAL, 8478 bytes) 
[WI-0][TI-0] - [INFO] 2024-04-23 10:10:22.924 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8117977528089887 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:11:05.939 +0800 o.a.d.s.w.r.o.TaskInstanceKillOperationFunction:[55] - Receive TaskInstanceKillRequest: TaskInstanceKillRequest(taskInstanceId=1123)
[WI-0][TI-1123] - [ERROR] 2024-04-23 10:11:05.957 +0800 o.a.d.s.w.r.o.TaskInstanceKillOperationFunction:[139] - kill task error
java.io.IOException: Cannot run program "pstree": error=2, No such file or directory
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1048)
	at org.apache.dolphinscheduler.common.shell.AbstractShell.runCommand(AbstractShell.java:138)
	at org.apache.dolphinscheduler.common.shell.AbstractShell.run(AbstractShell.java:118)
	at org.apache.dolphinscheduler.common.shell.ShellExecutor.execute(ShellExecutor.java:125)
	at org.apache.dolphinscheduler.common.shell.ShellExecutor.execCommand(ShellExecutor.java:103)
	at org.apache.dolphinscheduler.common.shell.ShellExecutor.execCommand(ShellExecutor.java:86)
	at org.apache.dolphinscheduler.common.utils.OSUtils.exeShell(OSUtils.java:345)
	at org.apache.dolphinscheduler.common.utils.OSUtils.exeCmd(OSUtils.java:334)
	at org.apache.dolphinscheduler.plugin.task.api.utils.ProcessUtils.getPidsStr(ProcessUtils.java:129)
	at org.apache.dolphinscheduler.server.worker.runner.operator.TaskInstanceKillOperationFunction.killProcess(TaskInstanceKillOperationFunction.java:130)
	at org.apache.dolphinscheduler.server.worker.runner.operator.TaskInstanceKillOperationFunction.doKill(TaskInstanceKillOperationFunction.java:96)
	at org.apache.dolphinscheduler.server.worker.runner.operator.TaskInstanceKillOperationFunction.operate(TaskInstanceKillOperationFunction.java:69)
	at org.apache.dolphinscheduler.server.worker.rpc.TaskInstanceOperatorImpl.killTask(TaskInstanceOperatorImpl.java:49)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.dolphinscheduler.extract.base.server.ServerMethodInvokerImpl.invoke(ServerMethodInvokerImpl.java:41)
	at org.apache.dolphinscheduler.extract.base.server.JdkDynamicServerHandler.lambda$processReceived$0(JdkDynamicServerHandler.java:108)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.io.IOException: error=2, No such file or directory
	at java.lang.UNIXProcess.forkAndExec(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:247)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	... 21 common frames omitted
[WI-0][TI-1123] - [INFO] 2024-04-23 10:11:05.957 +0800 o.a.d.p.t.a.u.ProcessUtils:[182] - Get appIds from worker 172.18.1.1:1234, taskLogPath: /opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1123.log
[WI-0][TI-1123] - [INFO] 2024-04-23 10:11:05.958 +0800 o.a.d.p.t.a.u.LogUtils:[79] - Start finding appId in /opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1123.log, fetch way: log 
[WI-0][TI-1123] - [INFO] 2024-04-23 10:11:05.958 +0800 o.a.d.p.t.a.u.ProcessUtils:[188] - The appId is empty
[WI-0][TI-1123] - [INFO] 2024-04-23 10:11:05.958 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[220] - Begin to kill process process, pid is : 1677
[WI-0][TI-1123] - [INFO] 2024-04-23 10:11:10.966 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[225] - Success kill task: 487_1123, pid: 1677
[WI-0][TI-1123] - [INFO] 2024-04-23 10:11:10.967 +0800 o.a.d.s.w.r.o.TaskInstanceKillOperationFunction:[119] - kill task by cancelApplication, taskInstanceId: 1123
[WI-0][TI-0] - [INFO] 2024-04-23 10:11:11.083 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7865011173008529 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:11:49.276 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8791208791208791 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:12:00.127 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1124, taskName=search for intake JSON files, firstSubmitTime=1713838320091, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.9:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=79, appIds=null, processInstanceId=488, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"processing"}], executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":""}],"rawScript":"# find 1 raw file in the folder\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\n\n# check if raw_file_dir is empty, then set raw_file_dir to null\nif [ -z \"$raw_file_dir\" ]; then\n    raw_file_dir=null\nfi\n\necho \"#{setValue(raw_file_dir=${raw_file_dir})}\"","resourceList":[]}, environmentConfig=export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='search for intake JSON files'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240423'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1124'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13340113777664'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240423101200'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='processing'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='488'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240422'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=null, dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-488][TI-1124] - [INFO] 2024-04-23 10:12:00.130 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: search for intake JSON files to wait queue success
[WI-488][TI-1124] - [INFO] 2024-04-23 10:12:00.130 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-488][TI-1124] - [INFO] 2024-04-23 10:12:00.135 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-488][TI-1124] - [INFO] 2024-04-23 10:12:00.136 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-488][TI-1124] - [INFO] 2024-04-23 10:12:00.136 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-488][TI-1124] - [INFO] 2024-04-23 10:12:00.136 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713838320136
[WI-488][TI-1124] - [INFO] 2024-04-23 10:12:00.136 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 488_1124
[WI-488][TI-1124] - [INFO] 2024-04-23 10:12:00.137 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1124,
  "taskName" : "search for intake JSON files",
  "firstSubmitTime" : 1713838320091,
  "startTime" : 1713838320136,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.9:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240423/13201021801792/79/488/1124.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 79,
  "processInstanceId" : 488,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"processing\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[{\"prop\":\"raw_file_dir\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"\"}],\"rawScript\":\"# find 1 raw file in the folder\\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\\n\\n# check if raw_file_dir is empty, then set raw_file_dir to null\\nif [ -z \\\"$raw_file_dir\\\" ]; then\\n    raw_file_dir=null\\nfi\\n\\necho \\\"#{setValue(raw_file_dir=${raw_file_dir})}\\\"\",\"resourceList\":[]}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "search for intake JSON files"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1124"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13340113777664"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423101200"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "processing"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "488"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240422"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "488_1124",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-488][TI-1124] - [INFO] 2024-04-23 10:12:00.138 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-488][TI-1124] - [INFO] 2024-04-23 10:12:00.138 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-488][TI-1124] - [INFO] 2024-04-23 10:12:00.138 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-488][TI-1124] - [INFO] 2024-04-23 10:12:00.154 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-488][TI-1124] - [INFO] 2024-04-23 10:12:00.155 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-488][TI-1124] - [INFO] 2024-04-23 10:12:00.156 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_79/488/1124 check successfully
[WI-488][TI-1124] - [INFO] 2024-04-23 10:12:00.156 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-488][TI-1124] - [INFO] 2024-04-23 10:12:00.157 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-488][TI-1124] - [INFO] 2024-04-23 10:12:00.161 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-488][TI-1124] - [INFO] 2024-04-23 10:12:00.162 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-488][TI-1124] - [INFO] 2024-04-23 10:12:00.163 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ {
    "prop" : "raw_file_dir",
    "direct" : "OUT",
    "type" : "VARCHAR",
    "value" : ""
  } ],
  "varPool" : null,
  "rawScript" : "# find 1 raw file in the folder\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\n\n# check if raw_file_dir is empty, then set raw_file_dir to null\nif [ -z \"$raw_file_dir\" ]; then\n    raw_file_dir=null\nfi\n\necho \"#{setValue(raw_file_dir=${raw_file_dir})}\"",
  "resourceList" : [ ]
}
[WI-488][TI-1124] - [INFO] 2024-04-23 10:12:00.163 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-488][TI-1124] - [INFO] 2024-04-23 10:12:00.164 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: null successfully
[WI-488][TI-1124] - [INFO] 2024-04-23 10:12:00.164 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-488][TI-1124] - [INFO] 2024-04-23 10:12:00.164 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-488][TI-1124] - [INFO] 2024-04-23 10:12:00.164 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-488][TI-1124] - [INFO] 2024-04-23 10:12:00.165 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-488][TI-1124] - [INFO] 2024-04-23 10:12:00.167 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-488][TI-1124] - [INFO] 2024-04-23 10:12:00.168 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export PYTHON_LAUNCHER=/bin/python3.11
# find 1 raw file in the folder
raw_file_dir=$(find /local_storage/reddit/processing -type f -name '*.json'| head -n 1)

# check if raw_file_dir is empty, then set raw_file_dir to null
if [ -z "$raw_file_dir" ]; then
    raw_file_dir=null
fi

echo "#{setValue(raw_file_dir=${raw_file_dir})}"
[WI-488][TI-1124] - [INFO] 2024-04-23 10:12:00.168 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-488][TI-1124] - [INFO] 2024-04-23 10:12:00.168 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_79/488/1124/488_1124.sh
[WI-488][TI-1124] - [INFO] 2024-04-23 10:12:00.175 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 1810
[WI-0][TI-1124] - [INFO] 2024-04-23 10:12:00.716 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1124, success=true)
[WI-0][TI-1124] - [INFO] 2024-04-23 10:12:00.723 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1124)
[WI-0][TI-0] - [INFO] 2024-04-23 10:12:01.183 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
	#{setValue(raw_file_dir=/local_storage/reddit/processing/386-20240422.json)}
[WI-488][TI-1124] - [INFO] 2024-04-23 10:12:01.185 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_79/488/1124, processId:1810 ,exitStatusCode:0 ,processWaitForStatus:true ,processExitValue:0
[WI-488][TI-1124] - [INFO] 2024-04-23 10:12:01.185 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-488][TI-1124] - [INFO] 2024-04-23 10:12:01.185 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-488][TI-1124] - [INFO] 2024-04-23 10:12:01.185 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-488][TI-1124] - [INFO] 2024-04-23 10:12:01.188 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-488][TI-1124] - [INFO] 2024-04-23 10:12:01.201 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: SUCCESS to master : 172.18.1.1:1234
[WI-488][TI-1124] - [INFO] 2024-04-23 10:12:01.203 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-488][TI-1124] - [INFO] 2024-04-23 10:12:01.204 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_79/488/1124
[WI-488][TI-1124] - [INFO] 2024-04-23 10:12:01.205 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_79/488/1124
[WI-488][TI-1124] - [INFO] 2024-04-23 10:12:01.205 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-1124] - [INFO] 2024-04-23 10:12:01.738 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1124, success=true)
[WI-0][TI-0] - [INFO] 2024-04-23 10:12:02.816 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1126, taskName=move to processing, firstSubmitTime=1713838322806, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.9:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=79, appIds=null, processInstanceId=488, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"processing"}], executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":""}],"rawScript":"# move file to the reddit processing folder\n# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error\nfilename=$(basename \"${raw_file_dir}\")\nif ! grep -q \"${REDDIT_HOME}/processing\" <<< \"${raw_file_dir}\"; then\n    mv ${raw_file_dir} ${REDDIT_HOME}/processing\nelse\n    echo JSON is already in processing\nfi\n\n# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing\necho \"#{setValue(raw_file_dir=${REDDIT_HOME}/processing/${filename})}\"","resourceList":[]}, environmentConfig=export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='move to processing'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240423'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1126'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13340390094208'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240423101202'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='processing'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='488'}, raw_file_dir=Property{prop='raw_file_dir', direct=IN, type=VARCHAR, value='/local_storage/reddit/processing/386-20240422.json'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240422'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-488][TI-1126] - [INFO] 2024-04-23 10:12:02.817 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: move to processing to wait queue success
[WI-488][TI-1126] - [INFO] 2024-04-23 10:12:02.818 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-488][TI-1126] - [INFO] 2024-04-23 10:12:02.819 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-488][TI-1126] - [INFO] 2024-04-23 10:12:02.819 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-488][TI-1126] - [INFO] 2024-04-23 10:12:02.819 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-488][TI-1126] - [INFO] 2024-04-23 10:12:02.820 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713838322820
[WI-488][TI-1126] - [INFO] 2024-04-23 10:12:02.820 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 488_1126
[WI-488][TI-1126] - [INFO] 2024-04-23 10:12:02.820 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1126,
  "taskName" : "move to processing",
  "firstSubmitTime" : 1713838322806,
  "startTime" : 1713838322820,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.9:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240423/13201021801792/79/488/1126.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 79,
  "processInstanceId" : 488,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"processing\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[{\"prop\":\"raw_file_dir\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"\"}],\"rawScript\":\"# move file to the reddit processing folder\\n# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error\\nfilename=$(basename \\\"${raw_file_dir}\\\")\\nif ! grep -q \\\"${REDDIT_HOME}/processing\\\" <<< \\\"${raw_file_dir}\\\"; then\\n    mv ${raw_file_dir} ${REDDIT_HOME}/processing\\nelse\\n    echo JSON is already in processing\\nfi\\n\\n# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing\\necho \\\"#{setValue(raw_file_dir=${REDDIT_HOME}/processing/${filename})}\\\"\",\"resourceList\":[]}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "move to processing"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1126"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13340390094208"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423101202"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "processing"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "488"
    },
    "raw_file_dir" : {
      "prop" : "raw_file_dir",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit/processing/386-20240422.json"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240422"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "488_1126",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"raw_file_dir\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"/local_storage/reddit/processing/386-20240422.json\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-488][TI-1126] - [INFO] 2024-04-23 10:12:02.820 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-488][TI-1126] - [INFO] 2024-04-23 10:12:02.820 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-488][TI-1126] - [INFO] 2024-04-23 10:12:02.820 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-488][TI-1126] - [INFO] 2024-04-23 10:12:02.825 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-488][TI-1126] - [INFO] 2024-04-23 10:12:02.826 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-488][TI-1126] - [INFO] 2024-04-23 10:12:02.828 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_79/488/1126 check successfully
[WI-488][TI-1126] - [INFO] 2024-04-23 10:12:02.828 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-488][TI-1126] - [INFO] 2024-04-23 10:12:02.833 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-488][TI-1126] - [INFO] 2024-04-23 10:12:02.841 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-488][TI-1126] - [INFO] 2024-04-23 10:12:02.841 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-488][TI-1126] - [INFO] 2024-04-23 10:12:02.842 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ {
    "prop" : "raw_file_dir",
    "direct" : "OUT",
    "type" : "VARCHAR",
    "value" : ""
  } ],
  "varPool" : null,
  "rawScript" : "# move file to the reddit processing folder\n# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error\nfilename=$(basename \"${raw_file_dir}\")\nif ! grep -q \"${REDDIT_HOME}/processing\" <<< \"${raw_file_dir}\"; then\n    mv ${raw_file_dir} ${REDDIT_HOME}/processing\nelse\n    echo JSON is already in processing\nfi\n\n# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing\necho \"#{setValue(raw_file_dir=${REDDIT_HOME}/processing/${filename})}\"",
  "resourceList" : [ ]
}
[WI-488][TI-1126] - [INFO] 2024-04-23 10:12:02.842 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-488][TI-1126] - [INFO] 2024-04-23 10:12:02.842 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}] successfully
[WI-488][TI-1126] - [INFO] 2024-04-23 10:12:02.842 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-488][TI-1126] - [INFO] 2024-04-23 10:12:02.842 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-488][TI-1126] - [INFO] 2024-04-23 10:12:02.842 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-488][TI-1126] - [INFO] 2024-04-23 10:12:02.843 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-488][TI-1126] - [INFO] 2024-04-23 10:12:02.843 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-488][TI-1126] - [INFO] 2024-04-23 10:12:02.843 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export PYTHON_LAUNCHER=/bin/python3.11
# move file to the reddit processing folder
# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error
filename=$(basename "/local_storage/reddit/processing/386-20240422.json")
if ! grep -q "/local_storage/reddit/processing" <<< "/local_storage/reddit/processing/386-20240422.json"; then
    mv /local_storage/reddit/processing/386-20240422.json /local_storage/reddit/processing
else
    echo JSON is already in processing
fi

# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing
echo "#{setValue(raw_file_dir=/local_storage/reddit/processing/${filename})}"
[WI-488][TI-1126] - [INFO] 2024-04-23 10:12:02.843 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-488][TI-1126] - [INFO] 2024-04-23 10:12:02.843 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_79/488/1126/488_1126.sh
[WI-488][TI-1126] - [INFO] 2024-04-23 10:12:02.892 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 1824
[WI-0][TI-0] - [INFO] 2024-04-23 10:12:02.900 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
[WI-0][TI-1126] - [INFO] 2024-04-23 10:12:03.091 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionRunningEvent(taskInstanceId=1126, processInstanceId=488, startTime=1713838322820, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, status=TaskExecutionStatus{code=1, desc='running'}, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/79/488/1126.log, executePath=null, processId=0, appIds=null, eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1126] - [INFO] 2024-04-23 10:12:03.117 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionRunningEvent(taskInstanceId=1126, processInstanceId=488, startTime=1713838322820, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, status=TaskExecutionStatus{code=1, desc='running'}, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/79/488/1126.log, executePath=null, processId=0, appIds=null, eventCreateTime=0, eventSendTime=1713838323091)
[WI-0][TI-1126] - [INFO] 2024-04-23 10:12:03.117 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionInfoEvent(taskInstanceId=1126, processInstanceId=488, startTime=1713838322820, workflowInstanceHost=172.18.0.9:5678, taskInstanceHost=172.18.1.1:1234, logPath=null, processId=0, eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1126] - [INFO] 2024-04-23 10:12:03.138 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionInfoEvent(taskInstanceId=1126, processInstanceId=488, startTime=1713838322820, workflowInstanceHost=172.18.0.9:5678, taskInstanceHost=172.18.1.1:1234, logPath=null, processId=0, eventCreateTime=0, eventSendTime=1713838323091)
[WI-0][TI-1126] - [INFO] 2024-04-23 10:12:03.725 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1126, success=true)
[WI-0][TI-1126] - [INFO] 2024-04-23 10:12:03.730 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1126)
[WI-0][TI-1126] - [INFO] 2024-04-23 10:12:03.739 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1126, success=true)
[WI-0][TI-1126] - [INFO] 2024-04-23 10:12:03.744 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1126)
[WI-0][TI-0] - [INFO] 2024-04-23 10:12:03.907 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	JSON is already in processing
	#{setValue(raw_file_dir=/local_storage/reddit/processing/386-20240422.json)}
[WI-488][TI-1126] - [INFO] 2024-04-23 10:12:03.908 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_79/488/1126, processId:1824 ,exitStatusCode:0 ,processWaitForStatus:true ,processExitValue:0
[WI-488][TI-1126] - [INFO] 2024-04-23 10:12:03.909 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-488][TI-1126] - [INFO] 2024-04-23 10:12:03.909 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-488][TI-1126] - [INFO] 2024-04-23 10:12:03.909 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-488][TI-1126] - [INFO] 2024-04-23 10:12:03.909 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-488][TI-1126] - [INFO] 2024-04-23 10:12:03.930 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: SUCCESS to master : 172.18.1.1:1234
[WI-488][TI-1126] - [INFO] 2024-04-23 10:12:03.930 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-488][TI-1126] - [INFO] 2024-04-23 10:12:03.930 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_79/488/1126
[WI-488][TI-1126] - [INFO] 2024-04-23 10:12:03.930 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_79/488/1126
[WI-488][TI-1126] - [INFO] 2024-04-23 10:12:03.930 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-1126] - [INFO] 2024-04-23 10:12:04.139 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1126, processInstanceId=488, status=7, startTime=1713838322820, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/79/488/1126.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_79/488/1126, endTime=1713838323909, processId=1824, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1126] - [INFO] 2024-04-23 10:12:04.147 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1126, processInstanceId=488, status=7, startTime=1713838322820, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/79/488/1126.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_79/488/1126, endTime=1713838323909, processId=1824, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713838324139)
[WI-0][TI-1126] - [INFO] 2024-04-23 10:12:04.747 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1126, success=true)
[WI-0][TI-1126] - [INFO] 2024-04-23 10:12:04.751 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1126, success=true)
[WI-0][TI-0] - [INFO] 2024-04-23 10:12:04.900 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1127, taskName=spark preprocessing, firstSubmitTime=1713838324892, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.9:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=79, appIds=null, processInstanceId=488, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"processing"}], executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[],"rawScript":"$SPARK_HOME/bin/spark-submit \\\n    --master spark://spark-master:7077 \\\n    --conf spark.driver.cores=2 \\\n    --conf spark.driver.memory=2G \\\n    --conf spark.executor.instances=2 \\\n    --conf spark.executor.cores=2 \\\n    --conf spark.executor.memory=2G \\\n    --files ${raw_file_dir} \\\n    --name reddit_preprocessing spark_reddit_preprocessing.py\n","resourceList":[{"id":null,"resourceName":"file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py","res":null}]}, environmentConfig=export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export HADOOP_CONF_DIR=/opt/hadoop-3.4.0/etc/hadoop
export PYSPARK_DRIVER_PYTHON=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='spark preprocessing'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240423'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1127'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13210058002752'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240423101204'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='processing'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='488'}, raw_file_dir=Property{prop='raw_file_dir', direct=IN, type=VARCHAR, value='/local_storage/reddit/processing/386-20240422.json'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240422'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-488][TI-1127] - [INFO] 2024-04-23 10:12:04.902 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: spark preprocessing to wait queue success
[WI-488][TI-1127] - [INFO] 2024-04-23 10:12:04.902 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-488][TI-1127] - [INFO] 2024-04-23 10:12:04.903 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-488][TI-1127] - [INFO] 2024-04-23 10:12:04.903 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-488][TI-1127] - [INFO] 2024-04-23 10:12:04.903 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-488][TI-1127] - [INFO] 2024-04-23 10:12:04.903 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713838324903
[WI-488][TI-1127] - [INFO] 2024-04-23 10:12:04.904 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 488_1127
[WI-488][TI-1127] - [INFO] 2024-04-23 10:12:04.904 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1127,
  "taskName" : "spark preprocessing",
  "firstSubmitTime" : 1713838324892,
  "startTime" : 1713838324903,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.9:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240423/13201021801792/79/488/1127.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 79,
  "processInstanceId" : 488,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"processing\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[],\"rawScript\":\"$SPARK_HOME/bin/spark-submit \\\\\\n    --master spark://spark-master:7077 \\\\\\n    --conf spark.driver.cores=2 \\\\\\n    --conf spark.driver.memory=2G \\\\\\n    --conf spark.executor.instances=2 \\\\\\n    --conf spark.executor.cores=2 \\\\\\n    --conf spark.executor.memory=2G \\\\\\n    --files ${raw_file_dir} \\\\\\n    --name reddit_preprocessing spark_reddit_preprocessing.py\\n\",\"resourceList\":[{\"id\":null,\"resourceName\":\"file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py\",\"res\":null}]}",
  "environmentConfig" : "export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3\nexport JAVA_HOME=/opt/java/openjdk\nexport HADOOP_CONF_DIR=/opt/hadoop-3.4.0/etc/hadoop\nexport PYSPARK_DRIVER_PYTHON=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "spark preprocessing"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1127"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13210058002752"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423101204"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "processing"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "488"
    },
    "raw_file_dir" : {
      "prop" : "raw_file_dir",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit/processing/386-20240422.json"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240422"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "488_1127",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"raw_file_dir\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"/local_storage/reddit/processing/386-20240422.json\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-488][TI-1127] - [INFO] 2024-04-23 10:12:04.905 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-488][TI-1127] - [INFO] 2024-04-23 10:12:04.905 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-488][TI-1127] - [INFO] 2024-04-23 10:12:04.905 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-488][TI-1127] - [INFO] 2024-04-23 10:12:04.908 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-488][TI-1127] - [INFO] 2024-04-23 10:12:04.908 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-488][TI-1127] - [INFO] 2024-04-23 10:12:04.909 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_79/488/1127 check successfully
[WI-488][TI-1127] - [INFO] 2024-04-23 10:12:04.909 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-488][TI-1127] - [INFO] 2024-04-23 10:12:04.911 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py=ResourceContext.ResourceItem(resourceAbsolutePathInStorage=file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py, resourceRelativePath=spark_reddit_preprocessing.py, resourceAbsolutePathInLocal=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_79/488/1127/spark_reddit_preprocessing.py)})
[WI-488][TI-1127] - [INFO] 2024-04-23 10:12:04.911 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-488][TI-1127] - [INFO] 2024-04-23 10:12:04.911 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-488][TI-1127] - [INFO] 2024-04-23 10:12:04.911 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ ],
  "varPool" : null,
  "rawScript" : "$SPARK_HOME/bin/spark-submit \\\n    --master spark://spark-master:7077 \\\n    --conf spark.driver.cores=2 \\\n    --conf spark.driver.memory=2G \\\n    --conf spark.executor.instances=2 \\\n    --conf spark.executor.cores=2 \\\n    --conf spark.executor.memory=2G \\\n    --files ${raw_file_dir} \\\n    --name reddit_preprocessing spark_reddit_preprocessing.py\n",
  "resourceList" : [ {
    "id" : null,
    "resourceName" : "file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py",
    "res" : null
  } ]
}
[WI-488][TI-1127] - [INFO] 2024-04-23 10:12:04.911 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-488][TI-1127] - [INFO] 2024-04-23 10:12:04.911 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}] successfully
[WI-488][TI-1127] - [INFO] 2024-04-23 10:12:04.912 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-488][TI-1127] - [INFO] 2024-04-23 10:12:04.912 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-488][TI-1127] - [INFO] 2024-04-23 10:12:04.912 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-488][TI-1127] - [INFO] 2024-04-23 10:12:04.912 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-488][TI-1127] - [INFO] 2024-04-23 10:12:04.912 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-488][TI-1127] - [INFO] 2024-04-23 10:12:04.912 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export HADOOP_CONF_DIR=/opt/hadoop-3.4.0/etc/hadoop
export PYSPARK_DRIVER_PYTHON=/bin/python3.11
$SPARK_HOME/bin/spark-submit \
    --master spark://spark-master:7077 \
    --conf spark.driver.cores=2 \
    --conf spark.driver.memory=2G \
    --conf spark.executor.instances=2 \
    --conf spark.executor.cores=2 \
    --conf spark.executor.memory=2G \
    --files /local_storage/reddit/processing/386-20240422.json \
    --name reddit_preprocessing spark_reddit_preprocessing.py

[WI-488][TI-1127] - [INFO] 2024-04-23 10:12:04.912 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-488][TI-1127] - [INFO] 2024-04-23 10:12:04.912 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_79/488/1127/488_1127.sh
[WI-488][TI-1127] - [INFO] 2024-04-23 10:12:04.916 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 1836
[WI-0][TI-0] - [INFO] 2024-04-23 10:12:04.924 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
[WI-0][TI-1127] - [INFO] 2024-04-23 10:12:05.149 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionRunningEvent(taskInstanceId=1127, processInstanceId=488, startTime=1713838324903, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, status=TaskExecutionStatus{code=1, desc='running'}, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/79/488/1127.log, executePath=null, processId=0, appIds=null, eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1127] - [INFO] 2024-04-23 10:12:05.152 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionRunningEvent(taskInstanceId=1127, processInstanceId=488, startTime=1713838324903, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, status=TaskExecutionStatus{code=1, desc='running'}, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/79/488/1127.log, executePath=null, processId=0, appIds=null, eventCreateTime=0, eventSendTime=1713838325148)
[WI-0][TI-1127] - [INFO] 2024-04-23 10:12:05.153 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionInfoEvent(taskInstanceId=1127, processInstanceId=488, startTime=1713838324903, workflowInstanceHost=172.18.0.9:5678, taskInstanceHost=172.18.1.1:1234, logPath=null, processId=0, eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1127] - [INFO] 2024-04-23 10:12:05.158 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionInfoEvent(taskInstanceId=1127, processInstanceId=488, startTime=1713838324903, workflowInstanceHost=172.18.0.9:5678, taskInstanceHost=172.18.1.1:1234, logPath=null, processId=0, eventCreateTime=0, eventSendTime=1713838325148)
[WI-0][TI-1127] - [INFO] 2024-04-23 10:12:05.753 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1127, success=true)
[WI-0][TI-1127] - [INFO] 2024-04-23 10:12:05.772 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1127)
[WI-0][TI-1127] - [INFO] 2024-04-23 10:12:05.795 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1127, success=true)
[WI-0][TI-1127] - [INFO] 2024-04-23 10:12:05.812 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1127)
[WI-0][TI-0] - [INFO] 2024-04-23 10:12:06.343 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7944785276073618 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:12:07.370 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7216216216216216 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:12:07.927 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:12:07 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[WI-0][TI-0] - [INFO] 2024-04-23 10:12:08.937 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:12:08 INFO SparkContext: Running Spark version 3.5.1
	24/04/23 10:12:08 INFO SparkContext: OS info Linux, 6.5.0-28-generic, amd64
	24/04/23 10:12:08 INFO SparkContext: Java version 1.8.0_402
	24/04/23 10:12:08 INFO ResourceUtils: ==============================================================
	24/04/23 10:12:08 INFO ResourceUtils: No custom resources configured for spark.driver.
	24/04/23 10:12:08 INFO ResourceUtils: ==============================================================
	24/04/23 10:12:08 INFO SparkContext: Submitted application: reddit_preprocessing
	24/04/23 10:12:08 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 2, script: , vendor: , memory -> name: memory, amount: 2048, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
	24/04/23 10:12:08 INFO ResourceProfile: Limiting resource is cpus at 2 tasks per executor
	24/04/23 10:12:08 INFO ResourceProfileManager: Added ResourceProfile id: 0
	24/04/23 10:12:08 INFO SecurityManager: Changing view acls to: default
	24/04/23 10:12:08 INFO SecurityManager: Changing modify acls to: default
	24/04/23 10:12:08 INFO SecurityManager: Changing view acls groups to: 
	24/04/23 10:12:08 INFO SecurityManager: Changing modify acls groups to: 
	24/04/23 10:12:08 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: default; groups with view permissions: EMPTY; users with modify permissions: default; groups with modify permissions: EMPTY
[WI-0][TI-0] - [INFO] 2024-04-23 10:12:09.407 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.747191011235955 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:12:09.941 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:12:09 INFO Utils: Successfully started service 'sparkDriver' on port 35463.
	24/04/23 10:12:09 INFO SparkEnv: Registering MapOutputTracker
	24/04/23 10:12:09 INFO SparkEnv: Registering BlockManagerMaster
	24/04/23 10:12:09 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
	24/04/23 10:12:09 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
	24/04/23 10:12:09 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
	24/04/23 10:12:09 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-741cd8bd-982a-42a7-9b9b-0374e7d0d89a
	24/04/23 10:12:09 INFO MemoryStore: MemoryStore started with capacity 912.3 MiB
	24/04/23 10:12:09 INFO SparkEnv: Registering OutputCommitCoordinator
[WI-0][TI-0] - [INFO] 2024-04-23 10:12:10.943 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:12:10 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
	24/04/23 10:12:10 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
	24/04/23 10:12:10 INFO Utils: Successfully started service 'SparkUI' on port 4041.
	24/04/23 10:12:10 INFO SparkContext: Added file file:///local_storage/reddit/processing/386-20240422.json at spark://c0e814e3f0bd:35463/files/386-20240422.json with timestamp 1713838328529
	24/04/23 10:12:10 INFO Utils: Copying /local_storage/reddit/processing/386-20240422.json to /tmp/spark-7d0e1ec2-bcfa-4e51-8728-811d88cd778a/userFiles-850970c2-1a2c-4571-9a63-48f738c2a65b/386-20240422.json
	24/04/23 10:12:10 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
	24/04/23 10:12:10 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.3:7077 after 45 ms (0 ms spent in bootstraps)
	24/04/23 10:12:10 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20240423021210-0006
	24/04/23 10:12:10 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45785.
	24/04/23 10:12:10 INFO NettyBlockTransferService: Server created on c0e814e3f0bd:45785
	24/04/23 10:12:10 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
	24/04/23 10:12:10 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, c0e814e3f0bd, 45785, None)
	24/04/23 10:12:10 INFO BlockManagerMasterEndpoint: Registering block manager c0e814e3f0bd:45785 with 912.3 MiB RAM, BlockManagerId(driver, c0e814e3f0bd, 45785, None)
	24/04/23 10:12:10 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, c0e814e3f0bd, 45785, None)
	24/04/23 10:12:10 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, c0e814e3f0bd, 45785, None)
	24/04/23 10:12:10 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
[WI-0][TI-0] - [INFO] 2024-04-23 10:12:11.944 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	
	
	
	 /tmp/spark-7d0e1ec2-bcfa-4e51-8728-811d88cd778a/userFiles-850970c2-1a2c-4571-9a63-48f738c2a65b/386-20240422.json 
	
	
	
	24/04/23 10:12:11 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
	24/04/23 10:12:11 INFO SharedState: Warehouse path is 'file:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_79/488/1127/spark-warehouse'.
[WI-0][TI-0] - [INFO] 2024-04-23 10:12:12.952 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:12:12 INFO InMemoryFileIndex: It took 36 ms to list leaf files for 1 paths.
	24/04/23 10:12:12 INFO InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.
[WI-0][TI-0] - [INFO] 2024-04-23 10:12:14.487 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7822085889570551 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:12:15.958 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:12:15 INFO FileSourceStrategy: Pushed Filters: 
	24/04/23 10:12:15 INFO FileSourceStrategy: Post-Scan Filters: 
	24/04/23 10:12:15 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 351.5 KiB, free 912.0 MiB)
	24/04/23 10:12:15 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 34.6 KiB, free 911.9 MiB)
	24/04/23 10:12:15 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on c0e814e3f0bd:45785 (size: 34.6 KiB, free: 912.3 MiB)
	24/04/23 10:12:15 INFO SparkContext: Created broadcast 0 from json at NativeMethodAccessorImpl.java:0
	24/04/23 10:12:15 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[WI-0][TI-0] - [INFO] 2024-04-23 10:12:16.547 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8425655976676384 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:12:16.966 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:12:16 INFO SparkContext: Starting job: json at NativeMethodAccessorImpl.java:0
	24/04/23 10:12:16 INFO DAGScheduler: Got job 0 (json at NativeMethodAccessorImpl.java:0) with 1 output partitions
	24/04/23 10:12:16 INFO DAGScheduler: Final stage: ResultStage 0 (json at NativeMethodAccessorImpl.java:0)
	24/04/23 10:12:16 INFO DAGScheduler: Parents of final stage: List()
	24/04/23 10:12:16 INFO DAGScheduler: Missing parents: List()
	24/04/23 10:12:16 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at json at NativeMethodAccessorImpl.java:0), which has no missing parents
	24/04/23 10:12:16 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 16.5 KiB, free 911.9 MiB)
	24/04/23 10:12:16 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.8 KiB, free 911.9 MiB)
	24/04/23 10:12:16 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on c0e814e3f0bd:45785 (size: 7.8 KiB, free: 912.3 MiB)
	24/04/23 10:12:16 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1585
	24/04/23 10:12:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at json at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
	24/04/23 10:12:16 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
[WI-0][TI-0] - [INFO] 2024-04-23 10:12:31.991 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:12:31 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
[WI-0][TI-0] - [INFO] 2024-04-23 10:12:47.014 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:12:46 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
[WI-0][TI-0] - [INFO] 2024-04-23 10:13:02.031 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:13:01 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
[WI-0][TI-0] - [INFO] 2024-04-23 10:13:17.055 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:13:16 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
[WI-0][TI-0] - [INFO] 2024-04-23 10:13:32.077 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:13:31 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
[WI-0][TI-0] - [INFO] 2024-04-23 10:13:47.129 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:13:46 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
[WI-0][TI-0] - [INFO] 2024-04-23 10:14:02.186 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:14:01 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
[WI-0][TI-0] - [INFO] 2024-04-23 10:14:17.350 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:14:16 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
[WI-0][TI-0] - [INFO] 2024-04-23 10:14:29.413 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:14:29 ERROR StandaloneSchedulerBackend: Application has been killed. Reason: Master removed our application: KILLED
	24/04/23 10:14:29 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
	24/04/23 10:14:29 INFO SparkContext: SparkContext is stopping with exitCode 0.
	24/04/23 10:14:29 INFO SparkUI: Stopped Spark web UI at http://c0e814e3f0bd:4041
	24/04/23 10:14:29 INFO TaskSchedulerImpl: Cancelling stage 0
	24/04/23 10:14:29 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage cancelled: Job aborted due to stage failure: Master removed our application: KILLED
	24/04/23 10:14:29 INFO DAGScheduler: ResultStage 0 (json at NativeMethodAccessorImpl.java:0) failed in 133.100 s due to Job aborted due to stage failure: Master removed our application: KILLED
	24/04/23 10:14:29 INFO DAGScheduler: Job 0 failed: json at NativeMethodAccessorImpl.java:0, took 133.205214 s
	24/04/23 10:14:29 INFO StandaloneSchedulerBackend: Shutting down all executors
	24/04/23 10:14:29 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Asking each executor to shut down
[WI-0][TI-0] - [INFO] 2024-04-23 10:14:30.072 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8204268107583025 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:14:30.417 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:14:29 ERROR Utils: Uncaught exception in thread stop-spark-context
	org.apache.spark.SparkException: Exception thrown in awaitResult: 
		at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
		at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
		at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
		at org.apache.spark.deploy.client.StandaloneAppClient.stop(StandaloneAppClient.scala:288)
		at org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend.org$apache$spark$scheduler$cluster$StandaloneSchedulerBackend$$stop(StandaloneSchedulerBackend.scala:275)
		at org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend.stop(StandaloneSchedulerBackend.scala:142)
		at org.apache.spark.scheduler.SchedulerBackend.stop(SchedulerBackend.scala:33)
		at org.apache.spark.scheduler.SchedulerBackend.stop$(SchedulerBackend.scala:33)
		at org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend.stop(CoarseGrainedSchedulerBackend.scala:54)
		at org.apache.spark.scheduler.TaskSchedulerImpl.$anonfun$stop$2(TaskSchedulerImpl.scala:992)
		at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1375)
		at org.apache.spark.scheduler.TaskSchedulerImpl.stop(TaskSchedulerImpl.scala:992)
		at org.apache.spark.scheduler.DAGScheduler.$anonfun$stop$4(DAGScheduler.scala:2976)
		at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1375)
		at org.apache.spark.scheduler.DAGScheduler.stop(DAGScheduler.scala:2976)
		at org.apache.spark.SparkContext.$anonfun$stop$12(SparkContext.scala:2263)
		at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1375)
		at org.apache.spark.SparkContext.stop(SparkContext.scala:2263)
		at org.apache.spark.SparkContext.stop(SparkContext.scala:2216)
		at org.apache.spark.SparkContext$$anon$3.run(SparkContext.scala:2203)
	Caused by: org.apache.spark.SparkException: Could not find AppClient.
		at org.apache.spark.rpc.netty.Dispatcher.postMessage(Dispatcher.scala:178)
		at org.apache.spark.rpc.netty.Dispatcher.postLocalMessage(Dispatcher.scala:144)
		at org.apache.spark.rpc.netty.NettyRpcEnv.askAbortable(NettyRpcEnv.scala:242)
		at org.apache.spark.rpc.netty.NettyRpcEndpointRef.askAbortable(NettyRpcEnv.scala:554)
		at org.apache.spark.rpc.netty.NettyRpcEndpointRef.ask(NettyRpcEnv.scala:558)
		at org.apache.spark.rpc.RpcEndpointRef.ask(RpcEndpointRef.scala:72)
		... 17 more
	24/04/23 10:14:29 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
	Traceback (most recent call last):
	  File "/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_79/488/1127/spark_reddit_preprocessing.py", line 44, in <module>
	    raw_df = spark.read.json(reddit_json_dir)
	             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
	  File "/opt/spark-3.5.1-bin-hadoop3/python/lib/pyspark.zip/pyspark/sql/readwriter.py", line 425, in json
	  File "/opt/spark-3.5.1-bin-hadoop3/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
	  File "/opt/spark-3.5.1-bin-hadoop3/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 179, in deco
	  File "/opt/spark-3.5.1-bin-hadoop3/python/lib/py4j-0.10.9.7-src.zip/py4j/protocol.py", line 326, in get_return_value
	py4j.protocol.Py4JJavaError: An error occurred while calling o30.json.
	: org.apache.spark.SparkException: Job aborted due to stage failure: Master removed our application: KILLED
		at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)
		at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)
		at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)
		at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
		at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
		at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
		at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)
		at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)
		at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)
		at scala.Option.foreach(Option.scala:407)
		at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)
		at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)
		at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)
		at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)
		at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
		at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:989)
		at org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)
		at org.apache.spark.SparkContext.runJob(SparkContext.scala:2493)
		at org.apache.spark.sql.catalyst.json.JsonInferSchema.infer(JsonInferSchema.scala:120)
		at org.apache.spark.sql.execution.datasources.json.TextInputJsonDataSource$.$anonfun$inferFromDataset$5(JsonDataSource.scala:109)
		at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)
		at org.apache.spark.sql.execution.datasources.json.TextInputJsonDataSource$.inferFromDataset(JsonDataSource.scala:109)
		at org.apache.spark.sql.execution.datasources.json.TextInputJsonDataSource$.infer(JsonDataSource.scala:98)
		at org.apache.spark.sql.execution.datasources.json.JsonDataSource.inferSchema(JsonDataSource.scala:64)
		at org.apache.spark.sql.execution.datasources.json.JsonFileFormat.inferSchema(JsonFileFormat.scala:59)
		at org.apache.spark.sql.execution.datasources.DataSource.$anonfun$getOrInferFileFormatSchema$11(DataSource.scala:208)
		at scala.Option.orElse(Option.scala:447)
		at org.apache.spark.sql.execution.datasources.DataSource.getOrInferFileFormatSchema(DataSource.scala:205)
		at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:407)
		at org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)
		at org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)
		at scala.Option.getOrElse(Option.scala:189)
		at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)
		at org.apache.spark.sql.DataFrameReader.json(DataFrameReader.scala:362)
		at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
		at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
		at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
		at java.lang.reflect.Method.invoke(Method.java:498)
		at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
		at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
		at py4j.Gateway.invoke(Gateway.java:282)
		at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
		at py4j.commands.CallCommand.execute(CallCommand.java:79)
		at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
		at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
		at java.lang.Thread.run(Thread.java:750)
	
	24/04/23 10:14:29 INFO ShutdownHookManager: Shutdown hook called
	24/04/23 10:14:29 INFO ShutdownHookManager: Deleting directory /tmp/spark-7d0e1ec2-bcfa-4e51-8728-811d88cd778a/userFiles-850970c2-1a2c-4571-9a63-48f738c2a65b
	24/04/23 10:14:29 INFO MemoryStore: MemoryStore cleared
	24/04/23 10:14:29 INFO BlockManager: BlockManager stopped
	24/04/23 10:14:29 INFO ShutdownHookManager: Deleting directory /tmp/spark-7d0e1ec2-bcfa-4e51-8728-811d88cd778a
	24/04/23 10:14:29 INFO BlockManagerMaster: BlockManagerMaster stopped
	24/04/23 10:14:29 INFO ShutdownHookManager: Deleting directory /tmp/spark-127d9bf6-641d-435a-86c5-4427a8361515
	24/04/23 10:14:29 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
	24/04/23 10:14:29 INFO ShutdownHookManager: Deleting directory /tmp/spark-7d0e1ec2-bcfa-4e51-8728-811d88cd778a/pyspark-330ca61a-4b8a-4a00-81fe-4072c6406d63
	24/04/23 10:14:29 INFO SparkContext: Successfully stopped SparkContext
[WI-488][TI-1127] - [INFO] 2024-04-23 10:14:30.419 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_79/488/1127, processId:1836 ,exitStatusCode:1 ,processWaitForStatus:true ,processExitValue:1
[WI-488][TI-1127] - [INFO] 2024-04-23 10:14:30.419 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-488][TI-1127] - [INFO] 2024-04-23 10:14:30.420 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-488][TI-1127] - [INFO] 2024-04-23 10:14:30.420 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-488][TI-1127] - [INFO] 2024-04-23 10:14:30.420 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-488][TI-1127] - [INFO] 2024-04-23 10:14:30.430 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: FAILURE to master : 172.18.1.1:1234
[WI-488][TI-1127] - [INFO] 2024-04-23 10:14:30.431 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-488][TI-1127] - [INFO] 2024-04-23 10:14:30.431 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_79/488/1127
[WI-488][TI-1127] - [INFO] 2024-04-23 10:14:30.432 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_79/488/1127
[WI-488][TI-1127] - [INFO] 2024-04-23 10:14:30.433 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-1127] - [INFO] 2024-04-23 10:14:30.652 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1127, processInstanceId=488, status=6, startTime=1713838324903, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/79/488/1127.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_79/488/1127, endTime=1713838470420, processId=1836, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1127] - [INFO] 2024-04-23 10:14:30.656 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1127, processInstanceId=488, status=6, startTime=1713838324903, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/79/488/1127.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_79/488/1127, endTime=1713838470420, processId=1836, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713838470651)
[WI-0][TI-1127] - [INFO] 2024-04-23 10:14:31.420 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1127, success=true)
[WI-0][TI-1127] - [INFO] 2024-04-23 10:14:31.426 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1127, success=true)
[WI-0][TI-0] - [ERROR] 2024-04-23 10:14:42.884 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[279] - Parse var pool error
java.io.IOException: Stream closed
	at java.io.BufferedInputStream.getBufIfOpen(BufferedInputStream.java:170)
	at java.io.BufferedInputStream.read1(BufferedInputStream.java:283)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:345)
	at sun.nio.cs.StreamDecoder.readBytes(StreamDecoder.java:284)
	at sun.nio.cs.StreamDecoder.implRead(StreamDecoder.java:326)
	at sun.nio.cs.StreamDecoder.read(StreamDecoder.java:178)
	at java.io.InputStreamReader.read(InputStreamReader.java:184)
	at java.io.BufferedReader.fill(BufferedReader.java:161)
	at java.io.BufferedReader.readLine(BufferedReader.java:324)
	at java.io.BufferedReader.readLine(BufferedReader.java:389)
	at org.apache.dolphinscheduler.plugin.task.api.AbstractCommandExecutor.lambda$parseProcessOutput$1(AbstractCommandExecutor.java:273)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
[WI-487][TI-1123] - [INFO] 2024-04-23 10:14:43.429 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has killed. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1123, processId:1677 ,exitStatusCode:137 ,processWaitForStatus:true ,processExitValue:137
[WI-487][TI-1123] - [INFO] 2024-04-23 10:14:43.431 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-487][TI-1123] - [INFO] 2024-04-23 10:14:43.432 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-487][TI-1123] - [INFO] 2024-04-23 10:14:43.433 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-487][TI-1123] - [INFO] 2024-04-23 10:14:43.442 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-487][TI-1123] - [INFO] 2024-04-23 10:14:43.547 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: KILL to master : 172.18.1.1:1234
[WI-487][TI-1123] - [INFO] 2024-04-23 10:14:43.547 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-487][TI-1123] - [INFO] 2024-04-23 10:14:43.547 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1123
[WI-487][TI-1123] - [INFO] 2024-04-23 10:14:43.548 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1123
[WI-487][TI-1123] - [INFO] 2024-04-23 10:14:43.548 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-1123] - [INFO] 2024-04-23 10:14:43.684 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1123, processInstanceId=487, status=9, startTime=1713838208504, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1123.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1123, endTime=1713838483436, processId=1677, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1123] - [INFO] 2024-04-23 10:14:43.692 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1123, processInstanceId=487, status=9, startTime=1713838208504, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1123.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1123, endTime=1713838483436, processId=1677, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713838483674)
[WI-0][TI-0] - [INFO] 2024-04-23 10:14:44.124 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.861271676300578 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-1111] - [INFO] 2024-04-23 10:14:45.697 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1111, processInstanceId=487, status=9, startTime=1713837256404, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1111.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1111, endTime=1713838170352, processId=1017, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713838184697)
[WI-0][TI-1111] - [INFO] 2024-04-23 10:14:45.744 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1111, processInstanceId=487, status=9, startTime=1713837256404, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1111.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1111, endTime=1713838170352, processId=1017, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713838485697)
[WI-0][TI-0] - [INFO] 2024-04-23 10:15:05.253 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.782991202346041 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:16:26.637 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7244318181818181 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:16:33.179 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1128, taskName=search for intake JSON files, firstSubmitTime=1713838593157, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.9:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=80, appIds=null, processInstanceId=489, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"processing"}], executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":""}],"rawScript":"# find 1 raw file in the folder\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\n\n# check if raw_file_dir is empty, then set raw_file_dir to null\nif [ -z \"$raw_file_dir\" ]; then\n    raw_file_dir=null\nfi\n\necho \"#{setValue(raw_file_dir=${raw_file_dir})}\"","resourceList":[]}, environmentConfig=export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='search for intake JSON files'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240423'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1128'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13340113777664'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240423101633'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='processing'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='489'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240422'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=null, dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-489][TI-1128] - [INFO] 2024-04-23 10:16:33.181 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: search for intake JSON files to wait queue success
[WI-489][TI-1128] - [INFO] 2024-04-23 10:16:33.182 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-489][TI-1128] - [INFO] 2024-04-23 10:16:33.186 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-489][TI-1128] - [INFO] 2024-04-23 10:16:33.186 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-489][TI-1128] - [INFO] 2024-04-23 10:16:33.187 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-489][TI-1128] - [INFO] 2024-04-23 10:16:33.187 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713838593187
[WI-489][TI-1128] - [INFO] 2024-04-23 10:16:33.187 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 489_1128
[WI-489][TI-1128] - [INFO] 2024-04-23 10:16:33.187 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1128,
  "taskName" : "search for intake JSON files",
  "firstSubmitTime" : 1713838593157,
  "startTime" : 1713838593187,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.9:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240423/13201021801792/80/489/1128.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 80,
  "processInstanceId" : 489,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"processing\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[{\"prop\":\"raw_file_dir\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"\"}],\"rawScript\":\"# find 1 raw file in the folder\\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\\n\\n# check if raw_file_dir is empty, then set raw_file_dir to null\\nif [ -z \\\"$raw_file_dir\\\" ]; then\\n    raw_file_dir=null\\nfi\\n\\necho \\\"#{setValue(raw_file_dir=${raw_file_dir})}\\\"\",\"resourceList\":[]}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "search for intake JSON files"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1128"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13340113777664"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423101633"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "processing"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "489"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240422"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "489_1128",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-489][TI-1128] - [INFO] 2024-04-23 10:16:33.187 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-489][TI-1128] - [INFO] 2024-04-23 10:16:33.187 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-489][TI-1128] - [INFO] 2024-04-23 10:16:33.187 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-489][TI-1128] - [INFO] 2024-04-23 10:16:33.190 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-489][TI-1128] - [INFO] 2024-04-23 10:16:33.190 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-489][TI-1128] - [INFO] 2024-04-23 10:16:33.191 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1128 check successfully
[WI-489][TI-1128] - [INFO] 2024-04-23 10:16:33.191 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-489][TI-1128] - [INFO] 2024-04-23 10:16:33.191 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-489][TI-1128] - [INFO] 2024-04-23 10:16:33.191 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-489][TI-1128] - [INFO] 2024-04-23 10:16:33.191 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-489][TI-1128] - [INFO] 2024-04-23 10:16:33.192 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ {
    "prop" : "raw_file_dir",
    "direct" : "OUT",
    "type" : "VARCHAR",
    "value" : ""
  } ],
  "varPool" : null,
  "rawScript" : "# find 1 raw file in the folder\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\n\n# check if raw_file_dir is empty, then set raw_file_dir to null\nif [ -z \"$raw_file_dir\" ]; then\n    raw_file_dir=null\nfi\n\necho \"#{setValue(raw_file_dir=${raw_file_dir})}\"",
  "resourceList" : [ ]
}
[WI-489][TI-1128] - [INFO] 2024-04-23 10:16:33.192 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-489][TI-1128] - [INFO] 2024-04-23 10:16:33.192 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: null successfully
[WI-489][TI-1128] - [INFO] 2024-04-23 10:16:33.192 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-489][TI-1128] - [INFO] 2024-04-23 10:16:33.192 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-489][TI-1128] - [INFO] 2024-04-23 10:16:33.192 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-489][TI-1128] - [INFO] 2024-04-23 10:16:33.194 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-489][TI-1128] - [INFO] 2024-04-23 10:16:33.194 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-489][TI-1128] - [INFO] 2024-04-23 10:16:33.194 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export PYTHON_LAUNCHER=/bin/python3.11
# find 1 raw file in the folder
raw_file_dir=$(find /local_storage/reddit/processing -type f -name '*.json'| head -n 1)

# check if raw_file_dir is empty, then set raw_file_dir to null
if [ -z "$raw_file_dir" ]; then
    raw_file_dir=null
fi

echo "#{setValue(raw_file_dir=${raw_file_dir})}"
[WI-489][TI-1128] - [INFO] 2024-04-23 10:16:33.194 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-489][TI-1128] - [INFO] 2024-04-23 10:16:33.194 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1128/489_1128.sh
[WI-489][TI-1128] - [INFO] 2024-04-23 10:16:33.202 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 2050
[WI-0][TI-1128] - [INFO] 2024-04-23 10:16:33.714 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1128, success=true)
[WI-0][TI-1128] - [INFO] 2024-04-23 10:16:33.721 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1128)
[WI-0][TI-0] - [INFO] 2024-04-23 10:16:34.204 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
	#{setValue(raw_file_dir=/local_storage/reddit/processing/386-20240422.json)}
[WI-489][TI-1128] - [INFO] 2024-04-23 10:16:34.231 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1128, processId:2050 ,exitStatusCode:0 ,processWaitForStatus:true ,processExitValue:0
[WI-489][TI-1128] - [INFO] 2024-04-23 10:16:34.233 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-489][TI-1128] - [INFO] 2024-04-23 10:16:34.233 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-489][TI-1128] - [INFO] 2024-04-23 10:16:34.233 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-489][TI-1128] - [INFO] 2024-04-23 10:16:34.243 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-489][TI-1128] - [INFO] 2024-04-23 10:16:34.258 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: SUCCESS to master : 172.18.1.1:1234
[WI-489][TI-1128] - [INFO] 2024-04-23 10:16:34.258 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-489][TI-1128] - [INFO] 2024-04-23 10:16:34.258 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1128
[WI-489][TI-1128] - [INFO] 2024-04-23 10:16:34.259 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1128
[WI-489][TI-1128] - [INFO] 2024-04-23 10:16:34.260 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-1128] - [INFO] 2024-04-23 10:16:34.773 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1128, success=true)
[WI-0][TI-0] - [INFO] 2024-04-23 10:16:35.806 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1130, taskName=move to processing, firstSubmitTime=1713838595800, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.9:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=80, appIds=null, processInstanceId=489, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"processing"}], executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":""}],"rawScript":"# move file to the reddit processing folder\n# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error\nfilename=$(basename \"${raw_file_dir}\")\nif ! grep -q \"${REDDIT_HOME}/processing\" <<< \"${raw_file_dir}\"; then\n    mv ${raw_file_dir} ${REDDIT_HOME}/processing\nelse\n    echo JSON is already in processing\nfi\n\n# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing\necho \"#{setValue(raw_file_dir=${REDDIT_HOME}/processing/${filename})}\"","resourceList":[]}, environmentConfig=export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='move to processing'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240423'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1130'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13340390094208'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240423101635'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='processing'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='489'}, raw_file_dir=Property{prop='raw_file_dir', direct=IN, type=VARCHAR, value='/local_storage/reddit/processing/386-20240422.json'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240422'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-489][TI-1130] - [INFO] 2024-04-23 10:16:35.807 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: move to processing to wait queue success
[WI-489][TI-1130] - [INFO] 2024-04-23 10:16:35.808 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-489][TI-1130] - [INFO] 2024-04-23 10:16:35.809 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-489][TI-1130] - [INFO] 2024-04-23 10:16:35.809 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-489][TI-1130] - [INFO] 2024-04-23 10:16:35.809 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-489][TI-1130] - [INFO] 2024-04-23 10:16:35.809 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713838595809
[WI-489][TI-1130] - [INFO] 2024-04-23 10:16:35.809 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 489_1130
[WI-489][TI-1130] - [INFO] 2024-04-23 10:16:35.809 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1130,
  "taskName" : "move to processing",
  "firstSubmitTime" : 1713838595800,
  "startTime" : 1713838595809,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.9:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240423/13201021801792/80/489/1130.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 80,
  "processInstanceId" : 489,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"processing\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[{\"prop\":\"raw_file_dir\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"\"}],\"rawScript\":\"# move file to the reddit processing folder\\n# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error\\nfilename=$(basename \\\"${raw_file_dir}\\\")\\nif ! grep -q \\\"${REDDIT_HOME}/processing\\\" <<< \\\"${raw_file_dir}\\\"; then\\n    mv ${raw_file_dir} ${REDDIT_HOME}/processing\\nelse\\n    echo JSON is already in processing\\nfi\\n\\n# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing\\necho \\\"#{setValue(raw_file_dir=${REDDIT_HOME}/processing/${filename})}\\\"\",\"resourceList\":[]}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "move to processing"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1130"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13340390094208"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423101635"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "processing"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "489"
    },
    "raw_file_dir" : {
      "prop" : "raw_file_dir",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit/processing/386-20240422.json"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240422"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "489_1130",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"raw_file_dir\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"/local_storage/reddit/processing/386-20240422.json\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-489][TI-1130] - [INFO] 2024-04-23 10:16:35.810 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-489][TI-1130] - [INFO] 2024-04-23 10:16:35.810 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-489][TI-1130] - [INFO] 2024-04-23 10:16:35.810 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-489][TI-1130] - [INFO] 2024-04-23 10:16:35.813 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-489][TI-1130] - [INFO] 2024-04-23 10:16:35.813 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-489][TI-1130] - [INFO] 2024-04-23 10:16:35.815 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1130 check successfully
[WI-489][TI-1130] - [INFO] 2024-04-23 10:16:35.815 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-489][TI-1130] - [INFO] 2024-04-23 10:16:35.815 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-489][TI-1130] - [INFO] 2024-04-23 10:16:35.816 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-489][TI-1130] - [INFO] 2024-04-23 10:16:35.816 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-489][TI-1130] - [INFO] 2024-04-23 10:16:35.816 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ {
    "prop" : "raw_file_dir",
    "direct" : "OUT",
    "type" : "VARCHAR",
    "value" : ""
  } ],
  "varPool" : null,
  "rawScript" : "# move file to the reddit processing folder\n# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error\nfilename=$(basename \"${raw_file_dir}\")\nif ! grep -q \"${REDDIT_HOME}/processing\" <<< \"${raw_file_dir}\"; then\n    mv ${raw_file_dir} ${REDDIT_HOME}/processing\nelse\n    echo JSON is already in processing\nfi\n\n# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing\necho \"#{setValue(raw_file_dir=${REDDIT_HOME}/processing/${filename})}\"",
  "resourceList" : [ ]
}
[WI-489][TI-1130] - [INFO] 2024-04-23 10:16:35.816 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-489][TI-1130] - [INFO] 2024-04-23 10:16:35.816 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}] successfully
[WI-489][TI-1130] - [INFO] 2024-04-23 10:16:35.816 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-489][TI-1130] - [INFO] 2024-04-23 10:16:35.816 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-489][TI-1130] - [INFO] 2024-04-23 10:16:35.816 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-489][TI-1130] - [INFO] 2024-04-23 10:16:35.817 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-489][TI-1130] - [INFO] 2024-04-23 10:16:35.817 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-489][TI-1130] - [INFO] 2024-04-23 10:16:35.817 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export PYTHON_LAUNCHER=/bin/python3.11
# move file to the reddit processing folder
# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error
filename=$(basename "/local_storage/reddit/processing/386-20240422.json")
if ! grep -q "/local_storage/reddit/processing" <<< "/local_storage/reddit/processing/386-20240422.json"; then
    mv /local_storage/reddit/processing/386-20240422.json /local_storage/reddit/processing
else
    echo JSON is already in processing
fi

# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing
echo "#{setValue(raw_file_dir=/local_storage/reddit/processing/${filename})}"
[WI-489][TI-1130] - [INFO] 2024-04-23 10:16:35.817 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-489][TI-1130] - [INFO] 2024-04-23 10:16:35.817 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1130/489_1130.sh
[WI-489][TI-1130] - [INFO] 2024-04-23 10:16:35.847 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 2064
[WI-0][TI-1130] - [INFO] 2024-04-23 10:16:35.933 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionRunningEvent(taskInstanceId=1130, processInstanceId=489, startTime=1713838595809, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, status=TaskExecutionStatus{code=1, desc='running'}, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/80/489/1130.log, executePath=null, processId=0, appIds=null, eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1130] - [INFO] 2024-04-23 10:16:35.953 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionRunningEvent(taskInstanceId=1130, processInstanceId=489, startTime=1713838595809, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, status=TaskExecutionStatus{code=1, desc='running'}, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/80/489/1130.log, executePath=null, processId=0, appIds=null, eventCreateTime=0, eventSendTime=1713838595931)
[WI-0][TI-1130] - [INFO] 2024-04-23 10:16:35.953 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionInfoEvent(taskInstanceId=1130, processInstanceId=489, startTime=1713838595809, workflowInstanceHost=172.18.0.9:5678, taskInstanceHost=172.18.1.1:1234, logPath=null, processId=0, eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1130] - [INFO] 2024-04-23 10:16:35.955 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionInfoEvent(taskInstanceId=1130, processInstanceId=489, startTime=1713838595809, workflowInstanceHost=172.18.0.9:5678, taskInstanceHost=172.18.1.1:1234, logPath=null, processId=0, eventCreateTime=0, eventSendTime=1713838595931)
[WI-0][TI-1130] - [INFO] 2024-04-23 10:16:36.725 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1130, success=true)
[WI-0][TI-1130] - [INFO] 2024-04-23 10:16:36.734 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1130)
[WI-0][TI-1130] - [INFO] 2024-04-23 10:16:36.738 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1130, success=true)
[WI-0][TI-1130] - [INFO] 2024-04-23 10:16:36.753 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1130)
[WI-0][TI-0] - [INFO] 2024-04-23 10:16:36.851 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
	JSON is already in processing
	#{setValue(raw_file_dir=/local_storage/reddit/processing/386-20240422.json)}
[WI-489][TI-1130] - [INFO] 2024-04-23 10:16:36.856 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1130, processId:2064 ,exitStatusCode:0 ,processWaitForStatus:true ,processExitValue:0
[WI-489][TI-1130] - [INFO] 2024-04-23 10:16:36.857 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-489][TI-1130] - [INFO] 2024-04-23 10:16:36.857 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-489][TI-1130] - [INFO] 2024-04-23 10:16:36.857 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-489][TI-1130] - [INFO] 2024-04-23 10:16:36.857 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-489][TI-1130] - [INFO] 2024-04-23 10:16:36.864 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: SUCCESS to master : 172.18.1.1:1234
[WI-489][TI-1130] - [INFO] 2024-04-23 10:16:36.865 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-489][TI-1130] - [INFO] 2024-04-23 10:16:36.865 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1130
[WI-489][TI-1130] - [INFO] 2024-04-23 10:16:36.865 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1130
[WI-489][TI-1130] - [INFO] 2024-04-23 10:16:36.866 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-1130] - [INFO] 2024-04-23 10:16:36.956 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1130, processInstanceId=489, status=7, startTime=1713838595809, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/80/489/1130.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1130, endTime=1713838596857, processId=2064, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1130] - [INFO] 2024-04-23 10:16:36.960 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1130, processInstanceId=489, status=7, startTime=1713838595809, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/80/489/1130.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1130, endTime=1713838596857, processId=2064, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713838596956)
[WI-0][TI-1130] - [INFO] 2024-04-23 10:16:37.719 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1130, success=true)
[WI-0][TI-1130] - [INFO] 2024-04-23 10:16:37.723 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1130, success=true)
[WI-0][TI-0] - [INFO] 2024-04-23 10:16:37.888 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1131, taskName=spark preprocessing, firstSubmitTime=1713838597866, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.9:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=80, appIds=null, processInstanceId=489, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"processing"}], executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[],"rawScript":"$SPARK_HOME/bin/spark-submit \\\n    --master spark://spark-master:7077 \\\n    --conf spark.driver.cores=2 \\\n    --conf spark.driver.memory=2G \\\n    --conf spark.executor.instances=1 \\\n    --conf spark.executor.cores=2 \\\n    --conf spark.executor.memory=2G \\\n    --files ${raw_file_dir} \\\n    --name reddit_preprocessing spark_reddit_preprocessing.py\n","resourceList":[{"id":null,"resourceName":"file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py","res":null}]}, environmentConfig=export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export HADOOP_CONF_DIR=/opt/hadoop-3.4.0/etc/hadoop
export PYSPARK_DRIVER_PYTHON=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='spark preprocessing'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240423'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1131'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13210058002752'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240423101637'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='processing'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='489'}, raw_file_dir=Property{prop='raw_file_dir', direct=IN, type=VARCHAR, value='/local_storage/reddit/processing/386-20240422.json'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240422'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-489][TI-1131] - [INFO] 2024-04-23 10:16:37.889 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: spark preprocessing to wait queue success
[WI-489][TI-1131] - [INFO] 2024-04-23 10:16:37.889 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-489][TI-1131] - [INFO] 2024-04-23 10:16:37.891 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-489][TI-1131] - [INFO] 2024-04-23 10:16:37.891 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-489][TI-1131] - [INFO] 2024-04-23 10:16:37.891 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-489][TI-1131] - [INFO] 2024-04-23 10:16:37.891 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713838597891
[WI-489][TI-1131] - [INFO] 2024-04-23 10:16:37.891 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 489_1131
[WI-489][TI-1131] - [INFO] 2024-04-23 10:16:37.891 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1131,
  "taskName" : "spark preprocessing",
  "firstSubmitTime" : 1713838597866,
  "startTime" : 1713838597891,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.9:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240423/13201021801792/80/489/1131.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 80,
  "processInstanceId" : 489,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"processing\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[],\"rawScript\":\"$SPARK_HOME/bin/spark-submit \\\\\\n    --master spark://spark-master:7077 \\\\\\n    --conf spark.driver.cores=2 \\\\\\n    --conf spark.driver.memory=2G \\\\\\n    --conf spark.executor.instances=1 \\\\\\n    --conf spark.executor.cores=2 \\\\\\n    --conf spark.executor.memory=2G \\\\\\n    --files ${raw_file_dir} \\\\\\n    --name reddit_preprocessing spark_reddit_preprocessing.py\\n\",\"resourceList\":[{\"id\":null,\"resourceName\":\"file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py\",\"res\":null}]}",
  "environmentConfig" : "export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3\nexport JAVA_HOME=/opt/java/openjdk\nexport HADOOP_CONF_DIR=/opt/hadoop-3.4.0/etc/hadoop\nexport PYSPARK_DRIVER_PYTHON=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "spark preprocessing"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1131"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13210058002752"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423101637"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "processing"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "489"
    },
    "raw_file_dir" : {
      "prop" : "raw_file_dir",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit/processing/386-20240422.json"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240422"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "489_1131",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"raw_file_dir\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"/local_storage/reddit/processing/386-20240422.json\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-489][TI-1131] - [INFO] 2024-04-23 10:16:37.892 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-489][TI-1131] - [INFO] 2024-04-23 10:16:37.892 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-489][TI-1131] - [INFO] 2024-04-23 10:16:37.892 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-489][TI-1131] - [INFO] 2024-04-23 10:16:37.895 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-489][TI-1131] - [INFO] 2024-04-23 10:16:37.896 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-489][TI-1131] - [INFO] 2024-04-23 10:16:37.896 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1131 check successfully
[WI-489][TI-1131] - [INFO] 2024-04-23 10:16:37.896 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-489][TI-1131] - [INFO] 2024-04-23 10:16:37.900 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py=ResourceContext.ResourceItem(resourceAbsolutePathInStorage=file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py, resourceRelativePath=spark_reddit_preprocessing.py, resourceAbsolutePathInLocal=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1131/spark_reddit_preprocessing.py)})
[WI-489][TI-1131] - [INFO] 2024-04-23 10:16:37.901 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-489][TI-1131] - [INFO] 2024-04-23 10:16:37.902 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-489][TI-1131] - [INFO] 2024-04-23 10:16:37.902 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ ],
  "varPool" : null,
  "rawScript" : "$SPARK_HOME/bin/spark-submit \\\n    --master spark://spark-master:7077 \\\n    --conf spark.driver.cores=2 \\\n    --conf spark.driver.memory=2G \\\n    --conf spark.executor.instances=1 \\\n    --conf spark.executor.cores=2 \\\n    --conf spark.executor.memory=2G \\\n    --files ${raw_file_dir} \\\n    --name reddit_preprocessing spark_reddit_preprocessing.py\n",
  "resourceList" : [ {
    "id" : null,
    "resourceName" : "file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py",
    "res" : null
  } ]
}
[WI-489][TI-1131] - [INFO] 2024-04-23 10:16:37.902 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-489][TI-1131] - [INFO] 2024-04-23 10:16:37.902 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}] successfully
[WI-489][TI-1131] - [INFO] 2024-04-23 10:16:37.902 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-489][TI-1131] - [INFO] 2024-04-23 10:16:37.902 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-489][TI-1131] - [INFO] 2024-04-23 10:16:37.902 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-489][TI-1131] - [INFO] 2024-04-23 10:16:37.903 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-489][TI-1131] - [INFO] 2024-04-23 10:16:37.903 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-489][TI-1131] - [INFO] 2024-04-23 10:16:37.903 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export HADOOP_CONF_DIR=/opt/hadoop-3.4.0/etc/hadoop
export PYSPARK_DRIVER_PYTHON=/bin/python3.11
$SPARK_HOME/bin/spark-submit \
    --master spark://spark-master:7077 \
    --conf spark.driver.cores=2 \
    --conf spark.driver.memory=2G \
    --conf spark.executor.instances=1 \
    --conf spark.executor.cores=2 \
    --conf spark.executor.memory=2G \
    --files /local_storage/reddit/processing/386-20240422.json \
    --name reddit_preprocessing spark_reddit_preprocessing.py

[WI-489][TI-1131] - [INFO] 2024-04-23 10:16:37.903 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-489][TI-1131] - [INFO] 2024-04-23 10:16:37.903 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1131/489_1131.sh
[WI-489][TI-1131] - [INFO] 2024-04-23 10:16:37.945 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 2076
[WI-0][TI-1131] - [INFO] 2024-04-23 10:16:37.962 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionRunningEvent(taskInstanceId=1131, processInstanceId=489, startTime=1713838597891, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, status=TaskExecutionStatus{code=1, desc='running'}, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/80/489/1131.log, executePath=null, processId=0, appIds=null, eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1131] - [INFO] 2024-04-23 10:16:37.966 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionRunningEvent(taskInstanceId=1131, processInstanceId=489, startTime=1713838597891, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, status=TaskExecutionStatus{code=1, desc='running'}, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/80/489/1131.log, executePath=null, processId=0, appIds=null, eventCreateTime=0, eventSendTime=1713838597961)
[WI-0][TI-1131] - [INFO] 2024-04-23 10:16:37.966 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionInfoEvent(taskInstanceId=1131, processInstanceId=489, startTime=1713838597891, workflowInstanceHost=172.18.0.9:5678, taskInstanceHost=172.18.1.1:1234, logPath=null, processId=0, eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1131] - [INFO] 2024-04-23 10:16:37.968 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionInfoEvent(taskInstanceId=1131, processInstanceId=489, startTime=1713838597891, workflowInstanceHost=172.18.0.9:5678, taskInstanceHost=172.18.1.1:1234, logPath=null, processId=0, eventCreateTime=0, eventSendTime=1713838597961)
[WI-0][TI-1131] - [INFO] 2024-04-23 10:16:38.720 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1131, success=true)
[WI-0][TI-1131] - [INFO] 2024-04-23 10:16:38.741 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1131)
[WI-0][TI-1131] - [INFO] 2024-04-23 10:16:38.749 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1131, success=true)
[WI-0][TI-1131] - [INFO] 2024-04-23 10:16:38.755 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1131)
[WI-0][TI-0] - [INFO] 2024-04-23 10:16:38.947 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
[WI-0][TI-0] - [INFO] 2024-04-23 10:16:39.767 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7433628318584071 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:16:40.977 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:16:40 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[WI-0][TI-0] - [INFO] 2024-04-23 10:16:42.020 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:16:41 INFO SparkContext: Running Spark version 3.5.1
	24/04/23 10:16:41 INFO SparkContext: OS info Linux, 6.5.0-28-generic, amd64
	24/04/23 10:16:41 INFO SparkContext: Java version 1.8.0_402
	24/04/23 10:16:41 INFO ResourceUtils: ==============================================================
	24/04/23 10:16:41 INFO ResourceUtils: No custom resources configured for spark.driver.
	24/04/23 10:16:41 INFO ResourceUtils: ==============================================================
	24/04/23 10:16:41 INFO SparkContext: Submitted application: reddit_preprocessing
	24/04/23 10:16:41 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 2, script: , vendor: , memory -> name: memory, amount: 2048, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
	24/04/23 10:16:41 INFO ResourceProfile: Limiting resource is cpus at 2 tasks per executor
	24/04/23 10:16:41 INFO ResourceProfileManager: Added ResourceProfile id: 0
	24/04/23 10:16:41 INFO SecurityManager: Changing view acls to: default
	24/04/23 10:16:41 INFO SecurityManager: Changing modify acls to: default
	24/04/23 10:16:41 INFO SecurityManager: Changing view acls groups to: 
	24/04/23 10:16:41 INFO SecurityManager: Changing modify acls groups to: 
	24/04/23 10:16:41 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: default; groups with view permissions: EMPTY; users with modify permissions: default; groups with modify permissions: EMPTY
[WI-0][TI-0] - [INFO] 2024-04-23 10:16:42.021 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8704318936877077 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:16:43.021 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:16:42 INFO Utils: Successfully started service 'sparkDriver' on port 44313.
	24/04/23 10:16:42 INFO SparkEnv: Registering MapOutputTracker
	24/04/23 10:16:42 INFO SparkEnv: Registering BlockManagerMaster
	24/04/23 10:16:42 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
	24/04/23 10:16:42 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
	24/04/23 10:16:42 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
	24/04/23 10:16:42 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-10f7098d-9180-4055-910c-458ef214f832
	24/04/23 10:16:42 INFO MemoryStore: MemoryStore started with capacity 912.3 MiB
	24/04/23 10:16:42 INFO SparkEnv: Registering OutputCommitCoordinator
	24/04/23 10:16:42 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
	24/04/23 10:16:42 INFO Utils: Successfully started service 'SparkUI' on port 4040.
	24/04/23 10:16:43 INFO SparkContext: Added file file:///local_storage/reddit/processing/386-20240422.json at spark://c0e814e3f0bd:44313/files/386-20240422.json with timestamp 1713838601239
[WI-0][TI-0] - [INFO] 2024-04-23 10:16:43.038 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8419452887537994 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:16:44.031 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:16:43 INFO Utils: Copying /local_storage/reddit/processing/386-20240422.json to /tmp/spark-50f4a7ac-24d7-45de-bd2b-edab0dac48f0/userFiles-638a2015-301d-4594-9245-ccf5a9821222/386-20240422.json
	24/04/23 10:16:43 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
	24/04/23 10:16:43 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.3:7077 after 52 ms (0 ms spent in bootstraps)
	24/04/23 10:16:43 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20240423021643-0007
	24/04/23 10:16:43 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20240423021643-0007/0 on worker-20240423012857-172.18.0.7-41063 (172.18.0.7:41063) with 2 core(s)
	24/04/23 10:16:43 INFO StandaloneSchedulerBackend: Granted executor ID app-20240423021643-0007/0 on hostPort 172.18.0.7:41063 with 2 core(s), 2.0 GiB RAM
	24/04/23 10:16:43 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42955.
	24/04/23 10:16:43 INFO NettyBlockTransferService: Server created on c0e814e3f0bd:42955
	24/04/23 10:16:43 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20240423021643-0007/0 is now RUNNING
	24/04/23 10:16:43 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
	24/04/23 10:16:43 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, c0e814e3f0bd, 42955, None)
	24/04/23 10:16:43 INFO BlockManagerMasterEndpoint: Registering block manager c0e814e3f0bd:42955 with 912.3 MiB RAM, BlockManagerId(driver, c0e814e3f0bd, 42955, None)
	24/04/23 10:16:43 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, c0e814e3f0bd, 42955, None)
	24/04/23 10:16:43 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, c0e814e3f0bd, 42955, None)
[WI-0][TI-0] - [INFO] 2024-04-23 10:16:44.058 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8328690807799443 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:16:45.032 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:16:44 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
	
	
	
	 /tmp/spark-50f4a7ac-24d7-45de-bd2b-edab0dac48f0/userFiles-638a2015-301d-4594-9245-ccf5a9821222/386-20240422.json 
	
	
	
	24/04/23 10:16:44 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
	24/04/23 10:16:44 INFO SharedState: Warehouse path is 'file:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1131/spark-warehouse'.
[WI-0][TI-0] - [INFO] 2024-04-23 10:16:45.059 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.888888888888889 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:16:46.060 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9378531073446329 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:16:47.066 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9518716577540107 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:16:48.053 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:16:47 INFO InMemoryFileIndex: It took 87 ms to list leaf files for 1 paths.
	24/04/23 10:16:47 INFO InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.
[WI-0][TI-0] - [INFO] 2024-04-23 10:16:48.073 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9651162790697674 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:16:49.095 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9804469273743017 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:16:50.113 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9353932584269663 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:16:51.118 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9064327485380117 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:16:52.059 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:16:51 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.7:56688) with ID 0,  ResourceProfileId 0
	24/04/23 10:16:51 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.7:46203 with 1048.8 MiB RAM, BlockManagerId(0, 172.18.0.7, 46203, None)
[WI-0][TI-0] - [INFO] 2024-04-23 10:16:52.130 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7161290322580645 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:16:53.060 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:16:52 INFO FileSourceStrategy: Pushed Filters: 
	24/04/23 10:16:52 INFO FileSourceStrategy: Post-Scan Filters: 
[WI-0][TI-0] - [INFO] 2024-04-23 10:16:54.062 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:16:53 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 351.5 KiB, free 912.0 MiB)
	24/04/23 10:16:53 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 34.6 KiB, free 911.9 MiB)
	24/04/23 10:16:53 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on c0e814e3f0bd:42955 (size: 34.6 KiB, free: 912.3 MiB)
	24/04/23 10:16:53 INFO SparkContext: Created broadcast 0 from json at NativeMethodAccessorImpl.java:0
	24/04/23 10:16:53 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
	24/04/23 10:16:53 INFO SparkContext: Starting job: json at NativeMethodAccessorImpl.java:0
	24/04/23 10:16:53 INFO DAGScheduler: Got job 0 (json at NativeMethodAccessorImpl.java:0) with 1 output partitions
	24/04/23 10:16:53 INFO DAGScheduler: Final stage: ResultStage 0 (json at NativeMethodAccessorImpl.java:0)
	24/04/23 10:16:53 INFO DAGScheduler: Parents of final stage: List()
	24/04/23 10:16:53 INFO DAGScheduler: Missing parents: List()
	24/04/23 10:16:53 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at json at NativeMethodAccessorImpl.java:0), which has no missing parents
	24/04/23 10:16:53 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 16.5 KiB, free 911.9 MiB)
	24/04/23 10:16:53 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.8 KiB, free 911.9 MiB)
	24/04/23 10:16:53 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on c0e814e3f0bd:42955 (size: 7.8 KiB, free: 912.3 MiB)
	24/04/23 10:16:53 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1585
	24/04/23 10:16:53 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at json at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
	24/04/23 10:16:53 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
	24/04/23 10:16:53 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.7, executor 0, partition 0, PROCESS_LOCAL, 8478 bytes) 
[WI-0][TI-0] - [INFO] 2024-04-23 10:17:45.394 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7404371584699454 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:19:01.215 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7910863509749304 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:19:05.283 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7272727272727273 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:19:16.331 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8571428571428572 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-1123] - [INFO] 2024-04-23 10:19:44.496 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1123, processInstanceId=487, status=9, startTime=1713838208504, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1123.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1123, endTime=1713838483436, processId=1677, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713838483674)
[WI-0][TI-1123] - [INFO] 2024-04-23 10:19:44.500 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1123, processInstanceId=487, status=9, startTime=1713838208504, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1123.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1123, endTime=1713838483436, processId=1677, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713838784496)
[WI-0][TI-1111] - [INFO] 2024-04-23 10:19:46.506 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1111, processInstanceId=487, status=9, startTime=1713837256404, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1111.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1111, endTime=1713838170352, processId=1017, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713838485697)
[WI-0][TI-1111] - [INFO] 2024-04-23 10:19:46.509 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1111, processInstanceId=487, status=9, startTime=1713837256404, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1111.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1111, endTime=1713838170352, processId=1017, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713838786506)
[WI-0][TI-0] - [INFO] 2024-04-23 10:20:17.658 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7158176943699732 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:20:32.742 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7342465753424657 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:22:42.710 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7019498607242339 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-1123] - [INFO] 2024-04-23 10:24:45.004 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1123, processInstanceId=487, status=9, startTime=1713838208504, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1123.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1123, endTime=1713838483436, processId=1677, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713838784496)
[WI-0][TI-1123] - [INFO] 2024-04-23 10:24:45.017 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1123, processInstanceId=487, status=9, startTime=1713838208504, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1123.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1123, endTime=1713838483436, processId=1677, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713839085004)
[WI-0][TI-1111] - [INFO] 2024-04-23 10:24:47.029 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1111, processInstanceId=487, status=9, startTime=1713837256404, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1111.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1111, endTime=1713838170352, processId=1017, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713838786506)
[WI-0][TI-1111] - [INFO] 2024-04-23 10:24:47.033 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1111, processInstanceId=487, status=9, startTime=1713837256404, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1111.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1111, endTime=1713838170352, processId=1017, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713839087029)
[WI-0][TI-0] - [INFO] 2024-04-23 10:27:24.935 +0800 o.a.d.s.w.r.o.TaskInstanceKillOperationFunction:[55] - Receive TaskInstanceKillRequest: TaskInstanceKillRequest(taskInstanceId=1131)
[WI-0][TI-1131] - [ERROR] 2024-04-23 10:27:24.938 +0800 o.a.d.s.w.r.o.TaskInstanceKillOperationFunction:[139] - kill task error
java.io.IOException: Cannot run program "pstree": error=2, No such file or directory
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1048)
	at org.apache.dolphinscheduler.common.shell.AbstractShell.runCommand(AbstractShell.java:138)
	at org.apache.dolphinscheduler.common.shell.AbstractShell.run(AbstractShell.java:118)
	at org.apache.dolphinscheduler.common.shell.ShellExecutor.execute(ShellExecutor.java:125)
	at org.apache.dolphinscheduler.common.shell.ShellExecutor.execCommand(ShellExecutor.java:103)
	at org.apache.dolphinscheduler.common.shell.ShellExecutor.execCommand(ShellExecutor.java:86)
	at org.apache.dolphinscheduler.common.utils.OSUtils.exeShell(OSUtils.java:345)
	at org.apache.dolphinscheduler.common.utils.OSUtils.exeCmd(OSUtils.java:334)
	at org.apache.dolphinscheduler.plugin.task.api.utils.ProcessUtils.getPidsStr(ProcessUtils.java:129)
	at org.apache.dolphinscheduler.server.worker.runner.operator.TaskInstanceKillOperationFunction.killProcess(TaskInstanceKillOperationFunction.java:130)
	at org.apache.dolphinscheduler.server.worker.runner.operator.TaskInstanceKillOperationFunction.doKill(TaskInstanceKillOperationFunction.java:96)
	at org.apache.dolphinscheduler.server.worker.runner.operator.TaskInstanceKillOperationFunction.operate(TaskInstanceKillOperationFunction.java:69)
	at org.apache.dolphinscheduler.server.worker.rpc.TaskInstanceOperatorImpl.killTask(TaskInstanceOperatorImpl.java:49)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.dolphinscheduler.extract.base.server.ServerMethodInvokerImpl.invoke(ServerMethodInvokerImpl.java:41)
	at org.apache.dolphinscheduler.extract.base.server.JdkDynamicServerHandler.lambda$processReceived$0(JdkDynamicServerHandler.java:108)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.io.IOException: error=2, No such file or directory
	at java.lang.UNIXProcess.forkAndExec(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:247)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	... 21 common frames omitted
[WI-0][TI-1131] - [INFO] 2024-04-23 10:27:24.939 +0800 o.a.d.p.t.a.u.ProcessUtils:[182] - Get appIds from worker 172.18.1.1:1234, taskLogPath: /opt/dolphinscheduler/logs/20240423/13201021801792/80/489/1131.log
[WI-0][TI-1131] - [INFO] 2024-04-23 10:27:24.939 +0800 o.a.d.p.t.a.u.LogUtils:[79] - Start finding appId in /opt/dolphinscheduler/logs/20240423/13201021801792/80/489/1131.log, fetch way: log 
[WI-0][TI-1131] - [INFO] 2024-04-23 10:27:24.939 +0800 o.a.d.p.t.a.u.ProcessUtils:[188] - The appId is empty
[WI-0][TI-1131] - [INFO] 2024-04-23 10:27:24.940 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[220] - Begin to kill process process, pid is : 2076
[WI-0][TI-1131] - [INFO] 2024-04-23 10:27:29.942 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[225] - Success kill task: 489_1131, pid: 2076
[WI-0][TI-1131] - [INFO] 2024-04-23 10:27:29.942 +0800 o.a.d.s.w.r.o.TaskInstanceKillOperationFunction:[119] - kill task by cancelApplication, taskInstanceId: 1131
[WI-0][TI-0] - [INFO] 2024-04-23 10:27:32.315 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7478005865102639 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:27:36.370 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1132, taskName=search for intake JSON files, firstSubmitTime=1713839256352, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.9:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=80, appIds=null, processInstanceId=489, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"processing"}], executorId=1, cmdTypeIfComplement=7, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":""}],"rawScript":"# find 1 raw file in the folder\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\n\n# check if raw_file_dir is empty, then set raw_file_dir to null\nif [ -z \"$raw_file_dir\" ]; then\n    raw_file_dir=null\nfi\n\necho \"#{setValue(raw_file_dir=${raw_file_dir})}\"","resourceList":[]}, environmentConfig=export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='search for intake JSON files'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240423'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1132'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13340113777664'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240423102736'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='processing'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='489'}, raw_file_dir=Property{prop='raw_file_dir', direct=OUT, type=VARCHAR, value='/local_storage/reddit/processing/386-20240422.json'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240422'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-489][TI-1132] - [INFO] 2024-04-23 10:27:36.375 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: search for intake JSON files to wait queue success
[WI-489][TI-1132] - [INFO] 2024-04-23 10:27:36.379 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-489][TI-1132] - [INFO] 2024-04-23 10:27:36.382 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-489][TI-1132] - [INFO] 2024-04-23 10:27:36.384 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-489][TI-1132] - [INFO] 2024-04-23 10:27:36.384 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-489][TI-1132] - [INFO] 2024-04-23 10:27:36.384 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713839256384
[WI-489][TI-1132] - [INFO] 2024-04-23 10:27:36.384 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 489_1132
[WI-489][TI-1132] - [INFO] 2024-04-23 10:27:36.385 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1132,
  "taskName" : "search for intake JSON files",
  "firstSubmitTime" : 1713839256352,
  "startTime" : 1713839256384,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.9:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240423/13201021801792/80/489/1132.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 80,
  "processInstanceId" : 489,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"processing\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 7,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[{\"prop\":\"raw_file_dir\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"\"}],\"rawScript\":\"# find 1 raw file in the folder\\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\\n\\n# check if raw_file_dir is empty, then set raw_file_dir to null\\nif [ -z \\\"$raw_file_dir\\\" ]; then\\n    raw_file_dir=null\\nfi\\n\\necho \\\"#{setValue(raw_file_dir=${raw_file_dir})}\\\"\",\"resourceList\":[]}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "search for intake JSON files"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1132"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13340113777664"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423102736"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "processing"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "489"
    },
    "raw_file_dir" : {
      "prop" : "raw_file_dir",
      "direct" : "OUT",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit/processing/386-20240422.json"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240422"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "489_1132",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"raw_file_dir\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"/local_storage/reddit/processing/386-20240422.json\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-489][TI-1132] - [INFO] 2024-04-23 10:27:36.394 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-489][TI-1132] - [INFO] 2024-04-23 10:27:36.395 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-489][TI-1132] - [INFO] 2024-04-23 10:27:36.395 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-489][TI-1132] - [INFO] 2024-04-23 10:27:36.398 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-489][TI-1132] - [INFO] 2024-04-23 10:27:36.399 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-489][TI-1132] - [INFO] 2024-04-23 10:27:36.400 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1132 check successfully
[WI-489][TI-1132] - [INFO] 2024-04-23 10:27:36.401 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-489][TI-1132] - [INFO] 2024-04-23 10:27:36.401 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-489][TI-1132] - [INFO] 2024-04-23 10:27:36.401 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-489][TI-1132] - [INFO] 2024-04-23 10:27:36.401 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-489][TI-1132] - [INFO] 2024-04-23 10:27:36.402 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ {
    "prop" : "raw_file_dir",
    "direct" : "OUT",
    "type" : "VARCHAR",
    "value" : ""
  } ],
  "varPool" : null,
  "rawScript" : "# find 1 raw file in the folder\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\n\n# check if raw_file_dir is empty, then set raw_file_dir to null\nif [ -z \"$raw_file_dir\" ]; then\n    raw_file_dir=null\nfi\n\necho \"#{setValue(raw_file_dir=${raw_file_dir})}\"",
  "resourceList" : [ ]
}
[WI-489][TI-1132] - [INFO] 2024-04-23 10:27:36.404 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-489][TI-1132] - [INFO] 2024-04-23 10:27:36.404 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}] successfully
[WI-489][TI-1132] - [INFO] 2024-04-23 10:27:36.404 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-489][TI-1132] - [INFO] 2024-04-23 10:27:36.404 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-489][TI-1132] - [INFO] 2024-04-23 10:27:36.404 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-489][TI-1132] - [INFO] 2024-04-23 10:27:36.404 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-489][TI-1132] - [INFO] 2024-04-23 10:27:36.405 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-489][TI-1132] - [INFO] 2024-04-23 10:27:36.405 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export PYTHON_LAUNCHER=/bin/python3.11
# find 1 raw file in the folder
raw_file_dir=$(find /local_storage/reddit/processing -type f -name '*.json'| head -n 1)

# check if raw_file_dir is empty, then set raw_file_dir to null
if [ -z "$raw_file_dir" ]; then
    raw_file_dir=null
fi

echo "#{setValue(raw_file_dir=/local_storage/reddit/processing/386-20240422.json)}"
[WI-489][TI-1132] - [INFO] 2024-04-23 10:27:36.405 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-489][TI-1132] - [INFO] 2024-04-23 10:27:36.405 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1132/489_1132.sh
[WI-489][TI-1132] - [INFO] 2024-04-23 10:27:36.433 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 2319
[WI-0][TI-0] - [INFO] 2024-04-23 10:27:36.436 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
[WI-0][TI-1132] - [INFO] 2024-04-23 10:27:36.841 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1132, success=true)
[WI-0][TI-1132] - [INFO] 2024-04-23 10:27:36.848 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1132)
[WI-0][TI-0] - [INFO] 2024-04-23 10:27:37.455 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	#{setValue(raw_file_dir=/local_storage/reddit/processing/386-20240422.json)}
[WI-489][TI-1132] - [INFO] 2024-04-23 10:27:37.456 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1132, processId:2319 ,exitStatusCode:0 ,processWaitForStatus:true ,processExitValue:0
[WI-489][TI-1132] - [INFO] 2024-04-23 10:27:37.457 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-489][TI-1132] - [INFO] 2024-04-23 10:27:37.457 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-489][TI-1132] - [INFO] 2024-04-23 10:27:37.457 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-489][TI-1132] - [INFO] 2024-04-23 10:27:37.457 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-489][TI-1132] - [INFO] 2024-04-23 10:27:37.460 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: SUCCESS to master : 172.18.1.1:1234
[WI-489][TI-1132] - [INFO] 2024-04-23 10:27:37.460 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-489][TI-1132] - [INFO] 2024-04-23 10:27:37.460 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1132
[WI-489][TI-1132] - [INFO] 2024-04-23 10:27:37.461 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1132
[WI-489][TI-1132] - [INFO] 2024-04-23 10:27:37.462 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-1132] - [INFO] 2024-04-23 10:27:37.839 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1132, success=true)
[WI-0][TI-0] - [INFO] 2024-04-23 10:27:38.920 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1134, taskName=move to processing, firstSubmitTime=1713839258912, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.9:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=80, appIds=null, processInstanceId=489, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"processing"}], executorId=1, cmdTypeIfComplement=7, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":""}],"rawScript":"# move file to the reddit processing folder\n# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error\nfilename=$(basename \"${raw_file_dir}\")\nif ! grep -q \"${REDDIT_HOME}/processing\" <<< \"${raw_file_dir}\"; then\n    mv ${raw_file_dir} ${REDDIT_HOME}/processing\nelse\n    echo JSON is already in processing\nfi\n\n# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing\necho \"#{setValue(raw_file_dir=${REDDIT_HOME}/processing/${filename})}\"","resourceList":[]}, environmentConfig=export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='move to processing'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240423'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1134'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13340390094208'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240423102738'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='processing'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='489'}, raw_file_dir=Property{prop='raw_file_dir', direct=IN, type=VARCHAR, value='/local_storage/reddit/processing/386-20240422.json'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240422'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-489][TI-1134] - [INFO] 2024-04-23 10:27:38.922 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: move to processing to wait queue success
[WI-489][TI-1134] - [INFO] 2024-04-23 10:27:38.922 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-489][TI-1134] - [INFO] 2024-04-23 10:27:38.923 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-489][TI-1134] - [INFO] 2024-04-23 10:27:38.923 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-489][TI-1134] - [INFO] 2024-04-23 10:27:38.923 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-489][TI-1134] - [INFO] 2024-04-23 10:27:38.923 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713839258923
[WI-489][TI-1134] - [INFO] 2024-04-23 10:27:38.923 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 489_1134
[WI-489][TI-1134] - [INFO] 2024-04-23 10:27:38.923 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1134,
  "taskName" : "move to processing",
  "firstSubmitTime" : 1713839258912,
  "startTime" : 1713839258923,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.9:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240423/13201021801792/80/489/1134.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 80,
  "processInstanceId" : 489,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"processing\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 7,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[{\"prop\":\"raw_file_dir\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"\"}],\"rawScript\":\"# move file to the reddit processing folder\\n# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error\\nfilename=$(basename \\\"${raw_file_dir}\\\")\\nif ! grep -q \\\"${REDDIT_HOME}/processing\\\" <<< \\\"${raw_file_dir}\\\"; then\\n    mv ${raw_file_dir} ${REDDIT_HOME}/processing\\nelse\\n    echo JSON is already in processing\\nfi\\n\\n# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing\\necho \\\"#{setValue(raw_file_dir=${REDDIT_HOME}/processing/${filename})}\\\"\",\"resourceList\":[]}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "move to processing"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1134"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13340390094208"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423102738"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "processing"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "489"
    },
    "raw_file_dir" : {
      "prop" : "raw_file_dir",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit/processing/386-20240422.json"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240422"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "489_1134",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"raw_file_dir\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"/local_storage/reddit/processing/386-20240422.json\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-489][TI-1134] - [INFO] 2024-04-23 10:27:38.924 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-489][TI-1134] - [INFO] 2024-04-23 10:27:38.924 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-489][TI-1134] - [INFO] 2024-04-23 10:27:38.924 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-489][TI-1134] - [INFO] 2024-04-23 10:27:38.926 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-489][TI-1134] - [INFO] 2024-04-23 10:27:38.927 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-489][TI-1134] - [INFO] 2024-04-23 10:27:38.927 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1134 check successfully
[WI-0][TI-1134] - [INFO] 2024-04-23 10:27:38.929 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionRunningEvent(taskInstanceId=1134, processInstanceId=489, startTime=1713839258923, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, status=TaskExecutionStatus{code=1, desc='running'}, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/80/489/1134.log, executePath=null, processId=0, appIds=null, eventCreateTime=0, eventSendTime=0)
[WI-489][TI-1134] - [INFO] 2024-04-23 10:27:38.929 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-489][TI-1134] - [INFO] 2024-04-23 10:27:38.931 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-489][TI-1134] - [INFO] 2024-04-23 10:27:38.931 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-489][TI-1134] - [INFO] 2024-04-23 10:27:38.934 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-489][TI-1134] - [INFO] 2024-04-23 10:27:38.934 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ {
    "prop" : "raw_file_dir",
    "direct" : "OUT",
    "type" : "VARCHAR",
    "value" : ""
  } ],
  "varPool" : null,
  "rawScript" : "# move file to the reddit processing folder\n# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error\nfilename=$(basename \"${raw_file_dir}\")\nif ! grep -q \"${REDDIT_HOME}/processing\" <<< \"${raw_file_dir}\"; then\n    mv ${raw_file_dir} ${REDDIT_HOME}/processing\nelse\n    echo JSON is already in processing\nfi\n\n# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing\necho \"#{setValue(raw_file_dir=${REDDIT_HOME}/processing/${filename})}\"",
  "resourceList" : [ ]
}
[WI-489][TI-1134] - [INFO] 2024-04-23 10:27:38.934 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-489][TI-1134] - [INFO] 2024-04-23 10:27:38.934 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}] successfully
[WI-489][TI-1134] - [INFO] 2024-04-23 10:27:38.934 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-489][TI-1134] - [INFO] 2024-04-23 10:27:38.934 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-489][TI-1134] - [INFO] 2024-04-23 10:27:38.935 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-0][TI-1134] - [INFO] 2024-04-23 10:27:38.935 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionRunningEvent(taskInstanceId=1134, processInstanceId=489, startTime=1713839258923, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, status=TaskExecutionStatus{code=1, desc='running'}, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/80/489/1134.log, executePath=null, processId=0, appIds=null, eventCreateTime=0, eventSendTime=1713839258927)
[WI-489][TI-1134] - [INFO] 2024-04-23 10:27:38.936 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-489][TI-1134] - [INFO] 2024-04-23 10:27:38.936 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-489][TI-1134] - [INFO] 2024-04-23 10:27:38.937 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export PYTHON_LAUNCHER=/bin/python3.11
# move file to the reddit processing folder
# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error
filename=$(basename "/local_storage/reddit/processing/386-20240422.json")
if ! grep -q "/local_storage/reddit/processing" <<< "/local_storage/reddit/processing/386-20240422.json"; then
    mv /local_storage/reddit/processing/386-20240422.json /local_storage/reddit/processing
else
    echo JSON is already in processing
fi

# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing
echo "#{setValue(raw_file_dir=/local_storage/reddit/processing/${filename})}"
[WI-489][TI-1134] - [INFO] 2024-04-23 10:27:38.937 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-489][TI-1134] - [INFO] 2024-04-23 10:27:38.938 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1134/489_1134.sh
[WI-489][TI-1134] - [INFO] 2024-04-23 10:27:38.940 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 2333
[WI-0][TI-1134] - [INFO] 2024-04-23 10:27:39.851 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1134, success=true)
[WI-0][TI-1134] - [INFO] 2024-04-23 10:27:39.858 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1134, success=true)
[WI-0][TI-1134] - [INFO] 2024-04-23 10:27:39.863 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1134)
[WI-0][TI-0] - [INFO] 2024-04-23 10:27:39.942 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
	JSON is already in processing
	#{setValue(raw_file_dir=/local_storage/reddit/processing/386-20240422.json)}
[WI-489][TI-1134] - [INFO] 2024-04-23 10:27:39.944 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1134, processId:2333 ,exitStatusCode:0 ,processWaitForStatus:true ,processExitValue:0
[WI-489][TI-1134] - [INFO] 2024-04-23 10:27:39.945 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-489][TI-1134] - [INFO] 2024-04-23 10:27:39.945 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-489][TI-1134] - [INFO] 2024-04-23 10:27:39.945 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-489][TI-1134] - [INFO] 2024-04-23 10:27:39.945 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-489][TI-1134] - [INFO] 2024-04-23 10:27:39.949 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: SUCCESS to master : 172.18.1.1:1234
[WI-489][TI-1134] - [INFO] 2024-04-23 10:27:39.949 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-489][TI-1134] - [INFO] 2024-04-23 10:27:39.949 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1134
[WI-489][TI-1134] - [INFO] 2024-04-23 10:27:39.951 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1134
[WI-489][TI-1134] - [INFO] 2024-04-23 10:27:39.951 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-1134] - [INFO] 2024-04-23 10:27:40.844 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1134, success=true)
[WI-0][TI-0] - [INFO] 2024-04-23 10:27:40.931 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1135, taskName=spark preprocessing, firstSubmitTime=1713839260924, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.9:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=80, appIds=null, processInstanceId=489, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"processing"}], executorId=1, cmdTypeIfComplement=7, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[],"rawScript":"$SPARK_HOME/bin/spark-submit \\\n    --master spark://spark-master:7077 \\\n    --conf spark.driver.cores=2 \\\n    --conf spark.driver.memory=2G \\\n    --conf spark.executor.instances=1 \\\n    --conf spark.executor.cores=2 \\\n    --conf spark.executor.memory=2G \\\n    --files ${raw_file_dir} \\\n    --name reddit_preprocessing spark_reddit_preprocessing.py\n","resourceList":[{"id":null,"resourceName":"file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py","res":null}]}, environmentConfig=export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export HADOOP_CONF_DIR=/opt/hadoop-3.4.0/etc/hadoop
export PYSPARK_DRIVER_PYTHON=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='spark preprocessing'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240423'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1135'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13210058002752'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240423102740'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='processing'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='489'}, raw_file_dir=Property{prop='raw_file_dir', direct=IN, type=VARCHAR, value='/local_storage/reddit/processing/386-20240422.json'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240422'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-489][TI-1135] - [INFO] 2024-04-23 10:27:40.932 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: spark preprocessing to wait queue success
[WI-489][TI-1135] - [INFO] 2024-04-23 10:27:40.932 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-489][TI-1135] - [INFO] 2024-04-23 10:27:40.933 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-489][TI-1135] - [INFO] 2024-04-23 10:27:40.933 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-489][TI-1135] - [INFO] 2024-04-23 10:27:40.933 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-489][TI-1135] - [INFO] 2024-04-23 10:27:40.933 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713839260933
[WI-489][TI-1135] - [INFO] 2024-04-23 10:27:40.934 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 489_1135
[WI-489][TI-1135] - [INFO] 2024-04-23 10:27:40.934 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1135,
  "taskName" : "spark preprocessing",
  "firstSubmitTime" : 1713839260924,
  "startTime" : 1713839260933,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.9:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240423/13201021801792/80/489/1135.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 80,
  "processInstanceId" : 489,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"processing\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 7,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[],\"rawScript\":\"$SPARK_HOME/bin/spark-submit \\\\\\n    --master spark://spark-master:7077 \\\\\\n    --conf spark.driver.cores=2 \\\\\\n    --conf spark.driver.memory=2G \\\\\\n    --conf spark.executor.instances=1 \\\\\\n    --conf spark.executor.cores=2 \\\\\\n    --conf spark.executor.memory=2G \\\\\\n    --files ${raw_file_dir} \\\\\\n    --name reddit_preprocessing spark_reddit_preprocessing.py\\n\",\"resourceList\":[{\"id\":null,\"resourceName\":\"file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py\",\"res\":null}]}",
  "environmentConfig" : "export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3\nexport JAVA_HOME=/opt/java/openjdk\nexport HADOOP_CONF_DIR=/opt/hadoop-3.4.0/etc/hadoop\nexport PYSPARK_DRIVER_PYTHON=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "spark preprocessing"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1135"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13210058002752"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423102740"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "processing"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "489"
    },
    "raw_file_dir" : {
      "prop" : "raw_file_dir",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit/processing/386-20240422.json"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240422"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "489_1135",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"raw_file_dir\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"/local_storage/reddit/processing/386-20240422.json\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-489][TI-1135] - [INFO] 2024-04-23 10:27:40.934 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-489][TI-1135] - [INFO] 2024-04-23 10:27:40.934 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-489][TI-1135] - [INFO] 2024-04-23 10:27:40.934 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-0][TI-1135] - [INFO] 2024-04-23 10:27:40.938 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionRunningEvent(taskInstanceId=1135, processInstanceId=489, startTime=1713839260933, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, status=TaskExecutionStatus{code=1, desc='running'}, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/80/489/1135.log, executePath=null, processId=0, appIds=null, eventCreateTime=0, eventSendTime=0)
[WI-489][TI-1135] - [INFO] 2024-04-23 10:27:40.939 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-489][TI-1135] - [INFO] 2024-04-23 10:27:40.943 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-0][TI-1135] - [INFO] 2024-04-23 10:27:40.943 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionRunningEvent(taskInstanceId=1135, processInstanceId=489, startTime=1713839260933, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, status=TaskExecutionStatus{code=1, desc='running'}, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/80/489/1135.log, executePath=null, processId=0, appIds=null, eventCreateTime=0, eventSendTime=1713839260938)
[WI-489][TI-1135] - [INFO] 2024-04-23 10:27:40.943 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1135 check successfully
[WI-489][TI-1135] - [INFO] 2024-04-23 10:27:40.944 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-489][TI-1135] - [INFO] 2024-04-23 10:27:40.945 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py=ResourceContext.ResourceItem(resourceAbsolutePathInStorage=file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py, resourceRelativePath=spark_reddit_preprocessing.py, resourceAbsolutePathInLocal=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1135/spark_reddit_preprocessing.py)})
[WI-489][TI-1135] - [INFO] 2024-04-23 10:27:40.946 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-489][TI-1135] - [INFO] 2024-04-23 10:27:40.946 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-489][TI-1135] - [INFO] 2024-04-23 10:27:40.946 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ ],
  "varPool" : null,
  "rawScript" : "$SPARK_HOME/bin/spark-submit \\\n    --master spark://spark-master:7077 \\\n    --conf spark.driver.cores=2 \\\n    --conf spark.driver.memory=2G \\\n    --conf spark.executor.instances=1 \\\n    --conf spark.executor.cores=2 \\\n    --conf spark.executor.memory=2G \\\n    --files ${raw_file_dir} \\\n    --name reddit_preprocessing spark_reddit_preprocessing.py\n",
  "resourceList" : [ {
    "id" : null,
    "resourceName" : "file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py",
    "res" : null
  } ]
}
[WI-489][TI-1135] - [INFO] 2024-04-23 10:27:40.946 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-489][TI-1135] - [INFO] 2024-04-23 10:27:40.947 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}] successfully
[WI-489][TI-1135] - [INFO] 2024-04-23 10:27:40.947 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-489][TI-1135] - [INFO] 2024-04-23 10:27:40.947 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-489][TI-1135] - [INFO] 2024-04-23 10:27:40.947 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-489][TI-1135] - [INFO] 2024-04-23 10:27:40.948 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-489][TI-1135] - [INFO] 2024-04-23 10:27:40.948 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-489][TI-1135] - [INFO] 2024-04-23 10:27:40.948 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export HADOOP_CONF_DIR=/opt/hadoop-3.4.0/etc/hadoop
export PYSPARK_DRIVER_PYTHON=/bin/python3.11
$SPARK_HOME/bin/spark-submit \
    --master spark://spark-master:7077 \
    --conf spark.driver.cores=2 \
    --conf spark.driver.memory=2G \
    --conf spark.executor.instances=1 \
    --conf spark.executor.cores=2 \
    --conf spark.executor.memory=2G \
    --files /local_storage/reddit/processing/386-20240422.json \
    --name reddit_preprocessing spark_reddit_preprocessing.py

[WI-489][TI-1135] - [INFO] 2024-04-23 10:27:40.948 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-489][TI-1135] - [INFO] 2024-04-23 10:27:40.948 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1135/489_1135.sh
[WI-489][TI-1135] - [INFO] 2024-04-23 10:27:40.952 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 2345
[WI-0][TI-1135] - [INFO] 2024-04-23 10:27:41.850 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1135, success=true)
[WI-0][TI-1135] - [INFO] 2024-04-23 10:27:41.858 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1135, success=true)
[WI-0][TI-1135] - [INFO] 2024-04-23 10:27:41.865 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1135)
[WI-0][TI-0] - [INFO] 2024-04-23 10:27:41.954 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
[WI-0][TI-0] - [INFO] 2024-04-23 10:27:42.956 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:27:42 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[WI-0][TI-0] - [INFO] 2024-04-23 10:27:43.959 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:27:43 INFO SparkContext: Running Spark version 3.5.1
	24/04/23 10:27:43 INFO SparkContext: OS info Linux, 6.5.0-28-generic, amd64
	24/04/23 10:27:43 INFO SparkContext: Java version 1.8.0_402
	24/04/23 10:27:43 INFO ResourceUtils: ==============================================================
	24/04/23 10:27:43 INFO ResourceUtils: No custom resources configured for spark.driver.
	24/04/23 10:27:43 INFO ResourceUtils: ==============================================================
	24/04/23 10:27:43 INFO SparkContext: Submitted application: reddit_preprocessing
	24/04/23 10:27:43 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 2, script: , vendor: , memory -> name: memory, amount: 2048, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
	24/04/23 10:27:43 INFO ResourceProfile: Limiting resource is cpus at 2 tasks per executor
	24/04/23 10:27:43 INFO ResourceProfileManager: Added ResourceProfile id: 0
	24/04/23 10:27:43 INFO SecurityManager: Changing view acls to: default
	24/04/23 10:27:43 INFO SecurityManager: Changing modify acls to: default
	24/04/23 10:27:43 INFO SecurityManager: Changing view acls groups to: 
	24/04/23 10:27:43 INFO SecurityManager: Changing modify acls groups to: 
	24/04/23 10:27:43 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: default; groups with view permissions: EMPTY; users with modify permissions: default; groups with modify permissions: EMPTY
[WI-0][TI-0] - [INFO] 2024-04-23 10:27:44.459 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7442528735632185 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:27:44.963 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:27:43 INFO Utils: Successfully started service 'sparkDriver' on port 37849.
	24/04/23 10:27:44 INFO SparkEnv: Registering MapOutputTracker
	24/04/23 10:27:44 INFO SparkEnv: Registering BlockManagerMaster
	24/04/23 10:27:44 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
	24/04/23 10:27:44 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
	24/04/23 10:27:44 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
	24/04/23 10:27:44 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-31fd9165-ec0c-43d9-822e-9e8c3a7204ce
	24/04/23 10:27:44 INFO MemoryStore: MemoryStore started with capacity 912.3 MiB
	24/04/23 10:27:44 INFO SparkEnv: Registering OutputCommitCoordinator
	24/04/23 10:27:44 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
	24/04/23 10:27:44 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
	24/04/23 10:27:44 INFO Utils: Successfully started service 'SparkUI' on port 4041.
	24/04/23 10:27:44 INFO SparkContext: Added file file:///local_storage/reddit/processing/386-20240422.json at spark://c0e814e3f0bd:37849/files/386-20240422.json with timestamp 1713839263412
	24/04/23 10:27:44 INFO Utils: Copying /local_storage/reddit/processing/386-20240422.json to /tmp/spark-00657c73-9a19-4473-93f4-9975038f3072/userFiles-4444f13e-4258-4a62-aea4-002e86397b6f/386-20240422.json
	24/04/23 10:27:44 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
[WI-0][TI-0] - [INFO] 2024-04-23 10:27:45.474 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7781456953642384 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:27:45.979 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:27:45 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.3:7077 after 38 ms (0 ms spent in bootstraps)
	24/04/23 10:27:45 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20240423022745-0008
	24/04/23 10:27:45 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41259.
	24/04/23 10:27:45 INFO NettyBlockTransferService: Server created on c0e814e3f0bd:41259
	24/04/23 10:27:45 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
	24/04/23 10:27:45 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, c0e814e3f0bd, 41259, None)
	24/04/23 10:27:45 INFO BlockManagerMasterEndpoint: Registering block manager c0e814e3f0bd:41259 with 912.3 MiB RAM, BlockManagerId(driver, c0e814e3f0bd, 41259, None)
	24/04/23 10:27:45 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, c0e814e3f0bd, 41259, None)
	24/04/23 10:27:45 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, c0e814e3f0bd, 41259, None)
	24/04/23 10:27:45 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
[WI-0][TI-0] - [INFO] 2024-04-23 10:27:46.477 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9176470588235294 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:27:46.983 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	
	
	
	 /tmp/spark-00657c73-9a19-4473-93f4-9975038f3072/userFiles-4444f13e-4258-4a62-aea4-002e86397b6f/386-20240422.json 
	
	
	
	24/04/23 10:27:46 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
	24/04/23 10:27:46 INFO SharedState: Warehouse path is 'file:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1135/spark-warehouse'.
[WI-0][TI-0] - [INFO] 2024-04-23 10:27:47.487 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8742690058479532 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:27:48.488 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9080779944289694 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:27:48.990 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:27:48 INFO InMemoryFileIndex: It took 45 ms to list leaf files for 1 paths.
	24/04/23 10:27:48 INFO InMemoryFileIndex: It took 2 ms to list leaf files for 1 paths.
[WI-0][TI-0] - [INFO] 2024-04-23 10:27:49.494 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8831063758248224 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:27:50.505 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8156502824593526 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:27:51.507 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7359550561797752 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:27:53.000 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:27:52 INFO FileSourceStrategy: Pushed Filters: 
	24/04/23 10:27:52 INFO FileSourceStrategy: Post-Scan Filters: 
	24/04/23 10:27:52 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 351.5 KiB, free 912.0 MiB)
	24/04/23 10:27:52 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 34.6 KiB, free 911.9 MiB)
	24/04/23 10:27:52 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on c0e814e3f0bd:41259 (size: 34.6 KiB, free: 912.3 MiB)
	24/04/23 10:27:52 INFO SparkContext: Created broadcast 0 from json at NativeMethodAccessorImpl.java:0
	24/04/23 10:27:52 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[WI-0][TI-0] - [INFO] 2024-04-23 10:27:53.530 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9008746355685131 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:27:54.003 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:27:53 INFO SparkContext: Starting job: json at NativeMethodAccessorImpl.java:0
	24/04/23 10:27:53 INFO DAGScheduler: Got job 0 (json at NativeMethodAccessorImpl.java:0) with 1 output partitions
	24/04/23 10:27:53 INFO DAGScheduler: Final stage: ResultStage 0 (json at NativeMethodAccessorImpl.java:0)
	24/04/23 10:27:53 INFO DAGScheduler: Parents of final stage: List()
	24/04/23 10:27:53 INFO DAGScheduler: Missing parents: List()
	24/04/23 10:27:53 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at json at NativeMethodAccessorImpl.java:0), which has no missing parents
	24/04/23 10:27:53 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 16.5 KiB, free 911.9 MiB)
	24/04/23 10:27:53 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.8 KiB, free 911.9 MiB)
	24/04/23 10:27:53 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on c0e814e3f0bd:41259 (size: 7.8 KiB, free: 912.3 MiB)
	24/04/23 10:27:53 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1585
	24/04/23 10:27:53 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at json at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
	24/04/23 10:27:53 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
[WI-0][TI-0] - [INFO] 2024-04-23 10:28:09.020 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:28:08 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
[WI-0][TI-0] - [INFO] 2024-04-23 10:28:22.662 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8165248226950355 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:28:24.061 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:28:23 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
[WI-0][TI-0] - [INFO] 2024-04-23 10:28:26.687 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.736413043478261 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:28:27.700 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.712707182320442 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:28:29.712 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7417582417582418 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:28:39.073 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:28:38 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
[WI-0][TI-0] - [INFO] 2024-04-23 10:28:54.435 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:28:53 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
[WI-0][TI-0] - [INFO] 2024-04-23 10:29:09.450 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:29:08 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
[WI-0][TI-0] - [ERROR] 2024-04-23 10:29:13.576 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[279] - Parse var pool error
java.io.IOException: Stream closed
	at java.io.BufferedInputStream.getBufIfOpen(BufferedInputStream.java:170)
	at java.io.BufferedInputStream.read1(BufferedInputStream.java:283)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:345)
	at sun.nio.cs.StreamDecoder.readBytes(StreamDecoder.java:284)
	at sun.nio.cs.StreamDecoder.implRead(StreamDecoder.java:326)
	at sun.nio.cs.StreamDecoder.read(StreamDecoder.java:178)
	at java.io.InputStreamReader.read(InputStreamReader.java:184)
	at java.io.BufferedReader.fill(BufferedReader.java:161)
	at java.io.BufferedReader.readLine(BufferedReader.java:324)
	at java.io.BufferedReader.readLine(BufferedReader.java:389)
	at org.apache.dolphinscheduler.plugin.task.api.AbstractCommandExecutor.lambda$parseProcessOutput$1(AbstractCommandExecutor.java:273)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
[WI-489][TI-1131] - [INFO] 2024-04-23 10:29:14.061 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has killed. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1131, processId:2076 ,exitStatusCode:137 ,processWaitForStatus:true ,processExitValue:137
[WI-489][TI-1131] - [INFO] 2024-04-23 10:29:14.070 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-489][TI-1131] - [INFO] 2024-04-23 10:29:14.074 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-489][TI-1131] - [INFO] 2024-04-23 10:29:14.080 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-489][TI-1131] - [INFO] 2024-04-23 10:29:14.080 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-489][TI-1131] - [INFO] 2024-04-23 10:29:14.097 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: KILL to master : 172.18.1.1:1234
[WI-489][TI-1131] - [INFO] 2024-04-23 10:29:14.098 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-0][TI-1131] - [INFO] 2024-04-23 10:29:14.097 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1131, processInstanceId=489, status=9, startTime=1713838597891, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/80/489/1131.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1131, endTime=1713839354080, processId=2076, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=0)
[WI-489][TI-1131] - [INFO] 2024-04-23 10:29:14.099 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1131
[WI-489][TI-1131] - [INFO] 2024-04-23 10:29:14.114 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1131
[WI-489][TI-1131] - [INFO] 2024-04-23 10:29:14.116 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-1131] - [INFO] 2024-04-23 10:29:14.132 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1131, processInstanceId=489, status=9, startTime=1713838597891, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/80/489/1131.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1131, endTime=1713839354080, processId=2076, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713839354084)
[WI-0][TI-0] - [INFO] 2024-04-23 10:29:14.461 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:29:13 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20240423022745-0008/0 on worker-20240423012857-172.18.0.7-41063 (172.18.0.7:41063) with 2 core(s)
	24/04/23 10:29:13 INFO StandaloneSchedulerBackend: Granted executor ID app-20240423022745-0008/0 on hostPort 172.18.0.7:41063 with 2 core(s), 2.0 GiB RAM
	24/04/23 10:29:13 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20240423022745-0008/0 is now RUNNING
[WI-0][TI-0] - [INFO] 2024-04-23 10:29:14.901 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.997229916897507 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-1131] - [INFO] 2024-04-23 10:29:15.064 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1131, success=true)
[WI-0][TI-1131] - [INFO] 2024-04-23 10:29:15.080 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1131, success=true)
[WI-0][TI-0] - [INFO] 2024-04-23 10:29:18.516 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:29:17 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.7:49158) with ID 0,  ResourceProfileId 0
	24/04/23 10:29:17 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.7:41855 with 1048.8 MiB RAM, BlockManagerId(0, 172.18.0.7, 41855, None)
	24/04/23 10:29:17 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.7, executor 0, partition 0, PROCESS_LOCAL, 8478 bytes) 
[WI-0][TI-0] - [INFO] 2024-04-23 10:29:25.977 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7632311977715878 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:29:27.019 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7580645161290323 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-1123] - [INFO] 2024-04-23 10:29:45.178 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1123, processInstanceId=487, status=9, startTime=1713838208504, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1123.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1123, endTime=1713838483436, processId=1677, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713839085004)
[WI-0][TI-1123] - [INFO] 2024-04-23 10:29:45.180 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1123, processInstanceId=487, status=9, startTime=1713838208504, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1123.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1123, endTime=1713838483436, processId=1677, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713839385177)
[WI-0][TI-1111] - [INFO] 2024-04-23 10:29:47.184 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1111, processInstanceId=487, status=9, startTime=1713837256404, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1111.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1111, endTime=1713838170352, processId=1017, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713839087029)
[WI-0][TI-1111] - [INFO] 2024-04-23 10:29:47.210 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1111, processInstanceId=487, status=9, startTime=1713837256404, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1111.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1111, endTime=1713838170352, processId=1017, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713839387184)
[WI-0][TI-0] - [INFO] 2024-04-23 10:30:12.363 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7711864406779662 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:30:15.401 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7771428571428571 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:30:16.410 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.726027397260274 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:30:17.411 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7541899441340782 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:30:33.468 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8011204481792717 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:30:38.499 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7826383129960907 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:30:39.517 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7194805194805195 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:30:40.519 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7030812324929971 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:31:00.628 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7698412698412699 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:31:22.681 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7768817204301075 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:31:36.728 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7114845938375349 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:31:40.751 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7138888888888888 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:31:44.792 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7085561497326204 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:31:45.802 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7002801120448179 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:32:00.835 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8787878787878788 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:32:01.848 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.712707182320442 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:32:20.921 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7755681818181818 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:32:21.930 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.770949720670391 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:32:27.935 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:32:27 ERROR StandaloneSchedulerBackend: Application has been killed. Reason: Master removed our application: KILLED
	24/04/23 10:32:27 INFO SparkContext: SparkContext is stopping with exitCode 0.
	24/04/23 10:32:27 INFO TaskSchedulerImpl: Cancelling stage 0
	24/04/23 10:32:27 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage cancelled: Job aborted due to stage failure: Master removed our application: KILLED
	24/04/23 10:32:27 INFO TaskSchedulerImpl: Stage 0 was cancelled
	24/04/23 10:32:27 INFO DAGScheduler: ResultStage 0 (json at NativeMethodAccessorImpl.java:0) failed in 274.631 s due to Job aborted due to stage failure: Master removed our application: KILLED
[WI-0][TI-0] - [INFO] 2024-04-23 10:32:28.943 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:32:27 INFO SparkUI: Stopped Spark web UI at http://c0e814e3f0bd:4041
	24/04/23 10:32:27 INFO StandaloneSchedulerBackend: Shutting down all executors
	24/04/23 10:32:27 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Asking each executor to shut down
	24/04/23 10:32:28 ERROR Utils: Uncaught exception in thread stop-spark-context
	org.apache.spark.SparkException: Exception thrown in awaitResult: 
		at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
		at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
		at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
		at org.apache.spark.deploy.client.StandaloneAppClient.stop(StandaloneAppClient.scala:288)
		at org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend.org$apache$spark$scheduler$cluster$StandaloneSchedulerBackend$$stop(StandaloneSchedulerBackend.scala:275)
		at org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend.stop(StandaloneSchedulerBackend.scala:142)
		at org.apache.spark.scheduler.SchedulerBackend.stop(SchedulerBackend.scala:33)
		at org.apache.spark.scheduler.SchedulerBackend.stop$(SchedulerBackend.scala:33)
		at org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend.stop(CoarseGrainedSchedulerBackend.scala:54)
		at org.apache.spark.scheduler.TaskSchedulerImpl.$anonfun$stop$2(TaskSchedulerImpl.scala:992)
		at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1375)
		at org.apache.spark.scheduler.TaskSchedulerImpl.stop(TaskSchedulerImpl.scala:992)
		at org.apache.spark.scheduler.DAGScheduler.$anonfun$stop$4(DAGScheduler.scala:2976)
		at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1375)
		at org.apache.spark.scheduler.DAGScheduler.stop(DAGScheduler.scala:2976)
		at org.apache.spark.SparkContext.$anonfun$stop$12(SparkContext.scala:2263)
		at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1375)
		at org.apache.spark.SparkContext.stop(SparkContext.scala:2263)
		at org.apache.spark.SparkContext.stop(SparkContext.scala:2216)
		at org.apache.spark.SparkContext$$anon$3.run(SparkContext.scala:2203)
	Caused by: org.apache.spark.SparkException: Could not find AppClient.
		at org.apache.spark.rpc.netty.Dispatcher.postMessage(Dispatcher.scala:178)
		at org.apache.spark.rpc.netty.Dispatcher.postLocalMessage(Dispatcher.scala:144)
		at org.apache.spark.rpc.netty.NettyRpcEnv.askAbortable(NettyRpcEnv.scala:242)
		at org.apache.spark.rpc.netty.NettyRpcEndpointRef.askAbortable(NettyRpcEnv.scala:554)
		at org.apache.spark.rpc.netty.NettyRpcEndpointRef.ask(NettyRpcEnv.scala:558)
		at org.apache.spark.rpc.RpcEndpointRef.ask(RpcEndpointRef.scala:72)
		... 17 more
	24/04/23 10:32:28 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
	24/04/23 10:32:28 INFO MemoryStore: MemoryStore cleared
	24/04/23 10:32:28 INFO BlockManager: BlockManager stopped
	24/04/23 10:32:28 INFO BlockManagerMaster: BlockManagerMaster stopped
	24/04/23 10:32:28 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
	24/04/23 10:32:28 INFO SparkContext: Successfully stopped SparkContext
	Traceback (most recent call last):
	  File "/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1135/spark_reddit_preprocessing.py", line 44, in <module>
	    raw_df = spark.read.json(reddit_json_dir)
	             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
	  File "/opt/spark-3.5.1-bin-hadoop3/python/lib/pyspark.zip/pyspark/sql/readwriter.py", line 425, in json
	  File "/opt/spark-3.5.1-bin-hadoop3/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
	  File "/opt/spark-3.5.1-bin-hadoop3/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 179, in deco
	  File "/opt/spark-3.5.1-bin-hadoop3/python/lib/py4j-0.10.9.7-src.zip/py4j/protocol.py", line 326, in get_return_value
	py4j.protocol.Py4JJavaError: An error occurred while calling o30.json.
	: org.apache.spark.SparkException: Job aborted due to stage failure: Master removed our application: KILLED
		at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)
		at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)
		at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)
		at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
		at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
		at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
		at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)
		at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)
		at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)
		at scala.Option.foreach(Option.scala:407)
		at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)
		at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)
		at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)
		at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)
		at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
		at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:989)
		at org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)
		at org.apache.spark.SparkContext.runJob(SparkContext.scala:2493)
		at org.apache.spark.sql.catalyst.json.JsonInferSchema.infer(JsonInferSchema.scala:120)
		at org.apache.spark.sql.execution.datasources.json.TextInputJsonDataSource$.$anonfun$inferFromDataset$5(JsonDataSource.scala:109)
		at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)
		at org.apache.spark.sql.execution.datasources.json.TextInputJsonDataSource$.inferFromDataset(JsonDataSource.scala:109)
		at org.apache.spark.sql.execution.datasources.json.TextInputJsonDataSource$.infer(JsonDataSource.scala:98)
		at org.apache.spark.sql.execution.datasources.json.JsonDataSource.inferSchema(JsonDataSource.scala:64)
		at org.apache.spark.sql.execution.datasources.json.JsonFileFormat.inferSchema(JsonFileFormat.scala:59)
		at org.apache.spark.sql.execution.datasources.DataSource.$anonfun$getOrInferFileFormatSchema$11(DataSource.scala:208)
		at scala.Option.orElse(Option.scala:447)
		at org.apache.spark.sql.execution.datasources.DataSource.getOrInferFileFormatSchema(DataSource.scala:205)
		at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:407)
		at org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)
		at org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)
		at scala.Option.getOrElse(Option.scala:189)
		at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)
		at org.apache.spark.sql.DataFrameReader.json(DataFrameReader.scala:362)
		at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
		at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
		at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
		at java.lang.reflect.Method.invoke(Method.java:498)
		at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
		at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
		at py4j.Gateway.invoke(Gateway.java:282)
		at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
		at py4j.commands.CallCommand.execute(CallCommand.java:79)
		at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
		at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
		at java.lang.Thread.run(Thread.java:750)
	
	24/04/23 10:32:28 INFO ShutdownHookManager: Shutdown hook called
	24/04/23 10:32:28 INFO ShutdownHookManager: Deleting directory /tmp/spark-2925b99c-7129-4d51-98e0-b4480b956560
	24/04/23 10:32:28 INFO ShutdownHookManager: Deleting directory /tmp/spark-00657c73-9a19-4473-93f4-9975038f3072
	24/04/23 10:32:28 INFO ShutdownHookManager: Deleting directory /tmp/spark-00657c73-9a19-4473-93f4-9975038f3072/pyspark-f461386f-ea70-4fbd-b331-8674558af458
[WI-489][TI-1135] - [INFO] 2024-04-23 10:32:28.947 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1135, processId:2345 ,exitStatusCode:1 ,processWaitForStatus:true ,processExitValue:1
[WI-489][TI-1135] - [INFO] 2024-04-23 10:32:28.949 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-489][TI-1135] - [INFO] 2024-04-23 10:32:28.949 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-489][TI-1135] - [INFO] 2024-04-23 10:32:28.949 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-489][TI-1135] - [INFO] 2024-04-23 10:32:28.950 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-489][TI-1135] - [INFO] 2024-04-23 10:32:28.953 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: FAILURE to master : 172.18.1.1:1234
[WI-489][TI-1135] - [INFO] 2024-04-23 10:32:28.953 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-489][TI-1135] - [INFO] 2024-04-23 10:32:28.953 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1135
[WI-489][TI-1135] - [INFO] 2024-04-23 10:32:28.954 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1135
[WI-489][TI-1135] - [INFO] 2024-04-23 10:32:28.954 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-1135] - [INFO] 2024-04-23 10:32:29.540 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1135, processInstanceId=489, status=6, startTime=1713839260933, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/80/489/1135.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1135, endTime=1713839548950, processId=2345, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1135] - [INFO] 2024-04-23 10:32:29.544 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1135, processInstanceId=489, status=6, startTime=1713839260933, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/80/489/1135.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1135, endTime=1713839548950, processId=2345, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713839549540)
[WI-0][TI-1135] - [INFO] 2024-04-23 10:32:29.548 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1135, success=true)
[WI-0][TI-1135] - [INFO] 2024-04-23 10:32:29.571 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1135, success=true)
[WI-0][TI-0] - [INFO] 2024-04-23 10:33:16.479 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1136, taskName=search for intake JSON files, firstSubmitTime=1713839596463, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.9:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=80, appIds=null, processInstanceId=489, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"processing"}], executorId=1, cmdTypeIfComplement=7, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":""}],"rawScript":"# find 1 raw file in the folder\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\n\n# check if raw_file_dir is empty, then set raw_file_dir to null\nif [ -z \"$raw_file_dir\" ]; then\n    raw_file_dir=null\nfi\n\necho \"#{setValue(raw_file_dir=${raw_file_dir})}\"","resourceList":[]}, environmentConfig=export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='search for intake JSON files'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240423'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1136'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13340113777664'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240423103316'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='processing'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='489'}, raw_file_dir=Property{prop='raw_file_dir', direct=OUT, type=VARCHAR, value='/local_storage/reddit/processing/386-20240422.json'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240422'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-489][TI-1136] - [INFO] 2024-04-23 10:33:16.481 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-489][TI-1136] - [INFO] 2024-04-23 10:33:16.486 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-489][TI-1136] - [INFO] 2024-04-23 10:33:16.486 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-489][TI-1136] - [INFO] 2024-04-23 10:33:16.486 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-489][TI-1136] - [INFO] 2024-04-23 10:33:16.488 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713839596488
[WI-489][TI-1136] - [INFO] 2024-04-23 10:33:16.488 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 489_1136
[WI-489][TI-1136] - [INFO] 2024-04-23 10:33:16.488 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1136,
  "taskName" : "search for intake JSON files",
  "firstSubmitTime" : 1713839596463,
  "startTime" : 1713839596488,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.9:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240423/13201021801792/80/489/1136.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 80,
  "processInstanceId" : 489,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"processing\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 7,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[{\"prop\":\"raw_file_dir\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"\"}],\"rawScript\":\"# find 1 raw file in the folder\\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\\n\\n# check if raw_file_dir is empty, then set raw_file_dir to null\\nif [ -z \\\"$raw_file_dir\\\" ]; then\\n    raw_file_dir=null\\nfi\\n\\necho \\\"#{setValue(raw_file_dir=${raw_file_dir})}\\\"\",\"resourceList\":[]}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "search for intake JSON files"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1136"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13340113777664"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423103316"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "processing"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "489"
    },
    "raw_file_dir" : {
      "prop" : "raw_file_dir",
      "direct" : "OUT",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit/processing/386-20240422.json"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240422"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "489_1136",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"raw_file_dir\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"/local_storage/reddit/processing/386-20240422.json\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-489][TI-1136] - [INFO] 2024-04-23 10:33:16.489 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-489][TI-1136] - [INFO] 2024-04-23 10:33:16.489 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-489][TI-1136] - [INFO] 2024-04-23 10:33:16.489 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-489][TI-1136] - [INFO] 2024-04-23 10:33:16.481 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: search for intake JSON files to wait queue success
[WI-489][TI-1136] - [INFO] 2024-04-23 10:33:16.501 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-489][TI-1136] - [INFO] 2024-04-23 10:33:16.502 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-489][TI-1136] - [INFO] 2024-04-23 10:33:16.503 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1136 check successfully
[WI-489][TI-1136] - [INFO] 2024-04-23 10:33:16.503 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-489][TI-1136] - [INFO] 2024-04-23 10:33:16.503 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-489][TI-1136] - [INFO] 2024-04-23 10:33:16.506 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-489][TI-1136] - [INFO] 2024-04-23 10:33:16.506 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-489][TI-1136] - [INFO] 2024-04-23 10:33:16.506 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ {
    "prop" : "raw_file_dir",
    "direct" : "OUT",
    "type" : "VARCHAR",
    "value" : ""
  } ],
  "varPool" : null,
  "rawScript" : "# find 1 raw file in the folder\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\n\n# check if raw_file_dir is empty, then set raw_file_dir to null\nif [ -z \"$raw_file_dir\" ]; then\n    raw_file_dir=null\nfi\n\necho \"#{setValue(raw_file_dir=${raw_file_dir})}\"",
  "resourceList" : [ ]
}
[WI-489][TI-1136] - [INFO] 2024-04-23 10:33:16.507 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-489][TI-1136] - [INFO] 2024-04-23 10:33:16.507 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}] successfully
[WI-489][TI-1136] - [INFO] 2024-04-23 10:33:16.507 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-489][TI-1136] - [INFO] 2024-04-23 10:33:16.507 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-489][TI-1136] - [INFO] 2024-04-23 10:33:16.507 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-489][TI-1136] - [INFO] 2024-04-23 10:33:16.507 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-489][TI-1136] - [INFO] 2024-04-23 10:33:16.507 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-489][TI-1136] - [INFO] 2024-04-23 10:33:16.507 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export PYTHON_LAUNCHER=/bin/python3.11
# find 1 raw file in the folder
raw_file_dir=$(find /local_storage/reddit/processing -type f -name '*.json'| head -n 1)

# check if raw_file_dir is empty, then set raw_file_dir to null
if [ -z "$raw_file_dir" ]; then
    raw_file_dir=null
fi

echo "#{setValue(raw_file_dir=/local_storage/reddit/processing/386-20240422.json)}"
[WI-489][TI-1136] - [INFO] 2024-04-23 10:33:16.507 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-489][TI-1136] - [INFO] 2024-04-23 10:33:16.508 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1136/489_1136.sh
[WI-489][TI-1136] - [INFO] 2024-04-23 10:33:16.532 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 2566
[WI-0][TI-0] - [INFO] 2024-04-23 10:33:16.536 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
[WI-0][TI-1136] - [INFO] 2024-04-23 10:33:16.608 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionRunningEvent(taskInstanceId=1136, processInstanceId=489, startTime=1713839596488, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, status=TaskExecutionStatus{code=1, desc='running'}, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/80/489/1136.log, executePath=null, processId=0, appIds=null, eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1136] - [INFO] 2024-04-23 10:33:16.614 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionRunningEvent(taskInstanceId=1136, processInstanceId=489, startTime=1713839596488, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, status=TaskExecutionStatus{code=1, desc='running'}, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/80/489/1136.log, executePath=null, processId=0, appIds=null, eventCreateTime=0, eventSendTime=1713839596607)
[WI-0][TI-1136] - [INFO] 2024-04-23 10:33:16.614 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionInfoEvent(taskInstanceId=1136, processInstanceId=489, startTime=1713839596488, workflowInstanceHost=172.18.0.9:5678, taskInstanceHost=172.18.1.1:1234, logPath=null, processId=0, eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1136] - [INFO] 2024-04-23 10:33:16.616 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionInfoEvent(taskInstanceId=1136, processInstanceId=489, startTime=1713839596488, workflowInstanceHost=172.18.0.9:5678, taskInstanceHost=172.18.1.1:1234, logPath=null, processId=0, eventCreateTime=0, eventSendTime=1713839596607)
[WI-0][TI-1136] - [INFO] 2024-04-23 10:33:16.678 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1136, success=true)
[WI-0][TI-1136] - [INFO] 2024-04-23 10:33:16.686 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1136)
[WI-0][TI-1136] - [INFO] 2024-04-23 10:33:16.695 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1136, success=true)
[WI-0][TI-1136] - [INFO] 2024-04-23 10:33:16.708 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1136)
[WI-0][TI-0] - [INFO] 2024-04-23 10:33:17.560 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	#{setValue(raw_file_dir=/local_storage/reddit/processing/386-20240422.json)}
[WI-489][TI-1136] - [INFO] 2024-04-23 10:33:17.561 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1136, processId:2566 ,exitStatusCode:0 ,processWaitForStatus:true ,processExitValue:0
[WI-489][TI-1136] - [INFO] 2024-04-23 10:33:17.563 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-489][TI-1136] - [INFO] 2024-04-23 10:33:17.563 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-489][TI-1136] - [INFO] 2024-04-23 10:33:17.563 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-489][TI-1136] - [INFO] 2024-04-23 10:33:17.564 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-489][TI-1136] - [INFO] 2024-04-23 10:33:17.567 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: SUCCESS to master : 172.18.1.1:1234
[WI-489][TI-1136] - [INFO] 2024-04-23 10:33:17.567 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-489][TI-1136] - [INFO] 2024-04-23 10:33:17.567 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1136
[WI-489][TI-1136] - [INFO] 2024-04-23 10:33:17.568 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1136
[WI-489][TI-1136] - [INFO] 2024-04-23 10:33:17.568 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-1136] - [INFO] 2024-04-23 10:33:17.617 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1136, processInstanceId=489, status=7, startTime=1713839596488, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/80/489/1136.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1136, endTime=1713839597563, processId=2566, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1136] - [INFO] 2024-04-23 10:33:17.622 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1136, processInstanceId=489, status=7, startTime=1713839596488, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/80/489/1136.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1136, endTime=1713839597563, processId=2566, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713839597617)
[WI-0][TI-1136] - [INFO] 2024-04-23 10:33:17.654 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1136, success=true)
[WI-0][TI-1136] - [INFO] 2024-04-23 10:33:17.656 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1136, success=true)
[WI-0][TI-0] - [INFO] 2024-04-23 10:33:18.886 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1138, taskName=move to processing, firstSubmitTime=1713839598870, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.9:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=80, appIds=null, processInstanceId=489, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"processing"}], executorId=1, cmdTypeIfComplement=7, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":""}],"rawScript":"# move file to the reddit processing folder\n# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error\nfilename=$(basename \"${raw_file_dir}\")\nif ! grep -q \"${REDDIT_HOME}/processing\" <<< \"${raw_file_dir}\"; then\n    mv ${raw_file_dir} ${REDDIT_HOME}/processing\nelse\n    echo JSON is already in processing\nfi\n\n# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing\necho \"#{setValue(raw_file_dir=${REDDIT_HOME}/processing/${filename})}\"","resourceList":[]}, environmentConfig=export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='move to processing'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240423'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1138'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13340390094208'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240423103318'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='processing'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='489'}, raw_file_dir=Property{prop='raw_file_dir', direct=IN, type=VARCHAR, value='/local_storage/reddit/processing/386-20240422.json'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240422'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-489][TI-1138] - [INFO] 2024-04-23 10:33:18.888 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: move to processing to wait queue success
[WI-489][TI-1138] - [INFO] 2024-04-23 10:33:18.889 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-489][TI-1138] - [INFO] 2024-04-23 10:33:18.890 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-489][TI-1138] - [INFO] 2024-04-23 10:33:18.891 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-489][TI-1138] - [INFO] 2024-04-23 10:33:18.891 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-489][TI-1138] - [INFO] 2024-04-23 10:33:18.891 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713839598891
[WI-489][TI-1138] - [INFO] 2024-04-23 10:33:18.891 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 489_1138
[WI-489][TI-1138] - [INFO] 2024-04-23 10:33:18.891 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1138,
  "taskName" : "move to processing",
  "firstSubmitTime" : 1713839598870,
  "startTime" : 1713839598891,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.9:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240423/13201021801792/80/489/1138.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 80,
  "processInstanceId" : 489,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"processing\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 7,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[{\"prop\":\"raw_file_dir\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"\"}],\"rawScript\":\"# move file to the reddit processing folder\\n# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error\\nfilename=$(basename \\\"${raw_file_dir}\\\")\\nif ! grep -q \\\"${REDDIT_HOME}/processing\\\" <<< \\\"${raw_file_dir}\\\"; then\\n    mv ${raw_file_dir} ${REDDIT_HOME}/processing\\nelse\\n    echo JSON is already in processing\\nfi\\n\\n# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing\\necho \\\"#{setValue(raw_file_dir=${REDDIT_HOME}/processing/${filename})}\\\"\",\"resourceList\":[]}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "move to processing"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1138"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13340390094208"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423103318"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "processing"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "489"
    },
    "raw_file_dir" : {
      "prop" : "raw_file_dir",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit/processing/386-20240422.json"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240422"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "489_1138",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"raw_file_dir\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"/local_storage/reddit/processing/386-20240422.json\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-489][TI-1138] - [INFO] 2024-04-23 10:33:18.892 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-489][TI-1138] - [INFO] 2024-04-23 10:33:18.892 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-489][TI-1138] - [INFO] 2024-04-23 10:33:18.892 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-489][TI-1138] - [INFO] 2024-04-23 10:33:18.898 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-489][TI-1138] - [INFO] 2024-04-23 10:33:18.898 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-489][TI-1138] - [INFO] 2024-04-23 10:33:18.898 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1138 check successfully
[WI-489][TI-1138] - [INFO] 2024-04-23 10:33:18.899 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-489][TI-1138] - [INFO] 2024-04-23 10:33:18.899 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-489][TI-1138] - [INFO] 2024-04-23 10:33:18.899 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-489][TI-1138] - [INFO] 2024-04-23 10:33:18.899 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-489][TI-1138] - [INFO] 2024-04-23 10:33:18.899 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ {
    "prop" : "raw_file_dir",
    "direct" : "OUT",
    "type" : "VARCHAR",
    "value" : ""
  } ],
  "varPool" : null,
  "rawScript" : "# move file to the reddit processing folder\n# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error\nfilename=$(basename \"${raw_file_dir}\")\nif ! grep -q \"${REDDIT_HOME}/processing\" <<< \"${raw_file_dir}\"; then\n    mv ${raw_file_dir} ${REDDIT_HOME}/processing\nelse\n    echo JSON is already in processing\nfi\n\n# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing\necho \"#{setValue(raw_file_dir=${REDDIT_HOME}/processing/${filename})}\"",
  "resourceList" : [ ]
}
[WI-489][TI-1138] - [INFO] 2024-04-23 10:33:18.900 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-489][TI-1138] - [INFO] 2024-04-23 10:33:18.900 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}] successfully
[WI-489][TI-1138] - [INFO] 2024-04-23 10:33:18.900 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-489][TI-1138] - [INFO] 2024-04-23 10:33:18.900 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-489][TI-1138] - [INFO] 2024-04-23 10:33:18.900 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-489][TI-1138] - [INFO] 2024-04-23 10:33:18.901 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-489][TI-1138] - [INFO] 2024-04-23 10:33:18.901 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-489][TI-1138] - [INFO] 2024-04-23 10:33:18.901 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export PYTHON_LAUNCHER=/bin/python3.11
# move file to the reddit processing folder
# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error
filename=$(basename "/local_storage/reddit/processing/386-20240422.json")
if ! grep -q "/local_storage/reddit/processing" <<< "/local_storage/reddit/processing/386-20240422.json"; then
    mv /local_storage/reddit/processing/386-20240422.json /local_storage/reddit/processing
else
    echo JSON is already in processing
fi

# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing
echo "#{setValue(raw_file_dir=/local_storage/reddit/processing/${filename})}"
[WI-489][TI-1138] - [INFO] 2024-04-23 10:33:18.901 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-489][TI-1138] - [INFO] 2024-04-23 10:33:18.901 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1138/489_1138.sh
[WI-489][TI-1138] - [INFO] 2024-04-23 10:33:18.904 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 2585
[WI-0][TI-1138] - [INFO] 2024-04-23 10:33:19.627 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionRunningEvent(taskInstanceId=1138, processInstanceId=489, startTime=1713839598891, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, status=TaskExecutionStatus{code=1, desc='running'}, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/80/489/1138.log, executePath=null, processId=0, appIds=null, eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1138] - [INFO] 2024-04-23 10:33:19.631 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionRunningEvent(taskInstanceId=1138, processInstanceId=489, startTime=1713839598891, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, status=TaskExecutionStatus{code=1, desc='running'}, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/80/489/1138.log, executePath=null, processId=0, appIds=null, eventCreateTime=0, eventSendTime=1713839599626)
[WI-0][TI-1138] - [INFO] 2024-04-23 10:33:19.631 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionInfoEvent(taskInstanceId=1138, processInstanceId=489, startTime=1713839598891, workflowInstanceHost=172.18.0.9:5678, taskInstanceHost=172.18.1.1:1234, logPath=null, processId=0, eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1138] - [INFO] 2024-04-23 10:33:19.634 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionInfoEvent(taskInstanceId=1138, processInstanceId=489, startTime=1713839598891, workflowInstanceHost=172.18.0.9:5678, taskInstanceHost=172.18.1.1:1234, logPath=null, processId=0, eventCreateTime=0, eventSendTime=1713839599626)
[WI-0][TI-1138] - [INFO] 2024-04-23 10:33:19.667 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1138, success=true)
[WI-0][TI-1138] - [INFO] 2024-04-23 10:33:19.672 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1138)
[WI-0][TI-1138] - [INFO] 2024-04-23 10:33:19.681 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1138, success=true)
[WI-0][TI-1138] - [INFO] 2024-04-23 10:33:19.687 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1138)
[WI-0][TI-0] - [INFO] 2024-04-23 10:33:19.928 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
	JSON is already in processing
	#{setValue(raw_file_dir=/local_storage/reddit/processing/386-20240422.json)}
[WI-489][TI-1138] - [INFO] 2024-04-23 10:33:19.943 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1138, processId:2585 ,exitStatusCode:0 ,processWaitForStatus:true ,processExitValue:0
[WI-489][TI-1138] - [INFO] 2024-04-23 10:33:19.944 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-489][TI-1138] - [INFO] 2024-04-23 10:33:19.944 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-489][TI-1138] - [INFO] 2024-04-23 10:33:19.946 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-489][TI-1138] - [INFO] 2024-04-23 10:33:19.947 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-489][TI-1138] - [INFO] 2024-04-23 10:33:19.950 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: SUCCESS to master : 172.18.1.1:1234
[WI-489][TI-1138] - [INFO] 2024-04-23 10:33:19.950 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-489][TI-1138] - [INFO] 2024-04-23 10:33:19.951 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1138
[WI-489][TI-1138] - [INFO] 2024-04-23 10:33:19.952 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1138
[WI-489][TI-1138] - [INFO] 2024-04-23 10:33:19.952 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-1138] - [INFO] 2024-04-23 10:33:20.634 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1138, processInstanceId=489, status=7, startTime=1713839598891, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/80/489/1138.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1138, endTime=1713839599946, processId=2585, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1138] - [INFO] 2024-04-23 10:33:20.637 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1138, processInstanceId=489, status=7, startTime=1713839598891, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/80/489/1138.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1138, endTime=1713839599946, processId=2585, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713839600634)
[WI-0][TI-1138] - [INFO] 2024-04-23 10:33:20.679 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1138, success=true)
[WI-0][TI-1138] - [INFO] 2024-04-23 10:33:20.683 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1138, success=true)
[WI-0][TI-0] - [INFO] 2024-04-23 10:33:20.786 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1139, taskName=spark preprocessing, firstSubmitTime=1713839600768, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.9:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=80, appIds=null, processInstanceId=489, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"processing"}], executorId=1, cmdTypeIfComplement=7, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[],"rawScript":"$SPARK_HOME/bin/spark-submit \\\n    --master spark://spark-master:7077 \\\n    --conf spark.driver.cores=2 \\\n    --conf spark.driver.memory=2G \\\n    --conf spark.executor.instances=1 \\\n    --conf spark.executor.cores=2 \\\n    --conf spark.executor.memory=2G \\\n    --files ${raw_file_dir} \\\n    --name reddit_preprocessing spark_reddit_preprocessing.py\n","resourceList":[{"id":null,"resourceName":"file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py","res":null}]}, environmentConfig=export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export HADOOP_CONF_DIR=/opt/hadoop-3.4.0/etc/hadoop
export PYSPARK_DRIVER_PYTHON=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='spark preprocessing'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240423'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1139'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13210058002752'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240423103320'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='processing'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='489'}, raw_file_dir=Property{prop='raw_file_dir', direct=IN, type=VARCHAR, value='/local_storage/reddit/processing/386-20240422.json'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240422'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-489][TI-1139] - [INFO] 2024-04-23 10:33:20.787 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: spark preprocessing to wait queue success
[WI-489][TI-1139] - [INFO] 2024-04-23 10:33:20.788 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-489][TI-1139] - [INFO] 2024-04-23 10:33:20.788 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-489][TI-1139] - [INFO] 2024-04-23 10:33:20.788 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-489][TI-1139] - [INFO] 2024-04-23 10:33:20.788 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-489][TI-1139] - [INFO] 2024-04-23 10:33:20.789 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713839600789
[WI-489][TI-1139] - [INFO] 2024-04-23 10:33:20.791 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 489_1139
[WI-489][TI-1139] - [INFO] 2024-04-23 10:33:20.792 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1139,
  "taskName" : "spark preprocessing",
  "firstSubmitTime" : 1713839600768,
  "startTime" : 1713839600789,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.9:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240423/13201021801792/80/489/1139.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 80,
  "processInstanceId" : 489,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"processing\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 7,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[],\"rawScript\":\"$SPARK_HOME/bin/spark-submit \\\\\\n    --master spark://spark-master:7077 \\\\\\n    --conf spark.driver.cores=2 \\\\\\n    --conf spark.driver.memory=2G \\\\\\n    --conf spark.executor.instances=1 \\\\\\n    --conf spark.executor.cores=2 \\\\\\n    --conf spark.executor.memory=2G \\\\\\n    --files ${raw_file_dir} \\\\\\n    --name reddit_preprocessing spark_reddit_preprocessing.py\\n\",\"resourceList\":[{\"id\":null,\"resourceName\":\"file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py\",\"res\":null}]}",
  "environmentConfig" : "export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3\nexport JAVA_HOME=/opt/java/openjdk\nexport HADOOP_CONF_DIR=/opt/hadoop-3.4.0/etc/hadoop\nexport PYSPARK_DRIVER_PYTHON=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "spark preprocessing"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1139"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13210058002752"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423103320"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "processing"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "489"
    },
    "raw_file_dir" : {
      "prop" : "raw_file_dir",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit/processing/386-20240422.json"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240422"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "489_1139",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"raw_file_dir\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"/local_storage/reddit/processing/386-20240422.json\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-489][TI-1139] - [INFO] 2024-04-23 10:33:20.792 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-489][TI-1139] - [INFO] 2024-04-23 10:33:20.793 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-489][TI-1139] - [INFO] 2024-04-23 10:33:20.793 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-489][TI-1139] - [INFO] 2024-04-23 10:33:20.815 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-489][TI-1139] - [INFO] 2024-04-23 10:33:20.816 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-489][TI-1139] - [INFO] 2024-04-23 10:33:20.817 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1139 check successfully
[WI-489][TI-1139] - [INFO] 2024-04-23 10:33:20.817 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-489][TI-1139] - [INFO] 2024-04-23 10:33:20.821 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py=ResourceContext.ResourceItem(resourceAbsolutePathInStorage=file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py, resourceRelativePath=spark_reddit_preprocessing.py, resourceAbsolutePathInLocal=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1139/spark_reddit_preprocessing.py)})
[WI-489][TI-1139] - [INFO] 2024-04-23 10:33:20.821 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-489][TI-1139] - [INFO] 2024-04-23 10:33:20.822 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-489][TI-1139] - [INFO] 2024-04-23 10:33:20.822 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ ],
  "varPool" : null,
  "rawScript" : "$SPARK_HOME/bin/spark-submit \\\n    --master spark://spark-master:7077 \\\n    --conf spark.driver.cores=2 \\\n    --conf spark.driver.memory=2G \\\n    --conf spark.executor.instances=1 \\\n    --conf spark.executor.cores=2 \\\n    --conf spark.executor.memory=2G \\\n    --files ${raw_file_dir} \\\n    --name reddit_preprocessing spark_reddit_preprocessing.py\n",
  "resourceList" : [ {
    "id" : null,
    "resourceName" : "file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py",
    "res" : null
  } ]
}
[WI-489][TI-1139] - [INFO] 2024-04-23 10:33:20.822 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-489][TI-1139] - [INFO] 2024-04-23 10:33:20.823 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}] successfully
[WI-489][TI-1139] - [INFO] 2024-04-23 10:33:20.823 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-489][TI-1139] - [INFO] 2024-04-23 10:33:20.823 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-489][TI-1139] - [INFO] 2024-04-23 10:33:20.823 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-489][TI-1139] - [INFO] 2024-04-23 10:33:20.824 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-489][TI-1139] - [INFO] 2024-04-23 10:33:20.824 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-489][TI-1139] - [INFO] 2024-04-23 10:33:20.824 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export HADOOP_CONF_DIR=/opt/hadoop-3.4.0/etc/hadoop
export PYSPARK_DRIVER_PYTHON=/bin/python3.11
$SPARK_HOME/bin/spark-submit \
    --master spark://spark-master:7077 \
    --conf spark.driver.cores=2 \
    --conf spark.driver.memory=2G \
    --conf spark.executor.instances=1 \
    --conf spark.executor.cores=2 \
    --conf spark.executor.memory=2G \
    --files /local_storage/reddit/processing/386-20240422.json \
    --name reddit_preprocessing spark_reddit_preprocessing.py

[WI-489][TI-1139] - [INFO] 2024-04-23 10:33:20.825 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-489][TI-1139] - [INFO] 2024-04-23 10:33:20.825 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1139/489_1139.sh
[WI-489][TI-1139] - [INFO] 2024-04-23 10:33:20.835 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 2597
[WI-0][TI-0] - [INFO] 2024-04-23 10:33:21.384 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8034513634513635 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-1139] - [INFO] 2024-04-23 10:33:21.638 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionRunningEvent(taskInstanceId=1139, processInstanceId=489, startTime=1713839600789, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, status=TaskExecutionStatus{code=1, desc='running'}, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/80/489/1139.log, executePath=null, processId=0, appIds=null, eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1139] - [INFO] 2024-04-23 10:33:21.642 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionRunningEvent(taskInstanceId=1139, processInstanceId=489, startTime=1713839600789, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, status=TaskExecutionStatus{code=1, desc='running'}, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/80/489/1139.log, executePath=null, processId=0, appIds=null, eventCreateTime=0, eventSendTime=1713839601638)
[WI-0][TI-1139] - [INFO] 2024-04-23 10:33:21.642 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionInfoEvent(taskInstanceId=1139, processInstanceId=489, startTime=1713839600789, workflowInstanceHost=172.18.0.9:5678, taskInstanceHost=172.18.1.1:1234, logPath=null, processId=0, eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1139] - [INFO] 2024-04-23 10:33:21.651 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionInfoEvent(taskInstanceId=1139, processInstanceId=489, startTime=1713839600789, workflowInstanceHost=172.18.0.9:5678, taskInstanceHost=172.18.1.1:1234, logPath=null, processId=0, eventCreateTime=0, eventSendTime=1713839601638)
[WI-0][TI-1139] - [INFO] 2024-04-23 10:33:21.725 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1139, success=true)
[WI-0][TI-1139] - [INFO] 2024-04-23 10:33:21.749 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1139)
[WI-0][TI-1139] - [INFO] 2024-04-23 10:33:21.772 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1139, success=true)
[WI-0][TI-1139] - [INFO] 2024-04-23 10:33:21.824 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1139)
[WI-0][TI-0] - [INFO] 2024-04-23 10:33:21.837 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
[WI-0][TI-0] - [INFO] 2024-04-23 10:33:22.421 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.888268156424581 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:33:23.427 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8763250883392226 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:33:23.859 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:33:23 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[WI-0][TI-0] - [INFO] 2024-04-23 10:33:24.429 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8024316109422492 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:33:25.431 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.760806916426513 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:33:25.861 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:33:24 INFO SparkContext: Running Spark version 3.5.1
	24/04/23 10:33:24 INFO SparkContext: OS info Linux, 6.5.0-28-generic, amd64
	24/04/23 10:33:24 INFO SparkContext: Java version 1.8.0_402
	24/04/23 10:33:25 INFO ResourceUtils: ==============================================================
	24/04/23 10:33:25 INFO ResourceUtils: No custom resources configured for spark.driver.
	24/04/23 10:33:25 INFO ResourceUtils: ==============================================================
	24/04/23 10:33:25 INFO SparkContext: Submitted application: reddit_preprocessing
	24/04/23 10:33:25 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 2, script: , vendor: , memory -> name: memory, amount: 2048, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
	24/04/23 10:33:25 INFO ResourceProfile: Limiting resource is cpus at 2 tasks per executor
	24/04/23 10:33:25 INFO ResourceProfileManager: Added ResourceProfile id: 0
	24/04/23 10:33:25 INFO SecurityManager: Changing view acls to: default
	24/04/23 10:33:25 INFO SecurityManager: Changing modify acls to: default
	24/04/23 10:33:25 INFO SecurityManager: Changing view acls groups to: 
	24/04/23 10:33:25 INFO SecurityManager: Changing modify acls groups to: 
	24/04/23 10:33:25 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: default; groups with view permissions: EMPTY; users with modify permissions: default; groups with modify permissions: EMPTY
	24/04/23 10:33:25 INFO Utils: Successfully started service 'sparkDriver' on port 43981.
[WI-0][TI-0] - [INFO] 2024-04-23 10:33:26.442 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8205980066445183 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:33:26.869 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:33:25 INFO SparkEnv: Registering MapOutputTracker
	24/04/23 10:33:25 INFO SparkEnv: Registering BlockManagerMaster
	24/04/23 10:33:26 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
	24/04/23 10:33:26 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
	24/04/23 10:33:26 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
	24/04/23 10:33:26 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-e24e36f2-ef04-450d-ac71-11803e5e7fa4
	24/04/23 10:33:26 INFO MemoryStore: MemoryStore started with capacity 912.3 MiB
	24/04/23 10:33:26 INFO SparkEnv: Registering OutputCommitCoordinator
	24/04/23 10:33:26 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
	24/04/23 10:33:26 INFO Utils: Successfully started service 'SparkUI' on port 4040.
	24/04/23 10:33:26 INFO SparkContext: Added file file:///local_storage/reddit/processing/386-20240422.json at spark://c0e814e3f0bd:43981/files/386-20240422.json with timestamp 1713839604957
	24/04/23 10:33:26 INFO Utils: Copying /local_storage/reddit/processing/386-20240422.json to /tmp/spark-b7d84492-205c-4eaf-a387-6cd221906081/userFiles-09f3bc54-c479-42eb-b309-d7bafa7a19f0/386-20240422.json
[WI-0][TI-0] - [INFO] 2024-04-23 10:33:27.446 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7987987987987987 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:33:27.890 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:33:26 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
	24/04/23 10:33:27 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.3:7077 after 143 ms (0 ms spent in bootstraps)
	24/04/23 10:33:27 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20240423023327-0009
	24/04/23 10:33:27 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20240423023327-0009/0 on worker-20240423012857-172.18.0.7-41063 (172.18.0.7:41063) with 2 core(s)
	24/04/23 10:33:27 INFO StandaloneSchedulerBackend: Granted executor ID app-20240423023327-0009/0 on hostPort 172.18.0.7:41063 with 2 core(s), 2.0 GiB RAM
	24/04/23 10:33:27 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35529.
	24/04/23 10:33:27 INFO NettyBlockTransferService: Server created on c0e814e3f0bd:35529
	24/04/23 10:33:27 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
	24/04/23 10:33:27 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, c0e814e3f0bd, 35529, None)
	24/04/23 10:33:27 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20240423023327-0009/0 is now RUNNING
	24/04/23 10:33:27 INFO BlockManagerMasterEndpoint: Registering block manager c0e814e3f0bd:35529 with 912.3 MiB RAM, BlockManagerId(driver, c0e814e3f0bd, 35529, None)
	24/04/23 10:33:27 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, c0e814e3f0bd, 35529, None)
	24/04/23 10:33:27 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, c0e814e3f0bd, 35529, None)
[WI-0][TI-0] - [INFO] 2024-04-23 10:33:28.451 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9553264604810996 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:33:28.897 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:33:28 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
[WI-0][TI-0] - [INFO] 2024-04-23 10:33:29.452 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9624999999999999 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:33:29.906 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	
	
	
	 /tmp/spark-b7d84492-205c-4eaf-a387-6cd221906081/userFiles-09f3bc54-c479-42eb-b309-d7bafa7a19f0/386-20240422.json 
	
	
	
	24/04/23 10:33:28 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
	24/04/23 10:33:28 INFO SharedState: Warehouse path is 'file:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1139/spark-warehouse'.
[WI-0][TI-0] - [INFO] 2024-04-23 10:33:30.456 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9122137404580153 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:33:31.470 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7912621359223301 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:33:32.561 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9448529411764706 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:33:32.950 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:33:31 INFO InMemoryFileIndex: It took 175 ms to list leaf files for 1 paths.
	24/04/23 10:33:32 INFO InMemoryFileIndex: It took 25 ms to list leaf files for 1 paths.
[WI-0][TI-0] - [INFO] 2024-04-23 10:33:33.563 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9705882352941178 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:33:34.570 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.960960960960961 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:33:35.571 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8772563176895307 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:33:36.573 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8600682593856656 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:33:36.974 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:33:36 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.7:37650) with ID 0,  ResourceProfileId 0
	24/04/23 10:33:36 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.7:45815 with 1048.8 MiB RAM, BlockManagerId(0, 172.18.0.7, 45815, None)
[WI-0][TI-0] - [INFO] 2024-04-23 10:33:37.575 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8306010928961749 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:33:38.986 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:33:38 INFO FileSourceStrategy: Pushed Filters: 
	24/04/23 10:33:38 INFO FileSourceStrategy: Post-Scan Filters: 
[WI-0][TI-0] - [INFO] 2024-04-23 10:33:39.607 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7126436781609196 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:33:39.988 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:33:39 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 351.5 KiB, free 912.0 MiB)
	24/04/23 10:33:39 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 34.7 KiB, free 911.9 MiB)
	24/04/23 10:33:39 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on c0e814e3f0bd:35529 (size: 34.7 KiB, free: 912.3 MiB)
	24/04/23 10:33:39 INFO SparkContext: Created broadcast 0 from json at NativeMethodAccessorImpl.java:0
	24/04/23 10:33:39 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
	24/04/23 10:33:39 INFO SparkContext: Starting job: json at NativeMethodAccessorImpl.java:0
	24/04/23 10:33:39 INFO DAGScheduler: Got job 0 (json at NativeMethodAccessorImpl.java:0) with 1 output partitions
	24/04/23 10:33:39 INFO DAGScheduler: Final stage: ResultStage 0 (json at NativeMethodAccessorImpl.java:0)
	24/04/23 10:33:39 INFO DAGScheduler: Parents of final stage: List()
	24/04/23 10:33:39 INFO DAGScheduler: Missing parents: List()
	24/04/23 10:33:39 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at json at NativeMethodAccessorImpl.java:0), which has no missing parents
	24/04/23 10:33:39 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 16.5 KiB, free 911.9 MiB)
	24/04/23 10:33:39 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.8 KiB, free 911.9 MiB)
	24/04/23 10:33:39 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on c0e814e3f0bd:35529 (size: 7.8 KiB, free: 912.3 MiB)
	24/04/23 10:33:39 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1585
	24/04/23 10:33:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at json at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
	24/04/23 10:33:39 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
[WI-0][TI-0] - [INFO] 2024-04-23 10:33:40.991 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:33:40 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.7, executor 0, partition 0, PROCESS_LOCAL, 8478 bytes) 
[WI-0][TI-0] - [INFO] 2024-04-23 10:34:08.728 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8148148148148149 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-1123] - [INFO] 2024-04-23 10:34:46.045 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1123, processInstanceId=487, status=9, startTime=1713838208504, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1123.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1123, endTime=1713838483436, processId=1677, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713839385177)
[WI-0][TI-1123] - [INFO] 2024-04-23 10:34:46.050 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1123, processInstanceId=487, status=9, startTime=1713838208504, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1123.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1123, endTime=1713838483436, processId=1677, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713839686045)
[WI-0][TI-1111] - [INFO] 2024-04-23 10:34:48.051 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1111, processInstanceId=487, status=9, startTime=1713837256404, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1111.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1111, endTime=1713838170352, processId=1017, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713839387184)
[WI-0][TI-1111] - [INFO] 2024-04-23 10:34:48.059 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1111, processInstanceId=487, status=9, startTime=1713837256404, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1111.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1111, endTime=1713838170352, processId=1017, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713839688051)
[WI-0][TI-1123] - [INFO] 2024-04-23 10:39:46.410 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1123, processInstanceId=487, status=9, startTime=1713838208504, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1123.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1123, endTime=1713838483436, processId=1677, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713839686045)
[WI-0][TI-1123] - [INFO] 2024-04-23 10:39:46.416 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1123, processInstanceId=487, status=9, startTime=1713838208504, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1123.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1123, endTime=1713838483436, processId=1677, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713839986410)
[WI-0][TI-1111] - [INFO] 2024-04-23 10:39:48.418 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1111, processInstanceId=487, status=9, startTime=1713837256404, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1111.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1111, endTime=1713838170352, processId=1017, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713839688051)
[WI-0][TI-1111] - [INFO] 2024-04-23 10:39:48.422 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1111, processInstanceId=487, status=9, startTime=1713837256404, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1111.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1111, endTime=1713838170352, processId=1017, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713839988418)
[WI-0][TI-1123] - [INFO] 2024-04-23 10:44:47.022 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1123, processInstanceId=487, status=9, startTime=1713838208504, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1123.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1123, endTime=1713838483436, processId=1677, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713839986410)
[WI-0][TI-1123] - [INFO] 2024-04-23 10:44:47.026 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1123, processInstanceId=487, status=9, startTime=1713838208504, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1123.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1123, endTime=1713838483436, processId=1677, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713840287022)
[WI-0][TI-1111] - [INFO] 2024-04-23 10:44:49.029 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1111, processInstanceId=487, status=9, startTime=1713837256404, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1111.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1111, endTime=1713838170352, processId=1017, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713839988418)
[WI-0][TI-1111] - [INFO] 2024-04-23 10:44:49.032 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1111, processInstanceId=487, status=9, startTime=1713837256404, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1111.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1111, endTime=1713838170352, processId=1017, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713840289029)
[WI-0][TI-1123] - [INFO] 2024-04-23 10:49:47.724 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1123, processInstanceId=487, status=9, startTime=1713838208504, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1123.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1123, endTime=1713838483436, processId=1677, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713840287022)
[WI-0][TI-1123] - [INFO] 2024-04-23 10:49:47.729 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1123, processInstanceId=487, status=9, startTime=1713838208504, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1123.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1123, endTime=1713838483436, processId=1677, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713840587724)
[WI-0][TI-1111] - [INFO] 2024-04-23 10:49:49.769 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1111, processInstanceId=487, status=9, startTime=1713837256404, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1111.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1111, endTime=1713838170352, processId=1017, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713840289029)
[WI-0][TI-1111] - [INFO] 2024-04-23 10:49:49.778 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1111, processInstanceId=487, status=9, startTime=1713837256404, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1111.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1111, endTime=1713838170352, processId=1017, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713840589769)
[WI-0][TI-1123] - [INFO] 2024-04-23 10:54:47.903 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1123, processInstanceId=487, status=9, startTime=1713838208504, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1123.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1123, endTime=1713838483436, processId=1677, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713840587724)
[WI-0][TI-1123] - [INFO] 2024-04-23 10:54:47.906 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1123, processInstanceId=487, status=9, startTime=1713838208504, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1123.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1123, endTime=1713838483436, processId=1677, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713840887903)
[WI-0][TI-1111] - [INFO] 2024-04-23 10:54:49.910 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1111, processInstanceId=487, status=9, startTime=1713837256404, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1111.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1111, endTime=1713838170352, processId=1017, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713840589769)
[WI-0][TI-1111] - [INFO] 2024-04-23 10:54:49.914 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1111, processInstanceId=487, status=9, startTime=1713837256404, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1111.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1111, endTime=1713838170352, processId=1017, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713840889910)
[WI-0][TI-0] - [INFO] 2024-04-23 10:55:08.124 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:55:07 ERROR StandaloneSchedulerBackend: Application has been killed. Reason: Master removed our application: KILLED
	24/04/23 10:55:07 INFO SparkContext: SparkContext is stopping with exitCode 0.
	24/04/23 10:55:07 INFO TaskSchedulerImpl: Cancelling stage 0
	24/04/23 10:55:07 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage cancelled: Job aborted due to stage failure: Master removed our application: KILLED
	24/04/23 10:55:07 INFO TaskSchedulerImpl: Stage 0 was cancelled
	24/04/23 10:55:07 INFO DAGScheduler: ResultStage 0 (json at NativeMethodAccessorImpl.java:0) failed in 1288.024 s due to Job aborted due to stage failure: Master removed our application: KILLED
	24/04/23 10:55:07 INFO DAGScheduler: Job 0 failed: json at NativeMethodAccessorImpl.java:0, took 1288.206347 s
	24/04/23 10:55:07 INFO SparkUI: Stopped Spark web UI at http://c0e814e3f0bd:4040
	24/04/23 10:55:07 INFO StandaloneSchedulerBackend: Shutting down all executors
	24/04/23 10:55:07 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Asking each executor to shut down
	24/04/23 10:55:07 ERROR Utils: Uncaught exception in thread stop-spark-context
	org.apache.spark.SparkException: Exception thrown in awaitResult: 
		at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
		at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
		at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
		at org.apache.spark.deploy.client.StandaloneAppClient.stop(StandaloneAppClient.scala:288)
		at org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend.org$apache$spark$scheduler$cluster$StandaloneSchedulerBackend$$stop(StandaloneSchedulerBackend.scala:275)
		at org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend.stop(StandaloneSchedulerBackend.scala:142)
		at org.apache.spark.scheduler.SchedulerBackend.stop(SchedulerBackend.scala:33)
		at org.apache.spark.scheduler.SchedulerBackend.stop$(SchedulerBackend.scala:33)
		at org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend.stop(CoarseGrainedSchedulerBackend.scala:54)
		at org.apache.spark.scheduler.TaskSchedulerImpl.$anonfun$stop$2(TaskSchedulerImpl.scala:992)
		at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1375)
		at org.apache.spark.scheduler.TaskSchedulerImpl.stop(TaskSchedulerImpl.scala:992)
		at org.apache.spark.scheduler.DAGScheduler.$anonfun$stop$4(DAGScheduler.scala:2976)
		at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1375)
		at org.apache.spark.scheduler.DAGScheduler.stop(DAGScheduler.scala:2976)
		at org.apache.spark.SparkContext.$anonfun$stop$12(SparkContext.scala:2263)
		at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1375)
		at org.apache.spark.SparkContext.stop(SparkContext.scala:2263)
		at org.apache.spark.SparkContext.stop(SparkContext.scala:2216)
		at org.apache.spark.SparkContext$$anon$3.run(SparkContext.scala:2203)
	Caused by: org.apache.spark.SparkException: Could not find AppClient.
		at org.apache.spark.rpc.netty.Dispatcher.postMessage(Dispatcher.scala:178)
		at org.apache.spark.rpc.netty.Dispatcher.postLocalMessage(Dispatcher.scala:144)
		at org.apache.spark.rpc.netty.NettyRpcEnv.askAbortable(NettyRpcEnv.scala:242)
		at org.apache.spark.rpc.netty.NettyRpcEndpointRef.askAbortable(NettyRpcEnv.scala:554)
		at org.apache.spark.rpc.netty.NettyRpcEndpointRef.ask(NettyRpcEnv.scala:558)
		at org.apache.spark.rpc.RpcEndpointRef.ask(RpcEndpointRef.scala:72)
		... 17 more
	Traceback (most recent call last):
	  File "/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1139/spark_reddit_preprocessing.py", line 44, in <module>
	    raw_df = spark.read.json(reddit_json_dir)
	             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
	  File "/opt/spark-3.5.1-bin-hadoop3/python/lib/pyspark.zip/pyspark/sql/readwriter.py", line 425, in json
	  File "/opt/spark-3.5.1-bin-hadoop3/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
	  File "/opt/spark-3.5.1-bin-hadoop3/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 179, in deco
	  File "/opt/spark-3.5.1-bin-hadoop3/python/lib/py4j-0.10.9.7-src.zip/py4j/protocol.py", line 326, in get_return_value
	py4j.protocol.Py4JJavaError: An error occurred while calling o30.json.
	: org.apache.spark.SparkException: Job aborted due to stage failure: Master removed our application: KILLED
		at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)
		at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)
		at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)
		at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
		at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
		at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
		at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)
		at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)
		at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)
		at scala.Option.foreach(Option.scala:407)
		at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)
		at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)
		at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)
		at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)
		at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
		at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:989)
		at org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)
		at org.apache.spark.SparkContext.runJob(SparkContext.scala:2493)
		at org.apache.spark.sql.catalyst.json.JsonInferSchema.infer(JsonInferSchema.scala:120)
		at org.apache.spark.sql.execution.datasources.json.TextInputJsonDataSource$.$anonfun$inferFromDataset$5(JsonDataSource.scala:109)
		at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)
		at org.apache.spark.sql.execution.datasources.json.TextInputJsonDataSource$.inferFromDataset(JsonDataSource.scala:109)
		at org.apache.spark.sql.execution.datasources.json.TextInputJsonDataSource$.infer(JsonDataSource.scala:98)
		at org.apache.spark.sql.execution.datasources.json.JsonDataSource.inferSchema(JsonDataSource.scala:64)
		at org.apache.spark.sql.execution.datasources.json.JsonFileFormat.inferSchema(JsonFileFormat.scala:59)
		at org.apache.spark.sql.execution.datasources.DataSource.$anonfun$getOrInferFileFormatSchema$11(DataSource.scala:208)
		at scala.Option.orElse(Option.scala:447)
		at org.apache.spark.sql.execution.datasources.DataSource.getOrInferFileFormatSchema(DataSource.scala:205)
		at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:407)
		at org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)
		at org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)
		at scala.Option.getOrElse(Option.scala:189)
		at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)
		at org.apache.spark.sql.DataFrameReader.json(DataFrameReader.scala:362)
		at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
		at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
		at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
		at java.lang.reflect.Method.invoke(Method.java:498)
		at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
		at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
		at py4j.Gateway.invoke(Gateway.java:282)
		at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
		at py4j.commands.CallCommand.execute(CallCommand.java:79)
		at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
		at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
		at java.lang.Thread.run(Thread.java:750)
	
	24/04/23 10:55:08 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
[WI-0][TI-0] - [INFO] 2024-04-23 10:55:08.840 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9289468590402168 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:55:09.143 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:55:08 INFO ShutdownHookManager: Shutdown hook called
	24/04/23 10:55:08 INFO ShutdownHookManager: Deleting directory /tmp/spark-b7d84492-205c-4eaf-a387-6cd221906081/pyspark-e676787d-10dc-4653-9a6f-844c3ee691fb
	24/04/23 10:55:08 INFO MemoryStore: MemoryStore cleared
	24/04/23 10:55:08 INFO BlockManager: BlockManager stopped
	24/04/23 10:55:08 INFO ShutdownHookManager: Deleting directory /tmp/spark-7be09e11-9ea4-4c7b-848f-df936dceeebd
	24/04/23 10:55:08 INFO BlockManagerMaster: BlockManagerMaster stopped
	24/04/23 10:55:08 INFO ShutdownHookManager: Deleting directory /tmp/spark-b7d84492-205c-4eaf-a387-6cd221906081/userFiles-09f3bc54-c479-42eb-b309-d7bafa7a19f0
	24/04/23 10:55:08 INFO ShutdownHookManager: Deleting directory /tmp/spark-b7d84492-205c-4eaf-a387-6cd221906081
	24/04/23 10:55:08 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
[WI-489][TI-1139] - [INFO] 2024-04-23 10:55:09.145 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1139, processId:2597 ,exitStatusCode:1 ,processWaitForStatus:true ,processExitValue:1
[WI-489][TI-1139] - [INFO] 2024-04-23 10:55:09.145 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-489][TI-1139] - [INFO] 2024-04-23 10:55:09.145 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-489][TI-1139] - [INFO] 2024-04-23 10:55:09.145 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-489][TI-1139] - [INFO] 2024-04-23 10:55:09.145 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-489][TI-1139] - [INFO] 2024-04-23 10:55:09.173 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: FAILURE to master : 172.18.1.1:1234
[WI-489][TI-1139] - [INFO] 2024-04-23 10:55:09.174 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-489][TI-1139] - [INFO] 2024-04-23 10:55:09.174 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1139
[WI-489][TI-1139] - [INFO] 2024-04-23 10:55:09.179 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1139
[WI-489][TI-1139] - [INFO] 2024-04-23 10:55:09.179 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-1139] - [INFO] 2024-04-23 10:55:09.814 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1139, success=true)
[WI-0][TI-0] - [INFO] 2024-04-23 10:55:10.857 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7677053824362606 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:55:21.959 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7568493150684932 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:55:26.983 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8146067415730337 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:55:35.027 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7933884297520661 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:55:36.038 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.728021978021978 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:55:40.057 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7847025495750709 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:55:48.402 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1141, taskName=search for intake JSON files, firstSubmitTime=1713840948385, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.9:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=80, appIds=null, processInstanceId=489, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"processing"}], executorId=1, cmdTypeIfComplement=7, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":""}],"rawScript":"# find 1 raw file in the folder\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\n\n# check if raw_file_dir is empty, then set raw_file_dir to null\nif [ -z \"$raw_file_dir\" ]; then\n    raw_file_dir=null\nfi\n\necho \"#{setValue(raw_file_dir=${raw_file_dir})}\"","resourceList":[]}, environmentConfig=export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='search for intake JSON files'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240423'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1141'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13340113777664'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240423105548'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='processing'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='489'}, raw_file_dir=Property{prop='raw_file_dir', direct=OUT, type=VARCHAR, value='/local_storage/reddit/processing/386-20240422.json'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240422'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-489][TI-1141] - [INFO] 2024-04-23 10:55:48.404 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: search for intake JSON files to wait queue success
[WI-489][TI-1141] - [INFO] 2024-04-23 10:55:48.404 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-489][TI-1141] - [INFO] 2024-04-23 10:55:48.408 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-489][TI-1141] - [INFO] 2024-04-23 10:55:48.408 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-489][TI-1141] - [INFO] 2024-04-23 10:55:48.408 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-489][TI-1141] - [INFO] 2024-04-23 10:55:48.408 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713840948408
[WI-489][TI-1141] - [INFO] 2024-04-23 10:55:48.409 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 489_1141
[WI-489][TI-1141] - [INFO] 2024-04-23 10:55:48.409 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1141,
  "taskName" : "search for intake JSON files",
  "firstSubmitTime" : 1713840948385,
  "startTime" : 1713840948408,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.9:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240423/13201021801792/80/489/1141.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 80,
  "processInstanceId" : 489,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"processing\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 7,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[{\"prop\":\"raw_file_dir\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"\"}],\"rawScript\":\"# find 1 raw file in the folder\\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\\n\\n# check if raw_file_dir is empty, then set raw_file_dir to null\\nif [ -z \\\"$raw_file_dir\\\" ]; then\\n    raw_file_dir=null\\nfi\\n\\necho \\\"#{setValue(raw_file_dir=${raw_file_dir})}\\\"\",\"resourceList\":[]}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "search for intake JSON files"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1141"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13340113777664"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423105548"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "processing"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "489"
    },
    "raw_file_dir" : {
      "prop" : "raw_file_dir",
      "direct" : "OUT",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit/processing/386-20240422.json"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240422"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "489_1141",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"raw_file_dir\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"/local_storage/reddit/processing/386-20240422.json\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-489][TI-1141] - [INFO] 2024-04-23 10:55:48.410 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-489][TI-1141] - [INFO] 2024-04-23 10:55:48.410 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-489][TI-1141] - [INFO] 2024-04-23 10:55:48.410 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-489][TI-1141] - [INFO] 2024-04-23 10:55:48.419 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-489][TI-1141] - [INFO] 2024-04-23 10:55:48.421 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-489][TI-1141] - [INFO] 2024-04-23 10:55:48.422 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1141 check successfully
[WI-489][TI-1141] - [INFO] 2024-04-23 10:55:48.422 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-489][TI-1141] - [INFO] 2024-04-23 10:55:48.422 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-489][TI-1141] - [INFO] 2024-04-23 10:55:48.423 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-489][TI-1141] - [INFO] 2024-04-23 10:55:48.423 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-489][TI-1141] - [INFO] 2024-04-23 10:55:48.423 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ {
    "prop" : "raw_file_dir",
    "direct" : "OUT",
    "type" : "VARCHAR",
    "value" : ""
  } ],
  "varPool" : null,
  "rawScript" : "# find 1 raw file in the folder\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\n\n# check if raw_file_dir is empty, then set raw_file_dir to null\nif [ -z \"$raw_file_dir\" ]; then\n    raw_file_dir=null\nfi\n\necho \"#{setValue(raw_file_dir=${raw_file_dir})}\"",
  "resourceList" : [ ]
}
[WI-489][TI-1141] - [INFO] 2024-04-23 10:55:48.423 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-489][TI-1141] - [INFO] 2024-04-23 10:55:48.424 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}] successfully
[WI-489][TI-1141] - [INFO] 2024-04-23 10:55:48.424 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-489][TI-1141] - [INFO] 2024-04-23 10:55:48.424 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-489][TI-1141] - [INFO] 2024-04-23 10:55:48.424 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-489][TI-1141] - [INFO] 2024-04-23 10:55:48.425 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-489][TI-1141] - [INFO] 2024-04-23 10:55:48.425 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-489][TI-1141] - [INFO] 2024-04-23 10:55:48.425 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export PYTHON_LAUNCHER=/bin/python3.11
# find 1 raw file in the folder
raw_file_dir=$(find /local_storage/reddit/processing -type f -name '*.json'| head -n 1)

# check if raw_file_dir is empty, then set raw_file_dir to null
if [ -z "$raw_file_dir" ]; then
    raw_file_dir=null
fi

echo "#{setValue(raw_file_dir=/local_storage/reddit/processing/386-20240422.json)}"
[WI-489][TI-1141] - [INFO] 2024-04-23 10:55:48.425 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-489][TI-1141] - [INFO] 2024-04-23 10:55:48.425 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1141/489_1141.sh
[WI-489][TI-1141] - [INFO] 2024-04-23 10:55:48.448 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 3001
[WI-0][TI-1141] - [INFO] 2024-04-23 10:55:48.988 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1141, success=true)
[WI-0][TI-1141] - [INFO] 2024-04-23 10:55:48.997 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1141)
[WI-0][TI-0] - [INFO] 2024-04-23 10:55:49.121 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.744927536231884 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:55:49.450 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
	#{setValue(raw_file_dir=/local_storage/reddit/processing/386-20240422.json)}
[WI-489][TI-1141] - [INFO] 2024-04-23 10:55:49.457 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1141, processId:3001 ,exitStatusCode:0 ,processWaitForStatus:true ,processExitValue:0
[WI-489][TI-1141] - [INFO] 2024-04-23 10:55:49.459 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-489][TI-1141] - [INFO] 2024-04-23 10:55:49.459 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-489][TI-1141] - [INFO] 2024-04-23 10:55:49.459 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-489][TI-1141] - [INFO] 2024-04-23 10:55:49.460 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-489][TI-1141] - [INFO] 2024-04-23 10:55:49.473 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: SUCCESS to master : 172.18.1.1:1234
[WI-489][TI-1141] - [INFO] 2024-04-23 10:55:49.477 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-489][TI-1141] - [INFO] 2024-04-23 10:55:49.478 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1141
[WI-489][TI-1141] - [INFO] 2024-04-23 10:55:49.478 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1141
[WI-489][TI-1141] - [INFO] 2024-04-23 10:55:49.478 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-1141] - [INFO] 2024-04-23 10:55:49.999 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1141, success=true)
[WI-0][TI-0] - [INFO] 2024-04-23 10:55:50.141 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7774725274725274 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:55:51.144 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7594202898550724 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:55:51.155 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1143, taskName=move to processing, firstSubmitTime=1713840951143, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.9:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=80, appIds=null, processInstanceId=489, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"processing"}], executorId=1, cmdTypeIfComplement=7, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":""}],"rawScript":"# move file to the reddit processing folder\n# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error\nfilename=$(basename \"${raw_file_dir}\")\nif ! grep -q \"${REDDIT_HOME}/processing\" <<< \"${raw_file_dir}\"; then\n    mv ${raw_file_dir} ${REDDIT_HOME}/processing\nelse\n    echo JSON is already in processing\nfi\n\n# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing\necho \"#{setValue(raw_file_dir=${REDDIT_HOME}/processing/${filename})}\"","resourceList":[]}, environmentConfig=export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='move to processing'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240423'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1143'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13340390094208'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240423105551'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='processing'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='489'}, raw_file_dir=Property{prop='raw_file_dir', direct=IN, type=VARCHAR, value='/local_storage/reddit/processing/386-20240422.json'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240422'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-489][TI-1143] - [INFO] 2024-04-23 10:55:51.156 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: move to processing to wait queue success
[WI-489][TI-1143] - [INFO] 2024-04-23 10:55:51.157 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-489][TI-1143] - [INFO] 2024-04-23 10:55:51.158 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-489][TI-1143] - [INFO] 2024-04-23 10:55:51.158 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-489][TI-1143] - [INFO] 2024-04-23 10:55:51.158 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-489][TI-1143] - [INFO] 2024-04-23 10:55:51.158 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713840951158
[WI-489][TI-1143] - [INFO] 2024-04-23 10:55:51.158 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 489_1143
[WI-489][TI-1143] - [INFO] 2024-04-23 10:55:51.159 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1143,
  "taskName" : "move to processing",
  "firstSubmitTime" : 1713840951143,
  "startTime" : 1713840951158,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.9:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240423/13201021801792/80/489/1143.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 80,
  "processInstanceId" : 489,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"processing\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 7,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[{\"prop\":\"raw_file_dir\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"\"}],\"rawScript\":\"# move file to the reddit processing folder\\n# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error\\nfilename=$(basename \\\"${raw_file_dir}\\\")\\nif ! grep -q \\\"${REDDIT_HOME}/processing\\\" <<< \\\"${raw_file_dir}\\\"; then\\n    mv ${raw_file_dir} ${REDDIT_HOME}/processing\\nelse\\n    echo JSON is already in processing\\nfi\\n\\n# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing\\necho \\\"#{setValue(raw_file_dir=${REDDIT_HOME}/processing/${filename})}\\\"\",\"resourceList\":[]}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "move to processing"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1143"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13340390094208"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423105551"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "processing"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "489"
    },
    "raw_file_dir" : {
      "prop" : "raw_file_dir",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit/processing/386-20240422.json"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240422"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "489_1143",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"raw_file_dir\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"/local_storage/reddit/processing/386-20240422.json\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-489][TI-1143] - [INFO] 2024-04-23 10:55:51.159 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-489][TI-1143] - [INFO] 2024-04-23 10:55:51.159 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-489][TI-1143] - [INFO] 2024-04-23 10:55:51.159 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-489][TI-1143] - [INFO] 2024-04-23 10:55:51.175 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-489][TI-1143] - [INFO] 2024-04-23 10:55:51.184 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-489][TI-1143] - [INFO] 2024-04-23 10:55:51.189 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1143 check successfully
[WI-489][TI-1143] - [INFO] 2024-04-23 10:55:51.190 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-489][TI-1143] - [INFO] 2024-04-23 10:55:51.190 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-489][TI-1143] - [INFO] 2024-04-23 10:55:51.190 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-489][TI-1143] - [INFO] 2024-04-23 10:55:51.191 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-489][TI-1143] - [INFO] 2024-04-23 10:55:51.192 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ {
    "prop" : "raw_file_dir",
    "direct" : "OUT",
    "type" : "VARCHAR",
    "value" : ""
  } ],
  "varPool" : null,
  "rawScript" : "# move file to the reddit processing folder\n# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error\nfilename=$(basename \"${raw_file_dir}\")\nif ! grep -q \"${REDDIT_HOME}/processing\" <<< \"${raw_file_dir}\"; then\n    mv ${raw_file_dir} ${REDDIT_HOME}/processing\nelse\n    echo JSON is already in processing\nfi\n\n# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing\necho \"#{setValue(raw_file_dir=${REDDIT_HOME}/processing/${filename})}\"",
  "resourceList" : [ ]
}
[WI-489][TI-1143] - [INFO] 2024-04-23 10:55:51.192 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-489][TI-1143] - [INFO] 2024-04-23 10:55:51.192 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}] successfully
[WI-489][TI-1143] - [INFO] 2024-04-23 10:55:51.192 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-489][TI-1143] - [INFO] 2024-04-23 10:55:51.193 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-489][TI-1143] - [INFO] 2024-04-23 10:55:51.193 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-489][TI-1143] - [INFO] 2024-04-23 10:55:51.196 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-489][TI-1143] - [INFO] 2024-04-23 10:55:51.196 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-489][TI-1143] - [INFO] 2024-04-23 10:55:51.196 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export PYTHON_LAUNCHER=/bin/python3.11
# move file to the reddit processing folder
# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error
filename=$(basename "/local_storage/reddit/processing/386-20240422.json")
if ! grep -q "/local_storage/reddit/processing" <<< "/local_storage/reddit/processing/386-20240422.json"; then
    mv /local_storage/reddit/processing/386-20240422.json /local_storage/reddit/processing
else
    echo JSON is already in processing
fi

# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing
echo "#{setValue(raw_file_dir=/local_storage/reddit/processing/${filename})}"
[WI-489][TI-1143] - [INFO] 2024-04-23 10:55:51.197 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-489][TI-1143] - [INFO] 2024-04-23 10:55:51.197 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1143/489_1143.sh
[WI-489][TI-1143] - [INFO] 2024-04-23 10:55:51.201 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 3014
[WI-0][TI-1143] - [INFO] 2024-04-23 10:55:51.999 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1143, success=true)
[WI-0][TI-1143] - [INFO] 2024-04-23 10:55:52.004 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1143)
[WI-0][TI-0] - [INFO] 2024-04-23 10:55:52.144 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.87683284457478 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:55:52.206 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
	JSON is already in processing
	#{setValue(raw_file_dir=/local_storage/reddit/processing/386-20240422.json)}
[WI-489][TI-1143] - [INFO] 2024-04-23 10:55:52.208 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1143, processId:3014 ,exitStatusCode:0 ,processWaitForStatus:true ,processExitValue:0
[WI-489][TI-1143] - [INFO] 2024-04-23 10:55:52.211 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-489][TI-1143] - [INFO] 2024-04-23 10:55:52.211 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-489][TI-1143] - [INFO] 2024-04-23 10:55:52.211 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-489][TI-1143] - [INFO] 2024-04-23 10:55:52.211 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-489][TI-1143] - [INFO] 2024-04-23 10:55:52.232 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: SUCCESS to master : 172.18.1.1:1234
[WI-489][TI-1143] - [INFO] 2024-04-23 10:55:52.234 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-489][TI-1143] - [INFO] 2024-04-23 10:55:52.235 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1143
[WI-489][TI-1143] - [INFO] 2024-04-23 10:55:52.236 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1143
[WI-489][TI-1143] - [INFO] 2024-04-23 10:55:52.237 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-1143] - [INFO] 2024-04-23 10:55:52.997 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1143, success=true)
[WI-0][TI-0] - [INFO] 2024-04-23 10:55:53.082 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1144, taskName=spark preprocessing, firstSubmitTime=1713840953073, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.9:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=80, appIds=null, processInstanceId=489, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"processing"}], executorId=1, cmdTypeIfComplement=7, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[],"rawScript":"$SPARK_HOME/bin/spark-submit \\\n    --master spark://spark-master:7077 \\\n    --conf spark.driver.cores=2 \\\n    --conf spark.driver.memory=2G \\\n    --conf spark.executor.instances=1 \\\n    --conf spark.executor.cores=2 \\\n    --conf spark.executor.memory=2G \\\n    --files ${raw_file_dir} \\\n    --name reddit_preprocessing spark_reddit_preprocessing.py\n","resourceList":[{"id":null,"resourceName":"file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py","res":null}]}, environmentConfig=export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export HADOOP_CONF_DIR=/opt/hadoop-3.4.0/etc/hadoop
export PYSPARK_DRIVER_PYTHON=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='spark preprocessing'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240423'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1144'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13210058002752'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240423105553'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='processing'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='489'}, raw_file_dir=Property{prop='raw_file_dir', direct=IN, type=VARCHAR, value='/local_storage/reddit/processing/386-20240422.json'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240422'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-489][TI-1144] - [INFO] 2024-04-23 10:55:53.083 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: spark preprocessing to wait queue success
[WI-489][TI-1144] - [INFO] 2024-04-23 10:55:53.084 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-489][TI-1144] - [INFO] 2024-04-23 10:55:53.084 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-489][TI-1144] - [INFO] 2024-04-23 10:55:53.085 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-489][TI-1144] - [INFO] 2024-04-23 10:55:53.085 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-489][TI-1144] - [INFO] 2024-04-23 10:55:53.087 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713840953087
[WI-489][TI-1144] - [INFO] 2024-04-23 10:55:53.087 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 489_1144
[WI-489][TI-1144] - [INFO] 2024-04-23 10:55:53.088 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1144,
  "taskName" : "spark preprocessing",
  "firstSubmitTime" : 1713840953073,
  "startTime" : 1713840953087,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.9:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240423/13201021801792/80/489/1144.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 80,
  "processInstanceId" : 489,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"processing\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 7,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[],\"rawScript\":\"$SPARK_HOME/bin/spark-submit \\\\\\n    --master spark://spark-master:7077 \\\\\\n    --conf spark.driver.cores=2 \\\\\\n    --conf spark.driver.memory=2G \\\\\\n    --conf spark.executor.instances=1 \\\\\\n    --conf spark.executor.cores=2 \\\\\\n    --conf spark.executor.memory=2G \\\\\\n    --files ${raw_file_dir} \\\\\\n    --name reddit_preprocessing spark_reddit_preprocessing.py\\n\",\"resourceList\":[{\"id\":null,\"resourceName\":\"file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py\",\"res\":null}]}",
  "environmentConfig" : "export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3\nexport JAVA_HOME=/opt/java/openjdk\nexport HADOOP_CONF_DIR=/opt/hadoop-3.4.0/etc/hadoop\nexport PYSPARK_DRIVER_PYTHON=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "spark preprocessing"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1144"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13210058002752"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423105553"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "processing"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "489"
    },
    "raw_file_dir" : {
      "prop" : "raw_file_dir",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit/processing/386-20240422.json"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240422"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "489_1144",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"raw_file_dir\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"/local_storage/reddit/processing/386-20240422.json\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-489][TI-1144] - [INFO] 2024-04-23 10:55:53.090 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-489][TI-1144] - [INFO] 2024-04-23 10:55:53.090 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-489][TI-1144] - [INFO] 2024-04-23 10:55:53.090 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-489][TI-1144] - [INFO] 2024-04-23 10:55:53.093 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-489][TI-1144] - [INFO] 2024-04-23 10:55:53.094 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-489][TI-1144] - [INFO] 2024-04-23 10:55:53.095 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1144 check successfully
[WI-489][TI-1144] - [INFO] 2024-04-23 10:55:53.096 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-489][TI-1144] - [INFO] 2024-04-23 10:55:53.100 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py=ResourceContext.ResourceItem(resourceAbsolutePathInStorage=file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py, resourceRelativePath=spark_reddit_preprocessing.py, resourceAbsolutePathInLocal=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1144/spark_reddit_preprocessing.py)})
[WI-489][TI-1144] - [INFO] 2024-04-23 10:55:53.101 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-489][TI-1144] - [INFO] 2024-04-23 10:55:53.102 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-489][TI-1144] - [INFO] 2024-04-23 10:55:53.103 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ ],
  "varPool" : null,
  "rawScript" : "$SPARK_HOME/bin/spark-submit \\\n    --master spark://spark-master:7077 \\\n    --conf spark.driver.cores=2 \\\n    --conf spark.driver.memory=2G \\\n    --conf spark.executor.instances=1 \\\n    --conf spark.executor.cores=2 \\\n    --conf spark.executor.memory=2G \\\n    --files ${raw_file_dir} \\\n    --name reddit_preprocessing spark_reddit_preprocessing.py\n",
  "resourceList" : [ {
    "id" : null,
    "resourceName" : "file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py",
    "res" : null
  } ]
}
[WI-489][TI-1144] - [INFO] 2024-04-23 10:55:53.103 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-489][TI-1144] - [INFO] 2024-04-23 10:55:53.104 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}] successfully
[WI-489][TI-1144] - [INFO] 2024-04-23 10:55:53.104 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-489][TI-1144] - [INFO] 2024-04-23 10:55:53.105 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-489][TI-1144] - [INFO] 2024-04-23 10:55:53.112 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-489][TI-1144] - [INFO] 2024-04-23 10:55:53.113 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-489][TI-1144] - [INFO] 2024-04-23 10:55:53.114 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-489][TI-1144] - [INFO] 2024-04-23 10:55:53.115 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export HADOOP_CONF_DIR=/opt/hadoop-3.4.0/etc/hadoop
export PYSPARK_DRIVER_PYTHON=/bin/python3.11
$SPARK_HOME/bin/spark-submit \
    --master spark://spark-master:7077 \
    --conf spark.driver.cores=2 \
    --conf spark.driver.memory=2G \
    --conf spark.executor.instances=1 \
    --conf spark.executor.cores=2 \
    --conf spark.executor.memory=2G \
    --files /local_storage/reddit/processing/386-20240422.json \
    --name reddit_preprocessing spark_reddit_preprocessing.py

[WI-489][TI-1144] - [INFO] 2024-04-23 10:55:53.115 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-489][TI-1144] - [INFO] 2024-04-23 10:55:53.116 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1144/489_1144.sh
[WI-489][TI-1144] - [INFO] 2024-04-23 10:55:53.133 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 3026
[WI-0][TI-0] - [INFO] 2024-04-23 10:55:53.144 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
[WI-0][TI-1144] - [INFO] 2024-04-23 10:55:54.013 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1144, success=true)
[WI-0][TI-1144] - [INFO] 2024-04-23 10:55:54.027 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1144)
[WI-0][TI-0] - [INFO] 2024-04-23 10:55:54.176 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7089337175792508 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:55:55.195 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7275362318840579 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:55:56.171 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:55:55 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[WI-0][TI-0] - [INFO] 2024-04-23 10:55:57.171 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:55:56 INFO SparkContext: Running Spark version 3.5.1
	24/04/23 10:55:56 INFO SparkContext: OS info Linux, 6.5.0-28-generic, amd64
	24/04/23 10:55:56 INFO SparkContext: Java version 1.8.0_402
	24/04/23 10:55:56 INFO ResourceUtils: ==============================================================
	24/04/23 10:55:56 INFO ResourceUtils: No custom resources configured for spark.driver.
	24/04/23 10:55:56 INFO ResourceUtils: ==============================================================
	24/04/23 10:55:56 INFO SparkContext: Submitted application: reddit_preprocessing
	24/04/23 10:55:56 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 2, script: , vendor: , memory -> name: memory, amount: 2048, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
	24/04/23 10:55:56 INFO ResourceProfile: Limiting resource is cpus at 2 tasks per executor
	24/04/23 10:55:56 INFO ResourceProfileManager: Added ResourceProfile id: 0
	24/04/23 10:55:56 INFO SecurityManager: Changing view acls to: default
	24/04/23 10:55:56 INFO SecurityManager: Changing modify acls to: default
	24/04/23 10:55:56 INFO SecurityManager: Changing view acls groups to: 
	24/04/23 10:55:56 INFO SecurityManager: Changing modify acls groups to: 
	24/04/23 10:55:56 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: default; groups with view permissions: EMPTY; users with modify permissions: default; groups with modify permissions: EMPTY
[WI-0][TI-0] - [INFO] 2024-04-23 10:55:58.173 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:55:57 INFO Utils: Successfully started service 'sparkDriver' on port 46657.
	24/04/23 10:55:57 INFO SparkEnv: Registering MapOutputTracker
	24/04/23 10:55:57 INFO SparkEnv: Registering BlockManagerMaster
	24/04/23 10:55:57 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
	24/04/23 10:55:57 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
	24/04/23 10:55:57 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
	24/04/23 10:55:57 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-9ae63cee-5a65-49db-83cf-1fd21095c566
	24/04/23 10:55:57 INFO MemoryStore: MemoryStore started with capacity 912.3 MiB
	24/04/23 10:55:57 INFO SparkEnv: Registering OutputCommitCoordinator
	24/04/23 10:55:57 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
[WI-0][TI-0] - [INFO] 2024-04-23 10:55:58.210 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8952095808383234 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:55:59.177 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:55:58 INFO Utils: Successfully started service 'SparkUI' on port 4040.
	24/04/23 10:55:58 INFO SparkContext: Added file file:///local_storage/reddit/processing/386-20240422.json at spark://c0e814e3f0bd:46657/files/386-20240422.json with timestamp 1713840956536
	24/04/23 10:55:58 INFO Utils: Copying /local_storage/reddit/processing/386-20240422.json to /tmp/spark-b9c8f81e-1f6a-447c-870b-58daf5d79ca4/userFiles-3c078aa3-3e27-4b8f-92ca-262c24a5f2dd/386-20240422.json
	24/04/23 10:55:58 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
	24/04/23 10:55:58 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.3:7077 after 34 ms (0 ms spent in bootstraps)
	24/04/23 10:55:58 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20240423025558-0010
	24/04/23 10:55:58 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20240423025558-0010/0 on worker-20240423012857-172.18.0.7-41063 (172.18.0.7:41063) with 2 core(s)
	24/04/23 10:55:58 INFO StandaloneSchedulerBackend: Granted executor ID app-20240423025558-0010/0 on hostPort 172.18.0.7:41063 with 2 core(s), 2.0 GiB RAM
	24/04/23 10:55:58 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46105.
	24/04/23 10:55:58 INFO NettyBlockTransferService: Server created on c0e814e3f0bd:46105
	24/04/23 10:55:58 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
	24/04/23 10:55:58 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, c0e814e3f0bd, 46105, None)
	24/04/23 10:55:58 INFO BlockManagerMasterEndpoint: Registering block manager c0e814e3f0bd:46105 with 912.3 MiB RAM, BlockManagerId(driver, c0e814e3f0bd, 46105, None)
	24/04/23 10:55:58 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20240423025558-0010/0 is now RUNNING
	24/04/23 10:55:58 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, c0e814e3f0bd, 46105, None)
	24/04/23 10:55:58 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, c0e814e3f0bd, 46105, None)
[WI-0][TI-0] - [INFO] 2024-04-23 10:55:59.244 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7994428969359331 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:56:00.194 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:55:59 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
	
	
	
	 /tmp/spark-b9c8f81e-1f6a-447c-870b-58daf5d79ca4/userFiles-3c078aa3-3e27-4b8f-92ca-262c24a5f2dd/386-20240422.json 
	
	
	
[WI-0][TI-0] - [INFO] 2024-04-23 10:56:00.258 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9247648902821316 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:56:01.260 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9130434782608696 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:56:02.202 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:56:01 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 345.6 KiB, free 912.0 MiB)
	24/04/23 10:56:01 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.7 KiB, free 911.9 MiB)
	24/04/23 10:56:01 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on c0e814e3f0bd:46105 (size: 32.7 KiB, free: 912.3 MiB)
	24/04/23 10:56:01 INFO SparkContext: Created broadcast 0 from wholeTextFiles at NativeMethodAccessorImpl.java:0
	24/04/23 10:56:01 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
	24/04/23 10:56:01 INFO SharedState: Warehouse path is 'file:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1144/spark-warehouse'.
[WI-0][TI-0] - [INFO] 2024-04-23 10:56:02.269 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8724035608308606 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:56:03.270 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8270440251572326 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:56:04.213 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:56:03 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.7:60540) with ID 0,  ResourceProfileId 0
	24/04/23 10:56:03 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.7:39001 with 1048.8 MiB RAM, BlockManagerId(0, 172.18.0.7, 39001, None)
[WI-0][TI-0] - [INFO] 2024-04-23 10:56:07.219 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:56:07 INFO CodeGenerator: Code generated in 660.176121 ms
[WI-0][TI-0] - [INFO] 2024-04-23 10:56:07.290 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7713414634146342 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:56:08.228 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 10:56:07 INFO FileInputFormat: Total input files to process : 1
	24/04/23 10:56:07 INFO FileInputFormat: Total input files to process : 1
	24/04/23 10:56:07 INFO SparkContext: Starting job: json at NativeMethodAccessorImpl.java:0
	24/04/23 10:56:07 INFO DAGScheduler: Got job 0 (json at NativeMethodAccessorImpl.java:0) with 1 output partitions
	24/04/23 10:56:07 INFO DAGScheduler: Final stage: ResultStage 0 (json at NativeMethodAccessorImpl.java:0)
	24/04/23 10:56:07 INFO DAGScheduler: Parents of final stage: List()
	24/04/23 10:56:07 INFO DAGScheduler: Missing parents: List()
	24/04/23 10:56:07 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[7] at json at NativeMethodAccessorImpl.java:0), which has no missing parents
	24/04/23 10:56:07 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 23.5 KiB, free 911.9 MiB)
	24/04/23 10:56:07 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 11.5 KiB, free 911.9 MiB)
	24/04/23 10:56:07 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on c0e814e3f0bd:46105 (size: 11.5 KiB, free: 912.3 MiB)
	24/04/23 10:56:07 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1585
	24/04/23 10:56:07 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[7] at json at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
	24/04/23 10:56:07 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
	24/04/23 10:56:07 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.7, executor 0, partition 0, PROCESS_LOCAL, 8008 bytes) 
[WI-0][TI-0] - [INFO] 2024-04-23 10:56:33.410 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7927170868347339 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:56:38.470 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7147058823529412 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:56:45.544 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8405405405405405 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:56:52.640 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7670454545454546 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 10:56:53.670 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7111111111111111 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-1123] - [INFO] 2024-04-23 10:59:48.118 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1123, processInstanceId=487, status=9, startTime=1713838208504, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1123.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1123, endTime=1713838483436, processId=1677, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713840887903)
[WI-0][TI-1123] - [INFO] 2024-04-23 10:59:48.128 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1123, processInstanceId=487, status=9, startTime=1713838208504, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1123.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1123, endTime=1713838483436, processId=1677, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713841188118)
[WI-0][TI-1111] - [INFO] 2024-04-23 10:59:50.130 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1111, processInstanceId=487, status=9, startTime=1713837256404, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1111.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1111, endTime=1713838170352, processId=1017, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713840889910)
[WI-0][TI-1111] - [INFO] 2024-04-23 10:59:50.138 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1111, processInstanceId=487, status=9, startTime=1713837256404, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1111.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1111, endTime=1713838170352, processId=1017, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713841190130)
