[WI-0][TI-0] - [INFO] 2024-04-23 11:02:05.891 +0800 o.a.d.s.w.r.o.TaskInstanceKillOperationFunction:[55] - Receive TaskInstanceKillRequest: TaskInstanceKillRequest(taskInstanceId=1144)
[WI-0][TI-1144] - [ERROR] 2024-04-23 11:02:05.912 +0800 o.a.d.s.w.r.o.TaskInstanceKillOperationFunction:[139] - kill task error
java.io.IOException: Cannot run program "pstree": error=2, No such file or directory
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1048)
	at org.apache.dolphinscheduler.common.shell.AbstractShell.runCommand(AbstractShell.java:138)
	at org.apache.dolphinscheduler.common.shell.AbstractShell.run(AbstractShell.java:118)
	at org.apache.dolphinscheduler.common.shell.ShellExecutor.execute(ShellExecutor.java:125)
	at org.apache.dolphinscheduler.common.shell.ShellExecutor.execCommand(ShellExecutor.java:103)
	at org.apache.dolphinscheduler.common.shell.ShellExecutor.execCommand(ShellExecutor.java:86)
	at org.apache.dolphinscheduler.common.utils.OSUtils.exeShell(OSUtils.java:345)
	at org.apache.dolphinscheduler.common.utils.OSUtils.exeCmd(OSUtils.java:334)
	at org.apache.dolphinscheduler.plugin.task.api.utils.ProcessUtils.getPidsStr(ProcessUtils.java:129)
	at org.apache.dolphinscheduler.server.worker.runner.operator.TaskInstanceKillOperationFunction.killProcess(TaskInstanceKillOperationFunction.java:130)
	at org.apache.dolphinscheduler.server.worker.runner.operator.TaskInstanceKillOperationFunction.doKill(TaskInstanceKillOperationFunction.java:96)
	at org.apache.dolphinscheduler.server.worker.runner.operator.TaskInstanceKillOperationFunction.operate(TaskInstanceKillOperationFunction.java:69)
	at org.apache.dolphinscheduler.server.worker.rpc.TaskInstanceOperatorImpl.killTask(TaskInstanceOperatorImpl.java:49)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.dolphinscheduler.extract.base.server.ServerMethodInvokerImpl.invoke(ServerMethodInvokerImpl.java:41)
	at org.apache.dolphinscheduler.extract.base.server.JdkDynamicServerHandler.lambda$processReceived$0(JdkDynamicServerHandler.java:108)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.io.IOException: error=2, No such file or directory
	at java.lang.UNIXProcess.forkAndExec(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:247)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	... 21 common frames omitted
[WI-0][TI-1144] - [INFO] 2024-04-23 11:02:05.913 +0800 o.a.d.p.t.a.u.ProcessUtils:[182] - Get appIds from worker 172.18.1.1:1234, taskLogPath: /opt/dolphinscheduler/logs/20240423/13201021801792/80/489/1144.log
[WI-0][TI-1144] - [INFO] 2024-04-23 11:02:05.913 +0800 o.a.d.p.t.a.u.LogUtils:[79] - Start finding appId in /opt/dolphinscheduler/logs/20240423/13201021801792/80/489/1144.log, fetch way: log 
[WI-0][TI-1144] - [INFO] 2024-04-23 11:02:05.913 +0800 o.a.d.p.t.a.u.ProcessUtils:[188] - The appId is empty
[WI-0][TI-1144] - [INFO] 2024-04-23 11:02:05.914 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[220] - Begin to kill process process, pid is : 3026
[WI-0][TI-0] - [INFO] 2024-04-23 11:02:06.736 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8137535816618912 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-1144] - [INFO] 2024-04-23 11:02:10.916 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[225] - Success kill task: 489_1144, pid: 3026
[WI-0][TI-1144] - [INFO] 2024-04-23 11:02:10.917 +0800 o.a.d.s.w.r.o.TaskInstanceKillOperationFunction:[119] - kill task by cancelApplication, taskInstanceId: 1144
[WI-0][TI-0] - [ERROR] 2024-04-23 11:02:11.182 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[279] - Parse var pool error
java.io.IOException: Stream closed
	at java.io.BufferedInputStream.getBufIfOpen(BufferedInputStream.java:170)
	at java.io.BufferedInputStream.read1(BufferedInputStream.java:283)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:345)
	at sun.nio.cs.StreamDecoder.readBytes(StreamDecoder.java:284)
	at sun.nio.cs.StreamDecoder.implRead(StreamDecoder.java:326)
	at sun.nio.cs.StreamDecoder.read(StreamDecoder.java:178)
	at java.io.InputStreamReader.read(InputStreamReader.java:184)
	at java.io.BufferedReader.fill(BufferedReader.java:161)
	at java.io.BufferedReader.readLine(BufferedReader.java:324)
	at java.io.BufferedReader.readLine(BufferedReader.java:389)
	at org.apache.dolphinscheduler.plugin.task.api.AbstractCommandExecutor.lambda$parseProcessOutput$1(AbstractCommandExecutor.java:273)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
[WI-489][TI-1144] - [INFO] 2024-04-23 11:02:11.354 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has killed. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1144, processId:3026 ,exitStatusCode:137 ,processWaitForStatus:true ,processExitValue:137
[WI-489][TI-1144] - [INFO] 2024-04-23 11:02:11.355 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-489][TI-1144] - [INFO] 2024-04-23 11:02:11.355 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-489][TI-1144] - [INFO] 2024-04-23 11:02:11.355 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-489][TI-1144] - [INFO] 2024-04-23 11:02:11.356 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-489][TI-1144] - [INFO] 2024-04-23 11:02:11.367 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: KILL to master : 172.18.1.1:1234
[WI-489][TI-1144] - [INFO] 2024-04-23 11:02:11.368 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-489][TI-1144] - [INFO] 2024-04-23 11:02:11.368 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1144
[WI-489][TI-1144] - [INFO] 2024-04-23 11:02:11.369 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1144
[WI-489][TI-1144] - [INFO] 2024-04-23 11:02:11.369 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-0] - [INFO] 2024-04-23 11:02:11.767 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7340425531914895 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-1144] - [INFO] 2024-04-23 11:02:12.362 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1144, processInstanceId=489, status=9, startTime=1713840953087, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/80/489/1144.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1144, endTime=1713841331355, processId=3026, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1144] - [INFO] 2024-04-23 11:02:12.365 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1144, processInstanceId=489, status=9, startTime=1713840953087, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/80/489/1144.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1144, endTime=1713841331355, processId=3026, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713841332349)
[WI-0][TI-0] - [INFO] 2024-04-23 11:02:12.789 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8272980501392758 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:02:57.988 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1145, taskName=search for intake JSON files, firstSubmitTime=1713841377961, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.9:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=80, appIds=null, processInstanceId=490, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"processing"}], executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":""}],"rawScript":"# find 1 raw file in the folder\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\n\n# check if raw_file_dir is empty, then set raw_file_dir to null\nif [ -z \"$raw_file_dir\" ]; then\n    raw_file_dir=null\nfi\n\necho \"#{setValue(raw_file_dir=${raw_file_dir})}\"","resourceList":[]}, environmentConfig=export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='search for intake JSON files'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240423'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1145'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13340113777664'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240423110257'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='processing'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='490'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240422'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=null, dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-490][TI-1145] - [INFO] 2024-04-23 11:02:57.989 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: search for intake JSON files to wait queue success
[WI-490][TI-1145] - [INFO] 2024-04-23 11:02:57.990 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-490][TI-1145] - [INFO] 2024-04-23 11:02:57.991 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-490][TI-1145] - [INFO] 2024-04-23 11:02:57.991 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-490][TI-1145] - [INFO] 2024-04-23 11:02:57.991 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-490][TI-1145] - [INFO] 2024-04-23 11:02:57.991 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713841377991
[WI-490][TI-1145] - [INFO] 2024-04-23 11:02:57.992 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 490_1145
[WI-490][TI-1145] - [INFO] 2024-04-23 11:02:57.992 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1145,
  "taskName" : "search for intake JSON files",
  "firstSubmitTime" : 1713841377961,
  "startTime" : 1713841377991,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.9:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240423/13201021801792/80/490/1145.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 80,
  "processInstanceId" : 490,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"processing\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[{\"prop\":\"raw_file_dir\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"\"}],\"rawScript\":\"# find 1 raw file in the folder\\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\\n\\n# check if raw_file_dir is empty, then set raw_file_dir to null\\nif [ -z \\\"$raw_file_dir\\\" ]; then\\n    raw_file_dir=null\\nfi\\n\\necho \\\"#{setValue(raw_file_dir=${raw_file_dir})}\\\"\",\"resourceList\":[]}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "search for intake JSON files"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1145"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13340113777664"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423110257"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "processing"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "490"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240422"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "490_1145",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-490][TI-1145] - [INFO] 2024-04-23 11:02:57.993 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-490][TI-1145] - [INFO] 2024-04-23 11:02:57.993 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-490][TI-1145] - [INFO] 2024-04-23 11:02:57.993 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-490][TI-1145] - [INFO] 2024-04-23 11:02:57.995 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-490][TI-1145] - [INFO] 2024-04-23 11:02:57.996 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-490][TI-1145] - [INFO] 2024-04-23 11:02:57.996 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/490/1145 check successfully
[WI-490][TI-1145] - [INFO] 2024-04-23 11:02:57.996 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-490][TI-1145] - [INFO] 2024-04-23 11:02:57.997 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-490][TI-1145] - [INFO] 2024-04-23 11:02:57.997 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-490][TI-1145] - [INFO] 2024-04-23 11:02:57.997 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-490][TI-1145] - [INFO] 2024-04-23 11:02:57.997 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ {
    "prop" : "raw_file_dir",
    "direct" : "OUT",
    "type" : "VARCHAR",
    "value" : ""
  } ],
  "varPool" : null,
  "rawScript" : "# find 1 raw file in the folder\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\n\n# check if raw_file_dir is empty, then set raw_file_dir to null\nif [ -z \"$raw_file_dir\" ]; then\n    raw_file_dir=null\nfi\n\necho \"#{setValue(raw_file_dir=${raw_file_dir})}\"",
  "resourceList" : [ ]
}
[WI-490][TI-1145] - [INFO] 2024-04-23 11:02:57.997 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-490][TI-1145] - [INFO] 2024-04-23 11:02:57.997 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: null successfully
[WI-490][TI-1145] - [INFO] 2024-04-23 11:02:57.997 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-490][TI-1145] - [INFO] 2024-04-23 11:02:57.997 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-490][TI-1145] - [INFO] 2024-04-23 11:02:57.998 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-490][TI-1145] - [INFO] 2024-04-23 11:02:57.998 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-490][TI-1145] - [INFO] 2024-04-23 11:02:57.998 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-490][TI-1145] - [INFO] 2024-04-23 11:02:57.998 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export PYTHON_LAUNCHER=/bin/python3.11
# find 1 raw file in the folder
raw_file_dir=$(find /local_storage/reddit/processing -type f -name '*.json'| head -n 1)

# check if raw_file_dir is empty, then set raw_file_dir to null
if [ -z "$raw_file_dir" ]; then
    raw_file_dir=null
fi

echo "#{setValue(raw_file_dir=${raw_file_dir})}"
[WI-490][TI-1145] - [INFO] 2024-04-23 11:02:57.999 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-490][TI-1145] - [INFO] 2024-04-23 11:02:57.999 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/490/1145/490_1145.sh
[WI-490][TI-1145] - [INFO] 2024-04-23 11:02:58.006 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 3247
[WI-0][TI-1145] - [INFO] 2024-04-23 11:02:58.431 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1145, success=true)
[WI-0][TI-1145] - [INFO] 2024-04-23 11:02:58.435 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1145)
[WI-0][TI-0] - [INFO] 2024-04-23 11:02:59.006 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
	#{setValue(raw_file_dir=/local_storage/reddit/processing/386-20240422.json)}
[WI-490][TI-1145] - [INFO] 2024-04-23 11:02:59.008 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/490/1145, processId:3247 ,exitStatusCode:0 ,processWaitForStatus:true ,processExitValue:0
[WI-490][TI-1145] - [INFO] 2024-04-23 11:02:59.008 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-490][TI-1145] - [INFO] 2024-04-23 11:02:59.009 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-490][TI-1145] - [INFO] 2024-04-23 11:02:59.009 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-490][TI-1145] - [INFO] 2024-04-23 11:02:59.010 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-490][TI-1145] - [INFO] 2024-04-23 11:02:59.015 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: SUCCESS to master : 172.18.1.1:1234
[WI-490][TI-1145] - [INFO] 2024-04-23 11:02:59.016 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-490][TI-1145] - [INFO] 2024-04-23 11:02:59.016 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/490/1145
[WI-490][TI-1145] - [INFO] 2024-04-23 11:02:59.018 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/490/1145
[WI-490][TI-1145] - [INFO] 2024-04-23 11:02:59.019 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-1145] - [INFO] 2024-04-23 11:02:59.437 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1145, success=true)
[WI-0][TI-0] - [INFO] 2024-04-23 11:03:00.579 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1147, taskName=move to processing, firstSubmitTime=1713841380563, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.9:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=80, appIds=null, processInstanceId=490, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"processing"}], executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":""}],"rawScript":"# move file to the reddit processing folder\n# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error\nfilename=$(basename \"${raw_file_dir}\")\nif ! grep -q \"${REDDIT_HOME}/processing\" <<< \"${raw_file_dir}\"; then\n    mv ${raw_file_dir} ${REDDIT_HOME}/processing\nelse\n    echo JSON is already in processing\nfi\n\n# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing\necho \"#{setValue(raw_file_dir=${REDDIT_HOME}/processing/${filename})}\"","resourceList":[]}, environmentConfig=export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='move to processing'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240423'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1147'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13340390094208'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240423110300'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='processing'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='490'}, raw_file_dir=Property{prop='raw_file_dir', direct=IN, type=VARCHAR, value='/local_storage/reddit/processing/386-20240422.json'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240422'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-490][TI-1147] - [INFO] 2024-04-23 11:03:00.581 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: move to processing to wait queue success
[WI-490][TI-1147] - [INFO] 2024-04-23 11:03:00.581 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-490][TI-1147] - [INFO] 2024-04-23 11:03:00.583 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-490][TI-1147] - [INFO] 2024-04-23 11:03:00.583 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-490][TI-1147] - [INFO] 2024-04-23 11:03:00.583 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-490][TI-1147] - [INFO] 2024-04-23 11:03:00.583 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713841380583
[WI-490][TI-1147] - [INFO] 2024-04-23 11:03:00.583 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 490_1147
[WI-490][TI-1147] - [INFO] 2024-04-23 11:03:00.583 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1147,
  "taskName" : "move to processing",
  "firstSubmitTime" : 1713841380563,
  "startTime" : 1713841380583,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.9:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240423/13201021801792/80/490/1147.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 80,
  "processInstanceId" : 490,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"processing\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[{\"prop\":\"raw_file_dir\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"\"}],\"rawScript\":\"# move file to the reddit processing folder\\n# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error\\nfilename=$(basename \\\"${raw_file_dir}\\\")\\nif ! grep -q \\\"${REDDIT_HOME}/processing\\\" <<< \\\"${raw_file_dir}\\\"; then\\n    mv ${raw_file_dir} ${REDDIT_HOME}/processing\\nelse\\n    echo JSON is already in processing\\nfi\\n\\n# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing\\necho \\\"#{setValue(raw_file_dir=${REDDIT_HOME}/processing/${filename})}\\\"\",\"resourceList\":[]}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "move to processing"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1147"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13340390094208"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423110300"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "processing"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "490"
    },
    "raw_file_dir" : {
      "prop" : "raw_file_dir",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit/processing/386-20240422.json"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240422"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "490_1147",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"raw_file_dir\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"/local_storage/reddit/processing/386-20240422.json\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-490][TI-1147] - [INFO] 2024-04-23 11:03:00.584 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-490][TI-1147] - [INFO] 2024-04-23 11:03:00.584 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-490][TI-1147] - [INFO] 2024-04-23 11:03:00.584 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-490][TI-1147] - [INFO] 2024-04-23 11:03:00.585 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-490][TI-1147] - [INFO] 2024-04-23 11:03:00.585 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-490][TI-1147] - [INFO] 2024-04-23 11:03:00.587 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/490/1147 check successfully
[WI-490][TI-1147] - [INFO] 2024-04-23 11:03:00.587 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-490][TI-1147] - [INFO] 2024-04-23 11:03:00.587 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-490][TI-1147] - [INFO] 2024-04-23 11:03:00.587 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-490][TI-1147] - [INFO] 2024-04-23 11:03:00.587 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-490][TI-1147] - [INFO] 2024-04-23 11:03:00.588 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ {
    "prop" : "raw_file_dir",
    "direct" : "OUT",
    "type" : "VARCHAR",
    "value" : ""
  } ],
  "varPool" : null,
  "rawScript" : "# move file to the reddit processing folder\n# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error\nfilename=$(basename \"${raw_file_dir}\")\nif ! grep -q \"${REDDIT_HOME}/processing\" <<< \"${raw_file_dir}\"; then\n    mv ${raw_file_dir} ${REDDIT_HOME}/processing\nelse\n    echo JSON is already in processing\nfi\n\n# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing\necho \"#{setValue(raw_file_dir=${REDDIT_HOME}/processing/${filename})}\"",
  "resourceList" : [ ]
}
[WI-490][TI-1147] - [INFO] 2024-04-23 11:03:00.588 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-490][TI-1147] - [INFO] 2024-04-23 11:03:00.588 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}] successfully
[WI-490][TI-1147] - [INFO] 2024-04-23 11:03:00.588 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-490][TI-1147] - [INFO] 2024-04-23 11:03:00.588 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-490][TI-1147] - [INFO] 2024-04-23 11:03:00.588 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-490][TI-1147] - [INFO] 2024-04-23 11:03:00.588 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-490][TI-1147] - [INFO] 2024-04-23 11:03:00.588 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-490][TI-1147] - [INFO] 2024-04-23 11:03:00.589 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export PYTHON_LAUNCHER=/bin/python3.11
# move file to the reddit processing folder
# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error
filename=$(basename "/local_storage/reddit/processing/386-20240422.json")
if ! grep -q "/local_storage/reddit/processing" <<< "/local_storage/reddit/processing/386-20240422.json"; then
    mv /local_storage/reddit/processing/386-20240422.json /local_storage/reddit/processing
else
    echo JSON is already in processing
fi

# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing
echo "#{setValue(raw_file_dir=/local_storage/reddit/processing/${filename})}"
[WI-490][TI-1147] - [INFO] 2024-04-23 11:03:00.589 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-490][TI-1147] - [INFO] 2024-04-23 11:03:00.595 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/490/1147/490_1147.sh
[WI-490][TI-1147] - [INFO] 2024-04-23 11:03:00.604 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 3260
[WI-0][TI-1147] - [INFO] 2024-04-23 11:03:01.446 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1147, success=true)
[WI-0][TI-1147] - [INFO] 2024-04-23 11:03:01.453 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1147)
[WI-0][TI-0] - [INFO] 2024-04-23 11:03:01.607 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
	JSON is already in processing
	#{setValue(raw_file_dir=/local_storage/reddit/processing/386-20240422.json)}
[WI-490][TI-1147] - [INFO] 2024-04-23 11:03:01.612 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/490/1147, processId:3260 ,exitStatusCode:0 ,processWaitForStatus:true ,processExitValue:0
[WI-490][TI-1147] - [INFO] 2024-04-23 11:03:01.614 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-490][TI-1147] - [INFO] 2024-04-23 11:03:01.614 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-490][TI-1147] - [INFO] 2024-04-23 11:03:01.615 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-490][TI-1147] - [INFO] 2024-04-23 11:03:01.615 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-490][TI-1147] - [INFO] 2024-04-23 11:03:01.618 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: SUCCESS to master : 172.18.1.1:1234
[WI-490][TI-1147] - [INFO] 2024-04-23 11:03:01.618 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-490][TI-1147] - [INFO] 2024-04-23 11:03:01.618 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/490/1147
[WI-490][TI-1147] - [INFO] 2024-04-23 11:03:01.619 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/490/1147
[WI-490][TI-1147] - [INFO] 2024-04-23 11:03:01.619 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-1147] - [INFO] 2024-04-23 11:03:02.459 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1147, success=true)
[WI-0][TI-0] - [INFO] 2024-04-23 11:03:02.516 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1148, taskName=spark preprocessing, firstSubmitTime=1713841382498, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.9:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=80, appIds=null, processInstanceId=490, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"processing"}], executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[],"rawScript":"$SPARK_HOME/bin/spark-submit \\\n    --master spark://spark-master:7077 \\\n    --conf spark.driver.cores=2 \\\n    --conf spark.driver.memory=2G \\\n    --conf spark.executor.instances=1 \\\n    --conf spark.executor.cores=2 \\\n    --conf spark.executor.memory=2G \\\n    --files ${raw_file_dir} \\\n    --name reddit_preprocessing spark_reddit_preprocessing.py\n","resourceList":[{"id":null,"resourceName":"file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py","res":null}]}, environmentConfig=export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export HADOOP_CONF_DIR=/opt/hadoop-3.4.0/etc/hadoop
export PYSPARK_DRIVER_PYTHON=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='spark preprocessing'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240423'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1148'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13210058002752'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240423110302'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='processing'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='490'}, raw_file_dir=Property{prop='raw_file_dir', direct=IN, type=VARCHAR, value='/local_storage/reddit/processing/386-20240422.json'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240422'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-490][TI-1148] - [INFO] 2024-04-23 11:03:02.519 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: spark preprocessing to wait queue success
[WI-490][TI-1148] - [INFO] 2024-04-23 11:03:02.520 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-490][TI-1148] - [INFO] 2024-04-23 11:03:02.522 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-490][TI-1148] - [INFO] 2024-04-23 11:03:02.522 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-490][TI-1148] - [INFO] 2024-04-23 11:03:02.522 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-490][TI-1148] - [INFO] 2024-04-23 11:03:02.522 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713841382522
[WI-490][TI-1148] - [INFO] 2024-04-23 11:03:02.522 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 490_1148
[WI-490][TI-1148] - [INFO] 2024-04-23 11:03:02.522 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1148,
  "taskName" : "spark preprocessing",
  "firstSubmitTime" : 1713841382498,
  "startTime" : 1713841382522,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.9:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240423/13201021801792/80/490/1148.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 80,
  "processInstanceId" : 490,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"processing\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[],\"rawScript\":\"$SPARK_HOME/bin/spark-submit \\\\\\n    --master spark://spark-master:7077 \\\\\\n    --conf spark.driver.cores=2 \\\\\\n    --conf spark.driver.memory=2G \\\\\\n    --conf spark.executor.instances=1 \\\\\\n    --conf spark.executor.cores=2 \\\\\\n    --conf spark.executor.memory=2G \\\\\\n    --files ${raw_file_dir} \\\\\\n    --name reddit_preprocessing spark_reddit_preprocessing.py\\n\",\"resourceList\":[{\"id\":null,\"resourceName\":\"file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py\",\"res\":null}]}",
  "environmentConfig" : "export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3\nexport JAVA_HOME=/opt/java/openjdk\nexport HADOOP_CONF_DIR=/opt/hadoop-3.4.0/etc/hadoop\nexport PYSPARK_DRIVER_PYTHON=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "spark preprocessing"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1148"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13210058002752"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423110302"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "processing"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "490"
    },
    "raw_file_dir" : {
      "prop" : "raw_file_dir",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit/processing/386-20240422.json"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240422"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "490_1148",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"raw_file_dir\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"/local_storage/reddit/processing/386-20240422.json\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-490][TI-1148] - [INFO] 2024-04-23 11:03:02.523 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-490][TI-1148] - [INFO] 2024-04-23 11:03:02.523 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-490][TI-1148] - [INFO] 2024-04-23 11:03:02.523 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-490][TI-1148] - [INFO] 2024-04-23 11:03:02.527 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-490][TI-1148] - [INFO] 2024-04-23 11:03:02.527 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-490][TI-1148] - [INFO] 2024-04-23 11:03:02.528 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/490/1148 check successfully
[WI-490][TI-1148] - [INFO] 2024-04-23 11:03:02.528 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-490][TI-1148] - [INFO] 2024-04-23 11:03:02.530 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py=ResourceContext.ResourceItem(resourceAbsolutePathInStorage=file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py, resourceRelativePath=spark_reddit_preprocessing.py, resourceAbsolutePathInLocal=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/490/1148/spark_reddit_preprocessing.py)})
[WI-490][TI-1148] - [INFO] 2024-04-23 11:03:02.532 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-490][TI-1148] - [INFO] 2024-04-23 11:03:02.533 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-490][TI-1148] - [INFO] 2024-04-23 11:03:02.533 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ ],
  "varPool" : null,
  "rawScript" : "$SPARK_HOME/bin/spark-submit \\\n    --master spark://spark-master:7077 \\\n    --conf spark.driver.cores=2 \\\n    --conf spark.driver.memory=2G \\\n    --conf spark.executor.instances=1 \\\n    --conf spark.executor.cores=2 \\\n    --conf spark.executor.memory=2G \\\n    --files ${raw_file_dir} \\\n    --name reddit_preprocessing spark_reddit_preprocessing.py\n",
  "resourceList" : [ {
    "id" : null,
    "resourceName" : "file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py",
    "res" : null
  } ]
}
[WI-490][TI-1148] - [INFO] 2024-04-23 11:03:02.536 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-490][TI-1148] - [INFO] 2024-04-23 11:03:02.537 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}] successfully
[WI-490][TI-1148] - [INFO] 2024-04-23 11:03:02.538 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-490][TI-1148] - [INFO] 2024-04-23 11:03:02.539 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-490][TI-1148] - [INFO] 2024-04-23 11:03:02.539 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-490][TI-1148] - [INFO] 2024-04-23 11:03:02.540 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-490][TI-1148] - [INFO] 2024-04-23 11:03:02.541 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-490][TI-1148] - [INFO] 2024-04-23 11:03:02.541 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export HADOOP_CONF_DIR=/opt/hadoop-3.4.0/etc/hadoop
export PYSPARK_DRIVER_PYTHON=/bin/python3.11
$SPARK_HOME/bin/spark-submit \
    --master spark://spark-master:7077 \
    --conf spark.driver.cores=2 \
    --conf spark.driver.memory=2G \
    --conf spark.executor.instances=1 \
    --conf spark.executor.cores=2 \
    --conf spark.executor.memory=2G \
    --files /local_storage/reddit/processing/386-20240422.json \
    --name reddit_preprocessing spark_reddit_preprocessing.py

[WI-490][TI-1148] - [INFO] 2024-04-23 11:03:02.541 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-490][TI-1148] - [INFO] 2024-04-23 11:03:02.542 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/490/1148/490_1148.sh
[WI-490][TI-1148] - [INFO] 2024-04-23 11:03:02.551 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 3272
[WI-0][TI-1148] - [INFO] 2024-04-23 11:03:03.463 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionRunningEvent(taskInstanceId=1148, processInstanceId=490, startTime=1713841382522, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, status=TaskExecutionStatus{code=1, desc='running'}, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/80/490/1148.log, executePath=null, processId=0, appIds=null, eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1148] - [INFO] 2024-04-23 11:03:03.465 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1148, success=true)
[WI-0][TI-1148] - [INFO] 2024-04-23 11:03:03.469 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionRunningEvent(taskInstanceId=1148, processInstanceId=490, startTime=1713841382522, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, status=TaskExecutionStatus{code=1, desc='running'}, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/80/490/1148.log, executePath=null, processId=0, appIds=null, eventCreateTime=0, eventSendTime=1713841383463)
[WI-0][TI-1148] - [INFO] 2024-04-23 11:03:03.472 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1148)
[WI-0][TI-1148] - [INFO] 2024-04-23 11:03:03.478 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1148, success=true)
[WI-0][TI-0] - [INFO] 2024-04-23 11:03:03.553 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
[WI-0][TI-0] - [INFO] 2024-04-23 11:03:05.591 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:03:04 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[WI-0][TI-0] - [INFO] 2024-04-23 11:03:06.599 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:03:05 INFO SparkContext: Running Spark version 3.5.1
	24/04/23 11:03:05 INFO SparkContext: OS info Linux, 6.5.0-28-generic, amd64
	24/04/23 11:03:05 INFO SparkContext: Java version 1.8.0_402
	24/04/23 11:03:05 INFO ResourceUtils: ==============================================================
	24/04/23 11:03:05 INFO ResourceUtils: No custom resources configured for spark.driver.
	24/04/23 11:03:05 INFO ResourceUtils: ==============================================================
	24/04/23 11:03:05 INFO SparkContext: Submitted application: reddit_preprocessing
	24/04/23 11:03:05 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 2, script: , vendor: , memory -> name: memory, amount: 2048, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
	24/04/23 11:03:05 INFO ResourceProfile: Limiting resource is cpus at 2 tasks per executor
	24/04/23 11:03:05 INFO ResourceProfileManager: Added ResourceProfile id: 0
	24/04/23 11:03:05 INFO SecurityManager: Changing view acls to: default
	24/04/23 11:03:05 INFO SecurityManager: Changing modify acls to: default
	24/04/23 11:03:05 INFO SecurityManager: Changing view acls groups to: 
	24/04/23 11:03:05 INFO SecurityManager: Changing modify acls groups to: 
	24/04/23 11:03:05 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: default; groups with view permissions: EMPTY; users with modify permissions: default; groups with modify permissions: EMPTY
	24/04/23 11:03:06 INFO Utils: Successfully started service 'sparkDriver' on port 36795.
	24/04/23 11:03:06 INFO SparkEnv: Registering MapOutputTracker
	24/04/23 11:03:06 INFO SparkEnv: Registering BlockManagerMaster
	24/04/23 11:03:06 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
	24/04/23 11:03:06 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
	24/04/23 11:03:06 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
[WI-0][TI-0] - [INFO] 2024-04-23 11:03:06.971 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8414985590778098 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:03:07.599 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:03:06 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-61d84acc-6e84-41c7-b27a-49fef7570e29
	24/04/23 11:03:06 INFO MemoryStore: MemoryStore started with capacity 912.3 MiB
	24/04/23 11:03:06 INFO SparkEnv: Registering OutputCommitCoordinator
	24/04/23 11:03:06 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
	24/04/23 11:03:07 INFO Utils: Successfully started service 'SparkUI' on port 4040.
	24/04/23 11:03:07 INFO SparkContext: Added file file:///local_storage/reddit/processing/386-20240422.json at spark://c0e814e3f0bd:36795/files/386-20240422.json with timestamp 1713841385608
	24/04/23 11:03:07 INFO Utils: Copying /local_storage/reddit/processing/386-20240422.json to /tmp/spark-54fb00b8-9ef8-4640-82a4-2ede8e000c60/userFiles-071d0d41-942a-48bc-942e-e4a8ffb9656d/386-20240422.json
	24/04/23 11:03:07 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
[WI-0][TI-0] - [INFO] 2024-04-23 11:03:08.000 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8141025641025641 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:03:08.620 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:03:07 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.3:7077 after 88 ms (0 ms spent in bootstraps)
	24/04/23 11:03:07 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20240423030307-0011
	24/04/23 11:03:08 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20240423030307-0011/0 on worker-20240423012857-172.18.0.7-41063 (172.18.0.7:41063) with 2 core(s)
	24/04/23 11:03:08 INFO StandaloneSchedulerBackend: Granted executor ID app-20240423030307-0011/0 on hostPort 172.18.0.7:41063 with 2 core(s), 2.0 GiB RAM
	24/04/23 11:03:08 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45081.
	24/04/23 11:03:08 INFO NettyBlockTransferService: Server created on c0e814e3f0bd:45081
	24/04/23 11:03:08 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
	24/04/23 11:03:08 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20240423030307-0011/0 is now RUNNING
	24/04/23 11:03:08 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, c0e814e3f0bd, 45081, None)
	24/04/23 11:03:08 INFO BlockManagerMasterEndpoint: Registering block manager c0e814e3f0bd:45081 with 912.3 MiB RAM, BlockManagerId(driver, c0e814e3f0bd, 45081, None)
	24/04/23 11:03:08 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, c0e814e3f0bd, 45081, None)
	24/04/23 11:03:08 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, c0e814e3f0bd, 45081, None)
[WI-0][TI-0] - [INFO] 2024-04-23 11:03:09.002 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9572368421052632 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:03:09.621 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:03:08 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
	
	
	
	 /tmp/spark-54fb00b8-9ef8-4640-82a4-2ede8e000c60/userFiles-071d0d41-942a-48bc-942e-e4a8ffb9656d/386-20240422.json 
	
	
	
[WI-0][TI-0] - [INFO] 2024-04-23 11:03:10.003 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9082568807339448 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:03:10.633 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:03:10 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 345.6 KiB, free 912.0 MiB)
[WI-0][TI-0] - [INFO] 2024-04-23 11:03:11.024 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9387186629526463 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:03:11.635 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:03:10 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.7 KiB, free 911.9 MiB)
	24/04/23 11:03:10 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on c0e814e3f0bd:45081 (size: 32.7 KiB, free: 912.3 MiB)
	24/04/23 11:03:10 INFO SparkContext: Created broadcast 0 from wholeTextFiles at NativeMethodAccessorImpl.java:0
	
	
	
	 1 
	
	
	
	24/04/23 11:03:11 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
	24/04/23 11:03:11 INFO SharedState: Warehouse path is 'file:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/490/1148/spark-warehouse'.
[WI-0][TI-0] - [INFO] 2024-04-23 11:03:12.025 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.967930029154519 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:03:13.031 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9613259668508287 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:03:14.045 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9747899159663865 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:03:15.048 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.929663608562691 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:03:15.670 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:03:15 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.7:43406) with ID 0,  ResourceProfileId 0
[WI-0][TI-0] - [INFO] 2024-04-23 11:03:16.050 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9612188365650969 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:03:16.671 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:03:15 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.7:44535 with 1048.8 MiB RAM, BlockManagerId(0, 172.18.0.7, 44535, None)
[WI-0][TI-0] - [INFO] 2024-04-23 11:03:17.078 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.838006230529595 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:03:18.127 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7966998821386477 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:03:19.135 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9186131263136484 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:03:20.158 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8596491228070176 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:03:20.695 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:03:20 INFO CodeGenerator: Code generated in 567.445679 ms
	24/04/23 11:03:20 INFO FileInputFormat: Total input files to process : 1
	24/04/23 11:03:20 INFO FileInputFormat: Total input files to process : 1
	24/04/23 11:03:20 INFO SparkContext: Starting job: json at NativeMethodAccessorImpl.java:0
	24/04/23 11:03:20 INFO DAGScheduler: Got job 0 (json at NativeMethodAccessorImpl.java:0) with 1 output partitions
	24/04/23 11:03:20 INFO DAGScheduler: Final stage: ResultStage 0 (json at NativeMethodAccessorImpl.java:0)
	24/04/23 11:03:20 INFO DAGScheduler: Parents of final stage: List()
	24/04/23 11:03:20 INFO DAGScheduler: Missing parents: List()
	24/04/23 11:03:20 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[7] at json at NativeMethodAccessorImpl.java:0), which has no missing parents
	24/04/23 11:03:20 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 23.5 KiB, free 911.9 MiB)
	24/04/23 11:03:20 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 11.5 KiB, free 911.9 MiB)
	24/04/23 11:03:20 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on c0e814e3f0bd:45081 (size: 11.5 KiB, free: 912.3 MiB)
	24/04/23 11:03:20 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1585
	24/04/23 11:03:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[7] at json at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[WI-0][TI-0] - [INFO] 2024-04-23 11:03:21.166 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8571428571428572 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:03:21.698 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:03:20 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.7, executor 0, partition 0, PROCESS_LOCAL, 8008 bytes) 
[WI-0][TI-1123] - [INFO] 2024-04-23 11:04:48.172 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1123, processInstanceId=487, status=9, startTime=1713838208504, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1123.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1123, endTime=1713838483436, processId=1677, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713841188118)
[WI-0][TI-1123] - [INFO] 2024-04-23 11:04:48.179 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1123, processInstanceId=487, status=9, startTime=1713838208504, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1123.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1123, endTime=1713838483436, processId=1677, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713841488172)
[WI-0][TI-1111] - [INFO] 2024-04-23 11:04:50.180 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1111, processInstanceId=487, status=9, startTime=1713837256404, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1111.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1111, endTime=1713838170352, processId=1017, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713841190130)
[WI-0][TI-1111] - [INFO] 2024-04-23 11:04:50.183 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1111, processInstanceId=487, status=9, startTime=1713837256404, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1111.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1111, endTime=1713838170352, processId=1017, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713841490180)
[WI-0][TI-0] - [INFO] 2024-04-23 11:05:06.201 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:05:05 ERROR StandaloneSchedulerBackend: Application has been killed. Reason: Master removed our application: KILLED
	24/04/23 11:05:05 INFO SparkContext: SparkContext is stopping with exitCode 0.
	24/04/23 11:05:05 INFO TaskSchedulerImpl: Cancelling stage 0
	24/04/23 11:05:05 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage cancelled: Job aborted due to stage failure: Master removed our application: KILLED
	24/04/23 11:05:05 INFO TaskSchedulerImpl: Stage 0 was cancelled
	24/04/23 11:05:05 INFO DAGScheduler: ResultStage 0 (json at NativeMethodAccessorImpl.java:0) failed in 105.398 s due to Job aborted due to stage failure: Master removed our application: KILLED
	24/04/23 11:05:05 INFO DAGScheduler: Job 0 failed: json at NativeMethodAccessorImpl.java:0, took 105.515205 s
	24/04/23 11:05:05 INFO SparkUI: Stopped Spark web UI at http://c0e814e3f0bd:4040
	24/04/23 11:05:05 INFO StandaloneSchedulerBackend: Shutting down all executors
	24/04/23 11:05:05 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Asking each executor to shut down
	24/04/23 11:05:05 ERROR Utils: Uncaught exception in thread stop-spark-context
	org.apache.spark.SparkException: Exception thrown in awaitResult: 
		at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
		at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
		at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
		at org.apache.spark.deploy.client.StandaloneAppClient.stop(StandaloneAppClient.scala:288)
		at org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend.org$apache$spark$scheduler$cluster$StandaloneSchedulerBackend$$stop(StandaloneSchedulerBackend.scala:275)
		at org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend.stop(StandaloneSchedulerBackend.scala:142)
		at org.apache.spark.scheduler.SchedulerBackend.stop(SchedulerBackend.scala:33)
		at org.apache.spark.scheduler.SchedulerBackend.stop$(SchedulerBackend.scala:33)
		at org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend.stop(CoarseGrainedSchedulerBackend.scala:54)
		at org.apache.spark.scheduler.TaskSchedulerImpl.$anonfun$stop$2(TaskSchedulerImpl.scala:992)
		at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1375)
		at org.apache.spark.scheduler.TaskSchedulerImpl.stop(TaskSchedulerImpl.scala:992)
		at org.apache.spark.scheduler.DAGScheduler.$anonfun$stop$4(DAGScheduler.scala:2976)
		at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1375)
		at org.apache.spark.scheduler.DAGScheduler.stop(DAGScheduler.scala:2976)
		at org.apache.spark.SparkContext.$anonfun$stop$12(SparkContext.scala:2263)
		at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1375)
		at org.apache.spark.SparkContext.stop(SparkContext.scala:2263)
		at org.apache.spark.SparkContext.stop(SparkContext.scala:2216)
		at org.apache.spark.SparkContext$$anon$3.run(SparkContext.scala:2203)
	Caused by: org.apache.spark.SparkException: Could not find AppClient.
		at org.apache.spark.rpc.netty.Dispatcher.postMessage(Dispatcher.scala:178)
		at org.apache.spark.rpc.netty.Dispatcher.postLocalMessage(Dispatcher.scala:144)
		at org.apache.spark.rpc.netty.NettyRpcEnv.askAbortable(NettyRpcEnv.scala:242)
		at org.apache.spark.rpc.netty.NettyRpcEndpointRef.askAbortable(NettyRpcEnv.scala:554)
		at org.apache.spark.rpc.netty.NettyRpcEndpointRef.ask(NettyRpcEnv.scala:558)
		at org.apache.spark.rpc.RpcEndpointRef.ask(RpcEndpointRef.scala:72)
		... 17 more
	24/04/23 11:05:06 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
	Traceback (most recent call last):
	  File "/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/490/1148/spark_reddit_preprocessing.py", line 47, in <module>
	    raw_df = spark.read.json(raw_df)
	             ^^^^^^^^^^^^^^^^^^^^^^^
	  File "/opt/spark-3.5.1-bin-hadoop3/python/lib/pyspark.zip/pyspark/sql/readwriter.py", line 440, in json
	  File "/opt/spark-3.5.1-bin-hadoop3/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
	  File "/opt/spark-3.5.1-bin-hadoop3/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 179, in deco
	  File "/opt/spark-3.5.1-bin-hadoop3/python/lib/py4j-0.10.9.7-src.zip/py4j/protocol.py", line 326, in get_return_value
	py4j.protocol.Py4JJavaError: An error occurred while calling o35.json.
	: org.apache.spark.SparkException: Job aborted due to stage failure: Master removed our application: KILLED
		at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)
		at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)
		at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)
		at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
		at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
		at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
		at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)
		at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)
		at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)
		at scala.Option.foreach(Option.scala:407)
		at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)
		at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)
		at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)
		at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)
		at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
		at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:989)
		at org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)
		at org.apache.spark.SparkContext.runJob(SparkContext.scala:2493)
		at org.apache.spark.sql.catalyst.json.JsonInferSchema.infer(JsonInferSchema.scala:120)
		at org.apache.spark.sql.execution.datasources.json.TextInputJsonDataSource$.$anonfun$inferFromDataset$5(JsonDataSource.scala:109)
		at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)
		at org.apache.spark.sql.execution.datasources.json.TextInputJsonDataSource$.inferFromDataset(JsonDataSource.scala:109)
		at org.apache.spark.sql.DataFrameReader.$anonfun$json$4(DataFrameReader.scala:416)
		at scala.Option.getOrElse(Option.scala:189)
		at org.apache.spark.sql.DataFrameReader.json(DataFrameReader.scala:416)
		at org.apache.spark.sql.DataFrameReader.json(DataFrameReader.scala:391)
		at org.apache.spark.sql.DataFrameReader.json(DataFrameReader.scala:377)
		at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
		at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
		at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
		at java.lang.reflect.Method.invoke(Method.java:498)
		at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
		at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
		at py4j.Gateway.invoke(Gateway.java:282)
		at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
		at py4j.commands.CallCommand.execute(CallCommand.java:79)
		at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
		at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
		at java.lang.Thread.run(Thread.java:750)
	
	24/04/23 11:05:06 INFO MemoryStore: MemoryStore cleared
	24/04/23 11:05:06 INFO BlockManager: BlockManager stopped
	24/04/23 11:05:06 INFO BlockManagerMaster: BlockManagerMaster stopped
	24/04/23 11:05:06 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
[WI-0][TI-0] - [INFO] 2024-04-23 11:05:07.203 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:05:06 INFO ShutdownHookManager: Shutdown hook called
	24/04/23 11:05:06 INFO ShutdownHookManager: Deleting directory /tmp/spark-54fb00b8-9ef8-4640-82a4-2ede8e000c60/userFiles-071d0d41-942a-48bc-942e-e4a8ffb9656d
	24/04/23 11:05:06 INFO SparkContext: Successfully stopped SparkContext
	24/04/23 11:05:06 INFO ShutdownHookManager: Deleting directory /tmp/spark-54fb00b8-9ef8-4640-82a4-2ede8e000c60/pyspark-5d089d12-2eee-468f-81f6-53cd8f0681a5
	24/04/23 11:05:06 INFO ShutdownHookManager: Deleting directory /tmp/spark-54fb00b8-9ef8-4640-82a4-2ede8e000c60
	24/04/23 11:05:06 INFO ShutdownHookManager: Deleting directory /tmp/spark-faa45f2b-1153-4653-8a51-b235e7825b56
[WI-490][TI-1148] - [INFO] 2024-04-23 11:05:07.214 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/490/1148, processId:3272 ,exitStatusCode:1 ,processWaitForStatus:true ,processExitValue:1
[WI-490][TI-1148] - [INFO] 2024-04-23 11:05:07.214 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-490][TI-1148] - [INFO] 2024-04-23 11:05:07.215 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-490][TI-1148] - [INFO] 2024-04-23 11:05:07.215 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-490][TI-1148] - [INFO] 2024-04-23 11:05:07.215 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-490][TI-1148] - [INFO] 2024-04-23 11:05:07.218 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: FAILURE to master : 172.18.1.1:1234
[WI-490][TI-1148] - [INFO] 2024-04-23 11:05:07.219 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-490][TI-1148] - [INFO] 2024-04-23 11:05:07.219 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/490/1148
[WI-490][TI-1148] - [INFO] 2024-04-23 11:05:07.220 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/490/1148
[WI-490][TI-1148] - [INFO] 2024-04-23 11:05:07.220 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-1148] - [INFO] 2024-04-23 11:05:08.205 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1148, processInstanceId=490, status=6, startTime=1713841382522, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/80/490/1148.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/490/1148, endTime=1713841507215, processId=3272, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1148] - [INFO] 2024-04-23 11:05:08.208 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1148, processInstanceId=490, status=6, startTime=1713841382522, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/80/490/1148.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/490/1148, endTime=1713841507215, processId=3272, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713841508204)
[WI-0][TI-1148] - [INFO] 2024-04-23 11:05:08.208 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1148, success=true)
[WI-0][TI-1148] - [INFO] 2024-04-23 11:05:08.210 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1148, success=true)
[WI-0][TI-0] - [INFO] 2024-04-23 11:05:08.285 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7893258426966292 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:05:19.333 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1149, taskName=search for intake JSON files, firstSubmitTime=1713841519327, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.9:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=80, appIds=null, processInstanceId=491, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"processing"}], executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":""}],"rawScript":"# find 1 raw file in the folder\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\n\n# check if raw_file_dir is empty, then set raw_file_dir to null\nif [ -z \"$raw_file_dir\" ]; then\n    raw_file_dir=null\nfi\n\necho \"#{setValue(raw_file_dir=${raw_file_dir})}\"","resourceList":[]}, environmentConfig=export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='search for intake JSON files'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240423'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1149'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13340113777664'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240423110519'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='processing'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='491'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240422'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=null, dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-491][TI-1149] - [INFO] 2024-04-23 11:05:19.335 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: search for intake JSON files to wait queue success
[WI-491][TI-1149] - [INFO] 2024-04-23 11:05:19.335 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-491][TI-1149] - [INFO] 2024-04-23 11:05:19.337 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-491][TI-1149] - [INFO] 2024-04-23 11:05:19.337 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-491][TI-1149] - [INFO] 2024-04-23 11:05:19.337 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-491][TI-1149] - [INFO] 2024-04-23 11:05:19.337 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713841519337
[WI-491][TI-1149] - [INFO] 2024-04-23 11:05:19.337 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 491_1149
[WI-491][TI-1149] - [INFO] 2024-04-23 11:05:19.337 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1149,
  "taskName" : "search for intake JSON files",
  "firstSubmitTime" : 1713841519327,
  "startTime" : 1713841519337,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.9:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240423/13201021801792/80/491/1149.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 80,
  "processInstanceId" : 491,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"processing\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[{\"prop\":\"raw_file_dir\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"\"}],\"rawScript\":\"# find 1 raw file in the folder\\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\\n\\n# check if raw_file_dir is empty, then set raw_file_dir to null\\nif [ -z \\\"$raw_file_dir\\\" ]; then\\n    raw_file_dir=null\\nfi\\n\\necho \\\"#{setValue(raw_file_dir=${raw_file_dir})}\\\"\",\"resourceList\":[]}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "search for intake JSON files"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1149"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13340113777664"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423110519"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "processing"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "491"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240422"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "491_1149",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-491][TI-1149] - [INFO] 2024-04-23 11:05:19.338 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-491][TI-1149] - [INFO] 2024-04-23 11:05:19.338 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-491][TI-1149] - [INFO] 2024-04-23 11:05:19.338 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-491][TI-1149] - [INFO] 2024-04-23 11:05:19.350 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-491][TI-1149] - [INFO] 2024-04-23 11:05:19.353 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-491][TI-1149] - [INFO] 2024-04-23 11:05:19.355 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/491/1149 check successfully
[WI-491][TI-1149] - [INFO] 2024-04-23 11:05:19.355 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-491][TI-1149] - [INFO] 2024-04-23 11:05:19.356 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-491][TI-1149] - [INFO] 2024-04-23 11:05:19.356 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-491][TI-1149] - [INFO] 2024-04-23 11:05:19.356 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-491][TI-1149] - [INFO] 2024-04-23 11:05:19.356 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ {
    "prop" : "raw_file_dir",
    "direct" : "OUT",
    "type" : "VARCHAR",
    "value" : ""
  } ],
  "varPool" : null,
  "rawScript" : "# find 1 raw file in the folder\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\n\n# check if raw_file_dir is empty, then set raw_file_dir to null\nif [ -z \"$raw_file_dir\" ]; then\n    raw_file_dir=null\nfi\n\necho \"#{setValue(raw_file_dir=${raw_file_dir})}\"",
  "resourceList" : [ ]
}
[WI-491][TI-1149] - [INFO] 2024-04-23 11:05:19.356 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-491][TI-1149] - [INFO] 2024-04-23 11:05:19.356 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: null successfully
[WI-491][TI-1149] - [INFO] 2024-04-23 11:05:19.356 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-491][TI-1149] - [INFO] 2024-04-23 11:05:19.357 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-491][TI-1149] - [INFO] 2024-04-23 11:05:19.357 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-491][TI-1149] - [INFO] 2024-04-23 11:05:19.359 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-491][TI-1149] - [INFO] 2024-04-23 11:05:19.360 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-491][TI-1149] - [INFO] 2024-04-23 11:05:19.360 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export PYTHON_LAUNCHER=/bin/python3.11
# find 1 raw file in the folder
raw_file_dir=$(find /local_storage/reddit/processing -type f -name '*.json'| head -n 1)

# check if raw_file_dir is empty, then set raw_file_dir to null
if [ -z "$raw_file_dir" ]; then
    raw_file_dir=null
fi

echo "#{setValue(raw_file_dir=${raw_file_dir})}"
[WI-491][TI-1149] - [INFO] 2024-04-23 11:05:19.360 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-491][TI-1149] - [INFO] 2024-04-23 11:05:19.360 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/491/1149/491_1149.sh
[WI-491][TI-1149] - [INFO] 2024-04-23 11:05:19.366 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 3427
[WI-0][TI-1149] - [INFO] 2024-04-23 11:05:20.233 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionRunningEvent(taskInstanceId=1149, processInstanceId=491, startTime=1713841519337, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, status=TaskExecutionStatus{code=1, desc='running'}, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/80/491/1149.log, executePath=null, processId=0, appIds=null, eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1149] - [INFO] 2024-04-23 11:05:20.237 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionRunningEvent(taskInstanceId=1149, processInstanceId=491, startTime=1713841519337, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, status=TaskExecutionStatus{code=1, desc='running'}, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/80/491/1149.log, executePath=null, processId=0, appIds=null, eventCreateTime=0, eventSendTime=1713841520230)
[WI-0][TI-1149] - [INFO] 2024-04-23 11:05:20.237 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionInfoEvent(taskInstanceId=1149, processInstanceId=491, startTime=1713841519337, workflowInstanceHost=172.18.0.9:5678, taskInstanceHost=172.18.1.1:1234, logPath=null, processId=0, eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1149] - [INFO] 2024-04-23 11:05:20.239 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionInfoEvent(taskInstanceId=1149, processInstanceId=491, startTime=1713841519337, workflowInstanceHost=172.18.0.9:5678, taskInstanceHost=172.18.1.1:1234, logPath=null, processId=0, eventCreateTime=0, eventSendTime=1713841520230)
[WI-0][TI-1149] - [INFO] 2024-04-23 11:05:20.244 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1149, success=true)
[WI-0][TI-1149] - [INFO] 2024-04-23 11:05:20.252 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1149)
[WI-0][TI-1149] - [INFO] 2024-04-23 11:05:20.259 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1149, success=true)
[WI-0][TI-1149] - [INFO] 2024-04-23 11:05:20.265 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1149)
[WI-0][TI-0] - [INFO] 2024-04-23 11:05:20.384 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
	#{setValue(raw_file_dir=/local_storage/reddit/processing/386-20240422.json)}
[WI-491][TI-1149] - [INFO] 2024-04-23 11:05:20.387 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/491/1149, processId:3427 ,exitStatusCode:0 ,processWaitForStatus:true ,processExitValue:0
[WI-491][TI-1149] - [INFO] 2024-04-23 11:05:20.387 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-491][TI-1149] - [INFO] 2024-04-23 11:05:20.387 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-491][TI-1149] - [INFO] 2024-04-23 11:05:20.387 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-491][TI-1149] - [INFO] 2024-04-23 11:05:20.388 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-491][TI-1149] - [INFO] 2024-04-23 11:05:20.393 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: SUCCESS to master : 172.18.1.1:1234
[WI-491][TI-1149] - [INFO] 2024-04-23 11:05:20.393 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-491][TI-1149] - [INFO] 2024-04-23 11:05:20.393 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/491/1149
[WI-491][TI-1149] - [INFO] 2024-04-23 11:05:20.394 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/491/1149
[WI-491][TI-1149] - [INFO] 2024-04-23 11:05:20.395 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-1149] - [INFO] 2024-04-23 11:05:21.238 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1149, success=true)
[WI-0][TI-0] - [INFO] 2024-04-23 11:05:22.322 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1151, taskName=move to processing, firstSubmitTime=1713841522313, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.9:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=80, appIds=null, processInstanceId=491, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"processing"}], executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":""}],"rawScript":"# move file to the reddit processing folder\n# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error\nfilename=$(basename \"${raw_file_dir}\")\nif ! grep -q \"${REDDIT_HOME}/processing\" <<< \"${raw_file_dir}\"; then\n    mv ${raw_file_dir} ${REDDIT_HOME}/processing\nelse\n    echo JSON is already in processing\nfi\n\n# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing\necho \"#{setValue(raw_file_dir=${REDDIT_HOME}/processing/${filename})}\"","resourceList":[]}, environmentConfig=export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='move to processing'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240423'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1151'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13340390094208'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240423110522'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='processing'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='491'}, raw_file_dir=Property{prop='raw_file_dir', direct=IN, type=VARCHAR, value='/local_storage/reddit/processing/386-20240422.json'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240422'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-491][TI-1151] - [INFO] 2024-04-23 11:05:22.324 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: move to processing to wait queue success
[WI-491][TI-1151] - [INFO] 2024-04-23 11:05:22.324 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-491][TI-1151] - [INFO] 2024-04-23 11:05:22.326 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-491][TI-1151] - [INFO] 2024-04-23 11:05:22.326 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-491][TI-1151] - [INFO] 2024-04-23 11:05:22.326 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-491][TI-1151] - [INFO] 2024-04-23 11:05:22.327 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713841522327
[WI-491][TI-1151] - [INFO] 2024-04-23 11:05:22.327 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 491_1151
[WI-491][TI-1151] - [INFO] 2024-04-23 11:05:22.327 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1151,
  "taskName" : "move to processing",
  "firstSubmitTime" : 1713841522313,
  "startTime" : 1713841522327,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.9:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240423/13201021801792/80/491/1151.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 80,
  "processInstanceId" : 491,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"processing\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[{\"prop\":\"raw_file_dir\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"\"}],\"rawScript\":\"# move file to the reddit processing folder\\n# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error\\nfilename=$(basename \\\"${raw_file_dir}\\\")\\nif ! grep -q \\\"${REDDIT_HOME}/processing\\\" <<< \\\"${raw_file_dir}\\\"; then\\n    mv ${raw_file_dir} ${REDDIT_HOME}/processing\\nelse\\n    echo JSON is already in processing\\nfi\\n\\n# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing\\necho \\\"#{setValue(raw_file_dir=${REDDIT_HOME}/processing/${filename})}\\\"\",\"resourceList\":[]}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "move to processing"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1151"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13340390094208"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423110522"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "processing"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "491"
    },
    "raw_file_dir" : {
      "prop" : "raw_file_dir",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit/processing/386-20240422.json"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240422"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "491_1151",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"raw_file_dir\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"/local_storage/reddit/processing/386-20240422.json\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-491][TI-1151] - [INFO] 2024-04-23 11:05:22.330 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-491][TI-1151] - [INFO] 2024-04-23 11:05:22.330 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-491][TI-1151] - [INFO] 2024-04-23 11:05:22.330 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-491][TI-1151] - [INFO] 2024-04-23 11:05:22.332 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-491][TI-1151] - [INFO] 2024-04-23 11:05:22.332 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-491][TI-1151] - [INFO] 2024-04-23 11:05:22.333 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/491/1151 check successfully
[WI-491][TI-1151] - [INFO] 2024-04-23 11:05:22.333 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-491][TI-1151] - [INFO] 2024-04-23 11:05:22.333 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-491][TI-1151] - [INFO] 2024-04-23 11:05:22.333 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-491][TI-1151] - [INFO] 2024-04-23 11:05:22.333 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-491][TI-1151] - [INFO] 2024-04-23 11:05:22.333 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ {
    "prop" : "raw_file_dir",
    "direct" : "OUT",
    "type" : "VARCHAR",
    "value" : ""
  } ],
  "varPool" : null,
  "rawScript" : "# move file to the reddit processing folder\n# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error\nfilename=$(basename \"${raw_file_dir}\")\nif ! grep -q \"${REDDIT_HOME}/processing\" <<< \"${raw_file_dir}\"; then\n    mv ${raw_file_dir} ${REDDIT_HOME}/processing\nelse\n    echo JSON is already in processing\nfi\n\n# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing\necho \"#{setValue(raw_file_dir=${REDDIT_HOME}/processing/${filename})}\"",
  "resourceList" : [ ]
}
[WI-491][TI-1151] - [INFO] 2024-04-23 11:05:22.334 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-491][TI-1151] - [INFO] 2024-04-23 11:05:22.334 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}] successfully
[WI-491][TI-1151] - [INFO] 2024-04-23 11:05:22.334 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-491][TI-1151] - [INFO] 2024-04-23 11:05:22.334 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-491][TI-1151] - [INFO] 2024-04-23 11:05:22.334 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-491][TI-1151] - [INFO] 2024-04-23 11:05:22.335 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-491][TI-1151] - [INFO] 2024-04-23 11:05:22.335 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-491][TI-1151] - [INFO] 2024-04-23 11:05:22.335 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export PYTHON_LAUNCHER=/bin/python3.11
# move file to the reddit processing folder
# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error
filename=$(basename "/local_storage/reddit/processing/386-20240422.json")
if ! grep -q "/local_storage/reddit/processing" <<< "/local_storage/reddit/processing/386-20240422.json"; then
    mv /local_storage/reddit/processing/386-20240422.json /local_storage/reddit/processing
else
    echo JSON is already in processing
fi

# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing
echo "#{setValue(raw_file_dir=/local_storage/reddit/processing/${filename})}"
[WI-491][TI-1151] - [INFO] 2024-04-23 11:05:22.335 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-491][TI-1151] - [INFO] 2024-04-23 11:05:22.335 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/491/1151/491_1151.sh
[WI-491][TI-1151] - [INFO] 2024-04-23 11:05:22.337 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 3440
[WI-0][TI-1151] - [INFO] 2024-04-23 11:05:23.245 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionRunningEvent(taskInstanceId=1151, processInstanceId=491, startTime=1713841522327, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, status=TaskExecutionStatus{code=1, desc='running'}, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/80/491/1151.log, executePath=null, processId=0, appIds=null, eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1151] - [INFO] 2024-04-23 11:05:23.249 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionRunningEvent(taskInstanceId=1151, processInstanceId=491, startTime=1713841522327, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, status=TaskExecutionStatus{code=1, desc='running'}, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/80/491/1151.log, executePath=null, processId=0, appIds=null, eventCreateTime=0, eventSendTime=1713841523243)
[WI-0][TI-1151] - [INFO] 2024-04-23 11:05:23.249 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionInfoEvent(taskInstanceId=1151, processInstanceId=491, startTime=1713841522327, workflowInstanceHost=172.18.0.9:5678, taskInstanceHost=172.18.1.1:1234, logPath=null, processId=0, eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1151] - [INFO] 2024-04-23 11:05:23.256 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionInfoEvent(taskInstanceId=1151, processInstanceId=491, startTime=1713841522327, workflowInstanceHost=172.18.0.9:5678, taskInstanceHost=172.18.1.1:1234, logPath=null, processId=0, eventCreateTime=0, eventSendTime=1713841523243)
[WI-0][TI-1151] - [INFO] 2024-04-23 11:05:23.259 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1151, success=true)
[WI-0][TI-1151] - [INFO] 2024-04-23 11:05:23.269 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1151)
[WI-0][TI-1151] - [INFO] 2024-04-23 11:05:23.278 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1151, success=true)
[WI-0][TI-1151] - [INFO] 2024-04-23 11:05:23.317 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1151)
[WI-0][TI-0] - [INFO] 2024-04-23 11:05:23.340 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
	JSON is already in processing
	#{setValue(raw_file_dir=/local_storage/reddit/processing/386-20240422.json)}
[WI-491][TI-1151] - [INFO] 2024-04-23 11:05:23.374 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/491/1151, processId:3440 ,exitStatusCode:0 ,processWaitForStatus:true ,processExitValue:0
[WI-491][TI-1151] - [INFO] 2024-04-23 11:05:23.375 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-491][TI-1151] - [INFO] 2024-04-23 11:05:23.375 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-491][TI-1151] - [INFO] 2024-04-23 11:05:23.375 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-491][TI-1151] - [INFO] 2024-04-23 11:05:23.375 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-491][TI-1151] - [INFO] 2024-04-23 11:05:23.386 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: SUCCESS to master : 172.18.1.1:1234
[WI-491][TI-1151] - [INFO] 2024-04-23 11:05:23.386 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-491][TI-1151] - [INFO] 2024-04-23 11:05:23.386 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/491/1151
[WI-491][TI-1151] - [INFO] 2024-04-23 11:05:23.386 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/491/1151
[WI-491][TI-1151] - [INFO] 2024-04-23 11:05:23.386 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-1151] - [INFO] 2024-04-23 11:05:24.240 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1151, success=true)
[WI-0][TI-0] - [INFO] 2024-04-23 11:05:24.263 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1152, taskName=spark preprocessing, firstSubmitTime=1713841524257, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.9:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=80, appIds=null, processInstanceId=491, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"processing"}], executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[],"rawScript":"$SPARK_HOME/bin/spark-submit \\\n    --master spark://spark-master:7077 \\\n    --conf spark.driver.cores=2 \\\n    --conf spark.driver.memory=2G \\\n    --conf spark.executor.instances=1 \\\n    --conf spark.executor.cores=2 \\\n    --conf spark.executor.memory=2G \\\n    --files ${raw_file_dir} \\\n    --name reddit_preprocessing spark_reddit_preprocessing.py\n","resourceList":[{"id":null,"resourceName":"file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py","res":null}]}, environmentConfig=export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export HADOOP_CONF_DIR=/opt/hadoop-3.4.0/etc/hadoop
export PYSPARK_DRIVER_PYTHON=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='spark preprocessing'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240423'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1152'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13210058002752'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240423110524'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='processing'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='491'}, raw_file_dir=Property{prop='raw_file_dir', direct=IN, type=VARCHAR, value='/local_storage/reddit/processing/386-20240422.json'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240422'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-491][TI-1152] - [INFO] 2024-04-23 11:05:24.265 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: spark preprocessing to wait queue success
[WI-491][TI-1152] - [INFO] 2024-04-23 11:05:24.266 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-491][TI-1152] - [INFO] 2024-04-23 11:05:24.267 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-491][TI-1152] - [INFO] 2024-04-23 11:05:24.267 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-491][TI-1152] - [INFO] 2024-04-23 11:05:24.267 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-491][TI-1152] - [INFO] 2024-04-23 11:05:24.267 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713841524267
[WI-491][TI-1152] - [INFO] 2024-04-23 11:05:24.267 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 491_1152
[WI-491][TI-1152] - [INFO] 2024-04-23 11:05:24.267 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1152,
  "taskName" : "spark preprocessing",
  "firstSubmitTime" : 1713841524257,
  "startTime" : 1713841524267,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.9:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240423/13201021801792/80/491/1152.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 80,
  "processInstanceId" : 491,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"processing\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[],\"rawScript\":\"$SPARK_HOME/bin/spark-submit \\\\\\n    --master spark://spark-master:7077 \\\\\\n    --conf spark.driver.cores=2 \\\\\\n    --conf spark.driver.memory=2G \\\\\\n    --conf spark.executor.instances=1 \\\\\\n    --conf spark.executor.cores=2 \\\\\\n    --conf spark.executor.memory=2G \\\\\\n    --files ${raw_file_dir} \\\\\\n    --name reddit_preprocessing spark_reddit_preprocessing.py\\n\",\"resourceList\":[{\"id\":null,\"resourceName\":\"file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py\",\"res\":null}]}",
  "environmentConfig" : "export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3\nexport JAVA_HOME=/opt/java/openjdk\nexport HADOOP_CONF_DIR=/opt/hadoop-3.4.0/etc/hadoop\nexport PYSPARK_DRIVER_PYTHON=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "spark preprocessing"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1152"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13210058002752"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423110524"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "processing"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "491"
    },
    "raw_file_dir" : {
      "prop" : "raw_file_dir",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit/processing/386-20240422.json"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240422"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "491_1152",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"raw_file_dir\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"/local_storage/reddit/processing/386-20240422.json\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-491][TI-1152] - [INFO] 2024-04-23 11:05:24.267 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-491][TI-1152] - [INFO] 2024-04-23 11:05:24.267 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-491][TI-1152] - [INFO] 2024-04-23 11:05:24.267 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-491][TI-1152] - [INFO] 2024-04-23 11:05:24.270 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-491][TI-1152] - [INFO] 2024-04-23 11:05:24.270 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-491][TI-1152] - [INFO] 2024-04-23 11:05:24.270 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/491/1152 check successfully
[WI-491][TI-1152] - [INFO] 2024-04-23 11:05:24.271 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-491][TI-1152] - [INFO] 2024-04-23 11:05:24.272 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py=ResourceContext.ResourceItem(resourceAbsolutePathInStorage=file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py, resourceRelativePath=spark_reddit_preprocessing.py, resourceAbsolutePathInLocal=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/491/1152/spark_reddit_preprocessing.py)})
[WI-491][TI-1152] - [INFO] 2024-04-23 11:05:24.272 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-491][TI-1152] - [INFO] 2024-04-23 11:05:24.272 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-491][TI-1152] - [INFO] 2024-04-23 11:05:24.273 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ ],
  "varPool" : null,
  "rawScript" : "$SPARK_HOME/bin/spark-submit \\\n    --master spark://spark-master:7077 \\\n    --conf spark.driver.cores=2 \\\n    --conf spark.driver.memory=2G \\\n    --conf spark.executor.instances=1 \\\n    --conf spark.executor.cores=2 \\\n    --conf spark.executor.memory=2G \\\n    --files ${raw_file_dir} \\\n    --name reddit_preprocessing spark_reddit_preprocessing.py\n",
  "resourceList" : [ {
    "id" : null,
    "resourceName" : "file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py",
    "res" : null
  } ]
}
[WI-491][TI-1152] - [INFO] 2024-04-23 11:05:24.273 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-491][TI-1152] - [INFO] 2024-04-23 11:05:24.273 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}] successfully
[WI-491][TI-1152] - [INFO] 2024-04-23 11:05:24.273 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-491][TI-1152] - [INFO] 2024-04-23 11:05:24.273 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-491][TI-1152] - [INFO] 2024-04-23 11:05:24.273 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-491][TI-1152] - [INFO] 2024-04-23 11:05:24.274 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-491][TI-1152] - [INFO] 2024-04-23 11:05:24.274 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-491][TI-1152] - [INFO] 2024-04-23 11:05:24.274 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export HADOOP_CONF_DIR=/opt/hadoop-3.4.0/etc/hadoop
export PYSPARK_DRIVER_PYTHON=/bin/python3.11
$SPARK_HOME/bin/spark-submit \
    --master spark://spark-master:7077 \
    --conf spark.driver.cores=2 \
    --conf spark.driver.memory=2G \
    --conf spark.executor.instances=1 \
    --conf spark.executor.cores=2 \
    --conf spark.executor.memory=2G \
    --files /local_storage/reddit/processing/386-20240422.json \
    --name reddit_preprocessing spark_reddit_preprocessing.py

[WI-491][TI-1152] - [INFO] 2024-04-23 11:05:24.274 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-491][TI-1152] - [INFO] 2024-04-23 11:05:24.274 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/491/1152/491_1152.sh
[WI-491][TI-1152] - [INFO] 2024-04-23 11:05:24.278 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 3452
[WI-0][TI-0] - [INFO] 2024-04-23 11:05:24.401 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7365680530517642 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-1152] - [INFO] 2024-04-23 11:05:25.246 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1152, success=true)
[WI-0][TI-1152] - [INFO] 2024-04-23 11:05:25.257 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionInfoEvent(taskInstanceId=1152, processInstanceId=491, startTime=1713841524267, workflowInstanceHost=172.18.0.9:5678, taskInstanceHost=172.18.1.1:1234, logPath=null, processId=0, eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1152] - [INFO] 2024-04-23 11:05:25.258 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1152)
[WI-0][TI-1152] - [INFO] 2024-04-23 11:05:25.278 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionInfoEvent(taskInstanceId=1152, processInstanceId=491, startTime=1713841524267, workflowInstanceHost=172.18.0.9:5678, taskInstanceHost=172.18.1.1:1234, logPath=null, processId=0, eventCreateTime=0, eventSendTime=1713841525257)
[WI-0][TI-1152] - [WARN] 2024-04-23 11:05:25.281 +0800 o.a.d.s.w.m.MessageRetryRunner:[139] - Retry send message to master error
java.util.ConcurrentModificationException: null
	at java.util.ArrayList$Itr.checkForComodification(ArrayList.java:911)
	at java.util.ArrayList$Itr.next(ArrayList.java:861)
	at org.apache.dolphinscheduler.server.worker.message.MessageRetryRunner.run(MessageRetryRunner.java:127)
[WI-0][TI-0] - [INFO] 2024-04-23 11:05:25.281 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
[WI-0][TI-1152] - [INFO] 2024-04-23 11:05:25.294 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1152)
[WI-0][TI-0] - [INFO] 2024-04-23 11:05:25.446 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8478039943442913 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:05:26.452 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8122977346278317 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:05:27.455 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8113207547169812 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:05:28.302 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:05:27 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[WI-0][TI-0] - [INFO] 2024-04-23 11:05:28.462 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8825136612021858 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:05:29.307 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:05:28 INFO SparkContext: Running Spark version 3.5.1
	24/04/23 11:05:28 INFO SparkContext: OS info Linux, 6.5.0-28-generic, amd64
	24/04/23 11:05:28 INFO SparkContext: Java version 1.8.0_402
	24/04/23 11:05:28 INFO ResourceUtils: ==============================================================
	24/04/23 11:05:28 INFO ResourceUtils: No custom resources configured for spark.driver.
	24/04/23 11:05:28 INFO ResourceUtils: ==============================================================
	24/04/23 11:05:28 INFO SparkContext: Submitted application: reddit_preprocessing
	24/04/23 11:05:29 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 2, script: , vendor: , memory -> name: memory, amount: 2048, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
	24/04/23 11:05:29 INFO ResourceProfile: Limiting resource is cpus at 2 tasks per executor
	24/04/23 11:05:29 INFO ResourceProfileManager: Added ResourceProfile id: 0
	24/04/23 11:05:29 INFO SecurityManager: Changing view acls to: default
	24/04/23 11:05:29 INFO SecurityManager: Changing modify acls to: default
[WI-0][TI-0] - [INFO] 2024-04-23 11:05:29.468 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.935374149659864 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:05:30.317 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:05:29 INFO Utils: Successfully started service 'sparkDriver' on port 33733.
	24/04/23 11:05:30 INFO SparkEnv: Registering MapOutputTracker
[WI-0][TI-0] - [INFO] 2024-04-23 11:05:30.474 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8954802259887006 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:05:31.347 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:05:30 INFO SparkEnv: Registering BlockManagerMaster
	24/04/23 11:05:30 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
	24/04/23 11:05:30 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
	24/04/23 11:05:30 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
	24/04/23 11:05:30 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-e46d05b4-5749-4b5a-8ca3-2410b5261f9a
	24/04/23 11:05:30 INFO MemoryStore: MemoryStore started with capacity 912.3 MiB
	24/04/23 11:05:30 INFO SparkEnv: Registering OutputCommitCoordinator
	24/04/23 11:05:30 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
	24/04/23 11:05:30 INFO Utils: Successfully started service 'SparkUI' on port 4040.
	24/04/23 11:05:30 INFO SparkContext: Added file file:///local_storage/reddit/processing/386-20240422.json at spark://c0e814e3f0bd:33733/files/386-20240422.json with timestamp 1713841528713
	24/04/23 11:05:31 INFO Utils: Copying /local_storage/reddit/processing/386-20240422.json to /tmp/spark-1b52b0a0-7006-4b71-98b1-930a00f40c04/userFiles-aa4afbba-c09f-44d9-800b-40e1e432585c/386-20240422.json
[WI-0][TI-0] - [INFO] 2024-04-23 11:05:31.476 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9403973509933775 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:05:32.362 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:05:31 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
	24/04/23 11:05:31 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.3:7077 after 77 ms (0 ms spent in bootstraps)
	24/04/23 11:05:31 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20240423030531-0012
	24/04/23 11:05:31 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20240423030531-0012/0 on worker-20240423012857-172.18.0.7-41063 (172.18.0.7:41063) with 2 core(s)
	24/04/23 11:05:31 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38383.
	24/04/23 11:05:31 INFO NettyBlockTransferService: Server created on c0e814e3f0bd:38383
	24/04/23 11:05:31 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
	24/04/23 11:05:31 INFO StandaloneSchedulerBackend: Granted executor ID app-20240423030531-0012/0 on hostPort 172.18.0.7:41063 with 2 core(s), 2.0 GiB RAM
	24/04/23 11:05:31 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, c0e814e3f0bd, 38383, None)
	24/04/23 11:05:31 INFO BlockManagerMasterEndpoint: Registering block manager c0e814e3f0bd:38383 with 912.3 MiB RAM, BlockManagerId(driver, c0e814e3f0bd, 38383, None)
	24/04/23 11:05:31 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20240423030531-0012/0 is now RUNNING
	24/04/23 11:05:31 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, c0e814e3f0bd, 38383, None)
	24/04/23 11:05:31 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, c0e814e3f0bd, 38383, None)
[WI-0][TI-0] - [INFO] 2024-04-23 11:05:32.507 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8859563875675583 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:05:33.363 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:05:32 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
	
	
	
	 /tmp/spark-1b52b0a0-7006-4b71-98b1-930a00f40c04/userFiles-aa4afbba-c09f-44d9-800b-40e1e432585c/386-20240422.json 
	
	
	
[WI-0][TI-0] - [INFO] 2024-04-23 11:05:33.527 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9271137026239067 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:05:34.529 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9909365558912386 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:05:35.384 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:05:34 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 345.6 KiB, free 912.0 MiB)
	24/04/23 11:05:35 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.7 KiB, free 911.9 MiB)
	24/04/23 11:05:35 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on c0e814e3f0bd:38383 (size: 32.7 KiB, free: 912.3 MiB)
	24/04/23 11:05:35 INFO SparkContext: Created broadcast 0 from wholeTextFiles at NativeMethodAccessorImpl.java:0
[WI-0][TI-0] - [INFO] 2024-04-23 11:05:35.562 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9435028248587571 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:05:36.406 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	
	
	
	 1 
	
	
	
	24/04/23 11:05:35 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
	24/04/23 11:05:35 INFO SharedState: Warehouse path is 'file:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/491/1152/spark-warehouse'.
[WI-0][TI-0] - [INFO] 2024-04-23 11:05:36.578 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9385113268608414 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:05:37.581 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.919093851132686 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:05:38.769 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.849740932642487 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:05:39.773 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9623824451410659 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:05:40.775 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8676923076923078 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:05:41.438 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:05:40 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.7:54260) with ID 0,  ResourceProfileId 0
	24/04/23 11:05:40 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.7:36607 with 1048.8 MiB RAM, BlockManagerId(0, 172.18.0.7, 36607, None)
[WI-0][TI-0] - [INFO] 2024-04-23 11:05:44.443 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:05:44 INFO CodeGenerator: Code generated in 399.704125 ms
	24/04/23 11:05:44 INFO FileInputFormat: Total input files to process : 1
	24/04/23 11:05:44 INFO FileInputFormat: Total input files to process : 1
	24/04/23 11:05:44 INFO SparkContext: Starting job: json at NativeMethodAccessorImpl.java:0
	24/04/23 11:05:44 INFO DAGScheduler: Got job 0 (json at NativeMethodAccessorImpl.java:0) with 1 output partitions
	24/04/23 11:05:44 INFO DAGScheduler: Final stage: ResultStage 0 (json at NativeMethodAccessorImpl.java:0)
	24/04/23 11:05:44 INFO DAGScheduler: Parents of final stage: List()
	24/04/23 11:05:44 INFO DAGScheduler: Missing parents: List()
	24/04/23 11:05:44 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[7] at json at NativeMethodAccessorImpl.java:0), which has no missing parents
[WI-0][TI-0] - [INFO] 2024-04-23 11:05:44.815 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8491620111731844 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:05:45.444 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:05:44 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 23.5 KiB, free 911.9 MiB)
	24/04/23 11:05:44 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 11.5 KiB, free 911.9 MiB)
	24/04/23 11:05:44 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on c0e814e3f0bd:38383 (size: 11.5 KiB, free: 912.3 MiB)
	24/04/23 11:05:44 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1585
	24/04/23 11:05:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[7] at json at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
	24/04/23 11:05:45 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
	24/04/23 11:05:45 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.7, executor 0, partition 0, PROCESS_LOCAL, 8008 bytes) 
[WI-0][TI-0] - [INFO] 2024-04-23 11:05:45.843 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7457142857142858 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:06:01.903 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7758112094395281 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:07:12.182 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7653958944281525 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-1144] - [INFO] 2024-04-23 11:07:12.690 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1144, processInstanceId=489, status=9, startTime=1713840953087, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/80/489/1144.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1144, endTime=1713841331355, processId=3026, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713841332349)
[WI-0][TI-1144] - [INFO] 2024-04-23 11:07:12.697 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1144, processInstanceId=489, status=9, startTime=1713840953087, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/80/489/1144.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1144, endTime=1713841331355, processId=3026, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713841632690)
[WI-0][TI-0] - [INFO] 2024-04-23 11:07:13.198 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7857142857142857 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:07:14.200 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7011494252873562 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:07:17.223 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7896253602305476 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:07:29.674 +0800 o.a.d.s.w.r.o.TaskInstanceKillOperationFunction:[55] - Receive TaskInstanceKillRequest: TaskInstanceKillRequest(taskInstanceId=1152)
[WI-0][TI-1152] - [ERROR] 2024-04-23 11:07:29.690 +0800 o.a.d.s.w.r.o.TaskInstanceKillOperationFunction:[139] - kill task error
java.io.IOException: Cannot run program "pstree": error=2, No such file or directory
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1048)
	at org.apache.dolphinscheduler.common.shell.AbstractShell.runCommand(AbstractShell.java:138)
	at org.apache.dolphinscheduler.common.shell.AbstractShell.run(AbstractShell.java:118)
	at org.apache.dolphinscheduler.common.shell.ShellExecutor.execute(ShellExecutor.java:125)
	at org.apache.dolphinscheduler.common.shell.ShellExecutor.execCommand(ShellExecutor.java:103)
	at org.apache.dolphinscheduler.common.shell.ShellExecutor.execCommand(ShellExecutor.java:86)
	at org.apache.dolphinscheduler.common.utils.OSUtils.exeShell(OSUtils.java:345)
	at org.apache.dolphinscheduler.common.utils.OSUtils.exeCmd(OSUtils.java:334)
	at org.apache.dolphinscheduler.plugin.task.api.utils.ProcessUtils.getPidsStr(ProcessUtils.java:129)
	at org.apache.dolphinscheduler.server.worker.runner.operator.TaskInstanceKillOperationFunction.killProcess(TaskInstanceKillOperationFunction.java:130)
	at org.apache.dolphinscheduler.server.worker.runner.operator.TaskInstanceKillOperationFunction.doKill(TaskInstanceKillOperationFunction.java:96)
	at org.apache.dolphinscheduler.server.worker.runner.operator.TaskInstanceKillOperationFunction.operate(TaskInstanceKillOperationFunction.java:69)
	at org.apache.dolphinscheduler.server.worker.rpc.TaskInstanceOperatorImpl.killTask(TaskInstanceOperatorImpl.java:49)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.dolphinscheduler.extract.base.server.ServerMethodInvokerImpl.invoke(ServerMethodInvokerImpl.java:41)
	at org.apache.dolphinscheduler.extract.base.server.JdkDynamicServerHandler.lambda$processReceived$0(JdkDynamicServerHandler.java:108)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.io.IOException: error=2, No such file or directory
	at java.lang.UNIXProcess.forkAndExec(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:247)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	... 21 common frames omitted
[WI-0][TI-1152] - [INFO] 2024-04-23 11:07:29.691 +0800 o.a.d.p.t.a.u.ProcessUtils:[182] - Get appIds from worker 172.18.1.1:1234, taskLogPath: /opt/dolphinscheduler/logs/20240423/13201021801792/80/491/1152.log
[WI-0][TI-1152] - [INFO] 2024-04-23 11:07:29.691 +0800 o.a.d.p.t.a.u.LogUtils:[79] - Start finding appId in /opt/dolphinscheduler/logs/20240423/13201021801792/80/491/1152.log, fetch way: log 
[WI-0][TI-1152] - [INFO] 2024-04-23 11:07:29.695 +0800 o.a.d.p.t.a.u.ProcessUtils:[188] - The appId is empty
[WI-0][TI-1152] - [INFO] 2024-04-23 11:07:29.711 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[220] - Begin to kill process process, pid is : 3452
[WI-0][TI-0] - [INFO] 2024-04-23 11:07:30.292 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8954802259887005 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:07:31.345 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8081081081081081 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:07:33.356 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7067448680351907 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-1152] - [INFO] 2024-04-23 11:07:34.717 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[225] - Success kill task: 491_1152, pid: 3452
[WI-0][TI-1152] - [INFO] 2024-04-23 11:07:34.719 +0800 o.a.d.s.w.r.o.TaskInstanceKillOperationFunction:[119] - kill task by cancelApplication, taskInstanceId: 1152
[WI-0][TI-0] - [INFO] 2024-04-23 11:07:40.929 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1153, taskName=search for intake JSON files, firstSubmitTime=1713841660922, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.9:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=80, appIds=null, processInstanceId=491, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"processing"}], executorId=1, cmdTypeIfComplement=7, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":""}],"rawScript":"# find 1 raw file in the folder\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\n\n# check if raw_file_dir is empty, then set raw_file_dir to null\nif [ -z \"$raw_file_dir\" ]; then\n    raw_file_dir=null\nfi\n\necho \"#{setValue(raw_file_dir=${raw_file_dir})}\"","resourceList":[]}, environmentConfig=export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='search for intake JSON files'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240423'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1153'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13340113777664'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240423110740'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='processing'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='491'}, raw_file_dir=Property{prop='raw_file_dir', direct=OUT, type=VARCHAR, value='/local_storage/reddit/processing/386-20240422.json'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240422'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-491][TI-1153] - [INFO] 2024-04-23 11:07:40.930 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: search for intake JSON files to wait queue success
[WI-491][TI-1153] - [INFO] 2024-04-23 11:07:40.931 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-491][TI-1153] - [INFO] 2024-04-23 11:07:40.932 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-491][TI-1153] - [INFO] 2024-04-23 11:07:40.932 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-491][TI-1153] - [INFO] 2024-04-23 11:07:40.932 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-491][TI-1153] - [INFO] 2024-04-23 11:07:40.932 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713841660932
[WI-491][TI-1153] - [INFO] 2024-04-23 11:07:40.932 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 491_1153
[WI-491][TI-1153] - [INFO] 2024-04-23 11:07:40.932 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1153,
  "taskName" : "search for intake JSON files",
  "firstSubmitTime" : 1713841660922,
  "startTime" : 1713841660932,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.9:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240423/13201021801792/80/491/1153.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 80,
  "processInstanceId" : 491,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"processing\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 7,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[{\"prop\":\"raw_file_dir\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"\"}],\"rawScript\":\"# find 1 raw file in the folder\\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\\n\\n# check if raw_file_dir is empty, then set raw_file_dir to null\\nif [ -z \\\"$raw_file_dir\\\" ]; then\\n    raw_file_dir=null\\nfi\\n\\necho \\\"#{setValue(raw_file_dir=${raw_file_dir})}\\\"\",\"resourceList\":[]}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "search for intake JSON files"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1153"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13340113777664"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423110740"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "processing"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "491"
    },
    "raw_file_dir" : {
      "prop" : "raw_file_dir",
      "direct" : "OUT",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit/processing/386-20240422.json"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240422"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "491_1153",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"raw_file_dir\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"/local_storage/reddit/processing/386-20240422.json\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-491][TI-1153] - [INFO] 2024-04-23 11:07:40.933 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-491][TI-1153] - [INFO] 2024-04-23 11:07:40.933 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-491][TI-1153] - [INFO] 2024-04-23 11:07:40.934 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-491][TI-1153] - [INFO] 2024-04-23 11:07:40.935 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-491][TI-1153] - [INFO] 2024-04-23 11:07:40.936 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-491][TI-1153] - [INFO] 2024-04-23 11:07:40.936 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/491/1153 check successfully
[WI-491][TI-1153] - [INFO] 2024-04-23 11:07:40.936 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-491][TI-1153] - [INFO] 2024-04-23 11:07:40.937 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-491][TI-1153] - [INFO] 2024-04-23 11:07:40.937 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-491][TI-1153] - [INFO] 2024-04-23 11:07:40.937 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-491][TI-1153] - [INFO] 2024-04-23 11:07:40.938 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ {
    "prop" : "raw_file_dir",
    "direct" : "OUT",
    "type" : "VARCHAR",
    "value" : ""
  } ],
  "varPool" : null,
  "rawScript" : "# find 1 raw file in the folder\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\n\n# check if raw_file_dir is empty, then set raw_file_dir to null\nif [ -z \"$raw_file_dir\" ]; then\n    raw_file_dir=null\nfi\n\necho \"#{setValue(raw_file_dir=${raw_file_dir})}\"",
  "resourceList" : [ ]
}
[WI-491][TI-1153] - [INFO] 2024-04-23 11:07:40.938 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-491][TI-1153] - [INFO] 2024-04-23 11:07:40.938 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}] successfully
[WI-491][TI-1153] - [INFO] 2024-04-23 11:07:40.938 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-491][TI-1153] - [INFO] 2024-04-23 11:07:40.938 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-491][TI-1153] - [INFO] 2024-04-23 11:07:40.938 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-491][TI-1153] - [INFO] 2024-04-23 11:07:40.939 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-491][TI-1153] - [INFO] 2024-04-23 11:07:40.939 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-491][TI-1153] - [INFO] 2024-04-23 11:07:40.939 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export PYTHON_LAUNCHER=/bin/python3.11
# find 1 raw file in the folder
raw_file_dir=$(find /local_storage/reddit/processing -type f -name '*.json'| head -n 1)

# check if raw_file_dir is empty, then set raw_file_dir to null
if [ -z "$raw_file_dir" ]; then
    raw_file_dir=null
fi

echo "#{setValue(raw_file_dir=/local_storage/reddit/processing/386-20240422.json)}"
[WI-491][TI-1153] - [INFO] 2024-04-23 11:07:40.939 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-491][TI-1153] - [INFO] 2024-04-23 11:07:40.939 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/491/1153/491_1153.sh
[WI-491][TI-1153] - [INFO] 2024-04-23 11:07:40.942 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 3589
[WI-0][TI-1153] - [INFO] 2024-04-23 11:07:41.749 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionRunningEvent(taskInstanceId=1153, processInstanceId=491, startTime=1713841660932, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, status=TaskExecutionStatus{code=1, desc='running'}, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/80/491/1153.log, executePath=null, processId=0, appIds=null, eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1153] - [INFO] 2024-04-23 11:07:41.769 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionRunningEvent(taskInstanceId=1153, processInstanceId=491, startTime=1713841660932, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, status=TaskExecutionStatus{code=1, desc='running'}, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/80/491/1153.log, executePath=null, processId=0, appIds=null, eventCreateTime=0, eventSendTime=1713841661743)
[WI-0][TI-1153] - [INFO] 2024-04-23 11:07:41.770 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionInfoEvent(taskInstanceId=1153, processInstanceId=491, startTime=1713841660932, workflowInstanceHost=172.18.0.9:5678, taskInstanceHost=172.18.1.1:1234, logPath=null, processId=0, eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1153] - [INFO] 2024-04-23 11:07:41.770 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1153, success=true)
[WI-0][TI-1153] - [INFO] 2024-04-23 11:07:41.776 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionInfoEvent(taskInstanceId=1153, processInstanceId=491, startTime=1713841660932, workflowInstanceHost=172.18.0.9:5678, taskInstanceHost=172.18.1.1:1234, logPath=null, processId=0, eventCreateTime=0, eventSendTime=1713841661743)
[WI-0][TI-1153] - [WARN] 2024-04-23 11:07:41.777 +0800 o.a.d.s.w.m.MessageRetryRunner:[139] - Retry send message to master error
java.util.ConcurrentModificationException: null
	at java.util.ArrayList$Itr.checkForComodification(ArrayList.java:911)
	at java.util.ArrayList$Itr.next(ArrayList.java:861)
	at org.apache.dolphinscheduler.server.worker.message.MessageRetryRunner.run(MessageRetryRunner.java:127)
[WI-0][TI-1153] - [INFO] 2024-04-23 11:07:41.778 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1153)
[WI-0][TI-1153] - [INFO] 2024-04-23 11:07:41.782 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1153, success=true)
[WI-0][TI-1153] - [INFO] 2024-04-23 11:07:41.787 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1153)
[WI-0][TI-0] - [INFO] 2024-04-23 11:07:41.943 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
	#{setValue(raw_file_dir=/local_storage/reddit/processing/386-20240422.json)}
[WI-491][TI-1153] - [INFO] 2024-04-23 11:07:41.947 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/491/1153, processId:3589 ,exitStatusCode:0 ,processWaitForStatus:true ,processExitValue:0
[WI-491][TI-1153] - [INFO] 2024-04-23 11:07:41.947 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-491][TI-1153] - [INFO] 2024-04-23 11:07:41.948 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-491][TI-1153] - [INFO] 2024-04-23 11:07:41.948 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-491][TI-1153] - [INFO] 2024-04-23 11:07:41.948 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-491][TI-1153] - [INFO] 2024-04-23 11:07:41.950 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: SUCCESS to master : 172.18.1.1:1234
[WI-491][TI-1153] - [INFO] 2024-04-23 11:07:41.950 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-491][TI-1153] - [INFO] 2024-04-23 11:07:41.951 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/491/1153
[WI-491][TI-1153] - [INFO] 2024-04-23 11:07:41.951 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/491/1153
[WI-491][TI-1153] - [INFO] 2024-04-23 11:07:41.951 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-1153] - [INFO] 2024-04-23 11:07:42.744 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1153, success=true)
[WI-0][TI-0] - [INFO] 2024-04-23 11:07:43.841 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1155, taskName=move to processing, firstSubmitTime=1713841663834, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.9:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=80, appIds=null, processInstanceId=491, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"processing"}], executorId=1, cmdTypeIfComplement=7, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":""}],"rawScript":"# move file to the reddit processing folder\n# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error\nfilename=$(basename \"${raw_file_dir}\")\nif ! grep -q \"${REDDIT_HOME}/processing\" <<< \"${raw_file_dir}\"; then\n    mv ${raw_file_dir} ${REDDIT_HOME}/processing\nelse\n    echo JSON is already in processing\nfi\n\n# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing\necho \"#{setValue(raw_file_dir=${REDDIT_HOME}/processing/${filename})}\"","resourceList":[]}, environmentConfig=export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='move to processing'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240423'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1155'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13340390094208'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240423110743'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='processing'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='491'}, raw_file_dir=Property{prop='raw_file_dir', direct=IN, type=VARCHAR, value='/local_storage/reddit/processing/386-20240422.json'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240422'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-491][TI-1155] - [INFO] 2024-04-23 11:07:43.843 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: move to processing to wait queue success
[WI-491][TI-1155] - [INFO] 2024-04-23 11:07:43.843 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-491][TI-1155] - [INFO] 2024-04-23 11:07:43.845 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-491][TI-1155] - [INFO] 2024-04-23 11:07:43.846 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-491][TI-1155] - [INFO] 2024-04-23 11:07:43.847 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-491][TI-1155] - [INFO] 2024-04-23 11:07:43.847 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713841663847
[WI-491][TI-1155] - [INFO] 2024-04-23 11:07:43.847 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 491_1155
[WI-491][TI-1155] - [INFO] 2024-04-23 11:07:43.847 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1155,
  "taskName" : "move to processing",
  "firstSubmitTime" : 1713841663834,
  "startTime" : 1713841663847,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.9:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240423/13201021801792/80/491/1155.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 80,
  "processInstanceId" : 491,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"processing\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 7,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[{\"prop\":\"raw_file_dir\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"\"}],\"rawScript\":\"# move file to the reddit processing folder\\n# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error\\nfilename=$(basename \\\"${raw_file_dir}\\\")\\nif ! grep -q \\\"${REDDIT_HOME}/processing\\\" <<< \\\"${raw_file_dir}\\\"; then\\n    mv ${raw_file_dir} ${REDDIT_HOME}/processing\\nelse\\n    echo JSON is already in processing\\nfi\\n\\n# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing\\necho \\\"#{setValue(raw_file_dir=${REDDIT_HOME}/processing/${filename})}\\\"\",\"resourceList\":[]}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "move to processing"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1155"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13340390094208"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423110743"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "processing"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "491"
    },
    "raw_file_dir" : {
      "prop" : "raw_file_dir",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit/processing/386-20240422.json"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240422"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "491_1155",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"raw_file_dir\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"/local_storage/reddit/processing/386-20240422.json\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-491][TI-1155] - [INFO] 2024-04-23 11:07:43.848 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-491][TI-1155] - [INFO] 2024-04-23 11:07:43.848 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-491][TI-1155] - [INFO] 2024-04-23 11:07:43.849 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-491][TI-1155] - [INFO] 2024-04-23 11:07:43.852 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-491][TI-1155] - [INFO] 2024-04-23 11:07:43.852 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-491][TI-1155] - [INFO] 2024-04-23 11:07:43.853 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/491/1155 check successfully
[WI-491][TI-1155] - [INFO] 2024-04-23 11:07:43.853 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-491][TI-1155] - [INFO] 2024-04-23 11:07:43.853 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-491][TI-1155] - [INFO] 2024-04-23 11:07:43.854 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-491][TI-1155] - [INFO] 2024-04-23 11:07:43.854 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-491][TI-1155] - [INFO] 2024-04-23 11:07:43.855 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ {
    "prop" : "raw_file_dir",
    "direct" : "OUT",
    "type" : "VARCHAR",
    "value" : ""
  } ],
  "varPool" : null,
  "rawScript" : "# move file to the reddit processing folder\n# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error\nfilename=$(basename \"${raw_file_dir}\")\nif ! grep -q \"${REDDIT_HOME}/processing\" <<< \"${raw_file_dir}\"; then\n    mv ${raw_file_dir} ${REDDIT_HOME}/processing\nelse\n    echo JSON is already in processing\nfi\n\n# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing\necho \"#{setValue(raw_file_dir=${REDDIT_HOME}/processing/${filename})}\"",
  "resourceList" : [ ]
}
[WI-491][TI-1155] - [INFO] 2024-04-23 11:07:43.855 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-491][TI-1155] - [INFO] 2024-04-23 11:07:43.855 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}] successfully
[WI-491][TI-1155] - [INFO] 2024-04-23 11:07:43.855 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-491][TI-1155] - [INFO] 2024-04-23 11:07:43.855 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-491][TI-1155] - [INFO] 2024-04-23 11:07:43.856 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-491][TI-1155] - [INFO] 2024-04-23 11:07:43.856 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-491][TI-1155] - [INFO] 2024-04-23 11:07:43.856 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-491][TI-1155] - [INFO] 2024-04-23 11:07:43.859 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export PYTHON_LAUNCHER=/bin/python3.11
# move file to the reddit processing folder
# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error
filename=$(basename "/local_storage/reddit/processing/386-20240422.json")
if ! grep -q "/local_storage/reddit/processing" <<< "/local_storage/reddit/processing/386-20240422.json"; then
    mv /local_storage/reddit/processing/386-20240422.json /local_storage/reddit/processing
else
    echo JSON is already in processing
fi

# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing
echo "#{setValue(raw_file_dir=/local_storage/reddit/processing/${filename})}"
[WI-491][TI-1155] - [INFO] 2024-04-23 11:07:43.861 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-491][TI-1155] - [INFO] 2024-04-23 11:07:43.861 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/491/1155/491_1155.sh
[WI-491][TI-1155] - [INFO] 2024-04-23 11:07:43.864 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 3603
[WI-0][TI-1155] - [INFO] 2024-04-23 11:07:44.792 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionRunningEvent(taskInstanceId=1155, processInstanceId=491, startTime=1713841663847, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, status=TaskExecutionStatus{code=1, desc='running'}, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/80/491/1155.log, executePath=null, processId=0, appIds=null, eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1155] - [INFO] 2024-04-23 11:07:44.797 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1155, success=true)
[WI-0][TI-1155] - [INFO] 2024-04-23 11:07:44.799 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionRunningEvent(taskInstanceId=1155, processInstanceId=491, startTime=1713841663847, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, status=TaskExecutionStatus{code=1, desc='running'}, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/80/491/1155.log, executePath=null, processId=0, appIds=null, eventCreateTime=0, eventSendTime=1713841664781)
[WI-0][TI-1155] - [INFO] 2024-04-23 11:07:44.808 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1155)
[WI-0][TI-1155] - [INFO] 2024-04-23 11:07:44.816 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1155, success=true)
[WI-0][TI-0] - [INFO] 2024-04-23 11:07:44.869 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
	JSON is already in processing
	#{setValue(raw_file_dir=/local_storage/reddit/processing/386-20240422.json)}
[WI-491][TI-1155] - [INFO] 2024-04-23 11:07:44.898 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/491/1155, processId:3603 ,exitStatusCode:0 ,processWaitForStatus:true ,processExitValue:0
[WI-491][TI-1155] - [INFO] 2024-04-23 11:07:44.899 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-491][TI-1155] - [INFO] 2024-04-23 11:07:44.900 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-491][TI-1155] - [INFO] 2024-04-23 11:07:44.900 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-491][TI-1155] - [INFO] 2024-04-23 11:07:44.903 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-491][TI-1155] - [INFO] 2024-04-23 11:07:44.935 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: SUCCESS to master : 172.18.1.1:1234
[WI-491][TI-1155] - [INFO] 2024-04-23 11:07:44.936 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-491][TI-1155] - [INFO] 2024-04-23 11:07:44.936 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/491/1155
[WI-491][TI-1155] - [INFO] 2024-04-23 11:07:44.937 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/491/1155
[WI-491][TI-1155] - [INFO] 2024-04-23 11:07:44.938 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-1155] - [INFO] 2024-04-23 11:07:45.754 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1155, success=true)
[WI-0][TI-0] - [INFO] 2024-04-23 11:07:45.785 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1156, taskName=spark preprocessing, firstSubmitTime=1713841665776, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.9:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=80, appIds=null, processInstanceId=491, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"processing"}], executorId=1, cmdTypeIfComplement=7, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[],"rawScript":"$SPARK_HOME/bin/spark-submit \\\n    --master spark://spark-master:7077 \\\n    --conf spark.driver.cores=2 \\\n    --conf spark.driver.memory=2G \\\n    --conf spark.executor.instances=1 \\\n    --conf spark.executor.cores=2 \\\n    --conf spark.executor.memory=2G \\\n    --files ${raw_file_dir} \\\n    --name reddit_preprocessing spark_reddit_preprocessing.py\n","resourceList":[{"id":null,"resourceName":"file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py","res":null}]}, environmentConfig=export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export HADOOP_CONF_DIR=/opt/hadoop-3.4.0/etc/hadoop
export PYSPARK_DRIVER_PYTHON=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='spark preprocessing'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240423'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1156'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13210058002752'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240423110745'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='processing'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='491'}, raw_file_dir=Property{prop='raw_file_dir', direct=IN, type=VARCHAR, value='/local_storage/reddit/processing/386-20240422.json'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240422'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-491][TI-1156] - [INFO] 2024-04-23 11:07:45.786 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: spark preprocessing to wait queue success
[WI-491][TI-1156] - [INFO] 2024-04-23 11:07:45.786 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-491][TI-1156] - [INFO] 2024-04-23 11:07:45.789 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-491][TI-1156] - [INFO] 2024-04-23 11:07:45.790 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-491][TI-1156] - [INFO] 2024-04-23 11:07:45.791 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-491][TI-1156] - [INFO] 2024-04-23 11:07:45.791 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713841665791
[WI-491][TI-1156] - [INFO] 2024-04-23 11:07:45.791 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 491_1156
[WI-491][TI-1156] - [INFO] 2024-04-23 11:07:45.792 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1156,
  "taskName" : "spark preprocessing",
  "firstSubmitTime" : 1713841665776,
  "startTime" : 1713841665791,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.9:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240423/13201021801792/80/491/1156.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 80,
  "processInstanceId" : 491,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"processing\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 7,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[],\"rawScript\":\"$SPARK_HOME/bin/spark-submit \\\\\\n    --master spark://spark-master:7077 \\\\\\n    --conf spark.driver.cores=2 \\\\\\n    --conf spark.driver.memory=2G \\\\\\n    --conf spark.executor.instances=1 \\\\\\n    --conf spark.executor.cores=2 \\\\\\n    --conf spark.executor.memory=2G \\\\\\n    --files ${raw_file_dir} \\\\\\n    --name reddit_preprocessing spark_reddit_preprocessing.py\\n\",\"resourceList\":[{\"id\":null,\"resourceName\":\"file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py\",\"res\":null}]}",
  "environmentConfig" : "export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3\nexport JAVA_HOME=/opt/java/openjdk\nexport HADOOP_CONF_DIR=/opt/hadoop-3.4.0/etc/hadoop\nexport PYSPARK_DRIVER_PYTHON=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "spark preprocessing"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1156"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13210058002752"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423110745"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "processing"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "491"
    },
    "raw_file_dir" : {
      "prop" : "raw_file_dir",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit/processing/386-20240422.json"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240422"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "491_1156",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"raw_file_dir\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"/local_storage/reddit/processing/386-20240422.json\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-491][TI-1156] - [INFO] 2024-04-23 11:07:45.793 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-491][TI-1156] - [INFO] 2024-04-23 11:07:45.793 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-491][TI-1156] - [INFO] 2024-04-23 11:07:45.793 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-491][TI-1156] - [INFO] 2024-04-23 11:07:45.796 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-491][TI-1156] - [INFO] 2024-04-23 11:07:45.796 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-491][TI-1156] - [INFO] 2024-04-23 11:07:45.797 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/491/1156 check successfully
[WI-491][TI-1156] - [INFO] 2024-04-23 11:07:45.797 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-0][TI-1156] - [INFO] 2024-04-23 11:07:45.807 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionRunningEvent(taskInstanceId=1156, processInstanceId=491, startTime=1713841665791, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, status=TaskExecutionStatus{code=1, desc='running'}, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/80/491/1156.log, executePath=null, processId=0, appIds=null, eventCreateTime=0, eventSendTime=0)
[WI-491][TI-1156] - [INFO] 2024-04-23 11:07:45.807 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py=ResourceContext.ResourceItem(resourceAbsolutePathInStorage=file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py, resourceRelativePath=spark_reddit_preprocessing.py, resourceAbsolutePathInLocal=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/491/1156/spark_reddit_preprocessing.py)})
[WI-491][TI-1156] - [INFO] 2024-04-23 11:07:45.807 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-491][TI-1156] - [INFO] 2024-04-23 11:07:45.811 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-491][TI-1156] - [INFO] 2024-04-23 11:07:45.811 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ ],
  "varPool" : null,
  "rawScript" : "$SPARK_HOME/bin/spark-submit \\\n    --master spark://spark-master:7077 \\\n    --conf spark.driver.cores=2 \\\n    --conf spark.driver.memory=2G \\\n    --conf spark.executor.instances=1 \\\n    --conf spark.executor.cores=2 \\\n    --conf spark.executor.memory=2G \\\n    --files ${raw_file_dir} \\\n    --name reddit_preprocessing spark_reddit_preprocessing.py\n",
  "resourceList" : [ {
    "id" : null,
    "resourceName" : "file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py",
    "res" : null
  } ]
}
[WI-491][TI-1156] - [INFO] 2024-04-23 11:07:45.811 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-0][TI-1156] - [INFO] 2024-04-23 11:07:45.811 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionRunningEvent(taskInstanceId=1156, processInstanceId=491, startTime=1713841665791, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, status=TaskExecutionStatus{code=1, desc='running'}, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/80/491/1156.log, executePath=null, processId=0, appIds=null, eventCreateTime=0, eventSendTime=1713841665801)
[WI-491][TI-1156] - [INFO] 2024-04-23 11:07:45.811 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}] successfully
[WI-491][TI-1156] - [INFO] 2024-04-23 11:07:45.811 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-491][TI-1156] - [INFO] 2024-04-23 11:07:45.811 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-491][TI-1156] - [INFO] 2024-04-23 11:07:45.811 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-491][TI-1156] - [INFO] 2024-04-23 11:07:45.812 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-491][TI-1156] - [INFO] 2024-04-23 11:07:45.812 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-491][TI-1156] - [INFO] 2024-04-23 11:07:45.812 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export HADOOP_CONF_DIR=/opt/hadoop-3.4.0/etc/hadoop
export PYSPARK_DRIVER_PYTHON=/bin/python3.11
$SPARK_HOME/bin/spark-submit \
    --master spark://spark-master:7077 \
    --conf spark.driver.cores=2 \
    --conf spark.driver.memory=2G \
    --conf spark.executor.instances=1 \
    --conf spark.executor.cores=2 \
    --conf spark.executor.memory=2G \
    --files /local_storage/reddit/processing/386-20240422.json \
    --name reddit_preprocessing spark_reddit_preprocessing.py

[WI-491][TI-1156] - [INFO] 2024-04-23 11:07:45.812 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-491][TI-1156] - [INFO] 2024-04-23 11:07:45.812 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/491/1156/491_1156.sh
[WI-491][TI-1156] - [INFO] 2024-04-23 11:07:45.827 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 3615
[WI-0][TI-0] - [INFO] 2024-04-23 11:07:46.451 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7277936962750716 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-1156] - [INFO] 2024-04-23 11:07:46.772 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1156, success=true)
[WI-0][TI-1156] - [INFO] 2024-04-23 11:07:46.786 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1156, success=true)
[WI-0][TI-1156] - [INFO] 2024-04-23 11:07:46.797 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1156)
[WI-0][TI-0] - [INFO] 2024-04-23 11:07:46.828 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
[WI-0][TI-0] - [INFO] 2024-04-23 11:07:47.462 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8299120234604105 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:07:48.504 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8895027624309393 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:07:49.507 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9111111111111111 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:07:49.834 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:07:49 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[WI-0][TI-0] - [INFO] 2024-04-23 11:07:50.521 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9274193548387097 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:07:50.836 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:07:50 INFO SparkContext: Running Spark version 3.5.1
	24/04/23 11:07:50 INFO SparkContext: OS info Linux, 6.5.0-28-generic, amd64
	24/04/23 11:07:50 INFO SparkContext: Java version 1.8.0_402
	24/04/23 11:07:50 INFO ResourceUtils: ==============================================================
	24/04/23 11:07:50 INFO ResourceUtils: No custom resources configured for spark.driver.
	24/04/23 11:07:50 INFO ResourceUtils: ==============================================================
	24/04/23 11:07:50 INFO SparkContext: Submitted application: reddit_preprocessing
	24/04/23 11:07:50 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 2, script: , vendor: , memory -> name: memory, amount: 2048, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
	24/04/23 11:07:50 INFO ResourceProfile: Limiting resource is cpus at 2 tasks per executor
	24/04/23 11:07:50 INFO ResourceProfileManager: Added ResourceProfile id: 0
[WI-0][TI-0] - [INFO] 2024-04-23 11:07:51.522 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8210227272727272 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:07:51.839 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:07:50 INFO SecurityManager: Changing view acls to: default
	24/04/23 11:07:50 INFO SecurityManager: Changing modify acls to: default
	24/04/23 11:07:50 INFO SecurityManager: Changing view acls groups to: 
	24/04/23 11:07:50 INFO SecurityManager: Changing modify acls groups to: 
	24/04/23 11:07:50 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: default; groups with view permissions: EMPTY; users with modify permissions: default; groups with modify permissions: EMPTY
	24/04/23 11:07:51 INFO Utils: Successfully started service 'sparkDriver' on port 34401.
	24/04/23 11:07:51 INFO SparkEnv: Registering MapOutputTracker
	24/04/23 11:07:51 INFO SparkEnv: Registering BlockManagerMaster
	24/04/23 11:07:51 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
	24/04/23 11:07:51 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
[WI-0][TI-0] - [INFO] 2024-04-23 11:07:52.525 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.910828025477707 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:07:52.843 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:07:51 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
	24/04/23 11:07:51 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-4008e145-d3ef-4c58-9dba-030dadc9e3b3
	24/04/23 11:07:51 INFO MemoryStore: MemoryStore started with capacity 912.3 MiB
	24/04/23 11:07:52 INFO SparkEnv: Registering OutputCommitCoordinator
	24/04/23 11:07:52 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
	24/04/23 11:07:52 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
	24/04/23 11:07:52 INFO Utils: Successfully started service 'SparkUI' on port 4041.
	24/04/23 11:07:52 INFO SparkContext: Added file file:///local_storage/reddit/processing/386-20240422.json at spark://c0e814e3f0bd:34401/files/386-20240422.json with timestamp 1713841670630
	24/04/23 11:07:52 INFO Utils: Copying /local_storage/reddit/processing/386-20240422.json to /tmp/spark-0a777719-093b-4097-9596-859c32707bfd/userFiles-6482d1ab-4aa8-41b5-bee2-82ccd86f6f67/386-20240422.json
[WI-0][TI-0] - [INFO] 2024-04-23 11:07:53.528 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8964401294498382 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:07:53.883 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:07:53 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
	24/04/23 11:07:53 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.3:7077 after 149 ms (0 ms spent in bootstraps)
	24/04/23 11:07:53 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20240423030753-0013
[WI-0][TI-0] - [INFO] 2024-04-23 11:07:54.540 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8757225433526012 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:07:54.914 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:07:53 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 32973.
	24/04/23 11:07:53 INFO NettyBlockTransferService: Server created on c0e814e3f0bd:32973
	24/04/23 11:07:53 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
	24/04/23 11:07:54 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, c0e814e3f0bd, 32973, None)
	24/04/23 11:07:54 INFO BlockManagerMasterEndpoint: Registering block manager c0e814e3f0bd:32973 with 912.3 MiB RAM, BlockManagerId(driver, c0e814e3f0bd, 32973, None)
	24/04/23 11:07:54 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, c0e814e3f0bd, 32973, None)
	24/04/23 11:07:54 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, c0e814e3f0bd, 32973, None)
	24/04/23 11:07:54 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
[WI-0][TI-0] - [INFO] 2024-04-23 11:07:55.546 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7999999999999999 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:07:55.918 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	
	
	
	 /tmp/spark-0a777719-093b-4097-9596-859c32707bfd/userFiles-6482d1ab-4aa8-41b5-bee2-82ccd86f6f67/386-20240422.json 
	
	
	
[WI-0][TI-0] - [INFO] 2024-04-23 11:07:56.547 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8445747800586509 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:07:56.920 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:07:56 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 345.6 KiB, free 912.0 MiB)
	24/04/23 11:07:56 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.7 KiB, free 911.9 MiB)
	24/04/23 11:07:56 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on c0e814e3f0bd:32973 (size: 32.7 KiB, free: 912.3 MiB)
	24/04/23 11:07:56 INFO SparkContext: Created broadcast 0 from wholeTextFiles at NativeMethodAccessorImpl.java:0
	
	
	
	 1 
	
	
	
	24/04/23 11:07:56 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
	24/04/23 11:07:56 INFO SharedState: Warehouse path is 'file:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/491/1156/spark-warehouse'.
[WI-0][TI-0] - [INFO] 2024-04-23 11:07:58.575 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7465181058495821 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:08:01.646 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7471590909090909 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:08:03.949 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:08:03 INFO CodeGenerator: Code generated in 557.058139 ms
	24/04/23 11:08:03 INFO FileInputFormat: Total input files to process : 1
	24/04/23 11:08:03 INFO FileInputFormat: Total input files to process : 1
	24/04/23 11:08:03 INFO SparkContext: Starting job: json at NativeMethodAccessorImpl.java:0
	24/04/23 11:08:03 INFO DAGScheduler: Got job 0 (json at NativeMethodAccessorImpl.java:0) with 1 output partitions
	24/04/23 11:08:03 INFO DAGScheduler: Final stage: ResultStage 0 (json at NativeMethodAccessorImpl.java:0)
	24/04/23 11:08:03 INFO DAGScheduler: Parents of final stage: List()
	24/04/23 11:08:03 INFO DAGScheduler: Missing parents: List()
	24/04/23 11:08:03 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[7] at json at NativeMethodAccessorImpl.java:0), which has no missing parents
[WI-0][TI-0] - [INFO] 2024-04-23 11:08:04.954 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:08:04 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 23.5 KiB, free 911.9 MiB)
	24/04/23 11:08:04 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 11.5 KiB, free 911.9 MiB)
	24/04/23 11:08:04 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on c0e814e3f0bd:32973 (size: 11.5 KiB, free: 912.3 MiB)
	24/04/23 11:08:04 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1585
	24/04/23 11:08:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[7] at json at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
	24/04/23 11:08:04 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
[WI-0][TI-0] - [INFO] 2024-04-23 11:08:19.981 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:08:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
[WI-0][TI-0] - [INFO] 2024-04-23 11:08:30.776 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7528089887640449 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:08:34.999 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:08:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
[WI-0][TI-0] - [ERROR] 2024-04-23 11:08:41.936 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[279] - Parse var pool error
java.io.IOException: Stream closed
	at java.io.BufferedInputStream.getBufIfOpen(BufferedInputStream.java:170)
	at java.io.BufferedInputStream.read1(BufferedInputStream.java:283)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:345)
	at sun.nio.cs.StreamDecoder.readBytes(StreamDecoder.java:284)
	at sun.nio.cs.StreamDecoder.implRead(StreamDecoder.java:326)
	at sun.nio.cs.StreamDecoder.read(StreamDecoder.java:178)
	at java.io.InputStreamReader.read(InputStreamReader.java:184)
	at java.io.BufferedReader.fill(BufferedReader.java:161)
	at java.io.BufferedReader.readLine(BufferedReader.java:324)
	at java.io.BufferedReader.readLine(BufferedReader.java:389)
	at org.apache.dolphinscheduler.plugin.task.api.AbstractCommandExecutor.lambda$parseProcessOutput$1(AbstractCommandExecutor.java:273)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
[WI-0][TI-0] - [INFO] 2024-04-23 11:08:42.011 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:08:41 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20240423030753-0013/0 on worker-20240423012857-172.18.0.7-41063 (172.18.0.7:41063) with 2 core(s)
	24/04/23 11:08:41 INFO StandaloneSchedulerBackend: Granted executor ID app-20240423030753-0013/0 on hostPort 172.18.0.7:41063 with 2 core(s), 2.0 GiB RAM
[WI-0][TI-0] - [INFO] 2024-04-23 11:08:42.881 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9691516709511568 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-491][TI-1152] - [INFO] 2024-04-23 11:08:42.887 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has killed. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/491/1152, processId:3452 ,exitStatusCode:137 ,processWaitForStatus:true ,processExitValue:137
[WI-491][TI-1152] - [INFO] 2024-04-23 11:08:42.887 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-491][TI-1152] - [INFO] 2024-04-23 11:08:42.888 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-491][TI-1152] - [INFO] 2024-04-23 11:08:42.888 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-491][TI-1152] - [INFO] 2024-04-23 11:08:42.888 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-491][TI-1152] - [INFO] 2024-04-23 11:08:42.933 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: KILL to master : 172.18.1.1:1234
[WI-491][TI-1152] - [INFO] 2024-04-23 11:08:42.933 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-491][TI-1152] - [INFO] 2024-04-23 11:08:42.933 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/491/1152
[WI-491][TI-1152] - [INFO] 2024-04-23 11:08:42.934 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/491/1152
[WI-491][TI-1152] - [INFO] 2024-04-23 11:08:42.934 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-1152] - [INFO] 2024-04-23 11:08:42.992 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1152, processInstanceId=491, status=9, startTime=1713841524267, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/80/491/1152.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/491/1152, endTime=1713841722888, processId=3452, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1152] - [INFO] 2024-04-23 11:08:43.001 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1152, processInstanceId=491, status=9, startTime=1713841524267, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/80/491/1152.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/491/1152, endTime=1713841722888, processId=3452, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713841722985)
[WI-0][TI-0] - [INFO] 2024-04-23 11:08:43.013 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:08:42 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20240423030753-0013/0 is now RUNNING
[WI-0][TI-1152] - [INFO] 2024-04-23 11:08:43.898 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1152, success=true)
[WI-0][TI-1152] - [INFO] 2024-04-23 11:08:43.903 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1152, success=true)
[WI-0][TI-0] - [INFO] 2024-04-23 11:08:43.957 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.917312661498708 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:08:44.961 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.873900293255132 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:08:45.968 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8132530120481929 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:08:46.977 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7111111111111111 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:08:48.047 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:08:47 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.7:37010) with ID 0,  ResourceProfileId 0
	24/04/23 11:08:47 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.7:34347 with 1048.8 MiB RAM, BlockManagerId(0, 172.18.0.7, 34347, None)
	24/04/23 11:08:47 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.7, executor 0, partition 0, PROCESS_LOCAL, 8008 bytes) 
[WI-0][TI-1123] - [INFO] 2024-04-23 11:09:49.116 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1123, processInstanceId=487, status=9, startTime=1713838208504, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1123.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1123, endTime=1713838483436, processId=1677, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713841488172)
[WI-0][TI-1123] - [INFO] 2024-04-23 11:09:49.119 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1123, processInstanceId=487, status=9, startTime=1713838208504, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1123.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1123, endTime=1713838483436, processId=1677, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713841789115)
[WI-0][TI-1111] - [INFO] 2024-04-23 11:09:51.120 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1111, processInstanceId=487, status=9, startTime=1713837256404, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1111.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1111, endTime=1713838170352, processId=1017, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713841490180)
[WI-0][TI-1111] - [INFO] 2024-04-23 11:09:51.123 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1111, processInstanceId=487, status=9, startTime=1713837256404, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1111.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1111, endTime=1713838170352, processId=1017, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713841791120)
[WI-0][TI-1144] - [INFO] 2024-04-23 11:12:12.854 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1144, processInstanceId=489, status=9, startTime=1713840953087, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/80/489/1144.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1144, endTime=1713841331355, processId=3026, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713841632690)
[WI-0][TI-1144] - [INFO] 2024-04-23 11:12:12.856 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1144, processInstanceId=489, status=9, startTime=1713840953087, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/80/489/1144.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1144, endTime=1713841331355, processId=3026, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713841932854)
[WI-0][TI-0] - [INFO] 2024-04-23 11:12:15.888 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7394957983193278 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:12:19.934 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7557471264367817 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-1123] - [INFO] 2024-04-23 11:14:49.548 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1123, processInstanceId=487, status=9, startTime=1713838208504, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1123.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1123, endTime=1713838483436, processId=1677, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713841789115)
[WI-0][TI-1123] - [INFO] 2024-04-23 11:14:49.556 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1123, processInstanceId=487, status=9, startTime=1713838208504, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1123.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1123, endTime=1713838483436, processId=1677, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713842089547)
[WI-0][TI-1111] - [INFO] 2024-04-23 11:14:51.558 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1111, processInstanceId=487, status=9, startTime=1713837256404, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1111.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1111, endTime=1713838170352, processId=1017, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713841791120)
[WI-0][TI-1111] - [INFO] 2024-04-23 11:14:51.562 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1111, processInstanceId=487, status=9, startTime=1713837256404, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1111.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1111, endTime=1713838170352, processId=1017, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713842091558)
[WI-0][TI-1144] - [INFO] 2024-04-23 11:17:13.384 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1144, processInstanceId=489, status=9, startTime=1713840953087, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/80/489/1144.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1144, endTime=1713841331355, processId=3026, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713841932854)
[WI-0][TI-1144] - [INFO] 2024-04-23 11:17:13.387 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1144, processInstanceId=489, status=9, startTime=1713840953087, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/80/489/1144.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1144, endTime=1713841331355, processId=3026, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713842233384)
[WI-0][TI-1123] - [INFO] 2024-04-23 11:19:49.856 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1123, processInstanceId=487, status=9, startTime=1713838208504, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1123.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1123, endTime=1713838483436, processId=1677, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713842089547)
[WI-0][TI-1123] - [INFO] 2024-04-23 11:19:49.860 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1123, processInstanceId=487, status=9, startTime=1713838208504, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1123.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1123, endTime=1713838483436, processId=1677, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713842389856)
[WI-0][TI-1111] - [INFO] 2024-04-23 11:19:51.863 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1111, processInstanceId=487, status=9, startTime=1713837256404, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1111.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1111, endTime=1713838170352, processId=1017, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713842091558)
[WI-0][TI-1111] - [INFO] 2024-04-23 11:19:51.866 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1111, processInstanceId=487, status=9, startTime=1713837256404, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1111.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1111, endTime=1713838170352, processId=1017, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713842391863)
[WI-0][TI-1144] - [INFO] 2024-04-23 11:22:13.728 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1144, processInstanceId=489, status=9, startTime=1713840953087, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/80/489/1144.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1144, endTime=1713841331355, processId=3026, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713842233384)
[WI-0][TI-1144] - [INFO] 2024-04-23 11:22:13.733 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1144, processInstanceId=489, status=9, startTime=1713840953087, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/80/489/1144.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1144, endTime=1713841331355, processId=3026, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713842533728)
[WI-0][TI-0] - [INFO] 2024-04-23 11:22:14.709 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:22:14 ERROR StandaloneSchedulerBackend: Application has been killed. Reason: Master removed our application: KILLED
	24/04/23 11:22:14 INFO SparkContext: SparkContext is stopping with exitCode 0.
	24/04/23 11:22:14 INFO TaskSchedulerImpl: Cancelling stage 0
	24/04/23 11:22:14 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage cancelled: Job aborted due to stage failure: Master removed our application: KILLED
	24/04/23 11:22:14 INFO TaskSchedulerImpl: Stage 0 was cancelled
	24/04/23 11:22:14 INFO DAGScheduler: ResultStage 0 (json at NativeMethodAccessorImpl.java:0) failed in 850.476 s due to Job aborted due to stage failure: Master removed our application: KILLED
	24/04/23 11:22:14 INFO DAGScheduler: Job 0 failed: json at NativeMethodAccessorImpl.java:0, took 850.687092 s
	24/04/23 11:22:14 INFO SparkUI: Stopped Spark web UI at http://c0e814e3f0bd:4041
	24/04/23 11:22:14 INFO StandaloneSchedulerBackend: Shutting down all executors
	24/04/23 11:22:14 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Asking each executor to shut down
	24/04/23 11:22:14 ERROR Utils: Uncaught exception in thread stop-spark-context
	org.apache.spark.SparkException: Exception thrown in awaitResult: 
		at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
		at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
		at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
		at org.apache.spark.deploy.client.StandaloneAppClient.stop(StandaloneAppClient.scala:288)
		at org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend.org$apache$spark$scheduler$cluster$StandaloneSchedulerBackend$$stop(StandaloneSchedulerBackend.scala:275)
		at org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend.stop(StandaloneSchedulerBackend.scala:142)
		at org.apache.spark.scheduler.SchedulerBackend.stop(SchedulerBackend.scala:33)
		at org.apache.spark.scheduler.SchedulerBackend.stop$(SchedulerBackend.scala:33)
		at org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend.stop(CoarseGrainedSchedulerBackend.scala:54)
		at org.apache.spark.scheduler.TaskSchedulerImpl.$anonfun$stop$2(TaskSchedulerImpl.scala:992)
		at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1375)
		at org.apache.spark.scheduler.TaskSchedulerImpl.stop(TaskSchedulerImpl.scala:992)
		at org.apache.spark.scheduler.DAGScheduler.$anonfun$stop$4(DAGScheduler.scala:2976)
		at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1375)
		at org.apache.spark.scheduler.DAGScheduler.stop(DAGScheduler.scala:2976)
		at org.apache.spark.SparkContext.$anonfun$stop$12(SparkContext.scala:2263)
		at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1375)
		at org.apache.spark.SparkContext.stop(SparkContext.scala:2263)
		at org.apache.spark.SparkContext.stop(SparkContext.scala:2216)
		at org.apache.spark.SparkContext$$anon$3.run(SparkContext.scala:2203)
	Caused by: org.apache.spark.SparkException: Could not find AppClient.
		at org.apache.spark.rpc.netty.Dispatcher.postMessage(Dispatcher.scala:178)
		at org.apache.spark.rpc.netty.Dispatcher.postLocalMessage(Dispatcher.scala:144)
		at org.apache.spark.rpc.netty.NettyRpcEnv.askAbortable(NettyRpcEnv.scala:242)
		at org.apache.spark.rpc.netty.NettyRpcEndpointRef.askAbortable(NettyRpcEnv.scala:554)
		at org.apache.spark.rpc.netty.NettyRpcEndpointRef.ask(NettyRpcEnv.scala:558)
		at org.apache.spark.rpc.RpcEndpointRef.ask(RpcEndpointRef.scala:72)
		... 17 more
	24/04/23 11:22:14 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
	Traceback (most recent call last):
	  File "/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/491/1156/spark_reddit_preprocessing.py", line 47, in <module>
	    raw_df = spark.read.json(raw_df)
	             ^^^^^^^^^^^^^^^^^^^^^^^
	  File "/opt/spark-3.5.1-bin-hadoop3/python/lib/pyspark.zip/pyspark/sql/readwriter.py", line 440, in json
	  File "/opt/spark-3.5.1-bin-hadoop3/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
	  File "/opt/spark-3.5.1-bin-hadoop3/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 179, in deco
	  File "/opt/spark-3.5.1-bin-hadoop3/python/lib/py4j-0.10.9.7-src.zip/py4j/protocol.py", line 326, in get_return_value
	py4j.protocol.Py4JJavaError: An error occurred while calling o35.json.
	: org.apache.spark.SparkException: Job aborted due to stage failure: Master removed our application: KILLED
		at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)
		at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)
		at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)
		at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
		at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
		at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
		at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)
		at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)
		at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)
		at scala.Option.foreach(Option.scala:407)
		at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)
		at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)
		at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)
		at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)
		at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
		at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:989)
		at org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)
		at org.apache.spark.SparkContext.runJob(SparkContext.scala:2493)
		at org.apache.spark.sql.catalyst.json.JsonInferSchema.infer(JsonInferSchema.scala:120)
		at org.apache.spark.sql.execution.datasources.json.TextInputJsonDataSource$.$anonfun$inferFromDataset$5(JsonDataSource.scala:109)
		at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)
		at org.apache.spark.sql.execution.datasources.json.TextInputJsonDataSource$.inferFromDataset(JsonDataSource.scala:109)
		at org.apache.spark.sql.DataFrameReader.$anonfun$json$4(DataFrameReader.scala:416)
		at scala.Option.getOrElse(Option.scala:189)
		at org.apache.spark.sql.DataFrameReader.json(DataFrameReader.scala:416)
		at org.apache.spark.sql.DataFrameReader.json(DataFrameReader.scala:391)
		at org.apache.spark.sql.DataFrameReader.json(DataFrameReader.scala:377)
		at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
		at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
		at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
		at java.lang.reflect.Method.invoke(Method.java:498)
		at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
		at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
		at py4j.Gateway.invoke(Gateway.java:282)
		at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
		at py4j.commands.CallCommand.execute(CallCommand.java:79)
		at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
		at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
		at java.lang.Thread.run(Thread.java:750)
	
	24/04/23 11:22:14 INFO MemoryStore: MemoryStore cleared
	24/04/23 11:22:14 INFO BlockManager: BlockManager stopped
	24/04/23 11:22:14 INFO BlockManagerMaster: BlockManagerMaster stopped
	24/04/23 11:22:14 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
[WI-0][TI-0] - [INFO] 2024-04-23 11:22:14.852 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8463687150837989 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:22:15.714 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:22:14 INFO ShutdownHookManager: Deleting directory /tmp/spark-0a777719-093b-4097-9596-859c32707bfd/pyspark-8111b764-b7e9-46e8-a839-0f83bbcecc2f
	24/04/23 11:22:14 INFO SparkContext: Successfully stopped SparkContext
	24/04/23 11:22:14 INFO ShutdownHookManager: Deleting directory /tmp/spark-0a777719-093b-4097-9596-859c32707bfd
	24/04/23 11:22:14 INFO ShutdownHookManager: Deleting directory /tmp/spark-7ae8b18a-737b-4b3f-9319-a7f2846683dc
[WI-491][TI-1156] - [INFO] 2024-04-23 11:22:15.723 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/491/1156, processId:3615 ,exitStatusCode:1 ,processWaitForStatus:true ,processExitValue:1
[WI-491][TI-1156] - [INFO] 2024-04-23 11:22:15.724 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-491][TI-1156] - [INFO] 2024-04-23 11:22:15.726 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-491][TI-1156] - [INFO] 2024-04-23 11:22:15.727 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-491][TI-1156] - [INFO] 2024-04-23 11:22:15.727 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-491][TI-1156] - [INFO] 2024-04-23 11:22:15.730 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: FAILURE to master : 172.18.1.1:1234
[WI-491][TI-1156] - [INFO] 2024-04-23 11:22:15.730 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-491][TI-1156] - [INFO] 2024-04-23 11:22:15.730 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/491/1156
[WI-491][TI-1156] - [INFO] 2024-04-23 11:22:15.731 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/491/1156
[WI-491][TI-1156] - [INFO] 2024-04-23 11:22:15.732 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-1156] - [INFO] 2024-04-23 11:22:15.739 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1156, processInstanceId=491, status=6, startTime=1713841665791, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/80/491/1156.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/491/1156, endTime=1713842535727, processId=3615, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1156] - [INFO] 2024-04-23 11:22:15.751 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1156, success=true)
[WI-0][TI-1156] - [INFO] 2024-04-23 11:22:15.752 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1156, processInstanceId=491, status=6, startTime=1713841665791, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/80/491/1156.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/491/1156, endTime=1713842535727, processId=3615, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713842535738)
[WI-0][TI-1156] - [INFO] 2024-04-23 11:22:15.753 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1156, success=true)
[WI-0][TI-1156] - [WARN] 2024-04-23 11:22:15.753 +0800 o.a.d.s.w.m.MessageRetryRunner:[139] - Retry send message to master error
java.util.ConcurrentModificationException: null
	at java.util.ArrayList$Itr.checkForComodification(ArrayList.java:911)
	at java.util.ArrayList$Itr.next(ArrayList.java:861)
	at org.apache.dolphinscheduler.server.worker.message.MessageRetryRunner.run(MessageRetryRunner.java:127)
[WI-0][TI-0] - [INFO] 2024-04-23 11:22:15.906 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7027777777777777 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:22:29.963 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1157, taskName=search for intake JSON files, firstSubmitTime=1713842549947, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.9:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=80, appIds=null, processInstanceId=492, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"processing"}], executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":""}],"rawScript":"# find 1 raw file in the folder\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\n\n# check if raw_file_dir is empty, then set raw_file_dir to null\nif [ -z \"$raw_file_dir\" ]; then\n    raw_file_dir=null\nfi\n\necho \"#{setValue(raw_file_dir=${raw_file_dir})}\"","resourceList":[]}, environmentConfig=export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='search for intake JSON files'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240423'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1157'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13340113777664'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240423112229'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='processing'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='492'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240422'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=null, dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-492][TI-1157] - [INFO] 2024-04-23 11:22:29.966 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: search for intake JSON files to wait queue success
[WI-492][TI-1157] - [INFO] 2024-04-23 11:22:29.972 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-492][TI-1157] - [INFO] 2024-04-23 11:22:29.975 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-492][TI-1157] - [INFO] 2024-04-23 11:22:29.975 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-492][TI-1157] - [INFO] 2024-04-23 11:22:29.975 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-492][TI-1157] - [INFO] 2024-04-23 11:22:29.976 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713842549976
[WI-492][TI-1157] - [INFO] 2024-04-23 11:22:29.976 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 492_1157
[WI-492][TI-1157] - [INFO] 2024-04-23 11:22:29.976 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1157,
  "taskName" : "search for intake JSON files",
  "firstSubmitTime" : 1713842549947,
  "startTime" : 1713842549976,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.9:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240423/13201021801792/80/492/1157.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 80,
  "processInstanceId" : 492,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"processing\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[{\"prop\":\"raw_file_dir\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"\"}],\"rawScript\":\"# find 1 raw file in the folder\\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\\n\\n# check if raw_file_dir is empty, then set raw_file_dir to null\\nif [ -z \\\"$raw_file_dir\\\" ]; then\\n    raw_file_dir=null\\nfi\\n\\necho \\\"#{setValue(raw_file_dir=${raw_file_dir})}\\\"\",\"resourceList\":[]}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "search for intake JSON files"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1157"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13340113777664"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423112229"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "processing"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "492"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240422"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "492_1157",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-492][TI-1157] - [INFO] 2024-04-23 11:22:29.977 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-492][TI-1157] - [INFO] 2024-04-23 11:22:29.978 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-492][TI-1157] - [INFO] 2024-04-23 11:22:29.978 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-492][TI-1157] - [INFO] 2024-04-23 11:22:29.989 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-492][TI-1157] - [INFO] 2024-04-23 11:22:29.996 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-492][TI-1157] - [INFO] 2024-04-23 11:22:29.997 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/492/1157 check successfully
[WI-492][TI-1157] - [INFO] 2024-04-23 11:22:29.997 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-492][TI-1157] - [INFO] 2024-04-23 11:22:29.997 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-492][TI-1157] - [INFO] 2024-04-23 11:22:29.998 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-492][TI-1157] - [INFO] 2024-04-23 11:22:29.998 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-492][TI-1157] - [INFO] 2024-04-23 11:22:29.998 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ {
    "prop" : "raw_file_dir",
    "direct" : "OUT",
    "type" : "VARCHAR",
    "value" : ""
  } ],
  "varPool" : null,
  "rawScript" : "# find 1 raw file in the folder\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\n\n# check if raw_file_dir is empty, then set raw_file_dir to null\nif [ -z \"$raw_file_dir\" ]; then\n    raw_file_dir=null\nfi\n\necho \"#{setValue(raw_file_dir=${raw_file_dir})}\"",
  "resourceList" : [ ]
}
[WI-492][TI-1157] - [INFO] 2024-04-23 11:22:29.998 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-492][TI-1157] - [INFO] 2024-04-23 11:22:29.998 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: null successfully
[WI-492][TI-1157] - [INFO] 2024-04-23 11:22:29.998 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-492][TI-1157] - [INFO] 2024-04-23 11:22:29.998 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-492][TI-1157] - [INFO] 2024-04-23 11:22:29.999 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-492][TI-1157] - [INFO] 2024-04-23 11:22:30.000 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-492][TI-1157] - [INFO] 2024-04-23 11:22:30.002 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-492][TI-1157] - [INFO] 2024-04-23 11:22:30.002 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export PYTHON_LAUNCHER=/bin/python3.11
# find 1 raw file in the folder
raw_file_dir=$(find /local_storage/reddit/processing -type f -name '*.json'| head -n 1)

# check if raw_file_dir is empty, then set raw_file_dir to null
if [ -z "$raw_file_dir" ]; then
    raw_file_dir=null
fi

echo "#{setValue(raw_file_dir=${raw_file_dir})}"
[WI-492][TI-1157] - [INFO] 2024-04-23 11:22:30.002 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-492][TI-1157] - [INFO] 2024-04-23 11:22:30.003 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/492/1157/492_1157.sh
[WI-492][TI-1157] - [INFO] 2024-04-23 11:22:30.015 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 3954
[WI-0][TI-1157] - [INFO] 2024-04-23 11:22:30.772 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1157, success=true)
[WI-0][TI-1157] - [INFO] 2024-04-23 11:22:30.775 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionInfoEvent(taskInstanceId=1157, processInstanceId=492, startTime=1713842549976, workflowInstanceHost=172.18.0.9:5678, taskInstanceHost=172.18.1.1:1234, logPath=null, processId=0, eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1157] - [INFO] 2024-04-23 11:22:30.778 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionInfoEvent(taskInstanceId=1157, processInstanceId=492, startTime=1713842549976, workflowInstanceHost=172.18.0.9:5678, taskInstanceHost=172.18.1.1:1234, logPath=null, processId=0, eventCreateTime=0, eventSendTime=1713842550775)
[WI-0][TI-1157] - [INFO] 2024-04-23 11:22:30.779 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1157)
[WI-0][TI-1157] - [INFO] 2024-04-23 11:22:30.784 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1157)
[WI-0][TI-0] - [INFO] 2024-04-23 11:22:31.015 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
	#{setValue(raw_file_dir=/local_storage/reddit/processing/386-20240422.json)}
[WI-492][TI-1157] - [INFO] 2024-04-23 11:22:31.019 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/492/1157, processId:3954 ,exitStatusCode:0 ,processWaitForStatus:true ,processExitValue:0
[WI-492][TI-1157] - [INFO] 2024-04-23 11:22:31.019 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-492][TI-1157] - [INFO] 2024-04-23 11:22:31.020 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-492][TI-1157] - [INFO] 2024-04-23 11:22:31.020 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-492][TI-1157] - [INFO] 2024-04-23 11:22:31.020 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-492][TI-1157] - [INFO] 2024-04-23 11:22:31.024 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: SUCCESS to master : 172.18.1.1:1234
[WI-492][TI-1157] - [INFO] 2024-04-23 11:22:31.025 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-492][TI-1157] - [INFO] 2024-04-23 11:22:31.025 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/492/1157
[WI-492][TI-1157] - [INFO] 2024-04-23 11:22:31.026 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/492/1157
[WI-492][TI-1157] - [INFO] 2024-04-23 11:22:31.026 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-1157] - [INFO] 2024-04-23 11:22:31.768 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1157, success=true)
[WI-0][TI-0] - [INFO] 2024-04-23 11:22:31.956 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.715099715099715 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:22:32.885 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1159, taskName=move to processing, firstSubmitTime=1713842552872, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.9:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=80, appIds=null, processInstanceId=492, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"processing"}], executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":""}],"rawScript":"# move file to the reddit processing folder\n# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error\nfilename=$(basename \"${raw_file_dir}\")\nif ! grep -q \"${REDDIT_HOME}/processing\" <<< \"${raw_file_dir}\"; then\n    mv ${raw_file_dir} ${REDDIT_HOME}/processing\nelse\n    echo JSON is already in processing\nfi\n\n# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing\necho \"#{setValue(raw_file_dir=${REDDIT_HOME}/processing/${filename})}\"","resourceList":[]}, environmentConfig=export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='move to processing'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240423'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1159'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13340390094208'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240423112232'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='processing'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='492'}, raw_file_dir=Property{prop='raw_file_dir', direct=IN, type=VARCHAR, value='/local_storage/reddit/processing/386-20240422.json'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240422'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-492][TI-1159] - [INFO] 2024-04-23 11:22:32.889 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: move to processing to wait queue success
[WI-492][TI-1159] - [INFO] 2024-04-23 11:22:32.890 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-492][TI-1159] - [INFO] 2024-04-23 11:22:32.892 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-492][TI-1159] - [INFO] 2024-04-23 11:22:32.892 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-492][TI-1159] - [INFO] 2024-04-23 11:22:32.892 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-492][TI-1159] - [INFO] 2024-04-23 11:22:32.892 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713842552892
[WI-492][TI-1159] - [INFO] 2024-04-23 11:22:32.892 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 492_1159
[WI-492][TI-1159] - [INFO] 2024-04-23 11:22:32.892 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1159,
  "taskName" : "move to processing",
  "firstSubmitTime" : 1713842552872,
  "startTime" : 1713842552892,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.9:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240423/13201021801792/80/492/1159.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 80,
  "processInstanceId" : 492,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"processing\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[{\"prop\":\"raw_file_dir\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"\"}],\"rawScript\":\"# move file to the reddit processing folder\\n# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error\\nfilename=$(basename \\\"${raw_file_dir}\\\")\\nif ! grep -q \\\"${REDDIT_HOME}/processing\\\" <<< \\\"${raw_file_dir}\\\"; then\\n    mv ${raw_file_dir} ${REDDIT_HOME}/processing\\nelse\\n    echo JSON is already in processing\\nfi\\n\\n# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing\\necho \\\"#{setValue(raw_file_dir=${REDDIT_HOME}/processing/${filename})}\\\"\",\"resourceList\":[]}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "move to processing"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1159"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13340390094208"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423112232"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "processing"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "492"
    },
    "raw_file_dir" : {
      "prop" : "raw_file_dir",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit/processing/386-20240422.json"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240422"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "492_1159",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"raw_file_dir\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"/local_storage/reddit/processing/386-20240422.json\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-492][TI-1159] - [INFO] 2024-04-23 11:22:32.893 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-492][TI-1159] - [INFO] 2024-04-23 11:22:32.894 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-492][TI-1159] - [INFO] 2024-04-23 11:22:32.894 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-492][TI-1159] - [INFO] 2024-04-23 11:22:32.895 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-492][TI-1159] - [INFO] 2024-04-23 11:22:32.896 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-492][TI-1159] - [INFO] 2024-04-23 11:22:32.896 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/492/1159 check successfully
[WI-492][TI-1159] - [INFO] 2024-04-23 11:22:32.896 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-492][TI-1159] - [INFO] 2024-04-23 11:22:32.896 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-492][TI-1159] - [INFO] 2024-04-23 11:22:32.897 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-492][TI-1159] - [INFO] 2024-04-23 11:22:32.897 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-492][TI-1159] - [INFO] 2024-04-23 11:22:32.897 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ {
    "prop" : "raw_file_dir",
    "direct" : "OUT",
    "type" : "VARCHAR",
    "value" : ""
  } ],
  "varPool" : null,
  "rawScript" : "# move file to the reddit processing folder\n# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error\nfilename=$(basename \"${raw_file_dir}\")\nif ! grep -q \"${REDDIT_HOME}/processing\" <<< \"${raw_file_dir}\"; then\n    mv ${raw_file_dir} ${REDDIT_HOME}/processing\nelse\n    echo JSON is already in processing\nfi\n\n# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing\necho \"#{setValue(raw_file_dir=${REDDIT_HOME}/processing/${filename})}\"",
  "resourceList" : [ ]
}
[WI-492][TI-1159] - [INFO] 2024-04-23 11:22:32.897 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-492][TI-1159] - [INFO] 2024-04-23 11:22:32.897 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}] successfully
[WI-492][TI-1159] - [INFO] 2024-04-23 11:22:32.897 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-492][TI-1159] - [INFO] 2024-04-23 11:22:32.897 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-492][TI-1159] - [INFO] 2024-04-23 11:22:32.897 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-492][TI-1159] - [INFO] 2024-04-23 11:22:32.898 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-492][TI-1159] - [INFO] 2024-04-23 11:22:32.898 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-492][TI-1159] - [INFO] 2024-04-23 11:22:32.898 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export PYTHON_LAUNCHER=/bin/python3.11
# move file to the reddit processing folder
# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error
filename=$(basename "/local_storage/reddit/processing/386-20240422.json")
if ! grep -q "/local_storage/reddit/processing" <<< "/local_storage/reddit/processing/386-20240422.json"; then
    mv /local_storage/reddit/processing/386-20240422.json /local_storage/reddit/processing
else
    echo JSON is already in processing
fi

# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing
echo "#{setValue(raw_file_dir=/local_storage/reddit/processing/${filename})}"
[WI-492][TI-1159] - [INFO] 2024-04-23 11:22:32.898 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-492][TI-1159] - [INFO] 2024-04-23 11:22:32.898 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/492/1159/492_1159.sh
[WI-492][TI-1159] - [INFO] 2024-04-23 11:22:32.906 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 3967
[WI-0][TI-1159] - [INFO] 2024-04-23 11:22:33.791 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionRunningEvent(taskInstanceId=1159, processInstanceId=492, startTime=1713842552892, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, status=TaskExecutionStatus{code=1, desc='running'}, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/80/492/1159.log, executePath=null, processId=0, appIds=null, eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1159] - [INFO] 2024-04-23 11:22:33.792 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1159, success=true)
[WI-0][TI-1159] - [INFO] 2024-04-23 11:22:33.809 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1159)
[WI-0][TI-1159] - [INFO] 2024-04-23 11:22:33.809 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionRunningEvent(taskInstanceId=1159, processInstanceId=492, startTime=1713842552892, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, status=TaskExecutionStatus{code=1, desc='running'}, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/80/492/1159.log, executePath=null, processId=0, appIds=null, eventCreateTime=0, eventSendTime=1713842553784)
[WI-0][TI-1159] - [WARN] 2024-04-23 11:22:33.810 +0800 o.a.d.s.w.m.MessageRetryRunner:[139] - Retry send message to master error
java.util.ConcurrentModificationException: null
	at java.util.ArrayList$Itr.checkForComodification(ArrayList.java:911)
	at java.util.ArrayList$Itr.next(ArrayList.java:861)
	at org.apache.dolphinscheduler.server.worker.message.MessageRetryRunner.run(MessageRetryRunner.java:127)
[WI-0][TI-1159] - [INFO] 2024-04-23 11:22:33.833 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1159, success=true)
[WI-0][TI-0] - [INFO] 2024-04-23 11:22:33.906 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
	JSON is already in processing
	#{setValue(raw_file_dir=/local_storage/reddit/processing/386-20240422.json)}
[WI-492][TI-1159] - [INFO] 2024-04-23 11:22:33.923 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/492/1159, processId:3967 ,exitStatusCode:0 ,processWaitForStatus:true ,processExitValue:0
[WI-492][TI-1159] - [INFO] 2024-04-23 11:22:33.923 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-492][TI-1159] - [INFO] 2024-04-23 11:22:33.923 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-492][TI-1159] - [INFO] 2024-04-23 11:22:33.924 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-492][TI-1159] - [INFO] 2024-04-23 11:22:33.924 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-492][TI-1159] - [INFO] 2024-04-23 11:22:33.928 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: SUCCESS to master : 172.18.1.1:1234
[WI-492][TI-1159] - [INFO] 2024-04-23 11:22:33.928 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-492][TI-1159] - [INFO] 2024-04-23 11:22:33.928 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/492/1159
[WI-492][TI-1159] - [INFO] 2024-04-23 11:22:33.929 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/492/1159
[WI-492][TI-1159] - [INFO] 2024-04-23 11:22:33.929 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-0] - [INFO] 2024-04-23 11:22:33.981 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.736986301369863 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-1159] - [INFO] 2024-04-23 11:22:34.794 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1159, success=true)
[WI-0][TI-0] - [INFO] 2024-04-23 11:22:34.908 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1160, taskName=spark preprocessing, firstSubmitTime=1713842554897, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.9:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=80, appIds=null, processInstanceId=492, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"processing"}], executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[],"rawScript":"$SPARK_HOME/bin/spark-submit \\\n    --master spark://spark-master:7077 \\\n    --conf spark.driver.cores=2 \\\n    --conf spark.driver.memory=2G \\\n    --conf spark.executor.instances=1 \\\n    --conf spark.executor.cores=2 \\\n    --conf spark.executor.memory=2G \\\n    --files ${raw_file_dir} \\\n    --name reddit_preprocessing spark_reddit_preprocessing.py\n","resourceList":[{"id":null,"resourceName":"file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py","res":null}]}, environmentConfig=export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export HADOOP_CONF_DIR=/opt/hadoop-3.4.0/etc/hadoop
export PYSPARK_DRIVER_PYTHON=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='spark preprocessing'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240423'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1160'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13210058002752'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240423112234'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='processing'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='492'}, raw_file_dir=Property{prop='raw_file_dir', direct=IN, type=VARCHAR, value='/local_storage/reddit/processing/386-20240422.json'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240422'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-492][TI-1160] - [INFO] 2024-04-23 11:22:34.910 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: spark preprocessing to wait queue success
[WI-492][TI-1160] - [INFO] 2024-04-23 11:22:34.911 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-492][TI-1160] - [INFO] 2024-04-23 11:22:34.915 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-492][TI-1160] - [INFO] 2024-04-23 11:22:34.915 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-492][TI-1160] - [INFO] 2024-04-23 11:22:34.915 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-492][TI-1160] - [INFO] 2024-04-23 11:22:34.915 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713842554915
[WI-492][TI-1160] - [INFO] 2024-04-23 11:22:34.915 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 492_1160
[WI-492][TI-1160] - [INFO] 2024-04-23 11:22:34.916 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1160,
  "taskName" : "spark preprocessing",
  "firstSubmitTime" : 1713842554897,
  "startTime" : 1713842554915,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.9:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240423/13201021801792/80/492/1160.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 80,
  "processInstanceId" : 492,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"processing\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[],\"rawScript\":\"$SPARK_HOME/bin/spark-submit \\\\\\n    --master spark://spark-master:7077 \\\\\\n    --conf spark.driver.cores=2 \\\\\\n    --conf spark.driver.memory=2G \\\\\\n    --conf spark.executor.instances=1 \\\\\\n    --conf spark.executor.cores=2 \\\\\\n    --conf spark.executor.memory=2G \\\\\\n    --files ${raw_file_dir} \\\\\\n    --name reddit_preprocessing spark_reddit_preprocessing.py\\n\",\"resourceList\":[{\"id\":null,\"resourceName\":\"file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py\",\"res\":null}]}",
  "environmentConfig" : "export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3\nexport JAVA_HOME=/opt/java/openjdk\nexport HADOOP_CONF_DIR=/opt/hadoop-3.4.0/etc/hadoop\nexport PYSPARK_DRIVER_PYTHON=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "spark preprocessing"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1160"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13210058002752"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423112234"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "processing"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "492"
    },
    "raw_file_dir" : {
      "prop" : "raw_file_dir",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit/processing/386-20240422.json"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240422"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "492_1160",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"raw_file_dir\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"/local_storage/reddit/processing/386-20240422.json\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-492][TI-1160] - [INFO] 2024-04-23 11:22:34.916 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-492][TI-1160] - [INFO] 2024-04-23 11:22:34.916 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-492][TI-1160] - [INFO] 2024-04-23 11:22:34.916 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-492][TI-1160] - [INFO] 2024-04-23 11:22:34.921 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-492][TI-1160] - [INFO] 2024-04-23 11:22:34.923 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-492][TI-1160] - [INFO] 2024-04-23 11:22:34.923 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/492/1160 check successfully
[WI-492][TI-1160] - [INFO] 2024-04-23 11:22:34.923 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-492][TI-1160] - [INFO] 2024-04-23 11:22:34.925 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py=ResourceContext.ResourceItem(resourceAbsolutePathInStorage=file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py, resourceRelativePath=spark_reddit_preprocessing.py, resourceAbsolutePathInLocal=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/492/1160/spark_reddit_preprocessing.py)})
[WI-492][TI-1160] - [INFO] 2024-04-23 11:22:34.926 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-492][TI-1160] - [INFO] 2024-04-23 11:22:34.926 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-492][TI-1160] - [INFO] 2024-04-23 11:22:34.926 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ ],
  "varPool" : null,
  "rawScript" : "$SPARK_HOME/bin/spark-submit \\\n    --master spark://spark-master:7077 \\\n    --conf spark.driver.cores=2 \\\n    --conf spark.driver.memory=2G \\\n    --conf spark.executor.instances=1 \\\n    --conf spark.executor.cores=2 \\\n    --conf spark.executor.memory=2G \\\n    --files ${raw_file_dir} \\\n    --name reddit_preprocessing spark_reddit_preprocessing.py\n",
  "resourceList" : [ {
    "id" : null,
    "resourceName" : "file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py",
    "res" : null
  } ]
}
[WI-492][TI-1160] - [INFO] 2024-04-23 11:22:34.926 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-492][TI-1160] - [INFO] 2024-04-23 11:22:34.927 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}] successfully
[WI-492][TI-1160] - [INFO] 2024-04-23 11:22:34.927 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-492][TI-1160] - [INFO] 2024-04-23 11:22:34.927 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-492][TI-1160] - [INFO] 2024-04-23 11:22:34.927 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-492][TI-1160] - [INFO] 2024-04-23 11:22:34.932 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-492][TI-1160] - [INFO] 2024-04-23 11:22:34.932 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-492][TI-1160] - [INFO] 2024-04-23 11:22:34.932 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export HADOOP_CONF_DIR=/opt/hadoop-3.4.0/etc/hadoop
export PYSPARK_DRIVER_PYTHON=/bin/python3.11
$SPARK_HOME/bin/spark-submit \
    --master spark://spark-master:7077 \
    --conf spark.driver.cores=2 \
    --conf spark.driver.memory=2G \
    --conf spark.executor.instances=1 \
    --conf spark.executor.cores=2 \
    --conf spark.executor.memory=2G \
    --files /local_storage/reddit/processing/386-20240422.json \
    --name reddit_preprocessing spark_reddit_preprocessing.py

[WI-492][TI-1160] - [INFO] 2024-04-23 11:22:34.932 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-492][TI-1160] - [INFO] 2024-04-23 11:22:34.932 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/492/1160/492_1160.sh
[WI-492][TI-1160] - [INFO] 2024-04-23 11:22:34.944 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 3979
[WI-0][TI-0] - [INFO] 2024-04-23 11:22:34.945 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
[WI-0][TI-0] - [INFO] 2024-04-23 11:22:35.009 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7756756756756756 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-1160] - [INFO] 2024-04-23 11:22:35.788 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1160, success=true)
[WI-0][TI-1160] - [INFO] 2024-04-23 11:22:35.807 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1160)
[WI-0][TI-0] - [INFO] 2024-04-23 11:22:36.017 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8782608695652174 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:22:37.018 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7619047619047619 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:22:38.199 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:22:37 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[WI-0][TI-0] - [INFO] 2024-04-23 11:22:39.214 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:22:38 INFO SparkContext: Running Spark version 3.5.1
	24/04/23 11:22:38 INFO SparkContext: OS info Linux, 6.5.0-28-generic, amd64
	24/04/23 11:22:38 INFO SparkContext: Java version 1.8.0_402
	24/04/23 11:22:38 INFO ResourceUtils: ==============================================================
	24/04/23 11:22:38 INFO ResourceUtils: No custom resources configured for spark.driver.
	24/04/23 11:22:38 INFO ResourceUtils: ==============================================================
	24/04/23 11:22:38 INFO SparkContext: Submitted application: reddit_preprocessing
	24/04/23 11:22:38 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 2, script: , vendor: , memory -> name: memory, amount: 2048, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
	24/04/23 11:22:38 INFO ResourceProfile: Limiting resource is cpus at 2 tasks per executor
	24/04/23 11:22:38 INFO ResourceProfileManager: Added ResourceProfile id: 0
	24/04/23 11:22:38 INFO SecurityManager: Changing view acls to: default
	24/04/23 11:22:38 INFO SecurityManager: Changing modify acls to: default
	24/04/23 11:22:38 INFO SecurityManager: Changing view acls groups to: 
	24/04/23 11:22:38 INFO SecurityManager: Changing modify acls groups to: 
	24/04/23 11:22:38 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: default; groups with view permissions: EMPTY; users with modify permissions: default; groups with modify permissions: EMPTY
	24/04/23 11:22:39 INFO Utils: Successfully started service 'sparkDriver' on port 46471.
	24/04/23 11:22:39 INFO SparkEnv: Registering MapOutputTracker
	24/04/23 11:22:39 INFO SparkEnv: Registering BlockManagerMaster
	24/04/23 11:22:39 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
	24/04/23 11:22:39 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
	24/04/23 11:22:39 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
[WI-0][TI-0] - [INFO] 2024-04-23 11:22:40.215 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:22:39 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-216b25f9-8322-4a4a-a340-5a547305c816
	24/04/23 11:22:39 INFO MemoryStore: MemoryStore started with capacity 912.3 MiB
	24/04/23 11:22:39 INFO SparkEnv: Registering OutputCommitCoordinator
	24/04/23 11:22:39 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
	24/04/23 11:22:39 INFO Utils: Successfully started service 'SparkUI' on port 4040.
	24/04/23 11:22:39 INFO SparkContext: Added file file:///local_storage/reddit/processing/386-20240422.json at spark://c0e814e3f0bd:46471/files/386-20240422.json with timestamp 1713842558339
	24/04/23 11:22:39 INFO Utils: Copying /local_storage/reddit/processing/386-20240422.json to /tmp/spark-fd06c2a3-05bb-47c7-a8c4-eacf88f91fc6/userFiles-7b315c0a-4169-40bd-9e9f-db81100259de/386-20240422.json
	24/04/23 11:22:39 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
	24/04/23 11:22:39 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.3:7077 after 117 ms (0 ms spent in bootstraps)
	24/04/23 11:22:40 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20240423032239-0014
	24/04/23 11:22:40 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20240423032239-0014/0 on worker-20240423012857-172.18.0.7-41063 (172.18.0.7:41063) with 2 core(s)
	24/04/23 11:22:40 INFO StandaloneSchedulerBackend: Granted executor ID app-20240423032239-0014/0 on hostPort 172.18.0.7:41063 with 2 core(s), 2.0 GiB RAM
	24/04/23 11:22:40 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33861.
	24/04/23 11:22:40 INFO NettyBlockTransferService: Server created on c0e814e3f0bd:33861
	24/04/23 11:22:40 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
	24/04/23 11:22:40 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, c0e814e3f0bd, 33861, None)
	24/04/23 11:22:40 INFO BlockManagerMasterEndpoint: Registering block manager c0e814e3f0bd:33861 with 912.3 MiB RAM, BlockManagerId(driver, c0e814e3f0bd, 33861, None)
	24/04/23 11:22:40 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, c0e814e3f0bd, 33861, None)
	24/04/23 11:22:40 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, c0e814e3f0bd, 33861, None)
	24/04/23 11:22:40 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20240423032239-0014/0 is now RUNNING
[WI-0][TI-0] - [INFO] 2024-04-23 11:22:40.234 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7111801242236024 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:22:41.219 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:22:40 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
	
	
	
	 /tmp/spark-fd06c2a3-05bb-47c7-a8c4-eacf88f91fc6/userFiles-7b315c0a-4169-40bd-9e9f-db81100259de/386-20240422.json 
	
	
	
	24/04/23 11:22:40 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
	24/04/23 11:22:40 INFO SharedState: Warehouse path is 'file:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/492/1160/spark-warehouse'.
[WI-0][TI-0] - [INFO] 2024-04-23 11:22:41.250 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.833976833976834 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:22:42.258 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8636363636363636 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:22:43.242 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:22:42 INFO InMemoryFileIndex: It took 56 ms to list leaf files for 1 paths.
	24/04/23 11:22:42 INFO InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.
[WI-0][TI-0] - [INFO] 2024-04-23 11:22:43.264 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9384615384615385 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:22:44.273 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.857566765578635 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:22:45.300 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:22:44 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.7:52240) with ID 0,  ResourceProfileId 0
	24/04/23 11:22:44 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.7:37781 with 1048.8 MiB RAM, BlockManagerId(0, 172.18.0.7, 37781, None)
[WI-0][TI-0] - [INFO] 2024-04-23 11:22:45.305 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.803347280334728 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:22:47.346 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:22:46 INFO FileSourceStrategy: Pushed Filters: 
	24/04/23 11:22:46 INFO FileSourceStrategy: Post-Scan Filters: 
	24/04/23 11:22:46 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 351.5 KiB, free 912.0 MiB)
	24/04/23 11:22:46 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 34.7 KiB, free 911.9 MiB)
	24/04/23 11:22:46 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on c0e814e3f0bd:33861 (size: 34.7 KiB, free: 912.3 MiB)
	24/04/23 11:22:46 INFO SparkContext: Created broadcast 0 from load at NativeMethodAccessorImpl.java:0
	24/04/23 11:22:46 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
	24/04/23 11:22:46 INFO SparkContext: Starting job: load at NativeMethodAccessorImpl.java:0
	24/04/23 11:22:47 INFO DAGScheduler: Got job 0 (load at NativeMethodAccessorImpl.java:0) with 1 output partitions
	24/04/23 11:22:47 INFO DAGScheduler: Final stage: ResultStage 0 (load at NativeMethodAccessorImpl.java:0)
	24/04/23 11:22:47 INFO DAGScheduler: Parents of final stage: List()
	24/04/23 11:22:47 INFO DAGScheduler: Missing parents: List()
	24/04/23 11:22:47 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at load at NativeMethodAccessorImpl.java:0), which has no missing parents
	24/04/23 11:22:47 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 16.5 KiB, free 911.9 MiB)
	24/04/23 11:22:47 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.8 KiB, free 911.9 MiB)
	24/04/23 11:22:47 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on c0e814e3f0bd:33861 (size: 7.8 KiB, free: 912.3 MiB)
	24/04/23 11:22:47 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1585
	24/04/23 11:22:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at load at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
	24/04/23 11:22:47 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
	24/04/23 11:22:47 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.7, executor 0, partition 0, PROCESS_LOCAL, 8478 bytes) 
[WI-0][TI-1123] - [INFO] 2024-04-23 11:24:50.678 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1123, processInstanceId=487, status=9, startTime=1713838208504, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1123.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1123, endTime=1713838483436, processId=1677, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713842389856)
[WI-0][TI-1123] - [INFO] 2024-04-23 11:24:50.680 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1123, processInstanceId=487, status=9, startTime=1713838208504, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1123.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1123, endTime=1713838483436, processId=1677, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713842690677)
[WI-0][TI-1111] - [INFO] 2024-04-23 11:24:52.695 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1111, processInstanceId=487, status=9, startTime=1713837256404, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1111.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1111, endTime=1713838170352, processId=1017, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713842391863)
[WI-0][TI-1111] - [INFO] 2024-04-23 11:24:52.701 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1111, processInstanceId=487, status=9, startTime=1713837256404, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1111.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1111, endTime=1713838170352, processId=1017, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713842692695)
[WI-0][TI-0] - [INFO] 2024-04-23 11:26:49.294 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8347107438016528 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:26:50.316 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7109826589595376 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:26:51.323 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8413597733711048 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:26:54.334 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7851239669421488 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-1144] - [INFO] 2024-04-23 11:27:14.336 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1144, processInstanceId=489, status=9, startTime=1713840953087, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/80/489/1144.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1144, endTime=1713841331355, processId=3026, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713842533728)
[WI-0][TI-1144] - [INFO] 2024-04-23 11:27:14.342 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1144, processInstanceId=489, status=9, startTime=1713840953087, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/80/489/1144.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1144, endTime=1713841331355, processId=3026, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713842834336)
[WI-0][TI-0] - [INFO] 2024-04-23 11:28:06.439 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:28:06 ERROR StandaloneSchedulerBackend: Application has been killed. Reason: Master removed our application: KILLED
	24/04/23 11:28:06 INFO TaskSchedulerImpl: Cancelling stage 0
	24/04/23 11:28:06 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage cancelled: Job aborted due to stage failure: Master removed our application: KILLED
	24/04/23 11:28:06 INFO SparkContext: SparkContext is stopping with exitCode 0.
	24/04/23 11:28:06 INFO TaskSchedulerImpl: Stage 0 was cancelled
	24/04/23 11:28:06 INFO DAGScheduler: ResultStage 0 (load at NativeMethodAccessorImpl.java:0) failed in 319.156 s due to Job aborted due to stage failure: Master removed our application: KILLED
	24/04/23 11:28:06 INFO DAGScheduler: Job 0 failed: load at NativeMethodAccessorImpl.java:0, took 319.278993 s
	24/04/23 11:28:06 INFO SparkUI: Stopped Spark web UI at http://c0e814e3f0bd:4040
	24/04/23 11:28:06 INFO StandaloneSchedulerBackend: Shutting down all executors
	24/04/23 11:28:06 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Asking each executor to shut down
[WI-0][TI-0] - [INFO] 2024-04-23 11:28:07.499 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:28:06 ERROR Utils: Uncaught exception in thread stop-spark-context
	org.apache.spark.SparkException: Exception thrown in awaitResult: 
		at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
		at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
		at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
		at org.apache.spark.deploy.client.StandaloneAppClient.stop(StandaloneAppClient.scala:288)
		at org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend.org$apache$spark$scheduler$cluster$StandaloneSchedulerBackend$$stop(StandaloneSchedulerBackend.scala:275)
		at org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend.stop(StandaloneSchedulerBackend.scala:142)
		at org.apache.spark.scheduler.SchedulerBackend.stop(SchedulerBackend.scala:33)
		at org.apache.spark.scheduler.SchedulerBackend.stop$(SchedulerBackend.scala:33)
		at org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend.stop(CoarseGrainedSchedulerBackend.scala:54)
		at org.apache.spark.scheduler.TaskSchedulerImpl.$anonfun$stop$2(TaskSchedulerImpl.scala:992)
		at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1375)
		at org.apache.spark.scheduler.TaskSchedulerImpl.stop(TaskSchedulerImpl.scala:992)
		at org.apache.spark.scheduler.DAGScheduler.$anonfun$stop$4(DAGScheduler.scala:2976)
		at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1375)
		at org.apache.spark.scheduler.DAGScheduler.stop(DAGScheduler.scala:2976)
		at org.apache.spark.SparkContext.$anonfun$stop$12(SparkContext.scala:2263)
		at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1375)
		at org.apache.spark.SparkContext.stop(SparkContext.scala:2263)
		at org.apache.spark.SparkContext.stop(SparkContext.scala:2216)
		at org.apache.spark.SparkContext$$anon$3.run(SparkContext.scala:2203)
	Caused by: org.apache.spark.SparkException: Could not find AppClient.
		at org.apache.spark.rpc.netty.Dispatcher.postMessage(Dispatcher.scala:178)
		at org.apache.spark.rpc.netty.Dispatcher.postLocalMessage(Dispatcher.scala:144)
		at org.apache.spark.rpc.netty.NettyRpcEnv.askAbortable(NettyRpcEnv.scala:242)
		at org.apache.spark.rpc.netty.NettyRpcEndpointRef.askAbortable(NettyRpcEnv.scala:554)
		at org.apache.spark.rpc.netty.NettyRpcEndpointRef.ask(NettyRpcEnv.scala:558)
		at org.apache.spark.rpc.RpcEndpointRef.ask(RpcEndpointRef.scala:72)
		... 17 more
	24/04/23 11:28:06 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
	Traceback (most recent call last):
	  File "/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/492/1160/spark_reddit_preprocessing.py", line 48, in <module>
	    raw_df = spark.read.format('json').load(
	             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
	  File "/opt/spark-3.5.1-bin-hadoop3/python/lib/pyspark.zip/pyspark/sql/readwriter.py", line 307, in load
	  File "/opt/spark-3.5.1-bin-hadoop3/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
	  File "/opt/spark-3.5.1-bin-hadoop3/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 179, in deco
	  File "/opt/spark-3.5.1-bin-hadoop3/python/lib/py4j-0.10.9.7-src.zip/py4j/protocol.py", line 326, in get_return_value
	py4j.protocol.Py4JJavaError: An error occurred while calling o33.load.
	: org.apache.spark.SparkException: Job aborted due to stage failure: Master removed our application: KILLED
		at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)
		at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)
		at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)
		at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
		at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
		at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
		at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)
		at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)
		at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)
		at scala.Option.foreach(Option.scala:407)
		at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)
		at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)
		at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)
		at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)
		at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
		at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:989)
		at org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)
		at org.apache.spark.SparkContext.runJob(SparkContext.scala:2493)
		at org.apache.spark.sql.catalyst.json.JsonInferSchema.infer(JsonInferSchema.scala:120)
		at org.apache.spark.sql.execution.datasources.json.TextInputJsonDataSource$.$anonfun$inferFromDataset$5(JsonDataSource.scala:109)
		at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)
		at org.apache.spark.sql.execution.datasources.json.TextInputJsonDataSource$.inferFromDataset(JsonDataSource.scala:109)
		at org.apache.spark.sql.execution.datasources.json.TextInputJsonDataSource$.infer(JsonDataSource.scala:98)
		at org.apache.spark.sql.execution.datasources.json.JsonDataSource.inferSchema(JsonDataSource.scala:64)
		at org.apache.spark.sql.execution.datasources.json.JsonFileFormat.inferSchema(JsonFileFormat.scala:59)
		at org.apache.spark.sql.execution.datasources.DataSource.$anonfun$getOrInferFileFormatSchema$11(DataSource.scala:208)
		at scala.Option.orElse(Option.scala:447)
		at org.apache.spark.sql.execution.datasources.DataSource.getOrInferFileFormatSchema(DataSource.scala:205)
		at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:407)
		at org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)
		at org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)
		at scala.Option.getOrElse(Option.scala:189)
		at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)
		at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:186)
		at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
		at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
		at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
		at java.lang.reflect.Method.invoke(Method.java:498)
		at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
		at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
		at py4j.Gateway.invoke(Gateway.java:282)
		at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
		at py4j.commands.CallCommand.execute(CallCommand.java:79)
		at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
		at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
		at java.lang.Thread.run(Thread.java:750)
	
	24/04/23 11:28:06 INFO MemoryStore: MemoryStore cleared
	24/04/23 11:28:06 INFO BlockManager: BlockManager stopped
	24/04/23 11:28:06 INFO BlockManagerMaster: BlockManagerMaster stopped
	24/04/23 11:28:06 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
	24/04/23 11:28:06 INFO ShutdownHookManager: Shutdown hook called
	24/04/23 11:28:06 INFO ShutdownHookManager: Deleting directory /tmp/spark-fd06c2a3-05bb-47c7-a8c4-eacf88f91fc6/pyspark-301377d6-c374-4d53-a310-003db7d4a62f
	24/04/23 11:28:07 INFO SparkContext: Successfully stopped SparkContext
	24/04/23 11:28:07 INFO ShutdownHookManager: Deleting directory /tmp/spark-fd06c2a3-05bb-47c7-a8c4-eacf88f91fc6/userFiles-7b315c0a-4169-40bd-9e9f-db81100259de
	24/04/23 11:28:07 INFO ShutdownHookManager: Deleting directory /tmp/spark-476e4ec1-60c8-4b82-9247-19ea4af8709a
	24/04/23 11:28:07 INFO ShutdownHookManager: Deleting directory /tmp/spark-fd06c2a3-05bb-47c7-a8c4-eacf88f91fc6
[WI-492][TI-1160] - [INFO] 2024-04-23 11:28:07.504 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/492/1160, processId:3979 ,exitStatusCode:1 ,processWaitForStatus:true ,processExitValue:1
[WI-492][TI-1160] - [INFO] 2024-04-23 11:28:07.508 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-492][TI-1160] - [INFO] 2024-04-23 11:28:07.511 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-492][TI-1160] - [INFO] 2024-04-23 11:28:07.511 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-492][TI-1160] - [INFO] 2024-04-23 11:28:07.517 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-492][TI-1160] - [INFO] 2024-04-23 11:28:07.525 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: FAILURE to master : 172.18.1.1:1234
[WI-492][TI-1160] - [INFO] 2024-04-23 11:28:07.526 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-492][TI-1160] - [INFO] 2024-04-23 11:28:07.527 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/492/1160
[WI-492][TI-1160] - [INFO] 2024-04-23 11:28:07.529 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/492/1160
[WI-492][TI-1160] - [INFO] 2024-04-23 11:28:07.529 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-0] - [INFO] 2024-04-23 11:28:07.624 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8638888888888889 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-1160] - [INFO] 2024-04-23 11:28:08.434 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1160, success=true)
[WI-0][TI-0] - [INFO] 2024-04-23 11:28:16.675 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7478510028653296 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:28:24.079 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1161, taskName=search for intake JSON files, firstSubmitTime=1713842904068, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.9:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=81, appIds=null, processInstanceId=493, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"processing"}], executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":""}],"rawScript":"# find 1 raw file in the folder\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\n\n# check if raw_file_dir is empty, then set raw_file_dir to null\nif [ -z \"$raw_file_dir\" ]; then\n    raw_file_dir=null\nfi\n\necho \"#{setValue(raw_file_dir=${raw_file_dir})}\"","resourceList":[]}, environmentConfig=export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='search for intake JSON files'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240423'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1161'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13340113777664'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240423112824'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='processing'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='493'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240422'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=null, dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-493][TI-1161] - [INFO] 2024-04-23 11:28:24.080 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: search for intake JSON files to wait queue success
[WI-493][TI-1161] - [INFO] 2024-04-23 11:28:24.080 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-493][TI-1161] - [INFO] 2024-04-23 11:28:24.082 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-493][TI-1161] - [INFO] 2024-04-23 11:28:24.082 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-493][TI-1161] - [INFO] 2024-04-23 11:28:24.082 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-493][TI-1161] - [INFO] 2024-04-23 11:28:24.082 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713842904082
[WI-493][TI-1161] - [INFO] 2024-04-23 11:28:24.082 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 493_1161
[WI-493][TI-1161] - [INFO] 2024-04-23 11:28:24.083 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1161,
  "taskName" : "search for intake JSON files",
  "firstSubmitTime" : 1713842904068,
  "startTime" : 1713842904082,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.9:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240423/13201021801792/81/493/1161.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 81,
  "processInstanceId" : 493,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"processing\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[{\"prop\":\"raw_file_dir\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"\"}],\"rawScript\":\"# find 1 raw file in the folder\\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\\n\\n# check if raw_file_dir is empty, then set raw_file_dir to null\\nif [ -z \\\"$raw_file_dir\\\" ]; then\\n    raw_file_dir=null\\nfi\\n\\necho \\\"#{setValue(raw_file_dir=${raw_file_dir})}\\\"\",\"resourceList\":[]}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "search for intake JSON files"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1161"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13340113777664"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423112824"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "processing"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "493"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240422"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "493_1161",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-493][TI-1161] - [INFO] 2024-04-23 11:28:24.083 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-493][TI-1161] - [INFO] 2024-04-23 11:28:24.083 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-493][TI-1161] - [INFO] 2024-04-23 11:28:24.083 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-493][TI-1161] - [INFO] 2024-04-23 11:28:24.089 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-493][TI-1161] - [INFO] 2024-04-23 11:28:24.090 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-493][TI-1161] - [INFO] 2024-04-23 11:28:24.090 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_81/493/1161 check successfully
[WI-493][TI-1161] - [INFO] 2024-04-23 11:28:24.090 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-493][TI-1161] - [INFO] 2024-04-23 11:28:24.090 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-493][TI-1161] - [INFO] 2024-04-23 11:28:24.090 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-493][TI-1161] - [INFO] 2024-04-23 11:28:24.090 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-493][TI-1161] - [INFO] 2024-04-23 11:28:24.091 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ {
    "prop" : "raw_file_dir",
    "direct" : "OUT",
    "type" : "VARCHAR",
    "value" : ""
  } ],
  "varPool" : null,
  "rawScript" : "# find 1 raw file in the folder\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\n\n# check if raw_file_dir is empty, then set raw_file_dir to null\nif [ -z \"$raw_file_dir\" ]; then\n    raw_file_dir=null\nfi\n\necho \"#{setValue(raw_file_dir=${raw_file_dir})}\"",
  "resourceList" : [ ]
}
[WI-493][TI-1161] - [INFO] 2024-04-23 11:28:24.091 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-493][TI-1161] - [INFO] 2024-04-23 11:28:24.091 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: null successfully
[WI-493][TI-1161] - [INFO] 2024-04-23 11:28:24.091 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-493][TI-1161] - [INFO] 2024-04-23 11:28:24.091 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-493][TI-1161] - [INFO] 2024-04-23 11:28:24.091 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-493][TI-1161] - [INFO] 2024-04-23 11:28:24.091 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-493][TI-1161] - [INFO] 2024-04-23 11:28:24.091 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-493][TI-1161] - [INFO] 2024-04-23 11:28:24.091 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export PYTHON_LAUNCHER=/bin/python3.11
# find 1 raw file in the folder
raw_file_dir=$(find /local_storage/reddit/processing -type f -name '*.json'| head -n 1)

# check if raw_file_dir is empty, then set raw_file_dir to null
if [ -z "$raw_file_dir" ]; then
    raw_file_dir=null
fi

echo "#{setValue(raw_file_dir=${raw_file_dir})}"
[WI-493][TI-1161] - [INFO] 2024-04-23 11:28:24.091 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-493][TI-1161] - [INFO] 2024-04-23 11:28:24.092 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_81/493/1161/493_1161.sh
[WI-493][TI-1161] - [INFO] 2024-04-23 11:28:24.103 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 4181
[WI-0][TI-0] - [INFO] 2024-04-23 11:28:24.103 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
[WI-0][TI-1161] - [INFO] 2024-04-23 11:28:24.487 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionRunningEvent(taskInstanceId=1161, processInstanceId=493, startTime=1713842904082, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, status=TaskExecutionStatus{code=1, desc='running'}, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/81/493/1161.log, executePath=null, processId=0, appIds=null, eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1161] - [INFO] 2024-04-23 11:28:24.499 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionRunningEvent(taskInstanceId=1161, processInstanceId=493, startTime=1713842904082, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, status=TaskExecutionStatus{code=1, desc='running'}, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/81/493/1161.log, executePath=null, processId=0, appIds=null, eventCreateTime=0, eventSendTime=1713842904487)
[WI-0][TI-1161] - [INFO] 2024-04-23 11:28:24.501 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionInfoEvent(taskInstanceId=1161, processInstanceId=493, startTime=1713842904082, workflowInstanceHost=172.18.0.9:5678, taskInstanceHost=172.18.1.1:1234, logPath=null, processId=0, eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1161] - [INFO] 2024-04-23 11:28:24.509 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1161, success=true)
[WI-0][TI-1161] - [INFO] 2024-04-23 11:28:24.509 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionInfoEvent(taskInstanceId=1161, processInstanceId=493, startTime=1713842904082, workflowInstanceHost=172.18.0.9:5678, taskInstanceHost=172.18.1.1:1234, logPath=null, processId=0, eventCreateTime=0, eventSendTime=1713842904487)
[WI-0][TI-1161] - [WARN] 2024-04-23 11:28:24.510 +0800 o.a.d.s.w.m.MessageRetryRunner:[139] - Retry send message to master error
java.util.ConcurrentModificationException: null
	at java.util.ArrayList$Itr.checkForComodification(ArrayList.java:911)
	at java.util.ArrayList$Itr.next(ArrayList.java:861)
	at org.apache.dolphinscheduler.server.worker.message.MessageRetryRunner.run(MessageRetryRunner.java:127)
[WI-0][TI-1161] - [INFO] 2024-04-23 11:28:24.518 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1161)
[WI-0][TI-1161] - [INFO] 2024-04-23 11:28:24.557 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1161, success=true)
[WI-0][TI-1161] - [INFO] 2024-04-23 11:28:24.564 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1161)
[WI-0][TI-0] - [INFO] 2024-04-23 11:28:25.107 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	#{setValue(raw_file_dir=/local_storage/reddit/processing/386-20240422.json)}
[WI-493][TI-1161] - [INFO] 2024-04-23 11:28:25.109 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_81/493/1161, processId:4181 ,exitStatusCode:0 ,processWaitForStatus:true ,processExitValue:0
[WI-493][TI-1161] - [INFO] 2024-04-23 11:28:25.110 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-493][TI-1161] - [INFO] 2024-04-23 11:28:25.110 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-493][TI-1161] - [INFO] 2024-04-23 11:28:25.110 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-493][TI-1161] - [INFO] 2024-04-23 11:28:25.111 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-493][TI-1161] - [INFO] 2024-04-23 11:28:25.113 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: SUCCESS to master : 172.18.1.1:1234
[WI-493][TI-1161] - [INFO] 2024-04-23 11:28:25.113 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-493][TI-1161] - [INFO] 2024-04-23 11:28:25.113 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_81/493/1161
[WI-493][TI-1161] - [INFO] 2024-04-23 11:28:25.114 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_81/493/1161
[WI-493][TI-1161] - [INFO] 2024-04-23 11:28:25.114 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-1161] - [INFO] 2024-04-23 11:28:25.493 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1161, success=true)
[WI-0][TI-0] - [INFO] 2024-04-23 11:28:26.586 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1163, taskName=move to processing, firstSubmitTime=1713842906579, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.9:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=81, appIds=null, processInstanceId=493, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"processing"}], executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":""}],"rawScript":"# move file to the reddit processing folder\n# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error\nfilename=$(basename \"${raw_file_dir}\")\nif ! grep -q \"${REDDIT_HOME}/processing\" <<< \"${raw_file_dir}\"; then\n    mv ${raw_file_dir} ${REDDIT_HOME}/processing\nelse\n    echo JSON is already in processing\nfi\n\n# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing\necho \"#{setValue(raw_file_dir=${REDDIT_HOME}/processing/${filename})}\"","resourceList":[]}, environmentConfig=export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='move to processing'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240423'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1163'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13340390094208'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240423112826'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='processing'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='493'}, raw_file_dir=Property{prop='raw_file_dir', direct=IN, type=VARCHAR, value='/local_storage/reddit/processing/386-20240422.json'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240422'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-493][TI-1163] - [INFO] 2024-04-23 11:28:26.587 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: move to processing to wait queue success
[WI-493][TI-1163] - [INFO] 2024-04-23 11:28:26.588 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-493][TI-1163] - [INFO] 2024-04-23 11:28:26.589 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-493][TI-1163] - [INFO] 2024-04-23 11:28:26.589 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-493][TI-1163] - [INFO] 2024-04-23 11:28:26.589 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-493][TI-1163] - [INFO] 2024-04-23 11:28:26.589 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713842906589
[WI-493][TI-1163] - [INFO] 2024-04-23 11:28:26.589 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 493_1163
[WI-493][TI-1163] - [INFO] 2024-04-23 11:28:26.590 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1163,
  "taskName" : "move to processing",
  "firstSubmitTime" : 1713842906579,
  "startTime" : 1713842906589,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.9:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240423/13201021801792/81/493/1163.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 81,
  "processInstanceId" : 493,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"processing\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[{\"prop\":\"raw_file_dir\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"\"}],\"rawScript\":\"# move file to the reddit processing folder\\n# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error\\nfilename=$(basename \\\"${raw_file_dir}\\\")\\nif ! grep -q \\\"${REDDIT_HOME}/processing\\\" <<< \\\"${raw_file_dir}\\\"; then\\n    mv ${raw_file_dir} ${REDDIT_HOME}/processing\\nelse\\n    echo JSON is already in processing\\nfi\\n\\n# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing\\necho \\\"#{setValue(raw_file_dir=${REDDIT_HOME}/processing/${filename})}\\\"\",\"resourceList\":[]}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "move to processing"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1163"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13340390094208"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423112826"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "processing"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "493"
    },
    "raw_file_dir" : {
      "prop" : "raw_file_dir",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit/processing/386-20240422.json"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240422"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "493_1163",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"raw_file_dir\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"/local_storage/reddit/processing/386-20240422.json\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-493][TI-1163] - [INFO] 2024-04-23 11:28:26.590 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-493][TI-1163] - [INFO] 2024-04-23 11:28:26.590 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-493][TI-1163] - [INFO] 2024-04-23 11:28:26.590 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-493][TI-1163] - [INFO] 2024-04-23 11:28:26.593 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-493][TI-1163] - [INFO] 2024-04-23 11:28:26.594 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-493][TI-1163] - [INFO] 2024-04-23 11:28:26.594 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_81/493/1163 check successfully
[WI-493][TI-1163] - [INFO] 2024-04-23 11:28:26.594 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-493][TI-1163] - [INFO] 2024-04-23 11:28:26.594 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-493][TI-1163] - [INFO] 2024-04-23 11:28:26.595 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-493][TI-1163] - [INFO] 2024-04-23 11:28:26.595 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-493][TI-1163] - [INFO] 2024-04-23 11:28:26.595 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ {
    "prop" : "raw_file_dir",
    "direct" : "OUT",
    "type" : "VARCHAR",
    "value" : ""
  } ],
  "varPool" : null,
  "rawScript" : "# move file to the reddit processing folder\n# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error\nfilename=$(basename \"${raw_file_dir}\")\nif ! grep -q \"${REDDIT_HOME}/processing\" <<< \"${raw_file_dir}\"; then\n    mv ${raw_file_dir} ${REDDIT_HOME}/processing\nelse\n    echo JSON is already in processing\nfi\n\n# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing\necho \"#{setValue(raw_file_dir=${REDDIT_HOME}/processing/${filename})}\"",
  "resourceList" : [ ]
}
[WI-493][TI-1163] - [INFO] 2024-04-23 11:28:26.596 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-493][TI-1163] - [INFO] 2024-04-23 11:28:26.596 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}] successfully
[WI-493][TI-1163] - [INFO] 2024-04-23 11:28:26.596 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-493][TI-1163] - [INFO] 2024-04-23 11:28:26.596 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-493][TI-1163] - [INFO] 2024-04-23 11:28:26.596 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-493][TI-1163] - [INFO] 2024-04-23 11:28:26.597 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-493][TI-1163] - [INFO] 2024-04-23 11:28:26.597 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-493][TI-1163] - [INFO] 2024-04-23 11:28:26.597 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export PYTHON_LAUNCHER=/bin/python3.11
# move file to the reddit processing folder
# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error
filename=$(basename "/local_storage/reddit/processing/386-20240422.json")
if ! grep -q "/local_storage/reddit/processing" <<< "/local_storage/reddit/processing/386-20240422.json"; then
    mv /local_storage/reddit/processing/386-20240422.json /local_storage/reddit/processing
else
    echo JSON is already in processing
fi

# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing
echo "#{setValue(raw_file_dir=/local_storage/reddit/processing/${filename})}"
[WI-493][TI-1163] - [INFO] 2024-04-23 11:28:26.597 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-493][TI-1163] - [INFO] 2024-04-23 11:28:26.597 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_81/493/1163/493_1163.sh
[WI-493][TI-1163] - [INFO] 2024-04-23 11:28:26.613 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 4194
[WI-0][TI-1163] - [INFO] 2024-04-23 11:28:27.471 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1163, success=true)
[WI-0][TI-1163] - [INFO] 2024-04-23 11:28:27.477 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1163)
[WI-0][TI-0] - [INFO] 2024-04-23 11:28:27.618 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
	JSON is already in processing
	#{setValue(raw_file_dir=/local_storage/reddit/processing/386-20240422.json)}
[WI-493][TI-1163] - [INFO] 2024-04-23 11:28:27.621 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_81/493/1163, processId:4194 ,exitStatusCode:0 ,processWaitForStatus:true ,processExitValue:0
[WI-493][TI-1163] - [INFO] 2024-04-23 11:28:27.623 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-493][TI-1163] - [INFO] 2024-04-23 11:28:27.623 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-493][TI-1163] - [INFO] 2024-04-23 11:28:27.623 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-493][TI-1163] - [INFO] 2024-04-23 11:28:27.623 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-493][TI-1163] - [INFO] 2024-04-23 11:28:27.641 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: SUCCESS to master : 172.18.1.1:1234
[WI-493][TI-1163] - [INFO] 2024-04-23 11:28:27.641 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-493][TI-1163] - [INFO] 2024-04-23 11:28:27.641 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_81/493/1163
[WI-493][TI-1163] - [INFO] 2024-04-23 11:28:27.642 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_81/493/1163
[WI-493][TI-1163] - [INFO] 2024-04-23 11:28:27.642 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-1163] - [INFO] 2024-04-23 11:28:28.475 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1163, success=true)
[WI-0][TI-0] - [INFO] 2024-04-23 11:28:28.607 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1164, taskName=spark preprocessing, firstSubmitTime=1713842908595, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.9:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=81, appIds=null, processInstanceId=493, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"processing"}], executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[],"rawScript":"$SPARK_HOME/bin/spark-submit \\\n    --master spark://spark-master:7077 \\\n    # --conf spark.driver.cores=2 \\\n    # --conf spark.driver.memory=2G \\\n    # --conf spark.executor.instances=1 \\\n    # --conf spark.executor.cores=2 \\\n    # --conf spark.executor.memory=2G \\\n    --files ${raw_file_dir} \\\n    --name reddit_preprocessing spark_reddit_preprocessing.py\n","resourceList":[{"id":null,"resourceName":"file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py","res":null}]}, environmentConfig=export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export HADOOP_CONF_DIR=/opt/hadoop-3.4.0/etc/hadoop
export PYSPARK_DRIVER_PYTHON=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='spark preprocessing'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240423'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1164'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13210058002752'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240423112828'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='processing'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='493'}, raw_file_dir=Property{prop='raw_file_dir', direct=IN, type=VARCHAR, value='/local_storage/reddit/processing/386-20240422.json'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240422'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-493][TI-1164] - [INFO] 2024-04-23 11:28:28.608 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: spark preprocessing to wait queue success
[WI-493][TI-1164] - [INFO] 2024-04-23 11:28:28.608 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-493][TI-1164] - [INFO] 2024-04-23 11:28:28.610 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-493][TI-1164] - [INFO] 2024-04-23 11:28:28.610 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-493][TI-1164] - [INFO] 2024-04-23 11:28:28.610 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-493][TI-1164] - [INFO] 2024-04-23 11:28:28.611 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713842908611
[WI-493][TI-1164] - [INFO] 2024-04-23 11:28:28.611 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 493_1164
[WI-493][TI-1164] - [INFO] 2024-04-23 11:28:28.611 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1164,
  "taskName" : "spark preprocessing",
  "firstSubmitTime" : 1713842908595,
  "startTime" : 1713842908611,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.9:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240423/13201021801792/81/493/1164.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 81,
  "processInstanceId" : 493,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"processing\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[],\"rawScript\":\"$SPARK_HOME/bin/spark-submit \\\\\\n    --master spark://spark-master:7077 \\\\\\n    # --conf spark.driver.cores=2 \\\\\\n    # --conf spark.driver.memory=2G \\\\\\n    # --conf spark.executor.instances=1 \\\\\\n    # --conf spark.executor.cores=2 \\\\\\n    # --conf spark.executor.memory=2G \\\\\\n    --files ${raw_file_dir} \\\\\\n    --name reddit_preprocessing spark_reddit_preprocessing.py\\n\",\"resourceList\":[{\"id\":null,\"resourceName\":\"file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py\",\"res\":null}]}",
  "environmentConfig" : "export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3\nexport JAVA_HOME=/opt/java/openjdk\nexport HADOOP_CONF_DIR=/opt/hadoop-3.4.0/etc/hadoop\nexport PYSPARK_DRIVER_PYTHON=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "spark preprocessing"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1164"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13210058002752"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423112828"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "processing"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "493"
    },
    "raw_file_dir" : {
      "prop" : "raw_file_dir",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit/processing/386-20240422.json"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240422"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "493_1164",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"raw_file_dir\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"/local_storage/reddit/processing/386-20240422.json\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-493][TI-1164] - [INFO] 2024-04-23 11:28:28.612 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-493][TI-1164] - [INFO] 2024-04-23 11:28:28.612 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-493][TI-1164] - [INFO] 2024-04-23 11:28:28.612 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-493][TI-1164] - [INFO] 2024-04-23 11:28:28.629 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-493][TI-1164] - [INFO] 2024-04-23 11:28:28.630 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-493][TI-1164] - [INFO] 2024-04-23 11:28:28.631 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_81/493/1164 check successfully
[WI-493][TI-1164] - [INFO] 2024-04-23 11:28:28.631 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-493][TI-1164] - [INFO] 2024-04-23 11:28:28.638 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py=ResourceContext.ResourceItem(resourceAbsolutePathInStorage=file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py, resourceRelativePath=spark_reddit_preprocessing.py, resourceAbsolutePathInLocal=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_81/493/1164/spark_reddit_preprocessing.py)})
[WI-493][TI-1164] - [INFO] 2024-04-23 11:28:28.639 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-493][TI-1164] - [INFO] 2024-04-23 11:28:28.640 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-493][TI-1164] - [INFO] 2024-04-23 11:28:28.640 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ ],
  "varPool" : null,
  "rawScript" : "$SPARK_HOME/bin/spark-submit \\\n    --master spark://spark-master:7077 \\\n    # --conf spark.driver.cores=2 \\\n    # --conf spark.driver.memory=2G \\\n    # --conf spark.executor.instances=1 \\\n    # --conf spark.executor.cores=2 \\\n    # --conf spark.executor.memory=2G \\\n    --files ${raw_file_dir} \\\n    --name reddit_preprocessing spark_reddit_preprocessing.py\n",
  "resourceList" : [ {
    "id" : null,
    "resourceName" : "file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py",
    "res" : null
  } ]
}
[WI-493][TI-1164] - [INFO] 2024-04-23 11:28:28.640 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-493][TI-1164] - [INFO] 2024-04-23 11:28:28.640 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}] successfully
[WI-493][TI-1164] - [INFO] 2024-04-23 11:28:28.640 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-493][TI-1164] - [INFO] 2024-04-23 11:28:28.641 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-493][TI-1164] - [INFO] 2024-04-23 11:28:28.641 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-493][TI-1164] - [INFO] 2024-04-23 11:28:28.642 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-493][TI-1164] - [INFO] 2024-04-23 11:28:28.642 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-493][TI-1164] - [INFO] 2024-04-23 11:28:28.642 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export HADOOP_CONF_DIR=/opt/hadoop-3.4.0/etc/hadoop
export PYSPARK_DRIVER_PYTHON=/bin/python3.11
$SPARK_HOME/bin/spark-submit \
    --master spark://spark-master:7077 \
    # --conf spark.driver.cores=2 \
    # --conf spark.driver.memory=2G \
    # --conf spark.executor.instances=1 \
    # --conf spark.executor.cores=2 \
    # --conf spark.executor.memory=2G \
    --files /local_storage/reddit/processing/386-20240422.json \
    --name reddit_preprocessing spark_reddit_preprocessing.py

[WI-493][TI-1164] - [INFO] 2024-04-23 11:28:28.643 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-493][TI-1164] - [INFO] 2024-04-23 11:28:28.643 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_81/493/1164/493_1164.sh
[WI-493][TI-1164] - [INFO] 2024-04-23 11:28:28.646 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 4206
[WI-0][TI-1164] - [INFO] 2024-04-23 11:28:29.496 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1164, success=true)
[WI-0][TI-1164] - [INFO] 2024-04-23 11:28:29.505 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1164)
[WI-0][TI-0] - [INFO] 2024-04-23 11:28:29.652 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
	Error: Missing application resource.
	
[WI-0][TI-0] - [INFO] 2024-04-23 11:28:30.659 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	Usage: spark-submit [options] <app jar | python file | R file> [app arguments]
	Usage: spark-submit --kill [submission ID] --master [spark://...]
	Usage: spark-submit --status [submission ID] --master [spark://...]
	Usage: spark-submit run-example [options] example-class [example args]
	
	Options:
	  --master MASTER_URL         spark://host:port, mesos://host:port, yarn,
	                              k8s://https://host:port, or local (Default: local[*]).
	  --deploy-mode DEPLOY_MODE   Whether to launch the driver program locally ("client") or
	                              on one of the worker machines inside the cluster ("cluster")
	                              (Default: client).
	  --class CLASS_NAME          Your application's main class (for Java / Scala apps).
	  --name NAME                 A name of your application.
	  --jars JARS                 Comma-separated list of jars to include on the driver
	                              and executor classpaths.
	  --packages                  Comma-separated list of maven coordinates of jars to include
	                              on the driver and executor classpaths. Will search the local
	                              maven repo, then maven central and any additional remote
	                              repositories given by --repositories. The format for the
	                              coordinates should be groupId:artifactId:version.
	  --exclude-packages          Comma-separated list of groupId:artifactId, to exclude while
	                              resolving the dependencies provided in --packages to avoid
	                              dependency conflicts.
	  --repositories              Comma-separated list of additional remote repositories to
	                              search for the maven coordinates given with --packages.
	  --py-files PY_FILES         Comma-separated list of .zip, .egg, or .py files to place
	                              on the PYTHONPATH for Python apps.
	  --files FILES               Comma-separated list of files to be placed in the working
	                              directory of each executor. File paths of these files
	                              in executors can be accessed via SparkFiles.get(fileName).
	  --archives ARCHIVES         Comma-separated list of archives to be extracted into the
	                              working directory of each executor.
	
	  --conf, -c PROP=VALUE       Arbitrary Spark configuration property.
	  --properties-file FILE      Path to a file from which to load extra properties. If not
	                              specified, this will look for conf/spark-defaults.conf.
	
	  --driver-memory MEM         Memory for driver (e.g. 1000M, 2G) (Default: 1024M).
	  --driver-java-options       Extra Java options to pass to the driver.
	  --driver-library-path       Extra library path entries to pass to the driver.
	  --driver-class-path         Extra class path entries to pass to the driver. Note that
	                              jars added with --jars are automatically included in the
	                              classpath.
	
	  --executor-memory MEM       Memory per executor (e.g. 1000M, 2G) (Default: 1G).
	
	  --proxy-user NAME           User to impersonate when submitting the application.
	                              This argument does not work with --principal / --keytab.
	
	  --help, -h                  Show this help message and exit.
	  --verbose, -v               Print additional debug output.
	  --version,                  Print the version of current Spark.
	
	 Spark Connect only:
	   --remote CONNECT_URL       URL to connect to the server for Spark Connect, e.g.,
	                              sc://host:port. --master and --deploy-mode cannot be set
	                              together with this option. This option is experimental, and
	                              might change between minor releases.
	
	 Cluster deploy mode only:
	  --driver-cores NUM          Number of cores used by the driver, only in cluster mode
	                              (Default: 1).
	
	 Spark standalone or Mesos with cluster deploy mode only:
	  --supervise                 If given, restarts the driver on failure.
	
	 Spark standalone, Mesos or K8s with cluster deploy mode only:
	  --kill SUBMISSION_ID        If given, kills the driver specified.
	  --status SUBMISSION_ID      If given, requests the status of the driver specified.
	
	 Spark standalone and Mesos only:
	  --total-executor-cores NUM  Total cores for all executors.
	
	 Spark standalone, YARN and Kubernetes only:
	  --executor-cores NUM        Number of cores used by each executor. (Default: 1 in
	                              YARN and K8S modes, or all available cores on the worker
	                              in standalone mode).
	
	 Spark on YARN and Kubernetes only:
	  --num-executors NUM         Number of executors to launch (Default: 2).
	                              If dynamic allocation is enabled, the initial number of
	                              executors will be at least NUM.
	  --principal PRINCIPAL       Principal to be used to login to KDC.
	  --keytab KEYTAB             The full path to the file that contains the keytab for the
	                              principal specified above.
	
	 Spark on YARN only:
	  --queue QUEUE_NAME          The YARN queue to submit to (Default: "default").
	      
[WI-0][TI-0] - [INFO] 2024-04-23 11:28:31.661 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_81/493/1164/493_1164.sh: line 15: --files: command not found
[WI-493][TI-1164] - [INFO] 2024-04-23 11:28:31.663 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_81/493/1164, processId:4206 ,exitStatusCode:127 ,processWaitForStatus:true ,processExitValue:127
[WI-493][TI-1164] - [INFO] 2024-04-23 11:28:31.665 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-493][TI-1164] - [INFO] 2024-04-23 11:28:31.666 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-493][TI-1164] - [INFO] 2024-04-23 11:28:31.666 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-493][TI-1164] - [INFO] 2024-04-23 11:28:31.667 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-493][TI-1164] - [INFO] 2024-04-23 11:28:31.670 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: FAILURE to master : 172.18.1.1:1234
[WI-493][TI-1164] - [INFO] 2024-04-23 11:28:31.671 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-493][TI-1164] - [INFO] 2024-04-23 11:28:31.671 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_81/493/1164
[WI-493][TI-1164] - [INFO] 2024-04-23 11:28:31.672 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_81/493/1164
[WI-493][TI-1164] - [INFO] 2024-04-23 11:28:31.673 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-1164] - [INFO] 2024-04-23 11:28:32.481 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1164, success=true)
[WI-0][TI-0] - [INFO] 2024-04-23 11:28:39.831 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7914285714285715 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:28:40.889 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.717741935483871 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-1123] - [INFO] 2024-04-23 11:29:51.009 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1123, processInstanceId=487, status=9, startTime=1713838208504, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1123.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1123, endTime=1713838483436, processId=1677, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713842690677)
[WI-0][TI-1123] - [INFO] 2024-04-23 11:29:51.015 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1123, processInstanceId=487, status=9, startTime=1713838208504, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1123.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1123, endTime=1713838483436, processId=1677, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713842991009)
[WI-0][TI-1111] - [INFO] 2024-04-23 11:29:53.021 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1111, processInstanceId=487, status=9, startTime=1713837256404, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1111.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1111, endTime=1713838170352, processId=1017, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713842692695)
[WI-0][TI-1111] - [INFO] 2024-04-23 11:29:53.026 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1111, processInstanceId=487, status=9, startTime=1713837256404, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1111.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1111, endTime=1713838170352, processId=1017, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713842993021)
[WI-0][TI-0] - [INFO] 2024-04-23 11:30:30.904 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1165, taskName=search for intake JSON files, firstSubmitTime=1713843030882, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.9:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=81, appIds=null, processInstanceId=493, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"processing"}], executorId=1, cmdTypeIfComplement=7, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":""}],"rawScript":"# find 1 raw file in the folder\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\n\n# check if raw_file_dir is empty, then set raw_file_dir to null\nif [ -z \"$raw_file_dir\" ]; then\n    raw_file_dir=null\nfi\n\necho \"#{setValue(raw_file_dir=${raw_file_dir})}\"","resourceList":[]}, environmentConfig=export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='search for intake JSON files'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240423'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1165'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13340113777664'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240423113030'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='processing'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='493'}, raw_file_dir=Property{prop='raw_file_dir', direct=OUT, type=VARCHAR, value='/local_storage/reddit/processing/386-20240422.json'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240422'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-493][TI-1165] - [INFO] 2024-04-23 11:30:30.906 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: search for intake JSON files to wait queue success
[WI-493][TI-1165] - [INFO] 2024-04-23 11:30:30.907 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-493][TI-1165] - [INFO] 2024-04-23 11:30:30.922 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-493][TI-1165] - [INFO] 2024-04-23 11:30:30.923 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-493][TI-1165] - [INFO] 2024-04-23 11:30:30.923 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-493][TI-1165] - [INFO] 2024-04-23 11:30:30.923 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713843030923
[WI-493][TI-1165] - [INFO] 2024-04-23 11:30:30.923 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 493_1165
[WI-493][TI-1165] - [INFO] 2024-04-23 11:30:30.923 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1165,
  "taskName" : "search for intake JSON files",
  "firstSubmitTime" : 1713843030882,
  "startTime" : 1713843030923,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.9:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240423/13201021801792/81/493/1165.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 81,
  "processInstanceId" : 493,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"processing\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 7,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[{\"prop\":\"raw_file_dir\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"\"}],\"rawScript\":\"# find 1 raw file in the folder\\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\\n\\n# check if raw_file_dir is empty, then set raw_file_dir to null\\nif [ -z \\\"$raw_file_dir\\\" ]; then\\n    raw_file_dir=null\\nfi\\n\\necho \\\"#{setValue(raw_file_dir=${raw_file_dir})}\\\"\",\"resourceList\":[]}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "search for intake JSON files"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1165"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13340113777664"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423113030"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "processing"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "493"
    },
    "raw_file_dir" : {
      "prop" : "raw_file_dir",
      "direct" : "OUT",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit/processing/386-20240422.json"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240422"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "493_1165",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"raw_file_dir\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"/local_storage/reddit/processing/386-20240422.json\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-493][TI-1165] - [INFO] 2024-04-23 11:30:30.924 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-493][TI-1165] - [INFO] 2024-04-23 11:30:30.924 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-493][TI-1165] - [INFO] 2024-04-23 11:30:30.924 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-493][TI-1165] - [INFO] 2024-04-23 11:30:30.926 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-493][TI-1165] - [INFO] 2024-04-23 11:30:30.927 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-493][TI-1165] - [INFO] 2024-04-23 11:30:30.928 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_81/493/1165 check successfully
[WI-493][TI-1165] - [INFO] 2024-04-23 11:30:30.928 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-493][TI-1165] - [INFO] 2024-04-23 11:30:30.928 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-493][TI-1165] - [INFO] 2024-04-23 11:30:30.929 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-493][TI-1165] - [INFO] 2024-04-23 11:30:30.929 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-493][TI-1165] - [INFO] 2024-04-23 11:30:30.929 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ {
    "prop" : "raw_file_dir",
    "direct" : "OUT",
    "type" : "VARCHAR",
    "value" : ""
  } ],
  "varPool" : null,
  "rawScript" : "# find 1 raw file in the folder\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\n\n# check if raw_file_dir is empty, then set raw_file_dir to null\nif [ -z \"$raw_file_dir\" ]; then\n    raw_file_dir=null\nfi\n\necho \"#{setValue(raw_file_dir=${raw_file_dir})}\"",
  "resourceList" : [ ]
}
[WI-493][TI-1165] - [INFO] 2024-04-23 11:30:30.929 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-493][TI-1165] - [INFO] 2024-04-23 11:30:30.929 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}] successfully
[WI-493][TI-1165] - [INFO] 2024-04-23 11:30:30.929 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-493][TI-1165] - [INFO] 2024-04-23 11:30:30.929 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-493][TI-1165] - [INFO] 2024-04-23 11:30:30.929 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-493][TI-1165] - [INFO] 2024-04-23 11:30:30.930 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-493][TI-1165] - [INFO] 2024-04-23 11:30:30.930 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-493][TI-1165] - [INFO] 2024-04-23 11:30:30.930 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export PYTHON_LAUNCHER=/bin/python3.11
# find 1 raw file in the folder
raw_file_dir=$(find /local_storage/reddit/processing -type f -name '*.json'| head -n 1)

# check if raw_file_dir is empty, then set raw_file_dir to null
if [ -z "$raw_file_dir" ]; then
    raw_file_dir=null
fi

echo "#{setValue(raw_file_dir=/local_storage/reddit/processing/386-20240422.json)}"
[WI-493][TI-1165] - [INFO] 2024-04-23 11:30:30.930 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-493][TI-1165] - [INFO] 2024-04-23 11:30:30.930 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_81/493/1165/493_1165.sh
[WI-493][TI-1165] - [INFO] 2024-04-23 11:30:30.952 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 4274
[WI-0][TI-0] - [INFO] 2024-04-23 11:30:30.952 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
[WI-0][TI-1165] - [INFO] 2024-04-23 11:30:30.966 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1165, success=true)
[WI-0][TI-1165] - [INFO] 2024-04-23 11:30:30.977 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1165)
[WI-0][TI-0] - [INFO] 2024-04-23 11:30:31.957 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	#{setValue(raw_file_dir=/local_storage/reddit/processing/386-20240422.json)}
[WI-493][TI-1165] - [INFO] 2024-04-23 11:30:31.961 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_81/493/1165, processId:4274 ,exitStatusCode:0 ,processWaitForStatus:true ,processExitValue:0
[WI-493][TI-1165] - [INFO] 2024-04-23 11:30:31.964 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-493][TI-1165] - [INFO] 2024-04-23 11:30:31.965 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-493][TI-1165] - [INFO] 2024-04-23 11:30:31.965 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-493][TI-1165] - [INFO] 2024-04-23 11:30:31.965 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-493][TI-1165] - [INFO] 2024-04-23 11:30:31.971 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: SUCCESS to master : 172.18.1.1:1234
[WI-493][TI-1165] - [INFO] 2024-04-23 11:30:31.971 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-493][TI-1165] - [INFO] 2024-04-23 11:30:31.971 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_81/493/1165
[WI-493][TI-1165] - [INFO] 2024-04-23 11:30:31.972 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_81/493/1165
[WI-493][TI-1165] - [INFO] 2024-04-23 11:30:31.972 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-1165] - [INFO] 2024-04-23 11:30:32.090 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1165, processInstanceId=493, status=7, startTime=1713843030923, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/81/493/1165.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_81/493/1165, endTime=1713843031965, processId=4274, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1165] - [INFO] 2024-04-23 11:30:32.092 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1165, processInstanceId=493, status=7, startTime=1713843030923, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/81/493/1165.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_81/493/1165, endTime=1713843031965, processId=4274, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713843032090)
[WI-0][TI-1165] - [INFO] 2024-04-23 11:30:32.948 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1165, success=true)
[WI-0][TI-1165] - [INFO] 2024-04-23 11:30:32.951 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1165, success=true)
[WI-0][TI-0] - [INFO] 2024-04-23 11:30:34.057 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1167, taskName=move to processing, firstSubmitTime=1713843034051, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.9:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=81, appIds=null, processInstanceId=493, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"processing"}], executorId=1, cmdTypeIfComplement=7, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":""}],"rawScript":"# move file to the reddit processing folder\n# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error\nfilename=$(basename \"${raw_file_dir}\")\nif ! grep -q \"${REDDIT_HOME}/processing\" <<< \"${raw_file_dir}\"; then\n    mv ${raw_file_dir} ${REDDIT_HOME}/processing\nelse\n    echo JSON is already in processing\nfi\n\n# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing\necho \"#{setValue(raw_file_dir=${REDDIT_HOME}/processing/${filename})}\"","resourceList":[]}, environmentConfig=export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='move to processing'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240423'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1167'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13340390094208'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240423113034'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='processing'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='493'}, raw_file_dir=Property{prop='raw_file_dir', direct=IN, type=VARCHAR, value='/local_storage/reddit/processing/386-20240422.json'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240422'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-493][TI-1167] - [INFO] 2024-04-23 11:30:34.057 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: move to processing to wait queue success
[WI-493][TI-1167] - [INFO] 2024-04-23 11:30:34.058 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-493][TI-1167] - [INFO] 2024-04-23 11:30:34.059 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-493][TI-1167] - [INFO] 2024-04-23 11:30:34.059 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-493][TI-1167] - [INFO] 2024-04-23 11:30:34.059 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-493][TI-1167] - [INFO] 2024-04-23 11:30:34.060 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713843034060
[WI-493][TI-1167] - [INFO] 2024-04-23 11:30:34.060 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 493_1167
[WI-493][TI-1167] - [INFO] 2024-04-23 11:30:34.060 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1167,
  "taskName" : "move to processing",
  "firstSubmitTime" : 1713843034051,
  "startTime" : 1713843034060,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.9:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240423/13201021801792/81/493/1167.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 81,
  "processInstanceId" : 493,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"processing\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 7,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[{\"prop\":\"raw_file_dir\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"\"}],\"rawScript\":\"# move file to the reddit processing folder\\n# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error\\nfilename=$(basename \\\"${raw_file_dir}\\\")\\nif ! grep -q \\\"${REDDIT_HOME}/processing\\\" <<< \\\"${raw_file_dir}\\\"; then\\n    mv ${raw_file_dir} ${REDDIT_HOME}/processing\\nelse\\n    echo JSON is already in processing\\nfi\\n\\n# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing\\necho \\\"#{setValue(raw_file_dir=${REDDIT_HOME}/processing/${filename})}\\\"\",\"resourceList\":[]}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "move to processing"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1167"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13340390094208"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423113034"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "processing"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "493"
    },
    "raw_file_dir" : {
      "prop" : "raw_file_dir",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit/processing/386-20240422.json"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240422"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "493_1167",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"raw_file_dir\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"/local_storage/reddit/processing/386-20240422.json\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-493][TI-1167] - [INFO] 2024-04-23 11:30:34.060 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-493][TI-1167] - [INFO] 2024-04-23 11:30:34.060 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-493][TI-1167] - [INFO] 2024-04-23 11:30:34.060 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-493][TI-1167] - [INFO] 2024-04-23 11:30:34.069 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-493][TI-1167] - [INFO] 2024-04-23 11:30:34.069 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-493][TI-1167] - [INFO] 2024-04-23 11:30:34.069 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_81/493/1167 check successfully
[WI-493][TI-1167] - [INFO] 2024-04-23 11:30:34.070 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-493][TI-1167] - [INFO] 2024-04-23 11:30:34.070 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-493][TI-1167] - [INFO] 2024-04-23 11:30:34.070 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-493][TI-1167] - [INFO] 2024-04-23 11:30:34.070 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-493][TI-1167] - [INFO] 2024-04-23 11:30:34.070 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ {
    "prop" : "raw_file_dir",
    "direct" : "OUT",
    "type" : "VARCHAR",
    "value" : ""
  } ],
  "varPool" : null,
  "rawScript" : "# move file to the reddit processing folder\n# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error\nfilename=$(basename \"${raw_file_dir}\")\nif ! grep -q \"${REDDIT_HOME}/processing\" <<< \"${raw_file_dir}\"; then\n    mv ${raw_file_dir} ${REDDIT_HOME}/processing\nelse\n    echo JSON is already in processing\nfi\n\n# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing\necho \"#{setValue(raw_file_dir=${REDDIT_HOME}/processing/${filename})}\"",
  "resourceList" : [ ]
}
[WI-493][TI-1167] - [INFO] 2024-04-23 11:30:34.070 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-493][TI-1167] - [INFO] 2024-04-23 11:30:34.070 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}] successfully
[WI-493][TI-1167] - [INFO] 2024-04-23 11:30:34.070 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-493][TI-1167] - [INFO] 2024-04-23 11:30:34.070 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-493][TI-1167] - [INFO] 2024-04-23 11:30:34.070 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-493][TI-1167] - [INFO] 2024-04-23 11:30:34.071 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-493][TI-1167] - [INFO] 2024-04-23 11:30:34.071 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-493][TI-1167] - [INFO] 2024-04-23 11:30:34.071 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export PYTHON_LAUNCHER=/bin/python3.11
# move file to the reddit processing folder
# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error
filename=$(basename "/local_storage/reddit/processing/386-20240422.json")
if ! grep -q "/local_storage/reddit/processing" <<< "/local_storage/reddit/processing/386-20240422.json"; then
    mv /local_storage/reddit/processing/386-20240422.json /local_storage/reddit/processing
else
    echo JSON is already in processing
fi

# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing
echo "#{setValue(raw_file_dir=/local_storage/reddit/processing/${filename})}"
[WI-493][TI-1167] - [INFO] 2024-04-23 11:30:34.071 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-493][TI-1167] - [INFO] 2024-04-23 11:30:34.071 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_81/493/1167/493_1167.sh
[WI-493][TI-1167] - [INFO] 2024-04-23 11:30:34.095 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 4288
[WI-0][TI-0] - [INFO] 2024-04-23 11:30:34.096 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
[WI-0][TI-1167] - [INFO] 2024-04-23 11:30:34.103 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionRunningEvent(taskInstanceId=1167, processInstanceId=493, startTime=1713843034060, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, status=TaskExecutionStatus{code=1, desc='running'}, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/81/493/1167.log, executePath=null, processId=0, appIds=null, eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1167] - [INFO] 2024-04-23 11:30:34.106 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionRunningEvent(taskInstanceId=1167, processInstanceId=493, startTime=1713843034060, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, status=TaskExecutionStatus{code=1, desc='running'}, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/81/493/1167.log, executePath=null, processId=0, appIds=null, eventCreateTime=0, eventSendTime=1713843034103)
[WI-0][TI-1167] - [INFO] 2024-04-23 11:30:34.106 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionInfoEvent(taskInstanceId=1167, processInstanceId=493, startTime=1713843034060, workflowInstanceHost=172.18.0.9:5678, taskInstanceHost=172.18.1.1:1234, logPath=null, processId=0, eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1167] - [INFO] 2024-04-23 11:30:34.109 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionInfoEvent(taskInstanceId=1167, processInstanceId=493, startTime=1713843034060, workflowInstanceHost=172.18.0.9:5678, taskInstanceHost=172.18.1.1:1234, logPath=null, processId=0, eventCreateTime=0, eventSendTime=1713843034103)
[WI-0][TI-1167] - [INFO] 2024-04-23 11:30:34.958 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1167, success=true)
[WI-0][TI-1167] - [INFO] 2024-04-23 11:30:34.962 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1167)
[WI-0][TI-1167] - [INFO] 2024-04-23 11:30:34.966 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1167, success=true)
[WI-0][TI-1167] - [INFO] 2024-04-23 11:30:34.969 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1167)
[WI-0][TI-0] - [INFO] 2024-04-23 11:30:35.100 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	JSON is already in processing
	#{setValue(raw_file_dir=/local_storage/reddit/processing/386-20240422.json)}
[WI-493][TI-1167] - [INFO] 2024-04-23 11:30:35.103 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_81/493/1167, processId:4288 ,exitStatusCode:0 ,processWaitForStatus:true ,processExitValue:0
[WI-493][TI-1167] - [INFO] 2024-04-23 11:30:35.112 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-493][TI-1167] - [INFO] 2024-04-23 11:30:35.112 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-493][TI-1167] - [INFO] 2024-04-23 11:30:35.112 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-493][TI-1167] - [INFO] 2024-04-23 11:30:35.113 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-493][TI-1167] - [INFO] 2024-04-23 11:30:35.115 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: SUCCESS to master : 172.18.1.1:1234
[WI-493][TI-1167] - [INFO] 2024-04-23 11:30:35.115 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-493][TI-1167] - [INFO] 2024-04-23 11:30:35.116 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_81/493/1167
[WI-493][TI-1167] - [INFO] 2024-04-23 11:30:35.116 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_81/493/1167
[WI-493][TI-1167] - [INFO] 2024-04-23 11:30:35.116 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-1167] - [INFO] 2024-04-23 11:30:35.951 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1167, success=true)
[WI-0][TI-0] - [INFO] 2024-04-23 11:30:36.027 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1168, taskName=spark preprocessing, firstSubmitTime=1713843036020, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.9:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=81, appIds=null, processInstanceId=493, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"processing"}], executorId=1, cmdTypeIfComplement=7, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[],"rawScript":"$SPARK_HOME/bin/spark-submit \\\n    --master spark://spark-master:7077 \\\n    # --conf spark.driver.cores=2 \\\n    # --conf spark.driver.memory=2G \\\n    # --conf spark.executor.instances=1 \\\n    # --conf spark.executor.cores=2 \\\n    # --conf spark.executor.memory=2G \\\n    --files ${raw_file_dir} \\\n    --name reddit_preprocessing spark_reddit_preprocessing.py\n","resourceList":[{"id":null,"resourceName":"file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py","res":null}]}, environmentConfig=export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export HADOOP_CONF_DIR=/opt/hadoop-3.4.0/etc/hadoop
export PYSPARK_DRIVER_PYTHON=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='spark preprocessing'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240423'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1168'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13210058002752'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240423113036'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='processing'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='493'}, raw_file_dir=Property{prop='raw_file_dir', direct=IN, type=VARCHAR, value='/local_storage/reddit/processing/386-20240422.json'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240422'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-493][TI-1168] - [INFO] 2024-04-23 11:30:36.029 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: spark preprocessing to wait queue success
[WI-493][TI-1168] - [INFO] 2024-04-23 11:30:36.030 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-493][TI-1168] - [INFO] 2024-04-23 11:30:36.032 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-493][TI-1168] - [INFO] 2024-04-23 11:30:36.032 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-493][TI-1168] - [INFO] 2024-04-23 11:30:36.033 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-493][TI-1168] - [INFO] 2024-04-23 11:30:36.033 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713843036033
[WI-493][TI-1168] - [INFO] 2024-04-23 11:30:36.033 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 493_1168
[WI-493][TI-1168] - [INFO] 2024-04-23 11:30:36.033 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1168,
  "taskName" : "spark preprocessing",
  "firstSubmitTime" : 1713843036020,
  "startTime" : 1713843036033,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.9:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240423/13201021801792/81/493/1168.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 81,
  "processInstanceId" : 493,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"processing\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 7,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[],\"rawScript\":\"$SPARK_HOME/bin/spark-submit \\\\\\n    --master spark://spark-master:7077 \\\\\\n    # --conf spark.driver.cores=2 \\\\\\n    # --conf spark.driver.memory=2G \\\\\\n    # --conf spark.executor.instances=1 \\\\\\n    # --conf spark.executor.cores=2 \\\\\\n    # --conf spark.executor.memory=2G \\\\\\n    --files ${raw_file_dir} \\\\\\n    --name reddit_preprocessing spark_reddit_preprocessing.py\\n\",\"resourceList\":[{\"id\":null,\"resourceName\":\"file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py\",\"res\":null}]}",
  "environmentConfig" : "export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3\nexport JAVA_HOME=/opt/java/openjdk\nexport HADOOP_CONF_DIR=/opt/hadoop-3.4.0/etc/hadoop\nexport PYSPARK_DRIVER_PYTHON=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "spark preprocessing"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1168"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13210058002752"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423113036"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "processing"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "493"
    },
    "raw_file_dir" : {
      "prop" : "raw_file_dir",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit/processing/386-20240422.json"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240422"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "493_1168",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"raw_file_dir\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"/local_storage/reddit/processing/386-20240422.json\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-493][TI-1168] - [INFO] 2024-04-23 11:30:36.034 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-493][TI-1168] - [INFO] 2024-04-23 11:30:36.034 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-493][TI-1168] - [INFO] 2024-04-23 11:30:36.034 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-493][TI-1168] - [INFO] 2024-04-23 11:30:36.037 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-493][TI-1168] - [INFO] 2024-04-23 11:30:36.038 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-493][TI-1168] - [INFO] 2024-04-23 11:30:36.039 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_81/493/1168 check successfully
[WI-493][TI-1168] - [INFO] 2024-04-23 11:30:36.039 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-493][TI-1168] - [INFO] 2024-04-23 11:30:36.041 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py=ResourceContext.ResourceItem(resourceAbsolutePathInStorage=file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py, resourceRelativePath=spark_reddit_preprocessing.py, resourceAbsolutePathInLocal=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_81/493/1168/spark_reddit_preprocessing.py)})
[WI-493][TI-1168] - [INFO] 2024-04-23 11:30:36.041 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-493][TI-1168] - [INFO] 2024-04-23 11:30:36.042 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-493][TI-1168] - [INFO] 2024-04-23 11:30:36.042 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ ],
  "varPool" : null,
  "rawScript" : "$SPARK_HOME/bin/spark-submit \\\n    --master spark://spark-master:7077 \\\n    # --conf spark.driver.cores=2 \\\n    # --conf spark.driver.memory=2G \\\n    # --conf spark.executor.instances=1 \\\n    # --conf spark.executor.cores=2 \\\n    # --conf spark.executor.memory=2G \\\n    --files ${raw_file_dir} \\\n    --name reddit_preprocessing spark_reddit_preprocessing.py\n",
  "resourceList" : [ {
    "id" : null,
    "resourceName" : "file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py",
    "res" : null
  } ]
}
[WI-493][TI-1168] - [INFO] 2024-04-23 11:30:36.046 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-493][TI-1168] - [INFO] 2024-04-23 11:30:36.046 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}] successfully
[WI-493][TI-1168] - [INFO] 2024-04-23 11:30:36.046 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-493][TI-1168] - [INFO] 2024-04-23 11:30:36.046 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-493][TI-1168] - [INFO] 2024-04-23 11:30:36.047 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-493][TI-1168] - [INFO] 2024-04-23 11:30:36.049 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-493][TI-1168] - [INFO] 2024-04-23 11:30:36.049 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-493][TI-1168] - [INFO] 2024-04-23 11:30:36.049 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export HADOOP_CONF_DIR=/opt/hadoop-3.4.0/etc/hadoop
export PYSPARK_DRIVER_PYTHON=/bin/python3.11
$SPARK_HOME/bin/spark-submit \
    --master spark://spark-master:7077 \
    # --conf spark.driver.cores=2 \
    # --conf spark.driver.memory=2G \
    # --conf spark.executor.instances=1 \
    # --conf spark.executor.cores=2 \
    # --conf spark.executor.memory=2G \
    --files /local_storage/reddit/processing/386-20240422.json \
    --name reddit_preprocessing spark_reddit_preprocessing.py

[WI-493][TI-1168] - [INFO] 2024-04-23 11:30:36.050 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-493][TI-1168] - [INFO] 2024-04-23 11:30:36.050 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_81/493/1168/493_1168.sh
[WI-493][TI-1168] - [INFO] 2024-04-23 11:30:36.054 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 4300
[WI-0][TI-1168] - [INFO] 2024-04-23 11:30:36.113 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionRunningEvent(taskInstanceId=1168, processInstanceId=493, startTime=1713843036033, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, status=TaskExecutionStatus{code=1, desc='running'}, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/81/493/1168.log, executePath=null, processId=0, appIds=null, eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1168] - [INFO] 2024-04-23 11:30:36.116 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionRunningEvent(taskInstanceId=1168, processInstanceId=493, startTime=1713843036033, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, status=TaskExecutionStatus{code=1, desc='running'}, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/81/493/1168.log, executePath=null, processId=0, appIds=null, eventCreateTime=0, eventSendTime=1713843036112)
[WI-0][TI-1168] - [INFO] 2024-04-23 11:30:36.116 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionInfoEvent(taskInstanceId=1168, processInstanceId=493, startTime=1713843036033, workflowInstanceHost=172.18.0.9:5678, taskInstanceHost=172.18.1.1:1234, logPath=null, processId=0, eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1168] - [INFO] 2024-04-23 11:30:36.119 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionInfoEvent(taskInstanceId=1168, processInstanceId=493, startTime=1713843036033, workflowInstanceHost=172.18.0.9:5678, taskInstanceHost=172.18.1.1:1234, logPath=null, processId=0, eventCreateTime=0, eventSendTime=1713843036112)
[WI-0][TI-1168] - [INFO] 2024-04-23 11:30:36.953 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1168, success=true)
[WI-0][TI-1168] - [INFO] 2024-04-23 11:30:36.960 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1168)
[WI-0][TI-1168] - [INFO] 2024-04-23 11:30:36.965 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1168, success=true)
[WI-0][TI-1168] - [INFO] 2024-04-23 11:30:36.970 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1168)
[WI-0][TI-0] - [INFO] 2024-04-23 11:30:37.060 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
	Error: Missing application resource.
	
[WI-0][TI-0] - [INFO] 2024-04-23 11:30:38.078 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	Usage: spark-submit [options] <app jar | python file | R file> [app arguments]
	Usage: spark-submit --kill [submission ID] --master [spark://...]
	Usage: spark-submit --status [submission ID] --master [spark://...]
	Usage: spark-submit run-example [options] example-class [example args]
	
	Options:
	  --master MASTER_URL         spark://host:port, mesos://host:port, yarn,
	                              k8s://https://host:port, or local (Default: local[*]).
	  --deploy-mode DEPLOY_MODE   Whether to launch the driver program locally ("client") or
	                              on one of the worker machines inside the cluster ("cluster")
	                              (Default: client).
	  --class CLASS_NAME          Your application's main class (for Java / Scala apps).
	  --name NAME                 A name of your application.
	  --jars JARS                 Comma-separated list of jars to include on the driver
	                              and executor classpaths.
	  --packages                  Comma-separated list of maven coordinates of jars to include
	                              on the driver and executor classpaths. Will search the local
	                              maven repo, then maven central and any additional remote
	                              repositories given by --repositories. The format for the
	                              coordinates should be groupId:artifactId:version.
	  --exclude-packages          Comma-separated list of groupId:artifactId, to exclude while
	                              resolving the dependencies provided in --packages to avoid
	                              dependency conflicts.
	  --repositories              Comma-separated list of additional remote repositories to
	                              search for the maven coordinates given with --packages.
	  --py-files PY_FILES         Comma-separated list of .zip, .egg, or .py files to place
	                              on the PYTHONPATH for Python apps.
	  --files FILES               Comma-separated list of files to be placed in the working
	                              directory of each executor. File paths of these files
	                              in executors can be accessed via SparkFiles.get(fileName).
	  --archives ARCHIVES         Comma-separated list of archives to be extracted into the
	                              working directory of each executor.
	
	  --conf, -c PROP=VALUE       Arbitrary Spark configuration property.
	  --properties-file FILE      Path to a file from which to load extra properties. If not
	                              specified, this will look for conf/spark-defaults.conf.
	
	  --driver-memory MEM         Memory for driver (e.g. 1000M, 2G) (Default: 1024M).
	  --driver-java-options       Extra Java options to pass to the driver.
	  --driver-library-path       Extra library path entries to pass to the driver.
	  --driver-class-path         Extra class path entries to pass to the driver. Note that
	                              jars added with --jars are automatically included in the
	                              classpath.
	
	  --executor-memory MEM       Memory per executor (e.g. 1000M, 2G) (Default: 1G).
	
	  --proxy-user NAME           User to impersonate when submitting the application.
	                              This argument does not work with --principal / --keytab.
	
	  --help, -h                  Show this help message and exit.
	  --verbose, -v               Print additional debug output.
	  --version,                  Print the version of current Spark.
	
	 Spark Connect only:
	   --remote CONNECT_URL       URL to connect to the server for Spark Connect, e.g.,
	                              sc://host:port. --master and --deploy-mode cannot be set
	                              together with this option. This option is experimental, and
	                              might change between minor releases.
	
	 Cluster deploy mode only:
	  --driver-cores NUM          Number of cores used by the driver, only in cluster mode
	                              (Default: 1).
	
	 Spark standalone or Mesos with cluster deploy mode only:
	  --supervise                 If given, restarts the driver on failure.
	
	 Spark standalone, Mesos or K8s with cluster deploy mode only:
	  --kill SUBMISSION_ID        If given, kills the driver specified.
	  --status SUBMISSION_ID      If given, requests the status of the driver specified.
	
	 Spark standalone and Mesos only:
	  --total-executor-cores NUM  Total cores for all executors.
	
	 Spark standalone, YARN and Kubernetes only:
	  --executor-cores NUM        Number of cores used by each executor. (Default: 1 in
	                              YARN and K8S modes, or all available cores on the worker
	                              in standalone mode).
	
	 Spark on YARN and Kubernetes only:
	  --num-executors NUM         Number of executors to launch (Default: 2).
	                              If dynamic allocation is enabled, the initial number of
	                              executors will be at least NUM.
	  --principal PRINCIPAL       Principal to be used to login to KDC.
	  --keytab KEYTAB             The full path to the file that contains the keytab for the
	                              principal specified above.
	
	 Spark on YARN only:
	  --queue QUEUE_NAME          The YARN queue to submit to (Default: "default").
	      
	/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_81/493/1168/493_1168.sh: line 15: --files: command not found
[WI-493][TI-1168] - [INFO] 2024-04-23 11:30:38.081 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_81/493/1168, processId:4300 ,exitStatusCode:127 ,processWaitForStatus:true ,processExitValue:127
[WI-493][TI-1168] - [INFO] 2024-04-23 11:30:38.082 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-493][TI-1168] - [INFO] 2024-04-23 11:30:38.083 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-493][TI-1168] - [INFO] 2024-04-23 11:30:38.083 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-493][TI-1168] - [INFO] 2024-04-23 11:30:38.084 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-493][TI-1168] - [INFO] 2024-04-23 11:30:38.086 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: FAILURE to master : 172.18.1.1:1234
[WI-493][TI-1168] - [INFO] 2024-04-23 11:30:38.087 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-493][TI-1168] - [INFO] 2024-04-23 11:30:38.087 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_81/493/1168
[WI-493][TI-1168] - [INFO] 2024-04-23 11:30:38.087 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_81/493/1168
[WI-493][TI-1168] - [INFO] 2024-04-23 11:30:38.088 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-1168] - [INFO] 2024-04-23 11:30:38.123 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1168, processInstanceId=493, status=6, startTime=1713843036033, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/81/493/1168.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_81/493/1168, endTime=1713843038083, processId=4300, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1168] - [INFO] 2024-04-23 11:30:38.127 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1168, processInstanceId=493, status=6, startTime=1713843036033, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/81/493/1168.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_81/493/1168, endTime=1713843038083, processId=4300, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713843038122)
[WI-0][TI-1168] - [INFO] 2024-04-23 11:30:38.954 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1168, success=true)
[WI-0][TI-1168] - [INFO] 2024-04-23 11:30:38.960 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1168, success=true)
[WI-0][TI-0] - [INFO] 2024-04-23 11:30:42.387 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7630057803468209 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:30:43.415 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8314606741573034 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:30:44.416 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8260869565217391 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:32:01.762 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.719298245614035 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-1144] - [INFO] 2024-04-23 11:32:14.416 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1144, processInstanceId=489, status=9, startTime=1713840953087, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/80/489/1144.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1144, endTime=1713841331355, processId=3026, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713842834336)
[WI-0][TI-1144] - [INFO] 2024-04-23 11:32:14.437 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1144, processInstanceId=489, status=9, startTime=1713840953087, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/80/489/1144.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1144, endTime=1713841331355, processId=3026, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713843134416)
[WI-0][TI-0] - [INFO] 2024-04-23 11:32:21.864 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.73463687150838 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:32:22.891 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7625698324022346 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:32:23.891 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7075208913649025 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:32:38.969 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7222222222222222 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:32:40.003 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7375690607734807 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:32:41.006 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8072625698324023 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:32:46.422 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1171, taskName=search for intake JSON files, firstSubmitTime=1713843166416, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.9:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=82, appIds=null, processInstanceId=493, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"processing"}], executorId=1, cmdTypeIfComplement=7, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":""}],"rawScript":"# find 1 raw file in the folder\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\n\n# check if raw_file_dir is empty, then set raw_file_dir to null\nif [ -z \"$raw_file_dir\" ]; then\n    raw_file_dir=null\nfi\n\necho \"#{setValue(raw_file_dir=${raw_file_dir})}\"","resourceList":[]}, environmentConfig=export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='search for intake JSON files'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240423'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1171'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13340113777664'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240423113246'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='processing'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='493'}, raw_file_dir=Property{prop='raw_file_dir', direct=OUT, type=VARCHAR, value='/local_storage/reddit/processing/386-20240422.json'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240422'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-493][TI-1171] - [INFO] 2024-04-23 11:32:46.424 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: search for intake JSON files to wait queue success
[WI-493][TI-1171] - [INFO] 2024-04-23 11:32:46.424 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-493][TI-1171] - [INFO] 2024-04-23 11:32:46.426 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-493][TI-1171] - [INFO] 2024-04-23 11:32:46.426 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-493][TI-1171] - [INFO] 2024-04-23 11:32:46.426 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-493][TI-1171] - [INFO] 2024-04-23 11:32:46.426 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713843166426
[WI-493][TI-1171] - [INFO] 2024-04-23 11:32:46.427 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 493_1171
[WI-493][TI-1171] - [INFO] 2024-04-23 11:32:46.427 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1171,
  "taskName" : "search for intake JSON files",
  "firstSubmitTime" : 1713843166416,
  "startTime" : 1713843166426,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.9:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240423/13201021801792/82/493/1171.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 82,
  "processInstanceId" : 493,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"processing\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 7,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[{\"prop\":\"raw_file_dir\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"\"}],\"rawScript\":\"# find 1 raw file in the folder\\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\\n\\n# check if raw_file_dir is empty, then set raw_file_dir to null\\nif [ -z \\\"$raw_file_dir\\\" ]; then\\n    raw_file_dir=null\\nfi\\n\\necho \\\"#{setValue(raw_file_dir=${raw_file_dir})}\\\"\",\"resourceList\":[]}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "search for intake JSON files"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1171"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13340113777664"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423113246"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "processing"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "493"
    },
    "raw_file_dir" : {
      "prop" : "raw_file_dir",
      "direct" : "OUT",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit/processing/386-20240422.json"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240422"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "493_1171",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"raw_file_dir\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"/local_storage/reddit/processing/386-20240422.json\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-493][TI-1171] - [INFO] 2024-04-23 11:32:46.428 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-493][TI-1171] - [INFO] 2024-04-23 11:32:46.428 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-493][TI-1171] - [INFO] 2024-04-23 11:32:46.428 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-493][TI-1171] - [INFO] 2024-04-23 11:32:46.432 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-493][TI-1171] - [INFO] 2024-04-23 11:32:46.433 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-493][TI-1171] - [INFO] 2024-04-23 11:32:46.434 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_82/493/1171 check successfully
[WI-493][TI-1171] - [INFO] 2024-04-23 11:32:46.434 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-493][TI-1171] - [INFO] 2024-04-23 11:32:46.434 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-493][TI-1171] - [INFO] 2024-04-23 11:32:46.434 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-493][TI-1171] - [INFO] 2024-04-23 11:32:46.434 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-493][TI-1171] - [INFO] 2024-04-23 11:32:46.437 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ {
    "prop" : "raw_file_dir",
    "direct" : "OUT",
    "type" : "VARCHAR",
    "value" : ""
  } ],
  "varPool" : null,
  "rawScript" : "# find 1 raw file in the folder\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\n\n# check if raw_file_dir is empty, then set raw_file_dir to null\nif [ -z \"$raw_file_dir\" ]; then\n    raw_file_dir=null\nfi\n\necho \"#{setValue(raw_file_dir=${raw_file_dir})}\"",
  "resourceList" : [ ]
}
[WI-493][TI-1171] - [INFO] 2024-04-23 11:32:46.438 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-493][TI-1171] - [INFO] 2024-04-23 11:32:46.438 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}] successfully
[WI-493][TI-1171] - [INFO] 2024-04-23 11:32:46.438 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-493][TI-1171] - [INFO] 2024-04-23 11:32:46.438 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-493][TI-1171] - [INFO] 2024-04-23 11:32:46.438 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-493][TI-1171] - [INFO] 2024-04-23 11:32:46.449 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-493][TI-1171] - [INFO] 2024-04-23 11:32:46.449 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-493][TI-1171] - [INFO] 2024-04-23 11:32:46.449 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export PYTHON_LAUNCHER=/bin/python3.11
# find 1 raw file in the folder
raw_file_dir=$(find /local_storage/reddit/processing -type f -name '*.json'| head -n 1)

# check if raw_file_dir is empty, then set raw_file_dir to null
if [ -z "$raw_file_dir" ]; then
    raw_file_dir=null
fi

echo "#{setValue(raw_file_dir=/local_storage/reddit/processing/386-20240422.json)}"
[WI-493][TI-1171] - [INFO] 2024-04-23 11:32:46.449 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-493][TI-1171] - [INFO] 2024-04-23 11:32:46.449 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_82/493/1171/493_1171.sh
[WI-493][TI-1171] - [INFO] 2024-04-23 11:32:46.466 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 4374
[WI-0][TI-1171] - [INFO] 2024-04-23 11:32:46.488 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionRunningEvent(taskInstanceId=1171, processInstanceId=493, startTime=1713843166426, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, status=TaskExecutionStatus{code=1, desc='running'}, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/82/493/1171.log, executePath=null, processId=0, appIds=null, eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1171] - [INFO] 2024-04-23 11:32:46.498 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionRunningEvent(taskInstanceId=1171, processInstanceId=493, startTime=1713843166426, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, status=TaskExecutionStatus{code=1, desc='running'}, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/82/493/1171.log, executePath=null, processId=0, appIds=null, eventCreateTime=0, eventSendTime=1713843166484)
[WI-0][TI-1171] - [INFO] 2024-04-23 11:32:46.498 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionInfoEvent(taskInstanceId=1171, processInstanceId=493, startTime=1713843166426, workflowInstanceHost=172.18.0.9:5678, taskInstanceHost=172.18.1.1:1234, logPath=null, processId=0, eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1171] - [INFO] 2024-04-23 11:32:46.504 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionInfoEvent(taskInstanceId=1171, processInstanceId=493, startTime=1713843166426, workflowInstanceHost=172.18.0.9:5678, taskInstanceHost=172.18.1.1:1234, logPath=null, processId=0, eventCreateTime=0, eventSendTime=1713843166484)
[WI-0][TI-1171] - [INFO] 2024-04-23 11:32:47.241 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1171, success=true)
[WI-0][TI-1171] - [INFO] 2024-04-23 11:32:47.246 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1171)
[WI-0][TI-1171] - [INFO] 2024-04-23 11:32:47.254 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1171, success=true)
[WI-0][TI-1171] - [INFO] 2024-04-23 11:32:47.259 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1171)
[WI-0][TI-0] - [INFO] 2024-04-23 11:32:47.467 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
	#{setValue(raw_file_dir=/local_storage/reddit/processing/386-20240422.json)}
[WI-493][TI-1171] - [INFO] 2024-04-23 11:32:47.469 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_82/493/1171, processId:4374 ,exitStatusCode:0 ,processWaitForStatus:true ,processExitValue:0
[WI-493][TI-1171] - [INFO] 2024-04-23 11:32:47.471 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-493][TI-1171] - [INFO] 2024-04-23 11:32:47.471 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-493][TI-1171] - [INFO] 2024-04-23 11:32:47.471 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-493][TI-1171] - [INFO] 2024-04-23 11:32:47.471 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-493][TI-1171] - [INFO] 2024-04-23 11:32:47.478 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: SUCCESS to master : 172.18.1.1:1234
[WI-493][TI-1171] - [INFO] 2024-04-23 11:32:47.479 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-493][TI-1171] - [INFO] 2024-04-23 11:32:47.479 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_82/493/1171
[WI-493][TI-1171] - [INFO] 2024-04-23 11:32:47.480 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_82/493/1171
[WI-493][TI-1171] - [INFO] 2024-04-23 11:32:47.480 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-1171] - [INFO] 2024-04-23 11:32:47.506 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1171, processInstanceId=493, status=7, startTime=1713843166426, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/82/493/1171.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_82/493/1171, endTime=1713843167471, processId=4374, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1171] - [INFO] 2024-04-23 11:32:47.510 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1171, processInstanceId=493, status=7, startTime=1713843166426, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/82/493/1171.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_82/493/1171, endTime=1713843167471, processId=4374, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713843167506)
[WI-0][TI-1171] - [INFO] 2024-04-23 11:32:48.242 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1171, success=true)
[WI-0][TI-1171] - [INFO] 2024-04-23 11:32:48.244 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1171, success=true)
[WI-0][TI-0] - [INFO] 2024-04-23 11:32:49.293 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1173, taskName=move to processing, firstSubmitTime=1713843169287, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.9:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=82, appIds=null, processInstanceId=493, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"processing"}], executorId=1, cmdTypeIfComplement=7, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":""}],"rawScript":"# move file to the reddit processing folder\n# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error\nfilename=$(basename \"${raw_file_dir}\")\nif ! grep -q \"${REDDIT_HOME}/processing\" <<< \"${raw_file_dir}\"; then\n    mv ${raw_file_dir} ${REDDIT_HOME}/processing\nelse\n    echo JSON is already in processing\nfi\n\n# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing\necho \"#{setValue(raw_file_dir=${REDDIT_HOME}/processing/${filename})}\"","resourceList":[]}, environmentConfig=export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='move to processing'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240423'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1173'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13340390094208'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240423113249'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='processing'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='493'}, raw_file_dir=Property{prop='raw_file_dir', direct=IN, type=VARCHAR, value='/local_storage/reddit/processing/386-20240422.json'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240422'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-493][TI-1173] - [INFO] 2024-04-23 11:32:49.294 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: move to processing to wait queue success
[WI-493][TI-1173] - [INFO] 2024-04-23 11:32:49.294 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-493][TI-1173] - [INFO] 2024-04-23 11:32:49.295 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-493][TI-1173] - [INFO] 2024-04-23 11:32:49.295 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-493][TI-1173] - [INFO] 2024-04-23 11:32:49.295 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-493][TI-1173] - [INFO] 2024-04-23 11:32:49.295 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713843169295
[WI-493][TI-1173] - [INFO] 2024-04-23 11:32:49.295 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 493_1173
[WI-493][TI-1173] - [INFO] 2024-04-23 11:32:49.295 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1173,
  "taskName" : "move to processing",
  "firstSubmitTime" : 1713843169287,
  "startTime" : 1713843169295,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.9:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240423/13201021801792/82/493/1173.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 82,
  "processInstanceId" : 493,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"processing\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 7,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[{\"prop\":\"raw_file_dir\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"\"}],\"rawScript\":\"# move file to the reddit processing folder\\n# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error\\nfilename=$(basename \\\"${raw_file_dir}\\\")\\nif ! grep -q \\\"${REDDIT_HOME}/processing\\\" <<< \\\"${raw_file_dir}\\\"; then\\n    mv ${raw_file_dir} ${REDDIT_HOME}/processing\\nelse\\n    echo JSON is already in processing\\nfi\\n\\n# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing\\necho \\\"#{setValue(raw_file_dir=${REDDIT_HOME}/processing/${filename})}\\\"\",\"resourceList\":[]}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "move to processing"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1173"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13340390094208"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423113249"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "processing"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "493"
    },
    "raw_file_dir" : {
      "prop" : "raw_file_dir",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit/processing/386-20240422.json"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240422"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "493_1173",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"raw_file_dir\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"/local_storage/reddit/processing/386-20240422.json\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-493][TI-1173] - [INFO] 2024-04-23 11:32:49.296 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-493][TI-1173] - [INFO] 2024-04-23 11:32:49.296 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-493][TI-1173] - [INFO] 2024-04-23 11:32:49.296 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-493][TI-1173] - [INFO] 2024-04-23 11:32:49.298 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-493][TI-1173] - [INFO] 2024-04-23 11:32:49.299 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-493][TI-1173] - [INFO] 2024-04-23 11:32:49.299 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_82/493/1173 check successfully
[WI-493][TI-1173] - [INFO] 2024-04-23 11:32:49.299 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-493][TI-1173] - [INFO] 2024-04-23 11:32:49.299 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-493][TI-1173] - [INFO] 2024-04-23 11:32:49.300 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-493][TI-1173] - [INFO] 2024-04-23 11:32:49.300 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-493][TI-1173] - [INFO] 2024-04-23 11:32:49.300 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ {
    "prop" : "raw_file_dir",
    "direct" : "OUT",
    "type" : "VARCHAR",
    "value" : ""
  } ],
  "varPool" : null,
  "rawScript" : "# move file to the reddit processing folder\n# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error\nfilename=$(basename \"${raw_file_dir}\")\nif ! grep -q \"${REDDIT_HOME}/processing\" <<< \"${raw_file_dir}\"; then\n    mv ${raw_file_dir} ${REDDIT_HOME}/processing\nelse\n    echo JSON is already in processing\nfi\n\n# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing\necho \"#{setValue(raw_file_dir=${REDDIT_HOME}/processing/${filename})}\"",
  "resourceList" : [ ]
}
[WI-493][TI-1173] - [INFO] 2024-04-23 11:32:49.300 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-493][TI-1173] - [INFO] 2024-04-23 11:32:49.300 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}] successfully
[WI-493][TI-1173] - [INFO] 2024-04-23 11:32:49.300 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-493][TI-1173] - [INFO] 2024-04-23 11:32:49.300 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-493][TI-1173] - [INFO] 2024-04-23 11:32:49.300 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-493][TI-1173] - [INFO] 2024-04-23 11:32:49.301 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-493][TI-1173] - [INFO] 2024-04-23 11:32:49.301 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-493][TI-1173] - [INFO] 2024-04-23 11:32:49.301 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export PYTHON_LAUNCHER=/bin/python3.11
# move file to the reddit processing folder
# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error
filename=$(basename "/local_storage/reddit/processing/386-20240422.json")
if ! grep -q "/local_storage/reddit/processing" <<< "/local_storage/reddit/processing/386-20240422.json"; then
    mv /local_storage/reddit/processing/386-20240422.json /local_storage/reddit/processing
else
    echo JSON is already in processing
fi

# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing
echo "#{setValue(raw_file_dir=/local_storage/reddit/processing/${filename})}"
[WI-493][TI-1173] - [INFO] 2024-04-23 11:32:49.301 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-493][TI-1173] - [INFO] 2024-04-23 11:32:49.301 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_82/493/1173/493_1173.sh
[WI-493][TI-1173] - [INFO] 2024-04-23 11:32:49.305 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 4388
[WI-0][TI-1173] - [INFO] 2024-04-23 11:32:49.515 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionRunningEvent(taskInstanceId=1173, processInstanceId=493, startTime=1713843169295, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, status=TaskExecutionStatus{code=1, desc='running'}, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/82/493/1173.log, executePath=null, processId=0, appIds=null, eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1173] - [INFO] 2024-04-23 11:32:49.529 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionRunningEvent(taskInstanceId=1173, processInstanceId=493, startTime=1713843169295, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, status=TaskExecutionStatus{code=1, desc='running'}, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/82/493/1173.log, executePath=null, processId=0, appIds=null, eventCreateTime=0, eventSendTime=1713843169515)
[WI-0][TI-1173] - [INFO] 2024-04-23 11:32:49.532 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionInfoEvent(taskInstanceId=1173, processInstanceId=493, startTime=1713843169295, workflowInstanceHost=172.18.0.9:5678, taskInstanceHost=172.18.1.1:1234, logPath=null, processId=0, eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1173] - [INFO] 2024-04-23 11:32:49.533 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionInfoEvent(taskInstanceId=1173, processInstanceId=493, startTime=1713843169295, workflowInstanceHost=172.18.0.9:5678, taskInstanceHost=172.18.1.1:1234, logPath=null, processId=0, eventCreateTime=0, eventSendTime=1713843169515)
[WI-0][TI-1173] - [INFO] 2024-04-23 11:32:50.243 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1173, success=true)
[WI-0][TI-1173] - [INFO] 2024-04-23 11:32:50.248 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1173)
[WI-0][TI-1173] - [INFO] 2024-04-23 11:32:50.256 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1173, success=true)
[WI-0][TI-1173] - [INFO] 2024-04-23 11:32:50.261 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1173)
[WI-0][TI-0] - [INFO] 2024-04-23 11:32:50.306 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
	JSON is already in processing
	#{setValue(raw_file_dir=/local_storage/reddit/processing/386-20240422.json)}
[WI-493][TI-1173] - [INFO] 2024-04-23 11:32:50.309 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_82/493/1173, processId:4388 ,exitStatusCode:0 ,processWaitForStatus:true ,processExitValue:0
[WI-493][TI-1173] - [INFO] 2024-04-23 11:32:50.309 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-493][TI-1173] - [INFO] 2024-04-23 11:32:50.309 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-493][TI-1173] - [INFO] 2024-04-23 11:32:50.309 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-493][TI-1173] - [INFO] 2024-04-23 11:32:50.310 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-493][TI-1173] - [INFO] 2024-04-23 11:32:50.328 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: SUCCESS to master : 172.18.1.1:1234
[WI-493][TI-1173] - [INFO] 2024-04-23 11:32:50.330 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-493][TI-1173] - [INFO] 2024-04-23 11:32:50.330 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_82/493/1173
[WI-493][TI-1173] - [INFO] 2024-04-23 11:32:50.330 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_82/493/1173
[WI-493][TI-1173] - [INFO] 2024-04-23 11:32:50.331 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-1173] - [INFO] 2024-04-23 11:32:50.535 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1173, processInstanceId=493, status=7, startTime=1713843169295, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/82/493/1173.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_82/493/1173, endTime=1713843170310, processId=4388, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1173] - [INFO] 2024-04-23 11:32:50.538 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1173, processInstanceId=493, status=7, startTime=1713843169295, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/82/493/1173.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_82/493/1173, endTime=1713843170310, processId=4388, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713843170535)
[WI-0][TI-1173] - [INFO] 2024-04-23 11:32:51.241 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1173, success=true)
[WI-0][TI-1173] - [INFO] 2024-04-23 11:32:51.243 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1173, success=true)
[WI-0][TI-0] - [INFO] 2024-04-23 11:32:51.328 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1174, taskName=spark preprocessing, firstSubmitTime=1713843171321, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.9:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=82, appIds=null, processInstanceId=493, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"processing"}], executorId=1, cmdTypeIfComplement=7, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[],"rawScript":"# $SPARK_HOME/bin/spark-submit \\\n#     --master spark://spark-master:7077 \\\n#     --conf spark.driver.cores=2 \\\n#     --conf spark.driver.memory=2G \\\n#     --conf spark.executor.instances=1 \\\n#     --conf spark.executor.cores=2 \\\n#     --conf spark.executor.memory=2G \\\n#     --files ${raw_file_dir} \\\n#     --name reddit_preprocessing spark_reddit_preprocessing.py\n\n$SPARK_HOME/bin/spark-submit \\\n    --master spark://spark-master:7077 \\\n    --files /path/to/raw_file_dir/raw_file.txt \\\n    --name reddit_preprocessing spark_reddit_preprocessing.py\n","resourceList":[{"id":null,"resourceName":"file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py","res":null}]}, environmentConfig=export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export HADOOP_CONF_DIR=/opt/hadoop-3.4.0/etc/hadoop
export PYSPARK_DRIVER_PYTHON=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='spark preprocessing'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240423'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1174'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13210058002752'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240423113251'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='processing'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='493'}, raw_file_dir=Property{prop='raw_file_dir', direct=IN, type=VARCHAR, value='/local_storage/reddit/processing/386-20240422.json'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240422'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-493][TI-1174] - [INFO] 2024-04-23 11:32:51.333 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: spark preprocessing to wait queue success
[WI-493][TI-1174] - [INFO] 2024-04-23 11:32:51.338 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-493][TI-1174] - [INFO] 2024-04-23 11:32:51.339 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-493][TI-1174] - [INFO] 2024-04-23 11:32:51.340 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-493][TI-1174] - [INFO] 2024-04-23 11:32:51.340 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-493][TI-1174] - [INFO] 2024-04-23 11:32:51.340 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713843171340
[WI-493][TI-1174] - [INFO] 2024-04-23 11:32:51.340 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 493_1174
[WI-493][TI-1174] - [INFO] 2024-04-23 11:32:51.340 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1174,
  "taskName" : "spark preprocessing",
  "firstSubmitTime" : 1713843171321,
  "startTime" : 1713843171340,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.9:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240423/13201021801792/82/493/1174.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 82,
  "processInstanceId" : 493,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"processing\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 7,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[],\"rawScript\":\"# $SPARK_HOME/bin/spark-submit \\\\\\n#     --master spark://spark-master:7077 \\\\\\n#     --conf spark.driver.cores=2 \\\\\\n#     --conf spark.driver.memory=2G \\\\\\n#     --conf spark.executor.instances=1 \\\\\\n#     --conf spark.executor.cores=2 \\\\\\n#     --conf spark.executor.memory=2G \\\\\\n#     --files ${raw_file_dir} \\\\\\n#     --name reddit_preprocessing spark_reddit_preprocessing.py\\n\\n$SPARK_HOME/bin/spark-submit \\\\\\n    --master spark://spark-master:7077 \\\\\\n    --files /path/to/raw_file_dir/raw_file.txt \\\\\\n    --name reddit_preprocessing spark_reddit_preprocessing.py\\n\",\"resourceList\":[{\"id\":null,\"resourceName\":\"file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py\",\"res\":null}]}",
  "environmentConfig" : "export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3\nexport JAVA_HOME=/opt/java/openjdk\nexport HADOOP_CONF_DIR=/opt/hadoop-3.4.0/etc/hadoop\nexport PYSPARK_DRIVER_PYTHON=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "spark preprocessing"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1174"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13210058002752"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423113251"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "processing"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "493"
    },
    "raw_file_dir" : {
      "prop" : "raw_file_dir",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit/processing/386-20240422.json"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240422"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "493_1174",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"raw_file_dir\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"/local_storage/reddit/processing/386-20240422.json\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-493][TI-1174] - [INFO] 2024-04-23 11:32:51.341 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-493][TI-1174] - [INFO] 2024-04-23 11:32:51.341 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-493][TI-1174] - [INFO] 2024-04-23 11:32:51.341 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-493][TI-1174] - [INFO] 2024-04-23 11:32:51.344 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-493][TI-1174] - [INFO] 2024-04-23 11:32:51.344 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-493][TI-1174] - [INFO] 2024-04-23 11:32:51.345 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_82/493/1174 check successfully
[WI-493][TI-1174] - [INFO] 2024-04-23 11:32:51.345 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-493][TI-1174] - [INFO] 2024-04-23 11:32:51.347 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py=ResourceContext.ResourceItem(resourceAbsolutePathInStorage=file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py, resourceRelativePath=spark_reddit_preprocessing.py, resourceAbsolutePathInLocal=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_82/493/1174/spark_reddit_preprocessing.py)})
[WI-493][TI-1174] - [INFO] 2024-04-23 11:32:51.347 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-493][TI-1174] - [INFO] 2024-04-23 11:32:51.348 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-493][TI-1174] - [INFO] 2024-04-23 11:32:51.348 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ ],
  "varPool" : null,
  "rawScript" : "# $SPARK_HOME/bin/spark-submit \\\n#     --master spark://spark-master:7077 \\\n#     --conf spark.driver.cores=2 \\\n#     --conf spark.driver.memory=2G \\\n#     --conf spark.executor.instances=1 \\\n#     --conf spark.executor.cores=2 \\\n#     --conf spark.executor.memory=2G \\\n#     --files ${raw_file_dir} \\\n#     --name reddit_preprocessing spark_reddit_preprocessing.py\n\n$SPARK_HOME/bin/spark-submit \\\n    --master spark://spark-master:7077 \\\n    --files /path/to/raw_file_dir/raw_file.txt \\\n    --name reddit_preprocessing spark_reddit_preprocessing.py\n",
  "resourceList" : [ {
    "id" : null,
    "resourceName" : "file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py",
    "res" : null
  } ]
}
[WI-493][TI-1174] - [INFO] 2024-04-23 11:32:51.348 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-493][TI-1174] - [INFO] 2024-04-23 11:32:51.348 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}] successfully
[WI-493][TI-1174] - [INFO] 2024-04-23 11:32:51.348 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-493][TI-1174] - [INFO] 2024-04-23 11:32:51.348 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-493][TI-1174] - [INFO] 2024-04-23 11:32:51.348 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-493][TI-1174] - [INFO] 2024-04-23 11:32:51.349 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-493][TI-1174] - [INFO] 2024-04-23 11:32:51.349 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-493][TI-1174] - [INFO] 2024-04-23 11:32:51.349 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export HADOOP_CONF_DIR=/opt/hadoop-3.4.0/etc/hadoop
export PYSPARK_DRIVER_PYTHON=/bin/python3.11
# $SPARK_HOME/bin/spark-submit \
#     --master spark://spark-master:7077 \
#     --conf spark.driver.cores=2 \
#     --conf spark.driver.memory=2G \
#     --conf spark.executor.instances=1 \
#     --conf spark.executor.cores=2 \
#     --conf spark.executor.memory=2G \
#     --files /local_storage/reddit/processing/386-20240422.json \
#     --name reddit_preprocessing spark_reddit_preprocessing.py

$SPARK_HOME/bin/spark-submit \
    --master spark://spark-master:7077 \
    --files /path/to/raw_file_dir/raw_file.txt \
    --name reddit_preprocessing spark_reddit_preprocessing.py

[WI-493][TI-1174] - [INFO] 2024-04-23 11:32:51.349 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-493][TI-1174] - [INFO] 2024-04-23 11:32:51.350 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_82/493/1174/493_1174.sh
[WI-493][TI-1174] - [INFO] 2024-04-23 11:32:51.360 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 4400
[WI-0][TI-1174] - [INFO] 2024-04-23 11:32:51.546 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionRunningEvent(taskInstanceId=1174, processInstanceId=493, startTime=1713843171340, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, status=TaskExecutionStatus{code=1, desc='running'}, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/82/493/1174.log, executePath=null, processId=0, appIds=null, eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1174] - [INFO] 2024-04-23 11:32:51.552 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionRunningEvent(taskInstanceId=1174, processInstanceId=493, startTime=1713843171340, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, status=TaskExecutionStatus{code=1, desc='running'}, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/82/493/1174.log, executePath=null, processId=0, appIds=null, eventCreateTime=0, eventSendTime=1713843171546)
[WI-0][TI-1174] - [INFO] 2024-04-23 11:32:51.552 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionInfoEvent(taskInstanceId=1174, processInstanceId=493, startTime=1713843171340, workflowInstanceHost=172.18.0.9:5678, taskInstanceHost=172.18.1.1:1234, logPath=null, processId=0, eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1174] - [INFO] 2024-04-23 11:32:51.562 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionInfoEvent(taskInstanceId=1174, processInstanceId=493, startTime=1713843171340, workflowInstanceHost=172.18.0.9:5678, taskInstanceHost=172.18.1.1:1234, logPath=null, processId=0, eventCreateTime=0, eventSendTime=1713843171546)
[WI-0][TI-1174] - [INFO] 2024-04-23 11:32:52.254 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1174, success=true)
[WI-0][TI-1174] - [INFO] 2024-04-23 11:32:52.259 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1174)
[WI-0][TI-1174] - [INFO] 2024-04-23 11:32:52.263 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1174, success=true)
[WI-0][TI-1174] - [INFO] 2024-04-23 11:32:52.267 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1174)
[WI-0][TI-0] - [INFO] 2024-04-23 11:32:52.364 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
[WI-0][TI-0] - [INFO] 2024-04-23 11:32:53.064 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7585227272727273 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:32:54.072 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8563685636856369 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:32:55.151 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8130841121495327 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:32:55.373 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:32:54 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[WI-0][TI-0] - [INFO] 2024-04-23 11:32:56.152 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9037267080745341 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:32:56.375 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:32:55 INFO SparkContext: Running Spark version 3.5.1
	24/04/23 11:32:55 INFO SparkContext: OS info Linux, 6.5.0-28-generic, amd64
	24/04/23 11:32:55 INFO SparkContext: Java version 1.8.0_402
	24/04/23 11:32:55 INFO ResourceUtils: ==============================================================
	24/04/23 11:32:55 INFO ResourceUtils: No custom resources configured for spark.driver.
	24/04/23 11:32:55 INFO ResourceUtils: ==============================================================
	24/04/23 11:32:55 INFO SparkContext: Submitted application: reddit_preprocessing
	24/04/23 11:32:55 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
	24/04/23 11:32:55 INFO ResourceProfile: Limiting resource is cpu
	24/04/23 11:32:55 INFO ResourceProfileManager: Added ResourceProfile id: 0
	24/04/23 11:32:55 INFO SecurityManager: Changing view acls to: default
	24/04/23 11:32:55 INFO SecurityManager: Changing modify acls to: default
	24/04/23 11:32:55 INFO SecurityManager: Changing view acls groups to: 
	24/04/23 11:32:55 INFO SecurityManager: Changing modify acls groups to: 
	24/04/23 11:32:55 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: default; groups with view permissions: EMPTY; users with modify permissions: default; groups with modify permissions: EMPTY
	24/04/23 11:32:56 INFO Utils: Successfully started service 'sparkDriver' on port 35231.
	24/04/23 11:32:56 INFO SparkEnv: Registering MapOutputTracker
[WI-0][TI-0] - [INFO] 2024-04-23 11:32:57.164 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8681672025723473 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:32:57.379 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:32:56 INFO SparkEnv: Registering BlockManagerMaster
	24/04/23 11:32:56 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
	24/04/23 11:32:56 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
	24/04/23 11:32:56 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
	24/04/23 11:32:56 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-0f704c0a-8f9b-4d92-b648-57113ec3e1e3
	24/04/23 11:32:56 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
	24/04/23 11:32:56 INFO SparkEnv: Registering OutputCommitCoordinator
	24/04/23 11:32:56 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
[WI-0][TI-0] - [INFO] 2024-04-23 11:32:58.164 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8952095808383234 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:32:58.379 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:32:57 INFO Utils: Successfully started service 'SparkUI' on port 4040.
	24/04/23 11:32:57 ERROR SparkContext: Error initializing SparkContext.
	java.io.FileNotFoundException: File file:/path/to/raw_file_dir/raw_file.txt does not exist
		at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:779)
		at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:1100)
		at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:769)
		at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:462)
		at org.apache.spark.SparkContext.addFile(SparkContext.scala:1755)
		at org.apache.spark.SparkContext.$anonfun$new$16(SparkContext.scala:533)
		at org.apache.spark.SparkContext.$anonfun$new$16$adapted(SparkContext.scala:533)
		at scala.collection.immutable.List.foreach(List.scala:431)
		at org.apache.spark.SparkContext.<init>(SparkContext.scala:533)
		at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)
		at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
		at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
		at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
		at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
		at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)
		at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
		at py4j.Gateway.invoke(Gateway.java:238)
		at py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)
		at py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)
		at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
		at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
		at java.lang.Thread.run(Thread.java:750)
	24/04/23 11:32:57 INFO SparkContext: SparkContext is stopping with exitCode 0.
	24/04/23 11:32:57 INFO SparkUI: Stopped Spark web UI at http://c0e814e3f0bd:4040
	24/04/23 11:32:57 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
	24/04/23 11:32:57 INFO MemoryStore: MemoryStore cleared
	24/04/23 11:32:57 INFO BlockManager: BlockManager stopped
	24/04/23 11:32:57 INFO BlockManagerMaster: BlockManagerMaster stopped
	24/04/23 11:32:57 WARN MetricsSystem: Stopping a MetricsSystem that is not running
	24/04/23 11:32:57 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
	24/04/23 11:32:57 INFO SparkContext: Successfully stopped SparkContext
	Traceback (most recent call last):
	  File "/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_82/493/1174/spark_reddit_preprocessing.py", line 24, in <module>
	    sc = pyspark.SparkContext(appName="reddit_preprocessing")
	         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
	  File "/opt/spark-3.5.1-bin-hadoop3/python/lib/pyspark.zip/pyspark/context.py", line 203, in __init__
	  File "/opt/spark-3.5.1-bin-hadoop3/python/lib/pyspark.zip/pyspark/context.py", line 296, in _do_init
	  File "/opt/spark-3.5.1-bin-hadoop3/python/lib/pyspark.zip/pyspark/context.py", line 421, in _initialize_context
	  File "/opt/spark-3.5.1-bin-hadoop3/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1587, in __call__
	  File "/opt/spark-3.5.1-bin-hadoop3/python/lib/py4j-0.10.9.7-src.zip/py4j/protocol.py", line 326, in get_return_value
	py4j.protocol.Py4JJavaError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext.
	: java.io.FileNotFoundException: File file:/path/to/raw_file_dir/raw_file.txt does not exist
		at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:779)
		at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:1100)
		at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:769)
		at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:462)
		at org.apache.spark.SparkContext.addFile(SparkContext.scala:1755)
		at org.apache.spark.SparkContext.$anonfun$new$16(SparkContext.scala:533)
		at org.apache.spark.SparkContext.$anonfun$new$16$adapted(SparkContext.scala:533)
		at scala.collection.immutable.List.foreach(List.scala:431)
		at org.apache.spark.SparkContext.<init>(SparkContext.scala:533)
		at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)
		at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
		at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
		at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
		at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
		at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)
		at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
		at py4j.Gateway.invoke(Gateway.java:238)
		at py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)
		at py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)
		at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
		at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
		at java.lang.Thread.run(Thread.java:750)
	
	24/04/23 11:32:58 INFO ShutdownHookManager: Shutdown hook called
	24/04/23 11:32:58 INFO ShutdownHookManager: Deleting directory /tmp/spark-4033d396-1f00-483b-8170-67a8b8f1253c
	24/04/23 11:32:58 INFO ShutdownHookManager: Deleting directory /tmp/spark-3b1ae290-174f-4fdb-9c5e-8df7ba67a74b
[WI-493][TI-1174] - [INFO] 2024-04-23 11:32:58.382 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_82/493/1174, processId:4400 ,exitStatusCode:1 ,processWaitForStatus:true ,processExitValue:1
[WI-493][TI-1174] - [INFO] 2024-04-23 11:32:58.383 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-493][TI-1174] - [INFO] 2024-04-23 11:32:58.384 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-493][TI-1174] - [INFO] 2024-04-23 11:32:58.384 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-493][TI-1174] - [INFO] 2024-04-23 11:32:58.386 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-493][TI-1174] - [INFO] 2024-04-23 11:32:58.389 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: FAILURE to master : 172.18.1.1:1234
[WI-493][TI-1174] - [INFO] 2024-04-23 11:32:58.390 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-493][TI-1174] - [INFO] 2024-04-23 11:32:58.390 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_82/493/1174
[WI-493][TI-1174] - [INFO] 2024-04-23 11:32:58.391 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_82/493/1174
[WI-493][TI-1174] - [INFO] 2024-04-23 11:32:58.391 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-1174] - [INFO] 2024-04-23 11:32:58.589 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1174, processInstanceId=493, status=6, startTime=1713843171340, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/82/493/1174.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_82/493/1174, endTime=1713843178386, processId=4400, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1174] - [INFO] 2024-04-23 11:32:58.591 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1174, processInstanceId=493, status=6, startTime=1713843171340, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/82/493/1174.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_82/493/1174, endTime=1713843178386, processId=4400, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713843178588)
[WI-0][TI-1174] - [INFO] 2024-04-23 11:32:59.355 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1174, success=true)
[WI-0][TI-1174] - [INFO] 2024-04-23 11:32:59.361 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1174, success=true)
[WI-0][TI-0] - [INFO] 2024-04-23 11:33:16.252 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7183908045977011 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:33:57.386 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7329192546583851 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:34:23.772 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1175, taskName=search for intake JSON files, firstSubmitTime=1713843263767, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.9:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=83, appIds=null, processInstanceId=494, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"processing"}], executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":""}],"rawScript":"# find 1 raw file in the folder\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\n\n# check if raw_file_dir is empty, then set raw_file_dir to null\nif [ -z \"$raw_file_dir\" ]; then\n    raw_file_dir=null\nfi\n\necho \"#{setValue(raw_file_dir=${raw_file_dir})}\"","resourceList":[]}, environmentConfig=export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='search for intake JSON files'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240423'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1175'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13340113777664'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240423113423'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='processing'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='494'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240422'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=null, dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-494][TI-1175] - [INFO] 2024-04-23 11:34:23.776 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: search for intake JSON files to wait queue success
[WI-494][TI-1175] - [INFO] 2024-04-23 11:34:23.777 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-494][TI-1175] - [INFO] 2024-04-23 11:34:23.786 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-494][TI-1175] - [INFO] 2024-04-23 11:34:23.786 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-494][TI-1175] - [INFO] 2024-04-23 11:34:23.786 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-494][TI-1175] - [INFO] 2024-04-23 11:34:23.786 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713843263786
[WI-494][TI-1175] - [INFO] 2024-04-23 11:34:23.786 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 494_1175
[WI-494][TI-1175] - [INFO] 2024-04-23 11:34:23.786 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1175,
  "taskName" : "search for intake JSON files",
  "firstSubmitTime" : 1713843263767,
  "startTime" : 1713843263786,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.9:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240423/13201021801792/83/494/1175.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 83,
  "processInstanceId" : 494,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"processing\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[{\"prop\":\"raw_file_dir\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"\"}],\"rawScript\":\"# find 1 raw file in the folder\\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\\n\\n# check if raw_file_dir is empty, then set raw_file_dir to null\\nif [ -z \\\"$raw_file_dir\\\" ]; then\\n    raw_file_dir=null\\nfi\\n\\necho \\\"#{setValue(raw_file_dir=${raw_file_dir})}\\\"\",\"resourceList\":[]}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "search for intake JSON files"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1175"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13340113777664"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423113423"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "processing"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "494"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240422"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "494_1175",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-494][TI-1175] - [INFO] 2024-04-23 11:34:23.787 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-494][TI-1175] - [INFO] 2024-04-23 11:34:23.787 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-494][TI-1175] - [INFO] 2024-04-23 11:34:23.787 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-494][TI-1175] - [INFO] 2024-04-23 11:34:23.792 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-494][TI-1175] - [INFO] 2024-04-23 11:34:23.793 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-494][TI-1175] - [INFO] 2024-04-23 11:34:23.794 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_83/494/1175 check successfully
[WI-494][TI-1175] - [INFO] 2024-04-23 11:34:23.794 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-494][TI-1175] - [INFO] 2024-04-23 11:34:23.794 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-494][TI-1175] - [INFO] 2024-04-23 11:34:23.798 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-494][TI-1175] - [INFO] 2024-04-23 11:34:23.798 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-494][TI-1175] - [INFO] 2024-04-23 11:34:23.798 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ {
    "prop" : "raw_file_dir",
    "direct" : "OUT",
    "type" : "VARCHAR",
    "value" : ""
  } ],
  "varPool" : null,
  "rawScript" : "# find 1 raw file in the folder\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\n\n# check if raw_file_dir is empty, then set raw_file_dir to null\nif [ -z \"$raw_file_dir\" ]; then\n    raw_file_dir=null\nfi\n\necho \"#{setValue(raw_file_dir=${raw_file_dir})}\"",
  "resourceList" : [ ]
}
[WI-494][TI-1175] - [INFO] 2024-04-23 11:34:23.798 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-494][TI-1175] - [INFO] 2024-04-23 11:34:23.799 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: null successfully
[WI-494][TI-1175] - [INFO] 2024-04-23 11:34:23.799 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-494][TI-1175] - [INFO] 2024-04-23 11:34:23.799 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-494][TI-1175] - [INFO] 2024-04-23 11:34:23.799 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-494][TI-1175] - [INFO] 2024-04-23 11:34:23.799 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-494][TI-1175] - [INFO] 2024-04-23 11:34:23.799 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-494][TI-1175] - [INFO] 2024-04-23 11:34:23.799 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export PYTHON_LAUNCHER=/bin/python3.11
# find 1 raw file in the folder
raw_file_dir=$(find /local_storage/reddit/processing -type f -name '*.json'| head -n 1)

# check if raw_file_dir is empty, then set raw_file_dir to null
if [ -z "$raw_file_dir" ]; then
    raw_file_dir=null
fi

echo "#{setValue(raw_file_dir=${raw_file_dir})}"
[WI-494][TI-1175] - [INFO] 2024-04-23 11:34:23.800 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-494][TI-1175] - [INFO] 2024-04-23 11:34:23.800 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_83/494/1175/494_1175.sh
[WI-494][TI-1175] - [INFO] 2024-04-23 11:34:23.808 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 4513
[WI-0][TI-1175] - [INFO] 2024-04-23 11:34:24.549 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1175, success=true)
[WI-0][TI-1175] - [INFO] 2024-04-23 11:34:24.555 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1175)
[WI-0][TI-0] - [INFO] 2024-04-23 11:34:24.809 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
	#{setValue(raw_file_dir=/local_storage/reddit/processing/386-20240422.json)}
[WI-494][TI-1175] - [INFO] 2024-04-23 11:34:24.813 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_83/494/1175, processId:4513 ,exitStatusCode:0 ,processWaitForStatus:true ,processExitValue:0
[WI-494][TI-1175] - [INFO] 2024-04-23 11:34:24.813 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-494][TI-1175] - [INFO] 2024-04-23 11:34:24.813 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-494][TI-1175] - [INFO] 2024-04-23 11:34:24.813 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-494][TI-1175] - [INFO] 2024-04-23 11:34:24.817 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-494][TI-1175] - [INFO] 2024-04-23 11:34:24.843 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: SUCCESS to master : 172.18.1.1:1234
[WI-494][TI-1175] - [INFO] 2024-04-23 11:34:24.843 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-494][TI-1175] - [INFO] 2024-04-23 11:34:24.843 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_83/494/1175
[WI-494][TI-1175] - [INFO] 2024-04-23 11:34:24.844 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_83/494/1175
[WI-494][TI-1175] - [INFO] 2024-04-23 11:34:24.844 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-1175] - [INFO] 2024-04-23 11:34:25.541 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1175, success=true)
[WI-0][TI-0] - [INFO] 2024-04-23 11:34:26.683 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1177, taskName=move to processing, firstSubmitTime=1713843266677, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.9:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=83, appIds=null, processInstanceId=494, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"processing"}], executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":""}],"rawScript":"# move file to the reddit processing folder\n# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error\nfilename=$(basename \"${raw_file_dir}\")\nif ! grep -q \"${REDDIT_HOME}/processing\" <<< \"${raw_file_dir}\"; then\n    mv ${raw_file_dir} ${REDDIT_HOME}/processing\nelse\n    echo JSON is already in processing\nfi\n\n# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing\necho \"#{setValue(raw_file_dir=${REDDIT_HOME}/processing/${filename})}\"","resourceList":[]}, environmentConfig=export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='move to processing'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240423'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1177'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13340390094208'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240423113426'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='processing'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='494'}, raw_file_dir=Property{prop='raw_file_dir', direct=IN, type=VARCHAR, value='/local_storage/reddit/processing/386-20240422.json'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240422'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-494][TI-1177] - [INFO] 2024-04-23 11:34:26.684 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: move to processing to wait queue success
[WI-494][TI-1177] - [INFO] 2024-04-23 11:34:26.685 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-494][TI-1177] - [INFO] 2024-04-23 11:34:26.685 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-494][TI-1177] - [INFO] 2024-04-23 11:34:26.685 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-494][TI-1177] - [INFO] 2024-04-23 11:34:26.685 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-494][TI-1177] - [INFO] 2024-04-23 11:34:26.685 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713843266685
[WI-494][TI-1177] - [INFO] 2024-04-23 11:34:26.686 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 494_1177
[WI-494][TI-1177] - [INFO] 2024-04-23 11:34:26.686 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1177,
  "taskName" : "move to processing",
  "firstSubmitTime" : 1713843266677,
  "startTime" : 1713843266685,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.9:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240423/13201021801792/83/494/1177.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 83,
  "processInstanceId" : 494,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"processing\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[{\"prop\":\"raw_file_dir\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"\"}],\"rawScript\":\"# move file to the reddit processing folder\\n# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error\\nfilename=$(basename \\\"${raw_file_dir}\\\")\\nif ! grep -q \\\"${REDDIT_HOME}/processing\\\" <<< \\\"${raw_file_dir}\\\"; then\\n    mv ${raw_file_dir} ${REDDIT_HOME}/processing\\nelse\\n    echo JSON is already in processing\\nfi\\n\\n# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing\\necho \\\"#{setValue(raw_file_dir=${REDDIT_HOME}/processing/${filename})}\\\"\",\"resourceList\":[]}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "move to processing"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1177"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13340390094208"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423113426"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "processing"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "494"
    },
    "raw_file_dir" : {
      "prop" : "raw_file_dir",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit/processing/386-20240422.json"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240422"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "494_1177",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"raw_file_dir\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"/local_storage/reddit/processing/386-20240422.json\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-494][TI-1177] - [INFO] 2024-04-23 11:34:26.687 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-494][TI-1177] - [INFO] 2024-04-23 11:34:26.687 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-494][TI-1177] - [INFO] 2024-04-23 11:34:26.687 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-494][TI-1177] - [INFO] 2024-04-23 11:34:26.689 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-494][TI-1177] - [INFO] 2024-04-23 11:34:26.690 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-494][TI-1177] - [INFO] 2024-04-23 11:34:26.690 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_83/494/1177 check successfully
[WI-494][TI-1177] - [INFO] 2024-04-23 11:34:26.690 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-494][TI-1177] - [INFO] 2024-04-23 11:34:26.690 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-494][TI-1177] - [INFO] 2024-04-23 11:34:26.690 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-494][TI-1177] - [INFO] 2024-04-23 11:34:26.691 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-494][TI-1177] - [INFO] 2024-04-23 11:34:26.691 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ {
    "prop" : "raw_file_dir",
    "direct" : "OUT",
    "type" : "VARCHAR",
    "value" : ""
  } ],
  "varPool" : null,
  "rawScript" : "# move file to the reddit processing folder\n# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error\nfilename=$(basename \"${raw_file_dir}\")\nif ! grep -q \"${REDDIT_HOME}/processing\" <<< \"${raw_file_dir}\"; then\n    mv ${raw_file_dir} ${REDDIT_HOME}/processing\nelse\n    echo JSON is already in processing\nfi\n\n# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing\necho \"#{setValue(raw_file_dir=${REDDIT_HOME}/processing/${filename})}\"",
  "resourceList" : [ ]
}
[WI-494][TI-1177] - [INFO] 2024-04-23 11:34:26.691 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-494][TI-1177] - [INFO] 2024-04-23 11:34:26.691 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}] successfully
[WI-494][TI-1177] - [INFO] 2024-04-23 11:34:26.692 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-494][TI-1177] - [INFO] 2024-04-23 11:34:26.692 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-494][TI-1177] - [INFO] 2024-04-23 11:34:26.692 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-494][TI-1177] - [INFO] 2024-04-23 11:34:26.692 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-494][TI-1177] - [INFO] 2024-04-23 11:34:26.692 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-494][TI-1177] - [INFO] 2024-04-23 11:34:26.692 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export PYTHON_LAUNCHER=/bin/python3.11
# move file to the reddit processing folder
# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error
filename=$(basename "/local_storage/reddit/processing/386-20240422.json")
if ! grep -q "/local_storage/reddit/processing" <<< "/local_storage/reddit/processing/386-20240422.json"; then
    mv /local_storage/reddit/processing/386-20240422.json /local_storage/reddit/processing
else
    echo JSON is already in processing
fi

# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing
echo "#{setValue(raw_file_dir=/local_storage/reddit/processing/${filename})}"
[WI-494][TI-1177] - [INFO] 2024-04-23 11:34:26.692 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-494][TI-1177] - [INFO] 2024-04-23 11:34:26.693 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_83/494/1177/494_1177.sh
[WI-494][TI-1177] - [INFO] 2024-04-23 11:34:26.695 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 4527
[WI-0][TI-1177] - [INFO] 2024-04-23 11:34:26.715 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionRunningEvent(taskInstanceId=1177, processInstanceId=494, startTime=1713843266685, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, status=TaskExecutionStatus{code=1, desc='running'}, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/83/494/1177.log, executePath=null, processId=0, appIds=null, eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1177] - [INFO] 2024-04-23 11:34:26.719 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionRunningEvent(taskInstanceId=1177, processInstanceId=494, startTime=1713843266685, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, status=TaskExecutionStatus{code=1, desc='running'}, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/83/494/1177.log, executePath=null, processId=0, appIds=null, eventCreateTime=0, eventSendTime=1713843266715)
[WI-0][TI-1177] - [INFO] 2024-04-23 11:34:26.719 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionInfoEvent(taskInstanceId=1177, processInstanceId=494, startTime=1713843266685, workflowInstanceHost=172.18.0.9:5678, taskInstanceHost=172.18.1.1:1234, logPath=null, processId=0, eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1177] - [INFO] 2024-04-23 11:34:26.722 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionInfoEvent(taskInstanceId=1177, processInstanceId=494, startTime=1713843266685, workflowInstanceHost=172.18.0.9:5678, taskInstanceHost=172.18.1.1:1234, logPath=null, processId=0, eventCreateTime=0, eventSendTime=1713843266715)
[WI-0][TI-1177] - [INFO] 2024-04-23 11:34:27.565 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1177, success=true)
[WI-0][TI-1177] - [INFO] 2024-04-23 11:34:27.570 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1177)
[WI-0][TI-1177] - [INFO] 2024-04-23 11:34:27.574 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1177, success=true)
[WI-0][TI-1177] - [INFO] 2024-04-23 11:34:27.578 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1177)
[WI-0][TI-0] - [INFO] 2024-04-23 11:34:27.737 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
	JSON is already in processing
	#{setValue(raw_file_dir=/local_storage/reddit/processing/386-20240422.json)}
[WI-494][TI-1177] - [INFO] 2024-04-23 11:34:27.744 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_83/494/1177, processId:4527 ,exitStatusCode:0 ,processWaitForStatus:true ,processExitValue:0
[WI-494][TI-1177] - [INFO] 2024-04-23 11:34:27.745 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-494][TI-1177] - [INFO] 2024-04-23 11:34:27.745 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-494][TI-1177] - [INFO] 2024-04-23 11:34:27.745 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-494][TI-1177] - [INFO] 2024-04-23 11:34:27.746 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-494][TI-1177] - [INFO] 2024-04-23 11:34:27.748 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: SUCCESS to master : 172.18.1.1:1234
[WI-494][TI-1177] - [INFO] 2024-04-23 11:34:27.748 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-494][TI-1177] - [INFO] 2024-04-23 11:34:27.748 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_83/494/1177
[WI-494][TI-1177] - [INFO] 2024-04-23 11:34:27.749 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_83/494/1177
[WI-494][TI-1177] - [INFO] 2024-04-23 11:34:27.749 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-1177] - [INFO] 2024-04-23 11:34:28.555 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1177, success=true)
[WI-0][TI-0] - [INFO] 2024-04-23 11:34:28.684 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1178, taskName=spark preprocessing, firstSubmitTime=1713843268679, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.9:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=83, appIds=null, processInstanceId=494, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"processing"}], executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[],"rawScript":"# $SPARK_HOME/bin/spark-submit \\\n#     --master spark://spark-master:7077 \\\n#     --conf spark.driver.cores=2 \\\n#     --conf spark.driver.memory=2G \\\n#     --conf spark.executor.instances=1 \\\n#     --conf spark.executor.cores=2 \\\n#     --conf spark.executor.memory=2G \\\n#     --files ${raw_file_dir} \\\n#     --name reddit_preprocessing spark_reddit_preprocessing.py\n\n$SPARK_HOME/bin/spark-submit \\\n    --master spark://spark-master:7077 \\\n    --files ${raw_file_dir} \\\n    --name reddit_preprocessing spark_reddit_preprocessing.py\n","resourceList":[{"id":null,"resourceName":"file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py","res":null}]}, environmentConfig=export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export HADOOP_CONF_DIR=/opt/hadoop-3.4.0/etc/hadoop
export PYSPARK_DRIVER_PYTHON=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='spark preprocessing'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240423'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1178'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13210058002752'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240423113428'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='processing'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='494'}, raw_file_dir=Property{prop='raw_file_dir', direct=IN, type=VARCHAR, value='/local_storage/reddit/processing/386-20240422.json'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240422'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-494][TI-1178] - [INFO] 2024-04-23 11:34:28.686 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: spark preprocessing to wait queue success
[WI-494][TI-1178] - [INFO] 2024-04-23 11:34:28.686 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-494][TI-1178] - [INFO] 2024-04-23 11:34:28.688 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-494][TI-1178] - [INFO] 2024-04-23 11:34:28.688 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-494][TI-1178] - [INFO] 2024-04-23 11:34:28.688 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-494][TI-1178] - [INFO] 2024-04-23 11:34:28.688 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713843268688
[WI-494][TI-1178] - [INFO] 2024-04-23 11:34:28.688 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 494_1178
[WI-494][TI-1178] - [INFO] 2024-04-23 11:34:28.688 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1178,
  "taskName" : "spark preprocessing",
  "firstSubmitTime" : 1713843268679,
  "startTime" : 1713843268688,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.9:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240423/13201021801792/83/494/1178.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 83,
  "processInstanceId" : 494,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"processing\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[],\"rawScript\":\"# $SPARK_HOME/bin/spark-submit \\\\\\n#     --master spark://spark-master:7077 \\\\\\n#     --conf spark.driver.cores=2 \\\\\\n#     --conf spark.driver.memory=2G \\\\\\n#     --conf spark.executor.instances=1 \\\\\\n#     --conf spark.executor.cores=2 \\\\\\n#     --conf spark.executor.memory=2G \\\\\\n#     --files ${raw_file_dir} \\\\\\n#     --name reddit_preprocessing spark_reddit_preprocessing.py\\n\\n$SPARK_HOME/bin/spark-submit \\\\\\n    --master spark://spark-master:7077 \\\\\\n    --files ${raw_file_dir} \\\\\\n    --name reddit_preprocessing spark_reddit_preprocessing.py\\n\",\"resourceList\":[{\"id\":null,\"resourceName\":\"file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py\",\"res\":null}]}",
  "environmentConfig" : "export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3\nexport JAVA_HOME=/opt/java/openjdk\nexport HADOOP_CONF_DIR=/opt/hadoop-3.4.0/etc/hadoop\nexport PYSPARK_DRIVER_PYTHON=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "spark preprocessing"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1178"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13210058002752"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423113428"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "processing"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "494"
    },
    "raw_file_dir" : {
      "prop" : "raw_file_dir",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit/processing/386-20240422.json"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240422"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "494_1178",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"raw_file_dir\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"/local_storage/reddit/processing/386-20240422.json\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-494][TI-1178] - [INFO] 2024-04-23 11:34:28.689 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-494][TI-1178] - [INFO] 2024-04-23 11:34:28.689 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-494][TI-1178] - [INFO] 2024-04-23 11:34:28.689 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-494][TI-1178] - [INFO] 2024-04-23 11:34:28.691 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-494][TI-1178] - [INFO] 2024-04-23 11:34:28.691 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-494][TI-1178] - [INFO] 2024-04-23 11:34:28.692 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_83/494/1178 check successfully
[WI-494][TI-1178] - [INFO] 2024-04-23 11:34:28.692 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-494][TI-1178] - [INFO] 2024-04-23 11:34:28.693 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py=ResourceContext.ResourceItem(resourceAbsolutePathInStorage=file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py, resourceRelativePath=spark_reddit_preprocessing.py, resourceAbsolutePathInLocal=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_83/494/1178/spark_reddit_preprocessing.py)})
[WI-494][TI-1178] - [INFO] 2024-04-23 11:34:28.694 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-494][TI-1178] - [INFO] 2024-04-23 11:34:28.695 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-494][TI-1178] - [INFO] 2024-04-23 11:34:28.695 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ ],
  "varPool" : null,
  "rawScript" : "# $SPARK_HOME/bin/spark-submit \\\n#     --master spark://spark-master:7077 \\\n#     --conf spark.driver.cores=2 \\\n#     --conf spark.driver.memory=2G \\\n#     --conf spark.executor.instances=1 \\\n#     --conf spark.executor.cores=2 \\\n#     --conf spark.executor.memory=2G \\\n#     --files ${raw_file_dir} \\\n#     --name reddit_preprocessing spark_reddit_preprocessing.py\n\n$SPARK_HOME/bin/spark-submit \\\n    --master spark://spark-master:7077 \\\n    --files ${raw_file_dir} \\\n    --name reddit_preprocessing spark_reddit_preprocessing.py\n",
  "resourceList" : [ {
    "id" : null,
    "resourceName" : "file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py",
    "res" : null
  } ]
}
[WI-494][TI-1178] - [INFO] 2024-04-23 11:34:28.696 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-494][TI-1178] - [INFO] 2024-04-23 11:34:28.696 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}] successfully
[WI-494][TI-1178] - [INFO] 2024-04-23 11:34:28.696 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-494][TI-1178] - [INFO] 2024-04-23 11:34:28.696 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-494][TI-1178] - [INFO] 2024-04-23 11:34:28.697 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-494][TI-1178] - [INFO] 2024-04-23 11:34:28.697 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-494][TI-1178] - [INFO] 2024-04-23 11:34:28.698 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-494][TI-1178] - [INFO] 2024-04-23 11:34:28.698 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export HADOOP_CONF_DIR=/opt/hadoop-3.4.0/etc/hadoop
export PYSPARK_DRIVER_PYTHON=/bin/python3.11
# $SPARK_HOME/bin/spark-submit \
#     --master spark://spark-master:7077 \
#     --conf spark.driver.cores=2 \
#     --conf spark.driver.memory=2G \
#     --conf spark.executor.instances=1 \
#     --conf spark.executor.cores=2 \
#     --conf spark.executor.memory=2G \
#     --files /local_storage/reddit/processing/386-20240422.json \
#     --name reddit_preprocessing spark_reddit_preprocessing.py

$SPARK_HOME/bin/spark-submit \
    --master spark://spark-master:7077 \
    --files /local_storage/reddit/processing/386-20240422.json \
    --name reddit_preprocessing spark_reddit_preprocessing.py

[WI-494][TI-1178] - [INFO] 2024-04-23 11:34:28.698 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-494][TI-1178] - [INFO] 2024-04-23 11:34:28.698 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_83/494/1178/494_1178.sh
[WI-494][TI-1178] - [INFO] 2024-04-23 11:34:28.712 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 4539
[WI-0][TI-1178] - [INFO] 2024-04-23 11:34:28.740 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionRunningEvent(taskInstanceId=1178, processInstanceId=494, startTime=1713843268688, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, status=TaskExecutionStatus{code=1, desc='running'}, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/83/494/1178.log, executePath=null, processId=0, appIds=null, eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1178] - [INFO] 2024-04-23 11:34:28.746 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionRunningEvent(taskInstanceId=1178, processInstanceId=494, startTime=1713843268688, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, status=TaskExecutionStatus{code=1, desc='running'}, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/83/494/1178.log, executePath=null, processId=0, appIds=null, eventCreateTime=0, eventSendTime=1713843268738)
[WI-0][TI-1178] - [INFO] 2024-04-23 11:34:28.746 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionInfoEvent(taskInstanceId=1178, processInstanceId=494, startTime=1713843268688, workflowInstanceHost=172.18.0.9:5678, taskInstanceHost=172.18.1.1:1234, logPath=null, processId=0, eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1178] - [INFO] 2024-04-23 11:34:28.755 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionInfoEvent(taskInstanceId=1178, processInstanceId=494, startTime=1713843268688, workflowInstanceHost=172.18.0.9:5678, taskInstanceHost=172.18.1.1:1234, logPath=null, processId=0, eventCreateTime=0, eventSendTime=1713843268738)
[WI-0][TI-1178] - [INFO] 2024-04-23 11:34:29.567 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1178, success=true)
[WI-0][TI-1178] - [INFO] 2024-04-23 11:34:29.574 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1178)
[WI-0][TI-1178] - [INFO] 2024-04-23 11:34:29.581 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1178, success=true)
[WI-0][TI-1178] - [INFO] 2024-04-23 11:34:29.587 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1178)
[WI-0][TI-0] - [INFO] 2024-04-23 11:34:29.719 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
[WI-0][TI-0] - [INFO] 2024-04-23 11:34:32.724 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:34:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
	24/04/23 11:34:32 INFO SparkContext: Running Spark version 3.5.1
	24/04/23 11:34:32 INFO SparkContext: OS info Linux, 6.5.0-28-generic, amd64
	24/04/23 11:34:32 INFO SparkContext: Java version 1.8.0_402
[WI-0][TI-0] - [INFO] 2024-04-23 11:34:33.728 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:34:32 INFO ResourceUtils: ==============================================================
	24/04/23 11:34:32 INFO ResourceUtils: No custom resources configured for spark.driver.
	24/04/23 11:34:32 INFO ResourceUtils: ==============================================================
	24/04/23 11:34:32 INFO SparkContext: Submitted application: reddit_preprocessing
	24/04/23 11:34:32 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
	24/04/23 11:34:32 INFO ResourceProfile: Limiting resource is cpu
	24/04/23 11:34:32 INFO ResourceProfileManager: Added ResourceProfile id: 0
	24/04/23 11:34:32 INFO SecurityManager: Changing view acls to: default
	24/04/23 11:34:32 INFO SecurityManager: Changing modify acls to: default
	24/04/23 11:34:32 INFO SecurityManager: Changing view acls groups to: 
	24/04/23 11:34:32 INFO SecurityManager: Changing modify acls groups to: 
	24/04/23 11:34:32 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: default; groups with view permissions: EMPTY; users with modify permissions: default; groups with modify permissions: EMPTY
	24/04/23 11:34:33 INFO Utils: Successfully started service 'sparkDriver' on port 36279.
[WI-0][TI-0] - [INFO] 2024-04-23 11:34:34.731 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:34:33 INFO SparkEnv: Registering MapOutputTracker
	24/04/23 11:34:33 INFO SparkEnv: Registering BlockManagerMaster
	24/04/23 11:34:33 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
	24/04/23 11:34:33 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
	24/04/23 11:34:33 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
	24/04/23 11:34:33 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-13c89560-a353-4ceb-9cfb-19850fbcb252
	24/04/23 11:34:33 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
	24/04/23 11:34:33 INFO SparkEnv: Registering OutputCommitCoordinator
	24/04/23 11:34:34 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
	24/04/23 11:34:34 INFO Utils: Successfully started service 'SparkUI' on port 4040.
	24/04/23 11:34:34 INFO SparkContext: Added file file:///local_storage/reddit/processing/386-20240422.json at spark://c0e814e3f0bd:36279/files/386-20240422.json with timestamp 1713843272700
	24/04/23 11:34:34 INFO Utils: Copying /local_storage/reddit/processing/386-20240422.json to /tmp/spark-99588096-86eb-4276-887c-c57873ba0931/userFiles-15bd1ba5-976a-44cb-b21f-290a07365354/386-20240422.json
	24/04/23 11:34:34 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
[WI-0][TI-0] - [INFO] 2024-04-23 11:34:35.611 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7420289855072464 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:34:35.732 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:34:34 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.3:7077 after 78 ms (0 ms spent in bootstraps)
	24/04/23 11:34:34 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20240423033434-0015
	24/04/23 11:34:34 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20240423033434-0015/0 on worker-20240423012857-172.18.0.7-41063 (172.18.0.7:41063) with 2 core(s)
	24/04/23 11:34:34 INFO StandaloneSchedulerBackend: Granted executor ID app-20240423033434-0015/0 on hostPort 172.18.0.7:41063 with 2 core(s), 1024.0 MiB RAM
	24/04/23 11:34:35 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35067.
	24/04/23 11:34:35 INFO NettyBlockTransferService: Server created on c0e814e3f0bd:35067
	24/04/23 11:34:35 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
	24/04/23 11:34:35 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, c0e814e3f0bd, 35067, None)
	24/04/23 11:34:35 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20240423033434-0015/0 is now RUNNING
	24/04/23 11:34:35 INFO BlockManagerMasterEndpoint: Registering block manager c0e814e3f0bd:35067 with 366.3 MiB RAM, BlockManagerId(driver, c0e814e3f0bd, 35067, None)
	24/04/23 11:34:35 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, c0e814e3f0bd, 35067, None)
	24/04/23 11:34:35 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, c0e814e3f0bd, 35067, None)
[WI-0][TI-0] - [INFO] 2024-04-23 11:34:36.635 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8971061093247588 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:34:36.736 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:34:35 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
	
	
	
	 /tmp/spark-99588096-86eb-4276-887c-c57873ba0931/userFiles-15bd1ba5-976a-44cb-b21f-290a07365354/386-20240422.json 
	
	
	
	24/04/23 11:34:36 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
	24/04/23 11:34:36 INFO SharedState: Warehouse path is 'file:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_83/494/1178/spark-warehouse'.
[WI-0][TI-0] - [INFO] 2024-04-23 11:34:37.640 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9174218691728202 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:34:38.644 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8892213527014815 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:34:39.658 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9122061738884168 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:34:39.752 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:34:39 INFO InMemoryFileIndex: It took 109 ms to list leaf files for 1 paths.
	24/04/23 11:34:39 INFO InMemoryFileIndex: It took 2 ms to list leaf files for 1 paths.
[WI-0][TI-0] - [INFO] 2024-04-23 11:34:40.662 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8375713816869051 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:34:41.664 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8361774744027304 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:34:41.757 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:34:41 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.7:43832) with ID 0,  ResourceProfileId 0
	24/04/23 11:34:41 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.7:34973 with 434.4 MiB RAM, BlockManagerId(0, 172.18.0.7, 34973, None)
[WI-0][TI-0] - [INFO] 2024-04-23 11:34:44.761 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:34:44 INFO FileSourceStrategy: Pushed Filters: 
	24/04/23 11:34:44 INFO FileSourceStrategy: Post-Scan Filters: 
[WI-0][TI-0] - [INFO] 2024-04-23 11:34:45.690 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7458100558659219 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:34:45.763 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:34:44 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 350.7 KiB, free 366.0 MiB)
	24/04/23 11:34:45 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 34.5 KiB, free 365.9 MiB)
	24/04/23 11:34:45 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on c0e814e3f0bd:35067 (size: 34.5 KiB, free: 366.3 MiB)
	24/04/23 11:34:45 INFO SparkContext: Created broadcast 0 from json at NativeMethodAccessorImpl.java:0
	24/04/23 11:34:45 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
	24/04/23 11:34:45 INFO SparkContext: Starting job: json at NativeMethodAccessorImpl.java:0
	24/04/23 11:34:45 INFO DAGScheduler: Got job 0 (json at NativeMethodAccessorImpl.java:0) with 1 output partitions
	24/04/23 11:34:45 INFO DAGScheduler: Final stage: ResultStage 0 (json at NativeMethodAccessorImpl.java:0)
	24/04/23 11:34:45 INFO DAGScheduler: Parents of final stage: List()
	24/04/23 11:34:45 INFO DAGScheduler: Missing parents: List()
	24/04/23 11:34:45 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at json at NativeMethodAccessorImpl.java:0), which has no missing parents
	24/04/23 11:34:45 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 16.4 KiB, free 365.9 MiB)
	24/04/23 11:34:45 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.7 KiB, free 365.9 MiB)
	24/04/23 11:34:45 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on c0e814e3f0bd:35067 (size: 7.7 KiB, free: 366.3 MiB)
	24/04/23 11:34:45 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1585
[WI-0][TI-0] - [INFO] 2024-04-23 11:34:46.764 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:34:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at json at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
	24/04/23 11:34:45 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
	24/04/23 11:34:45 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.7, executor 0, partition 0, PROCESS_LOCAL, 8478 bytes) 
[WI-0][TI-1123] - [INFO] 2024-04-23 11:34:51.800 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1123, processInstanceId=487, status=9, startTime=1713838208504, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1123.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1123, endTime=1713838483436, processId=1677, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713842991009)
[WI-0][TI-1123] - [INFO] 2024-04-23 11:34:51.802 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1123, processInstanceId=487, status=9, startTime=1713838208504, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1123.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1123, endTime=1713838483436, processId=1677, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713843291800)
[WI-0][TI-1111] - [INFO] 2024-04-23 11:34:53.804 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1111, processInstanceId=487, status=9, startTime=1713837256404, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1111.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1111, endTime=1713838170352, processId=1017, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713842993021)
[WI-0][TI-1111] - [INFO] 2024-04-23 11:34:53.807 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1111, processInstanceId=487, status=9, startTime=1713837256404, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1111.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1111, endTime=1713838170352, processId=1017, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713843293804)
[WI-0][TI-0] - [INFO] 2024-04-23 11:35:15.822 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7731092436974789 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:36:09.801 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.811965811965812 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:36:39.938 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7739130434782607 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:36:42.024 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7658959537572254 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:37:10.260 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8192090395480226 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-1144] - [INFO] 2024-04-23 11:37:14.875 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1144, processInstanceId=489, status=9, startTime=1713840953087, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/80/489/1144.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1144, endTime=1713841331355, processId=3026, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713843134416)
[WI-0][TI-1144] - [INFO] 2024-04-23 11:37:14.880 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1144, processInstanceId=489, status=9, startTime=1713840953087, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/80/489/1144.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1144, endTime=1713841331355, processId=3026, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713843434875)
[WI-0][TI-1123] - [INFO] 2024-04-23 11:39:51.892 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1123, processInstanceId=487, status=9, startTime=1713838208504, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1123.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1123, endTime=1713838483436, processId=1677, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713843291800)
[WI-0][TI-1123] - [INFO] 2024-04-23 11:39:51.919 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1123, processInstanceId=487, status=9, startTime=1713838208504, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1123.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1123, endTime=1713838483436, processId=1677, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713843591892)
[WI-0][TI-1111] - [INFO] 2024-04-23 11:39:53.921 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1111, processInstanceId=487, status=9, startTime=1713837256404, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1111.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1111, endTime=1713838170352, processId=1017, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713843293804)
[WI-0][TI-1111] - [INFO] 2024-04-23 11:39:53.924 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1111, processInstanceId=487, status=9, startTime=1713837256404, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1111.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1111, endTime=1713838170352, processId=1017, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713843593921)
[WI-0][TI-1144] - [INFO] 2024-04-23 11:42:15.080 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1144, processInstanceId=489, status=9, startTime=1713840953087, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/80/489/1144.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1144, endTime=1713841331355, processId=3026, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713843434875)
[WI-0][TI-1144] - [INFO] 2024-04-23 11:42:15.084 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1144, processInstanceId=489, status=9, startTime=1713840953087, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/80/489/1144.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1144, endTime=1713841331355, processId=3026, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713843735080)
[WI-0][TI-0] - [INFO] 2024-04-23 11:42:26.107 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:42:25 ERROR StandaloneSchedulerBackend: Application has been killed. Reason: Master removed our application: KILLED
	24/04/23 11:42:25 INFO SparkContext: SparkContext is stopping with exitCode 0.
	24/04/23 11:42:25 INFO TaskSchedulerImpl: Cancelling stage 0
	24/04/23 11:42:25 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage cancelled: Job aborted due to stage failure: Master removed our application: KILLED
	24/04/23 11:42:25 INFO TaskSchedulerImpl: Stage 0 was cancelled
	24/04/23 11:42:25 INFO DAGScheduler: ResultStage 0 (json at NativeMethodAccessorImpl.java:0) failed in 460.328 s due to Job aborted due to stage failure: Master removed our application: KILLED
	24/04/23 11:42:25 INFO DAGScheduler: Job 0 failed: json at NativeMethodAccessorImpl.java:0, took 460.439891 s
	24/04/23 11:42:25 INFO SparkUI: Stopped Spark web UI at http://c0e814e3f0bd:4040
	24/04/23 11:42:26 INFO StandaloneSchedulerBackend: Shutting down all executors
	24/04/23 11:42:26 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Asking each executor to shut down
	24/04/23 11:42:26 ERROR Utils: Uncaught exception in thread stop-spark-context
	org.apache.spark.SparkException: Exception thrown in awaitResult: 
		at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
		at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
		at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
		at org.apache.spark.deploy.client.StandaloneAppClient.stop(StandaloneAppClient.scala:288)
		at org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend.org$apache$spark$scheduler$cluster$StandaloneSchedulerBackend$$stop(StandaloneSchedulerBackend.scala:275)
		at org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend.stop(StandaloneSchedulerBackend.scala:142)
		at org.apache.spark.scheduler.SchedulerBackend.stop(SchedulerBackend.scala:33)
		at org.apache.spark.scheduler.SchedulerBackend.stop$(SchedulerBackend.scala:33)
		at org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend.stop(CoarseGrainedSchedulerBackend.scala:54)
		at org.apache.spark.scheduler.TaskSchedulerImpl.$anonfun$stop$2(TaskSchedulerImpl.scala:992)
		at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1375)
		at org.apache.spark.scheduler.TaskSchedulerImpl.stop(TaskSchedulerImpl.scala:992)
		at org.apache.spark.scheduler.DAGScheduler.$anonfun$stop$4(DAGScheduler.scala:2976)
		at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1375)
		at org.apache.spark.scheduler.DAGScheduler.stop(DAGScheduler.scala:2976)
		at org.apache.spark.SparkContext.$anonfun$stop$12(SparkContext.scala:2263)
		at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1375)
		at org.apache.spark.SparkContext.stop(SparkContext.scala:2263)
		at org.apache.spark.SparkContext.stop(SparkContext.scala:2216)
		at org.apache.spark.SparkContext$$anon$3.run(SparkContext.scala:2203)
	Caused by: org.apache.spark.SparkException: Could not find AppClient.
		at org.apache.spark.rpc.netty.Dispatcher.postMessage(Dispatcher.scala:178)
		at org.apache.spark.rpc.netty.Dispatcher.postLocalMessage(Dispatcher.scala:144)
		at org.apache.spark.rpc.netty.NettyRpcEnv.askAbortable(NettyRpcEnv.scala:242)
		at org.apache.spark.rpc.netty.NettyRpcEndpointRef.askAbortable(NettyRpcEnv.scala:554)
		at org.apache.spark.rpc.netty.NettyRpcEndpointRef.ask(NettyRpcEnv.scala:558)
		at org.apache.spark.rpc.RpcEndpointRef.ask(RpcEndpointRef.scala:72)
		... 17 more
[WI-0][TI-0] - [INFO] 2024-04-23 11:42:27.115 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:42:26 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
	24/04/23 11:42:26 INFO MemoryStore: MemoryStore cleared
	24/04/23 11:42:26 INFO BlockManager: BlockManager stopped
	Traceback (most recent call last):
	  File "/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_83/494/1178/spark_reddit_preprocessing.py", line 47, in <module>
	    raw_df = spark.read.json(reddit_json_dir)
	             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
	  File "/opt/spark-3.5.1-bin-hadoop3/python/lib/pyspark.zip/pyspark/sql/readwriter.py", line 425, in json
	  File "/opt/spark-3.5.1-bin-hadoop3/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
	  File "/opt/spark-3.5.1-bin-hadoop3/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 179, in deco
	  File "/opt/spark-3.5.1-bin-hadoop3/python/lib/py4j-0.10.9.7-src.zip/py4j/protocol.py", line 326, in get_return_value
	py4j.protocol.Py4JJavaError: An error occurred while calling o27.json.
	: org.apache.spark.SparkException: Job aborted due to stage failure: Master removed our application: KILLED
		at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)
		at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)
		at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)
		at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
		at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
		at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
		at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)
		at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)
		at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)
		at scala.Option.foreach(Option.scala:407)
		at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)
		at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)
		at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)
		at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)
		at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
		at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:989)
		at org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)
		at org.apache.spark.SparkContext.runJob(SparkContext.scala:2493)
		at org.apache.spark.sql.catalyst.json.JsonInferSchema.infer(JsonInferSchema.scala:120)
		at org.apache.spark.sql.execution.datasources.json.TextInputJsonDataSource$.$anonfun$inferFromDataset$5(JsonDataSource.scala:109)
		at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)
		at org.apache.spark.sql.execution.datasources.json.TextInputJsonDataSource$.inferFromDataset(JsonDataSource.scala:109)
		at org.apache.spark.sql.execution.datasources.json.TextInputJsonDataSource$.infer(JsonDataSource.scala:98)
		at org.apache.spark.sql.execution.datasources.json.JsonDataSource.inferSchema(JsonDataSource.scala:64)
		at org.apache.spark.sql.execution.datasources.json.JsonFileFormat.inferSchema(JsonFileFormat.scala:59)
		at org.apache.spark.sql.execution.datasources.DataSource.$anonfun$getOrInferFileFormatSchema$11(DataSource.scala:208)
		at scala.Option.orElse(Option.scala:447)
		at org.apache.spark.sql.execution.datasources.DataSource.getOrInferFileFormatSchema(DataSource.scala:205)
		at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:407)
		at org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)
		at org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)
		at scala.Option.getOrElse(Option.scala:189)
		at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)
		at org.apache.spark.sql.DataFrameReader.json(DataFrameReader.scala:362)
		at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
		at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
		at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
		at java.lang.reflect.Method.invoke(Method.java:498)
		at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
		at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
		at py4j.Gateway.invoke(Gateway.java:282)
		at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
		at py4j.commands.CallCommand.execute(CallCommand.java:79)
		at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
		at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
		at java.lang.Thread.run(Thread.java:750)
	
	24/04/23 11:42:26 INFO BlockManagerMaster: BlockManagerMaster stopped
	24/04/23 11:42:26 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
	24/04/23 11:42:26 INFO ShutdownHookManager: Shutdown hook called
	24/04/23 11:42:26 INFO ShutdownHookManager: Deleting directory /tmp/spark-99588096-86eb-4276-887c-c57873ba0931/pyspark-b9f6f416-7692-4ccd-ae92-eb58c7630249
	24/04/23 11:42:26 INFO SparkContext: Successfully stopped SparkContext
	24/04/23 11:42:26 INFO ShutdownHookManager: Deleting directory /tmp/spark-d82130f4-1c60-4103-9ad3-8425d86d629e
	24/04/23 11:42:26 INFO ShutdownHookManager: Deleting directory /tmp/spark-99588096-86eb-4276-887c-c57873ba0931/userFiles-15bd1ba5-976a-44cb-b21f-290a07365354
	24/04/23 11:42:26 INFO ShutdownHookManager: Deleting directory /tmp/spark-99588096-86eb-4276-887c-c57873ba0931
[WI-494][TI-1178] - [INFO] 2024-04-23 11:42:27.127 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_83/494/1178, processId:4539 ,exitStatusCode:1 ,processWaitForStatus:true ,processExitValue:1
[WI-494][TI-1178] - [INFO] 2024-04-23 11:42:27.131 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-494][TI-1178] - [INFO] 2024-04-23 11:42:27.134 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-494][TI-1178] - [INFO] 2024-04-23 11:42:27.135 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-494][TI-1178] - [INFO] 2024-04-23 11:42:27.137 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-494][TI-1178] - [INFO] 2024-04-23 11:42:27.141 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: FAILURE to master : 172.18.1.1:1234
[WI-494][TI-1178] - [INFO] 2024-04-23 11:42:27.142 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-494][TI-1178] - [INFO] 2024-04-23 11:42:27.142 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_83/494/1178
[WI-494][TI-1178] - [INFO] 2024-04-23 11:42:27.145 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_83/494/1178
[WI-494][TI-1178] - [INFO] 2024-04-23 11:42:27.145 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-0] - [INFO] 2024-04-23 11:42:27.152 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7835616438356164 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-1178] - [INFO] 2024-04-23 11:42:28.111 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1178, processInstanceId=494, status=6, startTime=1713843268688, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/83/494/1178.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_83/494/1178, endTime=1713843747135, processId=4539, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1178] - [INFO] 2024-04-23 11:42:28.116 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1178, processInstanceId=494, status=6, startTime=1713843268688, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/83/494/1178.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_83/494/1178, endTime=1713843747135, processId=4539, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713843748109)
[WI-0][TI-1178] - [INFO] 2024-04-23 11:42:28.120 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1178, success=true)
[WI-0][TI-1178] - [INFO] 2024-04-23 11:42:28.122 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1178, success=true)
[WI-0][TI-0] - [INFO] 2024-04-23 11:42:42.288 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1179, taskName=search for intake JSON files, firstSubmitTime=1713843762258, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.9:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=83, appIds=null, processInstanceId=494, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"processing"}], executorId=1, cmdTypeIfComplement=7, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":""}],"rawScript":"# find 1 raw file in the folder\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\n\n# check if raw_file_dir is empty, then set raw_file_dir to null\nif [ -z \"$raw_file_dir\" ]; then\n    raw_file_dir=null\nfi\n\necho \"#{setValue(raw_file_dir=${raw_file_dir})}\"","resourceList":[]}, environmentConfig=export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='search for intake JSON files'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240423'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1179'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13340113777664'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240423114242'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='processing'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='494'}, raw_file_dir=Property{prop='raw_file_dir', direct=OUT, type=VARCHAR, value='/local_storage/reddit/processing/386-20240422.json'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240422'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-494][TI-1179] - [INFO] 2024-04-23 11:42:42.291 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: search for intake JSON files to wait queue success
[WI-494][TI-1179] - [INFO] 2024-04-23 11:42:42.291 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-494][TI-1179] - [INFO] 2024-04-23 11:42:42.294 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-494][TI-1179] - [INFO] 2024-04-23 11:42:42.295 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-494][TI-1179] - [INFO] 2024-04-23 11:42:42.295 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-494][TI-1179] - [INFO] 2024-04-23 11:42:42.295 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713843762295
[WI-494][TI-1179] - [INFO] 2024-04-23 11:42:42.296 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 494_1179
[WI-494][TI-1179] - [INFO] 2024-04-23 11:42:42.296 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1179,
  "taskName" : "search for intake JSON files",
  "firstSubmitTime" : 1713843762258,
  "startTime" : 1713843762295,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.9:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240423/13201021801792/83/494/1179.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 83,
  "processInstanceId" : 494,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"processing\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 7,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[{\"prop\":\"raw_file_dir\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"\"}],\"rawScript\":\"# find 1 raw file in the folder\\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\\n\\n# check if raw_file_dir is empty, then set raw_file_dir to null\\nif [ -z \\\"$raw_file_dir\\\" ]; then\\n    raw_file_dir=null\\nfi\\n\\necho \\\"#{setValue(raw_file_dir=${raw_file_dir})}\\\"\",\"resourceList\":[]}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "search for intake JSON files"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1179"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13340113777664"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423114242"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "processing"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "494"
    },
    "raw_file_dir" : {
      "prop" : "raw_file_dir",
      "direct" : "OUT",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit/processing/386-20240422.json"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240422"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "494_1179",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"raw_file_dir\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"/local_storage/reddit/processing/386-20240422.json\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-494][TI-1179] - [INFO] 2024-04-23 11:42:42.297 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-494][TI-1179] - [INFO] 2024-04-23 11:42:42.297 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-494][TI-1179] - [INFO] 2024-04-23 11:42:42.297 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-494][TI-1179] - [INFO] 2024-04-23 11:42:42.301 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-494][TI-1179] - [INFO] 2024-04-23 11:42:42.301 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-494][TI-1179] - [INFO] 2024-04-23 11:42:42.302 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_83/494/1179 check successfully
[WI-494][TI-1179] - [INFO] 2024-04-23 11:42:42.302 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-494][TI-1179] - [INFO] 2024-04-23 11:42:42.302 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-494][TI-1179] - [INFO] 2024-04-23 11:42:42.302 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-494][TI-1179] - [INFO] 2024-04-23 11:42:42.303 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-494][TI-1179] - [INFO] 2024-04-23 11:42:42.303 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ {
    "prop" : "raw_file_dir",
    "direct" : "OUT",
    "type" : "VARCHAR",
    "value" : ""
  } ],
  "varPool" : null,
  "rawScript" : "# find 1 raw file in the folder\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\n\n# check if raw_file_dir is empty, then set raw_file_dir to null\nif [ -z \"$raw_file_dir\" ]; then\n    raw_file_dir=null\nfi\n\necho \"#{setValue(raw_file_dir=${raw_file_dir})}\"",
  "resourceList" : [ ]
}
[WI-494][TI-1179] - [INFO] 2024-04-23 11:42:42.303 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-494][TI-1179] - [INFO] 2024-04-23 11:42:42.303 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}] successfully
[WI-494][TI-1179] - [INFO] 2024-04-23 11:42:42.303 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-494][TI-1179] - [INFO] 2024-04-23 11:42:42.303 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-494][TI-1179] - [INFO] 2024-04-23 11:42:42.303 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-494][TI-1179] - [INFO] 2024-04-23 11:42:42.304 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-494][TI-1179] - [INFO] 2024-04-23 11:42:42.304 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-494][TI-1179] - [INFO] 2024-04-23 11:42:42.304 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export PYTHON_LAUNCHER=/bin/python3.11
# find 1 raw file in the folder
raw_file_dir=$(find /local_storage/reddit/processing -type f -name '*.json'| head -n 1)

# check if raw_file_dir is empty, then set raw_file_dir to null
if [ -z "$raw_file_dir" ]; then
    raw_file_dir=null
fi

echo "#{setValue(raw_file_dir=/local_storage/reddit/processing/386-20240422.json)}"
[WI-494][TI-1179] - [INFO] 2024-04-23 11:42:42.304 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-494][TI-1179] - [INFO] 2024-04-23 11:42:42.304 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_83/494/1179/494_1179.sh
[WI-0][TI-0] - [INFO] 2024-04-23 11:42:42.314 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
[WI-494][TI-1179] - [INFO] 2024-04-23 11:42:42.314 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 4775
[WI-0][TI-1179] - [INFO] 2024-04-23 11:42:43.137 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionRunningEvent(taskInstanceId=1179, processInstanceId=494, startTime=1713843762295, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, status=TaskExecutionStatus{code=1, desc='running'}, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/83/494/1179.log, executePath=null, processId=0, appIds=null, eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1179] - [INFO] 2024-04-23 11:42:43.139 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionRunningEvent(taskInstanceId=1179, processInstanceId=494, startTime=1713843762295, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, status=TaskExecutionStatus{code=1, desc='running'}, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/83/494/1179.log, executePath=null, processId=0, appIds=null, eventCreateTime=0, eventSendTime=1713843763136)
[WI-0][TI-1179] - [INFO] 2024-04-23 11:42:43.140 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionInfoEvent(taskInstanceId=1179, processInstanceId=494, startTime=1713843762295, workflowInstanceHost=172.18.0.9:5678, taskInstanceHost=172.18.1.1:1234, logPath=null, processId=0, eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1179] - [INFO] 2024-04-23 11:42:43.142 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionInfoEvent(taskInstanceId=1179, processInstanceId=494, startTime=1713843762295, workflowInstanceHost=172.18.0.9:5678, taskInstanceHost=172.18.1.1:1234, logPath=null, processId=0, eventCreateTime=0, eventSendTime=1713843763136)
[WI-0][TI-1179] - [INFO] 2024-04-23 11:42:43.147 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1179, success=true)
[WI-0][TI-1179] - [INFO] 2024-04-23 11:42:43.153 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1179)
[WI-0][TI-1179] - [INFO] 2024-04-23 11:42:43.161 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1179, success=true)
[WI-0][TI-1179] - [INFO] 2024-04-23 11:42:43.167 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1179)
[WI-0][TI-0] - [INFO] 2024-04-23 11:42:43.316 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	#{setValue(raw_file_dir=/local_storage/reddit/processing/386-20240422.json)}
[WI-494][TI-1179] - [INFO] 2024-04-23 11:42:43.318 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_83/494/1179, processId:4775 ,exitStatusCode:0 ,processWaitForStatus:true ,processExitValue:0
[WI-494][TI-1179] - [INFO] 2024-04-23 11:42:43.318 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-494][TI-1179] - [INFO] 2024-04-23 11:42:43.318 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-494][TI-1179] - [INFO] 2024-04-23 11:42:43.318 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-494][TI-1179] - [INFO] 2024-04-23 11:42:43.319 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-494][TI-1179] - [INFO] 2024-04-23 11:42:43.323 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: SUCCESS to master : 172.18.1.1:1234
[WI-494][TI-1179] - [INFO] 2024-04-23 11:42:43.323 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-494][TI-1179] - [INFO] 2024-04-23 11:42:43.324 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_83/494/1179
[WI-494][TI-1179] - [INFO] 2024-04-23 11:42:43.325 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_83/494/1179
[WI-494][TI-1179] - [INFO] 2024-04-23 11:42:43.325 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-1179] - [INFO] 2024-04-23 11:42:44.138 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1179, success=true)
[WI-0][TI-0] - [INFO] 2024-04-23 11:42:45.286 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1181, taskName=move to processing, firstSubmitTime=1713843765259, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.9:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=83, appIds=null, processInstanceId=494, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"processing"}], executorId=1, cmdTypeIfComplement=7, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":""}],"rawScript":"# move file to the reddit processing folder\n# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error\nfilename=$(basename \"${raw_file_dir}\")\nif ! grep -q \"${REDDIT_HOME}/processing\" <<< \"${raw_file_dir}\"; then\n    mv ${raw_file_dir} ${REDDIT_HOME}/processing\nelse\n    echo JSON is already in processing\nfi\n\n# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing\necho \"#{setValue(raw_file_dir=${REDDIT_HOME}/processing/${filename})}\"","resourceList":[]}, environmentConfig=export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='move to processing'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240423'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1181'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13340390094208'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240423114245'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='processing'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='494'}, raw_file_dir=Property{prop='raw_file_dir', direct=IN, type=VARCHAR, value='/local_storage/reddit/processing/386-20240422.json'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240422'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-494][TI-1181] - [INFO] 2024-04-23 11:42:45.287 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: move to processing to wait queue success
[WI-494][TI-1181] - [INFO] 2024-04-23 11:42:45.288 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-494][TI-1181] - [INFO] 2024-04-23 11:42:45.289 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-494][TI-1181] - [INFO] 2024-04-23 11:42:45.290 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-494][TI-1181] - [INFO] 2024-04-23 11:42:45.290 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-494][TI-1181] - [INFO] 2024-04-23 11:42:45.290 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713843765290
[WI-494][TI-1181] - [INFO] 2024-04-23 11:42:45.290 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 494_1181
[WI-494][TI-1181] - [INFO] 2024-04-23 11:42:45.290 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1181,
  "taskName" : "move to processing",
  "firstSubmitTime" : 1713843765259,
  "startTime" : 1713843765290,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.9:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240423/13201021801792/83/494/1181.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 83,
  "processInstanceId" : 494,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"processing\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 7,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[{\"prop\":\"raw_file_dir\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"\"}],\"rawScript\":\"# move file to the reddit processing folder\\n# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error\\nfilename=$(basename \\\"${raw_file_dir}\\\")\\nif ! grep -q \\\"${REDDIT_HOME}/processing\\\" <<< \\\"${raw_file_dir}\\\"; then\\n    mv ${raw_file_dir} ${REDDIT_HOME}/processing\\nelse\\n    echo JSON is already in processing\\nfi\\n\\n# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing\\necho \\\"#{setValue(raw_file_dir=${REDDIT_HOME}/processing/${filename})}\\\"\",\"resourceList\":[]}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "move to processing"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1181"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13340390094208"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423114245"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "processing"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "494"
    },
    "raw_file_dir" : {
      "prop" : "raw_file_dir",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit/processing/386-20240422.json"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240422"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "494_1181",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"raw_file_dir\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"/local_storage/reddit/processing/386-20240422.json\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-494][TI-1181] - [INFO] 2024-04-23 11:42:45.291 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-494][TI-1181] - [INFO] 2024-04-23 11:42:45.291 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-494][TI-1181] - [INFO] 2024-04-23 11:42:45.291 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-494][TI-1181] - [INFO] 2024-04-23 11:42:45.293 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-494][TI-1181] - [INFO] 2024-04-23 11:42:45.295 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-494][TI-1181] - [INFO] 2024-04-23 11:42:45.296 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_83/494/1181 check successfully
[WI-494][TI-1181] - [INFO] 2024-04-23 11:42:45.296 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-494][TI-1181] - [INFO] 2024-04-23 11:42:45.297 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-494][TI-1181] - [INFO] 2024-04-23 11:42:45.297 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-494][TI-1181] - [INFO] 2024-04-23 11:42:45.297 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-494][TI-1181] - [INFO] 2024-04-23 11:42:45.298 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ {
    "prop" : "raw_file_dir",
    "direct" : "OUT",
    "type" : "VARCHAR",
    "value" : ""
  } ],
  "varPool" : null,
  "rawScript" : "# move file to the reddit processing folder\n# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error\nfilename=$(basename \"${raw_file_dir}\")\nif ! grep -q \"${REDDIT_HOME}/processing\" <<< \"${raw_file_dir}\"; then\n    mv ${raw_file_dir} ${REDDIT_HOME}/processing\nelse\n    echo JSON is already in processing\nfi\n\n# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing\necho \"#{setValue(raw_file_dir=${REDDIT_HOME}/processing/${filename})}\"",
  "resourceList" : [ ]
}
[WI-494][TI-1181] - [INFO] 2024-04-23 11:42:45.298 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-494][TI-1181] - [INFO] 2024-04-23 11:42:45.299 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}] successfully
[WI-494][TI-1181] - [INFO] 2024-04-23 11:42:45.302 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-494][TI-1181] - [INFO] 2024-04-23 11:42:45.302 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-494][TI-1181] - [INFO] 2024-04-23 11:42:45.302 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-494][TI-1181] - [INFO] 2024-04-23 11:42:45.303 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-494][TI-1181] - [INFO] 2024-04-23 11:42:45.303 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-494][TI-1181] - [INFO] 2024-04-23 11:42:45.303 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export PYTHON_LAUNCHER=/bin/python3.11
# move file to the reddit processing folder
# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error
filename=$(basename "/local_storage/reddit/processing/386-20240422.json")
if ! grep -q "/local_storage/reddit/processing" <<< "/local_storage/reddit/processing/386-20240422.json"; then
    mv /local_storage/reddit/processing/386-20240422.json /local_storage/reddit/processing
else
    echo JSON is already in processing
fi

# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing
echo "#{setValue(raw_file_dir=/local_storage/reddit/processing/${filename})}"
[WI-494][TI-1181] - [INFO] 2024-04-23 11:42:45.304 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-494][TI-1181] - [INFO] 2024-04-23 11:42:45.304 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_83/494/1181/494_1181.sh
[WI-494][TI-1181] - [INFO] 2024-04-23 11:42:45.329 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 4788
[WI-0][TI-1181] - [INFO] 2024-04-23 11:42:46.145 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionRunningEvent(taskInstanceId=1181, processInstanceId=494, startTime=1713843765290, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, status=TaskExecutionStatus{code=1, desc='running'}, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/83/494/1181.log, executePath=null, processId=0, appIds=null, eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1181] - [INFO] 2024-04-23 11:42:46.151 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionRunningEvent(taskInstanceId=1181, processInstanceId=494, startTime=1713843765290, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, status=TaskExecutionStatus{code=1, desc='running'}, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/83/494/1181.log, executePath=null, processId=0, appIds=null, eventCreateTime=0, eventSendTime=1713843766145)
[WI-0][TI-1181] - [INFO] 2024-04-23 11:42:46.151 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionInfoEvent(taskInstanceId=1181, processInstanceId=494, startTime=1713843765290, workflowInstanceHost=172.18.0.9:5678, taskInstanceHost=172.18.1.1:1234, logPath=null, processId=0, eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1181] - [INFO] 2024-04-23 11:42:46.152 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionInfoEvent(taskInstanceId=1181, processInstanceId=494, startTime=1713843765290, workflowInstanceHost=172.18.0.9:5678, taskInstanceHost=172.18.1.1:1234, logPath=null, processId=0, eventCreateTime=0, eventSendTime=1713843766145)
[WI-0][TI-1181] - [INFO] 2024-04-23 11:42:46.154 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1181, success=true)
[WI-0][TI-1181] - [INFO] 2024-04-23 11:42:46.158 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1181)
[WI-0][TI-1181] - [INFO] 2024-04-23 11:42:46.162 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1181, success=true)
[WI-0][TI-1181] - [INFO] 2024-04-23 11:42:46.166 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1181)
[WI-0][TI-0] - [INFO] 2024-04-23 11:42:46.351 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
	JSON is already in processing
	#{setValue(raw_file_dir=/local_storage/reddit/processing/386-20240422.json)}
[WI-494][TI-1181] - [INFO] 2024-04-23 11:42:46.357 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_83/494/1181, processId:4788 ,exitStatusCode:0 ,processWaitForStatus:true ,processExitValue:0
[WI-494][TI-1181] - [INFO] 2024-04-23 11:42:46.357 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-494][TI-1181] - [INFO] 2024-04-23 11:42:46.357 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-494][TI-1181] - [INFO] 2024-04-23 11:42:46.358 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-494][TI-1181] - [INFO] 2024-04-23 11:42:46.359 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-494][TI-1181] - [INFO] 2024-04-23 11:42:46.362 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: SUCCESS to master : 172.18.1.1:1234
[WI-494][TI-1181] - [INFO] 2024-04-23 11:42:46.362 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-494][TI-1181] - [INFO] 2024-04-23 11:42:46.363 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_83/494/1181
[WI-494][TI-1181] - [INFO] 2024-04-23 11:42:46.364 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_83/494/1181
[WI-494][TI-1181] - [INFO] 2024-04-23 11:42:46.364 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-1181] - [INFO] 2024-04-23 11:42:47.153 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1181, processInstanceId=494, status=7, startTime=1713843765290, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/83/494/1181.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_83/494/1181, endTime=1713843766359, processId=4788, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1181] - [INFO] 2024-04-23 11:42:47.153 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1181, success=true)
[WI-0][TI-1181] - [INFO] 2024-04-23 11:42:47.156 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1181, processInstanceId=494, status=7, startTime=1713843765290, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/83/494/1181.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_83/494/1181, endTime=1713843766359, processId=4788, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713843767152)
[WI-0][TI-1181] - [WARN] 2024-04-23 11:42:47.156 +0800 o.a.d.s.w.m.MessageRetryRunner:[139] - Retry send message to master error
java.util.ConcurrentModificationException: null
	at java.util.ArrayList$Itr.checkForComodification(ArrayList.java:911)
	at java.util.ArrayList$Itr.next(ArrayList.java:861)
	at org.apache.dolphinscheduler.server.worker.message.MessageRetryRunner.run(MessageRetryRunner.java:127)
[WI-0][TI-0] - [INFO] 2024-04-23 11:42:47.268 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1182, taskName=spark preprocessing, firstSubmitTime=1713843767261, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.9:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=83, appIds=null, processInstanceId=494, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"processing"}], executorId=1, cmdTypeIfComplement=7, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[],"rawScript":"# $SPARK_HOME/bin/spark-submit \\\n#     --master spark://spark-master:7077 \\\n#     --conf spark.driver.cores=2 \\\n#     --conf spark.driver.memory=2G \\\n#     --conf spark.executor.instances=1 \\\n#     --conf spark.executor.cores=2 \\\n#     --conf spark.executor.memory=2G \\\n#     --files ${raw_file_dir} \\\n#     --name reddit_preprocessing spark_reddit_preprocessing.py\n\n$SPARK_HOME/bin/spark-submit \\\n    --master spark://spark-master:7077 \\\n    --files ${raw_file_dir} \\\n    --name reddit_preprocessing spark_reddit_preprocessing.py\n","resourceList":[{"id":null,"resourceName":"file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py","res":null}]}, environmentConfig=export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export HADOOP_CONF_DIR=/opt/hadoop-3.4.0/etc/hadoop
export PYSPARK_DRIVER_PYTHON=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='spark preprocessing'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240423'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1182'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13210058002752'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240423114247'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='processing'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='494'}, raw_file_dir=Property{prop='raw_file_dir', direct=IN, type=VARCHAR, value='/local_storage/reddit/processing/386-20240422.json'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240422'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-494][TI-1182] - [INFO] 2024-04-23 11:42:47.270 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: spark preprocessing to wait queue success
[WI-494][TI-1182] - [INFO] 2024-04-23 11:42:47.270 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-494][TI-1182] - [INFO] 2024-04-23 11:42:47.271 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-494][TI-1182] - [INFO] 2024-04-23 11:42:47.272 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-494][TI-1182] - [INFO] 2024-04-23 11:42:47.272 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-494][TI-1182] - [INFO] 2024-04-23 11:42:47.272 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713843767272
[WI-494][TI-1182] - [INFO] 2024-04-23 11:42:47.272 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 494_1182
[WI-494][TI-1182] - [INFO] 2024-04-23 11:42:47.272 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1182,
  "taskName" : "spark preprocessing",
  "firstSubmitTime" : 1713843767261,
  "startTime" : 1713843767272,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.9:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240423/13201021801792/83/494/1182.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 83,
  "processInstanceId" : 494,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"processing\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 7,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[],\"rawScript\":\"# $SPARK_HOME/bin/spark-submit \\\\\\n#     --master spark://spark-master:7077 \\\\\\n#     --conf spark.driver.cores=2 \\\\\\n#     --conf spark.driver.memory=2G \\\\\\n#     --conf spark.executor.instances=1 \\\\\\n#     --conf spark.executor.cores=2 \\\\\\n#     --conf spark.executor.memory=2G \\\\\\n#     --files ${raw_file_dir} \\\\\\n#     --name reddit_preprocessing spark_reddit_preprocessing.py\\n\\n$SPARK_HOME/bin/spark-submit \\\\\\n    --master spark://spark-master:7077 \\\\\\n    --files ${raw_file_dir} \\\\\\n    --name reddit_preprocessing spark_reddit_preprocessing.py\\n\",\"resourceList\":[{\"id\":null,\"resourceName\":\"file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py\",\"res\":null}]}",
  "environmentConfig" : "export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3\nexport JAVA_HOME=/opt/java/openjdk\nexport HADOOP_CONF_DIR=/opt/hadoop-3.4.0/etc/hadoop\nexport PYSPARK_DRIVER_PYTHON=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "spark preprocessing"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1182"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13210058002752"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423114247"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "processing"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "494"
    },
    "raw_file_dir" : {
      "prop" : "raw_file_dir",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit/processing/386-20240422.json"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240422"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "494_1182",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"raw_file_dir\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"/local_storage/reddit/processing/386-20240422.json\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-494][TI-1182] - [INFO] 2024-04-23 11:42:47.273 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-494][TI-1182] - [INFO] 2024-04-23 11:42:47.273 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-494][TI-1182] - [INFO] 2024-04-23 11:42:47.273 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-494][TI-1182] - [INFO] 2024-04-23 11:42:47.278 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-494][TI-1182] - [INFO] 2024-04-23 11:42:47.278 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-494][TI-1182] - [INFO] 2024-04-23 11:42:47.279 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_83/494/1182 check successfully
[WI-494][TI-1182] - [INFO] 2024-04-23 11:42:47.279 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-494][TI-1182] - [INFO] 2024-04-23 11:42:47.281 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py=ResourceContext.ResourceItem(resourceAbsolutePathInStorage=file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py, resourceRelativePath=spark_reddit_preprocessing.py, resourceAbsolutePathInLocal=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_83/494/1182/spark_reddit_preprocessing.py)})
[WI-494][TI-1182] - [INFO] 2024-04-23 11:42:47.282 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-494][TI-1182] - [INFO] 2024-04-23 11:42:47.283 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-494][TI-1182] - [INFO] 2024-04-23 11:42:47.284 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ ],
  "varPool" : null,
  "rawScript" : "# $SPARK_HOME/bin/spark-submit \\\n#     --master spark://spark-master:7077 \\\n#     --conf spark.driver.cores=2 \\\n#     --conf spark.driver.memory=2G \\\n#     --conf spark.executor.instances=1 \\\n#     --conf spark.executor.cores=2 \\\n#     --conf spark.executor.memory=2G \\\n#     --files ${raw_file_dir} \\\n#     --name reddit_preprocessing spark_reddit_preprocessing.py\n\n$SPARK_HOME/bin/spark-submit \\\n    --master spark://spark-master:7077 \\\n    --files ${raw_file_dir} \\\n    --name reddit_preprocessing spark_reddit_preprocessing.py\n",
  "resourceList" : [ {
    "id" : null,
    "resourceName" : "file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py",
    "res" : null
  } ]
}
[WI-494][TI-1182] - [INFO] 2024-04-23 11:42:47.284 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-494][TI-1182] - [INFO] 2024-04-23 11:42:47.285 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}] successfully
[WI-494][TI-1182] - [INFO] 2024-04-23 11:42:47.286 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-494][TI-1182] - [INFO] 2024-04-23 11:42:47.286 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-494][TI-1182] - [INFO] 2024-04-23 11:42:47.287 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-494][TI-1182] - [INFO] 2024-04-23 11:42:47.288 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-494][TI-1182] - [INFO] 2024-04-23 11:42:47.288 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-494][TI-1182] - [INFO] 2024-04-23 11:42:47.289 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export HADOOP_CONF_DIR=/opt/hadoop-3.4.0/etc/hadoop
export PYSPARK_DRIVER_PYTHON=/bin/python3.11
# $SPARK_HOME/bin/spark-submit \
#     --master spark://spark-master:7077 \
#     --conf spark.driver.cores=2 \
#     --conf spark.driver.memory=2G \
#     --conf spark.executor.instances=1 \
#     --conf spark.executor.cores=2 \
#     --conf spark.executor.memory=2G \
#     --files /local_storage/reddit/processing/386-20240422.json \
#     --name reddit_preprocessing spark_reddit_preprocessing.py

$SPARK_HOME/bin/spark-submit \
    --master spark://spark-master:7077 \
    --files /local_storage/reddit/processing/386-20240422.json \
    --name reddit_preprocessing spark_reddit_preprocessing.py

[WI-494][TI-1182] - [INFO] 2024-04-23 11:42:47.290 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-494][TI-1182] - [INFO] 2024-04-23 11:42:47.290 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_83/494/1182/494_1182.sh
[WI-494][TI-1182] - [INFO] 2024-04-23 11:42:47.294 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 4800
[WI-0][TI-1182] - [INFO] 2024-04-23 11:42:48.165 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionRunningEvent(taskInstanceId=1182, processInstanceId=494, startTime=1713843767272, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, status=TaskExecutionStatus{code=1, desc='running'}, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/83/494/1182.log, executePath=null, processId=0, appIds=null, eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1181] - [INFO] 2024-04-23 11:42:48.165 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1181, success=true)
[WI-0][TI-1182] - [INFO] 2024-04-23 11:42:48.171 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionRunningEvent(taskInstanceId=1182, processInstanceId=494, startTime=1713843767272, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, status=TaskExecutionStatus{code=1, desc='running'}, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/83/494/1182.log, executePath=null, processId=0, appIds=null, eventCreateTime=0, eventSendTime=1713843768164)
[WI-0][TI-1182] - [INFO] 2024-04-23 11:42:48.172 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionInfoEvent(taskInstanceId=1182, processInstanceId=494, startTime=1713843767272, workflowInstanceHost=172.18.0.9:5678, taskInstanceHost=172.18.1.1:1234, logPath=null, processId=0, eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1182] - [INFO] 2024-04-23 11:42:48.174 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionInfoEvent(taskInstanceId=1182, processInstanceId=494, startTime=1713843767272, workflowInstanceHost=172.18.0.9:5678, taskInstanceHost=172.18.1.1:1234, logPath=null, processId=0, eventCreateTime=0, eventSendTime=1713843768164)
[WI-0][TI-1182] - [INFO] 2024-04-23 11:42:48.178 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1182, success=true)
[WI-0][TI-1182] - [INFO] 2024-04-23 11:42:48.182 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1182)
[WI-0][TI-1182] - [INFO] 2024-04-23 11:42:48.186 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1182, success=true)
[WI-0][TI-1182] - [INFO] 2024-04-23 11:42:48.190 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1182)
[WI-0][TI-0] - [INFO] 2024-04-23 11:42:48.297 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
[WI-0][TI-0] - [INFO] 2024-04-23 11:42:49.249 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7077363896848138 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:42:50.433 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:42:49 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[WI-0][TI-0] - [INFO] 2024-04-23 11:42:51.442 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:42:50 INFO SparkContext: Running Spark version 3.5.1
	24/04/23 11:42:50 INFO SparkContext: OS info Linux, 6.5.0-28-generic, amd64
	24/04/23 11:42:50 INFO SparkContext: Java version 1.8.0_402
	24/04/23 11:42:50 INFO ResourceUtils: ==============================================================
	24/04/23 11:42:50 INFO ResourceUtils: No custom resources configured for spark.driver.
	24/04/23 11:42:50 INFO ResourceUtils: ==============================================================
	24/04/23 11:42:50 INFO SparkContext: Submitted application: reddit_preprocessing
	24/04/23 11:42:50 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
	24/04/23 11:42:50 INFO ResourceProfile: Limiting resource is cpu
	24/04/23 11:42:50 INFO ResourceProfileManager: Added ResourceProfile id: 0
	24/04/23 11:42:50 INFO SecurityManager: Changing view acls to: default
	24/04/23 11:42:50 INFO SecurityManager: Changing modify acls to: default
	24/04/23 11:42:50 INFO SecurityManager: Changing view acls groups to: 
	24/04/23 11:42:50 INFO SecurityManager: Changing modify acls groups to: 
	24/04/23 11:42:50 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: default; groups with view permissions: EMPTY; users with modify permissions: default; groups with modify permissions: EMPTY
	24/04/23 11:42:51 INFO Utils: Successfully started service 'sparkDriver' on port 36547.
	24/04/23 11:42:51 INFO SparkEnv: Registering MapOutputTracker
	24/04/23 11:42:51 INFO SparkEnv: Registering BlockManagerMaster
	24/04/23 11:42:51 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
	24/04/23 11:42:51 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
	24/04/23 11:42:51 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
	24/04/23 11:42:51 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-53c2d6df-20bc-48d1-ab9a-2c3e7d8498d2
[WI-0][TI-0] - [INFO] 2024-04-23 11:42:52.454 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:42:51 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
	24/04/23 11:42:51 INFO SparkEnv: Registering OutputCommitCoordinator
	24/04/23 11:42:51 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
	24/04/23 11:42:51 INFO Utils: Successfully started service 'SparkUI' on port 4040.
	24/04/23 11:42:51 INFO SparkContext: Added file file:///local_storage/reddit/processing/386-20240422.json at spark://c0e814e3f0bd:36547/files/386-20240422.json with timestamp 1713843770560
	24/04/23 11:42:51 INFO Utils: Copying /local_storage/reddit/processing/386-20240422.json to /tmp/spark-54db77b1-4faf-49e3-b79f-3690e8c07bda/userFiles-1bb237b8-a0cb-46cc-8a0b-90840f2c7eac/386-20240422.json
	24/04/23 11:42:52 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
	24/04/23 11:42:52 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.3:7077 after 97 ms (0 ms spent in bootstraps)
[WI-0][TI-0] - [INFO] 2024-04-23 11:42:52.463 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7882352941176471 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:42:53.463 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:42:52 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20240423034252-0016
	24/04/23 11:42:52 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20240423034252-0016/0 on worker-20240423012857-172.18.0.7-41063 (172.18.0.7:41063) with 2 core(s)
	24/04/23 11:42:52 INFO StandaloneSchedulerBackend: Granted executor ID app-20240423034252-0016/0 on hostPort 172.18.0.7:41063 with 2 core(s), 1024.0 MiB RAM
	24/04/23 11:42:52 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41557.
	24/04/23 11:42:52 INFO NettyBlockTransferService: Server created on c0e814e3f0bd:41557
	24/04/23 11:42:52 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
	24/04/23 11:42:52 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20240423034252-0016/0 is now RUNNING
	24/04/23 11:42:52 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, c0e814e3f0bd, 41557, None)
	24/04/23 11:42:52 INFO BlockManagerMasterEndpoint: Registering block manager c0e814e3f0bd:41557 with 366.3 MiB RAM, BlockManagerId(driver, c0e814e3f0bd, 41557, None)
	24/04/23 11:42:52 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, c0e814e3f0bd, 41557, None)
	24/04/23 11:42:52 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, c0e814e3f0bd, 41557, None)
	24/04/23 11:42:53 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
[WI-0][TI-0] - [INFO] 2024-04-23 11:42:53.477 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8524096385542169 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:42:54.468 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	
	
	
	 file:///tmp/spark-54db77b1-4faf-49e3-b79f-3690e8c07bda/userFiles-1bb237b8-a0cb-46cc-8a0b-90840f2c7eac/386-20240422.json 
	
	
	
	24/04/23 11:42:53 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
	24/04/23 11:42:53 INFO SharedState: Warehouse path is 'file:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_83/494/1182/spark-warehouse'.
[WI-0][TI-0] - [INFO] 2024-04-23 11:42:54.479 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9398734177215191 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:42:55.512 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8212121212121213 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:42:56.538 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8461538461538463 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:42:56.551 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:42:55 INFO InMemoryFileIndex: It took 79 ms to list leaf files for 1 paths.
	24/04/23 11:42:56 INFO InMemoryFileIndex: It took 3 ms to list leaf files for 1 paths.
[WI-0][TI-0] - [INFO] 2024-04-23 11:42:57.555 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8397435897435896 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:42:58.555 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:42:57 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.7:42584) with ID 0,  ResourceProfileId 0
	24/04/23 11:42:58 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.7:41737 with 434.4 MiB RAM, BlockManagerId(0, 172.18.0.7, 41737, None)
[WI-0][TI-0] - [INFO] 2024-04-23 11:42:58.558 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.860759493670886 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:43:01.573 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:43:00 INFO FileSourceStrategy: Pushed Filters: 
	24/04/23 11:43:00 INFO FileSourceStrategy: Post-Scan Filters: 
	24/04/23 11:43:01 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 350.7 KiB, free 366.0 MiB)
	24/04/23 11:43:01 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 34.5 KiB, free 365.9 MiB)
	24/04/23 11:43:01 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on c0e814e3f0bd:41557 (size: 34.5 KiB, free: 366.3 MiB)
	24/04/23 11:43:01 INFO SparkContext: Created broadcast 0 from json at NativeMethodAccessorImpl.java:0
	24/04/23 11:43:01 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
	24/04/23 11:43:01 INFO SparkContext: Starting job: json at NativeMethodAccessorImpl.java:0
	24/04/23 11:43:01 INFO DAGScheduler: Got job 0 (json at NativeMethodAccessorImpl.java:0) with 1 output partitions
	24/04/23 11:43:01 INFO DAGScheduler: Final stage: ResultStage 0 (json at NativeMethodAccessorImpl.java:0)
	24/04/23 11:43:01 INFO DAGScheduler: Parents of final stage: List()
	24/04/23 11:43:01 INFO DAGScheduler: Missing parents: List()
	24/04/23 11:43:01 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at json at NativeMethodAccessorImpl.java:0), which has no missing parents
[WI-0][TI-0] - [INFO] 2024-04-23 11:43:02.574 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:43:01 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 16.4 KiB, free 365.9 MiB)
	24/04/23 11:43:01 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.7 KiB, free 365.9 MiB)
	24/04/23 11:43:01 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on c0e814e3f0bd:41557 (size: 7.7 KiB, free: 366.3 MiB)
	24/04/23 11:43:01 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1585
	24/04/23 11:43:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at json at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
	24/04/23 11:43:01 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
	24/04/23 11:43:01 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.7, executor 0, partition 0, PROCESS_LOCAL, 8478 bytes) 
[WI-0][TI-0] - [INFO] 2024-04-23 11:43:10.667 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7768595041322314 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:43:11.711 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7154471544715447 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-1123] - [INFO] 2024-04-23 11:44:52.792 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1123, processInstanceId=487, status=9, startTime=1713838208504, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1123.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1123, endTime=1713838483436, processId=1677, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713843591892)
[WI-0][TI-1123] - [INFO] 2024-04-23 11:44:52.799 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1123, processInstanceId=487, status=9, startTime=1713838208504, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1123.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1123, endTime=1713838483436, processId=1677, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713843892792)
[WI-0][TI-1111] - [INFO] 2024-04-23 11:44:54.802 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1111, processInstanceId=487, status=9, startTime=1713837256404, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1111.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1111, endTime=1713838170352, processId=1017, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713843593921)
[WI-0][TI-1111] - [INFO] 2024-04-23 11:44:54.805 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1111, processInstanceId=487, status=9, startTime=1713837256404, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1111.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1111, endTime=1713838170352, processId=1017, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713843894802)
[WI-0][TI-1144] - [INFO] 2024-04-23 11:47:15.287 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1144, processInstanceId=489, status=9, startTime=1713840953087, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/80/489/1144.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1144, endTime=1713841331355, processId=3026, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713843735080)
[WI-0][TI-1144] - [INFO] 2024-04-23 11:47:15.292 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1144, processInstanceId=489, status=9, startTime=1713840953087, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/80/489/1144.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1144, endTime=1713841331355, processId=3026, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713844035287)
[WI-0][TI-0] - [INFO] 2024-04-23 11:49:12.408 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:49:12 ERROR StandaloneSchedulerBackend: Application has been killed. Reason: Master removed our application: KILLED
	24/04/23 11:49:12 INFO SparkContext: SparkContext is stopping with exitCode 0.
	24/04/23 11:49:12 INFO TaskSchedulerImpl: Cancelling stage 0
	24/04/23 11:49:12 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage cancelled: Job aborted due to stage failure: Master removed our application: KILLED
	24/04/23 11:49:12 INFO TaskSchedulerImpl: Stage 0 was cancelled
	24/04/23 11:49:12 INFO DAGScheduler: ResultStage 0 (json at NativeMethodAccessorImpl.java:0) failed in 370.786 s due to Job aborted due to stage failure: Master removed our application: KILLED
[WI-0][TI-0] - [INFO] 2024-04-23 11:49:13.414 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:49:12 INFO SparkUI: Stopped Spark web UI at http://c0e814e3f0bd:4040
	24/04/23 11:49:12 INFO DAGScheduler: Job 0 failed: json at NativeMethodAccessorImpl.java:0, took 370.955609 s
	24/04/23 11:49:12 INFO StandaloneSchedulerBackend: Shutting down all executors
	24/04/23 11:49:12 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Asking each executor to shut down
	24/04/23 11:49:12 ERROR Utils: Uncaught exception in thread stop-spark-context
	org.apache.spark.SparkException: Exception thrown in awaitResult: 
		at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
		at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
		at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
		at org.apache.spark.deploy.client.StandaloneAppClient.stop(StandaloneAppClient.scala:288)
		at org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend.org$apache$spark$scheduler$cluster$StandaloneSchedulerBackend$$stop(StandaloneSchedulerBackend.scala:275)
		at org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend.stop(StandaloneSchedulerBackend.scala:142)
		at org.apache.spark.scheduler.SchedulerBackend.stop(SchedulerBackend.scala:33)
		at org.apache.spark.scheduler.SchedulerBackend.stop$(SchedulerBackend.scala:33)
		at org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend.stop(CoarseGrainedSchedulerBackend.scala:54)
		at org.apache.spark.scheduler.TaskSchedulerImpl.$anonfun$stop$2(TaskSchedulerImpl.scala:992)
		at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1375)
		at org.apache.spark.scheduler.TaskSchedulerImpl.stop(TaskSchedulerImpl.scala:992)
		at org.apache.spark.scheduler.DAGScheduler.$anonfun$stop$4(DAGScheduler.scala:2976)
		at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1375)
		at org.apache.spark.scheduler.DAGScheduler.stop(DAGScheduler.scala:2976)
		at org.apache.spark.SparkContext.$anonfun$stop$12(SparkContext.scala:2263)
		at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1375)
		at org.apache.spark.SparkContext.stop(SparkContext.scala:2263)
		at org.apache.spark.SparkContext.stop(SparkContext.scala:2216)
		at org.apache.spark.SparkContext$$anon$3.run(SparkContext.scala:2203)
	Caused by: org.apache.spark.SparkException: Could not find AppClient.
		at org.apache.spark.rpc.netty.Dispatcher.postMessage(Dispatcher.scala:178)
		at org.apache.spark.rpc.netty.Dispatcher.postLocalMessage(Dispatcher.scala:144)
		at org.apache.spark.rpc.netty.NettyRpcEnv.askAbortable(NettyRpcEnv.scala:242)
		at org.apache.spark.rpc.netty.NettyRpcEndpointRef.askAbortable(NettyRpcEnv.scala:554)
		at org.apache.spark.rpc.netty.NettyRpcEndpointRef.ask(NettyRpcEnv.scala:558)
		at org.apache.spark.rpc.RpcEndpointRef.ask(RpcEndpointRef.scala:72)
		... 17 more
	24/04/23 11:49:12 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
	Traceback (most recent call last):
	  File "/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_83/494/1182/spark_reddit_preprocessing.py", line 47, in <module>
	    raw_df = spark.read.json(reddit_json_dir)
	             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
	  File "/opt/spark-3.5.1-bin-hadoop3/python/lib/pyspark.zip/pyspark/sql/readwriter.py", line 425, in json
	  File "/opt/spark-3.5.1-bin-hadoop3/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
	  File "/opt/spark-3.5.1-bin-hadoop3/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 179, in deco
	  File "/opt/spark-3.5.1-bin-hadoop3/python/lib/py4j-0.10.9.7-src.zip/py4j/protocol.py", line 326, in get_return_value
	py4j.protocol.Py4JJavaError: An error occurred while calling o27.json.
	: org.apache.spark.SparkException: Job aborted due to stage failure: Master removed our application: KILLED
		at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)
		at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)
		at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)
		at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
		at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
		at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
		at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)
		at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)
		at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)
		at scala.Option.foreach(Option.scala:407)
		at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)
		at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)
		at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)
		at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)
		at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
		at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:989)
		at org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)
		at org.apache.spark.SparkContext.runJob(SparkContext.scala:2493)
		at org.apache.spark.sql.catalyst.json.JsonInferSchema.infer(JsonInferSchema.scala:120)
		at org.apache.spark.sql.execution.datasources.json.TextInputJsonDataSource$.$anonfun$inferFromDataset$5(JsonDataSource.scala:109)
		at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)
		at org.apache.spark.sql.execution.datasources.json.TextInputJsonDataSource$.inferFromDataset(JsonDataSource.scala:109)
		at org.apache.spark.sql.execution.datasources.json.TextInputJsonDataSource$.infer(JsonDataSource.scala:98)
		at org.apache.spark.sql.execution.datasources.json.JsonDataSource.inferSchema(JsonDataSource.scala:64)
		at org.apache.spark.sql.execution.datasources.json.JsonFileFormat.inferSchema(JsonFileFormat.scala:59)
		at org.apache.spark.sql.execution.datasources.DataSource.$anonfun$getOrInferFileFormatSchema$11(DataSource.scala:208)
		at scala.Option.orElse(Option.scala:447)
		at org.apache.spark.sql.execution.datasources.DataSource.getOrInferFileFormatSchema(DataSource.scala:205)
		at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:407)
		at org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)
		at org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)
		at scala.Option.getOrElse(Option.scala:189)
		at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)
		at org.apache.spark.sql.DataFrameReader.json(DataFrameReader.scala:362)
		at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
		at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
		at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
		at java.lang.reflect.Method.invoke(Method.java:498)
		at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
		at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
		at py4j.Gateway.invoke(Gateway.java:282)
		at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
		at py4j.commands.CallCommand.execute(CallCommand.java:79)
		at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
		at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
		at java.lang.Thread.run(Thread.java:750)
	
	24/04/23 11:49:12 INFO MemoryStore: MemoryStore cleared
	24/04/23 11:49:12 INFO BlockManager: BlockManager stopped
	24/04/23 11:49:12 INFO ShutdownHookManager: Shutdown hook called
	24/04/23 11:49:12 INFO ShutdownHookManager: Deleting directory /tmp/spark-54db77b1-4faf-49e3-b79f-3690e8c07bda
	24/04/23 11:49:12 INFO ShutdownHookManager: Deleting directory /tmp/spark-54db77b1-4faf-49e3-b79f-3690e8c07bda/userFiles-1bb237b8-a0cb-46cc-8a0b-90840f2c7eac
	24/04/23 11:49:12 INFO BlockManagerMaster: BlockManagerMaster stopped
	24/04/23 11:49:12 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
	24/04/23 11:49:12 INFO ShutdownHookManager: Deleting directory /tmp/spark-54db77b1-4faf-49e3-b79f-3690e8c07bda/pyspark-c981a575-b89c-45bb-91c0-f98b3ac7dff0
	24/04/23 11:49:12 INFO ShutdownHookManager: Deleting directory /tmp/spark-98a6b152-3957-4039-8265-7f652830e9a7
	24/04/23 11:49:13 INFO SparkContext: Successfully stopped SparkContext
[WI-494][TI-1182] - [INFO] 2024-04-23 11:49:13.415 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_83/494/1182, processId:4800 ,exitStatusCode:1 ,processWaitForStatus:true ,processExitValue:1
[WI-494][TI-1182] - [INFO] 2024-04-23 11:49:13.417 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-494][TI-1182] - [INFO] 2024-04-23 11:49:13.417 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-494][TI-1182] - [INFO] 2024-04-23 11:49:13.418 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-494][TI-1182] - [INFO] 2024-04-23 11:49:13.418 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-494][TI-1182] - [INFO] 2024-04-23 11:49:13.420 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: FAILURE to master : 172.18.1.1:1234
[WI-494][TI-1182] - [INFO] 2024-04-23 11:49:13.421 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-494][TI-1182] - [INFO] 2024-04-23 11:49:13.421 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_83/494/1182
[WI-494][TI-1182] - [INFO] 2024-04-23 11:49:13.421 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_83/494/1182
[WI-494][TI-1182] - [INFO] 2024-04-23 11:49:13.425 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-1182] - [INFO] 2024-04-23 11:49:13.608 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1182, processInstanceId=494, status=6, startTime=1713843767272, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/83/494/1182.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_83/494/1182, endTime=1713844153418, processId=4800, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1182] - [INFO] 2024-04-23 11:49:13.612 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1182, success=true)
[WI-0][TI-1182] - [INFO] 2024-04-23 11:49:13.617 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1182, processInstanceId=494, status=6, startTime=1713843767272, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/83/494/1182.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_83/494/1182, endTime=1713844153418, processId=4800, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713844153603)
[WI-0][TI-1182] - [WARN] 2024-04-23 11:49:13.618 +0800 o.a.d.s.w.m.MessageRetryRunner:[139] - Retry send message to master error
java.util.ConcurrentModificationException: null
	at java.util.ArrayList$Itr.checkForComodification(ArrayList.java:911)
	at java.util.ArrayList$Itr.next(ArrayList.java:861)
	at org.apache.dolphinscheduler.server.worker.message.MessageRetryRunner.run(MessageRetryRunner.java:127)
[WI-0][TI-1182] - [INFO] 2024-04-23 11:49:13.621 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1182, success=true)
[WI-0][TI-0] - [INFO] 2024-04-23 11:49:13.821 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7471590909090908 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:49:14.839 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.76775956284153 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:49:47.903 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1183, taskName=search for intake JSON files, firstSubmitTime=1713844187892, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.9:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=84, appIds=null, processInstanceId=495, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"processing"}], executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":""}],"rawScript":"# find 1 raw file in the folder\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\n\n# check if raw_file_dir is empty, then set raw_file_dir to null\nif [ -z \"$raw_file_dir\" ]; then\n    raw_file_dir=null\nfi\n\necho \"#{setValue(raw_file_dir=${raw_file_dir})}\"","resourceList":[]}, environmentConfig=export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='search for intake JSON files'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240423'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1183'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13340113777664'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240423114947'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='processing'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='495'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240422'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=null, dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-495][TI-1183] - [INFO] 2024-04-23 11:49:47.904 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: search for intake JSON files to wait queue success
[WI-495][TI-1183] - [INFO] 2024-04-23 11:49:47.905 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-495][TI-1183] - [INFO] 2024-04-23 11:49:47.921 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-495][TI-1183] - [INFO] 2024-04-23 11:49:47.921 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-495][TI-1183] - [INFO] 2024-04-23 11:49:47.922 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-495][TI-1183] - [INFO] 2024-04-23 11:49:47.922 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713844187922
[WI-495][TI-1183] - [INFO] 2024-04-23 11:49:47.923 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 495_1183
[WI-495][TI-1183] - [INFO] 2024-04-23 11:49:47.923 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1183,
  "taskName" : "search for intake JSON files",
  "firstSubmitTime" : 1713844187892,
  "startTime" : 1713844187922,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.9:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240423/13201021801792/84/495/1183.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 84,
  "processInstanceId" : 495,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"processing\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[{\"prop\":\"raw_file_dir\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"\"}],\"rawScript\":\"# find 1 raw file in the folder\\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\\n\\n# check if raw_file_dir is empty, then set raw_file_dir to null\\nif [ -z \\\"$raw_file_dir\\\" ]; then\\n    raw_file_dir=null\\nfi\\n\\necho \\\"#{setValue(raw_file_dir=${raw_file_dir})}\\\"\",\"resourceList\":[]}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "search for intake JSON files"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1183"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13340113777664"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423114947"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "processing"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "495"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240422"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "495_1183",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-495][TI-1183] - [INFO] 2024-04-23 11:49:47.923 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-495][TI-1183] - [INFO] 2024-04-23 11:49:47.923 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-495][TI-1183] - [INFO] 2024-04-23 11:49:47.923 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-495][TI-1183] - [INFO] 2024-04-23 11:49:47.928 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-495][TI-1183] - [INFO] 2024-04-23 11:49:47.928 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-495][TI-1183] - [INFO] 2024-04-23 11:49:47.930 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_84/495/1183 check successfully
[WI-495][TI-1183] - [INFO] 2024-04-23 11:49:47.930 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-495][TI-1183] - [INFO] 2024-04-23 11:49:47.930 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-495][TI-1183] - [INFO] 2024-04-23 11:49:47.930 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-495][TI-1183] - [INFO] 2024-04-23 11:49:47.930 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-495][TI-1183] - [INFO] 2024-04-23 11:49:47.930 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ {
    "prop" : "raw_file_dir",
    "direct" : "OUT",
    "type" : "VARCHAR",
    "value" : ""
  } ],
  "varPool" : null,
  "rawScript" : "# find 1 raw file in the folder\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\n\n# check if raw_file_dir is empty, then set raw_file_dir to null\nif [ -z \"$raw_file_dir\" ]; then\n    raw_file_dir=null\nfi\n\necho \"#{setValue(raw_file_dir=${raw_file_dir})}\"",
  "resourceList" : [ ]
}
[WI-495][TI-1183] - [INFO] 2024-04-23 11:49:47.931 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-495][TI-1183] - [INFO] 2024-04-23 11:49:47.931 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: null successfully
[WI-495][TI-1183] - [INFO] 2024-04-23 11:49:47.931 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-495][TI-1183] - [INFO] 2024-04-23 11:49:47.931 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-495][TI-1183] - [INFO] 2024-04-23 11:49:47.931 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-495][TI-1183] - [INFO] 2024-04-23 11:49:47.932 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-495][TI-1183] - [INFO] 2024-04-23 11:49:47.936 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-495][TI-1183] - [INFO] 2024-04-23 11:49:47.936 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export PYTHON_LAUNCHER=/bin/python3.11
# find 1 raw file in the folder
raw_file_dir=$(find /local_storage/reddit/processing -type f -name '*.json'| head -n 1)

# check if raw_file_dir is empty, then set raw_file_dir to null
if [ -z "$raw_file_dir" ]; then
    raw_file_dir=null
fi

echo "#{setValue(raw_file_dir=${raw_file_dir})}"
[WI-495][TI-1183] - [INFO] 2024-04-23 11:49:47.936 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-495][TI-1183] - [INFO] 2024-04-23 11:49:47.936 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_84/495/1183/495_1183.sh
[WI-495][TI-1183] - [INFO] 2024-04-23 11:49:47.950 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 5018
[WI-0][TI-1183] - [INFO] 2024-04-23 11:49:48.639 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1183, success=true)
[WI-0][TI-1183] - [INFO] 2024-04-23 11:49:48.645 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1183)
[WI-0][TI-0] - [INFO] 2024-04-23 11:49:48.952 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
	#{setValue(raw_file_dir=/local_storage/reddit/processing/386-20240422.json)}
[WI-495][TI-1183] - [INFO] 2024-04-23 11:49:48.955 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_84/495/1183, processId:5018 ,exitStatusCode:0 ,processWaitForStatus:true ,processExitValue:0
[WI-495][TI-1183] - [INFO] 2024-04-23 11:49:48.956 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-495][TI-1183] - [INFO] 2024-04-23 11:49:48.956 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-495][TI-1183] - [INFO] 2024-04-23 11:49:48.956 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-495][TI-1183] - [INFO] 2024-04-23 11:49:48.956 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-495][TI-1183] - [INFO] 2024-04-23 11:49:48.968 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: SUCCESS to master : 172.18.1.1:1234
[WI-495][TI-1183] - [INFO] 2024-04-23 11:49:48.968 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-495][TI-1183] - [INFO] 2024-04-23 11:49:48.968 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_84/495/1183
[WI-495][TI-1183] - [INFO] 2024-04-23 11:49:48.969 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_84/495/1183
[WI-495][TI-1183] - [INFO] 2024-04-23 11:49:48.969 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-1183] - [INFO] 2024-04-23 11:49:49.637 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1183, success=true)
[WI-0][TI-0] - [INFO] 2024-04-23 11:49:50.730 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1185, taskName=move to processing, firstSubmitTime=1713844190712, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.9:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=84, appIds=null, processInstanceId=495, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"processing"}], executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":""}],"rawScript":"# move file to the reddit processing folder\n# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error\nfilename=$(basename \"${raw_file_dir}\")\nif ! grep -q \"${REDDIT_HOME}/processing\" <<< \"${raw_file_dir}\"; then\n    mv ${raw_file_dir} ${REDDIT_HOME}/processing\nelse\n    echo JSON is already in processing\nfi\n\n# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing\necho \"#{setValue(raw_file_dir=${REDDIT_HOME}/processing/${filename})}\"","resourceList":[]}, environmentConfig=export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='move to processing'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240423'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1185'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13340390094208'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240423114950'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='processing'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='495'}, raw_file_dir=Property{prop='raw_file_dir', direct=IN, type=VARCHAR, value='/local_storage/reddit/processing/386-20240422.json'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240422'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-495][TI-1185] - [INFO] 2024-04-23 11:49:50.731 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: move to processing to wait queue success
[WI-495][TI-1185] - [INFO] 2024-04-23 11:49:50.731 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-495][TI-1185] - [INFO] 2024-04-23 11:49:50.744 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-495][TI-1185] - [INFO] 2024-04-23 11:49:50.744 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-495][TI-1185] - [INFO] 2024-04-23 11:49:50.744 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-495][TI-1185] - [INFO] 2024-04-23 11:49:50.745 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713844190745
[WI-495][TI-1185] - [INFO] 2024-04-23 11:49:50.746 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 495_1185
[WI-495][TI-1185] - [INFO] 2024-04-23 11:49:50.746 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1185,
  "taskName" : "move to processing",
  "firstSubmitTime" : 1713844190712,
  "startTime" : 1713844190745,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.9:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240423/13201021801792/84/495/1185.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 84,
  "processInstanceId" : 495,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"processing\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[{\"prop\":\"raw_file_dir\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"\"}],\"rawScript\":\"# move file to the reddit processing folder\\n# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error\\nfilename=$(basename \\\"${raw_file_dir}\\\")\\nif ! grep -q \\\"${REDDIT_HOME}/processing\\\" <<< \\\"${raw_file_dir}\\\"; then\\n    mv ${raw_file_dir} ${REDDIT_HOME}/processing\\nelse\\n    echo JSON is already in processing\\nfi\\n\\n# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing\\necho \\\"#{setValue(raw_file_dir=${REDDIT_HOME}/processing/${filename})}\\\"\",\"resourceList\":[]}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "move to processing"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1185"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13340390094208"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423114950"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "processing"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "495"
    },
    "raw_file_dir" : {
      "prop" : "raw_file_dir",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit/processing/386-20240422.json"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240422"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "495_1185",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"raw_file_dir\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"/local_storage/reddit/processing/386-20240422.json\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-495][TI-1185] - [INFO] 2024-04-23 11:49:50.747 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-495][TI-1185] - [INFO] 2024-04-23 11:49:50.747 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-495][TI-1185] - [INFO] 2024-04-23 11:49:50.747 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-495][TI-1185] - [INFO] 2024-04-23 11:49:50.756 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-495][TI-1185] - [INFO] 2024-04-23 11:49:50.757 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-495][TI-1185] - [INFO] 2024-04-23 11:49:50.758 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_84/495/1185 check successfully
[WI-495][TI-1185] - [INFO] 2024-04-23 11:49:50.758 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-495][TI-1185] - [INFO] 2024-04-23 11:49:50.759 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-495][TI-1185] - [INFO] 2024-04-23 11:49:50.759 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-495][TI-1185] - [INFO] 2024-04-23 11:49:50.759 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-495][TI-1185] - [INFO] 2024-04-23 11:49:50.759 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ {
    "prop" : "raw_file_dir",
    "direct" : "OUT",
    "type" : "VARCHAR",
    "value" : ""
  } ],
  "varPool" : null,
  "rawScript" : "# move file to the reddit processing folder\n# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error\nfilename=$(basename \"${raw_file_dir}\")\nif ! grep -q \"${REDDIT_HOME}/processing\" <<< \"${raw_file_dir}\"; then\n    mv ${raw_file_dir} ${REDDIT_HOME}/processing\nelse\n    echo JSON is already in processing\nfi\n\n# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing\necho \"#{setValue(raw_file_dir=${REDDIT_HOME}/processing/${filename})}\"",
  "resourceList" : [ ]
}
[WI-495][TI-1185] - [INFO] 2024-04-23 11:49:50.760 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-495][TI-1185] - [INFO] 2024-04-23 11:49:50.760 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}] successfully
[WI-495][TI-1185] - [INFO] 2024-04-23 11:49:50.761 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-495][TI-1185] - [INFO] 2024-04-23 11:49:50.762 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-495][TI-1185] - [INFO] 2024-04-23 11:49:50.762 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-495][TI-1185] - [INFO] 2024-04-23 11:49:50.765 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-495][TI-1185] - [INFO] 2024-04-23 11:49:50.765 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-495][TI-1185] - [INFO] 2024-04-23 11:49:50.766 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export PYTHON_LAUNCHER=/bin/python3.11
# move file to the reddit processing folder
# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error
filename=$(basename "/local_storage/reddit/processing/386-20240422.json")
if ! grep -q "/local_storage/reddit/processing" <<< "/local_storage/reddit/processing/386-20240422.json"; then
    mv /local_storage/reddit/processing/386-20240422.json /local_storage/reddit/processing
else
    echo JSON is already in processing
fi

# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing
echo "#{setValue(raw_file_dir=/local_storage/reddit/processing/${filename})}"
[WI-495][TI-1185] - [INFO] 2024-04-23 11:49:50.766 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-495][TI-1185] - [INFO] 2024-04-23 11:49:50.766 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_84/495/1185/495_1185.sh
[WI-495][TI-1185] - [INFO] 2024-04-23 11:49:50.794 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 5031
[WI-0][TI-0] - [INFO] 2024-04-23 11:49:50.794 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
[WI-0][TI-1185] - [INFO] 2024-04-23 11:49:51.694 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1185, success=true)
[WI-0][TI-1185] - [INFO] 2024-04-23 11:49:51.761 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionInfoEvent(taskInstanceId=1185, processInstanceId=495, startTime=1713844190745, workflowInstanceHost=172.18.0.9:5678, taskInstanceHost=172.18.1.1:1234, logPath=null, processId=0, eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1185] - [INFO] 2024-04-23 11:49:51.775 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionInfoEvent(taskInstanceId=1185, processInstanceId=495, startTime=1713844190745, workflowInstanceHost=172.18.0.9:5678, taskInstanceHost=172.18.1.1:1234, logPath=null, processId=0, eventCreateTime=0, eventSendTime=1713844191760)
[WI-0][TI-1185] - [INFO] 2024-04-23 11:49:51.777 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1185)
[WI-0][TI-1185] - [INFO] 2024-04-23 11:49:51.800 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1185)
[WI-0][TI-0] - [INFO] 2024-04-23 11:49:51.800 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	JSON is already in processing
	#{setValue(raw_file_dir=/local_storage/reddit/processing/386-20240422.json)}
[WI-495][TI-1185] - [INFO] 2024-04-23 11:49:51.802 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_84/495/1185, processId:5031 ,exitStatusCode:0 ,processWaitForStatus:true ,processExitValue:0
[WI-495][TI-1185] - [INFO] 2024-04-23 11:49:51.803 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-495][TI-1185] - [INFO] 2024-04-23 11:49:51.803 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-495][TI-1185] - [INFO] 2024-04-23 11:49:51.803 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-495][TI-1185] - [INFO] 2024-04-23 11:49:51.803 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-495][TI-1185] - [INFO] 2024-04-23 11:49:51.808 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: SUCCESS to master : 172.18.1.1:1234
[WI-495][TI-1185] - [INFO] 2024-04-23 11:49:51.808 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-495][TI-1185] - [INFO] 2024-04-23 11:49:51.808 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_84/495/1185
[WI-495][TI-1185] - [INFO] 2024-04-23 11:49:51.811 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_84/495/1185
[WI-495][TI-1185] - [INFO] 2024-04-23 11:49:51.812 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-1185] - [INFO] 2024-04-23 11:49:51.824 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1185, success=true)
[WI-0][TI-0] - [INFO] 2024-04-23 11:49:52.895 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1186, taskName=spark preprocessing, firstSubmitTime=1713844192887, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.9:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=84, appIds=null, processInstanceId=495, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"processing"}], executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[],"rawScript":"# $SPARK_HOME/bin/spark-submit \\\n#     --master spark://spark-master:7077 \\\n#     --conf spark.driver.cores=2 \\\n#     --conf spark.driver.memory=2G \\\n#     --conf spark.executor.instances=1 \\\n#     --conf spark.executor.cores=2 \\\n#     --conf spark.executor.memory=2G \\\n#     --files ${raw_file_dir} \\\n#     --name reddit_preprocessing spark_reddit_preprocessing.py\n\n$SPARK_HOME/bin/spark-submit \\\n    --master local \\\n    --files ${raw_file_dir} \\\n    --name reddit_preprocessing spark_reddit_preprocessing.py\n","resourceList":[{"id":null,"resourceName":"file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py","res":null}]}, environmentConfig=export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export HADOOP_CONF_DIR=/opt/hadoop-3.4.0/etc/hadoop
export PYSPARK_DRIVER_PYTHON=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='spark preprocessing'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240423'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1186'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13210058002752'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240423114952'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='processing'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='495'}, raw_file_dir=Property{prop='raw_file_dir', direct=IN, type=VARCHAR, value='/local_storage/reddit/processing/386-20240422.json'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240422'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-495][TI-1186] - [INFO] 2024-04-23 11:49:52.899 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: spark preprocessing to wait queue success
[WI-495][TI-1186] - [INFO] 2024-04-23 11:49:52.900 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-495][TI-1186] - [INFO] 2024-04-23 11:49:52.903 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-495][TI-1186] - [INFO] 2024-04-23 11:49:52.903 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-495][TI-1186] - [INFO] 2024-04-23 11:49:52.903 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-495][TI-1186] - [INFO] 2024-04-23 11:49:52.903 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713844192903
[WI-495][TI-1186] - [INFO] 2024-04-23 11:49:52.903 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 495_1186
[WI-495][TI-1186] - [INFO] 2024-04-23 11:49:52.904 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1186,
  "taskName" : "spark preprocessing",
  "firstSubmitTime" : 1713844192887,
  "startTime" : 1713844192903,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.9:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240423/13201021801792/84/495/1186.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 84,
  "processInstanceId" : 495,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"processing\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[],\"rawScript\":\"# $SPARK_HOME/bin/spark-submit \\\\\\n#     --master spark://spark-master:7077 \\\\\\n#     --conf spark.driver.cores=2 \\\\\\n#     --conf spark.driver.memory=2G \\\\\\n#     --conf spark.executor.instances=1 \\\\\\n#     --conf spark.executor.cores=2 \\\\\\n#     --conf spark.executor.memory=2G \\\\\\n#     --files ${raw_file_dir} \\\\\\n#     --name reddit_preprocessing spark_reddit_preprocessing.py\\n\\n$SPARK_HOME/bin/spark-submit \\\\\\n    --master local \\\\\\n    --files ${raw_file_dir} \\\\\\n    --name reddit_preprocessing spark_reddit_preprocessing.py\\n\",\"resourceList\":[{\"id\":null,\"resourceName\":\"file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py\",\"res\":null}]}",
  "environmentConfig" : "export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3\nexport JAVA_HOME=/opt/java/openjdk\nexport HADOOP_CONF_DIR=/opt/hadoop-3.4.0/etc/hadoop\nexport PYSPARK_DRIVER_PYTHON=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "spark preprocessing"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1186"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13210058002752"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423114952"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "processing"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "495"
    },
    "raw_file_dir" : {
      "prop" : "raw_file_dir",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit/processing/386-20240422.json"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240422"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "495_1186",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"raw_file_dir\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"/local_storage/reddit/processing/386-20240422.json\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-495][TI-1186] - [INFO] 2024-04-23 11:49:52.904 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-495][TI-1186] - [INFO] 2024-04-23 11:49:52.905 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-495][TI-1186] - [INFO] 2024-04-23 11:49:52.905 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-495][TI-1186] - [INFO] 2024-04-23 11:49:52.926 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-495][TI-1186] - [INFO] 2024-04-23 11:49:52.927 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-495][TI-1186] - [INFO] 2024-04-23 11:49:52.928 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_84/495/1186 check successfully
[WI-495][TI-1186] - [INFO] 2024-04-23 11:49:52.929 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-495][TI-1186] - [INFO] 2024-04-23 11:49:52.932 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py=ResourceContext.ResourceItem(resourceAbsolutePathInStorage=file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py, resourceRelativePath=spark_reddit_preprocessing.py, resourceAbsolutePathInLocal=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_84/495/1186/spark_reddit_preprocessing.py)})
[WI-495][TI-1186] - [INFO] 2024-04-23 11:49:52.933 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-495][TI-1186] - [INFO] 2024-04-23 11:49:52.933 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-495][TI-1186] - [INFO] 2024-04-23 11:49:52.933 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ ],
  "varPool" : null,
  "rawScript" : "# $SPARK_HOME/bin/spark-submit \\\n#     --master spark://spark-master:7077 \\\n#     --conf spark.driver.cores=2 \\\n#     --conf spark.driver.memory=2G \\\n#     --conf spark.executor.instances=1 \\\n#     --conf spark.executor.cores=2 \\\n#     --conf spark.executor.memory=2G \\\n#     --files ${raw_file_dir} \\\n#     --name reddit_preprocessing spark_reddit_preprocessing.py\n\n$SPARK_HOME/bin/spark-submit \\\n    --master local \\\n    --files ${raw_file_dir} \\\n    --name reddit_preprocessing spark_reddit_preprocessing.py\n",
  "resourceList" : [ {
    "id" : null,
    "resourceName" : "file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py",
    "res" : null
  } ]
}
[WI-495][TI-1186] - [INFO] 2024-04-23 11:49:52.934 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-495][TI-1186] - [INFO] 2024-04-23 11:49:52.941 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}] successfully
[WI-495][TI-1186] - [INFO] 2024-04-23 11:49:52.941 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-495][TI-1186] - [INFO] 2024-04-23 11:49:52.941 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-495][TI-1186] - [INFO] 2024-04-23 11:49:52.941 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-0][TI-0] - [INFO] 2024-04-23 11:49:52.941 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7214484679665738 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-495][TI-1186] - [INFO] 2024-04-23 11:49:52.943 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-495][TI-1186] - [INFO] 2024-04-23 11:49:52.943 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-495][TI-1186] - [INFO] 2024-04-23 11:49:52.943 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export HADOOP_CONF_DIR=/opt/hadoop-3.4.0/etc/hadoop
export PYSPARK_DRIVER_PYTHON=/bin/python3.11
# $SPARK_HOME/bin/spark-submit \
#     --master spark://spark-master:7077 \
#     --conf spark.driver.cores=2 \
#     --conf spark.driver.memory=2G \
#     --conf spark.executor.instances=1 \
#     --conf spark.executor.cores=2 \
#     --conf spark.executor.memory=2G \
#     --files /local_storage/reddit/processing/386-20240422.json \
#     --name reddit_preprocessing spark_reddit_preprocessing.py

$SPARK_HOME/bin/spark-submit \
    --master local \
    --files /local_storage/reddit/processing/386-20240422.json \
    --name reddit_preprocessing spark_reddit_preprocessing.py

[WI-495][TI-1186] - [INFO] 2024-04-23 11:49:52.943 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-495][TI-1186] - [INFO] 2024-04-23 11:49:52.943 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_84/495/1186/495_1186.sh
[WI-495][TI-1186] - [INFO] 2024-04-23 11:49:53.001 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 5043
[WI-0][TI-0] - [INFO] 2024-04-23 11:49:53.002 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
[WI-0][TI-1186] - [INFO] 2024-04-23 11:49:53.648 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1186, success=true)
[WI-0][TI-1186] - [INFO] 2024-04-23 11:49:53.655 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1186)
[WI-0][TI-1123] - [INFO] 2024-04-23 11:49:53.778 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1123, processInstanceId=487, status=9, startTime=1713838208504, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1123.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1123, endTime=1713838483436, processId=1677, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713843892792)
[WI-0][TI-1123] - [INFO] 2024-04-23 11:49:53.786 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1123, processInstanceId=487, status=9, startTime=1713838208504, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1123.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1123, endTime=1713838483436, processId=1677, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713844193778)
[WI-0][TI-0] - [INFO] 2024-04-23 11:49:53.995 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8727272727272728 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:49:54.996 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8562091503267975 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-1111] - [INFO] 2024-04-23 11:49:55.788 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1111, processInstanceId=487, status=9, startTime=1713837256404, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1111.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1111, endTime=1713838170352, processId=1017, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713843894802)
[WI-0][TI-1111] - [INFO] 2024-04-23 11:49:55.792 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1111, processInstanceId=487, status=9, startTime=1713837256404, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1111.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1111, endTime=1713838170352, processId=1017, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713844195788)
[WI-0][TI-0] - [INFO] 2024-04-23 11:49:56.000 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8238482384823849 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:49:57.002 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9390243902439024 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:49:57.023 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:49:56 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[WI-0][TI-0] - [INFO] 2024-04-23 11:49:58.006 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.752136752136752 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:49:58.026 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:49:57 INFO SparkContext: Running Spark version 3.5.1
	24/04/23 11:49:57 INFO SparkContext: OS info Linux, 6.5.0-28-generic, amd64
	24/04/23 11:49:57 INFO SparkContext: Java version 1.8.0_402
	24/04/23 11:49:57 INFO ResourceUtils: ==============================================================
	24/04/23 11:49:57 INFO ResourceUtils: No custom resources configured for spark.driver.
	24/04/23 11:49:57 INFO ResourceUtils: ==============================================================
	24/04/23 11:49:57 INFO SparkContext: Submitted application: reddit_preprocessing
	24/04/23 11:49:57 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
	24/04/23 11:49:57 INFO ResourceProfile: Limiting resource is cpu
	24/04/23 11:49:57 INFO ResourceProfileManager: Added ResourceProfile id: 0
[WI-0][TI-0] - [INFO] 2024-04-23 11:49:59.010 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8981481481481481 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:49:59.027 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:49:58 INFO SecurityManager: Changing view acls to: default
	24/04/23 11:49:58 INFO SecurityManager: Changing modify acls to: default
	24/04/23 11:49:58 INFO SecurityManager: Changing view acls groups to: 
	24/04/23 11:49:58 INFO SecurityManager: Changing modify acls groups to: 
	24/04/23 11:49:58 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: default; groups with view permissions: EMPTY; users with modify permissions: default; groups with modify permissions: EMPTY
	24/04/23 11:49:58 INFO Utils: Successfully started service 'sparkDriver' on port 44863.
[WI-0][TI-0] - [INFO] 2024-04-23 11:50:00.113 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:49:59 INFO SparkEnv: Registering MapOutputTracker
	24/04/23 11:49:59 INFO SparkEnv: Registering BlockManagerMaster
	24/04/23 11:49:59 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
	24/04/23 11:49:59 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
	24/04/23 11:49:59 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
	24/04/23 11:49:59 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-a4f98a01-0caf-4a64-a4bf-b684f3996c55
	24/04/23 11:49:59 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
	24/04/23 11:49:59 INFO SparkEnv: Registering OutputCommitCoordinator
	24/04/23 11:49:59 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
[WI-0][TI-0] - [INFO] 2024-04-23 11:50:00.119 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7971014492753622 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:50:01.119 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:50:00 INFO Utils: Successfully started service 'SparkUI' on port 4040.
	24/04/23 11:50:00 INFO SparkContext: Added file file:///local_storage/reddit/processing/386-20240422.json at file:///local_storage/reddit/processing/386-20240422.json with timestamp 1713844197796
	24/04/23 11:50:00 INFO Utils: Copying /local_storage/reddit/processing/386-20240422.json to /tmp/spark-400d1306-e716-4156-9468-2daeab7d50a2/userFiles-69a1cff2-4377-4211-9086-c08a9b20fb02/386-20240422.json
[WI-0][TI-0] - [INFO] 2024-04-23 11:50:01.121 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9243421052631579 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:50:02.121 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:50:01 INFO Executor: Starting executor ID driver on host c0e814e3f0bd
	24/04/23 11:50:01 INFO Executor: OS info Linux, 6.5.0-28-generic, amd64
	24/04/23 11:50:01 INFO Executor: Java version 1.8.0_402
	24/04/23 11:50:01 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
	24/04/23 11:50:01 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@33c91747 for default.
	24/04/23 11:50:01 INFO Executor: Fetching file:///local_storage/reddit/processing/386-20240422.json with timestamp 1713844197796
	24/04/23 11:50:01 INFO Utils: /local_storage/reddit/processing/386-20240422.json has been previously copied to /tmp/spark-400d1306-e716-4156-9468-2daeab7d50a2/userFiles-69a1cff2-4377-4211-9086-c08a9b20fb02/386-20240422.json
	24/04/23 11:50:01 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43433.
	24/04/23 11:50:01 INFO NettyBlockTransferService: Server created on c0e814e3f0bd:43433
	24/04/23 11:50:01 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
	24/04/23 11:50:01 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, c0e814e3f0bd, 43433, None)
	24/04/23 11:50:01 INFO BlockManagerMasterEndpoint: Registering block manager c0e814e3f0bd:43433 with 366.3 MiB RAM, BlockManagerId(driver, c0e814e3f0bd, 43433, None)
	24/04/23 11:50:01 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, c0e814e3f0bd, 43433, None)
	24/04/23 11:50:01 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, c0e814e3f0bd, 43433, None)
[WI-0][TI-0] - [INFO] 2024-04-23 11:50:02.126 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7374301675977654 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:50:03.125 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	
	
	
	 file:///tmp/spark-400d1306-e716-4156-9468-2daeab7d50a2/userFiles-69a1cff2-4377-4211-9086-c08a9b20fb02/386-20240422.json 
	
	
	
	24/04/23 11:50:02 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
	24/04/23 11:50:02 INFO SharedState: Warehouse path is 'file:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_84/495/1186/spark-warehouse'.
[WI-0][TI-0] - [INFO] 2024-04-23 11:50:05.138 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:50:04 INFO InMemoryFileIndex: It took 83 ms to list leaf files for 1 paths.
	24/04/23 11:50:04 INFO InMemoryFileIndex: It took 3 ms to list leaf files for 1 paths.
[WI-0][TI-0] - [INFO] 2024-04-23 11:50:07.230 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8088235294117647 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:50:08.248 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.869969040247678 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:50:09.236 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:50:09 INFO FileSourceStrategy: Pushed Filters: 
	24/04/23 11:50:09 INFO FileSourceStrategy: Post-Scan Filters: 
[WI-0][TI-0] - [INFO] 2024-04-23 11:50:09.251 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8515406162464986 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:50:10.241 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:50:10 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 350.7 KiB, free 366.0 MiB)
	24/04/23 11:50:10 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 34.4 KiB, free 365.9 MiB)
	24/04/23 11:50:10 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on c0e814e3f0bd:43433 (size: 34.4 KiB, free: 366.3 MiB)
	24/04/23 11:50:10 INFO SparkContext: Created broadcast 0 from json at NativeMethodAccessorImpl.java:0
	24/04/23 11:50:10 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4266164 bytes, open cost is considered as scanning 4194304 bytes.
[WI-0][TI-0] - [INFO] 2024-04-23 11:50:10.258 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.887905604719764 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:50:11.244 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:50:10 INFO SparkContext: Starting job: json at NativeMethodAccessorImpl.java:0
	24/04/23 11:50:10 INFO DAGScheduler: Got job 0 (json at NativeMethodAccessorImpl.java:0) with 1 output partitions
	24/04/23 11:50:10 INFO DAGScheduler: Final stage: ResultStage 0 (json at NativeMethodAccessorImpl.java:0)
	24/04/23 11:50:10 INFO DAGScheduler: Parents of final stage: List()
	24/04/23 11:50:10 INFO DAGScheduler: Missing parents: List()
	24/04/23 11:50:10 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at json at NativeMethodAccessorImpl.java:0), which has no missing parents
	24/04/23 11:50:10 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 16.4 KiB, free 365.9 MiB)
	24/04/23 11:50:10 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.7 KiB, free 365.9 MiB)
	24/04/23 11:50:10 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on c0e814e3f0bd:43433 (size: 7.7 KiB, free: 366.3 MiB)
	24/04/23 11:50:10 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1585
	24/04/23 11:50:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at json at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
	24/04/23 11:50:11 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
	24/04/23 11:50:11 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (c0e814e3f0bd, executor driver, partition 0, PROCESS_LOCAL, 8481 bytes) 
[WI-0][TI-0] - [INFO] 2024-04-23 11:50:11.260 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9382022471910112 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:50:12.250 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:50:11 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
	24/04/23 11:50:12 INFO FileScanRDD: Reading File path: file:///tmp/spark-400d1306-e716-4156-9468-2daeab7d50a2/userFiles-69a1cff2-4377-4211-9086-c08a9b20fb02/386-20240422.json, range: 0-71860, partition values: [empty row]
[WI-0][TI-0] - [INFO] 2024-04-23 11:50:12.268 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9368770764119602 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:50:13.251 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:50:12 INFO CodeGenerator: Code generated in 431.423052 ms
	24/04/23 11:50:12 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1964 bytes result sent to driver
	24/04/23 11:50:12 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1773 ms on c0e814e3f0bd (executor driver) (1/1)
	24/04/23 11:50:12 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
	24/04/23 11:50:12 INFO DAGScheduler: ResultStage 0 (json at NativeMethodAccessorImpl.java:0) finished in 2.205 s
	24/04/23 11:50:12 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
	24/04/23 11:50:12 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
	24/04/23 11:50:12 INFO DAGScheduler: Job 0 finished: json at NativeMethodAccessorImpl.java:0, took 2.427653 s
	
	
	
	 1 
	
	
	
[WI-0][TI-0] - [INFO] 2024-04-23 11:50:13.270 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8637602179836513 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:50:14.253 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	Traceback (most recent call last):
	  File "/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_84/495/1186/spark_reddit_preprocessing.py", line 51, in <module>
	    new_df = raw_df.withColumn("type", split(raw_df["name"], "_")[0]) \
	                                             ~~~~~~^^^^^^^^
	  File "/opt/spark-3.5.1-bin-hadoop3/python/lib/pyspark.zip/pyspark/sql/dataframe.py", line 3078, in __getitem__
	  File "/opt/spark-3.5.1-bin-hadoop3/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
	  File "/opt/spark-3.5.1-bin-hadoop3/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 185, in deco
	pyspark.errors.exceptions.captured.AnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `name` cannot be resolved. Did you mean one of the following? [`_corrupt_record`].
	24/04/23 11:50:13 INFO SparkContext: Invoking stop() from shutdown hook
	24/04/23 11:50:13 INFO SparkContext: SparkContext is stopping with exitCode 0.
	24/04/23 11:50:13 INFO SparkUI: Stopped Spark web UI at http://c0e814e3f0bd:4040
	24/04/23 11:50:13 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
	24/04/23 11:50:13 INFO MemoryStore: MemoryStore cleared
	24/04/23 11:50:13 INFO BlockManager: BlockManager stopped
	24/04/23 11:50:13 INFO BlockManagerMaster: BlockManagerMaster stopped
	24/04/23 11:50:13 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
	24/04/23 11:50:13 INFO SparkContext: Successfully stopped SparkContext
	24/04/23 11:50:13 INFO ShutdownHookManager: Shutdown hook called
	24/04/23 11:50:13 INFO ShutdownHookManager: Deleting directory /tmp/spark-ad36f5ea-3ba7-48b2-8223-81e980ecccaf
	24/04/23 11:50:13 INFO ShutdownHookManager: Deleting directory /tmp/spark-400d1306-e716-4156-9468-2daeab7d50a2
	24/04/23 11:50:13 INFO ShutdownHookManager: Deleting directory /tmp/spark-400d1306-e716-4156-9468-2daeab7d50a2/pyspark-2b34757c-b237-4b48-bad5-20101bcaa348
[WI-495][TI-1186] - [INFO] 2024-04-23 11:50:14.255 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_84/495/1186, processId:5043 ,exitStatusCode:1 ,processWaitForStatus:true ,processExitValue:1
[WI-495][TI-1186] - [INFO] 2024-04-23 11:50:14.255 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-495][TI-1186] - [INFO] 2024-04-23 11:50:14.256 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-495][TI-1186] - [INFO] 2024-04-23 11:50:14.256 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-495][TI-1186] - [INFO] 2024-04-23 11:50:14.256 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-495][TI-1186] - [INFO] 2024-04-23 11:50:14.262 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: FAILURE to master : 172.18.1.1:1234
[WI-495][TI-1186] - [INFO] 2024-04-23 11:50:14.262 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-495][TI-1186] - [INFO] 2024-04-23 11:50:14.262 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_84/495/1186
[WI-495][TI-1186] - [INFO] 2024-04-23 11:50:14.263 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_84/495/1186
[WI-495][TI-1186] - [INFO] 2024-04-23 11:50:14.263 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-0] - [INFO] 2024-04-23 11:50:14.271 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8121546961325966 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-1186] - [INFO] 2024-04-23 11:50:14.740 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1186, success=true)
[WI-0][TI-0] - [INFO] 2024-04-23 11:50:15.273 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7068493150684931 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:50:19.316 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7086575586575586 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:50:20.334 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8022898888820678 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:50:24.348 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8619718309859155 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:50:42.461 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7252747252747253 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:50:43.494 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8487179487179486 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:50:47.509 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8909574468085106 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:50:48.520 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8446866485013624 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:50:49.521 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9259259259259259 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:50:50.524 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.75 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:50:55.568 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7702265372168285 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:51:11.716 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8039772727272727 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:51:13.752 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8933717579250722 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:51:14.770 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8328542555580508 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:51:16.787 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7893175074183976 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:51:17.802 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7218760877131918 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:51:18.807 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7355072463768115 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:52:06.986 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7419354838709677 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-1144] - [INFO] 2024-04-23 11:52:16.253 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1144, processInstanceId=489, status=9, startTime=1713840953087, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/80/489/1144.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1144, endTime=1713841331355, processId=3026, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713844035287)
[WI-0][TI-1144] - [INFO] 2024-04-23 11:52:16.266 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1144, processInstanceId=489, status=9, startTime=1713840953087, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/80/489/1144.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1144, endTime=1713841331355, processId=3026, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713844336253)
[WI-0][TI-0] - [INFO] 2024-04-23 11:52:18.019 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8263305322128852 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:52:29.776 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1187, taskName=search for intake JSON files, firstSubmitTime=1713844349770, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.9:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=84, appIds=null, processInstanceId=495, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"processing"}], executorId=1, cmdTypeIfComplement=7, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":""}],"rawScript":"# find 1 raw file in the folder\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\n\n# check if raw_file_dir is empty, then set raw_file_dir to null\nif [ -z \"$raw_file_dir\" ]; then\n    raw_file_dir=null\nfi\n\necho \"#{setValue(raw_file_dir=${raw_file_dir})}\"","resourceList":[]}, environmentConfig=export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='search for intake JSON files'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240423'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1187'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13340113777664'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240423115229'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='processing'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='495'}, raw_file_dir=Property{prop='raw_file_dir', direct=OUT, type=VARCHAR, value='/local_storage/reddit/processing/386-20240422.json'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240422'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-495][TI-1187] - [INFO] 2024-04-23 11:52:29.778 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: search for intake JSON files to wait queue success
[WI-495][TI-1187] - [INFO] 2024-04-23 11:52:29.779 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-495][TI-1187] - [INFO] 2024-04-23 11:52:29.786 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-495][TI-1187] - [INFO] 2024-04-23 11:52:29.786 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-495][TI-1187] - [INFO] 2024-04-23 11:52:29.786 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-495][TI-1187] - [INFO] 2024-04-23 11:52:29.786 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713844349786
[WI-495][TI-1187] - [INFO] 2024-04-23 11:52:29.786 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 495_1187
[WI-495][TI-1187] - [INFO] 2024-04-23 11:52:29.786 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1187,
  "taskName" : "search for intake JSON files",
  "firstSubmitTime" : 1713844349770,
  "startTime" : 1713844349786,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.9:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240423/13201021801792/84/495/1187.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 84,
  "processInstanceId" : 495,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"processing\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 7,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[{\"prop\":\"raw_file_dir\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"\"}],\"rawScript\":\"# find 1 raw file in the folder\\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\\n\\n# check if raw_file_dir is empty, then set raw_file_dir to null\\nif [ -z \\\"$raw_file_dir\\\" ]; then\\n    raw_file_dir=null\\nfi\\n\\necho \\\"#{setValue(raw_file_dir=${raw_file_dir})}\\\"\",\"resourceList\":[]}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "search for intake JSON files"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1187"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13340113777664"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423115229"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "processing"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "495"
    },
    "raw_file_dir" : {
      "prop" : "raw_file_dir",
      "direct" : "OUT",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit/processing/386-20240422.json"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240422"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "495_1187",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"raw_file_dir\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"/local_storage/reddit/processing/386-20240422.json\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-495][TI-1187] - [INFO] 2024-04-23 11:52:29.789 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-495][TI-1187] - [INFO] 2024-04-23 11:52:29.790 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-495][TI-1187] - [INFO] 2024-04-23 11:52:29.790 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-495][TI-1187] - [INFO] 2024-04-23 11:52:29.815 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-495][TI-1187] - [INFO] 2024-04-23 11:52:29.816 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-495][TI-1187] - [INFO] 2024-04-23 11:52:29.816 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_84/495/1187 check successfully
[WI-495][TI-1187] - [INFO] 2024-04-23 11:52:29.817 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-495][TI-1187] - [INFO] 2024-04-23 11:52:29.818 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-495][TI-1187] - [INFO] 2024-04-23 11:52:29.818 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-495][TI-1187] - [INFO] 2024-04-23 11:52:29.819 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-495][TI-1187] - [INFO] 2024-04-23 11:52:29.819 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ {
    "prop" : "raw_file_dir",
    "direct" : "OUT",
    "type" : "VARCHAR",
    "value" : ""
  } ],
  "varPool" : null,
  "rawScript" : "# find 1 raw file in the folder\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\n\n# check if raw_file_dir is empty, then set raw_file_dir to null\nif [ -z \"$raw_file_dir\" ]; then\n    raw_file_dir=null\nfi\n\necho \"#{setValue(raw_file_dir=${raw_file_dir})}\"",
  "resourceList" : [ ]
}
[WI-495][TI-1187] - [INFO] 2024-04-23 11:52:29.819 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-495][TI-1187] - [INFO] 2024-04-23 11:52:29.820 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}] successfully
[WI-495][TI-1187] - [INFO] 2024-04-23 11:52:29.820 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-495][TI-1187] - [INFO] 2024-04-23 11:52:29.820 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-495][TI-1187] - [INFO] 2024-04-23 11:52:29.820 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-495][TI-1187] - [INFO] 2024-04-23 11:52:29.821 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-495][TI-1187] - [INFO] 2024-04-23 11:52:29.821 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-495][TI-1187] - [INFO] 2024-04-23 11:52:29.821 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export PYTHON_LAUNCHER=/bin/python3.11
# find 1 raw file in the folder
raw_file_dir=$(find /local_storage/reddit/processing -type f -name '*.json'| head -n 1)

# check if raw_file_dir is empty, then set raw_file_dir to null
if [ -z "$raw_file_dir" ]; then
    raw_file_dir=null
fi

echo "#{setValue(raw_file_dir=/local_storage/reddit/processing/386-20240422.json)}"
[WI-495][TI-1187] - [INFO] 2024-04-23 11:52:29.821 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-495][TI-1187] - [INFO] 2024-04-23 11:52:29.821 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_84/495/1187/495_1187.sh
[WI-495][TI-1187] - [INFO] 2024-04-23 11:52:29.846 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 5188
[WI-0][TI-0] - [INFO] 2024-04-23 11:52:29.851 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
[WI-0][TI-1187] - [INFO] 2024-04-23 11:52:30.076 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1187, success=true)
[WI-0][TI-1187] - [INFO] 2024-04-23 11:52:30.091 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1187)
[WI-0][TI-0] - [INFO] 2024-04-23 11:52:30.122 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8254847645429363 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:52:30.871 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	#{setValue(raw_file_dir=/local_storage/reddit/processing/386-20240422.json)}
[WI-495][TI-1187] - [INFO] 2024-04-23 11:52:30.874 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_84/495/1187, processId:5188 ,exitStatusCode:0 ,processWaitForStatus:true ,processExitValue:0
[WI-495][TI-1187] - [INFO] 2024-04-23 11:52:30.874 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-495][TI-1187] - [INFO] 2024-04-23 11:52:30.874 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-495][TI-1187] - [INFO] 2024-04-23 11:52:30.875 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-495][TI-1187] - [INFO] 2024-04-23 11:52:30.875 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-495][TI-1187] - [INFO] 2024-04-23 11:52:30.877 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: SUCCESS to master : 172.18.1.1:1234
[WI-495][TI-1187] - [INFO] 2024-04-23 11:52:30.881 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-495][TI-1187] - [INFO] 2024-04-23 11:52:30.881 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_84/495/1187
[WI-495][TI-1187] - [INFO] 2024-04-23 11:52:30.881 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_84/495/1187
[WI-495][TI-1187] - [INFO] 2024-04-23 11:52:30.882 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-1187] - [INFO] 2024-04-23 11:52:31.045 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1187, success=true)
[WI-0][TI-0] - [INFO] 2024-04-23 11:52:32.073 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1189, taskName=move to processing, firstSubmitTime=1713844352065, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.9:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=84, appIds=null, processInstanceId=495, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"processing"}], executorId=1, cmdTypeIfComplement=7, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":""}],"rawScript":"# move file to the reddit processing folder\n# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error\nfilename=$(basename \"${raw_file_dir}\")\nif ! grep -q \"${REDDIT_HOME}/processing\" <<< \"${raw_file_dir}\"; then\n    mv ${raw_file_dir} ${REDDIT_HOME}/processing\nelse\n    echo JSON is already in processing\nfi\n\n# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing\necho \"#{setValue(raw_file_dir=${REDDIT_HOME}/processing/${filename})}\"","resourceList":[]}, environmentConfig=export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='move to processing'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240423'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1189'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13340390094208'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240423115232'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='processing'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='495'}, raw_file_dir=Property{prop='raw_file_dir', direct=IN, type=VARCHAR, value='/local_storage/reddit/processing/386-20240422.json'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240422'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-495][TI-1189] - [INFO] 2024-04-23 11:52:32.074 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: move to processing to wait queue success
[WI-495][TI-1189] - [INFO] 2024-04-23 11:52:32.075 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-495][TI-1189] - [INFO] 2024-04-23 11:52:32.076 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-495][TI-1189] - [INFO] 2024-04-23 11:52:32.076 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-495][TI-1189] - [INFO] 2024-04-23 11:52:32.077 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-495][TI-1189] - [INFO] 2024-04-23 11:52:32.077 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713844352077
[WI-495][TI-1189] - [INFO] 2024-04-23 11:52:32.077 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 495_1189
[WI-495][TI-1189] - [INFO] 2024-04-23 11:52:32.077 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1189,
  "taskName" : "move to processing",
  "firstSubmitTime" : 1713844352065,
  "startTime" : 1713844352077,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.9:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240423/13201021801792/84/495/1189.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 84,
  "processInstanceId" : 495,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"processing\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 7,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[{\"prop\":\"raw_file_dir\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"\"}],\"rawScript\":\"# move file to the reddit processing folder\\n# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error\\nfilename=$(basename \\\"${raw_file_dir}\\\")\\nif ! grep -q \\\"${REDDIT_HOME}/processing\\\" <<< \\\"${raw_file_dir}\\\"; then\\n    mv ${raw_file_dir} ${REDDIT_HOME}/processing\\nelse\\n    echo JSON is already in processing\\nfi\\n\\n# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing\\necho \\\"#{setValue(raw_file_dir=${REDDIT_HOME}/processing/${filename})}\\\"\",\"resourceList\":[]}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "move to processing"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1189"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13340390094208"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423115232"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "processing"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "495"
    },
    "raw_file_dir" : {
      "prop" : "raw_file_dir",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit/processing/386-20240422.json"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240422"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "495_1189",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"raw_file_dir\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"/local_storage/reddit/processing/386-20240422.json\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-495][TI-1189] - [INFO] 2024-04-23 11:52:32.077 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-495][TI-1189] - [INFO] 2024-04-23 11:52:32.078 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-495][TI-1189] - [INFO] 2024-04-23 11:52:32.078 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-495][TI-1189] - [INFO] 2024-04-23 11:52:32.080 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-495][TI-1189] - [INFO] 2024-04-23 11:52:32.081 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-495][TI-1189] - [INFO] 2024-04-23 11:52:32.081 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_84/495/1189 check successfully
[WI-495][TI-1189] - [INFO] 2024-04-23 11:52:32.082 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-495][TI-1189] - [INFO] 2024-04-23 11:52:32.082 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-495][TI-1189] - [INFO] 2024-04-23 11:52:32.082 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-495][TI-1189] - [INFO] 2024-04-23 11:52:32.083 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-495][TI-1189] - [INFO] 2024-04-23 11:52:32.083 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ {
    "prop" : "raw_file_dir",
    "direct" : "OUT",
    "type" : "VARCHAR",
    "value" : ""
  } ],
  "varPool" : null,
  "rawScript" : "# move file to the reddit processing folder\n# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error\nfilename=$(basename \"${raw_file_dir}\")\nif ! grep -q \"${REDDIT_HOME}/processing\" <<< \"${raw_file_dir}\"; then\n    mv ${raw_file_dir} ${REDDIT_HOME}/processing\nelse\n    echo JSON is already in processing\nfi\n\n# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing\necho \"#{setValue(raw_file_dir=${REDDIT_HOME}/processing/${filename})}\"",
  "resourceList" : [ ]
}
[WI-495][TI-1189] - [INFO] 2024-04-23 11:52:32.084 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-495][TI-1189] - [INFO] 2024-04-23 11:52:32.084 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}] successfully
[WI-495][TI-1189] - [INFO] 2024-04-23 11:52:32.084 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-495][TI-1189] - [INFO] 2024-04-23 11:52:32.084 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-495][TI-1189] - [INFO] 2024-04-23 11:52:32.085 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-495][TI-1189] - [INFO] 2024-04-23 11:52:32.087 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-495][TI-1189] - [INFO] 2024-04-23 11:52:32.087 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-495][TI-1189] - [INFO] 2024-04-23 11:52:32.088 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export PYTHON_LAUNCHER=/bin/python3.11
# move file to the reddit processing folder
# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error
filename=$(basename "/local_storage/reddit/processing/386-20240422.json")
if ! grep -q "/local_storage/reddit/processing" <<< "/local_storage/reddit/processing/386-20240422.json"; then
    mv /local_storage/reddit/processing/386-20240422.json /local_storage/reddit/processing
else
    echo JSON is already in processing
fi

# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing
echo "#{setValue(raw_file_dir=/local_storage/reddit/processing/${filename})}"
[WI-495][TI-1189] - [INFO] 2024-04-23 11:52:32.088 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-495][TI-1189] - [INFO] 2024-04-23 11:52:32.088 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_84/495/1189/495_1189.sh
[WI-495][TI-1189] - [INFO] 2024-04-23 11:52:32.092 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 5202
[WI-0][TI-1189] - [INFO] 2024-04-23 11:52:32.295 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionRunningEvent(taskInstanceId=1189, processInstanceId=495, startTime=1713844352077, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, status=TaskExecutionStatus{code=1, desc='running'}, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/84/495/1189.log, executePath=null, processId=0, appIds=null, eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1189] - [INFO] 2024-04-23 11:52:32.297 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionRunningEvent(taskInstanceId=1189, processInstanceId=495, startTime=1713844352077, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, status=TaskExecutionStatus{code=1, desc='running'}, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/84/495/1189.log, executePath=null, processId=0, appIds=null, eventCreateTime=0, eventSendTime=1713844352294)
[WI-0][TI-1189] - [INFO] 2024-04-23 11:52:32.298 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionInfoEvent(taskInstanceId=1189, processInstanceId=495, startTime=1713844352077, workflowInstanceHost=172.18.0.9:5678, taskInstanceHost=172.18.1.1:1234, logPath=null, processId=0, eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1189] - [INFO] 2024-04-23 11:52:32.300 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionInfoEvent(taskInstanceId=1189, processInstanceId=495, startTime=1713844352077, workflowInstanceHost=172.18.0.9:5678, taskInstanceHost=172.18.1.1:1234, logPath=null, processId=0, eventCreateTime=0, eventSendTime=1713844352294)
[WI-0][TI-1189] - [INFO] 2024-04-23 11:52:33.042 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1189, success=true)
[WI-0][TI-1189] - [INFO] 2024-04-23 11:52:33.047 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1189)
[WI-0][TI-1189] - [INFO] 2024-04-23 11:52:33.054 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1189, success=true)
[WI-0][TI-1189] - [INFO] 2024-04-23 11:52:33.059 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1189)
[WI-0][TI-0] - [INFO] 2024-04-23 11:52:33.093 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
	JSON is already in processing
	#{setValue(raw_file_dir=/local_storage/reddit/processing/386-20240422.json)}
[WI-495][TI-1189] - [INFO] 2024-04-23 11:52:33.097 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_84/495/1189, processId:5202 ,exitStatusCode:0 ,processWaitForStatus:true ,processExitValue:0
[WI-495][TI-1189] - [INFO] 2024-04-23 11:52:33.098 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-495][TI-1189] - [INFO] 2024-04-23 11:52:33.098 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-495][TI-1189] - [INFO] 2024-04-23 11:52:33.098 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-495][TI-1189] - [INFO] 2024-04-23 11:52:33.099 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-495][TI-1189] - [INFO] 2024-04-23 11:52:33.101 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: SUCCESS to master : 172.18.1.1:1234
[WI-495][TI-1189] - [INFO] 2024-04-23 11:52:33.101 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-495][TI-1189] - [INFO] 2024-04-23 11:52:33.101 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_84/495/1189
[WI-495][TI-1189] - [INFO] 2024-04-23 11:52:33.102 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_84/495/1189
[WI-495][TI-1189] - [INFO] 2024-04-23 11:52:33.102 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-1189] - [INFO] 2024-04-23 11:52:33.302 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1189, processInstanceId=495, status=7, startTime=1713844352077, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/84/495/1189.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_84/495/1189, endTime=1713844353098, processId=5202, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1189] - [INFO] 2024-04-23 11:52:33.304 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1189, processInstanceId=495, status=7, startTime=1713844352077, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/84/495/1189.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_84/495/1189, endTime=1713844353098, processId=5202, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713844353302)
[WI-0][TI-1189] - [INFO] 2024-04-23 11:52:34.038 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1189, success=true)
[WI-0][TI-1189] - [INFO] 2024-04-23 11:52:34.042 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1189, success=true)
[WI-0][TI-0] - [INFO] 2024-04-23 11:52:34.101 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1190, taskName=spark preprocessing, firstSubmitTime=1713844354095, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.9:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=84, appIds=null, processInstanceId=495, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"processing"}], executorId=1, cmdTypeIfComplement=7, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[],"rawScript":"# $SPARK_HOME/bin/spark-submit \\\n#     --master spark://spark-master:7077 \\\n#     --conf spark.driver.cores=2 \\\n#     --conf spark.driver.memory=2G \\\n#     --conf spark.executor.instances=1 \\\n#     --conf spark.executor.cores=2 \\\n#     --conf spark.executor.memory=2G \\\n#     --files ${raw_file_dir} \\\n#     --name reddit_preprocessing spark_reddit_preprocessing.py\n\n$SPARK_HOME/bin/spark-submit \\\n    --master local \\\n    --files ${raw_file_dir} \\\n    --name reddit_preprocessing spark_reddit_preprocessing.py\n","resourceList":[{"id":null,"resourceName":"file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py","res":null}]}, environmentConfig=export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export HADOOP_CONF_DIR=/opt/hadoop-3.4.0/etc/hadoop
export PYSPARK_DRIVER_PYTHON=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='spark preprocessing'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240423'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1190'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13210058002752'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240423115234'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='processing'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='495'}, raw_file_dir=Property{prop='raw_file_dir', direct=IN, type=VARCHAR, value='/local_storage/reddit/processing/386-20240422.json'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240422'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-495][TI-1190] - [INFO] 2024-04-23 11:52:34.103 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: spark preprocessing to wait queue success
[WI-495][TI-1190] - [INFO] 2024-04-23 11:52:34.103 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-495][TI-1190] - [INFO] 2024-04-23 11:52:34.105 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-495][TI-1190] - [INFO] 2024-04-23 11:52:34.105 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-495][TI-1190] - [INFO] 2024-04-23 11:52:34.105 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-495][TI-1190] - [INFO] 2024-04-23 11:52:34.105 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713844354105
[WI-495][TI-1190] - [INFO] 2024-04-23 11:52:34.105 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 495_1190
[WI-495][TI-1190] - [INFO] 2024-04-23 11:52:34.106 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1190,
  "taskName" : "spark preprocessing",
  "firstSubmitTime" : 1713844354095,
  "startTime" : 1713844354105,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.9:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240423/13201021801792/84/495/1190.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 84,
  "processInstanceId" : 495,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"processing\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 7,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[],\"rawScript\":\"# $SPARK_HOME/bin/spark-submit \\\\\\n#     --master spark://spark-master:7077 \\\\\\n#     --conf spark.driver.cores=2 \\\\\\n#     --conf spark.driver.memory=2G \\\\\\n#     --conf spark.executor.instances=1 \\\\\\n#     --conf spark.executor.cores=2 \\\\\\n#     --conf spark.executor.memory=2G \\\\\\n#     --files ${raw_file_dir} \\\\\\n#     --name reddit_preprocessing spark_reddit_preprocessing.py\\n\\n$SPARK_HOME/bin/spark-submit \\\\\\n    --master local \\\\\\n    --files ${raw_file_dir} \\\\\\n    --name reddit_preprocessing spark_reddit_preprocessing.py\\n\",\"resourceList\":[{\"id\":null,\"resourceName\":\"file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py\",\"res\":null}]}",
  "environmentConfig" : "export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3\nexport JAVA_HOME=/opt/java/openjdk\nexport HADOOP_CONF_DIR=/opt/hadoop-3.4.0/etc/hadoop\nexport PYSPARK_DRIVER_PYTHON=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "spark preprocessing"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1190"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13210058002752"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423115234"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "processing"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "495"
    },
    "raw_file_dir" : {
      "prop" : "raw_file_dir",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit/processing/386-20240422.json"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240422"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "495_1190",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"raw_file_dir\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"/local_storage/reddit/processing/386-20240422.json\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-495][TI-1190] - [INFO] 2024-04-23 11:52:34.107 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-495][TI-1190] - [INFO] 2024-04-23 11:52:34.107 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-495][TI-1190] - [INFO] 2024-04-23 11:52:34.107 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-495][TI-1190] - [INFO] 2024-04-23 11:52:34.109 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-495][TI-1190] - [INFO] 2024-04-23 11:52:34.109 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-495][TI-1190] - [INFO] 2024-04-23 11:52:34.110 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_84/495/1190 check successfully
[WI-495][TI-1190] - [INFO] 2024-04-23 11:52:34.110 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-495][TI-1190] - [INFO] 2024-04-23 11:52:34.112 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py=ResourceContext.ResourceItem(resourceAbsolutePathInStorage=file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py, resourceRelativePath=spark_reddit_preprocessing.py, resourceAbsolutePathInLocal=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_84/495/1190/spark_reddit_preprocessing.py)})
[WI-495][TI-1190] - [INFO] 2024-04-23 11:52:34.113 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-495][TI-1190] - [INFO] 2024-04-23 11:52:34.113 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-495][TI-1190] - [INFO] 2024-04-23 11:52:34.113 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ ],
  "varPool" : null,
  "rawScript" : "# $SPARK_HOME/bin/spark-submit \\\n#     --master spark://spark-master:7077 \\\n#     --conf spark.driver.cores=2 \\\n#     --conf spark.driver.memory=2G \\\n#     --conf spark.executor.instances=1 \\\n#     --conf spark.executor.cores=2 \\\n#     --conf spark.executor.memory=2G \\\n#     --files ${raw_file_dir} \\\n#     --name reddit_preprocessing spark_reddit_preprocessing.py\n\n$SPARK_HOME/bin/spark-submit \\\n    --master local \\\n    --files ${raw_file_dir} \\\n    --name reddit_preprocessing spark_reddit_preprocessing.py\n",
  "resourceList" : [ {
    "id" : null,
    "resourceName" : "file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py",
    "res" : null
  } ]
}
[WI-495][TI-1190] - [INFO] 2024-04-23 11:52:34.114 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-495][TI-1190] - [INFO] 2024-04-23 11:52:34.114 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}] successfully
[WI-495][TI-1190] - [INFO] 2024-04-23 11:52:34.114 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-495][TI-1190] - [INFO] 2024-04-23 11:52:34.114 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-495][TI-1190] - [INFO] 2024-04-23 11:52:34.114 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-495][TI-1190] - [INFO] 2024-04-23 11:52:34.115 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-495][TI-1190] - [INFO] 2024-04-23 11:52:34.115 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-495][TI-1190] - [INFO] 2024-04-23 11:52:34.115 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export HADOOP_CONF_DIR=/opt/hadoop-3.4.0/etc/hadoop
export PYSPARK_DRIVER_PYTHON=/bin/python3.11
# $SPARK_HOME/bin/spark-submit \
#     --master spark://spark-master:7077 \
#     --conf spark.driver.cores=2 \
#     --conf spark.driver.memory=2G \
#     --conf spark.executor.instances=1 \
#     --conf spark.executor.cores=2 \
#     --conf spark.executor.memory=2G \
#     --files /local_storage/reddit/processing/386-20240422.json \
#     --name reddit_preprocessing spark_reddit_preprocessing.py

$SPARK_HOME/bin/spark-submit \
    --master local \
    --files /local_storage/reddit/processing/386-20240422.json \
    --name reddit_preprocessing spark_reddit_preprocessing.py

[WI-495][TI-1190] - [INFO] 2024-04-23 11:52:34.116 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-495][TI-1190] - [INFO] 2024-04-23 11:52:34.116 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_84/495/1190/495_1190.sh
[WI-495][TI-1190] - [INFO] 2024-04-23 11:52:34.120 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 5214
[WI-0][TI-1190] - [INFO] 2024-04-23 11:52:34.305 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionRunningEvent(taskInstanceId=1190, processInstanceId=495, startTime=1713844354105, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, status=TaskExecutionStatus{code=1, desc='running'}, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/84/495/1190.log, executePath=null, processId=0, appIds=null, eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1190] - [INFO] 2024-04-23 11:52:34.307 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionRunningEvent(taskInstanceId=1190, processInstanceId=495, startTime=1713844354105, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, status=TaskExecutionStatus{code=1, desc='running'}, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/84/495/1190.log, executePath=null, processId=0, appIds=null, eventCreateTime=0, eventSendTime=1713844354305)
[WI-0][TI-1190] - [INFO] 2024-04-23 11:52:34.307 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionInfoEvent(taskInstanceId=1190, processInstanceId=495, startTime=1713844354105, workflowInstanceHost=172.18.0.9:5678, taskInstanceHost=172.18.1.1:1234, logPath=null, processId=0, eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1190] - [INFO] 2024-04-23 11:52:34.308 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionInfoEvent(taskInstanceId=1190, processInstanceId=495, startTime=1713844354105, workflowInstanceHost=172.18.0.9:5678, taskInstanceHost=172.18.1.1:1234, logPath=null, processId=0, eventCreateTime=0, eventSendTime=1713844354305)
[WI-0][TI-1190] - [INFO] 2024-04-23 11:52:35.040 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1190, success=true)
[WI-0][TI-1190] - [INFO] 2024-04-23 11:52:35.047 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1190)
[WI-0][TI-1190] - [INFO] 2024-04-23 11:52:35.052 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1190, success=true)
[WI-0][TI-1190] - [INFO] 2024-04-23 11:52:35.056 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1190)
[WI-0][TI-0] - [INFO] 2024-04-23 11:52:35.121 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
[WI-0][TI-0] - [INFO] 2024-04-23 11:52:36.124 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:52:36 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[WI-0][TI-0] - [INFO] 2024-04-23 11:52:37.127 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:52:36 INFO SparkContext: Running Spark version 3.5.1
	24/04/23 11:52:36 INFO SparkContext: OS info Linux, 6.5.0-28-generic, amd64
	24/04/23 11:52:36 INFO SparkContext: Java version 1.8.0_402
	24/04/23 11:52:36 INFO ResourceUtils: ==============================================================
	24/04/23 11:52:36 INFO ResourceUtils: No custom resources configured for spark.driver.
	24/04/23 11:52:36 INFO ResourceUtils: ==============================================================
	24/04/23 11:52:36 INFO SparkContext: Submitted application: reddit_preprocessing
	24/04/23 11:52:36 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
	24/04/23 11:52:36 INFO ResourceProfile: Limiting resource is cpu
	24/04/23 11:52:36 INFO ResourceProfileManager: Added ResourceProfile id: 0
	24/04/23 11:52:36 INFO SecurityManager: Changing view acls to: default
	24/04/23 11:52:36 INFO SecurityManager: Changing modify acls to: default
	24/04/23 11:52:36 INFO SecurityManager: Changing view acls groups to: 
	24/04/23 11:52:36 INFO SecurityManager: Changing modify acls groups to: 
	24/04/23 11:52:36 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: default; groups with view permissions: EMPTY; users with modify permissions: default; groups with modify permissions: EMPTY
[WI-0][TI-0] - [INFO] 2024-04-23 11:52:38.129 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:52:37 INFO Utils: Successfully started service 'sparkDriver' on port 45469.
	24/04/23 11:52:37 INFO SparkEnv: Registering MapOutputTracker
	24/04/23 11:52:37 INFO SparkEnv: Registering BlockManagerMaster
	24/04/23 11:52:37 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
	24/04/23 11:52:37 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
	24/04/23 11:52:37 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
	24/04/23 11:52:37 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-07baafc4-6bae-4585-9b3b-e06adb19acc3
	24/04/23 11:52:37 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
	24/04/23 11:52:38 INFO SparkEnv: Registering OutputCommitCoordinator
[WI-0][TI-0] - [INFO] 2024-04-23 11:52:38.179 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.853658536585366 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:52:39.131 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:52:38 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
	24/04/23 11:52:38 INFO Utils: Successfully started service 'SparkUI' on port 4040.
	24/04/23 11:52:38 INFO SparkContext: Added file file:///local_storage/reddit/processing/386-20240422.json at file:///local_storage/reddit/processing/386-20240422.json with timestamp 1713844356774
	24/04/23 11:52:38 INFO Utils: Copying /local_storage/reddit/processing/386-20240422.json to /tmp/spark-726d7c29-4863-4b71-b138-a750f2f70a4d/userFiles-30858fdb-fae1-4d29-bc61-3ea1cd3ebcc0/386-20240422.json
	24/04/23 11:52:38 INFO Executor: Starting executor ID driver on host c0e814e3f0bd
	24/04/23 11:52:38 INFO Executor: OS info Linux, 6.5.0-28-generic, amd64
	24/04/23 11:52:39 INFO Executor: Java version 1.8.0_402
	24/04/23 11:52:39 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
	24/04/23 11:52:39 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@3fd2ac2b for default.
	24/04/23 11:52:39 INFO Executor: Fetching file:///local_storage/reddit/processing/386-20240422.json with timestamp 1713844356774
	24/04/23 11:52:39 INFO Utils: /local_storage/reddit/processing/386-20240422.json has been previously copied to /tmp/spark-726d7c29-4863-4b71-b138-a750f2f70a4d/userFiles-30858fdb-fae1-4d29-bc61-3ea1cd3ebcc0/386-20240422.json
[WI-0][TI-0] - [INFO] 2024-04-23 11:52:39.202 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8920454545454545 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:52:40.133 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:52:39 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43967.
	24/04/23 11:52:39 INFO NettyBlockTransferService: Server created on c0e814e3f0bd:43967
	24/04/23 11:52:39 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
	24/04/23 11:52:39 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, c0e814e3f0bd, 43967, None)
	24/04/23 11:52:39 INFO BlockManagerMasterEndpoint: Registering block manager c0e814e3f0bd:43967 with 366.3 MiB RAM, BlockManagerId(driver, c0e814e3f0bd, 43967, None)
	24/04/23 11:52:39 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, c0e814e3f0bd, 43967, None)
	24/04/23 11:52:39 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, c0e814e3f0bd, 43967, None)
[WI-0][TI-0] - [INFO] 2024-04-23 11:52:40.204 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7028571428571428 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:52:41.135 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	
	
	
	 /tmp/spark-726d7c29-4863-4b71-b138-a750f2f70a4d/userFiles-30858fdb-fae1-4d29-bc61-3ea1cd3ebcc0/386-20240422.json 
	
	
	
	24/04/23 11:52:40 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
	24/04/23 11:52:40 INFO SharedState: Warehouse path is 'file:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_84/495/1190/spark-warehouse'.
[WI-0][TI-0] - [INFO] 2024-04-23 11:52:43.138 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:52:42 INFO InMemoryFileIndex: It took 47 ms to list leaf files for 1 paths.
	24/04/23 11:52:42 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
[WI-0][TI-0] - [INFO] 2024-04-23 11:52:46.165 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:52:45 INFO FileSourceStrategy: Pushed Filters: 
	24/04/23 11:52:45 INFO FileSourceStrategy: Post-Scan Filters: 
[WI-0][TI-0] - [INFO] 2024-04-23 11:52:46.252 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8478260869565217 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:52:47.166 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:52:46 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 350.7 KiB, free 366.0 MiB)
	24/04/23 11:52:46 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 34.4 KiB, free 365.9 MiB)
	24/04/23 11:52:46 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on c0e814e3f0bd:43967 (size: 34.4 KiB, free: 366.3 MiB)
	24/04/23 11:52:46 INFO SparkContext: Created broadcast 0 from json at NativeMethodAccessorImpl.java:0
	24/04/23 11:52:46 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4266164 bytes, open cost is considered as scanning 4194304 bytes.
	24/04/23 11:52:46 INFO SparkContext: Starting job: json at NativeMethodAccessorImpl.java:0
	24/04/23 11:52:46 INFO DAGScheduler: Got job 0 (json at NativeMethodAccessorImpl.java:0) with 1 output partitions
	24/04/23 11:52:46 INFO DAGScheduler: Final stage: ResultStage 0 (json at NativeMethodAccessorImpl.java:0)
	24/04/23 11:52:46 INFO DAGScheduler: Parents of final stage: List()
	24/04/23 11:52:46 INFO DAGScheduler: Missing parents: List()
	24/04/23 11:52:46 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at json at NativeMethodAccessorImpl.java:0), which has no missing parents
	24/04/23 11:52:47 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 16.4 KiB, free 365.9 MiB)
	24/04/23 11:52:47 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.7 KiB, free 365.9 MiB)
	24/04/23 11:52:47 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on c0e814e3f0bd:43967 (size: 7.7 KiB, free: 366.3 MiB)
	24/04/23 11:52:47 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1585
	24/04/23 11:52:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at json at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
	24/04/23 11:52:47 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
[WI-0][TI-0] - [INFO] 2024-04-23 11:52:47.311 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7178683385579937 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:52:48.168 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:52:47 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (c0e814e3f0bd, executor driver, partition 0, PROCESS_LOCAL, 8481 bytes) 
	24/04/23 11:52:47 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
	24/04/23 11:52:47 INFO FileScanRDD: Reading File path: file:///tmp/spark-726d7c29-4863-4b71-b138-a750f2f70a4d/userFiles-30858fdb-fae1-4d29-bc61-3ea1cd3ebcc0/386-20240422.json, range: 0-71860, partition values: [empty row]
[WI-0][TI-0] - [INFO] 2024-04-23 11:52:48.315 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7088607594936709 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:52:49.170 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:52:48 INFO CodeGenerator: Code generated in 382.496429 ms
	24/04/23 11:52:48 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1964 bytes result sent to driver
	24/04/23 11:52:48 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1281 ms on c0e814e3f0bd (executor driver) (1/1)
	24/04/23 11:52:48 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
	24/04/23 11:52:48 INFO DAGScheduler: ResultStage 0 (json at NativeMethodAccessorImpl.java:0) finished in 1.524 s
	24/04/23 11:52:48 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
	24/04/23 11:52:48 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
	24/04/23 11:52:48 INFO DAGScheduler: Job 0 finished: json at NativeMethodAccessorImpl.java:0, took 1.622388 s
	
	
	
	 1 
	
	
	
	Traceback (most recent call last):
	  File "/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_84/495/1190/spark_reddit_preprocessing.py", line 51, in <module>
	    new_df = raw_df.withColumn("type", split(raw_df["name"], "_")[0]) \
	                                             ~~~~~~^^^^^^^^
	  File "/opt/spark-3.5.1-bin-hadoop3/python/lib/pyspark.zip/pyspark/sql/dataframe.py", line 3078, in __getitem__
	  File "/opt/spark-3.5.1-bin-hadoop3/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
	  File "/opt/spark-3.5.1-bin-hadoop3/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 185, in deco
	pyspark.errors.exceptions.captured.AnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `name` cannot be resolved. Did you mean one of the following? [`_corrupt_record`].
	24/04/23 11:52:48 INFO SparkContext: Invoking stop() from shutdown hook
	24/04/23 11:52:48 INFO SparkContext: SparkContext is stopping with exitCode 0.
	24/04/23 11:52:48 INFO SparkUI: Stopped Spark web UI at http://c0e814e3f0bd:4040
	24/04/23 11:52:48 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
	24/04/23 11:52:48 INFO MemoryStore: MemoryStore cleared
	24/04/23 11:52:48 INFO BlockManager: BlockManager stopped
	24/04/23 11:52:48 INFO BlockManagerMaster: BlockManagerMaster stopped
	24/04/23 11:52:48 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
	24/04/23 11:52:48 INFO SparkContext: Successfully stopped SparkContext
	24/04/23 11:52:48 INFO ShutdownHookManager: Shutdown hook called
	24/04/23 11:52:48 INFO ShutdownHookManager: Deleting directory /tmp/spark-726d7c29-4863-4b71-b138-a750f2f70a4d
	24/04/23 11:52:48 INFO ShutdownHookManager: Deleting directory /tmp/spark-6b4cfb90-f0fb-4573-8273-d002bfc6cb69
	24/04/23 11:52:48 INFO ShutdownHookManager: Deleting directory /tmp/spark-726d7c29-4863-4b71-b138-a750f2f70a4d/pyspark-9fb4d9b5-7b64-4be1-95ac-53f0aa2bd076
[WI-495][TI-1190] - [INFO] 2024-04-23 11:52:49.172 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_84/495/1190, processId:5214 ,exitStatusCode:1 ,processWaitForStatus:true ,processExitValue:1
[WI-495][TI-1190] - [INFO] 2024-04-23 11:52:49.173 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-495][TI-1190] - [INFO] 2024-04-23 11:52:49.173 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-495][TI-1190] - [INFO] 2024-04-23 11:52:49.173 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-495][TI-1190] - [INFO] 2024-04-23 11:52:49.173 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-495][TI-1190] - [INFO] 2024-04-23 11:52:49.176 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: FAILURE to master : 172.18.1.1:1234
[WI-495][TI-1190] - [INFO] 2024-04-23 11:52:49.177 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-495][TI-1190] - [INFO] 2024-04-23 11:52:49.177 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_84/495/1190
[WI-495][TI-1190] - [INFO] 2024-04-23 11:52:49.179 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_84/495/1190
[WI-495][TI-1190] - [INFO] 2024-04-23 11:52:49.179 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-1190] - [INFO] 2024-04-23 11:52:49.666 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1190, processInstanceId=495, status=6, startTime=1713844354105, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/84/495/1190.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_84/495/1190, endTime=1713844369173, processId=5214, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1190] - [INFO] 2024-04-23 11:52:49.669 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1190, processInstanceId=495, status=6, startTime=1713844354105, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/84/495/1190.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_84/495/1190, endTime=1713844369173, processId=5214, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713844369665)
[WI-0][TI-1190] - [INFO] 2024-04-23 11:52:50.104 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1190, success=true)
[WI-0][TI-1190] - [INFO] 2024-04-23 11:52:50.107 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1190, success=true)
[WI-0][TI-0] - [INFO] 2024-04-23 11:52:57.340 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7162162162162162 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:53:22.442 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7815126050420168 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:53:28.506 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.853448275862069 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:53:43.555 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7130434782608696 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-1123] - [INFO] 2024-04-23 11:54:54.407 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1123, processInstanceId=487, status=9, startTime=1713838208504, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1123.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1123, endTime=1713838483436, processId=1677, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713844193778)
[WI-0][TI-1123] - [INFO] 2024-04-23 11:54:54.412 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1123, processInstanceId=487, status=9, startTime=1713838208504, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1123.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1123, endTime=1713838483436, processId=1677, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713844494407)
[WI-0][TI-1111] - [INFO] 2024-04-23 11:54:56.421 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1111, processInstanceId=487, status=9, startTime=1713837256404, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1111.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1111, endTime=1713838170352, processId=1017, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713844195788)
[WI-0][TI-1111] - [INFO] 2024-04-23 11:54:56.425 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1111, processInstanceId=487, status=9, startTime=1713837256404, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1111.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1111, endTime=1713838170352, processId=1017, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713844496421)
[WI-0][TI-0] - [INFO] 2024-04-23 11:56:51.858 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1191, taskName=search for intake JSON files, firstSubmitTime=1713844611851, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.9:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=84, appIds=null, processInstanceId=495, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"processing"}], executorId=1, cmdTypeIfComplement=7, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":""}],"rawScript":"# find 1 raw file in the folder\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\n\n# check if raw_file_dir is empty, then set raw_file_dir to null\nif [ -z \"$raw_file_dir\" ]; then\n    raw_file_dir=null\nfi\n\necho \"#{setValue(raw_file_dir=${raw_file_dir})}\"","resourceList":[]}, environmentConfig=export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='search for intake JSON files'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240423'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1191'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13340113777664'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240423115651'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='processing'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='495'}, raw_file_dir=Property{prop='raw_file_dir', direct=OUT, type=VARCHAR, value='/local_storage/reddit/processing/386-20240422.json'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240422'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-495][TI-1191] - [INFO] 2024-04-23 11:56:51.860 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: search for intake JSON files to wait queue success
[WI-495][TI-1191] - [INFO] 2024-04-23 11:56:51.860 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-495][TI-1191] - [INFO] 2024-04-23 11:56:51.864 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-495][TI-1191] - [INFO] 2024-04-23 11:56:51.864 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-495][TI-1191] - [INFO] 2024-04-23 11:56:51.865 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-495][TI-1191] - [INFO] 2024-04-23 11:56:51.865 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713844611865
[WI-495][TI-1191] - [INFO] 2024-04-23 11:56:51.865 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 495_1191
[WI-495][TI-1191] - [INFO] 2024-04-23 11:56:51.866 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1191,
  "taskName" : "search for intake JSON files",
  "firstSubmitTime" : 1713844611851,
  "startTime" : 1713844611865,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.9:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240423/13201021801792/84/495/1191.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 84,
  "processInstanceId" : 495,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"processing\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 7,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[{\"prop\":\"raw_file_dir\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"\"}],\"rawScript\":\"# find 1 raw file in the folder\\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\\n\\n# check if raw_file_dir is empty, then set raw_file_dir to null\\nif [ -z \\\"$raw_file_dir\\\" ]; then\\n    raw_file_dir=null\\nfi\\n\\necho \\\"#{setValue(raw_file_dir=${raw_file_dir})}\\\"\",\"resourceList\":[]}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "search for intake JSON files"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1191"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13340113777664"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423115651"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "processing"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "495"
    },
    "raw_file_dir" : {
      "prop" : "raw_file_dir",
      "direct" : "OUT",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit/processing/386-20240422.json"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240422"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "495_1191",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"raw_file_dir\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"/local_storage/reddit/processing/386-20240422.json\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-495][TI-1191] - [INFO] 2024-04-23 11:56:51.867 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-495][TI-1191] - [INFO] 2024-04-23 11:56:51.867 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-495][TI-1191] - [INFO] 2024-04-23 11:56:51.868 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-495][TI-1191] - [INFO] 2024-04-23 11:56:51.880 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-495][TI-1191] - [INFO] 2024-04-23 11:56:51.881 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-495][TI-1191] - [INFO] 2024-04-23 11:56:51.884 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_84/495/1191 check successfully
[WI-495][TI-1191] - [INFO] 2024-04-23 11:56:51.884 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-495][TI-1191] - [INFO] 2024-04-23 11:56:51.884 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-495][TI-1191] - [INFO] 2024-04-23 11:56:51.885 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-495][TI-1191] - [INFO] 2024-04-23 11:56:51.885 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-495][TI-1191] - [INFO] 2024-04-23 11:56:51.885 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ {
    "prop" : "raw_file_dir",
    "direct" : "OUT",
    "type" : "VARCHAR",
    "value" : ""
  } ],
  "varPool" : null,
  "rawScript" : "# find 1 raw file in the folder\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\n\n# check if raw_file_dir is empty, then set raw_file_dir to null\nif [ -z \"$raw_file_dir\" ]; then\n    raw_file_dir=null\nfi\n\necho \"#{setValue(raw_file_dir=${raw_file_dir})}\"",
  "resourceList" : [ ]
}
[WI-495][TI-1191] - [INFO] 2024-04-23 11:56:51.885 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-495][TI-1191] - [INFO] 2024-04-23 11:56:51.886 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}] successfully
[WI-495][TI-1191] - [INFO] 2024-04-23 11:56:51.886 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-495][TI-1191] - [INFO] 2024-04-23 11:56:51.886 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-495][TI-1191] - [INFO] 2024-04-23 11:56:51.886 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-495][TI-1191] - [INFO] 2024-04-23 11:56:51.887 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-495][TI-1191] - [INFO] 2024-04-23 11:56:51.887 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-495][TI-1191] - [INFO] 2024-04-23 11:56:51.887 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export PYTHON_LAUNCHER=/bin/python3.11
# find 1 raw file in the folder
raw_file_dir=$(find /local_storage/reddit/processing -type f -name '*.json'| head -n 1)

# check if raw_file_dir is empty, then set raw_file_dir to null
if [ -z "$raw_file_dir" ]; then
    raw_file_dir=null
fi

echo "#{setValue(raw_file_dir=/local_storage/reddit/processing/386-20240422.json)}"
[WI-495][TI-1191] - [INFO] 2024-04-23 11:56:51.887 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-495][TI-1191] - [INFO] 2024-04-23 11:56:51.887 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_84/495/1191/495_1191.sh
[WI-495][TI-1191] - [INFO] 2024-04-23 11:56:51.923 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 5378
[WI-0][TI-0] - [INFO] 2024-04-23 11:56:51.924 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
[WI-0][TI-1191] - [INFO] 2024-04-23 11:56:52.673 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionRunningEvent(taskInstanceId=1191, processInstanceId=495, startTime=1713844611865, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, status=TaskExecutionStatus{code=1, desc='running'}, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/84/495/1191.log, executePath=null, processId=0, appIds=null, eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1191] - [INFO] 2024-04-23 11:56:52.676 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionRunningEvent(taskInstanceId=1191, processInstanceId=495, startTime=1713844611865, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, status=TaskExecutionStatus{code=1, desc='running'}, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/84/495/1191.log, executePath=null, processId=0, appIds=null, eventCreateTime=0, eventSendTime=1713844612672)
[WI-0][TI-1191] - [INFO] 2024-04-23 11:56:52.676 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionInfoEvent(taskInstanceId=1191, processInstanceId=495, startTime=1713844611865, workflowInstanceHost=172.18.0.9:5678, taskInstanceHost=172.18.1.1:1234, logPath=null, processId=0, eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1191] - [INFO] 2024-04-23 11:56:52.677 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1191, success=true)
[WI-0][TI-1191] - [INFO] 2024-04-23 11:56:52.678 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionInfoEvent(taskInstanceId=1191, processInstanceId=495, startTime=1713844611865, workflowInstanceHost=172.18.0.9:5678, taskInstanceHost=172.18.1.1:1234, logPath=null, processId=0, eventCreateTime=0, eventSendTime=1713844612672)
[WI-0][TI-1191] - [WARN] 2024-04-23 11:56:52.679 +0800 o.a.d.s.w.m.MessageRetryRunner:[139] - Retry send message to master error
java.util.ConcurrentModificationException: null
	at java.util.ArrayList$Itr.checkForComodification(ArrayList.java:911)
	at java.util.ArrayList$Itr.next(ArrayList.java:861)
	at org.apache.dolphinscheduler.server.worker.message.MessageRetryRunner.run(MessageRetryRunner.java:127)
[WI-0][TI-1191] - [INFO] 2024-04-23 11:56:52.680 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1191)
[WI-0][TI-1191] - [INFO] 2024-04-23 11:56:52.686 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1191, success=true)
[WI-0][TI-1191] - [INFO] 2024-04-23 11:56:52.692 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1191)
[WI-0][TI-0] - [INFO] 2024-04-23 11:56:52.934 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	#{setValue(raw_file_dir=/local_storage/reddit/processing/386-20240422.json)}
[WI-495][TI-1191] - [INFO] 2024-04-23 11:56:52.936 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_84/495/1191, processId:5378 ,exitStatusCode:0 ,processWaitForStatus:true ,processExitValue:0
[WI-495][TI-1191] - [INFO] 2024-04-23 11:56:52.937 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-495][TI-1191] - [INFO] 2024-04-23 11:56:52.938 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-495][TI-1191] - [INFO] 2024-04-23 11:56:52.938 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-495][TI-1191] - [INFO] 2024-04-23 11:56:52.938 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-495][TI-1191] - [INFO] 2024-04-23 11:56:52.940 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: SUCCESS to master : 172.18.1.1:1234
[WI-495][TI-1191] - [INFO] 2024-04-23 11:56:52.940 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-495][TI-1191] - [INFO] 2024-04-23 11:56:52.940 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_84/495/1191
[WI-495][TI-1191] - [INFO] 2024-04-23 11:56:52.941 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_84/495/1191
[WI-495][TI-1191] - [INFO] 2024-04-23 11:56:52.941 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-1191] - [INFO] 2024-04-23 11:56:53.672 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1191, success=true)
[WI-0][TI-0] - [INFO] 2024-04-23 11:56:54.806 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1193, taskName=move to processing, firstSubmitTime=1713844614800, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.9:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=84, appIds=null, processInstanceId=495, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"processing"}], executorId=1, cmdTypeIfComplement=7, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":""}],"rawScript":"# move file to the reddit processing folder\n# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error\nfilename=$(basename \"${raw_file_dir}\")\nif ! grep -q \"${REDDIT_HOME}/processing\" <<< \"${raw_file_dir}\"; then\n    mv ${raw_file_dir} ${REDDIT_HOME}/processing\nelse\n    echo JSON is already in processing\nfi\n\n# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing\necho \"#{setValue(raw_file_dir=${REDDIT_HOME}/processing/${filename})}\"","resourceList":[]}, environmentConfig=export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='move to processing'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240423'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1193'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13340390094208'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240423115654'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='processing'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='495'}, raw_file_dir=Property{prop='raw_file_dir', direct=IN, type=VARCHAR, value='/local_storage/reddit/processing/386-20240422.json'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240422'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-495][TI-1193] - [INFO] 2024-04-23 11:56:54.808 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: move to processing to wait queue success
[WI-495][TI-1193] - [INFO] 2024-04-23 11:56:54.808 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-495][TI-1193] - [INFO] 2024-04-23 11:56:54.809 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-495][TI-1193] - [INFO] 2024-04-23 11:56:54.809 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-495][TI-1193] - [INFO] 2024-04-23 11:56:54.809 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-495][TI-1193] - [INFO] 2024-04-23 11:56:54.809 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713844614809
[WI-495][TI-1193] - [INFO] 2024-04-23 11:56:54.810 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 495_1193
[WI-495][TI-1193] - [INFO] 2024-04-23 11:56:54.810 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1193,
  "taskName" : "move to processing",
  "firstSubmitTime" : 1713844614800,
  "startTime" : 1713844614809,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.9:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240423/13201021801792/84/495/1193.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 84,
  "processInstanceId" : 495,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"processing\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 7,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[{\"prop\":\"raw_file_dir\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"\"}],\"rawScript\":\"# move file to the reddit processing folder\\n# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error\\nfilename=$(basename \\\"${raw_file_dir}\\\")\\nif ! grep -q \\\"${REDDIT_HOME}/processing\\\" <<< \\\"${raw_file_dir}\\\"; then\\n    mv ${raw_file_dir} ${REDDIT_HOME}/processing\\nelse\\n    echo JSON is already in processing\\nfi\\n\\n# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing\\necho \\\"#{setValue(raw_file_dir=${REDDIT_HOME}/processing/${filename})}\\\"\",\"resourceList\":[]}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "move to processing"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1193"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13340390094208"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423115654"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "processing"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "495"
    },
    "raw_file_dir" : {
      "prop" : "raw_file_dir",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit/processing/386-20240422.json"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240422"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "495_1193",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"raw_file_dir\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"/local_storage/reddit/processing/386-20240422.json\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-495][TI-1193] - [INFO] 2024-04-23 11:56:54.811 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-495][TI-1193] - [INFO] 2024-04-23 11:56:54.811 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-495][TI-1193] - [INFO] 2024-04-23 11:56:54.811 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-495][TI-1193] - [INFO] 2024-04-23 11:56:54.815 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-495][TI-1193] - [INFO] 2024-04-23 11:56:54.816 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-495][TI-1193] - [INFO] 2024-04-23 11:56:54.816 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_84/495/1193 check successfully
[WI-495][TI-1193] - [INFO] 2024-04-23 11:56:54.816 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-495][TI-1193] - [INFO] 2024-04-23 11:56:54.817 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-495][TI-1193] - [INFO] 2024-04-23 11:56:54.817 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-495][TI-1193] - [INFO] 2024-04-23 11:56:54.817 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-495][TI-1193] - [INFO] 2024-04-23 11:56:54.817 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ {
    "prop" : "raw_file_dir",
    "direct" : "OUT",
    "type" : "VARCHAR",
    "value" : ""
  } ],
  "varPool" : null,
  "rawScript" : "# move file to the reddit processing folder\n# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error\nfilename=$(basename \"${raw_file_dir}\")\nif ! grep -q \"${REDDIT_HOME}/processing\" <<< \"${raw_file_dir}\"; then\n    mv ${raw_file_dir} ${REDDIT_HOME}/processing\nelse\n    echo JSON is already in processing\nfi\n\n# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing\necho \"#{setValue(raw_file_dir=${REDDIT_HOME}/processing/${filename})}\"",
  "resourceList" : [ ]
}
[WI-495][TI-1193] - [INFO] 2024-04-23 11:56:54.818 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-495][TI-1193] - [INFO] 2024-04-23 11:56:54.818 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}] successfully
[WI-495][TI-1193] - [INFO] 2024-04-23 11:56:54.818 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-495][TI-1193] - [INFO] 2024-04-23 11:56:54.818 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-495][TI-1193] - [INFO] 2024-04-23 11:56:54.818 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-495][TI-1193] - [INFO] 2024-04-23 11:56:54.819 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-495][TI-1193] - [INFO] 2024-04-23 11:56:54.819 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-495][TI-1193] - [INFO] 2024-04-23 11:56:54.820 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export PYTHON_LAUNCHER=/bin/python3.11
# move file to the reddit processing folder
# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error
filename=$(basename "/local_storage/reddit/processing/386-20240422.json")
if ! grep -q "/local_storage/reddit/processing" <<< "/local_storage/reddit/processing/386-20240422.json"; then
    mv /local_storage/reddit/processing/386-20240422.json /local_storage/reddit/processing
else
    echo JSON is already in processing
fi

# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing
echo "#{setValue(raw_file_dir=/local_storage/reddit/processing/${filename})}"
[WI-495][TI-1193] - [INFO] 2024-04-23 11:56:54.820 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-495][TI-1193] - [INFO] 2024-04-23 11:56:54.820 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_84/495/1193/495_1193.sh
[WI-495][TI-1193] - [INFO] 2024-04-23 11:56:54.823 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 5392
[WI-0][TI-1193] - [INFO] 2024-04-23 11:56:55.675 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1193, success=true)
[WI-0][TI-1193] - [INFO] 2024-04-23 11:56:55.679 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1193)
[WI-0][TI-0] - [INFO] 2024-04-23 11:56:55.826 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
	JSON is already in processing
	#{setValue(raw_file_dir=/local_storage/reddit/processing/386-20240422.json)}
[WI-495][TI-1193] - [INFO] 2024-04-23 11:56:55.830 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_84/495/1193, processId:5392 ,exitStatusCode:0 ,processWaitForStatus:true ,processExitValue:0
[WI-495][TI-1193] - [INFO] 2024-04-23 11:56:55.831 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-495][TI-1193] - [INFO] 2024-04-23 11:56:55.835 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-495][TI-1193] - [INFO] 2024-04-23 11:56:55.836 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-495][TI-1193] - [INFO] 2024-04-23 11:56:55.836 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-495][TI-1193] - [INFO] 2024-04-23 11:56:55.839 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: SUCCESS to master : 172.18.1.1:1234
[WI-495][TI-1193] - [INFO] 2024-04-23 11:56:55.839 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-495][TI-1193] - [INFO] 2024-04-23 11:56:55.839 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_84/495/1193
[WI-495][TI-1193] - [INFO] 2024-04-23 11:56:55.840 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_84/495/1193
[WI-495][TI-1193] - [INFO] 2024-04-23 11:56:55.840 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-1193] - [INFO] 2024-04-23 11:56:56.674 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1193, success=true)
[WI-0][TI-0] - [INFO] 2024-04-23 11:56:56.749 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1194, taskName=spark preprocessing, firstSubmitTime=1713844616741, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.9:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=84, appIds=null, processInstanceId=495, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"processing"}], executorId=1, cmdTypeIfComplement=7, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[],"rawScript":"# $SPARK_HOME/bin/spark-submit \\\n#     --master spark://spark-master:7077 \\\n#     --conf spark.driver.cores=2 \\\n#     --conf spark.driver.memory=2G \\\n#     --conf spark.executor.instances=1 \\\n#     --conf spark.executor.cores=2 \\\n#     --conf spark.executor.memory=2G \\\n#     --files ${raw_file_dir} \\\n#     --name reddit_preprocessing spark_reddit_preprocessing.py\n\n$SPARK_HOME/bin/spark-submit \\\n    --master local \\\n    --files ${raw_file_dir} \\\n    --name reddit_preprocessing spark_reddit_preprocessing.py\n","resourceList":[{"id":null,"resourceName":"file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py","res":null}]}, environmentConfig=export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export PYSPARK_DRIVER_PYTHON=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='spark preprocessing'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240423'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1194'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13210058002752'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240423115656'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='processing'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='495'}, raw_file_dir=Property{prop='raw_file_dir', direct=IN, type=VARCHAR, value='/local_storage/reddit/processing/386-20240422.json'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240422'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-495][TI-1194] - [INFO] 2024-04-23 11:56:56.752 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: spark preprocessing to wait queue success
[WI-495][TI-1194] - [INFO] 2024-04-23 11:56:56.752 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-495][TI-1194] - [INFO] 2024-04-23 11:56:56.754 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-495][TI-1194] - [INFO] 2024-04-23 11:56:56.754 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-495][TI-1194] - [INFO] 2024-04-23 11:56:56.754 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-495][TI-1194] - [INFO] 2024-04-23 11:56:56.755 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713844616755
[WI-495][TI-1194] - [INFO] 2024-04-23 11:56:56.755 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 495_1194
[WI-495][TI-1194] - [INFO] 2024-04-23 11:56:56.755 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1194,
  "taskName" : "spark preprocessing",
  "firstSubmitTime" : 1713844616741,
  "startTime" : 1713844616755,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.9:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240423/13201021801792/84/495/1194.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 84,
  "processInstanceId" : 495,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"processing\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 7,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[],\"rawScript\":\"# $SPARK_HOME/bin/spark-submit \\\\\\n#     --master spark://spark-master:7077 \\\\\\n#     --conf spark.driver.cores=2 \\\\\\n#     --conf spark.driver.memory=2G \\\\\\n#     --conf spark.executor.instances=1 \\\\\\n#     --conf spark.executor.cores=2 \\\\\\n#     --conf spark.executor.memory=2G \\\\\\n#     --files ${raw_file_dir} \\\\\\n#     --name reddit_preprocessing spark_reddit_preprocessing.py\\n\\n$SPARK_HOME/bin/spark-submit \\\\\\n    --master local \\\\\\n    --files ${raw_file_dir} \\\\\\n    --name reddit_preprocessing spark_reddit_preprocessing.py\\n\",\"resourceList\":[{\"id\":null,\"resourceName\":\"file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py\",\"res\":null}]}",
  "environmentConfig" : "export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3\nexport JAVA_HOME=/opt/java/openjdk\nexport PYSPARK_DRIVER_PYTHON=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "spark preprocessing"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1194"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13210058002752"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423115656"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "processing"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "495"
    },
    "raw_file_dir" : {
      "prop" : "raw_file_dir",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit/processing/386-20240422.json"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240422"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "495_1194",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"raw_file_dir\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"/local_storage/reddit/processing/386-20240422.json\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-495][TI-1194] - [INFO] 2024-04-23 11:56:56.756 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-495][TI-1194] - [INFO] 2024-04-23 11:56:56.756 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-495][TI-1194] - [INFO] 2024-04-23 11:56:56.756 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-495][TI-1194] - [INFO] 2024-04-23 11:56:56.764 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-495][TI-1194] - [INFO] 2024-04-23 11:56:56.765 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-495][TI-1194] - [INFO] 2024-04-23 11:56:56.766 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_84/495/1194 check successfully
[WI-495][TI-1194] - [INFO] 2024-04-23 11:56:56.767 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-495][TI-1194] - [INFO] 2024-04-23 11:56:56.769 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py=ResourceContext.ResourceItem(resourceAbsolutePathInStorage=file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py, resourceRelativePath=spark_reddit_preprocessing.py, resourceAbsolutePathInLocal=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_84/495/1194/spark_reddit_preprocessing.py)})
[WI-495][TI-1194] - [INFO] 2024-04-23 11:56:56.770 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-495][TI-1194] - [INFO] 2024-04-23 11:56:56.771 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-495][TI-1194] - [INFO] 2024-04-23 11:56:56.771 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ ],
  "varPool" : null,
  "rawScript" : "# $SPARK_HOME/bin/spark-submit \\\n#     --master spark://spark-master:7077 \\\n#     --conf spark.driver.cores=2 \\\n#     --conf spark.driver.memory=2G \\\n#     --conf spark.executor.instances=1 \\\n#     --conf spark.executor.cores=2 \\\n#     --conf spark.executor.memory=2G \\\n#     --files ${raw_file_dir} \\\n#     --name reddit_preprocessing spark_reddit_preprocessing.py\n\n$SPARK_HOME/bin/spark-submit \\\n    --master local \\\n    --files ${raw_file_dir} \\\n    --name reddit_preprocessing spark_reddit_preprocessing.py\n",
  "resourceList" : [ {
    "id" : null,
    "resourceName" : "file:/dolphinscheduler/default/resources/spark_reddit_preprocessing.py",
    "res" : null
  } ]
}
[WI-495][TI-1194] - [INFO] 2024-04-23 11:56:56.771 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-495][TI-1194] - [INFO] 2024-04-23 11:56:56.772 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}] successfully
[WI-495][TI-1194] - [INFO] 2024-04-23 11:56:56.772 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-495][TI-1194] - [INFO] 2024-04-23 11:56:56.772 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-495][TI-1194] - [INFO] 2024-04-23 11:56:56.772 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-495][TI-1194] - [INFO] 2024-04-23 11:56:56.773 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-495][TI-1194] - [INFO] 2024-04-23 11:56:56.774 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-495][TI-1194] - [INFO] 2024-04-23 11:56:56.774 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export PYSPARK_DRIVER_PYTHON=/bin/python3.11
# $SPARK_HOME/bin/spark-submit \
#     --master spark://spark-master:7077 \
#     --conf spark.driver.cores=2 \
#     --conf spark.driver.memory=2G \
#     --conf spark.executor.instances=1 \
#     --conf spark.executor.cores=2 \
#     --conf spark.executor.memory=2G \
#     --files /local_storage/reddit/processing/386-20240422.json \
#     --name reddit_preprocessing spark_reddit_preprocessing.py

$SPARK_HOME/bin/spark-submit \
    --master local \
    --files /local_storage/reddit/processing/386-20240422.json \
    --name reddit_preprocessing spark_reddit_preprocessing.py

[WI-495][TI-1194] - [INFO] 2024-04-23 11:56:56.774 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-495][TI-1194] - [INFO] 2024-04-23 11:56:56.775 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_84/495/1194/495_1194.sh
[WI-495][TI-1194] - [INFO] 2024-04-23 11:56:56.777 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 5404
[WI-0][TI-1194] - [INFO] 2024-04-23 11:56:57.682 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1194, success=true)
[WI-0][TI-1194] - [INFO] 2024-04-23 11:56:57.686 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionInfoEvent(taskInstanceId=1194, processInstanceId=495, startTime=1713844616755, workflowInstanceHost=172.18.0.9:5678, taskInstanceHost=172.18.1.1:1234, logPath=null, processId=0, eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1194] - [INFO] 2024-04-23 11:56:57.688 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionInfoEvent(taskInstanceId=1194, processInstanceId=495, startTime=1713844616755, workflowInstanceHost=172.18.0.9:5678, taskInstanceHost=172.18.1.1:1234, logPath=null, processId=0, eventCreateTime=0, eventSendTime=1713844617686)
[WI-0][TI-1194] - [INFO] 2024-04-23 11:56:57.694 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1194)
[WI-0][TI-1194] - [INFO] 2024-04-23 11:56:57.709 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1194)
[WI-0][TI-0] - [INFO] 2024-04-23 11:56:57.782 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
[WI-0][TI-0] - [INFO] 2024-04-23 11:56:59.786 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:56:59 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[WI-0][TI-0] - [INFO] 2024-04-23 11:57:00.788 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:57:00 INFO SparkContext: Running Spark version 3.5.1
	24/04/23 11:57:00 INFO SparkContext: OS info Linux, 6.5.0-28-generic, amd64
	24/04/23 11:57:00 INFO SparkContext: Java version 1.8.0_402
	24/04/23 11:57:00 INFO ResourceUtils: ==============================================================
	24/04/23 11:57:00 INFO ResourceUtils: No custom resources configured for spark.driver.
	24/04/23 11:57:00 INFO ResourceUtils: ==============================================================
	24/04/23 11:57:00 INFO SparkContext: Submitted application: reddit_preprocessing
	24/04/23 11:57:00 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
	24/04/23 11:57:00 INFO ResourceProfile: Limiting resource is cpu
	24/04/23 11:57:00 INFO ResourceProfileManager: Added ResourceProfile id: 0
	24/04/23 11:57:00 INFO SecurityManager: Changing view acls to: default
	24/04/23 11:57:00 INFO SecurityManager: Changing modify acls to: default
	24/04/23 11:57:00 INFO SecurityManager: Changing view acls groups to: 
	24/04/23 11:57:00 INFO SecurityManager: Changing modify acls groups to: 
	24/04/23 11:57:00 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: default; groups with view permissions: EMPTY; users with modify permissions: default; groups with modify permissions: EMPTY
[WI-0][TI-0] - [INFO] 2024-04-23 11:57:01.790 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:57:01 INFO Utils: Successfully started service 'sparkDriver' on port 37603.
	24/04/23 11:57:01 INFO SparkEnv: Registering MapOutputTracker
	24/04/23 11:57:01 INFO SparkEnv: Registering BlockManagerMaster
	24/04/23 11:57:01 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
	24/04/23 11:57:01 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
	24/04/23 11:57:01 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
	24/04/23 11:57:01 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-740ca06c-b14e-4f07-9dd0-e48af6736f0a
	24/04/23 11:57:01 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
	24/04/23 11:57:01 INFO SparkEnv: Registering OutputCommitCoordinator
	24/04/23 11:57:01 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
	24/04/23 11:57:01 INFO Utils: Successfully started service 'SparkUI' on port 4040.
[WI-0][TI-0] - [INFO] 2024-04-23 11:57:02.794 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:57:01 INFO SparkContext: Added file file:///local_storage/reddit/processing/386-20240422.json at file:///local_storage/reddit/processing/386-20240422.json with timestamp 1713844620538
	24/04/23 11:57:01 INFO Utils: Copying /local_storage/reddit/processing/386-20240422.json to /tmp/spark-a9b9ee78-703d-4336-b65c-e7d943c4e3b7/userFiles-f5ae9c8d-df2c-4155-be73-baeec4e8c5fc/386-20240422.json
	24/04/23 11:57:02 INFO Executor: Starting executor ID driver on host c0e814e3f0bd
	24/04/23 11:57:02 INFO Executor: OS info Linux, 6.5.0-28-generic, amd64
	24/04/23 11:57:02 INFO Executor: Java version 1.8.0_402
	24/04/23 11:57:02 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
	24/04/23 11:57:02 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@5838c894 for default.
	24/04/23 11:57:02 INFO Executor: Fetching file:///local_storage/reddit/processing/386-20240422.json with timestamp 1713844620538
	24/04/23 11:57:02 INFO Utils: /local_storage/reddit/processing/386-20240422.json has been previously copied to /tmp/spark-a9b9ee78-703d-4336-b65c-e7d943c4e3b7/userFiles-f5ae9c8d-df2c-4155-be73-baeec4e8c5fc/386-20240422.json
	24/04/23 11:57:02 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45127.
	24/04/23 11:57:02 INFO NettyBlockTransferService: Server created on c0e814e3f0bd:45127
	24/04/23 11:57:02 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
	24/04/23 11:57:02 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, c0e814e3f0bd, 45127, None)
	24/04/23 11:57:02 INFO BlockManagerMasterEndpoint: Registering block manager c0e814e3f0bd:45127 with 366.3 MiB RAM, BlockManagerId(driver, c0e814e3f0bd, 45127, None)
	24/04/23 11:57:02 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, c0e814e3f0bd, 45127, None)
	24/04/23 11:57:02 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, c0e814e3f0bd, 45127, None)
[WI-0][TI-0] - [INFO] 2024-04-23 11:57:02.868 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8265895953757226 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:57:03.801 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	
	
	
	 /tmp/spark-a9b9ee78-703d-4336-b65c-e7d943c4e3b7/userFiles-f5ae9c8d-df2c-4155-be73-baeec4e8c5fc/386-20240422.json 
	
	
	
	24/04/23 11:57:03 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 345.6 KiB, free 366.0 MiB)
	24/04/23 11:57:03 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.7 KiB, free 365.9 MiB)
	24/04/23 11:57:03 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on c0e814e3f0bd:45127 (size: 32.7 KiB, free: 366.3 MiB)
	24/04/23 11:57:03 INFO SparkContext: Created broadcast 0 from wholeTextFiles at NativeMethodAccessorImpl.java:0
[WI-0][TI-0] - [INFO] 2024-04-23 11:57:03.889 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.730909090909091 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:57:04.830 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:57:03 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
	24/04/23 11:57:03 INFO SharedState: Warehouse path is 'file:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_84/495/1194/spark-warehouse'.
[WI-0][TI-0] - [INFO] 2024-04-23 11:57:04.939 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.803921568627451 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:57:05.941 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7972027972027973 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:57:06.945 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.886685552407932 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:57:07.950 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8229813664596273 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:57:10.005 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7982954545454546 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:57:10.849 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:57:10 INFO CodeGenerator: Code generated in 424.938886 ms
	24/04/23 11:57:10 INFO FileInputFormat: Total input files to process : 1
	24/04/23 11:57:10 INFO FileInputFormat: Total input files to process : 1
	24/04/23 11:57:10 INFO SparkContext: Starting job: json at NativeMethodAccessorImpl.java:0
	24/04/23 11:57:10 INFO DAGScheduler: Got job 0 (json at NativeMethodAccessorImpl.java:0) with 1 output partitions
	24/04/23 11:57:10 INFO DAGScheduler: Final stage: ResultStage 0 (json at NativeMethodAccessorImpl.java:0)
	24/04/23 11:57:10 INFO DAGScheduler: Parents of final stage: List()
	24/04/23 11:57:10 INFO DAGScheduler: Missing parents: List()
	24/04/23 11:57:10 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[7] at json at NativeMethodAccessorImpl.java:0), which has no missing parents
	24/04/23 11:57:10 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 23.3 KiB, free 365.9 MiB)
	24/04/23 11:57:10 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 11.4 KiB, free 365.9 MiB)
	24/04/23 11:57:10 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on c0e814e3f0bd:45127 (size: 11.4 KiB, free: 366.3 MiB)
	24/04/23 11:57:10 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1585
	24/04/23 11:57:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[7] at json at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
	24/04/23 11:57:10 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
[WI-0][TI-0] - [INFO] 2024-04-23 11:57:11.018 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8980564889655799 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:57:11.852 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:57:11 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (c0e814e3f0bd, executor driver, partition 0, PROCESS_LOCAL, 8011 bytes) 
	24/04/23 11:57:11 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
[WI-0][TI-0] - [INFO] 2024-04-23 11:57:12.022 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9068493150684931 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-23 11:57:12.977 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:57:12 INFO WholeTextFileRDD: Input split: Paths:/tmp/spark-a9b9ee78-703d-4336-b65c-e7d943c4e3b7/userFiles-f5ae9c8d-df2c-4155-be73-baeec4e8c5fc/386-20240422.json:0+71860
[WI-0][TI-0] - [INFO] 2024-04-23 11:57:13.979 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/23 11:57:13 INFO CodeGenerator: Code generated in 62.737992 ms
	24/04/23 11:57:13 ERROR Executor: Exception in task 0.0 in stage 0.0 (TID 0)
	org.apache.spark.api.python.PythonException: Traceback (most recent call last):
	  File "/opt/spark-3.5.1-bin-hadoop3/python/lib/pyspark.zip/pyspark/worker.py", line 1100, in main
	    raise PySparkRuntimeError(
	pyspark.errors.exceptions.base.PySparkRuntimeError: [PYTHON_VERSION_MISMATCH] Python in worker has different version (3, 10) than that in driver 3.11, PySpark cannot run with different minor versions.
	Please check environment variables PYSPARK_PYTHON and PYSPARK_DRIVER_PYTHON are correctly set.
	
		at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)
		at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)
		at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)
		at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)
		at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
		at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
		at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
		at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
		at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
		at org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)
		at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)
		at scala.collection.Iterator.isEmpty(Iterator.scala:387)
		at scala.collection.Iterator.isEmpty$(Iterator.scala:387)
		at scala.collection.AbstractIterator.isEmpty(Iterator.scala:1431)
		at scala.collection.TraversableOnce.reduceLeftOption(TraversableOnce.scala:249)
		at scala.collection.TraversableOnce.reduceLeftOption$(TraversableOnce.scala:248)
		at scala.collection.AbstractIterator.reduceLeftOption(Iterator.scala:1431)
		at scala.collection.TraversableOnce.reduceOption(TraversableOnce.scala:256)
		at scala.collection.TraversableOnce.reduceOption$(TraversableOnce.scala:256)
		at scala.collection.AbstractIterator.reduceOption(Iterator.scala:1431)
		at org.apache.spark.sql.catalyst.json.JsonInferSchema.$anonfun$infer$1(JsonInferSchema.scala:107)
		at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:858)
		at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:858)
		at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
		at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
		at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
		at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
		at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
		at org.apache.spark.scheduler.Task.run(Task.scala:141)
		at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
		at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
		at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
		at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
		at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
		at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
		at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
		at java.lang.Thread.run(Thread.java:750)
	24/04/23 11:57:13 WARN TaskSetManager: Lost task 0.0 in stage 0.0 (TID 0) (c0e814e3f0bd executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):
	  File "/opt/spark-3.5.1-bin-hadoop3/python/lib/pyspark.zip/pyspark/worker.py", line 1100, in main
	    raise PySparkRuntimeError(
	pyspark.errors.exceptions.base.PySparkRuntimeError: [PYTHON_VERSION_MISMATCH] Python in worker has different version (3, 10) than that in driver 3.11, PySpark cannot run with different minor versions.
	Please check environment variables PYSPARK_PYTHON and PYSPARK_DRIVER_PYTHON are correctly set.
	
		at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)
		at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)
		at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)
		at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)
		at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
		at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
		at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
		at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
		at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
		at org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)
		at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)
		at scala.collection.Iterator.isEmpty(Iterator.scala:387)
		at scala.collection.Iterator.isEmpty$(Iterator.scala:387)
		at scala.collection.AbstractIterator.isEmpty(Iterator.scala:1431)
		at scala.collection.TraversableOnce.reduceLeftOption(TraversableOnce.scala:249)
		at scala.collection.TraversableOnce.reduceLeftOption$(TraversableOnce.scala:248)
		at scala.collection.AbstractIterator.reduceLeftOption(Iterator.scala:1431)
		at scala.collection.TraversableOnce.reduceOption(TraversableOnce.scala:256)
		at scala.collection.TraversableOnce.reduceOption$(TraversableOnce.scala:256)
		at scala.collection.AbstractIterator.reduceOption(Iterator.scala:1431)
		at org.apache.spark.sql.catalyst.json.JsonInferSchema.$anonfun$infer$1(JsonInferSchema.scala:107)
		at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:858)
		at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:858)
		at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
		at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
		at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
		at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
		at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
		at org.apache.spark.scheduler.Task.run(Task.scala:141)
		at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
		at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
		at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
		at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
		at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
		at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
		at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
		at java.lang.Thread.run(Thread.java:750)
	
	24/04/23 11:57:13 ERROR TaskSetManager: Task 0 in stage 0.0 failed 1 times; aborting job
	24/04/23 11:57:13 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
	24/04/23 11:57:13 INFO TaskSchedulerImpl: Cancelling stage 0
	24/04/23 11:57:13 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage cancelled: Job aborted due to stage failure: Task 0 in stage 0.0 failed 1 times, most recent failure: Lost task 0.0 in stage 0.0 (TID 0) (c0e814e3f0bd executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):
	  File "/opt/spark-3.5.1-bin-hadoop3/python/lib/pyspark.zip/pyspark/worker.py", line 1100, in main
	    raise PySparkRuntimeError(
	pyspark.errors.exceptions.base.PySparkRuntimeError: [PYTHON_VERSION_MISMATCH] Python in worker has different version (3, 10) than that in driver 3.11, PySpark cannot run with different minor versions.
	Please check environment variables PYSPARK_PYTHON and PYSPARK_DRIVER_PYTHON are correctly set.
	
		at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)
		at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)
		at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)
		at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)
		at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
		at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
		at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
		at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
		at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
		at org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)
		at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)
		at scala.collection.Iterator.isEmpty(Iterator.scala:387)
		at scala.collection.Iterator.isEmpty$(Iterator.scala:387)
		at scala.collection.AbstractIterator.isEmpty(Iterator.scala:1431)
		at scala.collection.TraversableOnce.reduceLeftOption(TraversableOnce.scala:249)
		at scala.collection.TraversableOnce.reduceLeftOption$(TraversableOnce.scala:248)
		at scala.collection.AbstractIterator.reduceLeftOption(Iterator.scala:1431)
		at scala.collection.TraversableOnce.reduceOption(TraversableOnce.scala:256)
		at scala.collection.TraversableOnce.reduceOption$(TraversableOnce.scala:256)
		at scala.collection.AbstractIterator.reduceOption(Iterator.scala:1431)
		at org.apache.spark.sql.catalyst.json.JsonInferSchema.$anonfun$infer$1(JsonInferSchema.scala:107)
		at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:858)
		at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:858)
		at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
		at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
		at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
		at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
		at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
		at org.apache.spark.scheduler.Task.run(Task.scala:141)
		at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
		at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
		at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
		at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
		at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
		at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
		at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
		at java.lang.Thread.run(Thread.java:750)
	
	Driver stacktrace:
	24/04/23 11:57:13 INFO DAGScheduler: ResultStage 0 (json at NativeMethodAccessorImpl.java:0) failed in 2.846 s due to Job aborted due to stage failure: Task 0 in stage 0.0 failed 1 times, most recent failure: Lost task 0.0 in stage 0.0 (TID 0) (c0e814e3f0bd executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):
	  File "/opt/spark-3.5.1-bin-hadoop3/python/lib/pyspark.zip/pyspark/worker.py", line 1100, in main
	    raise PySparkRuntimeError(
	pyspark.errors.exceptions.base.PySparkRuntimeError: [PYTHON_VERSION_MISMATCH] Python in worker has different version (3, 10) than that in driver 3.11, PySpark cannot run with different minor versions.
	Please check environment variables PYSPARK_PYTHON and PYSPARK_DRIVER_PYTHON are correctly set.
	
		at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)
		at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)
		at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)
		at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)
		at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
		at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
		at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
		at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
		at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
		at org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)
		at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)
		at scala.collection.Iterator.isEmpty(Iterator.scala:387)
		at scala.collection.Iterator.isEmpty$(Iterator.scala:387)
		at scala.collection.AbstractIterator.isEmpty(Iterator.scala:1431)
		at scala.collection.TraversableOnce.reduceLeftOption(TraversableOnce.scala:249)
		at scala.collection.TraversableOnce.reduceLeftOption$(TraversableOnce.scala:248)
		at scala.collection.AbstractIterator.reduceLeftOption(Iterator.scala:1431)
		at scala.collection.TraversableOnce.reduceOption(TraversableOnce.scala:256)
		at scala.collection.TraversableOnce.reduceOption$(TraversableOnce.scala:256)
		at scala.collection.AbstractIterator.reduceOption(Iterator.scala:1431)
		at org.apache.spark.sql.catalyst.json.JsonInferSchema.$anonfun$infer$1(JsonInferSchema.scala:107)
		at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:858)
		at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:858)
		at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
		at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
		at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
		at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
		at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
		at org.apache.spark.scheduler.Task.run(Task.scala:141)
		at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
		at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
		at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
		at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
		at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
		at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
		at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
		at java.lang.Thread.run(Thread.java:750)
	
	Driver stacktrace:
	24/04/23 11:57:13 INFO DAGScheduler: Job 0 failed: json at NativeMethodAccessorImpl.java:0, took 3.015790 s
	Traceback (most recent call last):
	  File "/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_84/495/1194/spark_reddit_preprocessing.py", line 50, in <module>
	    raw_df = spark.read.json(raw_df)
	             ^^^^^^^^^^^^^^^^^^^^^^^
	  File "/opt/spark-3.5.1-bin-hadoop3/python/lib/pyspark.zip/pyspark/sql/readwriter.py", line 440, in json
	  File "/opt/spark-3.5.1-bin-hadoop3/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
	  File "/opt/spark-3.5.1-bin-hadoop3/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 179, in deco
	  File "/opt/spark-3.5.1-bin-hadoop3/python/lib/py4j-0.10.9.7-src.zip/py4j/protocol.py", line 326, in get_return_value
	py4j.protocol.Py4JJavaError: An error occurred while calling o30.json.
	: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 0.0 failed 1 times, most recent failure: Lost task 0.0 in stage 0.0 (TID 0) (c0e814e3f0bd executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):
	  File "/opt/spark-3.5.1-bin-hadoop3/python/lib/pyspark.zip/pyspark/worker.py", line 1100, in main
	    raise PySparkRuntimeError(
	pyspark.errors.exceptions.base.PySparkRuntimeError: [PYTHON_VERSION_MISMATCH] Python in worker has different version (3, 10) than that in driver 3.11, PySpark cannot run with different minor versions.
	Please check environment variables PYSPARK_PYTHON and PYSPARK_DRIVER_PYTHON are correctly set.
	
		at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)
		at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)
		at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)
		at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)
		at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
		at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
		at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
		at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
		at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
		at org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)
		at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)
		at scala.collection.Iterator.isEmpty(Iterator.scala:387)
		at scala.collection.Iterator.isEmpty$(Iterator.scala:387)
		at scala.collection.AbstractIterator.isEmpty(Iterator.scala:1431)
		at scala.collection.TraversableOnce.reduceLeftOption(TraversableOnce.scala:249)
		at scala.collection.TraversableOnce.reduceLeftOption$(TraversableOnce.scala:248)
		at scala.collection.AbstractIterator.reduceLeftOption(Iterator.scala:1431)
		at scala.collection.TraversableOnce.reduceOption(TraversableOnce.scala:256)
		at scala.collection.TraversableOnce.reduceOption$(TraversableOnce.scala:256)
		at scala.collection.AbstractIterator.reduceOption(Iterator.scala:1431)
		at org.apache.spark.sql.catalyst.json.JsonInferSchema.$anonfun$infer$1(JsonInferSchema.scala:107)
		at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:858)
		at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:858)
		at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
		at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
		at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
		at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
		at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
		at org.apache.spark.scheduler.Task.run(Task.scala:141)
		at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
		at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
		at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
		at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
		at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
		at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
		at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
		at java.lang.Thread.run(Thread.java:750)
	
	Driver stacktrace:
		at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)
		at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)
		at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)
		at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
		at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
		at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
		at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)
		at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)
		at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)
		at scala.Option.foreach(Option.scala:407)
		at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)
		at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)
		at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)
		at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)
		at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
		at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:989)
		at org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)
		at org.apache.spark.SparkContext.runJob(SparkContext.scala:2493)
		at org.apache.spark.sql.catalyst.json.JsonInferSchema.infer(JsonInferSchema.scala:120)
		at org.apache.spark.sql.execution.datasources.json.TextInputJsonDataSource$.$anonfun$inferFromDataset$5(JsonDataSource.scala:109)
		at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)
		at org.apache.spark.sql.execution.datasources.json.TextInputJsonDataSource$.inferFromDataset(JsonDataSource.scala:109)
		at org.apache.spark.sql.DataFrameReader.$anonfun$json$4(DataFrameReader.scala:416)
		at scala.Option.getOrElse(Option.scala:189)
		at org.apache.spark.sql.DataFrameReader.json(DataFrameReader.scala:416)
		at org.apache.spark.sql.DataFrameReader.json(DataFrameReader.scala:391)
		at org.apache.spark.sql.DataFrameReader.json(DataFrameReader.scala:377)
		at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
		at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
		at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
		at java.lang.reflect.Method.invoke(Method.java:498)
		at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
		at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
		at py4j.Gateway.invoke(Gateway.java:282)
		at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
		at py4j.commands.CallCommand.execute(CallCommand.java:79)
		at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
		at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
		at java.lang.Thread.run(Thread.java:750)
	Caused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):
	  File "/opt/spark-3.5.1-bin-hadoop3/python/lib/pyspark.zip/pyspark/worker.py", line 1100, in main
	    raise PySparkRuntimeError(
	pyspark.errors.exceptions.base.PySparkRuntimeError: [PYTHON_VERSION_MISMATCH] Python in worker has different version (3, 10) than that in driver 3.11, PySpark cannot run with different minor versions.
	Please check environment variables PYSPARK_PYTHON and PYSPARK_DRIVER_PYTHON are correctly set.
	
		at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)
		at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)
		at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)
		at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)
		at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
		at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
		at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
		at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
		at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
		at org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)
		at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)
		at scala.collection.Iterator.isEmpty(Iterator.scala:387)
		at scala.collection.Iterator.isEmpty$(Iterator.scala:387)
		at scala.collection.AbstractIterator.isEmpty(Iterator.scala:1431)
		at scala.collection.TraversableOnce.reduceLeftOption(TraversableOnce.scala:249)
		at scala.collection.TraversableOnce.reduceLeftOption$(TraversableOnce.scala:248)
		at scala.collection.AbstractIterator.reduceLeftOption(Iterator.scala:1431)
		at scala.collection.TraversableOnce.reduceOption(TraversableOnce.scala:256)
		at scala.collection.TraversableOnce.reduceOption$(TraversableOnce.scala:256)
		at scala.collection.AbstractIterator.reduceOption(Iterator.scala:1431)
		at org.apache.spark.sql.catalyst.json.JsonInferSchema.$anonfun$infer$1(JsonInferSchema.scala:107)
		at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:858)
		at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:858)
		at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
		at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
		at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
		at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
		at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
		at org.apache.spark.scheduler.Task.run(Task.scala:141)
		at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
		at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
		at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
		at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
		at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
		at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
		at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
		... 1 more
	
	24/04/23 11:57:13 INFO SparkContext: Invoking stop() from shutdown hook
	24/04/23 11:57:13 INFO SparkContext: SparkContext is stopping with exitCode 0.
	24/04/23 11:57:13 INFO SparkUI: Stopped Spark web UI at http://c0e814e3f0bd:4040
	24/04/23 11:57:13 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
	24/04/23 11:57:13 INFO MemoryStore: MemoryStore cleared
	24/04/23 11:57:13 INFO BlockManager: BlockManager stopped
	24/04/23 11:57:13 INFO BlockManagerMaster: BlockManagerMaster stopped
	24/04/23 11:57:13 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
	24/04/23 11:57:13 INFO SparkContext: Successfully stopped SparkContext
	24/04/23 11:57:13 INFO ShutdownHookManager: Shutdown hook called
	24/04/23 11:57:13 INFO ShutdownHookManager: Deleting directory /tmp/spark-a9b9ee78-703d-4336-b65c-e7d943c4e3b7/pyspark-d4298422-6958-41fc-896f-8bc39dc9b3a1
	24/04/23 11:57:13 INFO ShutdownHookManager: Deleting directory /tmp/spark-a9b9ee78-703d-4336-b65c-e7d943c4e3b7
	24/04/23 11:57:13 INFO ShutdownHookManager: Deleting directory /tmp/spark-852dd0a6-db3c-411d-a0d9-9d3ababd7ac3
[WI-495][TI-1194] - [INFO] 2024-04-23 11:57:13.983 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_84/495/1194, processId:5404 ,exitStatusCode:1 ,processWaitForStatus:true ,processExitValue:1
[WI-495][TI-1194] - [INFO] 2024-04-23 11:57:13.983 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-495][TI-1194] - [INFO] 2024-04-23 11:57:13.983 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-495][TI-1194] - [INFO] 2024-04-23 11:57:13.983 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-495][TI-1194] - [INFO] 2024-04-23 11:57:13.983 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-495][TI-1194] - [INFO] 2024-04-23 11:57:13.987 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: FAILURE to master : 172.18.1.1:1234
[WI-495][TI-1194] - [INFO] 2024-04-23 11:57:13.987 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-495][TI-1194] - [INFO] 2024-04-23 11:57:13.988 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_84/495/1194
[WI-495][TI-1194] - [INFO] 2024-04-23 11:57:13.988 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_84/495/1194
[WI-495][TI-1194] - [INFO] 2024-04-23 11:57:13.989 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-1194] - [INFO] 2024-04-23 11:57:14.726 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1194, processInstanceId=495, status=6, startTime=1713844616755, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/84/495/1194.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_84/495/1194, endTime=1713844633983, processId=5404, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=0)
[WI-0][TI-1194] - [INFO] 2024-04-23 11:57:14.729 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1194, processInstanceId=495, status=6, startTime=1713844616755, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/84/495/1194.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_84/495/1194, endTime=1713844633983, processId=5404, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713844634726)
[WI-0][TI-1194] - [INFO] 2024-04-23 11:57:14.733 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1194, success=true)
[WI-0][TI-1194] - [INFO] 2024-04-23 11:57:14.742 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1194, success=true)
[WI-0][TI-1144] - [INFO] 2024-04-23 11:57:16.735 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1144, processInstanceId=489, status=9, startTime=1713840953087, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/80/489/1144.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1144, endTime=1713841331355, processId=3026, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713844336253)
[WI-0][TI-1144] - [INFO] 2024-04-23 11:57:16.747 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1144, processInstanceId=489, status=9, startTime=1713840953087, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/80/489/1144.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_80/489/1144, endTime=1713841331355, processId=3026, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713844636735)
[WI-0][TI-1123] - [INFO] 2024-04-23 11:59:55.109 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1123, processInstanceId=487, status=9, startTime=1713838208504, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1123.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1123, endTime=1713838483436, processId=1677, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713844494407)
[WI-0][TI-1123] - [INFO] 2024-04-23 11:59:55.112 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1123, processInstanceId=487, status=9, startTime=1713838208504, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1123.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1123, endTime=1713838483436, processId=1677, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713844795109)
[WI-0][TI-1111] - [INFO] 2024-04-23 11:59:57.118 +0800 o.a.d.s.w.m.MessageRetryRunner:[132] - Begin retry send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1111, processInstanceId=487, status=9, startTime=1713837256404, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1111.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1111, endTime=1713838170352, processId=1017, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713844496421)
[WI-0][TI-1111] - [INFO] 2024-04-23 11:59:57.120 +0800 o.a.d.s.w.m.MessageRetryRunner:[135] - Success send message to master, event: TaskInstanceExecutionFinishEvent(taskInstanceId=1111, processInstanceId=487, status=9, startTime=1713837256404, taskInstanceHost=172.18.1.1:1234, workflowInstanceHost=172.18.0.9:5678, logPath=/opt/dolphinscheduler/logs/20240423/13201021801792/78/487/1111.log, executePath=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_78/487/1111, endTime=1713838170352, processId=1017, appIds=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/386-20240422.json"}], eventCreateTime=0, eventSendTime=1713844797117)
