[WI-0][TI-0] - [WARN] 2024-04-24 06:03:36.662 +0800 o.s.c.k.c.p.AbstractKubernetesProfileEnvironmentPostProcessor:[258] - Not running inside kubernetes. Skipping 'kubernetes' profile activation.
[WI-0][TI-0] - [WARN] 2024-04-24 06:03:40.495 +0800 o.s.c.k.c.p.AbstractKubernetesProfileEnvironmentPostProcessor:[258] - Not running inside kubernetes. Skipping 'kubernetes' profile activation.
[WI-0][TI-0] - [INFO] 2024-04-24 06:03:40.527 +0800 o.a.d.s.w.WorkerServer:[634] - No active profile set, falling back to 1 default profile: "default"
[WI-0][TI-0] - [INFO] 2024-04-24 06:03:51.327 +0800 o.s.c.c.s.GenericScope:[283] - BeanFactory id=7e7bf7c6-2cb3-34d2-a0d5-a56161c67d0e
[WI-0][TI-0] - [INFO] 2024-04-24 06:03:53.420 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'org.springframework.cloud.commons.config.CommonsConfigAutoConfiguration' of type [org.springframework.cloud.commons.config.CommonsConfigAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-04-24 06:03:53.437 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'org.springframework.cloud.client.loadbalancer.LoadBalancerDefaultMappingsProviderAutoConfiguration' of type [org.springframework.cloud.client.loadbalancer.LoadBalancerDefaultMappingsProviderAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-04-24 06:03:53.442 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'loadBalancerClientsDefaultsMappingsProvider' of type [org.springframework.cloud.client.loadbalancer.LoadBalancerDefaultMappingsProviderAutoConfiguration$$Lambda$392/189820624] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-04-24 06:03:53.452 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'defaultsBindHandlerAdvisor' of type [org.springframework.cloud.commons.config.DefaultsBindHandlerAdvisor] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-04-24 06:03:53.713 +0800 o.a.d.c.u.NetUtils:[312] - Get all NetworkInterfaces: [name:eth0 (eth0), name:lo (lo)]
[WI-0][TI-0] - [INFO] 2024-04-24 06:03:53.762 +0800 o.a.d.s.w.c.WorkerConfig:[98] - 
****************************Worker Configuration**************************************
  listen-port -> 1234
  exec-threads -> 100
  max-heartbeat-interval -> PT10S
  host-weight -> 100
  tenantConfig -> TenantConfig(autoCreateTenantEnabled=true, distributedTenantEnabled=false, defaultTenantEnabled=false)
  server-load-protection -> WorkerServerLoadProtection(enabled=true, maxCpuUsagePercentageThresholds=0.7, maxJVMMemoryUsagePercentageThresholds=0.7, maxSystemMemoryUsagePercentageThresholds=0.7, maxDiskUsagePercentageThresholds=0.7)
  registry-disconnect-strategy -> ConnectStrategyProperties(strategy=WAITING, maxWaitingTime=PT1M40S)
  task-execute-threads-full-policy: REJECT
  address -> 172.18.1.1:1234
  registry-path: /nodes/worker/172.18.1.1:1234
****************************Worker Configuration**************************************
[WI-0][TI-0] - [INFO] 2024-04-24 06:03:53.763 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'workerConfig' of type [org.apache.dolphinscheduler.server.worker.config.WorkerConfig$$EnhancerBySpringCGLIB$$153d90bb] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-04-24 06:03:54.134 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'io.kubernetes.client.spring.extended.manifests.config.KubernetesManifestsAutoConfiguration' of type [io.kubernetes.client.spring.extended.manifests.config.KubernetesManifestsAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-04-24 06:03:54.159 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'kubernetes.manifests-io.kubernetes.client.spring.extended.manifests.config.KubernetesManifestsProperties' of type [io.kubernetes.client.spring.extended.manifests.config.KubernetesManifestsProperties] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-04-24 06:03:54.202 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'io.kubernetes.client.spring.extended.controller.config.KubernetesInformerAutoConfiguration' of type [io.kubernetes.client.spring.extended.controller.config.KubernetesInformerAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-04-24 06:03:54.292 +0800 o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[376] - Bean 'defaultApiClient' of type [io.kubernetes.client.openapi.ApiClient] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[WI-0][TI-0] - [INFO] 2024-04-24 06:03:54.777 +0800 o.e.j.u.log:[170] - Logging initialized @29464ms to org.eclipse.jetty.util.log.Slf4jLog
[WI-0][TI-0] - [INFO] 2024-04-24 06:03:57.080 +0800 o.s.b.w.e.j.JettyServletWebServerFactory:[166] - Server initialized with port: 1235
[WI-0][TI-0] - [INFO] 2024-04-24 06:03:57.179 +0800 o.e.j.s.Server:[375] - jetty-9.4.48.v20220622; built: 2022-06-21T20:42:25.880Z; git: 6b67c5719d1f4371b33655ff2d047d24e171e49a; jvm 1.8.0_402-b06
[WI-0][TI-0] - [INFO] 2024-04-24 06:03:57.532 +0800 o.e.j.s.h.C.application:[2368] - Initializing Spring embedded WebApplicationContext
[WI-0][TI-0] - [INFO] 2024-04-24 06:03:57.534 +0800 o.s.b.w.s.c.ServletWebServerApplicationContext:[292] - Root WebApplicationContext: initialization completed in 16896 ms
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:00.751 +0800 o.e.j.s.session:[334] - DefaultSessionIdManager workerName=node0
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:00.752 +0800 o.e.j.s.session:[339] - No SessionScavenger set, using defaults
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:00.806 +0800 o.e.j.s.session:[132] - node0 Scavenging every 600000ms
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:01.071 +0800 o.e.j.s.h.ContextHandler:[921] - Started o.s.b.w.e.j.JettyEmbeddedWebAppContext@5403431a{application,/,[file:///tmp/jetty-docbase.1235.4951441206090913115/],AVAILABLE}
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:01.072 +0800 o.e.j.s.Server:[415] - Started @35759ms
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:01.726 +0800 o.a.c.f.i.CuratorFrameworkImpl:[338] - Starting
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:01.733 +0800 o.a.z.ZooKeeper:[98] - Client environment:zookeeper.version=3.8.0-5a02a05eddb59aee6ac762f7ea82e92a68eb9c0f, built on 2022-02-25 08:49 UTC
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:01.734 +0800 o.a.z.ZooKeeper:[98] - Client environment:host.name=62c50ccd7bf9
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:01.734 +0800 o.a.z.ZooKeeper:[98] - Client environment:java.version=1.8.0_402
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:01.735 +0800 o.a.z.ZooKeeper:[98] - Client environment:java.vendor=Temurin
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:01.735 +0800 o.a.z.ZooKeeper:[98] - Client environment:java.home=/opt/java/openjdk
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:01.736 +0800 o.a.z.ZooKeeper:[98] - Client environment:java.class.path=/opt/dolphinscheduler/conf:/opt/dolphinscheduler/libs/kerb-client-1.0.1.jar:/opt/dolphinscheduler/libs/spring-cloud-starter-kubernetes-client-config-2.1.3.jar:/opt/dolphinscheduler/libs/oauth2-oidc-sdk-9.35.jar:/opt/dolphinscheduler/libs/jsqlparser-4.4.jar:/opt/dolphinscheduler/libs/reactive-streams-1.0.4.jar:/opt/dolphinscheduler/libs/kubernetes-model-extensions-5.10.2.jar:/opt/dolphinscheduler/libs/zookeeper-3.8.0.jar:/opt/dolphinscheduler/libs/kubernetes-model-apps-5.10.2.jar:/opt/dolphinscheduler/libs/grpc-api-1.41.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-pigeon-3.2.1.jar:/opt/dolphinscheduler/libs/client-java-api-13.0.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-obs-3.2.1.jar:/opt/dolphinscheduler/libs/spring-web-5.3.22.jar:/opt/dolphinscheduler/libs/aws-java-sdk-emr-1.12.300.jar:/opt/dolphinscheduler/libs/spring-context-5.3.22.jar:/opt/dolphinscheduler/libs/gapic-google-cloud-storage-v2-2.18.0-alpha.jar:/opt/dolphinscheduler/libs/spring-cloud-kubernetes-client-config-2.1.3.jar:/opt/dolphinscheduler/libs/jetty-io-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/annotations-13.0.jar:/opt/dolphinscheduler/libs/jpam-1.1.jar:/opt/dolphinscheduler/libs/joda-time-2.10.13.jar:/opt/dolphinscheduler/libs/spring-cloud-kubernetes-client-autoconfig-2.1.3.jar:/opt/dolphinscheduler/libs/kerb-identity-1.0.1.jar:/opt/dolphinscheduler/libs/vertica-jdbc-12.0.4-0.jar:/opt/dolphinscheduler/libs/grpc-googleapis-1.52.1.jar:/opt/dolphinscheduler/libs/aliyun-java-sdk-kms-2.11.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-dvc-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-hana-3.2.1.jar:/opt/dolphinscheduler/libs/kubernetes-httpclient-okhttp-6.0.0.jar:/opt/dolphinscheduler/libs/jline-2.12.jar:/opt/dolphinscheduler/libs/sshd-core-2.8.0.jar:/opt/dolphinscheduler/libs/jna-platform-5.10.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-sqlserver-3.2.1.jar:/opt/dolphinscheduler/libs/commons-beanutils-1.9.4.jar:/opt/dolphinscheduler/libs/grpc-services-1.41.0.jar:/opt/dolphinscheduler/libs/jmespath-java-1.12.300.jar:/opt/dolphinscheduler/libs/curator-client-5.3.0.jar:/opt/dolphinscheduler/libs/proto-google-common-protos-2.0.1.jar:/opt/dolphinscheduler/libs/mybatis-3.5.10.jar:/opt/dolphinscheduler/libs/jackson-annotations-2.13.4.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-all-3.2.1.jar:/opt/dolphinscheduler/libs/jakarta.xml.bind-api-2.3.3.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-jupyter-3.2.1.jar:/opt/dolphinscheduler/libs/mybatis-plus-extension-3.5.2.jar:/opt/dolphinscheduler/libs/j2objc-annotations-1.3.jar:/opt/dolphinscheduler/libs/Java-WebSocket-1.5.1.jar:/opt/dolphinscheduler/libs/azure-storage-common-12.20.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-sagemaker-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-databend-3.2.1.jar:/opt/dolphinscheduler/libs/google-auth-library-oauth2-http-1.15.0.jar:/opt/dolphinscheduler/libs/jetty-security-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-python-3.2.1.jar:/opt/dolphinscheduler/libs/snappy-java-1.1.10.1.jar:/opt/dolphinscheduler/libs/kubernetes-model-batch-5.10.2.jar:/opt/dolphinscheduler/libs/netty-transport-native-epoll-4.1.53.Final-linux-x86_64.jar:/opt/dolphinscheduler/libs/jackson-core-asl-1.9.13.jar:/opt/dolphinscheduler/libs/gson-fire-1.8.5.jar:/opt/dolphinscheduler/libs/clickhouse-jdbc-0.4.6.jar:/opt/dolphinscheduler/libs/grpc-netty-shaded-1.41.0.jar:/opt/dolphinscheduler/libs/caffeine-2.9.3.jar:/opt/dolphinscheduler/libs/aliyun-java-sdk-core-4.5.10.jar:/opt/dolphinscheduler/libs/jackson-module-jaxb-annotations-2.13.3.jar:/opt/dolphinscheduler/libs/jetty-http-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/jersey-servlet-1.19.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-dinky-3.2.1.jar:/opt/dolphinscheduler/libs/simpleclient_tracer_common-0.15.0.jar:/opt/dolphinscheduler/libs/netty-handler-4.1.53.Final.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-datafactory-3.2.1.jar:/opt/dolphinscheduler/libs/json-path-2.7.0.jar:/opt/dolphinscheduler/libs/mybatis-plus-annotation-3.5.2.jar:/opt/dolphinscheduler/libs/azure-resourcemanager-datafactory-1.0.0-beta.19.jar:/opt/dolphinscheduler/libs/commons-codec-1.11.jar:/opt/dolphinscheduler/libs/dolphinscheduler-extract-master-3.2.1.jar:/opt/dolphinscheduler/libs/spring-aop-5.3.22.jar:/opt/dolphinscheduler/libs/kubernetes-model-core-5.10.2.jar:/opt/dolphinscheduler/libs/kubernetes-model-networking-5.10.2.jar:/opt/dolphinscheduler/libs/kotlin-stdlib-jdk7-1.6.21.jar:/opt/dolphinscheduler/libs/kerby-xdr-1.0.1.jar:/opt/dolphinscheduler/libs/aliyun-java-sdk-ram-3.1.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-k8s-3.2.1.jar:/opt/dolphinscheduler/libs/guava-31.1-jre.jar:/opt/dolphinscheduler/libs/netty-codec-dns-4.1.53.Final.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-kubeflow-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-azure-sql-3.2.1.jar:/opt/dolphinscheduler/libs/HikariCP-4.0.3.jar:/opt/dolphinscheduler/libs/hive-metastore-2.3.9.jar:/opt/dolphinscheduler/libs/msal4j-1.13.3.jar:/opt/dolphinscheduler/libs/jackson-core-2.13.4.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-hive-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-mr-3.2.1.jar:/opt/dolphinscheduler/libs/kubernetes-model-node-5.10.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-common-3.2.1.jar:/opt/dolphinscheduler/libs/jose4j-0.7.8.jar:/opt/dolphinscheduler/libs/jul-to-slf4j-1.7.36.jar:/opt/dolphinscheduler/libs/azure-identity-1.7.1.jar:/opt/dolphinscheduler/libs/spring-boot-autoconfigure-2.7.3.jar:/opt/dolphinscheduler/libs/commons-math3-3.1.1.jar:/opt/dolphinscheduler/libs/jackson-jaxrs-json-provider-2.13.3.jar:/opt/dolphinscheduler/libs/perfmark-api-0.23.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-doris-3.2.1.jar:/opt/dolphinscheduler/libs/httpclient-4.5.13.jar:/opt/dolphinscheduler/libs/hive-service-2.3.9.jar:/opt/dolphinscheduler/libs/kerby-util-1.0.1.jar:/opt/dolphinscheduler/libs/commons-collections-3.2.2.jar:/opt/dolphinscheduler/libs/hadoop-yarn-client-3.2.4.jar:/opt/dolphinscheduler/libs/commons-text-1.8.jar:/opt/dolphinscheduler/libs/dolphinscheduler-worker-3.2.1.jar:/opt/dolphinscheduler/libs/hadoop-yarn-common-3.2.4.jar:/opt/dolphinscheduler/libs/zeppelin-client-0.10.1.jar:/opt/dolphinscheduler/libs/azure-core-management-1.10.1.jar:/opt/dolphinscheduler/libs/hadoop-mapreduce-client-jobclient-3.2.4.jar:/opt/dolphinscheduler/libs/jta-1.1.jar:/opt/dolphinscheduler/libs/annotations-4.1.1.4.jar:/opt/dolphinscheduler/libs/dolphinscheduler-extract-alert-3.2.1.jar:/opt/dolphinscheduler/libs/curator-framework-5.3.0.jar:/opt/dolphinscheduler/libs/hive-jdbc-2.3.9.jar:/opt/dolphinscheduler/libs/kyuubi-hive-jdbc-shaded-1.7.0.jar:/opt/dolphinscheduler/libs/client-java-proto-13.0.2.jar:/opt/dolphinscheduler/libs/checker-qual-3.19.0.jar:/opt/dolphinscheduler/libs/jetty-servlet-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/google-cloud-core-grpc-2.10.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-shell-3.2.1.jar:/opt/dolphinscheduler/libs/spring-security-rsa-1.0.10.RELEASE.jar:/opt/dolphinscheduler/libs/avro-1.7.7.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-postgresql-3.2.1.jar:/opt/dolphinscheduler/libs/netty-nio-client-2.17.282.jar:/opt/dolphinscheduler/libs/spring-webmvc-5.3.22.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-mysql-3.2.1.jar:/opt/dolphinscheduler/libs/opentracing-util-0.33.0.jar:/opt/dolphinscheduler/libs/auto-value-1.10.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-all-3.2.1.jar:/opt/dolphinscheduler/libs/jetcd-core-0.5.11.jar:/opt/dolphinscheduler/libs/grpc-context-1.41.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-datasync-3.2.1.jar:/opt/dolphinscheduler/libs/jackson-dataformat-cbor-2.13.3.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-gcs-3.2.1.jar:/opt/dolphinscheduler/libs/client-java-extended-13.0.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-redshift-3.2.1.jar:/opt/dolphinscheduler/libs/opencsv-2.3.jar:/opt/dolphinscheduler/libs/jcip-annotations-1.0-1.jar:/opt/dolphinscheduler/libs/accessors-smart-2.4.8.jar:/opt/dolphinscheduler/libs/hadoop-client-3.2.4.jar:/opt/dolphinscheduler/libs/commons-collections4-4.3.jar:/opt/dolphinscheduler/libs/metrics-core-4.2.11.jar:/opt/dolphinscheduler/libs/netty-resolver-4.1.53.Final.jar:/opt/dolphinscheduler/libs/parquet-hadoop-bundle-1.8.1.jar:/opt/dolphinscheduler/libs/bucket4j-core-6.2.0.jar:/opt/dolphinscheduler/libs/spring-cloud-starter-3.1.3.jar:/opt/dolphinscheduler/libs/mssql-jdbc-11.2.1.jre8.jar:/opt/dolphinscheduler/libs/netty-tcnative-boringssl-static-2.0.53.Final.jar:/opt/dolphinscheduler/libs/kubernetes-model-coordination-5.10.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-linkis-3.2.1.jar:/opt/dolphinscheduler/libs/commons-net-3.6.jar:/opt/dolphinscheduler/libs/netty-transport-native-kqueue-4.1.53.Final-osx-x86_64.jar:/opt/dolphinscheduler/libs/dolphinscheduler-meter-3.2.1.jar:/opt/dolphinscheduler/libs/kubernetes-client-api-6.0.0.jar:/opt/dolphinscheduler/libs/kubernetes-model-certificates-5.10.2.jar:/opt/dolphinscheduler/libs/opencensus-api-0.31.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-mlflow-3.2.1.jar:/opt/dolphinscheduler/libs/kotlin-stdlib-jdk8-1.6.21.jar:/opt/dolphinscheduler/libs/dolphinscheduler-registry-jdbc-3.2.1.jar:/opt/dolphinscheduler/libs/audience-annotations-0.12.0.jar:/opt/dolphinscheduler/libs/simpleclient_httpserver-0.15.0.jar:/opt/dolphinscheduler/libs/jetty-xml-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/kerby-asn1-1.0.1.jar:/opt/dolphinscheduler/libs/lang-tag-1.6.jar:/opt/dolphinscheduler/libs/api-common-2.6.0.jar:/opt/dolphinscheduler/libs/HdrHistogram-2.1.12.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-abs-3.2.1.jar:/opt/dolphinscheduler/libs/failsafe-2.4.4.jar:/opt/dolphinscheduler/libs/hbase-noop-htrace-4.1.1.jar:/opt/dolphinscheduler/libs/jamon-runtime-2.3.1.jar:/opt/dolphinscheduler/libs/jetty-util-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/threetenbp-1.6.5.jar:/opt/dolphinscheduler/libs/jakarta.activation-api-1.2.2.jar:/opt/dolphinscheduler/libs/kubernetes-model-common-5.10.2.jar:/opt/dolphinscheduler/libs/okhttp-4.9.3.jar:/opt/dolphinscheduler/libs/profiles-2.17.282.jar:/opt/dolphinscheduler/libs/hadoop-auth-3.2.4.jar:/opt/dolphinscheduler/libs/grpc-netty-1.41.0.jar:/opt/dolphinscheduler/libs/httpcore-nio-4.4.15.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-seatunnel-3.2.1.jar:/opt/dolphinscheduler/libs/aws-java-sdk-sagemaker-1.12.300.jar:/opt/dolphinscheduler/libs/oshi-core-6.1.1.jar:/opt/dolphinscheduler/libs/bonecp-0.8.0.RELEASE.jar:/opt/dolphinscheduler/libs/jackson-module-parameter-names-2.13.3.jar:/opt/dolphinscheduler/libs/bcutil-jdk15on-1.69.jar:/opt/dolphinscheduler/libs/aws-json-protocol-2.17.282.jar:/opt/dolphinscheduler/libs/dolphinscheduler-extract-base-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-all-3.2.1.jar:/opt/dolphinscheduler/libs/derby-10.14.2.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-snowflake-3.2.1.jar:/opt/dolphinscheduler/libs/netty-codec-http2-4.1.53.Final.jar:/opt/dolphinscheduler/libs/jetty-continuation-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/jackson-mapper-asl-1.9.13.jar:/opt/dolphinscheduler/libs/datanucleus-core-4.1.17.jar:/opt/dolphinscheduler/libs/netty-tcnative-boringssl-static-2.0.53.Final-osx-aarch_64.jar:/opt/dolphinscheduler/libs/failureaccess-1.0.1.jar:/opt/dolphinscheduler/libs/error_prone_annotations-2.5.1.jar:/opt/dolphinscheduler/libs/kerb-admin-1.0.1.jar:/opt/dolphinscheduler/libs/token-provider-1.0.1.jar:/opt/dolphinscheduler/libs/reactor-netty-core-1.0.22.jar:/opt/dolphinscheduler/libs/dolphinscheduler-registry-all-3.2.1.jar:/opt/dolphinscheduler/libs/jakarta.servlet-api-4.0.4.jar:/opt/dolphinscheduler/libs/http-client-spi-2.17.282.jar:/opt/dolphinscheduler/libs/regions-2.17.282.jar:/opt/dolphinscheduler/libs/logback-core-1.2.11.jar:/opt/dolphinscheduler/libs/json-1.8.jar:/opt/dolphinscheduler/libs/gax-grpc-2.23.0.jar:/opt/dolphinscheduler/libs/google-http-client-1.42.3.jar:/opt/dolphinscheduler/libs/hive-serde-2.3.9.jar:/opt/dolphinscheduler/libs/jettison-1.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-http-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-registry-zookeeper-3.2.1.jar:/opt/dolphinscheduler/libs/spring-security-crypto-5.7.3.jar:/opt/dolphinscheduler/libs/auth-2.17.282.jar:/opt/dolphinscheduler/libs/proto-google-cloud-storage-v2-2.18.0-alpha.jar:/opt/dolphinscheduler/libs/jetty-server-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/javax.annotation-api-1.3.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-starrocks-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-dataquality-3.2.1.jar:/opt/dolphinscheduler/libs/jcl-over-slf4j-1.7.36.jar:/opt/dolphinscheduler/libs/commons-lang3-3.12.0.jar:/opt/dolphinscheduler/libs/tomcat-embed-el-9.0.65.jar:/opt/dolphinscheduler/libs/opentracing-noop-0.33.0.jar:/opt/dolphinscheduler/libs/client-java-13.0.2.jar:/opt/dolphinscheduler/libs/spring-beans-5.3.22.jar:/opt/dolphinscheduler/libs/snakeyaml-1.33.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-ssh-3.2.1.jar:/opt/dolphinscheduler/libs/commons-pool-1.6.jar:/opt/dolphinscheduler/libs/javax.servlet-api-3.1.0.jar:/opt/dolphinscheduler/libs/hadoop-common-3.2.4.jar:/opt/dolphinscheduler/libs/kubernetes-model-apiextensions-5.10.2.jar:/opt/dolphinscheduler/libs/spring-boot-2.7.3.jar:/opt/dolphinscheduler/libs/bcprov-ext-jdk15on-1.69.jar:/opt/dolphinscheduler/libs/spring-boot-starter-2.7.3.jar:/opt/dolphinscheduler/libs/paranamer-2.3.jar:/opt/dolphinscheduler/libs/httpmime-4.5.13.jar:/opt/dolphinscheduler/libs/reactor-core-3.4.22.jar:/opt/dolphinscheduler/libs/azure-core-1.36.0.jar:/opt/dolphinscheduler/libs/bcpkix-jdk15on-1.69.jar:/opt/dolphinscheduler/libs/kubernetes-model-scheduling-5.10.2.jar:/opt/dolphinscheduler/libs/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/dolphinscheduler/libs/websocket-client-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/unirest-java-3.7.04-standalone.jar:/opt/dolphinscheduler/libs/hadoop-mapreduce-client-core-3.2.4.jar:/opt/dolphinscheduler/libs/google-auth-library-credentials-1.15.0.jar:/opt/dolphinscheduler/libs/azure-storage-internal-avro-12.6.0.jar:/opt/dolphinscheduler/libs/jackson-datatype-jdk8-2.13.3.jar:/opt/dolphinscheduler/libs/spring-expression-5.3.22.jar:/opt/dolphinscheduler/libs/aspectjweaver-1.9.7.jar:/opt/dolphinscheduler/libs/websocket-common-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/client-java-api-fluent-13.0.2.jar:/opt/dolphinscheduler/libs/mybatis-plus-3.5.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-athena-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-oss-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-openmldb-3.2.1.jar:/opt/dolphinscheduler/libs/curator-recipes-5.3.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-api-3.2.1.jar:/opt/dolphinscheduler/libs/netty-all-4.1.53.Final.jar:/opt/dolphinscheduler/libs/netty-resolver-dns-4.1.53.Final.jar:/opt/dolphinscheduler/libs/kubernetes-model-autoscaling-5.10.2.jar:/opt/dolphinscheduler/libs/kerb-util-1.0.1.jar:/opt/dolphinscheduler/libs/grpc-alts-1.41.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-presto-3.2.1.jar:/opt/dolphinscheduler/libs/kerb-simplekdc-1.0.1.jar:/opt/dolphinscheduler/libs/protobuf-java-util-3.17.2.jar:/opt/dolphinscheduler/libs/azure-core-http-netty-1.13.0.jar:/opt/dolphinscheduler/libs/transaction-api-1.1.jar:/opt/dolphinscheduler/libs/datanucleus-api-jdo-4.2.4.jar:/opt/dolphinscheduler/libs/zeppelin-common-0.10.1.jar:/opt/dolphinscheduler/libs/zt-zip-1.15.jar:/opt/dolphinscheduler/libs/animal-sniffer-annotations-1.19.jar:/opt/dolphinscheduler/libs/google-http-client-jackson2-1.42.3.jar:/opt/dolphinscheduler/libs/netty-buffer-4.1.53.Final.jar:/opt/dolphinscheduler/libs/jsr305-3.0.0.jar:/opt/dolphinscheduler/libs/netty-transport-classes-epoll-4.1.79.Final.jar:/opt/dolphinscheduler/libs/spring-boot-actuator-autoconfigure-2.7.3.jar:/opt/dolphinscheduler/libs/simpleclient-0.15.0.jar:/opt/dolphinscheduler/libs/aliyun-sdk-oss-3.15.1.jar:/opt/dolphinscheduler/libs/json-utils-2.17.282.jar:/opt/dolphinscheduler/libs/tephra-api-0.6.0.jar:/opt/dolphinscheduler/libs/spring-jdbc-5.3.22.jar:/opt/dolphinscheduler/libs/grpc-xds-1.41.0.jar:/opt/dolphinscheduler/libs/logback-classic-1.2.11.jar:/opt/dolphinscheduler/libs/google-cloud-storage-2.18.0.jar:/opt/dolphinscheduler/libs/micrometer-registry-prometheus-1.9.3.jar:/opt/dolphinscheduler/libs/grpc-core-1.41.0.jar:/opt/dolphinscheduler/libs/aws-java-sdk-kms-1.12.300.jar:/opt/dolphinscheduler/libs/kubernetes-model-rbac-5.10.2.jar:/opt/dolphinscheduler/libs/ini4j-0.5.4.jar:/opt/dolphinscheduler/libs/spring-boot-starter-web-2.7.3.jar:/opt/dolphinscheduler/libs/spring-cloud-commons-3.1.3.jar:/opt/dolphinscheduler/libs/netty-codec-http-4.1.53.Final.jar:/opt/dolphinscheduler/libs/jetty-client-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/jetcd-common-0.5.11.jar:/opt/dolphinscheduler/libs/metrics-spi-2.17.282.jar:/opt/dolphinscheduler/libs/utils-2.17.282.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-emr-3.2.1.jar:/opt/dolphinscheduler/libs/protocol-core-2.17.282.jar:/opt/dolphinscheduler/libs/micrometer-core-1.9.3.jar:/opt/dolphinscheduler/libs/netty-transport-native-unix-common-4.1.53.Final.jar:/opt/dolphinscheduler/libs/zjsonpatch-0.4.11.jar:/opt/dolphinscheduler/libs/annotations-2.17.282.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-sql-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-extract-common-3.2.1.jar:/opt/dolphinscheduler/libs/apache-client-2.17.282.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-oceanbase-3.2.1.jar:/opt/dolphinscheduler/libs/jdo-api-3.0.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-datax-3.2.1.jar:/opt/dolphinscheduler/libs/postgresql-42.4.1.jar:/opt/dolphinscheduler/libs/jetty-util-ajax-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/gax-2.23.0.jar:/opt/dolphinscheduler/libs/grpc-stub-1.41.0.jar:/opt/dolphinscheduler/libs/libfb303-0.9.3.jar:/opt/dolphinscheduler/libs/spring-core-5.3.22.jar:/opt/dolphinscheduler/libs/jaxb-api-2.3.1.jar:/opt/dolphinscheduler/libs/hive-service-rpc-2.3.9.jar:/opt/dolphinscheduler/libs/kubernetes-model-flowcontrol-5.10.2.jar:/opt/dolphinscheduler/libs/commons-logging-1.1.1.jar:/opt/dolphinscheduler/libs/mybatis-spring-2.0.7.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-oracle-3.2.1.jar:/opt/dolphinscheduler/libs/opencensus-proto-0.2.0.jar:/opt/dolphinscheduler/libs/grpc-protobuf-1.41.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-clickhouse-3.2.1.jar:/opt/dolphinscheduler/libs/spring-cloud-starter-bootstrap-3.1.3.jar:/opt/dolphinscheduler/libs/kubernetes-model-admissionregistration-5.10.2.jar:/opt/dolphinscheduler/libs/grpc-google-cloud-storage-v2-2.18.0-alpha.jar:/opt/dolphinscheduler/libs/esdk-obs-java-bundle-3.23.3.jar:/opt/dolphinscheduler/libs/dnsjava-2.1.7.jar:/opt/dolphinscheduler/libs/asm-9.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-spark-3.2.1.jar:/opt/dolphinscheduler/libs/netty-tcnative-boringssl-static-2.0.53.Final-linux-aarch_64.jar:/opt/dolphinscheduler/libs/re2j-1.6.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-vertica-3.2.1.jar:/opt/dolphinscheduler/libs/json-smart-2.4.8.jar:/opt/dolphinscheduler/libs/reactor-netty-http-1.0.22.jar:/opt/dolphinscheduler/libs/google-api-services-storage-v1-rev20220705-2.0.0.jar:/opt/dolphinscheduler/libs/kubernetes-client-6.0.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-kyuubi-3.2.1.jar:/opt/dolphinscheduler/libs/auto-value-annotations-1.10.1.jar:/opt/dolphinscheduler/libs/commons-cli-1.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-data-quality-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-chunjun-3.2.1.jar:/opt/dolphinscheduler/libs/kerb-server-1.0.1.jar:/opt/dolphinscheduler/libs/content-type-2.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-remoteshell-3.2.1.jar:/opt/dolphinscheduler/libs/opencensus-contrib-http-util-0.31.1.jar:/opt/dolphinscheduler/libs/druid-1.2.20.jar:/opt/dolphinscheduler/libs/javolution-5.5.1.jar:/opt/dolphinscheduler/libs/protobuf-java-3.17.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-db2-3.2.1.jar:/opt/dolphinscheduler/libs/aws-java-sdk-core-1.12.300.jar:/opt/dolphinscheduler/libs/spring-boot-starter-logging-2.7.3.jar:/opt/dolphinscheduler/libs/kerby-pkix-1.0.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-procedure-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-registry-etcd-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-sqoop-3.2.1.jar:/opt/dolphinscheduler/libs/zookeeper-jute-3.8.0.jar:/opt/dolphinscheduler/libs/netty-resolver-dns-native-macos-4.1.53.Final-osx-x86_64.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-sagemaker-3.2.1.jar:/opt/dolphinscheduler/libs/spring-boot-configuration-processor-2.6.1.jar:/opt/dolphinscheduler/libs/hive-common-2.3.9.jar:/opt/dolphinscheduler/libs/kerb-common-1.0.1.jar:/opt/dolphinscheduler/libs/stax-api-1.0.1.jar:/opt/dolphinscheduler/libs/kubernetes-model-storageclass-5.10.2.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-s3-3.2.1.jar:/opt/dolphinscheduler/libs/spring-boot-starter-jetty-2.7.3.jar:/opt/dolphinscheduler/libs/okio-2.8.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-dms-3.2.1.jar:/opt/dolphinscheduler/libs/simpleclient_common-0.15.0.jar:/opt/dolphinscheduler/libs/sdk-core-2.17.282.jar:/opt/dolphinscheduler/libs/javax.activation-api-1.2.0.jar:/opt/dolphinscheduler/libs/netty-handler-proxy-4.1.53.Final.jar:/opt/dolphinscheduler/libs/kerby-config-1.0.1.jar:/opt/dolphinscheduler/libs/netty-tcnative-classes-2.0.53.Final.jar:/opt/dolphinscheduler/libs/jackson-jaxrs-base-2.13.3.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-trino-3.2.1.jar:/opt/dolphinscheduler/libs/presto-jdbc-0.238.1.jar:/opt/dolphinscheduler/libs/websocket-api-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-flink-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-api-3.2.1.jar:/opt/dolphinscheduler/libs/kubernetes-model-metrics-5.10.2.jar:/opt/dolphinscheduler/libs/datasync-2.17.282.jar:/opt/dolphinscheduler/libs/hadoop-yarn-api-3.2.4.jar:/opt/dolphinscheduler/libs/google-http-client-apache-v2-1.42.3.jar:/opt/dolphinscheduler/libs/hadoop-annotations-3.2.4.jar:/opt/dolphinscheduler/libs/google-oauth-client-1.34.1.jar:/opt/dolphinscheduler/libs/sshd-common-2.8.0.jar:/opt/dolphinscheduler/libs/LatencyUtils-2.0.3.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-spark-3.2.1.jar:/opt/dolphinscheduler/libs/slf4j-api-1.7.36.jar:/opt/dolphinscheduler/libs/snowflake-jdbc-3.13.29.jar:/opt/dolphinscheduler/libs/jackson-datatype-jsr310-2.13.3.jar:/opt/dolphinscheduler/libs/trino-jdbc-402.jar:/opt/dolphinscheduler/libs/logging-interceptor-4.9.3.jar:/opt/dolphinscheduler/libs/simpleclient_tracer_otel_agent-0.15.0.jar:/opt/dolphinscheduler/libs/janino-3.0.16.jar:/opt/dolphinscheduler/libs/jackson-dataformat-yaml-2.13.3.jar:/opt/dolphinscheduler/libs/ion-java-1.0.2.jar:/opt/dolphinscheduler/libs/commons-dbcp-1.4.jar:/opt/dolphinscheduler/libs/jsp-api-2.1.jar:/opt/dolphinscheduler/libs/google-http-client-gson-1.42.3.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-hivecli-3.2.1.jar:/opt/dolphinscheduler/libs/spring-boot-actuator-2.7.3.jar:/opt/dolphinscheduler/libs/google-cloud-core-http-2.10.0.jar:/opt/dolphinscheduler/libs/DmJdbcDriver18-8.1.2.79.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-java-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-dameng-3.2.1.jar:/opt/dolphinscheduler/libs/sshd-sftp-2.8.0.jar:/opt/dolphinscheduler/libs/kerb-crypto-1.0.1.jar:/opt/dolphinscheduler/libs/conscrypt-openjdk-uber-2.5.2.jar:/opt/dolphinscheduler/libs/httpcore-4.4.15.jar:/opt/dolphinscheduler/libs/lz4-java-1.4.0.jar:/opt/dolphinscheduler/libs/guava-retrying-2.0.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-flink-stream-3.2.1.jar:/opt/dolphinscheduler/libs/spring-tx-5.3.22.jar:/opt/dolphinscheduler/libs/grpc-auth-1.41.0.jar:/opt/dolphinscheduler/libs/netty-tcnative-boringssl-static-2.0.53.Final-osx-x86_64.jar:/opt/dolphinscheduler/libs/databend-jdbc-0.0.7.jar:/opt/dolphinscheduler/libs/bcprov-jdk15on-1.69.jar:/opt/dolphinscheduler/libs/commons-lang-2.6.jar:/opt/dolphinscheduler/libs/kubernetes-model-policy-5.10.2.jar:/opt/dolphinscheduler/libs/commons-io-2.11.0.jar:/opt/dolphinscheduler/libs/grpc-grpclb-1.41.0.jar:/opt/dolphinscheduler/libs/netty-tcnative-boringssl-static-2.0.53.Final-linux-x86_64.jar:/opt/dolphinscheduler/libs/opentracing-api-0.33.0.jar:/opt/dolphinscheduler/libs/sshd-scp-2.8.0.jar:/opt/dolphinscheduler/libs/reload4j-1.2.18.3.jar:/opt/dolphinscheduler/libs/netty-tcnative-2.0.48.Final.jar:/opt/dolphinscheduler/libs/jdom2-2.0.6.1.jar:/opt/dolphinscheduler/libs/spring-boot-starter-json-2.7.3.jar:/opt/dolphinscheduler/libs/netty-transport-native-epoll-4.1.53.Final.jar:/opt/dolphinscheduler/libs/google-cloud-core-2.10.0.jar:/opt/dolphinscheduler/libs/javax.jdo-3.2.0-m3.jar:/opt/dolphinscheduler/libs/gax-httpjson-0.108.0.jar:/opt/dolphinscheduler/libs/mybatis-plus-core-3.5.2.jar:/opt/dolphinscheduler/libs/auto-service-annotations-1.0.1.jar:/opt/dolphinscheduler/libs/nimbus-jose-jwt-9.22.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-zeppelin-3.2.1.jar:/opt/dolphinscheduler/libs/commons-compress-1.21.jar:/opt/dolphinscheduler/libs/hadoop-hdfs-client-3.2.4.jar:/opt/dolphinscheduler/libs/msal4j-persistence-extension-1.1.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-pytorch-3.2.1.jar:/opt/dolphinscheduler/libs/netty-tcnative-boringssl-static-2.0.53.Final-windows-x86_64.jar:/opt/dolphinscheduler/libs/jetty-servlets-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/woodstox-core-6.4.0.jar:/opt/dolphinscheduler/libs/spring-cloud-kubernetes-commons-2.1.3.jar:/opt/dolphinscheduler/libs/grpc-protobuf-lite-1.41.0.jar:/opt/dolphinscheduler/libs/jetty-webapp-9.4.48.v20220622.jar:/opt/dolphinscheduler/libs/eventstream-1.0.1.jar:/opt/dolphinscheduler/libs/commons-compiler-3.1.7.jar:/opt/dolphinscheduler/libs/netty-transport-4.1.53.Final.jar:/opt/dolphinscheduler/libs/spring-cloud-context-3.1.3.jar:/opt/dolphinscheduler/libs/aws-java-sdk-dms-1.12.300.jar:/opt/dolphinscheduler/libs/hive-storage-api-2.4.0.jar:/opt/dolphinscheduler/libs/client-java-spring-integration-13.0.2.jar:/opt/dolphinscheduler/libs/spring-boot-starter-actuator-2.7.3.jar:/opt/dolphinscheduler/libs/third-party-jackson-core-2.17.282.jar:/opt/dolphinscheduler/libs/dolphinscheduler-storage-hdfs-3.2.1.jar:/opt/dolphinscheduler/libs/netty-codec-4.1.53.Final.jar:/opt/dolphinscheduler/libs/google-http-client-appengine-1.42.3.jar:/opt/dolphinscheduler/libs/commons-configuration2-2.1.1.jar:/opt/dolphinscheduler/libs/datanucleus-rdbms-4.1.19.jar:/opt/dolphinscheduler/libs/swagger-annotations-1.6.2.jar:/opt/dolphinscheduler/libs/simpleclient_tracer_otel-0.15.0.jar:/opt/dolphinscheduler/libs/kotlin-stdlib-common-1.6.21.jar:/opt/dolphinscheduler/libs/aws-core-2.17.282.jar:/opt/dolphinscheduler/libs/kerb-core-1.0.1.jar:/opt/dolphinscheduler/libs/httpasyncclient-4.1.5.jar:/opt/dolphinscheduler/libs/dolphinscheduler-extract-worker-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-spi-3.2.1.jar:/opt/dolphinscheduler/libs/okhttp-2.7.5.jar:/opt/dolphinscheduler/libs/google-api-client-2.2.0.jar:/opt/dolphinscheduler/libs/kotlin-stdlib-1.6.21.jar:/opt/dolphinscheduler/libs/jakarta.websocket-api-1.1.2.jar:/opt/dolphinscheduler/libs/libthrift-0.9.3.jar:/opt/dolphinscheduler/libs/spring-boot-starter-aop-2.7.3.jar:/opt/dolphinscheduler/libs/netty-common-4.1.53.Final.jar:/opt/dolphinscheduler/libs/log4j-1.2-api-2.17.2.jar:/opt/dolphinscheduler/libs/jackson-databind-2.13.4.jar:/opt/dolphinscheduler/libs/jackson-dataformat-xml-2.13.3.jar:/opt/dolphinscheduler/libs/kubernetes-model-events-5.10.2.jar:/opt/dolphinscheduler/libs/gson-2.9.1.jar:/opt/dolphinscheduler/libs/proto-google-iam-v1-1.9.0.jar:/opt/dolphinscheduler/libs/netty-codec-socks-4.1.53.Final.jar:/opt/dolphinscheduler/libs/zjsonpatch-0.3.0.jar:/opt/dolphinscheduler/libs/hadoop-mapreduce-client-common-3.2.4.jar:/opt/dolphinscheduler/libs/dolphinscheduler-registry-api-3.2.1.jar:/opt/dolphinscheduler/libs/azure-storage-blob-12.21.0.jar:/opt/dolphinscheduler/libs/dolphinscheduler-task-zeppelin-3.2.1.jar:/opt/dolphinscheduler/libs/dolphinscheduler-datasource-api-3.2.1.jar:/opt/dolphinscheduler/libs/aws-java-sdk-s3-1.12.300.jar:/opt/dolphinscheduler/libs/stax2-api-4.2.1.jar:/opt/dolphinscheduler/libs/jakarta.annotation-api-1.3.5.jar:/opt/dolphinscheduler/libs/kubernetes-model-discovery-5.10.2.jar:/opt/dolphinscheduler/libs/jna-5.10.0.jar:/opt/dolphinscheduler/libs/spring-jcl-5.3.22.jar
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:01.737 +0800 o.a.z.ZooKeeper:[98] - Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:01.737 +0800 o.a.z.ZooKeeper:[98] - Client environment:java.io.tmpdir=/tmp
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:01.737 +0800 o.a.z.ZooKeeper:[98] - Client environment:java.compiler=<NA>
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:01.738 +0800 o.a.z.ZooKeeper:[98] - Client environment:os.name=Linux
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:01.738 +0800 o.a.z.ZooKeeper:[98] - Client environment:os.arch=amd64
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:01.739 +0800 o.a.z.ZooKeeper:[98] - Client environment:os.version=6.5.0-28-generic
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:01.739 +0800 o.a.z.ZooKeeper:[98] - Client environment:user.name=root
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:01.739 +0800 o.a.z.ZooKeeper:[98] - Client environment:user.home=/root
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:01.740 +0800 o.a.z.ZooKeeper:[98] - Client environment:user.dir=/opt/dolphinscheduler
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:01.740 +0800 o.a.z.ZooKeeper:[98] - Client environment:os.memory.free=3213MB
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:01.740 +0800 o.a.z.ZooKeeper:[98] - Client environment:os.memory.max=3840MB
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:01.741 +0800 o.a.z.ZooKeeper:[98] - Client environment:os.memory.total=3840MB
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:01.744 +0800 o.a.z.ZooKeeper:[637] - Initiating client connection, connectString=dolphinscheduler-zookeeper:2181 sessionTimeout=30000 watcher=org.apache.curator.ConnectionState@1de08775
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:01.849 +0800 o.a.z.c.X509Util:[77] - Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:01.938 +0800 o.a.z.ClientCnxnSocket:[239] - jute.maxbuffer value is 1048575 Bytes
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:02.033 +0800 o.a.z.ClientCnxn:[1732] - zookeeper.request.timeout value is 0. feature enabled=false
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:02.269 +0800 o.a.c.f.i.CuratorFrameworkImpl:[386] - Default schema
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:02.646 +0800 o.a.z.ClientCnxn:[1171] - Opening socket connection to server dolphinscheduler-zookeeper/172.18.0.4:2181.
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:02.720 +0800 o.a.z.ClientCnxn:[1173] - SASL config status: Will not attempt to authenticate using SASL (unknown error)
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:02.758 +0800 o.a.z.ClientCnxn:[1005] - Socket connection established, initiating session, client: /172.18.1.1:43358, server: dolphinscheduler-zookeeper/172.18.0.4:2181
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:02.828 +0800 o.a.z.ClientCnxn:[1444] - Session establishment complete on server dolphinscheduler-zookeeper/172.18.0.4:2181, session id = 0x100008347ee0001, negotiated timeout = 30000
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:02.871 +0800 o.a.c.f.s.ConnectionStateManager:[252] - State change: CONNECTED
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:02.976 +0800 o.a.c.f.i.EnsembleTracker:[201] - New config event received: {}
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:03.212 +0800 o.a.c.f.i.EnsembleTracker:[201] - New config event received: {}
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:04.319 +0800 o.a.d.s.w.r.WorkerRpcServer:[41] - WorkerRpcServer starting...
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:04.926 +0800 o.a.d.e.b.NettyRemotingServer:[112] - WorkerRpcServer bind success at port: 1234
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:04.930 +0800 o.a.d.s.w.r.WorkerRpcServer:[43] - WorkerRpcServer started...
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:05.165 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: JAVA - JavaTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:05.170 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: JAVA - JavaTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:05.176 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: JUPYTER - JupyterTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:05.178 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: JUPYTER - JupyterTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:05.181 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: SPARK - SparkTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:05.191 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: SPARK - SparkTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:05.191 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: FLINK_STREAM - FlinkStreamTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:05.219 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: FLINK_STREAM - FlinkStreamTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:05.220 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: PYTHON - PythonTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:05.222 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: PYTHON - PythonTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:05.229 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: DATASYNC - DatasyncTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:05.231 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: DATASYNC - DatasyncTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:05.231 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: DATA_FACTORY - DatafactoryTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:05.232 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: DATA_FACTORY - DatafactoryTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:05.248 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: CHUNJUN - ChunJunTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:05.251 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: CHUNJUN - ChunJunTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:05.265 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: REMOTESHELL - RemoteShellTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:05.282 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: REMOTESHELL - RemoteShellTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:05.282 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: PIGEON - PigeonTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:05.284 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: PIGEON - PigeonTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:05.285 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: SHELL - ShellTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:05.287 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: SHELL - ShellTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:05.287 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: PROCEDURE - ProcedureTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:05.298 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: PROCEDURE - ProcedureTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:05.299 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: MR - MapReduceTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:05.300 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: MR - MapReduceTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:05.301 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: SQOOP - SqoopTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:05.304 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: SQOOP - SqoopTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:05.324 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: PYTORCH - PytorchTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:05.334 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: PYTORCH - PytorchTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:05.340 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: K8S - K8sTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:05.353 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: K8S - K8sTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:05.354 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: SEATUNNEL - SeatunnelTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:05.413 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: SEATUNNEL - SeatunnelTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:05.415 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: SAGEMAKER - SagemakerTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:05.418 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: SAGEMAKER - SagemakerTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:05.427 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: HTTP - HttpTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:05.440 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: HTTP - HttpTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:05.483 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: EMR - EmrTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:05.502 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: EMR - EmrTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:05.520 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: DMS - DmsTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:05.524 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: DMS - DmsTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:05.525 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: DATA_QUALITY - DataQualityTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:05.527 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: DATA_QUALITY - DataQualityTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:05.527 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: KUBEFLOW - KubeflowTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:05.528 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: KUBEFLOW - KubeflowTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:05.548 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: SQL - SqlTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:05.560 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: SQL - SqlTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:05.561 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: DVC - DvcTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:05.565 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: DVC - DvcTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:05.566 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: DATAX - DataxTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:05.574 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: DATAX - DataxTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:05.585 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: ZEPPELIN - ZeppelinTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:05.592 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: ZEPPELIN - ZeppelinTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:05.593 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: DINKY - DinkyTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:05.612 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: DINKY - DinkyTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:05.613 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: MLFLOW - MlflowTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:05.616 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: MLFLOW - MlflowTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:05.617 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: OPENMLDB - OpenmldbTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:05.619 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: OPENMLDB - OpenmldbTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:05.620 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: LINKIS - LinkisTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:05.623 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: LINKIS - LinkisTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:05.625 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: FLINK - FlinkTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:05.627 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: FLINK - FlinkTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:05.627 +0800 o.a.d.p.t.a.TaskPluginManager:[63] - Registering task plugin: HIVECLI - HiveCliTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:05.644 +0800 o.a.d.p.t.a.TaskPluginManager:[68] - Registered task plugin: HIVECLI - HiveCliTaskChannelFactory
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:05.821 +0800 o.a.d.c.u.JSONUtils:[72] - init timezone: sun.util.calendar.ZoneInfo[id="Asia/Shanghai",offset=28800000,dstSavings=0,useDaylight=false,transitions=31,lastRule=null]
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:06.203 +0800 o.a.d.s.w.r.WorkerRegistryClient:[104] - Worker node: 172.18.1.1:1234 registry to ZK /nodes/worker/172.18.1.1:1234 successfully
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:07.239 +0800 o.a.d.c.m.BaseHeartBeatTask:[48] - Starting WorkerHeartBeatTask...
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:07.272 +0800 o.a.d.c.m.BaseHeartBeatTask:[50] - Started WorkerHeartBeatTask, heartBeatInterval: 10000...
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:07.273 +0800 o.a.d.s.w.r.WorkerRegistryClient:[114] - Worker node: 172.18.1.1:1234 registry finished
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:07.275 +0800 o.a.d.s.w.m.MessageRetryRunner:[69] - Message retry runner staring
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:07.322 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.1111111111111112 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:07.542 +0800 o.a.d.s.w.m.MessageRetryRunner:[72] - Injected message sender: TaskInstanceExecutionFinishEventSender
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:07.563 +0800 o.a.d.s.w.m.MessageRetryRunner:[72] - Injected message sender: TaskInstanceExecutionInfoUpdateEventSender
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:07.563 +0800 o.a.d.s.w.m.MessageRetryRunner:[72] - Injected message sender: TaskInstanceExecutionRunningEventSender
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:07.565 +0800 o.a.d.s.w.m.MessageRetryRunner:[75] - Message retry runner started
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:08.421 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.4578313253012047 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:09.453 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.6283185840707963 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:10.459 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.8837209302325582 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:11.833 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.2724252491694352 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:13.096 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 2.0 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:14.260 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.6608695652173915 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:15.273 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.8712871287128712 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:16.369 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.7439024390243902 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:16.919 +0800 o.s.b.a.e.w.EndpointLinksResolver:[58] - Exposing 3 endpoint(s) beneath base path '/actuator'
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:17.405 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.4482758620689655 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:17.283 +0800 o.e.j.s.h.C.application:[2368] - Initializing Spring DispatcherServlet 'dispatcherServlet'
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:17.432 +0800 o.s.w.s.DispatcherServlet:[525] - Initializing Servlet 'dispatcherServlet'
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:17.458 +0800 o.s.w.s.DispatcherServlet:[547] - Completed initialization in 24 ms
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:17.492 +0800 o.e.j.s.AbstractConnector:[333] - Started ServerConnector@1f45db49{HTTP/1.1, (http/1.1)}{0.0.0.0:1235}
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:17.509 +0800 o.s.b.w.e.j.JettyWebServer:[172] - Jetty started on port(s) 1235 (http/1.1) with context path '/'
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:17.706 +0800 o.a.d.s.w.WorkerServer:[61] - Started WorkerServer in 48.325 seconds (JVM running for 52.393)
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:18.546 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.4408602150537635 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:19.558 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.1451612903225805 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:20.564 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9869281045751634 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:21.588 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9956711558383898 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:22.601 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9925234422682129 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:23.605 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8953488372093023 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:24.861 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9384615384615385 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:25.865 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.961038961038961 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:26.918 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9728260869565217 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:27.975 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.0199004975124377 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:29.060 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.143859160163508 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:34.273 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7723214285714285 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:35.414 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8894736842105264 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 06:04:37.443 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.710237537638006 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 06:07:42.941 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7172413793103448 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 06:08:09.330 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7106017191977078 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 06:08:14.362 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8205128205128205 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 06:08:19.404 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7328990228013029 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 06:08:27.508 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.943342776203966 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 06:08:28.530 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8449848024316109 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 06:08:33.588 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8478260869565217 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 06:08:35.636 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7287671232876712 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 06:08:46.710 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.813953488372093 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 06:08:47.136 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1317, taskName=search for intake JSON files, firstSubmitTime=1713910126396, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.9:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=94, appIds=null, processInstanceId=554, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"processing"}], executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":""}],"rawScript":"# find 1 raw file in the folder\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\n\n# check if raw_file_dir is empty, then set raw_file_dir to null\nif [ -z \"$raw_file_dir\" ]; then\n    raw_file_dir=null\nfi\n\necho \"#{setValue(raw_file_dir=${raw_file_dir})}\"","resourceList":[]}, environmentConfig=export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='search for intake JSON files'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240424'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1317'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13340113777664'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240424060846'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='processing'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='554'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240423'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=null, dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-554][TI-1317] - [INFO] 2024-04-24 06:08:47.241 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: search for intake JSON files to wait queue success
[WI-554][TI-1317] - [INFO] 2024-04-24 06:08:47.250 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-554][TI-1317] - [INFO] 2024-04-24 06:08:47.260 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-554][TI-1317] - [INFO] 2024-04-24 06:08:47.261 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-554][TI-1317] - [INFO] 2024-04-24 06:08:47.263 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-554][TI-1317] - [INFO] 2024-04-24 06:08:47.264 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713910127264
[WI-554][TI-1317] - [INFO] 2024-04-24 06:08:47.265 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 554_1317
[WI-554][TI-1317] - [INFO] 2024-04-24 06:08:47.273 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1317,
  "taskName" : "search for intake JSON files",
  "firstSubmitTime" : 1713910126396,
  "startTime" : 1713910127264,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.9:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240424/13201021801792/94/554/1317.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 94,
  "processInstanceId" : 554,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"processing\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[{\"prop\":\"raw_file_dir\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"\"}],\"rawScript\":\"# find 1 raw file in the folder\\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\\n\\n# check if raw_file_dir is empty, then set raw_file_dir to null\\nif [ -z \\\"$raw_file_dir\\\" ]; then\\n    raw_file_dir=null\\nfi\\n\\necho \\\"#{setValue(raw_file_dir=${raw_file_dir})}\\\"\",\"resourceList\":[]}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "search for intake JSON files"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240424"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1317"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13340113777664"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240424060846"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "processing"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "554"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "554_1317",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-554][TI-1317] - [INFO] 2024-04-24 06:08:47.277 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-554][TI-1317] - [INFO] 2024-04-24 06:08:47.280 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-554][TI-1317] - [INFO] 2024-04-24 06:08:47.281 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-554][TI-1317] - [INFO] 2024-04-24 06:08:47.565 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-554][TI-1317] - [INFO] 2024-04-24 06:08:47.675 +0800 o.a.d.c.u.OSUtils:[231] - create linux os user: default
[WI-554][TI-1317] - [INFO] 2024-04-24 06:08:47.677 +0800 o.a.d.c.u.OSUtils:[233] - execute cmd: sudo useradd -g root
 default
[WI-0][TI-0] - [INFO] 2024-04-24 06:08:47.761 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.2668810289389068 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-554][TI-1317] - [INFO] 2024-04-24 06:08:47.919 +0800 o.a.d.c.u.OSUtils:[190] - create user default success
[WI-554][TI-1317] - [INFO] 2024-04-24 06:08:47.921 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-554][TI-1317] - [INFO] 2024-04-24 06:08:47.948 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_94/554/1317 check successfully
[WI-554][TI-1317] - [INFO] 2024-04-24 06:08:47.950 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-554][TI-1317] - [INFO] 2024-04-24 06:08:47.975 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-554][TI-1317] - [INFO] 2024-04-24 06:08:48.048 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-554][TI-1317] - [INFO] 2024-04-24 06:08:48.070 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-554][TI-1317] - [INFO] 2024-04-24 06:08:48.102 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ {
    "prop" : "raw_file_dir",
    "direct" : "OUT",
    "type" : "VARCHAR",
    "value" : ""
  } ],
  "varPool" : null,
  "rawScript" : "# find 1 raw file in the folder\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\n\n# check if raw_file_dir is empty, then set raw_file_dir to null\nif [ -z \"$raw_file_dir\" ]; then\n    raw_file_dir=null\nfi\n\necho \"#{setValue(raw_file_dir=${raw_file_dir})}\"",
  "resourceList" : [ ]
}
[WI-554][TI-1317] - [INFO] 2024-04-24 06:08:48.110 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-554][TI-1317] - [INFO] 2024-04-24 06:08:48.111 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: null successfully
[WI-554][TI-1317] - [INFO] 2024-04-24 06:08:48.152 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-554][TI-1317] - [INFO] 2024-04-24 06:08:48.153 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-554][TI-1317] - [INFO] 2024-04-24 06:08:48.154 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-0][TI-1317] - [INFO] 2024-04-24 06:08:48.175 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1317, success=true)
[WI-554][TI-1317] - [INFO] 2024-04-24 06:08:48.191 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-554][TI-1317] - [INFO] 2024-04-24 06:08:48.192 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-554][TI-1317] - [INFO] 2024-04-24 06:08:48.193 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export PYTHON_LAUNCHER=/bin/python3.11
# find 1 raw file in the folder
raw_file_dir=$(find /local_storage/reddit/processing -type f -name '*.json'| head -n 1)

# check if raw_file_dir is empty, then set raw_file_dir to null
if [ -z "$raw_file_dir" ]; then
    raw_file_dir=null
fi

echo "#{setValue(raw_file_dir=${raw_file_dir})}"
[WI-554][TI-1317] - [INFO] 2024-04-24 06:08:48.194 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-554][TI-1317] - [INFO] 2024-04-24 06:08:48.199 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_94/554/1317/554_1317.sh
[WI-554][TI-1317] - [INFO] 2024-04-24 06:08:48.224 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 137
[WI-0][TI-0] - [INFO] 2024-04-24 06:08:48.770 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 1.0471380471380471 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-1317] - [INFO] 2024-04-24 06:08:49.083 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1317)
[WI-0][TI-0] - [INFO] 2024-04-24 06:08:49.230 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
	#{setValue(raw_file_dir=/local_storage/reddit/processing/500-20240423.json)}
[WI-554][TI-1317] - [INFO] 2024-04-24 06:08:49.241 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_94/554/1317, processId:137 ,exitStatusCode:0 ,processWaitForStatus:true ,processExitValue:0
[WI-554][TI-1317] - [INFO] 2024-04-24 06:08:49.243 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-554][TI-1317] - [INFO] 2024-04-24 06:08:49.244 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-554][TI-1317] - [INFO] 2024-04-24 06:08:49.244 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-554][TI-1317] - [INFO] 2024-04-24 06:08:49.247 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-554][TI-1317] - [INFO] 2024-04-24 06:08:49.300 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: SUCCESS to master : 172.18.1.1:1234
[WI-554][TI-1317] - [INFO] 2024-04-24 06:08:49.315 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-554][TI-1317] - [INFO] 2024-04-24 06:08:49.316 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_94/554/1317
[WI-554][TI-1317] - [INFO] 2024-04-24 06:08:49.378 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_94/554/1317
[WI-554][TI-1317] - [INFO] 2024-04-24 06:08:49.419 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-0] - [INFO] 2024-04-24 06:08:49.772 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7411764705882352 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-1317] - [INFO] 2024-04-24 06:08:50.118 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1317, success=true)
[WI-0][TI-0] - [INFO] 2024-04-24 06:08:50.776 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7987616099071208 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 06:09:31.906 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7207207207207207 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 06:09:33.618 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1320, taskName=search for intake JSON files, firstSubmitTime=1713910173608, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.9:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=94, appIds=null, processInstanceId=555, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"in"}], executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":""}],"rawScript":"# find 1 raw file in the folder\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\n\n# check if raw_file_dir is empty, then set raw_file_dir to null\nif [ -z \"$raw_file_dir\" ]; then\n    raw_file_dir=null\nfi\n\necho \"#{setValue(raw_file_dir=${raw_file_dir})}\"","resourceList":[]}, environmentConfig=export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='search for intake JSON files'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240424'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1320'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13340113777664'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240424060933'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='in'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='555'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240423'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=null, dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-555][TI-1320] - [INFO] 2024-04-24 06:09:33.620 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: search for intake JSON files to wait queue success
[WI-555][TI-1320] - [INFO] 2024-04-24 06:09:33.620 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-555][TI-1320] - [INFO] 2024-04-24 06:09:33.626 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-555][TI-1320] - [INFO] 2024-04-24 06:09:33.627 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-555][TI-1320] - [INFO] 2024-04-24 06:09:33.628 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-555][TI-1320] - [INFO] 2024-04-24 06:09:33.629 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713910173629
[WI-555][TI-1320] - [INFO] 2024-04-24 06:09:33.629 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 555_1320
[WI-555][TI-1320] - [INFO] 2024-04-24 06:09:33.631 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1320,
  "taskName" : "search for intake JSON files",
  "firstSubmitTime" : 1713910173608,
  "startTime" : 1713910173629,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.9:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240424/13201021801792/94/555/1320.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 94,
  "processInstanceId" : 555,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"in\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[{\"prop\":\"raw_file_dir\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"\"}],\"rawScript\":\"# find 1 raw file in the folder\\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\\n\\n# check if raw_file_dir is empty, then set raw_file_dir to null\\nif [ -z \\\"$raw_file_dir\\\" ]; then\\n    raw_file_dir=null\\nfi\\n\\necho \\\"#{setValue(raw_file_dir=${raw_file_dir})}\\\"\",\"resourceList\":[]}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "search for intake JSON files"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240424"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1320"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13340113777664"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240424060933"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "in"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "555"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "555_1320",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-555][TI-1320] - [INFO] 2024-04-24 06:09:33.631 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-555][TI-1320] - [INFO] 2024-04-24 06:09:33.632 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-555][TI-1320] - [INFO] 2024-04-24 06:09:33.632 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-555][TI-1320] - [INFO] 2024-04-24 06:09:33.641 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-555][TI-1320] - [INFO] 2024-04-24 06:09:33.641 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-555][TI-1320] - [INFO] 2024-04-24 06:09:33.642 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_94/555/1320 check successfully
[WI-555][TI-1320] - [INFO] 2024-04-24 06:09:33.642 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-555][TI-1320] - [INFO] 2024-04-24 06:09:33.642 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-555][TI-1320] - [INFO] 2024-04-24 06:09:33.643 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-555][TI-1320] - [INFO] 2024-04-24 06:09:33.643 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-555][TI-1320] - [INFO] 2024-04-24 06:09:33.644 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ {
    "prop" : "raw_file_dir",
    "direct" : "OUT",
    "type" : "VARCHAR",
    "value" : ""
  } ],
  "varPool" : null,
  "rawScript" : "# find 1 raw file in the folder\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\n\n# check if raw_file_dir is empty, then set raw_file_dir to null\nif [ -z \"$raw_file_dir\" ]; then\n    raw_file_dir=null\nfi\n\necho \"#{setValue(raw_file_dir=${raw_file_dir})}\"",
  "resourceList" : [ ]
}
[WI-555][TI-1320] - [INFO] 2024-04-24 06:09:33.644 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-555][TI-1320] - [INFO] 2024-04-24 06:09:33.644 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: null successfully
[WI-555][TI-1320] - [INFO] 2024-04-24 06:09:33.644 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-555][TI-1320] - [INFO] 2024-04-24 06:09:33.644 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-555][TI-1320] - [INFO] 2024-04-24 06:09:33.644 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-555][TI-1320] - [INFO] 2024-04-24 06:09:33.644 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-555][TI-1320] - [INFO] 2024-04-24 06:09:33.645 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-555][TI-1320] - [INFO] 2024-04-24 06:09:33.645 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export PYTHON_LAUNCHER=/bin/python3.11
# find 1 raw file in the folder
raw_file_dir=$(find /local_storage/reddit/in -type f -name '*.json'| head -n 1)

# check if raw_file_dir is empty, then set raw_file_dir to null
if [ -z "$raw_file_dir" ]; then
    raw_file_dir=null
fi

echo "#{setValue(raw_file_dir=${raw_file_dir})}"
[WI-555][TI-1320] - [INFO] 2024-04-24 06:09:33.645 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-555][TI-1320] - [INFO] 2024-04-24 06:09:33.645 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_94/555/1320/555_1320.sh
[WI-555][TI-1320] - [INFO] 2024-04-24 06:09:33.654 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 166
[WI-0][TI-1320] - [INFO] 2024-04-24 06:09:34.156 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1320, success=true)
[WI-0][TI-1320] - [INFO] 2024-04-24 06:09:34.169 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1320)
[WI-0][TI-0] - [INFO] 2024-04-24 06:09:34.657 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
	#{setValue(raw_file_dir=null)}
[WI-555][TI-1320] - [INFO] 2024-04-24 06:09:34.662 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_94/555/1320, processId:166 ,exitStatusCode:0 ,processWaitForStatus:true ,processExitValue:0
[WI-555][TI-1320] - [INFO] 2024-04-24 06:09:34.665 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-555][TI-1320] - [INFO] 2024-04-24 06:09:34.666 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-555][TI-1320] - [INFO] 2024-04-24 06:09:34.667 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-555][TI-1320] - [INFO] 2024-04-24 06:09:34.668 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-555][TI-1320] - [INFO] 2024-04-24 06:09:34.674 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: SUCCESS to master : 172.18.1.1:1234
[WI-555][TI-1320] - [INFO] 2024-04-24 06:09:34.674 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-555][TI-1320] - [INFO] 2024-04-24 06:09:34.674 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_94/555/1320
[WI-555][TI-1320] - [INFO] 2024-04-24 06:09:34.675 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_94/555/1320
[WI-555][TI-1320] - [INFO] 2024-04-24 06:09:34.676 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-1320] - [INFO] 2024-04-24 06:09:35.184 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1320, success=true)
[WI-0][TI-0] - [INFO] 2024-04-24 06:09:35.976 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.723404255319149 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 06:09:36.364 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1322, taskName=end workflow, firstSubmitTime=1713910176353, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.9:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=94, appIds=null, processInstanceId=555, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"in"}], executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[],"rawScript":"echo No Files Detected - End Workflow","resourceList":[]}, environmentConfig=export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='end workflow'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240424'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1322'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13348985859488'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240424060936'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='in'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='555'}, raw_file_dir=Property{prop='raw_file_dir', direct=IN, type=VARCHAR, value='null'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240423'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"null"}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-555][TI-1322] - [INFO] 2024-04-24 06:09:36.366 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: end workflow to wait queue success
[WI-555][TI-1322] - [INFO] 2024-04-24 06:09:36.366 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-555][TI-1322] - [INFO] 2024-04-24 06:09:36.369 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-555][TI-1322] - [INFO] 2024-04-24 06:09:36.369 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-555][TI-1322] - [INFO] 2024-04-24 06:09:36.369 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-555][TI-1322] - [INFO] 2024-04-24 06:09:36.369 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713910176369
[WI-555][TI-1322] - [INFO] 2024-04-24 06:09:36.369 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 555_1322
[WI-555][TI-1322] - [INFO] 2024-04-24 06:09:36.369 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1322,
  "taskName" : "end workflow",
  "firstSubmitTime" : 1713910176353,
  "startTime" : 1713910176369,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.9:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240424/13201021801792/94/555/1322.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 94,
  "processInstanceId" : 555,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"in\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[],\"rawScript\":\"echo No Files Detected - End Workflow\",\"resourceList\":[]}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "end workflow"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240424"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1322"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13348985859488"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240424060936"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "in"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "555"
    },
    "raw_file_dir" : {
      "prop" : "raw_file_dir",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "null"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "555_1322",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"raw_file_dir\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"null\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-555][TI-1322] - [INFO] 2024-04-24 06:09:36.370 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-555][TI-1322] - [INFO] 2024-04-24 06:09:36.370 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-555][TI-1322] - [INFO] 2024-04-24 06:09:36.370 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-555][TI-1322] - [INFO] 2024-04-24 06:09:36.417 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-555][TI-1322] - [INFO] 2024-04-24 06:09:36.419 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-555][TI-1322] - [INFO] 2024-04-24 06:09:36.420 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_94/555/1322 check successfully
[WI-555][TI-1322] - [INFO] 2024-04-24 06:09:36.420 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-555][TI-1322] - [INFO] 2024-04-24 06:09:36.420 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-555][TI-1322] - [INFO] 2024-04-24 06:09:36.421 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-555][TI-1322] - [INFO] 2024-04-24 06:09:36.421 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-555][TI-1322] - [INFO] 2024-04-24 06:09:36.422 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ ],
  "varPool" : null,
  "rawScript" : "echo No Files Detected - End Workflow",
  "resourceList" : [ ]
}
[WI-555][TI-1322] - [INFO] 2024-04-24 06:09:36.422 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-555][TI-1322] - [INFO] 2024-04-24 06:09:36.426 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"null"}] successfully
[WI-555][TI-1322] - [INFO] 2024-04-24 06:09:36.428 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-555][TI-1322] - [INFO] 2024-04-24 06:09:36.428 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-555][TI-1322] - [INFO] 2024-04-24 06:09:36.428 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-555][TI-1322] - [INFO] 2024-04-24 06:09:36.429 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-555][TI-1322] - [INFO] 2024-04-24 06:09:36.429 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-555][TI-1322] - [INFO] 2024-04-24 06:09:36.430 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export PYTHON_LAUNCHER=/bin/python3.11
echo No Files Detected - End Workflow
[WI-555][TI-1322] - [INFO] 2024-04-24 06:09:36.430 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-555][TI-1322] - [INFO] 2024-04-24 06:09:36.430 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_94/555/1322/555_1322.sh
[WI-555][TI-1322] - [INFO] 2024-04-24 06:09:36.438 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 182
[WI-0][TI-1322] - [INFO] 2024-04-24 06:09:37.181 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1322, success=true)
[WI-0][TI-1322] - [INFO] 2024-04-24 06:09:37.198 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1322)
[WI-0][TI-0] - [INFO] 2024-04-24 06:09:37.439 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
	No Files Detected - End Workflow
[WI-555][TI-1322] - [INFO] 2024-04-24 06:09:37.440 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_94/555/1322, processId:182 ,exitStatusCode:0 ,processWaitForStatus:true ,processExitValue:0
[WI-555][TI-1322] - [INFO] 2024-04-24 06:09:37.440 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-555][TI-1322] - [INFO] 2024-04-24 06:09:37.440 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-555][TI-1322] - [INFO] 2024-04-24 06:09:37.440 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-555][TI-1322] - [INFO] 2024-04-24 06:09:37.441 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-555][TI-1322] - [INFO] 2024-04-24 06:09:37.451 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: SUCCESS to master : 172.18.1.1:1234
[WI-555][TI-1322] - [INFO] 2024-04-24 06:09:37.452 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-555][TI-1322] - [INFO] 2024-04-24 06:09:37.452 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_94/555/1322
[WI-555][TI-1322] - [INFO] 2024-04-24 06:09:37.454 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_94/555/1322
[WI-555][TI-1322] - [INFO] 2024-04-24 06:09:37.455 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-1322] - [INFO] 2024-04-24 06:09:38.185 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1322, success=true)
[WI-0][TI-0] - [INFO] 2024-04-24 06:09:41.015 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7357357357357357 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 06:09:46.727 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1323, taskName=search for intake JSON files, firstSubmitTime=1713910186696, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.9:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=94, appIds=null, processInstanceId=556, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"processing"}], executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":""}],"rawScript":"# find 1 raw file in the folder\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\n\n# check if raw_file_dir is empty, then set raw_file_dir to null\nif [ -z \"$raw_file_dir\" ]; then\n    raw_file_dir=null\nfi\n\necho \"#{setValue(raw_file_dir=${raw_file_dir})}\"","resourceList":[]}, environmentConfig=export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='search for intake JSON files'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240424'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1323'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13340113777664'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240424060946'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='processing'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='556'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240423'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=null, dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-556][TI-1323] - [INFO] 2024-04-24 06:09:46.730 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: search for intake JSON files to wait queue success
[WI-556][TI-1323] - [INFO] 2024-04-24 06:09:46.732 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-556][TI-1323] - [INFO] 2024-04-24 06:09:46.736 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-556][TI-1323] - [INFO] 2024-04-24 06:09:46.736 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-556][TI-1323] - [INFO] 2024-04-24 06:09:46.736 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-556][TI-1323] - [INFO] 2024-04-24 06:09:46.736 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713910186736
[WI-556][TI-1323] - [INFO] 2024-04-24 06:09:46.736 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 556_1323
[WI-556][TI-1323] - [INFO] 2024-04-24 06:09:46.738 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1323,
  "taskName" : "search for intake JSON files",
  "firstSubmitTime" : 1713910186696,
  "startTime" : 1713910186736,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.9:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240424/13201021801792/94/556/1323.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 94,
  "processInstanceId" : 556,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"processing\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[{\"prop\":\"raw_file_dir\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"\"}],\"rawScript\":\"# find 1 raw file in the folder\\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\\n\\n# check if raw_file_dir is empty, then set raw_file_dir to null\\nif [ -z \\\"$raw_file_dir\\\" ]; then\\n    raw_file_dir=null\\nfi\\n\\necho \\\"#{setValue(raw_file_dir=${raw_file_dir})}\\\"\",\"resourceList\":[]}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "search for intake JSON files"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240424"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1323"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13340113777664"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240424060946"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "processing"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "556"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "556_1323",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-556][TI-1323] - [INFO] 2024-04-24 06:09:46.739 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-556][TI-1323] - [INFO] 2024-04-24 06:09:46.739 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-556][TI-1323] - [INFO] 2024-04-24 06:09:46.739 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-556][TI-1323] - [INFO] 2024-04-24 06:09:46.747 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-556][TI-1323] - [INFO] 2024-04-24 06:09:46.749 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-556][TI-1323] - [INFO] 2024-04-24 06:09:46.750 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_94/556/1323 check successfully
[WI-556][TI-1323] - [INFO] 2024-04-24 06:09:46.751 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-556][TI-1323] - [INFO] 2024-04-24 06:09:46.751 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-556][TI-1323] - [INFO] 2024-04-24 06:09:46.752 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-556][TI-1323] - [INFO] 2024-04-24 06:09:46.753 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-556][TI-1323] - [INFO] 2024-04-24 06:09:46.753 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ {
    "prop" : "raw_file_dir",
    "direct" : "OUT",
    "type" : "VARCHAR",
    "value" : ""
  } ],
  "varPool" : null,
  "rawScript" : "# find 1 raw file in the folder\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\n\n# check if raw_file_dir is empty, then set raw_file_dir to null\nif [ -z \"$raw_file_dir\" ]; then\n    raw_file_dir=null\nfi\n\necho \"#{setValue(raw_file_dir=${raw_file_dir})}\"",
  "resourceList" : [ ]
}
[WI-556][TI-1323] - [INFO] 2024-04-24 06:09:46.754 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-556][TI-1323] - [INFO] 2024-04-24 06:09:46.754 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: null successfully
[WI-556][TI-1323] - [INFO] 2024-04-24 06:09:46.754 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-556][TI-1323] - [INFO] 2024-04-24 06:09:46.755 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-556][TI-1323] - [INFO] 2024-04-24 06:09:46.755 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-556][TI-1323] - [INFO] 2024-04-24 06:09:46.756 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-556][TI-1323] - [INFO] 2024-04-24 06:09:46.756 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-556][TI-1323] - [INFO] 2024-04-24 06:09:46.757 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export PYTHON_LAUNCHER=/bin/python3.11
# find 1 raw file in the folder
raw_file_dir=$(find /local_storage/reddit/processing -type f -name '*.json'| head -n 1)

# check if raw_file_dir is empty, then set raw_file_dir to null
if [ -z "$raw_file_dir" ]; then
    raw_file_dir=null
fi

echo "#{setValue(raw_file_dir=${raw_file_dir})}"
[WI-556][TI-1323] - [INFO] 2024-04-24 06:09:46.757 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-556][TI-1323] - [INFO] 2024-04-24 06:09:46.757 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_94/556/1323/556_1323.sh
[WI-556][TI-1323] - [INFO] 2024-04-24 06:09:46.768 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 193
[WI-0][TI-1323] - [INFO] 2024-04-24 06:09:47.176 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1323, success=true)
[WI-0][TI-1323] - [INFO] 2024-04-24 06:09:47.215 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1323)
[WI-0][TI-0] - [INFO] 2024-04-24 06:09:47.770 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
	#{setValue(raw_file_dir=/local_storage/reddit/processing/500-20240423.json)}
[WI-556][TI-1323] - [INFO] 2024-04-24 06:09:47.772 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_94/556/1323, processId:193 ,exitStatusCode:0 ,processWaitForStatus:true ,processExitValue:0
[WI-556][TI-1323] - [INFO] 2024-04-24 06:09:47.773 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-556][TI-1323] - [INFO] 2024-04-24 06:09:47.773 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-556][TI-1323] - [INFO] 2024-04-24 06:09:47.773 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-556][TI-1323] - [INFO] 2024-04-24 06:09:47.774 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-556][TI-1323] - [INFO] 2024-04-24 06:09:47.784 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: SUCCESS to master : 172.18.1.1:1234
[WI-556][TI-1323] - [INFO] 2024-04-24 06:09:47.785 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-556][TI-1323] - [INFO] 2024-04-24 06:09:47.785 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_94/556/1323
[WI-556][TI-1323] - [INFO] 2024-04-24 06:09:47.786 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_94/556/1323
[WI-556][TI-1323] - [INFO] 2024-04-24 06:09:47.787 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-0] - [INFO] 2024-04-24 06:09:48.069 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7352112676056337 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-1323] - [INFO] 2024-04-24 06:09:48.175 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1323, success=true)
[WI-0][TI-0] - [INFO] 2024-04-24 06:09:49.347 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1325, taskName=move to processing, firstSubmitTime=1713910189318, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.9:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=94, appIds=null, processInstanceId=556, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"processing"}], executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":""}],"rawScript":"# move file to the reddit processing folder\n# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error\nfilename=$(basename \"${raw_file_dir}\")\nif ! grep -q \"${REDDIT_HOME}/processing\" <<< \"${raw_file_dir}\"; then\n    mv ${raw_file_dir} ${REDDIT_HOME}/processing\nelse\n    echo JSON is already in processing\nfi\n\n# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing\necho \"#{setValue(raw_file_dir=${REDDIT_HOME}/processing/${filename})}\"","resourceList":[]}, environmentConfig=export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='move to processing'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240424'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1325'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13340390094208'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240424060949'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='processing'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='556'}, raw_file_dir=Property{prop='raw_file_dir', direct=IN, type=VARCHAR, value='/local_storage/reddit/processing/500-20240423.json'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240423'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-556][TI-1325] - [INFO] 2024-04-24 06:09:49.348 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: move to processing to wait queue success
[WI-556][TI-1325] - [INFO] 2024-04-24 06:09:49.349 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-556][TI-1325] - [INFO] 2024-04-24 06:09:49.350 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-556][TI-1325] - [INFO] 2024-04-24 06:09:49.351 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-556][TI-1325] - [INFO] 2024-04-24 06:09:49.351 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-556][TI-1325] - [INFO] 2024-04-24 06:09:49.351 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713910189351
[WI-556][TI-1325] - [INFO] 2024-04-24 06:09:49.351 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 556_1325
[WI-556][TI-1325] - [INFO] 2024-04-24 06:09:49.352 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1325,
  "taskName" : "move to processing",
  "firstSubmitTime" : 1713910189318,
  "startTime" : 1713910189351,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.9:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240424/13201021801792/94/556/1325.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 94,
  "processInstanceId" : 556,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"processing\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[{\"prop\":\"raw_file_dir\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"\"}],\"rawScript\":\"# move file to the reddit processing folder\\n# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error\\nfilename=$(basename \\\"${raw_file_dir}\\\")\\nif ! grep -q \\\"${REDDIT_HOME}/processing\\\" <<< \\\"${raw_file_dir}\\\"; then\\n    mv ${raw_file_dir} ${REDDIT_HOME}/processing\\nelse\\n    echo JSON is already in processing\\nfi\\n\\n# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing\\necho \\\"#{setValue(raw_file_dir=${REDDIT_HOME}/processing/${filename})}\\\"\",\"resourceList\":[]}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "move to processing"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240424"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1325"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13340390094208"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240424060949"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "processing"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "556"
    },
    "raw_file_dir" : {
      "prop" : "raw_file_dir",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit/processing/500-20240423.json"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "556_1325",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"raw_file_dir\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"/local_storage/reddit/processing/500-20240423.json\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-556][TI-1325] - [INFO] 2024-04-24 06:09:49.353 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-556][TI-1325] - [INFO] 2024-04-24 06:09:49.354 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-556][TI-1325] - [INFO] 2024-04-24 06:09:49.354 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-556][TI-1325] - [INFO] 2024-04-24 06:09:49.359 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-556][TI-1325] - [INFO] 2024-04-24 06:09:49.364 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-556][TI-1325] - [INFO] 2024-04-24 06:09:49.365 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_94/556/1325 check successfully
[WI-556][TI-1325] - [INFO] 2024-04-24 06:09:49.365 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-556][TI-1325] - [INFO] 2024-04-24 06:09:49.365 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-556][TI-1325] - [INFO] 2024-04-24 06:09:49.366 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-556][TI-1325] - [INFO] 2024-04-24 06:09:49.370 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-556][TI-1325] - [INFO] 2024-04-24 06:09:49.371 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ {
    "prop" : "raw_file_dir",
    "direct" : "OUT",
    "type" : "VARCHAR",
    "value" : ""
  } ],
  "varPool" : null,
  "rawScript" : "# move file to the reddit processing folder\n# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error\nfilename=$(basename \"${raw_file_dir}\")\nif ! grep -q \"${REDDIT_HOME}/processing\" <<< \"${raw_file_dir}\"; then\n    mv ${raw_file_dir} ${REDDIT_HOME}/processing\nelse\n    echo JSON is already in processing\nfi\n\n# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing\necho \"#{setValue(raw_file_dir=${REDDIT_HOME}/processing/${filename})}\"",
  "resourceList" : [ ]
}
[WI-556][TI-1325] - [INFO] 2024-04-24 06:09:49.371 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-556][TI-1325] - [INFO] 2024-04-24 06:09:49.371 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}] successfully
[WI-556][TI-1325] - [INFO] 2024-04-24 06:09:49.371 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-556][TI-1325] - [INFO] 2024-04-24 06:09:49.371 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-556][TI-1325] - [INFO] 2024-04-24 06:09:49.371 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-556][TI-1325] - [INFO] 2024-04-24 06:09:49.373 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-556][TI-1325] - [INFO] 2024-04-24 06:09:49.373 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-556][TI-1325] - [INFO] 2024-04-24 06:09:49.385 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export PYTHON_LAUNCHER=/bin/python3.11
# move file to the reddit processing folder
# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error
filename=$(basename "/local_storage/reddit/processing/500-20240423.json")
if ! grep -q "/local_storage/reddit/processing" <<< "/local_storage/reddit/processing/500-20240423.json"; then
    mv /local_storage/reddit/processing/500-20240423.json /local_storage/reddit/processing
else
    echo JSON is already in processing
fi

# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing
echo "#{setValue(raw_file_dir=/local_storage/reddit/processing/${filename})}"
[WI-556][TI-1325] - [INFO] 2024-04-24 06:09:49.398 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-556][TI-1325] - [INFO] 2024-04-24 06:09:49.399 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_94/556/1325/556_1325.sh
[WI-556][TI-1325] - [INFO] 2024-04-24 06:09:49.403 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 206
[WI-0][TI-1325] - [INFO] 2024-04-24 06:09:50.184 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1325, success=true)
[WI-0][TI-1325] - [INFO] 2024-04-24 06:09:50.193 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1325)
[WI-0][TI-0] - [INFO] 2024-04-24 06:09:50.404 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
	JSON is already in processing
	#{setValue(raw_file_dir=/local_storage/reddit/processing/500-20240423.json)}
[WI-556][TI-1325] - [INFO] 2024-04-24 06:09:50.412 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_94/556/1325, processId:206 ,exitStatusCode:0 ,processWaitForStatus:true ,processExitValue:0
[WI-556][TI-1325] - [INFO] 2024-04-24 06:09:50.412 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-556][TI-1325] - [INFO] 2024-04-24 06:09:50.412 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-556][TI-1325] - [INFO] 2024-04-24 06:09:50.413 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-556][TI-1325] - [INFO] 2024-04-24 06:09:50.414 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-556][TI-1325] - [INFO] 2024-04-24 06:09:50.418 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: SUCCESS to master : 172.18.1.1:1234
[WI-556][TI-1325] - [INFO] 2024-04-24 06:09:50.419 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-556][TI-1325] - [INFO] 2024-04-24 06:09:50.419 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_94/556/1325
[WI-556][TI-1325] - [INFO] 2024-04-24 06:09:50.420 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_94/556/1325
[WI-556][TI-1325] - [INFO] 2024-04-24 06:09:50.420 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-1325] - [INFO] 2024-04-24 06:09:51.175 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1325, success=true)
[WI-0][TI-0] - [INFO] 2024-04-24 06:09:51.242 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1326, taskName=spark preprocessing, firstSubmitTime=1713910191232, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.9:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=94, appIds=null, processInstanceId=556, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"processing"}], executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[],"rawScript":"$SPARK_HOME/bin/spark-submit \\\n    --master spark://spark-master:7077 \\\n    --deploy-mode client \\\n    --conf spark.driver.cores=1 \\\n    --conf spark.driver.memory=1G \\\n    --conf spark.executor.instances=1 \\\n    --conf spark.executor.cores=1 \\\n    --conf spark.executor.memory=1G \\\n    --name reddit_preprocessing \\\n    testing.py\n\n# $SPARK_HOME/bin/spark-submit \\\n#     --master local \\\n#     --files ${raw_file_dir} \\\n#     --name reddit_preprocessing spark_reddit_preprocessing.py\n","resourceList":[{"id":null,"resourceName":"file:/dolphinscheduler/default/resources/testing.py","res":null}]}, environmentConfig=export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export PYSPARK_DRIVER_PYTHON=/bin/python3.11
export PYTHON_LAUNCHER=/bin/python3.11
export PYSPARK_PYTHON=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='spark preprocessing'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240424'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1326'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13210058002752'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240424060951'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='processing'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='556'}, raw_file_dir=Property{prop='raw_file_dir', direct=IN, type=VARCHAR, value='/local_storage/reddit/processing/500-20240423.json'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240423'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-556][TI-1326] - [INFO] 2024-04-24 06:09:51.243 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: spark preprocessing to wait queue success
[WI-556][TI-1326] - [INFO] 2024-04-24 06:09:51.243 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-556][TI-1326] - [INFO] 2024-04-24 06:09:51.245 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-556][TI-1326] - [INFO] 2024-04-24 06:09:51.245 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-556][TI-1326] - [INFO] 2024-04-24 06:09:51.246 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-556][TI-1326] - [INFO] 2024-04-24 06:09:51.246 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713910191246
[WI-556][TI-1326] - [INFO] 2024-04-24 06:09:51.246 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 556_1326
[WI-556][TI-1326] - [INFO] 2024-04-24 06:09:51.246 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1326,
  "taskName" : "spark preprocessing",
  "firstSubmitTime" : 1713910191232,
  "startTime" : 1713910191246,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.9:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240424/13201021801792/94/556/1326.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 94,
  "processInstanceId" : 556,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"processing\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[],\"rawScript\":\"$SPARK_HOME/bin/spark-submit \\\\\\n    --master spark://spark-master:7077 \\\\\\n    --deploy-mode client \\\\\\n    --conf spark.driver.cores=1 \\\\\\n    --conf spark.driver.memory=1G \\\\\\n    --conf spark.executor.instances=1 \\\\\\n    --conf spark.executor.cores=1 \\\\\\n    --conf spark.executor.memory=1G \\\\\\n    --name reddit_preprocessing \\\\\\n    testing.py\\n\\n# $SPARK_HOME/bin/spark-submit \\\\\\n#     --master local \\\\\\n#     --files ${raw_file_dir} \\\\\\n#     --name reddit_preprocessing spark_reddit_preprocessing.py\\n\",\"resourceList\":[{\"id\":null,\"resourceName\":\"file:/dolphinscheduler/default/resources/testing.py\",\"res\":null}]}",
  "environmentConfig" : "export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3\nexport JAVA_HOME=/opt/java/openjdk\nexport PYSPARK_DRIVER_PYTHON=/bin/python3.11\nexport PYTHON_LAUNCHER=/bin/python3.11\nexport PYSPARK_PYTHON=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "spark preprocessing"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240424"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1326"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13210058002752"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240424060951"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "processing"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "556"
    },
    "raw_file_dir" : {
      "prop" : "raw_file_dir",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit/processing/500-20240423.json"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "556_1326",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"raw_file_dir\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"/local_storage/reddit/processing/500-20240423.json\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-556][TI-1326] - [INFO] 2024-04-24 06:09:51.247 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-556][TI-1326] - [INFO] 2024-04-24 06:09:51.247 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-556][TI-1326] - [INFO] 2024-04-24 06:09:51.247 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-556][TI-1326] - [INFO] 2024-04-24 06:09:51.252 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-556][TI-1326] - [INFO] 2024-04-24 06:09:51.252 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-556][TI-1326] - [INFO] 2024-04-24 06:09:51.252 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_94/556/1326 check successfully
[WI-556][TI-1326] - [INFO] 2024-04-24 06:09:51.253 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-556][TI-1326] - [INFO] 2024-04-24 06:09:51.277 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={file:/dolphinscheduler/default/resources/testing.py=ResourceContext.ResourceItem(resourceAbsolutePathInStorage=file:/dolphinscheduler/default/resources/testing.py, resourceRelativePath=testing.py, resourceAbsolutePathInLocal=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_94/556/1326/testing.py)})
[WI-556][TI-1326] - [INFO] 2024-04-24 06:09:51.279 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-556][TI-1326] - [INFO] 2024-04-24 06:09:51.279 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-556][TI-1326] - [INFO] 2024-04-24 06:09:51.280 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ ],
  "varPool" : null,
  "rawScript" : "$SPARK_HOME/bin/spark-submit \\\n    --master spark://spark-master:7077 \\\n    --deploy-mode client \\\n    --conf spark.driver.cores=1 \\\n    --conf spark.driver.memory=1G \\\n    --conf spark.executor.instances=1 \\\n    --conf spark.executor.cores=1 \\\n    --conf spark.executor.memory=1G \\\n    --name reddit_preprocessing \\\n    testing.py\n\n# $SPARK_HOME/bin/spark-submit \\\n#     --master local \\\n#     --files ${raw_file_dir} \\\n#     --name reddit_preprocessing spark_reddit_preprocessing.py\n",
  "resourceList" : [ {
    "id" : null,
    "resourceName" : "file:/dolphinscheduler/default/resources/testing.py",
    "res" : null
  } ]
}
[WI-556][TI-1326] - [INFO] 2024-04-24 06:09:51.280 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-556][TI-1326] - [INFO] 2024-04-24 06:09:51.280 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}] successfully
[WI-556][TI-1326] - [INFO] 2024-04-24 06:09:51.281 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-556][TI-1326] - [INFO] 2024-04-24 06:09:51.281 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-556][TI-1326] - [INFO] 2024-04-24 06:09:51.281 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-556][TI-1326] - [INFO] 2024-04-24 06:09:51.282 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-556][TI-1326] - [INFO] 2024-04-24 06:09:51.282 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-556][TI-1326] - [INFO] 2024-04-24 06:09:51.282 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export PYSPARK_DRIVER_PYTHON=/bin/python3.11
export PYTHON_LAUNCHER=/bin/python3.11
export PYSPARK_PYTHON=/bin/python3.11
$SPARK_HOME/bin/spark-submit \
    --master spark://spark-master:7077 \
    --deploy-mode client \
    --conf spark.driver.cores=1 \
    --conf spark.driver.memory=1G \
    --conf spark.executor.instances=1 \
    --conf spark.executor.cores=1 \
    --conf spark.executor.memory=1G \
    --name reddit_preprocessing \
    testing.py

# $SPARK_HOME/bin/spark-submit \
#     --master local \
#     --files /local_storage/reddit/processing/500-20240423.json \
#     --name reddit_preprocessing spark_reddit_preprocessing.py

[WI-556][TI-1326] - [INFO] 2024-04-24 06:09:51.282 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-556][TI-1326] - [INFO] 2024-04-24 06:09:51.283 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_94/556/1326/556_1326.sh
[WI-556][TI-1326] - [INFO] 2024-04-24 06:09:51.291 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 218
[WI-0][TI-1326] - [INFO] 2024-04-24 06:09:52.220 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1326, success=true)
[WI-0][TI-1326] - [INFO] 2024-04-24 06:09:52.250 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1326)
[WI-0][TI-0] - [INFO] 2024-04-24 06:09:52.297 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
[WI-0][TI-0] - [INFO] 2024-04-24 06:09:53.153 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8999999999999999 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 06:09:54.168 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7807017543859649 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 06:09:56.321 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 06:09:55 INFO SparkContext: Running Spark version 3.5.1
	24/04/24 06:09:55 INFO SparkContext: OS info Linux, 6.5.0-28-generic, amd64
	24/04/24 06:09:55 INFO SparkContext: Java version 1.8.0_402
	24/04/24 06:09:55 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
	24/04/24 06:09:55 INFO ResourceUtils: ==============================================================
	24/04/24 06:09:55 INFO ResourceUtils: No custom resources configured for spark.driver.
	24/04/24 06:09:55 INFO ResourceUtils: ==============================================================
	24/04/24 06:09:55 INFO SparkContext: Submitted application: PySpark Test Job
	24/04/24 06:09:55 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
	24/04/24 06:09:55 INFO ResourceProfile: Limiting resource is cpus at 1 tasks per executor
	24/04/24 06:09:55 INFO ResourceProfileManager: Added ResourceProfile id: 0
	24/04/24 06:09:55 INFO SecurityManager: Changing view acls to: default
	24/04/24 06:09:55 INFO SecurityManager: Changing modify acls to: default
	24/04/24 06:09:55 INFO SecurityManager: Changing view acls groups to: 
	24/04/24 06:09:55 INFO SecurityManager: Changing modify acls groups to: 
	24/04/24 06:09:55 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: default; groups with view permissions: EMPTY; users with modify permissions: default; groups with modify permissions: EMPTY
[WI-0][TI-0] - [INFO] 2024-04-24 06:09:57.325 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 06:09:56 INFO Utils: Successfully started service 'sparkDriver' on port 32911.
	24/04/24 06:09:56 INFO SparkEnv: Registering MapOutputTracker
	24/04/24 06:09:56 INFO SparkEnv: Registering BlockManagerMaster
	24/04/24 06:09:56 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
	24/04/24 06:09:56 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
	24/04/24 06:09:56 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
	24/04/24 06:09:56 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-268a3ff2-753d-4e51-83b3-f85d7a66ce7d
	24/04/24 06:09:56 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
	24/04/24 06:09:56 INFO SparkEnv: Registering OutputCommitCoordinator
	24/04/24 06:09:57 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
[WI-0][TI-0] - [INFO] 2024-04-24 06:09:58.223 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7507246376811594 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 06:09:58.326 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 06:09:57 INFO Utils: Successfully started service 'SparkUI' on port 4040.
	24/04/24 06:09:57 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
	24/04/24 06:09:58 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.6:7077 after 51 ms (3 ms spent in bootstraps)
[WI-0][TI-0] - [INFO] 2024-04-24 06:09:59.302 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9342465753424658 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 06:09:59.333 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 06:09:58 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20240423220958-0000
	24/04/24 06:09:58 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37685.
	24/04/24 06:09:58 INFO NettyBlockTransferService: Server created on 62c50ccd7bf9:37685
	24/04/24 06:09:58 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
	24/04/24 06:09:58 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20240423220958-0000/0 on worker-20240423220329-172.18.0.8-33083 (172.18.0.8:33083) with 1 core(s)
	24/04/24 06:09:58 INFO StandaloneSchedulerBackend: Granted executor ID app-20240423220958-0000/0 on hostPort 172.18.0.8:33083 with 1 core(s), 1024.0 MiB RAM
	24/04/24 06:09:58 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20240423220958-0000/1 on worker-20240423220329-172.18.0.8-33083 (172.18.0.8:33083) with 1 core(s)
	24/04/24 06:09:58 INFO StandaloneSchedulerBackend: Granted executor ID app-20240423220958-0000/1 on hostPort 172.18.0.8:33083 with 1 core(s), 1024.0 MiB RAM
	24/04/24 06:09:58 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 62c50ccd7bf9, 37685, None)
	24/04/24 06:09:58 INFO BlockManagerMasterEndpoint: Registering block manager 62c50ccd7bf9:37685 with 366.3 MiB RAM, BlockManagerId(driver, 62c50ccd7bf9, 37685, None)
	24/04/24 06:09:58 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 62c50ccd7bf9, 37685, None)
	24/04/24 06:09:58 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 62c50ccd7bf9, 37685, None)
	24/04/24 06:09:59 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20240423220958-0000/1 is now RUNNING
	24/04/24 06:09:59 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20240423220958-0000/0 is now RUNNING
	24/04/24 06:09:59 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
[WI-0][TI-0] - [INFO] 2024-04-24 06:10:00.311 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9453376205787781 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 06:10:00.335 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 06:09:59 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
	24/04/24 06:10:00 INFO SharedState: Warehouse path is 'file:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_94/556/1326/spark-warehouse'.
[WI-0][TI-0] - [INFO] 2024-04-24 06:10:01.312 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9572368421052632 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 06:10:02.319 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9338235294117647 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 06:10:03.328 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9843260188087773 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 06:10:04.331 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9769736842105263 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 06:10:05.349 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.981132075471698 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 06:10:06.351 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9655172413793103 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 06:10:06.383 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	Traceback (most recent call last):
	  File "/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_94/556/1326/testing.py", line 10, in <module>
	    text_file = spark.read.text("/path/to/your/input/file.txt")
	                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
	  File "/opt/spark-3.5.1-bin-hadoop3/python/lib/pyspark.zip/pyspark/sql/readwriter.py", line 615, in text
	  File "/opt/spark-3.5.1-bin-hadoop3/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
	  File "/opt/spark-3.5.1-bin-hadoop3/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 185, in deco
	pyspark.errors.exceptions.captured.AnalysisException: [PATH_NOT_FOUND] Path does not exist: file:/path/to/your/input/file.txt.
	24/04/24 06:10:05 INFO SparkContext: Invoking stop() from shutdown hook
	24/04/24 06:10:05 INFO SparkContext: SparkContext is stopping with exitCode 0.
	24/04/24 06:10:06 INFO SparkUI: Stopped Spark web UI at http://62c50ccd7bf9:4040
	24/04/24 06:10:06 INFO StandaloneSchedulerBackend: Shutting down all executors
	24/04/24 06:10:06 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Asking each executor to shut down
	24/04/24 06:10:06 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
	24/04/24 06:10:06 INFO MemoryStore: MemoryStore cleared
	24/04/24 06:10:06 INFO BlockManager: BlockManager stopped
	24/04/24 06:10:06 INFO BlockManagerMaster: BlockManagerMaster stopped
	24/04/24 06:10:06 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
	24/04/24 06:10:06 INFO SparkContext: Successfully stopped SparkContext
	24/04/24 06:10:06 INFO ShutdownHookManager: Shutdown hook called
	24/04/24 06:10:06 INFO ShutdownHookManager: Deleting directory /tmp/spark-fea8c74a-7de4-48b4-aca4-258eb78db485
	24/04/24 06:10:06 INFO ShutdownHookManager: Deleting directory /tmp/spark-fea8c74a-7de4-48b4-aca4-258eb78db485/pyspark-1abbb434-505c-4836-8624-b3075ef7e818
	24/04/24 06:10:06 INFO ShutdownHookManager: Deleting directory /tmp/spark-d280b915-4158-41e9-899d-699d038c6e87
[WI-556][TI-1326] - [INFO] 2024-04-24 06:10:07.386 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_94/556/1326, processId:218 ,exitStatusCode:1 ,processWaitForStatus:true ,processExitValue:1
[WI-556][TI-1326] - [INFO] 2024-04-24 06:10:07.388 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-556][TI-1326] - [INFO] 2024-04-24 06:10:07.388 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-556][TI-1326] - [INFO] 2024-04-24 06:10:07.388 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-556][TI-1326] - [INFO] 2024-04-24 06:10:07.389 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-556][TI-1326] - [INFO] 2024-04-24 06:10:07.393 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: FAILURE to master : 172.18.1.1:1234
[WI-556][TI-1326] - [INFO] 2024-04-24 06:10:07.394 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-556][TI-1326] - [INFO] 2024-04-24 06:10:07.394 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_94/556/1326
[WI-556][TI-1326] - [INFO] 2024-04-24 06:10:07.395 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_94/556/1326
[WI-556][TI-1326] - [INFO] 2024-04-24 06:10:07.395 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-1326] - [INFO] 2024-04-24 06:10:08.267 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1326, success=true)
[WI-0][TI-0] - [INFO] 2024-04-24 06:10:59.539 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7549295774647887 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 06:11:01.617 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7311827956989246 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 06:11:08.661 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7087087087087087 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 06:11:10.760 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7790368271954674 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 06:11:13.843 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7865497076023392 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 06:11:21.205 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1327, taskName=search for intake JSON files, firstSubmitTime=1713910281177, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.9:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=94, appIds=null, processInstanceId=556, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"processing"}], executorId=1, cmdTypeIfComplement=7, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":""}],"rawScript":"# find 1 raw file in the folder\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\n\n# check if raw_file_dir is empty, then set raw_file_dir to null\nif [ -z \"$raw_file_dir\" ]; then\n    raw_file_dir=null\nfi\n\necho \"#{setValue(raw_file_dir=${raw_file_dir})}\"","resourceList":[]}, environmentConfig=export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='search for intake JSON files'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240424'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1327'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13340113777664'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240424061121'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='processing'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='556'}, raw_file_dir=Property{prop='raw_file_dir', direct=OUT, type=VARCHAR, value='/local_storage/reddit/processing/500-20240423.json'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240423'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-556][TI-1327] - [INFO] 2024-04-24 06:11:21.210 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-556][TI-1327] - [INFO] 2024-04-24 06:11:21.210 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: search for intake JSON files to wait queue success
[WI-556][TI-1327] - [INFO] 2024-04-24 06:11:21.229 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-556][TI-1327] - [INFO] 2024-04-24 06:11:21.230 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-556][TI-1327] - [INFO] 2024-04-24 06:11:21.233 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-556][TI-1327] - [INFO] 2024-04-24 06:11:21.234 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713910281234
[WI-556][TI-1327] - [INFO] 2024-04-24 06:11:21.235 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 556_1327
[WI-556][TI-1327] - [INFO] 2024-04-24 06:11:21.236 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1327,
  "taskName" : "search for intake JSON files",
  "firstSubmitTime" : 1713910281177,
  "startTime" : 1713910281234,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.9:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240424/13201021801792/94/556/1327.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 94,
  "processInstanceId" : 556,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"processing\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 7,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[{\"prop\":\"raw_file_dir\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"\"}],\"rawScript\":\"# find 1 raw file in the folder\\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\\n\\n# check if raw_file_dir is empty, then set raw_file_dir to null\\nif [ -z \\\"$raw_file_dir\\\" ]; then\\n    raw_file_dir=null\\nfi\\n\\necho \\\"#{setValue(raw_file_dir=${raw_file_dir})}\\\"\",\"resourceList\":[]}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "search for intake JSON files"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240424"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1327"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13340113777664"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240424061121"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "processing"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "556"
    },
    "raw_file_dir" : {
      "prop" : "raw_file_dir",
      "direct" : "OUT",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit/processing/500-20240423.json"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "556_1327",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"raw_file_dir\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"/local_storage/reddit/processing/500-20240423.json\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-556][TI-1327] - [INFO] 2024-04-24 06:11:21.238 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-556][TI-1327] - [INFO] 2024-04-24 06:11:21.238 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-556][TI-1327] - [INFO] 2024-04-24 06:11:21.239 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-556][TI-1327] - [INFO] 2024-04-24 06:11:21.250 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-556][TI-1327] - [INFO] 2024-04-24 06:11:21.252 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-556][TI-1327] - [INFO] 2024-04-24 06:11:21.255 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_94/556/1327 check successfully
[WI-556][TI-1327] - [INFO] 2024-04-24 06:11:21.256 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-556][TI-1327] - [INFO] 2024-04-24 06:11:21.258 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-556][TI-1327] - [INFO] 2024-04-24 06:11:21.259 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-556][TI-1327] - [INFO] 2024-04-24 06:11:21.259 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-556][TI-1327] - [INFO] 2024-04-24 06:11:21.260 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ {
    "prop" : "raw_file_dir",
    "direct" : "OUT",
    "type" : "VARCHAR",
    "value" : ""
  } ],
  "varPool" : null,
  "rawScript" : "# find 1 raw file in the folder\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\n\n# check if raw_file_dir is empty, then set raw_file_dir to null\nif [ -z \"$raw_file_dir\" ]; then\n    raw_file_dir=null\nfi\n\necho \"#{setValue(raw_file_dir=${raw_file_dir})}\"",
  "resourceList" : [ ]
}
[WI-556][TI-1327] - [INFO] 2024-04-24 06:11:21.262 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-556][TI-1327] - [INFO] 2024-04-24 06:11:21.263 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}] successfully
[WI-556][TI-1327] - [INFO] 2024-04-24 06:11:21.264 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-556][TI-1327] - [INFO] 2024-04-24 06:11:21.264 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-556][TI-1327] - [INFO] 2024-04-24 06:11:21.265 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-556][TI-1327] - [INFO] 2024-04-24 06:11:21.266 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-556][TI-1327] - [INFO] 2024-04-24 06:11:21.267 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-556][TI-1327] - [INFO] 2024-04-24 06:11:21.272 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export PYTHON_LAUNCHER=/bin/python3.11
# find 1 raw file in the folder
raw_file_dir=$(find /local_storage/reddit/processing -type f -name '*.json'| head -n 1)

# check if raw_file_dir is empty, then set raw_file_dir to null
if [ -z "$raw_file_dir" ]; then
    raw_file_dir=null
fi

echo "#{setValue(raw_file_dir=/local_storage/reddit/processing/500-20240423.json)}"
[WI-556][TI-1327] - [INFO] 2024-04-24 06:11:21.273 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-556][TI-1327] - [INFO] 2024-04-24 06:11:21.274 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_94/556/1327/556_1327.sh
[WI-556][TI-1327] - [INFO] 2024-04-24 06:11:21.291 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 358
[WI-0][TI-0] - [INFO] 2024-04-24 06:11:21.292 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
[WI-0][TI-1327] - [INFO] 2024-04-24 06:11:21.355 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1327, success=true)
[WI-0][TI-1327] - [INFO] 2024-04-24 06:11:21.371 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1327)
[WI-0][TI-0] - [INFO] 2024-04-24 06:11:22.299 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	#{setValue(raw_file_dir=/local_storage/reddit/processing/500-20240423.json)}
[WI-556][TI-1327] - [INFO] 2024-04-24 06:11:22.301 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_94/556/1327, processId:358 ,exitStatusCode:0 ,processWaitForStatus:true ,processExitValue:0
[WI-556][TI-1327] - [INFO] 2024-04-24 06:11:22.313 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-556][TI-1327] - [INFO] 2024-04-24 06:11:22.314 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-556][TI-1327] - [INFO] 2024-04-24 06:11:22.315 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-556][TI-1327] - [INFO] 2024-04-24 06:11:22.317 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-556][TI-1327] - [INFO] 2024-04-24 06:11:22.328 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: SUCCESS to master : 172.18.1.1:1234
[WI-556][TI-1327] - [INFO] 2024-04-24 06:11:22.328 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-556][TI-1327] - [INFO] 2024-04-24 06:11:22.328 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_94/556/1327
[WI-556][TI-1327] - [INFO] 2024-04-24 06:11:22.329 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_94/556/1327
[WI-556][TI-1327] - [INFO] 2024-04-24 06:11:22.329 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-1327] - [INFO] 2024-04-24 06:11:22.365 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1327, success=true)
[WI-0][TI-0] - [INFO] 2024-04-24 06:11:23.522 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1329, taskName=move to processing, firstSubmitTime=1713910283481, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.9:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=94, appIds=null, processInstanceId=556, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"processing"}], executorId=1, cmdTypeIfComplement=7, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":""}],"rawScript":"# move file to the reddit processing folder\n# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error\nfilename=$(basename \"${raw_file_dir}\")\nif ! grep -q \"${REDDIT_HOME}/processing\" <<< \"${raw_file_dir}\"; then\n    mv ${raw_file_dir} ${REDDIT_HOME}/processing\nelse\n    echo JSON is already in processing\nfi\n\n# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing\necho \"#{setValue(raw_file_dir=${REDDIT_HOME}/processing/${filename})}\"","resourceList":[]}, environmentConfig=export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='move to processing'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240424'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1329'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13340390094208'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240424061123'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='processing'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='556'}, raw_file_dir=Property{prop='raw_file_dir', direct=IN, type=VARCHAR, value='/local_storage/reddit/processing/500-20240423.json'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240423'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-556][TI-1329] - [INFO] 2024-04-24 06:11:23.527 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: move to processing to wait queue success
[WI-556][TI-1329] - [INFO] 2024-04-24 06:11:23.528 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-556][TI-1329] - [INFO] 2024-04-24 06:11:23.530 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-556][TI-1329] - [INFO] 2024-04-24 06:11:23.530 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-556][TI-1329] - [INFO] 2024-04-24 06:11:23.530 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-556][TI-1329] - [INFO] 2024-04-24 06:11:23.530 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713910283530
[WI-556][TI-1329] - [INFO] 2024-04-24 06:11:23.530 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 556_1329
[WI-556][TI-1329] - [INFO] 2024-04-24 06:11:23.532 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1329,
  "taskName" : "move to processing",
  "firstSubmitTime" : 1713910283481,
  "startTime" : 1713910283530,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.9:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240424/13201021801792/94/556/1329.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 94,
  "processInstanceId" : 556,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"processing\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 7,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[{\"prop\":\"raw_file_dir\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"\"}],\"rawScript\":\"# move file to the reddit processing folder\\n# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error\\nfilename=$(basename \\\"${raw_file_dir}\\\")\\nif ! grep -q \\\"${REDDIT_HOME}/processing\\\" <<< \\\"${raw_file_dir}\\\"; then\\n    mv ${raw_file_dir} ${REDDIT_HOME}/processing\\nelse\\n    echo JSON is already in processing\\nfi\\n\\n# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing\\necho \\\"#{setValue(raw_file_dir=${REDDIT_HOME}/processing/${filename})}\\\"\",\"resourceList\":[]}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "move to processing"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240424"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1329"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13340390094208"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240424061123"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "processing"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "556"
    },
    "raw_file_dir" : {
      "prop" : "raw_file_dir",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit/processing/500-20240423.json"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "556_1329",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"raw_file_dir\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"/local_storage/reddit/processing/500-20240423.json\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-556][TI-1329] - [INFO] 2024-04-24 06:11:23.533 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-556][TI-1329] - [INFO] 2024-04-24 06:11:23.534 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-556][TI-1329] - [INFO] 2024-04-24 06:11:23.534 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-556][TI-1329] - [INFO] 2024-04-24 06:11:23.558 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-556][TI-1329] - [INFO] 2024-04-24 06:11:23.560 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-556][TI-1329] - [INFO] 2024-04-24 06:11:23.564 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_94/556/1329 check successfully
[WI-556][TI-1329] - [INFO] 2024-04-24 06:11:23.569 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-556][TI-1329] - [INFO] 2024-04-24 06:11:23.570 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-556][TI-1329] - [INFO] 2024-04-24 06:11:23.571 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-556][TI-1329] - [INFO] 2024-04-24 06:11:23.572 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-556][TI-1329] - [INFO] 2024-04-24 06:11:23.579 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ {
    "prop" : "raw_file_dir",
    "direct" : "OUT",
    "type" : "VARCHAR",
    "value" : ""
  } ],
  "varPool" : null,
  "rawScript" : "# move file to the reddit processing folder\n# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error\nfilename=$(basename \"${raw_file_dir}\")\nif ! grep -q \"${REDDIT_HOME}/processing\" <<< \"${raw_file_dir}\"; then\n    mv ${raw_file_dir} ${REDDIT_HOME}/processing\nelse\n    echo JSON is already in processing\nfi\n\n# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing\necho \"#{setValue(raw_file_dir=${REDDIT_HOME}/processing/${filename})}\"",
  "resourceList" : [ ]
}
[WI-556][TI-1329] - [INFO] 2024-04-24 06:11:23.580 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-556][TI-1329] - [INFO] 2024-04-24 06:11:23.580 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}] successfully
[WI-556][TI-1329] - [INFO] 2024-04-24 06:11:23.581 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-556][TI-1329] - [INFO] 2024-04-24 06:11:23.581 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-556][TI-1329] - [INFO] 2024-04-24 06:11:23.581 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-556][TI-1329] - [INFO] 2024-04-24 06:11:23.583 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-556][TI-1329] - [INFO] 2024-04-24 06:11:23.584 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-556][TI-1329] - [INFO] 2024-04-24 06:11:23.584 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export PYTHON_LAUNCHER=/bin/python3.11
# move file to the reddit processing folder
# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error
filename=$(basename "/local_storage/reddit/processing/500-20240423.json")
if ! grep -q "/local_storage/reddit/processing" <<< "/local_storage/reddit/processing/500-20240423.json"; then
    mv /local_storage/reddit/processing/500-20240423.json /local_storage/reddit/processing
else
    echo JSON is already in processing
fi

# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing
echo "#{setValue(raw_file_dir=/local_storage/reddit/processing/${filename})}"
[WI-556][TI-1329] - [INFO] 2024-04-24 06:11:23.586 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-556][TI-1329] - [INFO] 2024-04-24 06:11:23.588 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_94/556/1329/556_1329.sh
[WI-556][TI-1329] - [INFO] 2024-04-24 06:11:23.594 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 372
[WI-0][TI-1329] - [INFO] 2024-04-24 06:11:24.367 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1329, success=true)
[WI-0][TI-1329] - [INFO] 2024-04-24 06:11:24.377 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1329)
[WI-0][TI-0] - [INFO] 2024-04-24 06:11:24.594 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
	JSON is already in processing
	#{setValue(raw_file_dir=/local_storage/reddit/processing/500-20240423.json)}
[WI-556][TI-1329] - [INFO] 2024-04-24 06:11:24.597 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_94/556/1329, processId:372 ,exitStatusCode:0 ,processWaitForStatus:true ,processExitValue:0
[WI-556][TI-1329] - [INFO] 2024-04-24 06:11:24.598 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-556][TI-1329] - [INFO] 2024-04-24 06:11:24.599 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-556][TI-1329] - [INFO] 2024-04-24 06:11:24.599 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-556][TI-1329] - [INFO] 2024-04-24 06:11:24.600 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-556][TI-1329] - [INFO] 2024-04-24 06:11:24.604 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: SUCCESS to master : 172.18.1.1:1234
[WI-556][TI-1329] - [INFO] 2024-04-24 06:11:24.605 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-556][TI-1329] - [INFO] 2024-04-24 06:11:24.605 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_94/556/1329
[WI-556][TI-1329] - [INFO] 2024-04-24 06:11:24.606 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_94/556/1329
[WI-556][TI-1329] - [INFO] 2024-04-24 06:11:24.606 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-1329] - [INFO] 2024-04-24 06:11:25.362 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1329, success=true)
[WI-0][TI-0] - [INFO] 2024-04-24 06:11:25.484 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1330, taskName=spark preprocessing, firstSubmitTime=1713910285466, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.9:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=94, appIds=null, processInstanceId=556, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"processing"}], executorId=1, cmdTypeIfComplement=7, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[],"rawScript":"$SPARK_HOME/bin/spark-submit \\\n    --master spark://spark-master:7077 \\\n    --deploy-mode client \\\n    --conf spark.driver.cores=1 \\\n    --conf spark.driver.memory=1G \\\n    --conf spark.executor.instances=1 \\\n    --conf spark.executor.cores=1 \\\n    --conf spark.executor.memory=1G \\\n    --name reddit_preprocessing \\\n    testing.py\n\n# $SPARK_HOME/bin/spark-submit \\\n#     --master local \\\n#     --files ${raw_file_dir} \\\n#     --name reddit_preprocessing spark_reddit_preprocessing.py\n","resourceList":[{"id":null,"resourceName":"file:/dolphinscheduler/default/resources/testing.py","res":null}]}, environmentConfig=export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export PYSPARK_DRIVER_PYTHON=/bin/python3.11
export PYTHON_LAUNCHER=/bin/python3.11
export PYSPARK_PYTHON=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='spark preprocessing'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240424'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1330'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13210058002752'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240424061125'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='processing'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='556'}, raw_file_dir=Property{prop='raw_file_dir', direct=IN, type=VARCHAR, value='/local_storage/reddit/processing/500-20240423.json'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240423'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-556][TI-1330] - [INFO] 2024-04-24 06:11:25.485 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: spark preprocessing to wait queue success
[WI-556][TI-1330] - [INFO] 2024-04-24 06:11:25.485 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-556][TI-1330] - [INFO] 2024-04-24 06:11:25.487 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-556][TI-1330] - [INFO] 2024-04-24 06:11:25.487 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-556][TI-1330] - [INFO] 2024-04-24 06:11:25.488 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-556][TI-1330] - [INFO] 2024-04-24 06:11:25.488 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713910285488
[WI-556][TI-1330] - [INFO] 2024-04-24 06:11:25.488 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 556_1330
[WI-556][TI-1330] - [INFO] 2024-04-24 06:11:25.489 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1330,
  "taskName" : "spark preprocessing",
  "firstSubmitTime" : 1713910285466,
  "startTime" : 1713910285488,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.9:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240424/13201021801792/94/556/1330.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 94,
  "processInstanceId" : 556,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"processing\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 7,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[],\"rawScript\":\"$SPARK_HOME/bin/spark-submit \\\\\\n    --master spark://spark-master:7077 \\\\\\n    --deploy-mode client \\\\\\n    --conf spark.driver.cores=1 \\\\\\n    --conf spark.driver.memory=1G \\\\\\n    --conf spark.executor.instances=1 \\\\\\n    --conf spark.executor.cores=1 \\\\\\n    --conf spark.executor.memory=1G \\\\\\n    --name reddit_preprocessing \\\\\\n    testing.py\\n\\n# $SPARK_HOME/bin/spark-submit \\\\\\n#     --master local \\\\\\n#     --files ${raw_file_dir} \\\\\\n#     --name reddit_preprocessing spark_reddit_preprocessing.py\\n\",\"resourceList\":[{\"id\":null,\"resourceName\":\"file:/dolphinscheduler/default/resources/testing.py\",\"res\":null}]}",
  "environmentConfig" : "export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3\nexport JAVA_HOME=/opt/java/openjdk\nexport PYSPARK_DRIVER_PYTHON=/bin/python3.11\nexport PYTHON_LAUNCHER=/bin/python3.11\nexport PYSPARK_PYTHON=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "spark preprocessing"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240424"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1330"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13210058002752"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240424061125"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "processing"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "556"
    },
    "raw_file_dir" : {
      "prop" : "raw_file_dir",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit/processing/500-20240423.json"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "556_1330",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"raw_file_dir\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"/local_storage/reddit/processing/500-20240423.json\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-556][TI-1330] - [INFO] 2024-04-24 06:11:25.489 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-556][TI-1330] - [INFO] 2024-04-24 06:11:25.489 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-556][TI-1330] - [INFO] 2024-04-24 06:11:25.490 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-556][TI-1330] - [INFO] 2024-04-24 06:11:25.494 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-556][TI-1330] - [INFO] 2024-04-24 06:11:25.495 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-556][TI-1330] - [INFO] 2024-04-24 06:11:25.495 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_94/556/1330 check successfully
[WI-556][TI-1330] - [INFO] 2024-04-24 06:11:25.496 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-556][TI-1330] - [INFO] 2024-04-24 06:11:25.514 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={file:/dolphinscheduler/default/resources/testing.py=ResourceContext.ResourceItem(resourceAbsolutePathInStorage=file:/dolphinscheduler/default/resources/testing.py, resourceRelativePath=testing.py, resourceAbsolutePathInLocal=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_94/556/1330/testing.py)})
[WI-556][TI-1330] - [INFO] 2024-04-24 06:11:25.515 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-556][TI-1330] - [INFO] 2024-04-24 06:11:25.516 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-556][TI-1330] - [INFO] 2024-04-24 06:11:25.516 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ ],
  "varPool" : null,
  "rawScript" : "$SPARK_HOME/bin/spark-submit \\\n    --master spark://spark-master:7077 \\\n    --deploy-mode client \\\n    --conf spark.driver.cores=1 \\\n    --conf spark.driver.memory=1G \\\n    --conf spark.executor.instances=1 \\\n    --conf spark.executor.cores=1 \\\n    --conf spark.executor.memory=1G \\\n    --name reddit_preprocessing \\\n    testing.py\n\n# $SPARK_HOME/bin/spark-submit \\\n#     --master local \\\n#     --files ${raw_file_dir} \\\n#     --name reddit_preprocessing spark_reddit_preprocessing.py\n",
  "resourceList" : [ {
    "id" : null,
    "resourceName" : "file:/dolphinscheduler/default/resources/testing.py",
    "res" : null
  } ]
}
[WI-556][TI-1330] - [INFO] 2024-04-24 06:11:25.516 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-556][TI-1330] - [INFO] 2024-04-24 06:11:25.517 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}] successfully
[WI-556][TI-1330] - [INFO] 2024-04-24 06:11:25.518 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-556][TI-1330] - [INFO] 2024-04-24 06:11:25.518 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-556][TI-1330] - [INFO] 2024-04-24 06:11:25.519 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-556][TI-1330] - [INFO] 2024-04-24 06:11:25.519 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-556][TI-1330] - [INFO] 2024-04-24 06:11:25.520 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-556][TI-1330] - [INFO] 2024-04-24 06:11:25.520 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export PYSPARK_DRIVER_PYTHON=/bin/python3.11
export PYTHON_LAUNCHER=/bin/python3.11
export PYSPARK_PYTHON=/bin/python3.11
$SPARK_HOME/bin/spark-submit \
    --master spark://spark-master:7077 \
    --deploy-mode client \
    --conf spark.driver.cores=1 \
    --conf spark.driver.memory=1G \
    --conf spark.executor.instances=1 \
    --conf spark.executor.cores=1 \
    --conf spark.executor.memory=1G \
    --name reddit_preprocessing \
    testing.py

# $SPARK_HOME/bin/spark-submit \
#     --master local \
#     --files /local_storage/reddit/processing/500-20240423.json \
#     --name reddit_preprocessing spark_reddit_preprocessing.py

[WI-556][TI-1330] - [INFO] 2024-04-24 06:11:25.520 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-556][TI-1330] - [INFO] 2024-04-24 06:11:25.520 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_94/556/1330/556_1330.sh
[WI-556][TI-1330] - [INFO] 2024-04-24 06:11:25.525 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 384
[WI-0][TI-1330] - [INFO] 2024-04-24 06:11:26.371 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1330, success=true)
[WI-0][TI-1330] - [INFO] 2024-04-24 06:11:26.383 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1330)
[WI-0][TI-0] - [INFO] 2024-04-24 06:11:26.536 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
[WI-0][TI-0] - [INFO] 2024-04-24 06:11:28.540 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 06:11:28 INFO SparkContext: Running Spark version 3.5.1
	24/04/24 06:11:28 INFO SparkContext: OS info Linux, 6.5.0-28-generic, amd64
	24/04/24 06:11:28 INFO SparkContext: Java version 1.8.0_402
	24/04/24 06:11:28 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
	24/04/24 06:11:28 INFO ResourceUtils: ==============================================================
	24/04/24 06:11:28 INFO ResourceUtils: No custom resources configured for spark.driver.
	24/04/24 06:11:28 INFO ResourceUtils: ==============================================================
	24/04/24 06:11:28 INFO SparkContext: Submitted application: PySpark Test Job
	24/04/24 06:11:28 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
	24/04/24 06:11:28 INFO ResourceProfile: Limiting resource is cpus at 1 tasks per executor
	24/04/24 06:11:28 INFO ResourceProfileManager: Added ResourceProfile id: 0
[WI-0][TI-0] - [INFO] 2024-04-24 06:11:29.555 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 06:11:28 INFO SecurityManager: Changing view acls to: default
	24/04/24 06:11:28 INFO SecurityManager: Changing modify acls to: default
	24/04/24 06:11:28 INFO SecurityManager: Changing view acls groups to: 
	24/04/24 06:11:28 INFO SecurityManager: Changing modify acls groups to: 
	24/04/24 06:11:28 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: default; groups with view permissions: EMPTY; users with modify permissions: default; groups with modify permissions: EMPTY
	24/04/24 06:11:29 INFO Utils: Successfully started service 'sparkDriver' on port 40679.
	24/04/24 06:11:29 INFO SparkEnv: Registering MapOutputTracker
	24/04/24 06:11:29 INFO SparkEnv: Registering BlockManagerMaster
	24/04/24 06:11:29 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
	24/04/24 06:11:29 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
	24/04/24 06:11:29 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
	24/04/24 06:11:29 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-ffd68d8a-0fd6-408f-8261-51d6d0e1bfa3
	24/04/24 06:11:29 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
	24/04/24 06:11:29 INFO SparkEnv: Registering OutputCommitCoordinator
	24/04/24 06:11:29 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
[WI-0][TI-0] - [INFO] 2024-04-24 06:11:30.559 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 06:11:29 INFO Utils: Successfully started service 'SparkUI' on port 4040.
	24/04/24 06:11:29 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
	24/04/24 06:11:30 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.6:7077 after 44 ms (0 ms spent in bootstraps)
	24/04/24 06:11:30 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20240423221130-0001
	24/04/24 06:11:30 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20240423221130-0001/0 on worker-20240423220329-172.18.0.8-33083 (172.18.0.8:33083) with 1 core(s)
	24/04/24 06:11:30 INFO StandaloneSchedulerBackend: Granted executor ID app-20240423221130-0001/0 on hostPort 172.18.0.8:33083 with 1 core(s), 1024.0 MiB RAM
	24/04/24 06:11:30 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20240423221130-0001/1 on worker-20240423220329-172.18.0.8-33083 (172.18.0.8:33083) with 1 core(s)
	24/04/24 06:11:30 INFO StandaloneSchedulerBackend: Granted executor ID app-20240423221130-0001/1 on hostPort 172.18.0.8:33083 with 1 core(s), 1024.0 MiB RAM
	24/04/24 06:11:30 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36531.
	24/04/24 06:11:30 INFO NettyBlockTransferService: Server created on 62c50ccd7bf9:36531
	24/04/24 06:11:30 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20240423221130-0001/0 is now RUNNING
	24/04/24 06:11:30 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
	24/04/24 06:11:30 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 62c50ccd7bf9, 36531, None)
	24/04/24 06:11:30 INFO BlockManagerMasterEndpoint: Registering block manager 62c50ccd7bf9:36531 with 366.3 MiB RAM, BlockManagerId(driver, 62c50ccd7bf9, 36531, None)
	24/04/24 06:11:30 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 62c50ccd7bf9, 36531, None)
	24/04/24 06:11:30 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 62c50ccd7bf9, 36531, None)
	24/04/24 06:11:30 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20240423221130-0001/1 is now RUNNING
[WI-0][TI-0] - [INFO] 2024-04-24 06:11:31.155 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9501779359430604 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 06:11:31.563 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 06:11:30 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
	24/04/24 06:11:31 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
	24/04/24 06:11:31 INFO SharedState: Warehouse path is 'file:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_94/556/1330/spark-warehouse'.
[WI-0][TI-0] - [INFO] 2024-04-24 06:11:32.209 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9601449275362319 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 06:11:33.237 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9385665529010239 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 06:11:34.245 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9183006535947713 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 06:11:35.260 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9090909090909091 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 06:11:36.270 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.935 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 06:11:37.272 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8869257950530035 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 06:11:38.274 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9703703703703703 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 06:11:39.283 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9611307420494699 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 06:11:39.716 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 06:11:39 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.8:56678) with ID 0,  ResourceProfileId 0
	24/04/24 06:11:39 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.8:56694) with ID 1,  ResourceProfileId 0
	24/04/24 06:11:39 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.8:41959 with 434.4 MiB RAM, BlockManagerId(0, 172.18.0.8, 41959, None)
	24/04/24 06:11:39 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.8:36519 with 434.4 MiB RAM, BlockManagerId(1, 172.18.0.8, 36519, None)
[WI-0][TI-0] - [INFO] 2024-04-24 06:11:41.721 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 06:11:41 INFO CodeGenerator: Code generated in 364.345296 ms
	24/04/24 06:11:41 INFO SparkContext: Starting job: json at NativeMethodAccessorImpl.java:0
	24/04/24 06:11:41 INFO DAGScheduler: Got job 0 (json at NativeMethodAccessorImpl.java:0) with 2 output partitions
	24/04/24 06:11:41 INFO DAGScheduler: Final stage: ResultStage 0 (json at NativeMethodAccessorImpl.java:0)
	24/04/24 06:11:41 INFO DAGScheduler: Parents of final stage: List()
	24/04/24 06:11:41 INFO DAGScheduler: Missing parents: List()
	24/04/24 06:11:41 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[6] at json at NativeMethodAccessorImpl.java:0), which has no missing parents
[WI-0][TI-0] - [INFO] 2024-04-24 06:11:42.725 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 06:11:41 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 20.8 KiB, free 366.3 MiB)
	24/04/24 06:11:41 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 10.1 KiB, free 366.3 MiB)
	24/04/24 06:11:41 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 62c50ccd7bf9:36531 (size: 10.1 KiB, free: 366.3 MiB)
	24/04/24 06:11:41 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1585
	24/04/24 06:11:41 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (MapPartitionsRDD[6] at json at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
	24/04/24 06:11:41 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks resource profile 0
	24/04/24 06:11:41 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.8, executor 1, partition 0, PROCESS_LOCAL, 7599 bytes) 
	24/04/24 06:11:41 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1) (172.18.0.8, executor 0, partition 1, PROCESS_LOCAL, 7684 bytes) 
[WI-0][TI-0] - [INFO] 2024-04-24 06:12:05.409 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7119113573407202 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 06:12:13.445 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8071625344352618 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 06:26:30.723 +0800 o.a.d.s.w.r.o.TaskInstanceKillOperationFunction:[55] - Receive TaskInstanceKillRequest: TaskInstanceKillRequest(taskInstanceId=1330)
[WI-0][TI-1330] - [ERROR] 2024-04-24 06:26:30.738 +0800 o.a.d.s.w.r.o.TaskInstanceKillOperationFunction:[139] - kill task error
java.io.IOException: Cannot run program "pstree": error=2, No such file or directory
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1048)
	at org.apache.dolphinscheduler.common.shell.AbstractShell.runCommand(AbstractShell.java:138)
	at org.apache.dolphinscheduler.common.shell.AbstractShell.run(AbstractShell.java:118)
	at org.apache.dolphinscheduler.common.shell.ShellExecutor.execute(ShellExecutor.java:125)
	at org.apache.dolphinscheduler.common.shell.ShellExecutor.execCommand(ShellExecutor.java:103)
	at org.apache.dolphinscheduler.common.shell.ShellExecutor.execCommand(ShellExecutor.java:86)
	at org.apache.dolphinscheduler.common.utils.OSUtils.exeShell(OSUtils.java:345)
	at org.apache.dolphinscheduler.common.utils.OSUtils.exeCmd(OSUtils.java:334)
	at org.apache.dolphinscheduler.plugin.task.api.utils.ProcessUtils.getPidsStr(ProcessUtils.java:129)
	at org.apache.dolphinscheduler.server.worker.runner.operator.TaskInstanceKillOperationFunction.killProcess(TaskInstanceKillOperationFunction.java:130)
	at org.apache.dolphinscheduler.server.worker.runner.operator.TaskInstanceKillOperationFunction.doKill(TaskInstanceKillOperationFunction.java:96)
	at org.apache.dolphinscheduler.server.worker.runner.operator.TaskInstanceKillOperationFunction.operate(TaskInstanceKillOperationFunction.java:69)
	at org.apache.dolphinscheduler.server.worker.rpc.TaskInstanceOperatorImpl.killTask(TaskInstanceOperatorImpl.java:49)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.dolphinscheduler.extract.base.server.ServerMethodInvokerImpl.invoke(ServerMethodInvokerImpl.java:41)
	at org.apache.dolphinscheduler.extract.base.server.JdkDynamicServerHandler.lambda$processReceived$0(JdkDynamicServerHandler.java:108)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.io.IOException: error=2, No such file or directory
	at java.lang.UNIXProcess.forkAndExec(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:247)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	... 21 common frames omitted
[WI-0][TI-1330] - [INFO] 2024-04-24 06:26:30.740 +0800 o.a.d.p.t.a.u.ProcessUtils:[182] - Get appIds from worker 172.18.1.1:1234, taskLogPath: /opt/dolphinscheduler/logs/20240424/13201021801792/94/556/1330.log
[WI-0][TI-1330] - [INFO] 2024-04-24 06:26:30.741 +0800 o.a.d.p.t.a.u.LogUtils:[79] - Start finding appId in /opt/dolphinscheduler/logs/20240424/13201021801792/94/556/1330.log, fetch way: log 
[WI-0][TI-1330] - [INFO] 2024-04-24 06:26:30.744 +0800 o.a.d.p.t.a.u.ProcessUtils:[188] - The appId is empty
[WI-0][TI-1330] - [INFO] 2024-04-24 06:26:30.746 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[220] - Begin to kill process process, pid is : 384
[WI-0][TI-0] - [INFO] 2024-04-24 06:26:30.946 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.747191011235955 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 06:26:33.972 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7272727272727272 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-1330] - [INFO] 2024-04-24 06:26:35.751 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[225] - Success kill task: 556_1330, pid: 384
[WI-0][TI-1330] - [INFO] 2024-04-24 06:26:35.752 +0800 o.a.d.s.w.r.o.TaskInstanceKillOperationFunction:[119] - kill task by cancelApplication, taskInstanceId: 1330
[WI-0][TI-0] - [ERROR] 2024-04-24 06:26:48.443 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[279] - Parse var pool error
java.io.IOException: Stream closed
	at java.io.BufferedInputStream.getBufIfOpen(BufferedInputStream.java:170)
	at java.io.BufferedInputStream.read1(BufferedInputStream.java:283)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:345)
	at sun.nio.cs.StreamDecoder.readBytes(StreamDecoder.java:284)
	at sun.nio.cs.StreamDecoder.implRead(StreamDecoder.java:326)
	at sun.nio.cs.StreamDecoder.read(StreamDecoder.java:178)
	at java.io.InputStreamReader.read(InputStreamReader.java:184)
	at java.io.BufferedReader.fill(BufferedReader.java:161)
	at java.io.BufferedReader.readLine(BufferedReader.java:324)
	at java.io.BufferedReader.readLine(BufferedReader.java:389)
	at org.apache.dolphinscheduler.plugin.task.api.AbstractCommandExecutor.lambda$parseProcessOutput$1(AbstractCommandExecutor.java:273)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
[WI-556][TI-1330] - [INFO] 2024-04-24 06:26:48.929 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has killed. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_94/556/1330, processId:384 ,exitStatusCode:137 ,processWaitForStatus:true ,processExitValue:137
[WI-556][TI-1330] - [INFO] 2024-04-24 06:26:48.930 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-556][TI-1330] - [INFO] 2024-04-24 06:26:48.931 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-556][TI-1330] - [INFO] 2024-04-24 06:26:48.933 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-556][TI-1330] - [INFO] 2024-04-24 06:26:48.937 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-556][TI-1330] - [INFO] 2024-04-24 06:26:48.952 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: KILL to master : 172.18.1.1:1234
[WI-556][TI-1330] - [INFO] 2024-04-24 06:26:48.953 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-556][TI-1330] - [INFO] 2024-04-24 06:26:48.954 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_94/556/1330
[WI-556][TI-1330] - [INFO] 2024-04-24 06:26:48.955 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_94/556/1330
[WI-556][TI-1330] - [INFO] 2024-04-24 06:26:48.956 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-0] - [INFO] 2024-04-24 06:26:56.366 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1331, taskName=search for intake JSON files, firstSubmitTime=1713911216357, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.9:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=94, appIds=null, processInstanceId=557, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"processing"}], executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":""}],"rawScript":"# find 1 raw file in the folder\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\n\n# check if raw_file_dir is empty, then set raw_file_dir to null\nif [ -z \"$raw_file_dir\" ]; then\n    raw_file_dir=null\nfi\n\necho \"#{setValue(raw_file_dir=${raw_file_dir})}\"","resourceList":[]}, environmentConfig=export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='search for intake JSON files'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240424'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1331'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13340113777664'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240424062656'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='processing'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='557'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240423'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=null, dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-557][TI-1331] - [INFO] 2024-04-24 06:26:56.369 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: search for intake JSON files to wait queue success
[WI-557][TI-1331] - [INFO] 2024-04-24 06:26:56.370 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-557][TI-1331] - [INFO] 2024-04-24 06:26:56.372 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-557][TI-1331] - [INFO] 2024-04-24 06:26:56.372 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-557][TI-1331] - [INFO] 2024-04-24 06:26:56.373 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-557][TI-1331] - [INFO] 2024-04-24 06:26:56.373 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713911216373
[WI-557][TI-1331] - [INFO] 2024-04-24 06:26:56.373 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 557_1331
[WI-557][TI-1331] - [INFO] 2024-04-24 06:26:56.373 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1331,
  "taskName" : "search for intake JSON files",
  "firstSubmitTime" : 1713911216357,
  "startTime" : 1713911216373,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.9:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240424/13201021801792/94/557/1331.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 94,
  "processInstanceId" : 557,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"processing\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[{\"prop\":\"raw_file_dir\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"\"}],\"rawScript\":\"# find 1 raw file in the folder\\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\\n\\n# check if raw_file_dir is empty, then set raw_file_dir to null\\nif [ -z \\\"$raw_file_dir\\\" ]; then\\n    raw_file_dir=null\\nfi\\n\\necho \\\"#{setValue(raw_file_dir=${raw_file_dir})}\\\"\",\"resourceList\":[]}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "search for intake JSON files"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240424"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1331"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13340113777664"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240424062656"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "processing"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "557"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "557_1331",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-557][TI-1331] - [INFO] 2024-04-24 06:26:56.374 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-557][TI-1331] - [INFO] 2024-04-24 06:26:56.374 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-557][TI-1331] - [INFO] 2024-04-24 06:26:56.375 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-557][TI-1331] - [INFO] 2024-04-24 06:26:56.386 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-557][TI-1331] - [INFO] 2024-04-24 06:26:56.388 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-557][TI-1331] - [INFO] 2024-04-24 06:26:56.389 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_94/557/1331 check successfully
[WI-557][TI-1331] - [INFO] 2024-04-24 06:26:56.390 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-557][TI-1331] - [INFO] 2024-04-24 06:26:56.391 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-557][TI-1331] - [INFO] 2024-04-24 06:26:56.392 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-557][TI-1331] - [INFO] 2024-04-24 06:26:56.392 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-557][TI-1331] - [INFO] 2024-04-24 06:26:56.392 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ {
    "prop" : "raw_file_dir",
    "direct" : "OUT",
    "type" : "VARCHAR",
    "value" : ""
  } ],
  "varPool" : null,
  "rawScript" : "# find 1 raw file in the folder\nraw_file_dir=$(find ${REDDIT_HOME}/${folder} -type f -name '*.json'| head -n 1)\n\n# check if raw_file_dir is empty, then set raw_file_dir to null\nif [ -z \"$raw_file_dir\" ]; then\n    raw_file_dir=null\nfi\n\necho \"#{setValue(raw_file_dir=${raw_file_dir})}\"",
  "resourceList" : [ ]
}
[WI-557][TI-1331] - [INFO] 2024-04-24 06:26:56.392 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-557][TI-1331] - [INFO] 2024-04-24 06:26:56.393 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: null successfully
[WI-557][TI-1331] - [INFO] 2024-04-24 06:26:56.393 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-557][TI-1331] - [INFO] 2024-04-24 06:26:56.393 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-557][TI-1331] - [INFO] 2024-04-24 06:26:56.393 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-557][TI-1331] - [INFO] 2024-04-24 06:26:56.394 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-557][TI-1331] - [INFO] 2024-04-24 06:26:56.395 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-557][TI-1331] - [INFO] 2024-04-24 06:26:56.395 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export PYTHON_LAUNCHER=/bin/python3.11
# find 1 raw file in the folder
raw_file_dir=$(find /local_storage/reddit/processing -type f -name '*.json'| head -n 1)

# check if raw_file_dir is empty, then set raw_file_dir to null
if [ -z "$raw_file_dir" ]; then
    raw_file_dir=null
fi

echo "#{setValue(raw_file_dir=${raw_file_dir})}"
[WI-557][TI-1331] - [INFO] 2024-04-24 06:26:56.395 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-557][TI-1331] - [INFO] 2024-04-24 06:26:56.396 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_94/557/1331/557_1331.sh
[WI-557][TI-1331] - [INFO] 2024-04-24 06:26:56.424 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 701
[WI-0][TI-1331] - [INFO] 2024-04-24 06:26:57.095 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1331, success=true)
[WI-0][TI-1331] - [INFO] 2024-04-24 06:26:57.101 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1331)
[WI-0][TI-0] - [INFO] 2024-04-24 06:26:57.435 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
	#{setValue(raw_file_dir=/local_storage/reddit/processing/500-20240423.json)}
[WI-557][TI-1331] - [INFO] 2024-04-24 06:26:57.440 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_94/557/1331, processId:701 ,exitStatusCode:0 ,processWaitForStatus:true ,processExitValue:0
[WI-557][TI-1331] - [INFO] 2024-04-24 06:26:57.442 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-557][TI-1331] - [INFO] 2024-04-24 06:26:57.442 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-557][TI-1331] - [INFO] 2024-04-24 06:26:57.443 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-557][TI-1331] - [INFO] 2024-04-24 06:26:57.444 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-557][TI-1331] - [INFO] 2024-04-24 06:26:57.453 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: SUCCESS to master : 172.18.1.1:1234
[WI-557][TI-1331] - [INFO] 2024-04-24 06:26:57.453 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-557][TI-1331] - [INFO] 2024-04-24 06:26:57.453 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_94/557/1331
[WI-557][TI-1331] - [INFO] 2024-04-24 06:26:57.454 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_94/557/1331
[WI-557][TI-1331] - [INFO] 2024-04-24 06:26:57.454 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-1331] - [INFO] 2024-04-24 06:26:58.091 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1331, success=true)
[WI-0][TI-0] - [INFO] 2024-04-24 06:26:59.176 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1333, taskName=move to processing, firstSubmitTime=1713911219146, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.9:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=94, appIds=null, processInstanceId=557, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"processing"}], executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[{"prop":"raw_file_dir","direct":"OUT","type":"VARCHAR","value":""}],"rawScript":"# move file to the reddit processing folder\n# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error\nfilename=$(basename \"${raw_file_dir}\")\nif ! grep -q \"${REDDIT_HOME}/processing\" <<< \"${raw_file_dir}\"; then\n    mv ${raw_file_dir} ${REDDIT_HOME}/processing\nelse\n    echo JSON is already in processing\nfi\n\n# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing\necho \"#{setValue(raw_file_dir=${REDDIT_HOME}/processing/${filename})}\"","resourceList":[]}, environmentConfig=export PYTHON_LAUNCHER=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='move to processing'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240424'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1333'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13340390094208'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240424062659'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='processing'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='557'}, raw_file_dir=Property{prop='raw_file_dir', direct=IN, type=VARCHAR, value='/local_storage/reddit/processing/500-20240423.json'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240423'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-557][TI-1333] - [INFO] 2024-04-24 06:26:59.178 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: move to processing to wait queue success
[WI-557][TI-1333] - [INFO] 2024-04-24 06:26:59.179 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-557][TI-1333] - [INFO] 2024-04-24 06:26:59.182 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-557][TI-1333] - [INFO] 2024-04-24 06:26:59.182 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-557][TI-1333] - [INFO] 2024-04-24 06:26:59.182 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-557][TI-1333] - [INFO] 2024-04-24 06:26:59.182 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713911219182
[WI-557][TI-1333] - [INFO] 2024-04-24 06:26:59.182 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 557_1333
[WI-557][TI-1333] - [INFO] 2024-04-24 06:26:59.183 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1333,
  "taskName" : "move to processing",
  "firstSubmitTime" : 1713911219146,
  "startTime" : 1713911219182,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.9:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240424/13201021801792/94/557/1333.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 94,
  "processInstanceId" : 557,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"processing\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[{\"prop\":\"raw_file_dir\",\"direct\":\"OUT\",\"type\":\"VARCHAR\",\"value\":\"\"}],\"rawScript\":\"# move file to the reddit processing folder\\n# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error\\nfilename=$(basename \\\"${raw_file_dir}\\\")\\nif ! grep -q \\\"${REDDIT_HOME}/processing\\\" <<< \\\"${raw_file_dir}\\\"; then\\n    mv ${raw_file_dir} ${REDDIT_HOME}/processing\\nelse\\n    echo JSON is already in processing\\nfi\\n\\n# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing\\necho \\\"#{setValue(raw_file_dir=${REDDIT_HOME}/processing/${filename})}\\\"\",\"resourceList\":[]}",
  "environmentConfig" : "export PYTHON_LAUNCHER=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "move to processing"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240424"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1333"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13340390094208"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240424062659"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "processing"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "557"
    },
    "raw_file_dir" : {
      "prop" : "raw_file_dir",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit/processing/500-20240423.json"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "557_1333",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"raw_file_dir\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"/local_storage/reddit/processing/500-20240423.json\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-557][TI-1333] - [INFO] 2024-04-24 06:26:59.184 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-557][TI-1333] - [INFO] 2024-04-24 06:26:59.184 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-557][TI-1333] - [INFO] 2024-04-24 06:26:59.184 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-557][TI-1333] - [INFO] 2024-04-24 06:26:59.196 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-557][TI-1333] - [INFO] 2024-04-24 06:26:59.197 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-557][TI-1333] - [INFO] 2024-04-24 06:26:59.198 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_94/557/1333 check successfully
[WI-557][TI-1333] - [INFO] 2024-04-24 06:26:59.198 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-557][TI-1333] - [INFO] 2024-04-24 06:26:59.210 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={})
[WI-557][TI-1333] - [INFO] 2024-04-24 06:26:59.211 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-557][TI-1333] - [INFO] 2024-04-24 06:26:59.211 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-557][TI-1333] - [INFO] 2024-04-24 06:26:59.216 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ {
    "prop" : "raw_file_dir",
    "direct" : "OUT",
    "type" : "VARCHAR",
    "value" : ""
  } ],
  "varPool" : null,
  "rawScript" : "# move file to the reddit processing folder\n# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error\nfilename=$(basename \"${raw_file_dir}\")\nif ! grep -q \"${REDDIT_HOME}/processing\" <<< \"${raw_file_dir}\"; then\n    mv ${raw_file_dir} ${REDDIT_HOME}/processing\nelse\n    echo JSON is already in processing\nfi\n\n# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing\necho \"#{setValue(raw_file_dir=${REDDIT_HOME}/processing/${filename})}\"",
  "resourceList" : [ ]
}
[WI-557][TI-1333] - [INFO] 2024-04-24 06:26:59.217 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-557][TI-1333] - [INFO] 2024-04-24 06:26:59.217 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}] successfully
[WI-557][TI-1333] - [INFO] 2024-04-24 06:26:59.220 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-557][TI-1333] - [INFO] 2024-04-24 06:26:59.220 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-557][TI-1333] - [INFO] 2024-04-24 06:26:59.220 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-557][TI-1333] - [INFO] 2024-04-24 06:26:59.221 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-557][TI-1333] - [INFO] 2024-04-24 06:26:59.222 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-557][TI-1333] - [INFO] 2024-04-24 06:26:59.228 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export PYTHON_LAUNCHER=/bin/python3.11
# move file to the reddit processing folder
# but dont move it, if it already exists in the folder, for example when the selected folder to search is reddit/processing, the file may already be inside the processing folder, which will lead to an error
filename=$(basename "/local_storage/reddit/processing/500-20240423.json")
if ! grep -q "/local_storage/reddit/processing" <<< "/local_storage/reddit/processing/500-20240423.json"; then
    mv /local_storage/reddit/processing/500-20240423.json /local_storage/reddit/processing
else
    echo JSON is already in processing
fi

# update the raw_file_dir parameters in the scenario that the raw file gets moved to processing
echo "#{setValue(raw_file_dir=/local_storage/reddit/processing/${filename})}"
[WI-557][TI-1333] - [INFO] 2024-04-24 06:26:59.229 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-557][TI-1333] - [INFO] 2024-04-24 06:26:59.229 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_94/557/1333/557_1333.sh
[WI-557][TI-1333] - [INFO] 2024-04-24 06:26:59.239 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 714
[WI-0][TI-1333] - [INFO] 2024-04-24 06:27:00.116 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1333, success=true)
[WI-0][TI-1333] - [INFO] 2024-04-24 06:27:00.133 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1333)
[WI-0][TI-0] - [INFO] 2024-04-24 06:27:00.246 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
	JSON is already in processing
	#{setValue(raw_file_dir=/local_storage/reddit/processing/500-20240423.json)}
[WI-557][TI-1333] - [INFO] 2024-04-24 06:27:00.249 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_94/557/1333, processId:714 ,exitStatusCode:0 ,processWaitForStatus:true ,processExitValue:0
[WI-557][TI-1333] - [INFO] 2024-04-24 06:27:00.250 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-557][TI-1333] - [INFO] 2024-04-24 06:27:00.250 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-557][TI-1333] - [INFO] 2024-04-24 06:27:00.250 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-557][TI-1333] - [INFO] 2024-04-24 06:27:00.251 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-557][TI-1333] - [INFO] 2024-04-24 06:27:00.256 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: SUCCESS to master : 172.18.1.1:1234
[WI-557][TI-1333] - [INFO] 2024-04-24 06:27:00.257 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-557][TI-1333] - [INFO] 2024-04-24 06:27:00.257 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_94/557/1333
[WI-557][TI-1333] - [INFO] 2024-04-24 06:27:00.258 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_94/557/1333
[WI-557][TI-1333] - [INFO] 2024-04-24 06:27:00.258 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-1333] - [INFO] 2024-04-24 06:27:01.100 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1333, success=true)
[WI-0][TI-0] - [INFO] 2024-04-24 06:27:01.197 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[53] - Receive TaskInstanceDispatchRequest: TaskInstanceDispatchRequest(taskExecutionContext=TaskExecutionContext(taskInstanceId=1334, taskName=spark preprocessing, firstSubmitTime=1713911221184, startTime=0, taskType=SHELL, workflowInstanceHost=172.18.0.9:5678, host=172.18.1.1:1234, executePath=null, logPath=null, appInfoPath=null, taskJson=null, processId=0, processDefineCode=13201021801792, processDefineVersion=94, appIds=null, processInstanceId=557, scheduleTime=0, globalParams=[{"prop":"folder","direct":"IN","type":"VARCHAR","value":"processing"}], executorId=1, cmdTypeIfComplement=0, tenantCode=default, processDefineId=0, projectId=0, projectCode=13010050770016, taskParams={"localParams":[],"rawScript":"$SPARK_HOME/bin/spark-submit \\\n    --master spark://spark-master:7077 \\\n    --deploy-mode client \\\n    --conf spark.driver.cores=1 \\\n    --conf spark.driver.memory=1G \\\n    --conf spark.executor.instances=1 \\\n    --conf spark.executor.cores=1 \\\n    --conf spark.executor.memory=1G \\\n    --name reddit_preprocessing \\\n    testing.py\n\n# $SPARK_HOME/bin/spark-submit \\\n#     --master local \\\n#     --files ${raw_file_dir} \\\n#     --name reddit_preprocessing spark_reddit_preprocessing.py\n","resourceList":[{"id":null,"resourceName":"file:/dolphinscheduler/default/resources/testing.py","res":null}]}, environmentConfig=export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export PYSPARK_DRIVER_PYTHON=/bin/python3.11
export PYTHON_LAUNCHER=/bin/python3.11
export PYSPARK_PYTHON=/bin/python3.11, definedParams=null, prepareParamsMap={system.task.definition.name=Property{prop='system.task.definition.name', direct=IN, type=VARCHAR, value='spark preprocessing'}, system.project.name=Property{prop='system.project.name', direct=IN, type=VARCHAR, value='null'}, REDDIT_HOME=Property{prop='REDDIT_HOME', direct=IN, type=VARCHAR, value='/local_storage/reddit'}, system.biz.curdate=Property{prop='system.biz.curdate', direct=IN, type=VARCHAR, value='20240424'}, system.task.instance.id=Property{prop='system.task.instance.id', direct=IN, type=VARCHAR, value='1334'}, system.task.definition.code=Property{prop='system.task.definition.code', direct=IN, type=VARCHAR, value='13210058002752'}, system.datetime=Property{prop='system.datetime', direct=IN, type=VARCHAR, value='20240424062701'}, folder=Property{prop='folder', direct=IN, type=VARCHAR, value='processing'}, system.project.code=Property{prop='system.project.code', direct=IN, type=VARCHAR, value='13010050770016'}, system.workflow.instance.id=Property{prop='system.workflow.instance.id', direct=IN, type=VARCHAR, value='557'}, raw_file_dir=Property{prop='raw_file_dir', direct=IN, type=VARCHAR, value='/local_storage/reddit/processing/500-20240423.json'}, system.biz.date=Property{prop='system.biz.date', direct=IN, type=VARCHAR, value='20240423'}, system.workflow.definition.name=Property{prop='system.workflow.definition.name', direct=IN, type=VARCHAR, value='preprocess_post'}, system.workflow.definition.code=Property{prop='system.workflow.definition.code', direct=IN, type=VARCHAR, value='13201021801792'}}, taskAppId=null, taskTimeoutStrategy=null, taskTimeout=2147483647, workerGroup=default, delayTime=0, currentExecutionStatus=TaskExecutionStatus{code=0, desc='submit success'}, resourceParametersHelper=null, endTime=0, sqlTaskExecutionContext=null, k8sTaskExecutionContext=null, resourceContext=null, varPool=[{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}], dryRun=0, paramsMap={}, dataQualityTaskExecutionContext=null, cpuQuota=-1, memoryMax=-1, testFlag=0, logBufferEnable=false, dispatchFailTimes=0))
[WI-557][TI-1334] - [INFO] 2024-04-24 06:27:01.198 +0800 o.a.d.s.w.r.o.TaskInstanceDispatchOperationFunction:[79] - Submit task: spark preprocessing to wait queue success
[WI-557][TI-1334] - [INFO] 2024-04-24 06:27:01.198 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-557][TI-1334] - [INFO] 2024-04-24 06:27:01.201 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Initialize task context  ***********************************
[WI-557][TI-1334] - [INFO] 2024-04-24 06:27:01.201 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-557][TI-1334] - [INFO] 2024-04-24 06:27:01.201 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[191] - Begin to initialize task
[WI-557][TI-1334] - [INFO] 2024-04-24 06:27:01.201 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[195] - Set task startTime: 1713911221201
[WI-557][TI-1334] - [INFO] 2024-04-24 06:27:01.201 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[200] - Set task appId: 557_1334
[WI-557][TI-1334] - [INFO] 2024-04-24 06:27:01.202 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[202] - End initialize task {
  "taskInstanceId" : 1334,
  "taskName" : "spark preprocessing",
  "firstSubmitTime" : 1713911221184,
  "startTime" : 1713911221201,
  "taskType" : "SHELL",
  "workflowInstanceHost" : "172.18.0.9:5678",
  "host" : "172.18.1.1:1234",
  "logPath" : "/opt/dolphinscheduler/logs/20240424/13201021801792/94/557/1334.log",
  "processId" : 0,
  "processDefineCode" : 13201021801792,
  "processDefineVersion" : 94,
  "processInstanceId" : 557,
  "scheduleTime" : 0,
  "globalParams" : "[{\"prop\":\"folder\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"processing\"}]",
  "executorId" : 1,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 13010050770016,
  "taskParams" : "{\"localParams\":[],\"rawScript\":\"$SPARK_HOME/bin/spark-submit \\\\\\n    --master spark://spark-master:7077 \\\\\\n    --deploy-mode client \\\\\\n    --conf spark.driver.cores=1 \\\\\\n    --conf spark.driver.memory=1G \\\\\\n    --conf spark.executor.instances=1 \\\\\\n    --conf spark.executor.cores=1 \\\\\\n    --conf spark.executor.memory=1G \\\\\\n    --name reddit_preprocessing \\\\\\n    testing.py\\n\\n# $SPARK_HOME/bin/spark-submit \\\\\\n#     --master local \\\\\\n#     --files ${raw_file_dir} \\\\\\n#     --name reddit_preprocessing spark_reddit_preprocessing.py\\n\",\"resourceList\":[{\"id\":null,\"resourceName\":\"file:/dolphinscheduler/default/resources/testing.py\",\"res\":null}]}",
  "environmentConfig" : "export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3\nexport JAVA_HOME=/opt/java/openjdk\nexport PYSPARK_DRIVER_PYTHON=/bin/python3.11\nexport PYTHON_LAUNCHER=/bin/python3.11\nexport PYSPARK_PYTHON=/bin/python3.11",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "spark preprocessing"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "REDDIT_HOME" : {
      "prop" : "REDDIT_HOME",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240424"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "1334"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13210058002752"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240424062701"
    },
    "folder" : {
      "prop" : "folder",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "processing"
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13010050770016"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "557"
    },
    "raw_file_dir" : {
      "prop" : "raw_file_dir",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "/local_storage/reddit/processing/500-20240423.json"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20240423"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "preprocess_post"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "13201021801792"
    }
  },
  "taskAppId" : "557_1334",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "varPool" : "[{\"prop\":\"raw_file_dir\",\"direct\":\"IN\",\"type\":\"VARCHAR\",\"value\":\"/local_storage/reddit/processing/500-20240423.json\"}]",
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[WI-557][TI-1334] - [INFO] 2024-04-24 06:27:01.202 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-557][TI-1334] - [INFO] 2024-04-24 06:27:01.202 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Load task instance plugin  *********************************
[WI-557][TI-1334] - [INFO] 2024-04-24 06:27:01.203 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-557][TI-1334] - [INFO] 2024-04-24 06:27:01.205 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[209] - Send task status RUNNING_EXECUTION master: 172.18.1.1:1234
[WI-557][TI-1334] - [INFO] 2024-04-24 06:27:01.205 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[217] - TenantCode: default check successfully
[WI-557][TI-1334] - [INFO] 2024-04-24 06:27:01.206 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[220] - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_94/557/1334 check successfully
[WI-557][TI-1334] - [INFO] 2024-04-24 06:27:01.206 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[227] - Create TaskChannel: org.apache.dolphinscheduler.plugin.task.shell.ShellTaskChannel successfully
[WI-557][TI-1334] - [INFO] 2024-04-24 06:27:01.208 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[232] - Download resources successfully: 
ResourceContext(resourceItemMap={file:/dolphinscheduler/default/resources/testing.py=ResourceContext.ResourceItem(resourceAbsolutePathInStorage=file:/dolphinscheduler/default/resources/testing.py, resourceRelativePath=testing.py, resourceAbsolutePathInLocal=/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_94/557/1334/testing.py)})
[WI-557][TI-1334] - [INFO] 2024-04-24 06:27:01.208 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[235] - Download upstream files: [] successfully
[WI-557][TI-1334] - [INFO] 2024-04-24 06:27:01.208 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[239] - Task plugin instance: SHELL create successfully
[WI-557][TI-1334] - [INFO] 2024-04-24 06:27:01.209 +0800 o.a.d.p.t.s.ShellTask:[70] - Initialize shell task params {
  "localParams" : [ ],
  "varPool" : null,
  "rawScript" : "$SPARK_HOME/bin/spark-submit \\\n    --master spark://spark-master:7077 \\\n    --deploy-mode client \\\n    --conf spark.driver.cores=1 \\\n    --conf spark.driver.memory=1G \\\n    --conf spark.executor.instances=1 \\\n    --conf spark.executor.cores=1 \\\n    --conf spark.executor.memory=1G \\\n    --name reddit_preprocessing \\\n    testing.py\n\n# $SPARK_HOME/bin/spark-submit \\\n#     --master local \\\n#     --files ${raw_file_dir} \\\n#     --name reddit_preprocessing spark_reddit_preprocessing.py\n",
  "resourceList" : [ {
    "id" : null,
    "resourceName" : "file:/dolphinscheduler/default/resources/testing.py",
    "res" : null
  } ]
}
[WI-557][TI-1334] - [INFO] 2024-04-24 06:27:01.209 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[243] - Success initialized task plugin instance successfully
[WI-557][TI-1334] - [INFO] 2024-04-24 06:27:01.209 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[246] - Set taskVarPool: [{"prop":"raw_file_dir","direct":"IN","type":"VARCHAR","value":"/local_storage/reddit/processing/500-20240423.json"}] successfully
[WI-557][TI-1334] - [INFO] 2024-04-24 06:27:01.209 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-557][TI-1334] - [INFO] 2024-04-24 06:27:01.209 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Execute task instance  *************************************
[WI-557][TI-1334] - [INFO] 2024-04-24 06:27:01.209 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-557][TI-1334] - [INFO] 2024-04-24 06:27:01.210 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[64] - Final Shell file is: 
[WI-557][TI-1334] - [INFO] 2024-04-24 06:27:01.210 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[65] - ****************************** Script Content *****************************************************************
[WI-557][TI-1334] - [INFO] 2024-04-24 06:27:01.210 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[67] - #!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
export SPARK_HOME=/opt/spark-3.5.1-bin-hadoop3
export JAVA_HOME=/opt/java/openjdk
export PYSPARK_DRIVER_PYTHON=/bin/python3.11
export PYTHON_LAUNCHER=/bin/python3.11
export PYSPARK_PYTHON=/bin/python3.11
$SPARK_HOME/bin/spark-submit \
    --master spark://spark-master:7077 \
    --deploy-mode client \
    --conf spark.driver.cores=1 \
    --conf spark.driver.memory=1G \
    --conf spark.executor.instances=1 \
    --conf spark.executor.cores=1 \
    --conf spark.executor.memory=1G \
    --name reddit_preprocessing \
    testing.py

# $SPARK_HOME/bin/spark-submit \
#     --master local \
#     --files /local_storage/reddit/processing/500-20240423.json \
#     --name reddit_preprocessing spark_reddit_preprocessing.py

[WI-557][TI-1334] - [INFO] 2024-04-24 06:27:01.210 +0800 o.a.d.p.t.a.s.BaseLinuxShellInterceptorBuilder:[68] - ****************************** Script Content *****************************************************************
[WI-557][TI-1334] - [INFO] 2024-04-24 06:27:01.210 +0800 o.a.d.p.t.a.s.BaseShellInterceptor:[46] - Executing shell command : sudo -u default -i /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_94/557/1334/557_1334.sh
[WI-557][TI-1334] - [INFO] 2024-04-24 06:27:01.214 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[154] - process start, process id is: 726
[WI-0][TI-1334] - [INFO] 2024-04-24 06:27:02.136 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionRunningEventAckListenFunction:[44] - Receive TaskInstanceExecutionRunningEventAck: TaskInstanceExecutionRunningEventAck(taskInstanceId=1334, success=true)
[WI-0][TI-1334] - [INFO] 2024-04-24 06:27:02.148 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionInfoEventAckListenFunction:[45] - Receive TaskInstanceExecutionInfoEventAck: TaskInstanceExecutionInfoEventAck(success=true, taskInstanceId=1334)
[WI-0][TI-0] - [INFO] 2024-04-24 06:27:02.214 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	sudo: unable to change directory to /home/default: No such file or directory
[WI-0][TI-0] - [INFO] 2024-04-24 06:27:04.081 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7611111111111111 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 06:27:05.112 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8634119473236194 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 06:27:05.217 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 06:27:04 INFO SparkContext: Running Spark version 3.5.1
	24/04/24 06:27:04 INFO SparkContext: OS info Linux, 6.5.0-28-generic, amd64
	24/04/24 06:27:04 INFO SparkContext: Java version 1.8.0_402
	24/04/24 06:27:04 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
	24/04/24 06:27:05 INFO ResourceUtils: ==============================================================
	24/04/24 06:27:05 INFO ResourceUtils: No custom resources configured for spark.driver.
	24/04/24 06:27:05 INFO ResourceUtils: ==============================================================
	24/04/24 06:27:05 INFO SparkContext: Submitted application: Create DataFrame from List
	24/04/24 06:27:05 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
	24/04/24 06:27:05 INFO ResourceProfile: Limiting resource is cpus at 1 tasks per executor
	24/04/24 06:27:05 INFO ResourceProfileManager: Added ResourceProfile id: 0
	24/04/24 06:27:05 INFO SecurityManager: Changing view acls to: default
	24/04/24 06:27:05 INFO SecurityManager: Changing modify acls to: default
	24/04/24 06:27:05 INFO SecurityManager: Changing view acls groups to: 
	24/04/24 06:27:05 INFO SecurityManager: Changing modify acls groups to: 
[WI-0][TI-0] - [INFO] 2024-04-24 06:27:06.117 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8270961494645706 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 06:27:06.245 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 06:27:05 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: default; groups with view permissions: EMPTY; users with modify permissions: default; groups with modify permissions: EMPTY
	24/04/24 06:27:05 INFO Utils: Successfully started service 'sparkDriver' on port 37065.
	24/04/24 06:27:05 INFO SparkEnv: Registering MapOutputTracker
	24/04/24 06:27:05 INFO SparkEnv: Registering BlockManagerMaster
	24/04/24 06:27:05 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
	24/04/24 06:27:05 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
	24/04/24 06:27:05 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
	24/04/24 06:27:05 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-2386ab74-b19c-40a1-9098-e9a7b575d4c4
	24/04/24 06:27:05 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
	24/04/24 06:27:05 INFO SparkEnv: Registering OutputCommitCoordinator
[WI-0][TI-0] - [INFO] 2024-04-24 06:27:07.129 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8039772727272727 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 06:27:07.249 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 06:27:06 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
	24/04/24 06:27:06 INFO Utils: Successfully started service 'SparkUI' on port 4040.
	24/04/24 06:27:06 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
	24/04/24 06:27:06 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.6:7077 after 128 ms (0 ms spent in bootstraps)
	24/04/24 06:27:07 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20240423222707-0002
	24/04/24 06:27:07 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20240423222707-0002/0 on worker-20240423220329-172.18.0.8-33083 (172.18.0.8:33083) with 1 core(s)
	24/04/24 06:27:07 INFO StandaloneSchedulerBackend: Granted executor ID app-20240423222707-0002/0 on hostPort 172.18.0.8:33083 with 1 core(s), 1024.0 MiB RAM
	24/04/24 06:27:07 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20240423222707-0002/1 on worker-20240423220329-172.18.0.8-33083 (172.18.0.8:33083) with 1 core(s)
[WI-0][TI-0] - [INFO] 2024-04-24 06:27:08.143 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.994413407821229 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 06:27:08.267 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 06:27:07 INFO StandaloneSchedulerBackend: Granted executor ID app-20240423222707-0002/1 on hostPort 172.18.0.8:33083 with 1 core(s), 1024.0 MiB RAM
	24/04/24 06:27:07 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36553.
	24/04/24 06:27:07 INFO NettyBlockTransferService: Server created on 62c50ccd7bf9:36553
	24/04/24 06:27:07 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
	24/04/24 06:27:07 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20240423222707-0002/0 is now RUNNING
	24/04/24 06:27:07 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 62c50ccd7bf9, 36553, None)
	24/04/24 06:27:07 INFO BlockManagerMasterEndpoint: Registering block manager 62c50ccd7bf9:36553 with 366.3 MiB RAM, BlockManagerId(driver, 62c50ccd7bf9, 36553, None)
	24/04/24 06:27:07 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20240423222707-0002/1 is now RUNNING
	24/04/24 06:27:07 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 62c50ccd7bf9, 36553, None)
	24/04/24 06:27:07 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 62c50ccd7bf9, 36553, None)
[WI-0][TI-0] - [INFO] 2024-04-24 06:27:09.154 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9802631578947368 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 06:27:09.273 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 06:27:08 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
	24/04/24 06:27:09 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
	24/04/24 06:27:09 INFO SharedState: Warehouse path is 'file:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_94/557/1334/spark-warehouse'.
[WI-0][TI-0] - [INFO] 2024-04-24 06:27:10.162 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9777777777777777 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 06:27:11.167 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.993485342019544 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 06:27:12.169 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9742765273311897 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 06:27:13.174 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9737704918032787 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 06:27:14.184 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9870967741935484 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 06:27:15.232 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.976027397260274 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 06:27:16.233 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9506172839506173 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 06:27:17.235 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9397163120567376 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 06:27:17.297 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 06:27:17 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.8:42356) with ID 0,  ResourceProfileId 0
[WI-0][TI-0] - [INFO] 2024-04-24 06:27:18.240 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9832402234636871 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 06:27:18.299 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 06:27:17 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.8:44449 with 434.4 MiB RAM, BlockManagerId(0, 172.18.0.8, 44449, None)
	24/04/24 06:27:17 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.8:42366) with ID 1,  ResourceProfileId 0
	24/04/24 06:27:17 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.8:46359 with 434.4 MiB RAM, BlockManagerId(1, 172.18.0.8, 46359, None)
[WI-0][TI-0] - [INFO] 2024-04-24 06:27:19.244 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.8022388059701493 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 06:27:19.300 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 06:27:18 INFO CodeGenerator: Code generated in 1076.953704 ms
	24/04/24 06:27:18 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0
	24/04/24 06:27:18 INFO DAGScheduler: Got job 0 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
	24/04/24 06:27:18 INFO DAGScheduler: Final stage: ResultStage 0 (showString at NativeMethodAccessorImpl.java:0)
	24/04/24 06:27:18 INFO DAGScheduler: Parents of final stage: List()
	24/04/24 06:27:18 INFO DAGScheduler: Missing parents: List()
	24/04/24 06:27:18 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[6] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
	24/04/24 06:27:19 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 12.7 KiB, free 366.3 MiB)
	24/04/24 06:27:19 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 366.3 MiB)
	24/04/24 06:27:19 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 62c50ccd7bf9:36553 (size: 6.7 KiB, free: 366.3 MiB)
	24/04/24 06:27:19 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1585
	24/04/24 06:27:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[6] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
	24/04/24 06:27:19 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
[WI-0][TI-0] - [INFO] 2024-04-24 06:27:20.302 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 06:27:19 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.8, executor 1, partition 0, PROCESS_LOCAL, 7636 bytes) 
[WI-0][TI-0] - [INFO] 2024-04-24 06:28:59.836 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 06:28:59 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20240423222707-0002/0 is now EXITED (Command exited with code 143)
	24/04/24 06:28:59 INFO StandaloneSchedulerBackend: Executor app-20240423222707-0002/0 removed: Command exited with code 143
	24/04/24 06:28:59 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20240423222707-0002/2 on worker-20240423220329-172.18.0.8-33083 (172.18.0.8:33083) with 1 core(s)
	24/04/24 06:28:59 INFO StandaloneSchedulerBackend: Granted executor ID app-20240423222707-0002/2 on hostPort 172.18.0.8:33083 with 1 core(s), 1024.0 MiB RAM
	24/04/24 06:28:59 ERROR TaskSchedulerImpl: Lost executor 0 on 172.18.0.8: Command exited with code 143
	24/04/24 06:28:59 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20240423222707-0002/2 is now FAILED (java.lang.IllegalStateException: Shutdown hooks cannot be modified during shutdown.)
	24/04/24 06:28:59 INFO StandaloneSchedulerBackend: Executor app-20240423222707-0002/2 removed: java.lang.IllegalStateException: Shutdown hooks cannot be modified during shutdown.
	24/04/24 06:28:59 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20240423222707-0002/3 on worker-20240423220329-172.18.0.8-33083 (172.18.0.8:33083) with 1 core(s)
	24/04/24 06:28:59 INFO StandaloneSchedulerBackend: Granted executor ID app-20240423222707-0002/3 on hostPort 172.18.0.8:33083 with 1 core(s), 1024.0 MiB RAM
	24/04/24 06:28:59 INFO DAGScheduler: Executor lost: 0 (epoch 0)
	24/04/24 06:28:59 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20240423222707-0002/3 is now FAILED (java.lang.IllegalStateException: Shutdown hooks cannot be modified during shutdown.)
	24/04/24 06:28:59 INFO StandaloneSchedulerBackend: Executor app-20240423222707-0002/3 removed: java.lang.IllegalStateException: Shutdown hooks cannot be modified during shutdown.
	24/04/24 06:28:59 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20240423222707-0002/4 on worker-20240423220329-172.18.0.8-33083 (172.18.0.8:33083) with 1 core(s)
	24/04/24 06:28:59 INFO StandaloneSchedulerBackend: Granted executor ID app-20240423222707-0002/4 on hostPort 172.18.0.8:33083 with 1 core(s), 1024.0 MiB RAM
	24/04/24 06:28:59 INFO BlockManagerMaster: Removal of executor 2 requested
	24/04/24 06:28:59 INFO BlockManagerMasterEndpoint: Trying to remove executor 0 from BlockManagerMaster.
	24/04/24 06:28:59 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Asked to remove non-existent executor 2
	24/04/24 06:28:59 INFO BlockManagerMaster: Removal of executor 3 requested
	24/04/24 06:28:59 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Asked to remove non-existent executor 3
	24/04/24 06:28:59 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20240423222707-0002/4 is now FAILED (java.lang.IllegalStateException: Shutdown hooks cannot be modified during shutdown.)
	24/04/24 06:28:59 INFO StandaloneSchedulerBackend: Executor app-20240423222707-0002/4 removed: java.lang.IllegalStateException: Shutdown hooks cannot be modified during shutdown.
	24/04/24 06:28:59 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20240423222707-0002/5 on worker-20240423220329-172.18.0.8-33083 (172.18.0.8:33083) with 1 core(s)
	24/04/24 06:28:59 INFO StandaloneSchedulerBackend: Granted executor ID app-20240423222707-0002/5 on hostPort 172.18.0.8:33083 with 1 core(s), 1024.0 MiB RAM
	24/04/24 06:28:59 INFO BlockManagerMaster: Removal of executor 4 requested
	24/04/24 06:28:59 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Asked to remove non-existent executor 4
	24/04/24 06:28:59 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(0, 172.18.0.8, 44449, None)
	24/04/24 06:28:59 INFO BlockManagerMasterEndpoint: Trying to remove executor 2 from BlockManagerMaster.
	24/04/24 06:28:59 INFO BlockManagerMasterEndpoint: Trying to remove executor 3 from BlockManagerMaster.
	24/04/24 06:28:59 INFO BlockManagerMasterEndpoint: Trying to remove executor 4 from BlockManagerMaster.
	24/04/24 06:28:59 INFO BlockManagerMaster: Removed 0 successfully in removeExecutor
	24/04/24 06:28:59 INFO DAGScheduler: Shuffle files lost for executor: 0 (epoch 0)
	24/04/24 06:28:59 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20240423222707-0002/5 is now FAILED (java.lang.IllegalStateException: Shutdown hooks cannot be modified during shutdown.)
	24/04/24 06:28:59 INFO StandaloneSchedulerBackend: Executor app-20240423222707-0002/5 removed: java.lang.IllegalStateException: Shutdown hooks cannot be modified during shutdown.
	24/04/24 06:28:59 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20240423222707-0002/6 on worker-20240423220329-172.18.0.8-33083 (172.18.0.8:33083) with 1 core(s)
	24/04/24 06:28:59 INFO StandaloneSchedulerBackend: Granted executor ID app-20240423222707-0002/6 on hostPort 172.18.0.8:33083 with 1 core(s), 1024.0 MiB RAM
	24/04/24 06:28:59 INFO BlockManagerMasterEndpoint: Trying to remove executor 5 from BlockManagerMaster.
	24/04/24 06:28:59 INFO BlockManagerMaster: Removal of executor 5 requested
	24/04/24 06:28:59 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Asked to remove non-existent executor 5
	24/04/24 06:28:59 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20240423222707-0002/6 is now FAILED (java.lang.IllegalStateException: Shutdown hooks cannot be modified during shutdown.)
	24/04/24 06:28:59 INFO StandaloneSchedulerBackend: Executor app-20240423222707-0002/6 removed: java.lang.IllegalStateException: Shutdown hooks cannot be modified during shutdown.
	24/04/24 06:28:59 INFO BlockManagerMasterEndpoint: Trying to remove executor 6 from BlockManagerMaster.
	24/04/24 06:28:59 INFO BlockManagerMaster: Removal of executor 6 requested
	24/04/24 06:28:59 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Asked to remove non-existent executor 6
	24/04/24 06:28:59 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20240423222707-0002/7 on worker-20240423220329-172.18.0.8-33083 (172.18.0.8:33083) with 1 core(s)
	24/04/24 06:28:59 INFO StandaloneSchedulerBackend: Granted executor ID app-20240423222707-0002/7 on hostPort 172.18.0.8:33083 with 1 core(s), 1024.0 MiB RAM
	24/04/24 06:28:59 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20240423222707-0002/7 is now FAILED (java.lang.IllegalStateException: Shutdown hooks cannot be modified during shutdown.)
	24/04/24 06:28:59 INFO StandaloneSchedulerBackend: Executor app-20240423222707-0002/7 removed: java.lang.IllegalStateException: Shutdown hooks cannot be modified during shutdown.
	24/04/24 06:28:59 INFO BlockManagerMasterEndpoint: Trying to remove executor 7 from BlockManagerMaster.
	24/04/24 06:28:59 INFO BlockManagerMaster: Removal of executor 7 requested
	24/04/24 06:28:59 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Asked to remove non-existent executor 7
	24/04/24 06:28:59 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20240423222707-0002/8 on worker-20240423220329-172.18.0.8-33083 (172.18.0.8:33083) with 1 core(s)
	24/04/24 06:28:59 INFO StandaloneSchedulerBackend: Granted executor ID app-20240423222707-0002/8 on hostPort 172.18.0.8:33083 with 1 core(s), 1024.0 MiB RAM
[WI-0][TI-0] - [INFO] 2024-04-24 06:29:00.004 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.7367021276595745 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 06:29:00.842 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 06:28:59 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20240423222707-0002/8 is now FAILED (java.lang.IllegalStateException: Shutdown hooks cannot be modified during shutdown.)
	24/04/24 06:28:59 INFO StandaloneSchedulerBackend: Executor app-20240423222707-0002/8 removed: java.lang.IllegalStateException: Shutdown hooks cannot be modified during shutdown.
	24/04/24 06:28:59 INFO BlockManagerMasterEndpoint: Trying to remove executor 8 from BlockManagerMaster.
	24/04/24 06:28:59 INFO BlockManagerMaster: Removal of executor 8 requested
	24/04/24 06:28:59 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Asked to remove non-existent executor 8
	24/04/24 06:28:59 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20240423222707-0002/9 on worker-20240423220329-172.18.0.8-33083 (172.18.0.8:33083) with 1 core(s)
	24/04/24 06:28:59 INFO StandaloneSchedulerBackend: Granted executor ID app-20240423222707-0002/9 on hostPort 172.18.0.8:33083 with 1 core(s), 1024.0 MiB RAM
	24/04/24 06:28:59 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20240423222707-0002/9 is now FAILED (java.lang.IllegalStateException: Shutdown hooks cannot be modified during shutdown.)
	24/04/24 06:28:59 INFO StandaloneSchedulerBackend: Executor app-20240423222707-0002/9 removed: java.lang.IllegalStateException: Shutdown hooks cannot be modified during shutdown.
	24/04/24 06:28:59 INFO BlockManagerMasterEndpoint: Trying to remove executor 9 from BlockManagerMaster.
	24/04/24 06:28:59 INFO BlockManagerMaster: Removal of executor 9 requested
	24/04/24 06:28:59 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Asked to remove non-existent executor 9
	24/04/24 06:28:59 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20240423222707-0002/10 on worker-20240423220329-172.18.0.8-33083 (172.18.0.8:33083) with 1 core(s)
	24/04/24 06:28:59 INFO StandaloneSchedulerBackend: Granted executor ID app-20240423222707-0002/10 on hostPort 172.18.0.8:33083 with 1 core(s), 1024.0 MiB RAM
	24/04/24 06:28:59 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20240423222707-0002/1 is now EXITED (Command exited with code 143)
	24/04/24 06:28:59 INFO StandaloneSchedulerBackend: Executor app-20240423222707-0002/1 removed: Command exited with code 143
	24/04/24 06:28:59 ERROR TaskSchedulerImpl: Lost executor 1 on 172.18.0.8: Command exited with code 143
	24/04/24 06:28:59 ERROR StandaloneSchedulerBackend: Application has been killed. Reason: Master removed our application: FAILED
	24/04/24 06:28:59 INFO TaskSetManager: task 0.0 in stage 0.0 (TID 0) failed because while it was being computed, its executor exited for a reason unrelated to the task. Not counting this failure towards the maximum number of failures for the task.
	24/04/24 06:29:00 INFO DAGScheduler: Executor lost: 1 (epoch 1)
	24/04/24 06:29:00 INFO BlockManagerMasterEndpoint: Trying to remove executor 1 from BlockManagerMaster.
	24/04/24 06:29:00 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
	24/04/24 06:29:00 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(1, 172.18.0.8, 46359, None)
	24/04/24 06:29:00 INFO BlockManagerMaster: Removed 1 successfully in removeExecutor
	24/04/24 06:29:00 INFO DAGScheduler: Shuffle files lost for executor: 1 (epoch 1)
	24/04/24 06:29:00 INFO TaskSchedulerImpl: Cancelling stage 0
	24/04/24 06:29:00 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage cancelled: Job aborted due to stage failure: Master removed our application: FAILED
	24/04/24 06:29:00 INFO DAGScheduler: ResultStage 0 (showString at NativeMethodAccessorImpl.java:0) failed in 101.401 s due to Job aborted due to stage failure: Master removed our application: FAILED
	24/04/24 06:29:00 INFO SparkContext: SparkContext is stopping with exitCode 0.
	24/04/24 06:29:00 INFO DAGScheduler: Job 0 failed: showString at NativeMethodAccessorImpl.java:0, took 101.611566 s
	24/04/24 06:29:00 INFO SparkUI: Stopped Spark web UI at http://62c50ccd7bf9:4040
	24/04/24 06:29:00 INFO StandaloneSchedulerBackend: Shutting down all executors
	24/04/24 06:29:00 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Asking each executor to shut down
	24/04/24 06:29:00 ERROR Utils: Uncaught exception in thread stop-spark-context
	org.apache.spark.SparkException: Exception thrown in awaitResult: 
		at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
		at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
		at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
		at org.apache.spark.deploy.client.StandaloneAppClient.stop(StandaloneAppClient.scala:288)
		at org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend.org$apache$spark$scheduler$cluster$StandaloneSchedulerBackend$$stop(StandaloneSchedulerBackend.scala:275)
		at org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend.stop(StandaloneSchedulerBackend.scala:142)
		at org.apache.spark.scheduler.SchedulerBackend.stop(SchedulerBackend.scala:33)
		at org.apache.spark.scheduler.SchedulerBackend.stop$(SchedulerBackend.scala:33)
		at org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend.stop(CoarseGrainedSchedulerBackend.scala:54)
		at org.apache.spark.scheduler.TaskSchedulerImpl.$anonfun$stop$2(TaskSchedulerImpl.scala:992)
		at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1375)
		at org.apache.spark.scheduler.TaskSchedulerImpl.stop(TaskSchedulerImpl.scala:992)
		at org.apache.spark.scheduler.DAGScheduler.$anonfun$stop$4(DAGScheduler.scala:2976)
		at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1375)
		at org.apache.spark.scheduler.DAGScheduler.stop(DAGScheduler.scala:2976)
		at org.apache.spark.SparkContext.$anonfun$stop$12(SparkContext.scala:2263)
		at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1375)
		at org.apache.spark.SparkContext.stop(SparkContext.scala:2263)
		at org.apache.spark.SparkContext.stop(SparkContext.scala:2216)
		at org.apache.spark.SparkContext$$anon$3.run(SparkContext.scala:2203)
	Caused by: org.apache.spark.SparkException: Could not find AppClient.
		at org.apache.spark.rpc.netty.Dispatcher.postMessage(Dispatcher.scala:178)
		at org.apache.spark.rpc.netty.Dispatcher.postLocalMessage(Dispatcher.scala:144)
		at org.apache.spark.rpc.netty.NettyRpcEnv.askAbortable(NettyRpcEnv.scala:242)
		at org.apache.spark.rpc.netty.NettyRpcEndpointRef.askAbortable(NettyRpcEnv.scala:554)
		at org.apache.spark.rpc.netty.NettyRpcEndpointRef.ask(NettyRpcEnv.scala:558)
		at org.apache.spark.rpc.RpcEndpointRef.ask(RpcEndpointRef.scala:72)
		... 17 more
	24/04/24 06:29:00 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
[WI-0][TI-0] - [INFO] 2024-04-24 06:29:01.046 +0800 o.a.d.s.w.c.WorkerServerLoadProtection:[48] - Worker OverLoad: the TotalCpuUsedPercentage: 0.9530791788856305 is over then the MaxCpuUsagePercentageThresholds 0.7
[WI-0][TI-0] - [INFO] 2024-04-24 06:29:01.844 +0800 o.a.d.p.t.a.AbstractTask:[169] -  -> 
	24/04/24 06:29:00 INFO MemoryStore: MemoryStore cleared
	24/04/24 06:29:00 INFO BlockManager: BlockManager stopped
	24/04/24 06:29:00 INFO BlockManagerMaster: BlockManagerMaster stopped
	24/04/24 06:29:00 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
	Traceback (most recent call last):
	  File "/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_94/557/1334/testing.py", line 19, in <module>
	    df.show()
	  File "/opt/spark-3.5.1-bin-hadoop3/python/lib/pyspark.zip/pyspark/sql/dataframe.py", line 945, in show
	  File "/opt/spark-3.5.1-bin-hadoop3/python/lib/pyspark.zip/pyspark/sql/dataframe.py", line 963, in _show_string
	  File "/opt/spark-3.5.1-bin-hadoop3/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
	  File "/opt/spark-3.5.1-bin-hadoop3/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 179, in deco
	  File "/opt/spark-3.5.1-bin-hadoop3/python/lib/py4j-0.10.9.7-src.zip/py4j/protocol.py", line 326, in get_return_value
	py4j.protocol.Py4JJavaError24/04/24 06:29:01 INFO SparkContext: Successfully stopped SparkContext
	: An error occurred while calling o46.showString.
	: org.apache.spark.SparkException: Job aborted due to stage failure: Master removed our application: FAILED
		at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)
		at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)
		at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)
		at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
		at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
		at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
		at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)
		at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)
		at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)
		at scala.Option.foreach(Option.scala:407)
		at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)
		at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)
		at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)
		at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)
		at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
		at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:989)
		at org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)
		at org.apache.spark.SparkContext.runJob(SparkContext.scala:2419)
		at org.apache.spark.SparkContext.runJob(SparkContext.scala:2438)
		at org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:530)
		at org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:483)
		at org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:61)
		at org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:4332)
		at org.apache.spark.sql.Dataset.$anonfun$head$1(Dataset.scala:3314)
		at org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:4322)
		at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
		at org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:4320)
		at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)
		at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)
		at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)
		at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
		at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)
		at org.apache.spark.sql.Dataset.withAction(Dataset.scala:4320)
		at org.apache.spark.sql.Dataset.head(Dataset.scala:3314)
		at org.apache.spark.sql.Dataset.take(Dataset.scala:3537)
		at org.apache.spark.sql.Dataset.getRows(Dataset.scala:280)
		at org.apache.spark.sql.Dataset.showString(Dataset.scala:315)
		at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
		at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
		at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
		at java.lang.reflect.Method.invoke(Method.java:498)
		at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
		at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
		at py4j.Gateway.invoke(Gateway.java:282)
		at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
		at py4j.commands.CallCommand.execute(CallCommand.java:79)
		at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
		at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
		at java.lang.Thread.run(Thread.java:750)
	
	24/04/24 06:29:01 INFO ShutdownHookManager: Shutdown hook called
	24/04/24 06:29:01 INFO ShutdownHookManager: Deleting directory /tmp/spark-057c1852-5cd3-4d1c-880b-36a264f1c156
	24/04/24 06:29:01 INFO ShutdownHookManager: Deleting directory /tmp/spark-22245d43-8a71-40cd-8ff4-7b445aa33089
	24/04/24 06:29:01 INFO ShutdownHookManager: Deleting directory /tmp/spark-057c1852-5cd3-4d1c-880b-36a264f1c156/pyspark-d6325ca1-1c13-43de-90fc-e9f64d30e8d9
[WI-557][TI-1334] - [INFO] 2024-04-24 06:29:01.845 +0800 o.a.d.p.t.a.AbstractCommandExecutor:[204] - process has exited. execute path:/tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_94/557/1334, processId:726 ,exitStatusCode:1 ,processWaitForStatus:true ,processExitValue:1
[WI-557][TI-1334] - [INFO] 2024-04-24 06:29:01.846 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-557][TI-1334] - [INFO] 2024-04-24 06:29:01.846 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - *********************************  Finalize task instance  ************************************
[WI-557][TI-1334] - [INFO] 2024-04-24 06:29:01.847 +0800 o.a.d.p.t.a.l.TaskInstanceLogHeader:[1259] - ***********************************************************************************************
[WI-557][TI-1334] - [INFO] 2024-04-24 06:29:01.853 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[289] - Upload output files: [] successfully
[WI-557][TI-1334] - [INFO] 2024-04-24 06:29:01.884 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[294] - Send task execute status: FAILURE to master : 172.18.1.1:1234
[WI-557][TI-1334] - [INFO] 2024-04-24 06:29:01.885 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[111] - Remove the current task execute context from worker cache
[WI-557][TI-1334] - [INFO] 2024-04-24 06:29:01.886 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[301] - The current execute mode isn't develop mode, will clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_94/557/1334
[WI-557][TI-1334] - [INFO] 2024-04-24 06:29:01.903 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[316] - Success clear the task execute file: /tmp/dolphinscheduler/exec/process/default/13010050770016/13201021801792_94/557/1334
[WI-557][TI-1334] - [INFO] 2024-04-24 06:29:01.904 +0800 o.a.d.s.w.r.WorkerTaskExecutor:[342] - FINALIZE_SESSION
[WI-0][TI-1334] - [INFO] 2024-04-24 06:29:02.846 +0800 o.a.d.s.w.r.l.TaskInstanceExecutionFinishEventAckListenFunction:[44] - Receive TaskInstanceExecutionFinishEventAck: TaskInstanceExecutionFinishEventAck(taskInstanceId=1334, success=true)
